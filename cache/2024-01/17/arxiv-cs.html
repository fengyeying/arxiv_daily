<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 12 Jan 24  to  Tue 16 Jan 24, announced Wed, 17 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item748">Cross-lists</a></li>
<li><a href="#item855">Replacements</a></li>
</ul>
<small>[ total of 1426 entries:  <b>1-1426</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 17 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06772" title="Abstract">arXiv:2401.06772</a> [<a href="/pdf/2401.06772" title="Download PDF">pdf</a>, <a href="/ps/2401.06772" title="Download PostScript">ps</a>, <a href="/format/2401.06772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Segment Based Semantic Parsing for Question Answering over  Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Sijia Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qisong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel method named "graph-to-segment" for
question answering over knowledge graphs, focusing on understanding question
utterances. This method centers on semantic parsing, a key approach for
interpreting these utterances. Our primary challenge lies in comprehending
implicit entities, relationships, and complex constraints like time,
ordinality, and aggregation within questions, contextualized by the knowledge
graph. Our framework employs a combination of rule-based and neural-based
techniques to parse and construct highly accurate and comprehensive semantic
segment sequences. These sequences form semantic query graphs, effectively
representing question utterances. We approach question semantic parsing as a
sequence generation task, utilizing an encoder-decoder neural network to
transform natural language questions into semantic segments. Moreover, to
enhance the parsing of implicit entities and relations, we incorporate a graph
neural network that leverages the context of the knowledge graph to better
understand question representations. Our experimental evaluations on two
datasets demonstrate the effectiveness and superior performance of our model in
semantic parsing for question answering.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06774" title="Abstract">arXiv:2401.06774</a> [<a href="/pdf/2401.06774" title="Download PDF">pdf</a>, <a href="/format/2401.06774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Directions for Clinical Data Generation with Large Language Models:  Data-to-Label and Label-to-Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rumeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appear in EMNLP2023 Findings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) can generate natural language texts for various
domains and tasks, but their potential for clinical text mining, a domain with
scarce, sensitive, and imbalanced medical data, is underexplored. We
investigate whether LLMs can augment clinical data for detecting Alzheimer's
Disease (AD)-related signs and symptoms from electronic health records (EHRs),
a challenging task that requires high expertise. We create a novel pragmatic
taxonomy for AD sign and symptom progression based on expert knowledge, which
guides LLMs to generate synthetic data following two different directions:
"data-to-label", which labels sentences from a public EHR collection with
AD-related signs and symptoms; and "label-to-data", which generates sentences
with AD-related signs and symptoms based on the label definition. We train a
system to detect AD-related signs and symptoms from EHRs, using three datasets:
(1) a gold dataset annotated by human experts on longitudinal EHRs of AD
patients; (2) a silver dataset created by the data-to-label method; and (3) a
bronze dataset created by the label-to-data method. We find that using the
silver and bronze datasets improves the system performance, outperforming the
system using only the gold dataset. This shows that LLMs can generate synthetic
clinical data for a complex task by incorporating expert knowledge, and our
label-to-data method can produce datasets that are free of sensitive
information, while maintaining acceptable quality.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06775" title="Abstract">arXiv:2401.06775</a> [<a href="/pdf/2401.06775" title="Download PDF">pdf</a>, <a href="/format/2401.06775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large language models in healthcare and medical domain: A review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nazi%2C+Z+A">Zabir Al Nazi</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wei Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The deployment of large language models (LLMs) within the healthcare sector
has sparked both enthusiasm and apprehension. These models exhibit the
remarkable capability to provide proficient responses to free-text queries,
demonstrating a nuanced understanding of professional medical knowledge. This
comprehensive survey delves into the functionalities of existing LLMs designed
for healthcare applications, elucidating the trajectory of their development,
starting from traditional Pretrained Language Models (PLMs) to the present
state of LLMs in healthcare sector. First, we explore the potential of LLMs to
amplify the efficiency and effectiveness of diverse healthcare applications,
particularly focusing on clinical language understanding tasks. These tasks
encompass a wide spectrum, ranging from named entity recognition and relation
extraction to natural language inference, multi-modal medical applications,
document classification, and question-answering. Additionally, we conduct an
extensive comparison of the most recent state-of-the-art LLMs in the healthcare
domain, while also assessing the utilization of various open-source LLMs and
highlighting their significance in healthcare applications. Furthermore, we
present the essential performance metrics employed to evaluate LLMs in the
biomedical domain, shedding light on their effectiveness and limitations.
Finally, we summarize the prominent challenges and constraints faced by large
language models in the healthcare sector, offering a holistic perspective on
their potential benefits and shortcomings. This review provides a comprehensive
exploration of the current landscape of LLMs in healthcare, addressing their
role in transforming medical applications and the areas that warrant further
research and development.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06781" title="Abstract">arXiv:2401.06781</a> [<a href="/pdf/2401.06781" title="Download PDF">pdf</a>, <a href="/format/2401.06781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PokerGPT: An End-to-End Lightweight Solver for Multi-Player Texas  Hold&#x27;em via Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenghao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yanbo Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yinlong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanru Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Poker, also known as Texas Hold'em, has always been a typical research target
within imperfect information games (IIGs). IIGs have long served as a measure
of artificial intelligence (AI) development. Representative prior works, such
as DeepStack and Libratus heavily rely on counterfactual regret minimization
(CFR) to tackle heads-up no-limit Poker. However, it is challenging for
subsequent researchers to learn CFR from previous models and apply it to other
real-world applications due to the expensive computational cost of CFR
iterations. Additionally, CFR is difficult to apply to multi-player games due
to the exponential growth of the game tree size. In this work, we introduce
PokerGPT, an end-to-end solver for playing Texas Hold'em with arbitrary number
of players and gaining high win rates, established on a lightweight large
language model (LLM). PokerGPT only requires simple textual information of
Poker games for generating decision-making advice, thus guaranteeing the
convenient interaction between AI and humans. We mainly transform a set of
textual records acquired from real games into prompts, and use them to
fine-tune a lightweight pre-trained LLM using reinforcement learning human
feedback technique. To improve fine-tuning performance, we conduct prompt
engineering on raw data, including filtering useful information, selecting
behaviors of players with high win rates, and further processing them into
textual instruction using multiple prompt engineering techniques. Through the
experiments, we demonstrate that PokerGPT outperforms previous approaches in
terms of win rate, model size, training time, and response speed, indicating
the great potential of LLMs in solving IIGs.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06782" title="Abstract">arXiv:2401.06782</a> [<a href="/pdf/2401.06782" title="Download PDF">pdf</a>, <a href="/format/2401.06782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Similarity Matching for Patent Documents Using Ensemble  BERT-related Model and Novel Text Processing Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Liqiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qunwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+C">Chang Che</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> It accepted by The 6th International Conference on Machine Learning and Machine Intelligence (MLMI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the realm of patent document analysis, assessing semantic similarity
between phrases presents a significant challenge, notably amplifying the
inherent complexities of Cooperative Patent Classification (CPC) research.
Firstly, this study addresses these challenges, recognizing early CPC work
while acknowledging past struggles with language barriers and document
intricacy. Secondly, it underscores the persisting difficulties of CPC
research.
<br />To overcome these challenges and bolster the CPC system, This paper presents
two key innovations. Firstly, it introduces an ensemble approach that
incorporates four BERT-related models, enhancing semantic similarity accuracy
through weighted averaging. Secondly, a novel text preprocessing method
tailored for patent documents is introduced, featuring a distinctive input
structure with token scoring that aids in capturing semantic relationships
during CPC context training, utilizing BCELoss. Our experimental findings
conclusively establish the effectiveness of both our Ensemble Model and novel
text processing strategies when deployed on the U.S. Patent Phrase to Phrase
Matching dataset.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06783" title="Abstract">arXiv:2401.06783</a> [<a href="/pdf/2401.06783" title="Download PDF">pdf</a>, <a href="/format/2401.06783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiSiam: A Multiple Input Siamese Network For Social Media Text  Classification And Duplicate Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhoi%2C+S">Sudhanshu Bhoi</a>, 
<a href="/search/cs?searchtype=author&query=Markhedkar%2C+S">Swapnil Markhedkar</a>, 
<a href="/search/cs?searchtype=author&query=Phadke%2C+S">Shruti Phadke</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Prashant Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Social media accounts post increasingly similar content, creating a chaotic
experience across platforms, which makes accessing desired information
difficult. These posts can be organized by categorizing and grouping duplicates
across social handles and accounts. There can be more than one duplicate of a
post, however, a conventional Siamese neural network only considers a pair of
inputs for duplicate text detection. In this paper, we first propose a
multiple-input Siamese network, MultiSiam. This condensed network is then used
to propose another model, SMCD (Social Media Classification and Duplication
Model) to perform both duplicate text grouping and categorization. The
MultiSiam network, just like the Siamese, can be used in multiple applications
by changing the sub-network appropriately.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06785" title="Abstract">arXiv:2401.06785</a> [<a href="/pdf/2401.06785" title="Download PDF">pdf</a>, <a href="/format/2401.06785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Instruction-Free LLM Self-Alignment with Limited Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuanshun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jiaheng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Aligning large language models (LLMs) with human values is a vital task for
LLM practitioners. Current alignment techniques have several limitations: (1)
requiring a large amount of annotated data; (2) demanding heavy human
involvement; (3) lacking a systematic mechanism to continuously improve. In
this work, we study aligning LLMs to a new domain with limited samples (e.g. &lt;
100). We propose an algorithm that can self-align LLMs iteratively without
active human involvement. Unlike existing works, our algorithm relies on
neither human-crafted instructions nor labeled rewards, significantly reducing
human involvement. In addition, our algorithm can self-improve the alignment
continuously. The key idea is to first retrieve high-quality samples related to
the target domain and use them as In-context Learning examples to generate more
samples. Then we use the self-generated samples to finetune the LLM
iteratively. We show that our method can unlock the LLMs' self-generalization
ability to perform alignment with near-zero human supervision. We test our
algorithm on three benchmarks in safety, truthfulness, and
instruction-following, and show good performance in alignment, domain
adaptability, and scalability.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06786" title="Abstract">arXiv:2401.06786</a> [<a href="/pdf/2401.06786" title="Download PDF">pdf</a>, <a href="/format/2401.06786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CloudEval-YAML: A Practical Benchmark for Cloud Configuration Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xumiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianshang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Pan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunfei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Songwu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wan Du</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhuoqing Mao</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+E">Ennan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dennis Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Among the thriving ecosystem of cloud computing and the proliferation of
Large Language Model (LLM)-based code generation tools, there is a lack of
benchmarking for code generation in cloud-native applications. In response to
this need, we present CloudEval-YAML, a practical benchmark for cloud
configuration generation. CloudEval-YAML tackles the diversity challenge by
focusing on YAML, the de facto standard of numerous cloud-native tools. We
develop the CloudEval-YAML benchmark with practicality in mind: the dataset
consists of hand-written problems with unit tests targeting practical
scenarios. We further enhanced the dataset to meet practical needs by
rephrasing questions in a concise, abbreviated, and bilingual manner. The
dataset consists of 1011 problems that take more than 1200 human hours to
complete. To improve practicality during evaluation, we build a scalable
evaluation platform for CloudEval-YAML that achieves a 20 times speedup over a
single machine. To the best of our knowledge, the CloudEval-YAML dataset is the
first hand-written dataset targeting cloud-native applications. We present an
in-depth evaluation of 12 LLMs, leading to a deeper understanding of the
problems and LLMs, as well as effective methods to improve task performance and
reduce cost.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06787" title="Abstract">arXiv:2401.06787</a> [<a href="/pdf/2401.06787" title="Download PDF">pdf</a>, <a href="/ps/2401.06787" title="Download PostScript">ps</a>, <a href="/format/2401.06787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Based Cyberbullying Detection in Bangla Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nath%2C+S+S">Sristy Shidul Nath</a>, 
<a href="/search/cs?searchtype=author&query=Karim%2C+R">Razuan Karim</a>, 
<a href="/search/cs?searchtype=author&query=Miraz%2C+M+H">Mahdi H. Miraz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Annals of Emerging Technologies in Computing (AETiC), Print ISSN:
  2516-0281, Online ISSN: 2516-029X, pp. 50-65, Vol. 8, No. 1, 1st January
  2024, Available: http://aetic.theiaer.org/archive/v8/v8n1/p5.html
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The Internet is currently the largest platform for global communication
including expressions of opinions, reviews, contents, images, videos and so
forth. Moreover, social media has now become a very broad and highly engaging
platform due to its immense popularity and swift adoption trend. Increased
social networking, however, also has detrimental impacts on the society leading
to a range of unwanted phenomena, such as online assault, intimidation, digital
bullying, criminality and trolling. Hence, cyberbullying has become a pervasive
and worrying problem that poses considerable psychological and emotional harm
to the people, particularly amongst the teens and the young adults. In order to
lessen its negative effects and provide victims with prompt support, a great
deal of research to identify cyberbullying instances at various online
platforms is emerging. In comparison to other languages, Bangla (also known as
Bengali) has fewer research studies in this domain. This study demonstrates a
deep learning strategy for identifying cyberbullying in Bengali, using a
dataset of 12282 versatile comments from multiple social media sites. In this
study, a two-layer bidirectional long short-term memory (Bi-LSTM) model has
been built to identify cyberbullying, using a variety of optimisers as well as
5-fold cross validation. To evaluate the functionality and efficacy of the
proposed system, rigorous assessment and validation procedures have been
employed throughout the project. The results of this study reveals that the
proposed model's accuracy, using momentum-based stochastic gradient descent
(SGD) optimiser, is 94.46%. It also reflects a higher accuracy of 95.08% and a
F1 score of 95.23% using Adam optimiser as well as a better accuracy of 94.31%
in 5-fold cross validation.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06789" title="Abstract">arXiv:2401.06789</a> [<a href="/pdf/2401.06789" title="Download PDF">pdf</a>, <a href="/ps/2401.06789" title="Download PostScript">ps</a>, <a href="/format/2401.06789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Retrieval and Classification of Real-Time Multi-Source  Hurricane Evacuation Notices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tingting Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shubo Tian</a>, 
<a href="/search/cs?searchtype=author&query=Daly%2C+J">Jordan Daly</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+M">Melissa Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Minna Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jinfeng Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">For an approaching disaster, the tracking of time-sensitive critical
information such as hurricane evacuation notices is challenging in the United
States. These notices are issued and distributed rapidly by numerous local
authorities that may spread across multiple states. They often undergo frequent
updates and are distributed through diverse online portals lacking standard
formats. In this study, we developed an approach to timely detect and track the
locally issued hurricane evacuation notices. The text data were collected
mainly with a spatially targeted web scraping method. They were manually
labeled and then classified using natural language processing techniques with
deep learning models. The classification of mandatory evacuation notices
achieved a high accuracy (recall = 96%). We used Hurricane Ian (2022) to
illustrate how real-time evacuation notices extracted from local government
sources could be redistributed with a Web GIS system. Our method applied to
future hurricanes provides live data for situation awareness to higher-level
government agencies and news media. The archived data helps scholars to study
government responses toward weather warnings and individual behaviors
influenced by evacuation history. The framework may be applied to other types
of disasters for rapid and targeted retrieval, classification, redistribution,
and archiving of real-time government orders and notifications.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06790" title="Abstract">arXiv:2401.06790</a> [<a href="/pdf/2401.06790" title="Download PDF">pdf</a>, <a href="/format/2401.06790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Zero-shot Prompting in the Automatic Creation and Expansion of  Topic Taxonomies for Tagging Retail Banking Transactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+S.+Moraes%2C+D">Daniel de S. Moraes</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P+T+C">Pedro T. C. Santos</a>, 
<a href="/search/cs?searchtype=author&query=da+Costa%2C+P+B">Polyana B. da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Pinto%2C+M+A+S">Matheus A. S. Pinto</a>, 
<a href="/search/cs?searchtype=author&query=de+J.+P.+Pinto%2C+I">Ivan de J. P. Pinto</a>, 
<a href="/search/cs?searchtype=author&query=da+Veiga%2C+%C3%81+M+G">&#xc1;lvaro M. G. da Veiga</a>, 
<a href="/search/cs?searchtype=author&query=Colcher%2C+S">Sergio Colcher</a>, 
<a href="/search/cs?searchtype=author&query=Busson%2C+A+J+G">Antonio J. G. Busson</a>, 
<a href="/search/cs?searchtype=author&query=Rocha%2C+R+H">Rafael H. Rocha</a>, 
<a href="/search/cs?searchtype=author&query=Gaio%2C+R">Rennan Gaio</a>, 
<a href="/search/cs?searchtype=author&query=Miceli%2C+R">Rafael Miceli</a>, 
<a href="/search/cs?searchtype=author&query=Tourinho%2C+G">Gabriela Tourinho</a>, 
<a href="/search/cs?searchtype=author&query=Rabaioli%2C+M">Marcos Rabaioli</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+L">Leandro Santos</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+F">Fellipe Marques</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+D">David Favaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work presents an unsupervised method for automatically constructing and
expanding topic taxonomies by using instruction-based fine-tuned LLMs (Large
Language Models). We apply topic modeling and keyword extraction techniques to
create initial topic taxonomies and LLMs to post-process the resulting terms
and create a hierarchy. To expand an existing taxonomy with new terms, we use
zero-shot prompting to find out where to add new nodes, which, to our
knowledge, is the first work to present such an approach to taxonomy tasks. We
use the resulting taxonomies to assign tags that characterize merchants from a
retail bank dataset. To evaluate our work, we asked 12 volunteers to answer a
two-part form in which we first assessed the quality of the taxonomies created
and then the tags assigned to merchants based on that taxonomy. The evaluation
revealed a coherence rate exceeding 90% for the chosen taxonomies, while the
average coherence for merchant tagging surpassed 80%.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06791" title="Abstract">arXiv:2401.06791</a> [<a href="/pdf/2401.06791" title="Download PDF">pdf</a>, <a href="/format/2401.06791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Span-based Model for Extracting Overlapping PICO Entities from RCT  Publications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gongbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+C">Chunhua Weng</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Objectives Extraction of PICO (Populations, Interventions, Comparison, and
Outcomes) entities is fundamental to evidence retrieval. We present a novel
method PICOX to extract overlapping PICO entities.
<br />Materials and Methods PICOX first identifies entities by assessing whether a
word marks the beginning or conclusion of an entity. Then it uses a multi-label
classifier to assign one or more PICO labels to a span candidate. PICOX was
evaluated using one of the best-performing baselines, EBM-NLP, and three more
datasets, i.e., PICO-Corpus, and RCT publications on Alzheimer's Disease or
COVID-19, using entity-level precision, recall, and F1 scores.
<br />Results PICOX achieved superior precision, recall, and F1 scores across the
board, with the micro F1 score improving from 45.05 to 50.87 (p &lt;&lt; 0.01). On
the PICO-Corpus, PICOX obtained higher recall and F1 scores than the baseline
and improved the micro recall score from 56.66 to 67.33. On the COVID-19
dataset, PICOX also outperformed the baseline and improved the micro F1 score
from 77.10 to 80.32. On the AD dataset, PICOX demonstrated comparable F1 scores
with higher precision when compared to the baseline.
<br />Conclusion PICOX excels in identifying overlapping entities and consistently
surpasses a leading baseline across multiple datasets. Ablation studies reveal
that its data augmentation strategy effectively minimizes false positives and
improves precision.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06792" title="Abstract">arXiv:2401.06792</a> [<a href="/pdf/2401.06792" title="Download PDF">pdf</a>, <a href="/format/2401.06792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LightHouse: A Survey of AGI Hallucination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the development of artificial intelligence, large-scale models have
become increasingly intelligent. However, numerous studies indicate that
hallucinations within these large models are a bottleneck hindering the
development of AI research. In the pursuit of achieving strong artificial
intelligence, a significant volume of research effort is being invested in the
AGI (Artificial General Intelligence) hallucination research. Previous
explorations have been conducted in researching hallucinations within LLMs
(Large Language Models). As for multimodal AGI, research on hallucinations is
still in an early stage. To further the progress of research in the domain of
hallucinatory phenomena, we present a bird's eye view of hallucinations in AGI,
summarizing the current work on AGI hallucinations and proposing some
directions for future research.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06793" title="Abstract">arXiv:2401.06793</a> [<a href="/pdf/2401.06793" title="Download PDF">pdf</a>, <a href="/ps/2401.06793" title="Download PostScript">ps</a>, <a href="/format/2401.06793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Algorithm for Inference of Decision Trees from Decision Rule  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durdymyradov%2C+K">Kerven Durdymyradov</a>, 
<a href="/search/cs?searchtype=author&query=Moshkov%2C+M">Mikhail Moshkov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2305.01721">arXiv:2305.01721</a>, <a href="/abs/2302.07063">arXiv:2302.07063</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Decision trees and decision rule systems play important roles as classifiers,
knowledge representation tools, and algorithms. They are easily interpretable
models for data analysis, making them widely used and studied in computer
science. Understanding the relationships between these two models is an
important task in this field. There are well-known methods for converting
decision trees into systems of decision rules. In this paper, we consider the
inverse transformation problem, which is not so simple. Instead of constructing
an entire decision tree, our study focuses on a greedy polynomial time
algorithm that simulates the operation of a decision tree on a given tuple of
attribute values.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06795" title="Abstract">arXiv:2401.06795</a> [<a href="/pdf/2401.06795" title="Download PDF">pdf</a>, <a href="/format/2401.06795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI and Generative AI for Research Discovery and Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glickman%2C+M">Mark Glickman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">AI and generative AI tools, including chatbots like ChatGPT that rely on
large language models (LLMs), have burst onto the scene this year, creating
incredible opportunities to increase work productivity and improve our lives.
Statisticians and data scientists have begun experiencing the benefits from the
availability of these tools in numerous ways, such as the generation of
programming code from text prompts to analyze data or fit statistical models.
One area that these tools can make a substantial impact is in research
discovery and summarization. Standalone tools and plugins to chatbots are being
developed that allow researchers to more quickly find relevant literature than
pre-2023 search tools. Furthermore, generative AI tools have improved to the
point where they can summarize and extract the key points from research
articles in succinct language. Finally, chatbots based on highly parameterized
LLMs can be used to simulate abductive reasoning, which provides researchers
the ability to make connections among related technical topics, which can also
be used for research discovery. We review the developments in AI and generative
AI for research discovery and summarization, and propose directions where these
types of tools are likely to head in the future that may be of interest to
statistician and data scientists.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06796" title="Abstract">arXiv:2401.06796</a> [<a href="/pdf/2401.06796" title="Download PDF">pdf</a>, <a href="/ps/2401.06796" title="Download PostScript">ps</a>, <a href="/format/2401.06796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Hallucinations: A Misnomer Worth Clarifying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maleki%2C+N">Negar Maleki</a>, 
<a href="/search/cs?searchtype=author&query=Padmanabhan%2C+B">Balaji Padmanabhan</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+K">Kaushik Dutta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As large language models continue to advance in Artificial Intelligence (AI),
text generation systems have been shown to suffer from a problematic phenomenon
termed often as "hallucination." However, with AI's increasing presence across
various domains including medicine, concerns have arisen regarding the use of
the term itself. In this study, we conducted a systematic review to identify
papers defining "AI hallucination" across fourteen databases. We present and
analyze definitions obtained across all databases, categorize them based on
their applications, and extract key points within each category. Our results
highlight a lack of consistency in how the term is used, but also help identify
several alternative terms in the literature. We discuss implications of these
and call for a more unified effort to bring consistency to an important
contemporary AI issue that can affect multiple domains significantly.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06799" title="Abstract">arXiv:2401.06799</a> [<a href="/pdf/2401.06799" title="Download PDF">pdf</a>, <a href="/format/2401.06799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Prompts Adaptable: Bayesian Modeling for Vision-Language Prompt  Learning with Data-Dependent Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Youngjae Cho</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">HeeSun Bae</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Seungjae Shin</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+Y+D">Yeo Dong Youn</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+W">Weonyoung Joo</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+I">Il-Chul Moon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent Vision-Language Pretrained (VLP) models have become the backbone for
many downstream tasks, but they are utilized as frozen model without learning.
Prompt learning is a method to improve the pre-trained VLP model by adding a
learnable context vector to the inputs of the text encoder. In a few-shot
learning scenario of the downstream task, MLE training can lead the context
vector to over-fit dominant image features in the training data. This
overfitting can potentially harm the generalization ability, especially in the
presence of a distribution shift between the training and test dataset. This
paper presents a Bayesian-based framework of prompt learning, which could
alleviate the overfitting issues on few-shot learning application and increase
the adaptability of prompts on unseen instances. Specifically, modeling
data-dependent prior enhances the adaptability of text features for both seen
and unseen image features without the trade-off of performance between them.
Based on the Bayesian framework, we utilize the Wasserstein Gradient Flow in
the estimation of our target posterior distribution, which enables our prompt
to be flexible in capturing the complex modes of image features. We demonstrate
the effectiveness of our method on benchmark datasets for several experiments
by showing statistically significant improvements on performance compared to
existing methods. The code is available at https://github.com/youngjae-cho/APP.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06800" title="Abstract">arXiv:2401.06800</a> [<a href="/pdf/2401.06800" title="Download PDF">pdf</a>, <a href="/format/2401.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Optimizing RAG for Domain Chatbots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+M">Mandar Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Tangarajan%2C+P">Praveen Tangarajan</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Anusua Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the advent of Large Language Models (LLM), conversational assistants
have become prevalent for domain use cases. LLMs acquire the ability to
contextual question answering through training, and Retrieval Augmented
Generation (RAG) further enables the bot to answer domain-specific questions.
This paper describes a RAG-based approach for building a chatbot that answers
user's queries using Frequently Asked Questions (FAQ) data. We train an
in-house retrieval embedding model using infoNCE loss, and experimental results
demonstrate that the in-house model works significantly better than the
well-known general-purpose public embedding model, both in terms of retrieval
accuracy and Out-of-Domain (OOD) query detection. As an LLM, we use an open
API-based paid ChatGPT model. We noticed that a previously retrieved-context
could be used to generate an answer for specific patterns/sequences of queries
(e.g., follow-up queries). Hence, there is a scope to optimize the number of
LLM tokens and cost. Assuming a fixed retrieval model and an LLM, we optimize
the number of LLM tokens using Reinforcement Learning (RL). Specifically, we
propose a policy-based model external to the RAG, which interacts with the RAG
pipeline through policy actions and updates the policy to optimize the cost.
The policy model can perform two actions: to fetch FAQ context or skip
retrieval. We use the open API-based GPT-4 as the reward model. We then train a
policy model using policy gradient on multiple training chat sessions. As a
policy model, we experimented with a public gpt-2 model and an in-house BERT
model. With the proposed RL-based optimization combined with similarity
threshold, we are able to achieve significant cost savings while getting a
slightly improved accuracy. Though we demonstrate results for the FAQ chatbot,
the proposed RL approach is generic and can be experimented with any existing
RAG pipeline.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06801" title="Abstract">arXiv:2401.06801</a> [<a href="/pdf/2401.06801" title="Download PDF">pdf</a>, <a href="/ps/2401.06801" title="Download PostScript">ps</a>, <a href="/format/2401.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-of-Thought: Utilizing Large Language Models to Solve Complex and  Dynamic Business Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Graph-of-Thought (GoT), Workflow Automation, Large Language Models (LLMs), Task Execution, Data-Driven Decision Making, Complexity Management
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">This paper presents Graph-of-Thought (GoT), a new model for workflow
automation that enhances the flexibility and efficiency of Large Language
Models (LLMs) in complex task execution. GoT advances beyond traditional linear
and tree-like cognitive models with a graph structure that enables dynamic path
selection. The open-source engine GoTFlow demonstrates the practical
application of GoT, facilitating automated, data-driven decision-making across
various domains. Despite challenges in complexity and transparency, GoTFlow's
potential for improving business processes is significant, promising
advancements in both efficiency and decision quality with continuous
development.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06802" title="Abstract">arXiv:2401.06802</a> [<a href="/pdf/2401.06802" title="Download PDF">pdf</a>, <a href="/format/2401.06802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Knowledge Distillation on Text Graph for Data-limited  Attribute Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quan Li</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+S">Shixiong Jing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lingwei Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures, uses log_2022.sty
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The popularization of social media increases user engagements and generates a
large amount of user-oriented data. Among them, text data (e.g., tweets, blogs)
significantly attracts researchers and speculators to infer user attributes
(e.g., age, gender, location) for fulfilling their intents. Generally, this
line of work casts attribute inference as a text classification problem, and
starts to leverage graph neural networks (GNNs) to utilize higher-level
representations of source texts. However, these text graphs are constructed
over words, suffering from high memory consumption and ineffectiveness on few
labeled texts. To address this challenge, we design a text-graph-based few-shot
learning model for attribute inferences on social media text data. Our model
first constructs and refines a text graph using manifold learning and message
passing, which offers a better trade-off between expressiveness and complexity.
Afterwards, to further use cross-domain texts and unlabeled texts to improve
few-shot performance, a hierarchical knowledge distillation is devised over
text graph to optimize the problem, which derives better text representations,
and advances model generalization ability. Experiments on social media datasets
demonstrate the state-of-the-art performance of our model on attribute
inferences with considerably fewer labeled texts.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06803" title="Abstract">arXiv:2401.06803</a> [<a href="/pdf/2401.06803" title="Download PDF">pdf</a>, <a href="/format/2401.06803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI Meets Semantic Communication: Evolution and Revolution of  Communication Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grassucci%2C+E">Eleonora Grassucci</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jihong Park</a>, 
<a href="/search/cs?searchtype=author&query=Barbarossa%2C+S">Sergio Barbarossa</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seong-Lyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jinho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Comminiello%2C+D">Danilo Comminiello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under consideration in IEEE Network Special Issue "The Interplay Between Generative AI and 5G-Advanced toward 6G"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">While deep generative models are showing exciting abilities in computer
vision and natural language processing, their adoption in communication
frameworks is still far underestimated. These methods are demonstrated to
evolve solutions to classic communication problems such as denoising,
restoration, or compression. Nevertheless, generative models can unveil their
real potential in semantic communication frameworks, in which the receiver is
not asked to recover the sequence of bits used to encode the transmitted
(semantic) message, but only to regenerate content that is semantically
consistent with the transmitted message. Disclosing generative models
capabilities in semantic communication paves the way for a paradigm shift with
respect to conventional communication systems, which has great potential to
reduce the amount of data traffic and offers a revolutionary versatility to
novel tasks and applications that were not even conceivable a few years ago. In
this paper, we present a unified perspective of deep generative models in
semantic communication and we unveil their revolutionary role in future
communication frameworks, enabling emerging applications and tasks. Finally, we
analyze the challenges and opportunities to face to develop generative models
specifically tailored for communication systems.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06804" title="Abstract">arXiv:2401.06804</a> [<a href="/pdf/2401.06804" title="Download PDF">pdf</a>, <a href="/ps/2401.06804" title="Download PostScript">ps</a>, <a href="/format/2401.06804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements,  Challenges and Research Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahin%2C+N">Nada Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Ismail%2C+L">Leila Ismail</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ChatGPT is a language model based on Generative AI. Existing research work on
ChatGPT focused on its use in various domains. However, its potential for Sign
Language Translation (SLT) is yet to be explored. This paper addresses this
void. Therefore, we present GPT's evolution aiming a retrospective analysis of
the improvements to its architecture for SLT. We explore ChatGPT's capabilities
in translating different sign languages in paving the way to better
accessibility for deaf and hard-of-hearing community. Our experimental results
indicate that ChatGPT can accurately translate from English to American (ASL),
Australian (AUSLAN), and British (BSL) sign languages and from Arabic Sign
Language (ArSL) to English with only one prompt iteration. However, the model
failed to translate from Arabic to ArSL and ASL, AUSLAN, and BSL to Arabic.
Consequently, we present challenges and derive insights for future research
directions.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06805" title="Abstract">arXiv:2401.06805</a> [<a href="/pdf/2401.06805" title="Download PDF">pdf</a>, <a href="/format/2401.06805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Reasoning Abilities of Multimodal Large Language Models  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wentao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xudong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiteng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+B">Bohan Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Q">Quanzeng You</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Strong Artificial Intelligence (Strong AI) or Artificial General Intelligence
(AGI) with abstract reasoning ability is the goal of next-generation AI. Recent
advancements in Large Language Models (LLMs), along with the emerging field of
Multimodal Large Language Models (MLLMs), have demonstrated impressive
capabilities across a wide range of multimodal tasks and applications.
Particularly, various MLLMs, each with distinct model architectures, training
data, and training stages, have been evaluated across a broad range of MLLM
benchmarks. These studies have, to varying degrees, revealed different aspects
of the current capabilities of MLLMs. However, the reasoning abilities of MLLMs
have not been systematically investigated. In this survey, we comprehensively
review the existing evaluation protocols of multimodal reasoning, categorize
and illustrate the frontiers of MLLMs, introduce recent trends in applications
of MLLMs on reasoning-intensive tasks, and finally discuss current practices
and future directions. We believe our survey establishes a solid base and sheds
light on this important topic, multimodal reasoning.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06806" title="Abstract">arXiv:2401.06806</a> [<a href="/pdf/2401.06806" title="Download PDF">pdf</a>, <a href="/ps/2401.06806" title="Download PostScript">ps</a>, <a href="/format/2401.06806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AugSumm: towards generalizable speech summarization using synthetic  labels from large language model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Roshan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE ICASSP for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Abstractive speech summarization (SSUM) aims to generate human-like summaries
from speech. Given variations in information captured and phrasing, recordings
can be summarized in multiple ways. Therefore, it is more reasonable to
consider a probabilistic distribution of all potential summaries rather than a
single summary. However, conventional SSUM models are mostly trained and
evaluated with a single ground-truth (GT) human-annotated deterministic summary
for every recording. Generating multiple human references would be ideal to
better represent the distribution statistically, but is impractical because
annotation is expensive. We tackle this challenge by proposing AugSumm, a
method to leverage large language models (LLMs) as a proxy for human annotators
to generate augmented summaries for training and evaluation. First, we explore
prompting strategies to generate synthetic summaries from ChatGPT. We validate
the quality of synthetic summaries using multiple metrics including human
evaluation, where we find that summaries generated using AugSumm are perceived
as more valid to humans. Second, we develop methods to utilize synthetic
summaries in training and evaluation. Experiments on How2 demonstrate that
pre-training on synthetic summaries and fine-tuning on GT summaries improves
ROUGE-L by 1 point on both GT and AugSumm-based test sets. AugSumm summaries
are available at https://github.com/Jungjee/AugSumm.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06807" title="Abstract">arXiv:2401.06807</a> [<a href="/pdf/2401.06807" title="Download PDF">pdf</a>, <a href="/format/2401.06807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue  Assistant
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomar%2C+M">Mohit Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+A">Abhisek Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+T">Tulika Saha</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+P">Prince Jha</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sriparna Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent times, there has been an increasing awareness about imminent
environmental challenges, resulting in people showing a stronger dedication to
taking care of the environment and nurturing green life. The current $19.6
billion indoor gardening industry, reflective of this growing sentiment, not
only signifies a monetary value but also speaks of a profound human desire to
reconnect with the natural world. However, several recent surveys cast a
revealing light on the fate of plants within our care, with more than half
succumbing primarily due to the silent menace of improper care. Thus, the need
for accessible expertise capable of assisting and guiding individuals through
the intricacies of plant care has become paramount more than ever. In this
work, we make the very first attempt at building a plant care assistant, which
aims to assist people with plant(-ing) concerns through conversations. We
propose a plant care conversational dataset named Plantational, which contains
around 1K dialogues between users and plant care experts. Our end-to-end
proposed approach is two-fold : (i) We first benchmark the dataset with the
help of various large language models (LLMs) and visual language model (VLM) by
studying the impact of instruction tuning (zero-shot and few-shot prompting)
and fine-tuning techniques on this task; (ii) finally, we build EcoSage, a
multi-modal plant care assisting dialogue generation framework, incorporating
an adapter-based modality infusion using a gated mechanism. We performed an
extensive examination (both automated and manual evaluation) of the performance
exhibited by various LLMs and VLM in the generation of the domain-specific
dialogue responses to underscore the respective strengths and weaknesses of
these diverse models.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06808" title="Abstract">arXiv:2401.06808</a> [<a href="/pdf/2401.06808" title="Download PDF">pdf</a>, <a href="/format/2401.06808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounded learning for compositional vector semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis%2C+M">Martha Lewis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Categorical compositional distributional semantics is an approach to
modelling language that combines the success of vector-based models of meaning
with the compositional power of formal semantics. However, this approach was
developed without an eye to cognitive plausibility. Vector representations of
concepts and concept binding are also of interest in cognitive science, and
have been proposed as a way of representing concepts within a biologically
plausible spiking neural network. This work proposes a way for compositional
distributional semantics to be implemented within a spiking neural network
architecture, with the potential to address problems in concept binding, and
give a small implementation. We also describe a means of training word
representations using labelled images.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06810" title="Abstract">arXiv:2401.06810</a> [<a href="/pdf/2401.06810" title="Download PDF">pdf</a>, <a href="/format/2401.06810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TONE: A 3-Tiered ONtology for Emotion analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+S">Srishti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+P+K">Piyush Kumar Garg</a>, 
<a href="/search/cs?searchtype=author&query=Dandapat%2C+S+K">Sourav Kumar Dandapat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Emotions have played an important part in many sectors, including psychology,
medicine, mental health, computer science, and so on, and categorizing them has
proven extremely useful in separating one emotion from another. Emotions can be
classified using the following two methods: (1) The supervised method's
efficiency is strongly dependent on the size and domain of the data collected.
A categorization established using relevant data from one domain may not work
well in another. (2) An unsupervised method that uses either domain expertise
or a knowledge base of emotion types already exists. Though this second
approach provides a suitable and generic categorization of emotions and is
cost-effective, the literature doesn't possess a publicly available knowledge
base that can be directly applied to any emotion categorization-related task.
This pushes us to create a knowledge base that can be used for emotion
classification across domains, and ontology is often used for this purpose. In
this study, we provide TONE, an emotion-based ontology that effectively creates
an emotional hierarchy based on Dr. Gerrod Parrot's group of emotions. In
addition to ontology development, we introduce a semi-automated vocabulary
construction process to generate a detailed collection of terms for emotions at
each tier of the hierarchy. We also demonstrate automated methods for
establishing three sorts of dependencies in order to develop linkages between
different emotions. Our human and automatic evaluation results show the
ontology's quality. Furthermore, we describe three distinct use cases that
demonstrate the applicability of our ontology.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06811" title="Abstract">arXiv:2401.06811</a> [<a href="/pdf/2401.06811" title="Download PDF">pdf</a>, <a href="/format/2401.06811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniRQR: A Unified Model for Retrieval Decision, Query, and Response  Generation in Internet-Based Knowledge Dialogue Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhongtian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yangqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Meng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ronghan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lifang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Knowledge-based dialogue systems with internet retrieval have recently
attracted considerable attention from researchers. The dialogue systems
overcome a major limitation of traditional knowledge dialogue systems, where
the timeliness of knowledge cannot be assured, hence providing greater
practical application value. Knowledge-based dialogue systems with internet
retrieval can be typically segmented into three tasks: Retrieval Decision,
Query Generation, and Response Generation. However, many of studies assumed
that all conversations require external knowledge to continue, neglecting the
critical step of determining when retrieval is necessary. This assumption often
leads to an over-dependence on external knowledge, even when it may not be
required. Our work addresses this oversight by employing a single unified model
facilitated by prompt and multi-task learning approaches. This model not only
decides whether retrieval is necessary but also generates retrieval queries and
responses. By integrating these functions, our system leverages the full
potential of pre-trained models and reduces the complexity and costs associated
with deploying multiple models. We conducted extensive experiments to
investigate the mutual enhancement among the three tasks in our system. What is
more, the experiment results on the Wizint and Dusinc datasets not only
demonstrate that our unified model surpasses the baseline performance for
individual tasks, but also reveal that it achieves comparable results when
contrasted with SOTA systems that deploy separate, specialized models for each
task.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06816" title="Abstract">arXiv:2401.06816</a> [<a href="/pdf/2401.06816" title="Download PDF">pdf</a>, <a href="/ps/2401.06816" title="Download PostScript">ps</a>, <a href="/format/2401.06816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When ChatGPT is gone: Creativity reverts and homogeneity persists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinghan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jihao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guiquan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30pages,6figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">ChatGPT has been evidenced to enhance human performance in creative tasks.
Yet, it is still unclear if this boosting effect sustains with and without
ChatGPT. In a pre-registered seven-day lab experiment and a follow-up survey
after 30 days of experiment completion, we examined the impacts of ChatGPT
presence and absence on sustained creativity using a text dataset of 3302
creative ideas and 427 creative solutions from 61 college students.
Participants in the treatment group used ChatGPT in creative tasks, while those
in the control group completed the tasks by themselves. The findings show that
although the boosting effect of ChatGPT was consistently observed over a
five-day creative journey, human creative performance reverted to baseline when
ChatGPT was down on the 7th and the 30th day. More critically, the use of
ChatGPT in creative tasks resulted in increasingly homogenized contents, and
this homogenization effect persisted even when ChatGPT was absence. These
findings pose a challenge to the prevailing argument that ChatGPT can enhance
human creativity. In fact, generative AI like ChatGPT lends to human with a
temporary rise in creative performance but boxes human creative capability in
the long run, highlighting the imperative for cautious generative AI
integration in creative endeavors.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06817" title="Abstract">arXiv:2401.06817</a> [<a href="/pdf/2401.06817" title="Download PDF">pdf</a>, <a href="/format/2401.06817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Regional Impacts of Climate Change using Natural Language  Processing Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallick%2C+T">Tanwi Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Murphy%2C+J">John Murphy</a>, 
<a href="/search/cs?searchtype=author&query=Bergerson%2C+J+D">Joshua David Bergerson</a>, 
<a href="/search/cs?searchtype=author&query=Verner%2C+D+R">Duane R. Verner</a>, 
<a href="/search/cs?searchtype=author&query=Hutchison%2C+J+K">John K Hutchison</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+L">Leslie-Anne Levy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the multifaceted effects of climate change across diverse
geographic locations is crucial for timely adaptation and the development of
effective mitigation strategies. As the volume of scientific literature on this
topic continues to grow exponentially, manually reviewing these documents has
become an immensely challenging task. Utilizing Natural Language Processing
(NLP) techniques to analyze this wealth of information presents an efficient
and scalable solution. By gathering extensive amounts of peer-reviewed articles
and studies, we can extract and process critical information about the effects
of climate change in specific regions. We employ BERT (Bidirectional Encoder
Representations from Transformers) for Named Entity Recognition (NER), which
enables us to efficiently identify specific geographies within the climate
literature. This, in turn, facilitates location-specific analyses. We conduct
region-specific climate trend analyses to pinpoint the predominant themes or
concerns related to climate change within a particular area, trace the temporal
progression of these identified issues, and evaluate their frequency, severity,
and potential development over time. These in-depth examinations of
location-specific climate data enable the creation of more customized
policy-making, adaptation, and mitigation strategies, addressing each region's
unique challenges and providing more effective solutions rooted in data-driven
insights. This approach, founded on a thorough exploration of scientific texts,
offers actionable insights to a wide range of stakeholders, from policymakers
to engineers to environmentalists. By proactively understanding these impacts,
societies are better positioned to prepare, allocate resources wisely, and
design tailored strategies to cope with future climate conditions, ensuring a
more resilient future for all.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06821" title="Abstract">arXiv:2401.06821</a> [<a href="/pdf/2401.06821" title="Download PDF">pdf</a>, <a href="/format/2401.06821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate Neural Networks Local Stability for Aircraft Predictive  Maintenance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ducoffe%2C+M">M&#xe9;lanie Ducoffe</a>, 
<a href="/search/cs?searchtype=author&query=Pov%C3%A9da%2C+G">Guillaume Pov&#xe9;da</a>, 
<a href="/search/cs?searchtype=author&query=Galametz%2C+A">Audrey Galametz</a>, 
<a href="/search/cs?searchtype=author&query=Boumazouza%2C+R">Ryma Boumazouza</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+M">Marion-C&#xe9;cile Martin</a>, 
<a href="/search/cs?searchtype=author&query=Baris%2C+J">Julien Baris</a>, 
<a href="/search/cs?searchtype=author&query=Daverschot%2C+D">Derk Daverschot</a>, 
<a href="/search/cs?searchtype=author&query=O%27Higgins%2C+E">Eugene O&#x27;Higgins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Surrogate Neural Networks (NN) now routinely serve as substitutes for
computationally demanding simulations (e.g., finite element). They enable
faster analyses in industrial applications e.g., manufacturing processes,
performance assessment. The verification of surrogate models is a critical step
to assess their robustness under different scenarios. We explore the
combination of empirical and formal methods in one NN verification pipeline. We
showcase its efficiency on an industrial use case of aircraft predictive
maintenance. We assess the local stability of surrogate NN designed to predict
the stress sustained by an aircraft part from external loads. Our contribution
lies in the complete verification of the surrogate models that possess a
high-dimensional input and output space, thus accommodating multi-objective
constraints. We also demonstrate the pipeline effectiveness in substantially
decreasing the runtime needed to assess the targeted property.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06824" title="Abstract">arXiv:2401.06824</a> [<a href="/pdf/2401.06824" title="Download PDF">pdf</a>, <a href="/format/2401.06824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open the Pandora&#x27;s Box of LLMs: Jailbreaking LLMs through Representation  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiaoqing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Getting large language models (LLMs) to refuse to answer hostile toxicity
questions is a core issue under the theme of LLMs security. Previous approaches
have used prompts engineering to jailbreak LLMs and answer some toxicity
questions. These approaches can easily fail after the model manufacturer makes
additional fine-tuning to the model. To promote the further understanding of
model jailbreaking by researchers, we are inspired by Representation
Engineering to propose a jailbreaking method that does not require elaborate
construction prompts, is not affected by model fine-tuning, and can be widely
applied to any open-source LLMs in a pluggable manner. We have evaluated this
method on multiple mainstream LLMs on carefully supplemented toxicity datasets,
and the experimental results demonstrate the significant effectiveness of our
approach. After being surprised by some interesting jailbreaking cases, we did
extensive in-depth research to explore the techniques behind this method.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06825" title="Abstract">arXiv:2401.06825</a> [<a href="/pdf/2401.06825" title="Download PDF">pdf</a>, <a href="/format/2401.06825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Memory Matching for Unsupervised Visible-Infrared Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiangming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangbo Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yeyun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yanyun Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised visible-infrared person re-identification (USL-VI-ReID) is a
promising yet challenging retrieval task. The key challenges in USL-VI-ReID are
to effectively generate pseudo-labels and establish pseudo-label
correspondences across modalities without relying on any prior annotations.
Recently, clustered pseudo-label methods have gained more attention in
USL-VI-ReID. However, previous methods fell short of fully exploiting the
individual nuances, as they simply utilized a single memory that represented an
identity to establish cross-modality correspondences, resulting in ambiguous
cross-modality correspondences. To address the problem, we propose a
Multi-Memory Matching (MMM) framework for USL-VI-ReID. We first design a
Cross-Modality Clustering (CMC) module to generate the pseudo-labels through
clustering together both two modality samples. To associate cross-modality
clustered pseudo-labels, we design a Multi-Memory Learning and Matching (MMLM)
module, ensuring that optimization explicitly focuses on the nuances of
individual perspectives and establishes reliable cross-modality
correspondences. Finally, we design a Soft Cluster-level Alignment (SCA) module
to narrow the modality gap while mitigating the effect of noise pseudo-labels
through a soft many-to-many alignment strategy. Extensive experiments on the
public SYSU-MM01 and RegDB datasets demonstrate the reliability of the
established cross-modality correspondences and the effectiveness of our MMM.
The source codes will be released.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06826" title="Abstract">arXiv:2401.06826</a> [<a href="/pdf/2401.06826" title="Download PDF">pdf</a>, <a href="/format/2401.06826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct Distillation between Different Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jialiang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+G">Gang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hongyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Knowledge Distillation (KD) aims to learn a compact student network using
knowledge from a large pre-trained teacher network, where both networks are
trained on data from the same distribution. However, in practical applications,
the student network may be required to perform in a new scenario (i.e., the
target domain), which usually exhibits significant differences from the known
scenario of the teacher network (i.e., the source domain). The traditional
domain adaptation techniques can be integrated with KD in a two-stage process
to bridge the domain gap, but the ultimate reliability of two-stage approaches
tends to be limited due to the high computational consumption and the
additional errors accumulated from both stages. To solve this problem, we
propose a new one-stage method dubbed ``Direct Distillation between Different
Domains" (4Ds). We first design a learnable adapter based on the Fourier
transform to separate the domain-invariant knowledge from the domain-specific
knowledge. Then, we build a fusion-activation mechanism to transfer the
valuable domain-invariant knowledge to the student network, while
simultaneously encouraging the adapter within the teacher network to learn the
domain-specific knowledge of the target data. As a result, the teacher network
can effectively transfer categorical knowledge that aligns with the target
domain of the student network. Intensive experiments on various benchmark
datasets demonstrate that our proposed 4Ds method successfully produces
reliable student networks and outperforms state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06827" title="Abstract">arXiv:2401.06827</a> [<a href="/pdf/2401.06827" title="Download PDF">pdf</a>, <a href="/format/2401.06827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guiming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kaize Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Pre-trained Vision-Language (V-L) models set the benchmark for generalization
to downstream tasks among the noteworthy contenders. Many characteristics of
the V-L model have been explored in existing research including the challenge
of the sensitivity to text input and the tuning process across multi-modal
prompts. With the advanced utilization of the V-L model like CLIP, recent
approaches deploy learnable prompts instead of hand-craft prompts to boost the
generalization performance and address the aforementioned challenges. Inspired
by layer-wise training, which is wildly used in image fusion, we note that
using a sequential training process to adapt different modalities branches of
CLIP efficiently facilitates the improvement of generalization. In the context
of addressing the multi-modal prompting challenge, we propose Token-wise
Adaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities
prompts, vision and language, as tokens in a sequential manner. APLe addresses
the challenges in V-L models to promote prompt learning across both modalities,
which indicates a competitive generalization performance in line with the
state-of-the-art. Preeminently, APLe shows robustness and favourable
performance in prompt-length experiments with an absolute advantage in adopting
the V-L models.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06829" title="Abstract">arXiv:2401.06829</a> [<a href="/pdf/2401.06829" title="Download PDF">pdf</a>, <a href="/format/2401.06829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Attention Watermarking of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldassini%2C+F+B">Folco Bertini Baldassini</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching-Chung Chang</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures. Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A new approach to linguistic watermarking of language models is presented in
which information is imperceptibly inserted into the output text while
preserving its readability and original meaning. A cross-attention mechanism is
used to embed watermarks in the text during inference. Two methods using
cross-attention are presented that minimize the effect of watermarking on the
performance of a pretrained model. Exploration of different training strategies
for optimizing the watermarking and of the challenges and implications of
applying this approach in real-world scenarios clarified the tradeoff between
watermark robustness and text quality. Watermark selection substantially
affects the generated output for high entropy sentences. This proactive
watermarking approach has potential application in future model development.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06830" title="Abstract">arXiv:2401.06830</a> [<a href="/pdf/2401.06830" title="Download PDF">pdf</a>, <a href="/format/2401.06830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecSys Challenge 2023: From data preparation to prediction, a simple,  efficient, robust and scalable solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manderlier%2C+M">Maxime Manderlier</a>, 
<a href="/search/cs?searchtype=author&query=Lecron%2C+F">Fabian Lecron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The RecSys Challenge 2023, presented by ShareChat, consists to predict if an
user will install an application on his smartphone after having seen
advertising impressions in ShareChat &amp; Moj apps. This paper presents the
solution of 'Team UMONS' to this challenge, giving accurate results (our best
score is 6.622686) with a relatively small model that can be easily implemented
in different production configurations. Our solution scales well when
increasing the dataset size and can be used with datasets containing missing
values.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06831" title="Abstract">arXiv:2401.06831</a> [<a href="/pdf/2401.06831" title="Download PDF">pdf</a>, <a href="/ps/2401.06831" title="Download PostScript">ps</a>, <a href="/format/2401.06831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on the Applications of Frontier AI, Foundation Models, and  Large Language Models to Intelligent Transportation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shoaib%2C+M+R">Mohamed R. Shoaib</a>, 
<a href="/search/cs?searchtype=author&query=Emara%2C+H+M">Heba M. Emara</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper appears in International Conference on Computer and Applications (ICCA) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey paper explores the transformative influence of frontier AI,
foundation models, and Large Language Models (LLMs) in the realm of Intelligent
Transportation Systems (ITS), emphasizing their integral role in advancing
transportation intelligence, optimizing traffic management, and contributing to
the realization of smart cities. Frontier AI refers to the forefront of AI
technology, encompassing the latest advancements, innovations, and experimental
techniques in the field, especially AI foundation models and LLMs. Foundation
models, like GPT-4, are large, general-purpose AI models that provide a base
for a wide range of applications. They are characterized by their versatility
and scalability. LLMs are obtained from finetuning foundation models with a
specific focus on processing and generating natural language. They excel in
tasks like language understanding, text generation, translation, and
summarization. By leveraging vast textual data, including traffic reports and
social media interactions, LLMs extract critical insights, fostering the
evolution of ITS. The survey navigates the dynamic synergy between LLMs and
ITS, delving into applications in traffic management, integration into
autonomous vehicles, and their role in shaping smart cities. It provides
insights into ongoing research, innovations, and emerging trends, aiming to
inspire collaboration at the intersection of language, intelligence, and
mobility for safer, more efficient, and sustainable transportation systems. The
paper further surveys interactions between LLMs and various aspects of ITS,
exploring roles in traffic management, facilitating autonomous vehicles, and
contributing to smart city development, while addressing challenges brought by
frontier AI and foundation models. This paper offers valuable inspiration for
future research and innovation in the transformative domain of intelligent
transportation.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06832" title="Abstract">arXiv:2401.06832</a> [<a href="/pdf/2401.06832" title="Download PDF">pdf</a>, <a href="/ps/2401.06832" title="Download PostScript">ps</a>, <a href="/format/2401.06832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XLS-R Deep Learning Model for Multilingual ASR on Low- Resource  Languages: Indonesian, Javanese, and Sundanese
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arisaputra%2C+P">Panji Arisaputra</a>, 
<a href="/search/cs?searchtype=author&query=Handoyo%2C+A+T">Alif Tri Handoyo</a>, 
<a href="/search/cs?searchtype=author&query=Zahra%2C+A">Amalia Zahra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This research paper focuses on the development and evaluation of Automatic
Speech Recognition (ASR) technology using the XLS-R 300m model. The study aims
to improve ASR performance in converting spoken language into written text,
specifically for Indonesian, Javanese, and Sundanese languages. The paper
discusses the testing procedures, datasets used, and methodology employed in
training and evaluating the ASR systems. The results show that the XLS-R 300m
model achieves competitive Word Error Rate (WER) measurements, with a slight
compromise in performance for Javanese and Sundanese languages. The integration
of a 5-gram KenLM language model significantly reduces WER and enhances ASR
accuracy. The research contributes to the advancement of ASR technology by
addressing linguistic diversity and improving performance across various
languages. The findings provide insights into optimizing ASR accuracy and
applicability for diverse linguistic contexts.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06833" title="Abstract">arXiv:2401.06833</a> [<a href="/pdf/2401.06833" title="Download PDF">pdf</a>, <a href="/format/2401.06833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hierarchical control framework for autonomous decision-making systems:  Integrating HMDP and MPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xue-Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jingjing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen-Hua Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 14 figures, submitted to Automatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This paper proposes a comprehensive hierarchical control framework for
autonomous decision-making arising in robotics and autonomous systems. In a
typical hierarchical control architecture, high-level decision making is often
characterised by discrete state and decision/control sets. However, a rational
decision is usually affected by not only the discrete states of the autonomous
system, but also the underlying continuous dynamics even the evolution of its
operational environment. This paper proposes a holistic and comprehensive
design process and framework for this type of challenging problems, from new
modelling and design problem formulation to control design and stability
analysis. It addresses the intricate interplay between traditional continuous
systems dynamics utilized at the low levels for control design and discrete
Markov decision processes (MDP) for facilitating high-level decision making. We
model the decision making system in complex environments as a hybrid system
consisting of a controlled MDP and autonomous (i.e. uncontrolled) continuous
dynamics. Consequently, the new formulation is called as hybrid Markov decision
process (HMDP). The design problem is formulated with a focus on ensuring both
safety and optimality while taking into account the influence of both the
discrete and continuous state variables of different levels. With the help of
the model predictive control (MPC) concept, a decision maker design scheme is
proposed for the proposed hybrid decision making model. By carefully designing
key ingredients involved in this scheme, it is shown that the recursive
feasibility and stability of the proposed autonomous decision making scheme are
guaranteed. The proposed framework is applied to develop an autonomous lane
changing system for intelligent vehicles.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06836" title="Abstract">arXiv:2401.06836</a> [<a href="/pdf/2401.06836" title="Download PDF">pdf</a>, <a href="/format/2401.06836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Emotional Generation Capability of Large Language Models  via Emotional Chain-of-Thought
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zaijing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gongwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rui Shao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+D">Dongmei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The Emotional Generation is a subset of emotional intelligence, which aims to
output an emotional response based on emotional conditions as input. Emotion
generation has a wide range of applications, including emotion chat, emotional
visual caption, and emotional rewriting. However, it faces challenges such as a
lack of interpretability and poor evaluability. In this paper, we propose the
Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that
enhances the performance of Large Language Models (LLMs) on various emotional
generation tasks by aligning with human emotional intelligence guidelines. To
assess the reliability of ECoT, we propose an automated model-based evaluation
method called EGS. Extensive experimental results demonstrate the effectiveness
of ECoT and EGS. Further,we discuss the promise of LLMs in the field of
sentiment analysis and present key insights into the LLMs with the ECoT in
emotional generation tasks.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06837" title="Abstract">arXiv:2401.06837</a> [<a href="/pdf/2401.06837" title="Download PDF">pdf</a>, <a href="/format/2401.06837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structsum Generation for Faster Text Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+P">Parag Jain</a>, 
<a href="/search/cs?searchtype=author&query=Marzoca%2C+A">Andreea Marzoca</a>, 
<a href="/search/cs?searchtype=author&query=Piccinno%2C+F">Francesco Piccinno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We consider the task of generating structured representations of text using
large language models (LLMs). We focus on tables and mind maps as
representative modalities. Tables are more organized way of representing data,
while mind maps provide a visually dynamic and flexible approach, particularly
suitable for sparse content. Despite the effectiveness of LLMs on different
tasks, we show that current models struggle with generating structured outputs.
In response, we present effective prompting strategies for both of these tasks.
We introduce a taxonomy of problems around factuality, global and local
structure, common to both modalities and propose a set of critiques to tackle
these issues resulting in an absolute improvement in accuracy of +37pp (79%)
for mind maps and +15pp (78%) for tables. To evaluate semantic coverage of
generated structured representations we propose Auto-QA, and we verify the
adequacy of Auto-QA using SQuAD dataset. We further evaluate the usefulness of
structured representations via a text comprehension user study. The results
show a significant reduction in comprehension time compared to text when using
table (42.9%) and mind map (31.9%), without loss in accuracy.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06838" title="Abstract">arXiv:2401.06838</a> [<a href="/pdf/2401.06838" title="Download PDF">pdf</a>, <a href="/format/2401.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPO: Advancing Multilingual Reasoning through Multilingual  Alignment-as-Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=She%2C+S">Shuaijie She</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wei Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project will be available at <a href="https://github.com/NJUNLP/MAPO">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Though reasoning abilities are considered language-agnostic, existing LLMs
exhibit inconsistent reasoning abilities across different languages, e.g.,
reasoning in a pivot language is superior to other languages due to the
imbalance of multilingual training data.To enhance reasoning abilities in
non-pivot languages, we propose an alignment-as-preference optimization
framework. Specifically, we adopt an open-source translation model to estimate
the consistency between answers in non-pivot and pivot languages. We further
adopt the answer consistency as the preference for DPO or PPO thus optimizing
the lesser reasoning. Experiments show that our method significantly improves
the model's multilingual reasoning, with better reasoning consistency across
languages. Our framework achieved a 13.7% accuracy improvement on out-of-domain
datasets MSVAMP while preserving the competitive performance on MGSM. Moreover,
we find that iterative DPO is helpful for further alignment and improvement of
the model's multilingual mathematical reasoning ability, further pushing the
improvement to 16.7%
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06853" title="Abstract">arXiv:2401.06853</a> [<a href="/pdf/2401.06853" title="Download PDF">pdf</a>, <a href="/format/2401.06853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Can Learn Temporal Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+S">Siheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Payani%2C+A">Ali Payani</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+R">Ramana Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Fekri%2C+F">Faramarz Fekri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) learn temporal concepts from the co-occurrence
of related tokens in a sequence. Compared with conventional text generation,
temporal reasoning, which reaches a conclusion based on mathematical, logical
and commonsense knowledge, is more challenging. In this paper, we propose
TempGraph-LLM, a new paradigm towards text-based temporal reasoning. To be
specific, we first teach LLMs to translate the context into a temporal graph. A
synthetic dataset, which is fully controllable and requires minimal
supervision, is constructed for pre-training on this task. We prove in
experiments that LLMs benefit from the pre-training on other tasks. On top of
that, we guide LLMs to perform symbolic reasoning with the strategies of Chain
of Thoughts (CoTs) bootstrapping and special data augmentation. We observe that
CoTs with symbolic reasoning bring more consistent and reliable results than
those using free text.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06855" title="Abstract">arXiv:2401.06855</a> [<a href="/pdf/2401.06855" title="Download PDF">pdf</a>, <a href="/format/2401.06855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Hallucination Detection and Editing for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Abhika Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Asai%2C+A">Akari Asai</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+V">Vidhisha Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>, 
<a href="/search/cs?searchtype=author&query=Hajishirzi%2C+H">Hannaneh Hajishirzi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LMs) are prone to generate diverse factually incorrect
statements, which are widely called hallucinations. Current approaches
predominantly focus on coarse-grained automatic hallucination detection or
editing, overlooking nuanced error levels. In this paper, we propose a novel
task -- automatic fine-grained hallucination detection -- and present a
comprehensive taxonomy encompassing six hierarchically defined types of
hallucination. To facilitate evaluation, we introduce a new benchmark that
includes fine-grained human judgments on two LM outputs across various domains.
Our analysis reveals that ChatGPT and Llama 2-Chat exhibit hallucinations in
60% and 75% of their outputs, respectively, and a majority of these
hallucinations fall into categories that have been underexplored. As an initial
step to address this, we train FAVA, a retrieval-augmented LM by carefully
designing synthetic data generations to detect and correct fine-grained
hallucinations. On our benchmark, our automatic and human evaluations show that
FAVA significantly outperforms ChatGPT on fine-grained hallucination detection
by a large margin though a large room for future improvement still exists.
FAVA's suggested edits also improve the factuality of LM-generated text,
resulting in 5-10% FActScore improvements.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06857" title="Abstract">arXiv:2401.06857</a> [<a href="/pdf/2401.06857" title="Download PDF">pdf</a>, <a href="/ps/2401.06857" title="Download PostScript">ps</a>, <a href="/format/2401.06857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank Tensor Decomposition over Finite Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jason Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">We show that finding rank-1, rank-2, and rank-3 decompositions of a 3D tensor
over a fixed finite field can be done in polynomial time. However, if some
cells in the tensor are allowed to have arbitrary values, then rank-2 is
NP-hard over the integers modulo 2. We also explore rank-1 decomposition of a
3D tensor and of a matrix where some cells are allowed to have arbitrary
values.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06866" title="Abstract">arXiv:2401.06866</a> [<a href="/pdf/2401.06866" title="Download PDF">pdf</a>, <a href="/format/2401.06866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Health-LLM: Large Language Models for Health Prediction via Wearable  Sensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yubin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xuhai Xu</a>, 
<a href="/search/cs?searchtype=author&query=McDuff%2C+D">Daniel McDuff</a>, 
<a href="/search/cs?searchtype=author&query=Breazeal%2C+C">Cynthia Breazeal</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H+W">Hae Won Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are capable of many natural language tasks, yet
they are far from perfect. In health applications, grounding and interpreting
domain-specific and non-linguistic data is important. This paper investigates
the capacity of LLMs to deliver multi-modal health predictions based on
contextual information (e.g. user demographics, health knowledge) and
physiological data (e.g. resting heart rate, sleep minutes). We present a
comprehensive evaluation of eight state-of-the-art LLMs with diverse prompting
and fine-tuning techniques on six public health datasets (PM-Data, LifeSnaps,
GLOBEM, AW_FB, MIT-BIH &amp; MIMIC-III). Our experiments cover thirteen consumer
health prediction tasks in mental health, activity, metabolic, sleep, and
cardiac assessment. Our fine-tuned model, Health-Alpaca exhibits comparable
performance to larger models (GPT-3.5 and GPT-4), achieving the best
performance in 5 out of 13 tasks. Ablation studies highlight the effectiveness
of context enhancement strategies, and generalization capability of the
fine-tuned models across training datasets and the size of training samples.
Notably, we observe that our context enhancement can yield up to 23.8%
improvement in performance. While constructing contextually rich prompts
(combining user context, health knowledge and temporal information) exhibits
synergistic improvement, the inclusion of health knowledge context in prompts
significantly enhances overall performance.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06868" title="Abstract">arXiv:2401.06868</a> [<a href="/pdf/2401.06868" title="Download PDF">pdf</a>, <a href="/format/2401.06868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicriteria decision support employing adaptive prediction in a  tensor-based feature representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Campello%2C+B+S+C">Betania Silva Carneiro Campello</a>, 
<a href="/search/cs?searchtype=author&query=Duarte%2C+L+T">Leonardo Tomazeli Duarte</a>, 
<a href="/search/cs?searchtype=author&query=Romano%2C+J+M+T">Jo&#xe3;o Marcos Travassos Romano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Multicriteria decision analysis (MCDA) is a widely used tool to support
decisions in which a set of alternatives should be ranked or classified based
on multiple criteria. Recent studies in MCDA have shown the relevance of
considering not only current evaluations of each criterion but also past data.
Past-data-based approaches carry new challenges, especially in time-varying
environments. This study deals with this challenge via essential tools of
signal processing, such as tensorial representations and adaptive prediction.
More specifically, we structure the criteria' past data as a tensor and, by
applying adaptive prediction, we compose signals with these prediction values
of the criteria. Besides, we transform the prediction in the time domain into a
most favorable decision making domain, called the feature domain. We present a
novel extension of the MCDA method PROMETHEE II, aimed at addressing the tensor
in the feature domain to obtain a ranking of alternatives. Numerical
experiments were performed using real-world time series, and our approach is
compared with other existing strategies. The results highlight the relevance
and efficiency of our proposal, especially for nonstationary time series.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06872" title="Abstract">arXiv:2401.06872</a> [<a href="/pdf/2401.06872" title="Download PDF">pdf</a>, <a href="/format/2401.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disease Transmission on Random Graphs Using Edge-Based Percolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">S. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Magpantay%2C+F+M+G">F.M.G. Magpantay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Dynamical Systems (math.DS); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">Edge-based percolation methods can be used to analyze disease transmission on
complex social networks. This allows us to include complex social heterogeneity
in our models while maintaining tractability. Here we review the seminal works
on this field by Newman et al (2001); Newman (2002, 2003), and Miller et al
(2012). We present a systematic discussion of the theoretical background behind
these models, including an extensive derivation of the major results. We also
connect these results relate back to the classical literature in random graph
theory Molloy and Reed (1995, 1998). Finally, we also present an accompanying R
package that takes epidemic and network parameters as input and generates
estimates of the epidemic trajectory and final size. This manuscript and the R
package was developed to help researchers easily understand and use network
models to investigate the interaction between different community structures
and disease transmission.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06874" title="Abstract">arXiv:2401.06874</a> [<a href="/pdf/2401.06874" title="Download PDF">pdf</a>, <a href="/ps/2401.06874" title="Download PostScript">ps</a>, <a href="/format/2401.06874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Joint Code and Belief Propagation Decoder Design for Quantum LDPC  Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+S">Sisi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Mandelbaum%2C+J">Jonathan Mandelbaum</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A4kel%2C+H">Holger J&#xe4;kel</a>, 
<a href="/search/cs?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum low-density parity-check (QLDPC) codes are among the most promising
candidates for future quantum error correction schemes. However, a limited
number of short to moderate-length QLDPC codes have been designed and their
decoding performance is sub-optimal with a quaternary belief propagation (BP)
decoder due to unavoidable short cycles in their Tanner graphs. In this letter,
we propose a novel joint code and decoder design for QLDPC codes. The
constructed codes have a minimum distance of about the square root of the block
length. In addition, it is, to the best of our knowledge, the first QLDPC code
family where BP decoding is not impaired by short cycles of length 4. This is
achieved by using an ensemble BP decoder mitigating the influence of assembled
short cycles. We outline two code construction methods based on classical
quasi-cyclic codes and finite geometry codes. Numerical results demonstrate
outstanding decoding performance over depolarizing channels.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06877" title="Abstract">arXiv:2401.06877</a> [<a href="/pdf/2401.06877" title="Download PDF">pdf</a>, <a href="/format/2401.06877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promptly Predicting Structures: The Return of Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+M">Maitrey Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+V">Valentina Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Srikumar%2C+V">Vivek Srikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Prompt-based methods have been used extensively across NLP to build zero- and
few-shot label predictors. Many NLP tasks are naturally structured: that is,
their outputs consist of multiple labels which constrain each other. Annotating
data for such tasks can be cumbersome. Can the promise of the prompt-based
paradigm be extended to such structured outputs? In this paper, we present a
framework for constructing zero- and few-shot linguistic structure predictors.
Our key insight is that we can use structural constraints -- and combinatorial
inference derived from them -- to filter out inconsistent structures predicted
by large language models. We instantiated this framework on two structured
prediction tasks, and five datasets. Across all cases, our results show that
enforcing consistency not only constructs structurally valid outputs, but also
improves performance over the unconstrained variants.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06883" title="Abstract">arXiv:2401.06883</a> [<a href="/pdf/2401.06883" title="Download PDF">pdf</a>, <a href="/ps/2401.06883" title="Download PostScript">ps</a>, <a href="/format/2401.06883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling While Privacy Preserving: A Comprehensive Synthetic Tabular Data  Generation and Evaluation in Learning Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Khalil%2C+M">Mohammad Khalil</a>, 
<a href="/search/cs?searchtype=author&query=Shakya%2C+R">Ronas Shakya</a>, 
<a href="/search/cs?searchtype=author&query=Jovanovic%2C+J">Jelena Jovanovic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Privacy poses a significant obstacle to the progress of learning analytics
(LA), presenting challenges like inadequate anonymization and data misuse that
current solutions struggle to address. Synthetic data emerges as a potential
remedy, offering robust privacy protection. However, prior LA research on
synthetic data lacks thorough evaluation, essential for assessing the delicate
balance between privacy and data utility. Synthetic data must not only enhance
privacy but also remain practical for data analytics. Moreover, diverse LA
scenarios come with varying privacy and utility needs, making the selection of
an appropriate synthetic data approach a pressing challenge. To address these
gaps, we propose a comprehensive evaluation of synthetic data, which
encompasses three dimensions of synthetic data quality, namely resemblance,
utility, and privacy. We apply this evaluation to three distinct LA datasets,
using three different synthetic data generation methods. Our results show that
synthetic data can maintain similar utility (i.e., predictive performance) as
real data, while preserving privacy. Furthermore, considering different privacy
and data utility requirements in different LA scenarios, we make customized
recommendations for synthetic data generation. This paper not only presents a
comprehensive evaluation of synthetic data but also illustrates its potential
in mitigating privacy concerns within the field of LA, thus contributing to a
wider application of synthetic data in LA and promoting a better practice for
open science.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06885" title="Abstract">arXiv:2401.06885</a> [<a href="/pdf/2401.06885" title="Download PDF">pdf</a>, <a href="/ps/2401.06885" title="Download PostScript">ps</a>, <a href="/format/2401.06885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Neural Networks for Large Language Models and Graph  Processing with Silicon Photonics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Afifi%2C+S">Salma Afifi</a>, 
<a href="/search/cs?searchtype=author&query=Sunny%2C+F">Febin Sunny</a>, 
<a href="/search/cs?searchtype=author&query=Nikdast%2C+M">Mahdi Nikdast</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the rapidly evolving landscape of artificial intelligence, large language
models (LLMs) and graph processing have emerged as transformative technologies
for natural language processing (NLP), computer vision, and graph-structured
data applications. However, the complex structures of these models pose
challenges for acceleration on conventional electronic platforms. In this
paper, we describe novel hardware accelerators based on silicon photonics to
accelerate transformer neural networks that are used in LLMs and graph neural
networks for graph data processing. Our analysis demonstrates that both
hardware accelerators achieve at least 10.2x throughput improvement and 3.8x
better energy efficiency over multiple state-of-the-art electronic hardware
accelerators designed for LLMs and graph processing.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06889" title="Abstract">arXiv:2401.06889</a> [<a href="/pdf/2401.06889" title="Download PDF">pdf</a>, <a href="/format/2401.06889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invisible Labor in Open Source Software Ecosystems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meluso%2C+J">John Meluso</a>, 
<a href="/search/cs?searchtype=author&query=Casari%2C+A">Amanda Casari</a>, 
<a href="/search/cs?searchtype=author&query=McLaughlin%2C+K">Katie McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Trujillo%2C+M+Z">Milo Z. Trujillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Invisible labor is work that is not fully visible, not appropriately
compensated, or both. In open source software (OSS) ecosystems, essential tasks
that do not involve code (like content moderation) often become invisible to
the detriment of individuals and organizations. However, invisible labor is so
difficult to measure that we do not know how much of OSS activities are
invisible. Our study addresses this challenge, demonstrating that roughly half
of OSS work is invisible. We do this by developing a survey technique with
cognitive anchoring that measures OSS developer self-assessments of labor
visibility and attribution. Survey respondents (n=142) reported that their work
is more likely to be nonvisible or partially visible (i.e. visible to at most 1
other person) than fully visible (i.e. visible to 2 or more people).
Furthermore, cognitively anchoring participants to the idea of high work
visibility increased perceptions of labor visibility and decreased visibility
importance compared to anchoring to low work visibility. This suggests that
advertising OSS activities as "open" may not make labor visible to most people,
but rather lead contributors to overestimate labor visibility. We therefore add
to a growing body of evidence that designing systems that recognize all kinds
of labor as legitimate contributions is likely to improve fairness in software
development while providing greater transparency into work designs that help
organizations and communities achieve their goals.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06890" title="Abstract">arXiv:2401.06890</a> [<a href="/pdf/2401.06890" title="Download PDF">pdf</a>, <a href="/format/2401.06890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Axiomatic Approach to Model-Agnostic Concept Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhili Feng</a>, 
<a href="/search/cs?searchtype=author&query=Moshkovitz%2C+M">Michal Moshkovitz</a>, 
<a href="/search/cs?searchtype=author&query=Di+Castro%2C+D">Dotan Di Castro</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Concept explanation is a popular approach for examining how
human-interpretable concepts impact the predictions of a model. However, most
existing methods for concept explanations are tailored to specific models. To
address this issue, this paper focuses on model-agnostic measures.
Specifically, we propose an approach to concept explanations that satisfy three
natural axioms: linearity, recursivity, and similarity. We then establish
connections with previous concept explanation methods, offering insight into
their varying semantic meanings. Experimentally, we demonstrate the utility of
the new method by applying it in different scenarios: for model selection,
optimizer selection, and model improvement using a kind of prompt editing for
zero-shot vision language models.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06894" title="Abstract">arXiv:2401.06894</a> [<a href="/pdf/2401.06894" title="Download PDF">pdf</a>, <a href="/format/2401.06894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Coded Caching Systems with Offline Users, with and without Demand  Privacy against Colluding Users
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yinbin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tuninetti%2C+D">Daniela Tuninetti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to TIT. arXiv admin note: text overlap with <a href="/abs/2202.01299">arXiv:2202.01299</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Coded caching is a technique that leverages locally cached contents at the
end users to reduce the network's peak-time communication load. Coded caching
has been shown to achieve significant performance gains compared to uncoded
schemes and is thus considered a promising technique to boost performance in
future networks by effectively trading off bandwidth for storage. The original
coded caching model introduced by Maddah-Ali and Niesen does not consider the
case where some users involved in the placement phase, may be offline during
the delivery phase. If so, the delivery may not start or it may be wasteful to
perform the delivery with fictitious demands for the offline users. In
addition, the active users may require their demand to be kept private. This
paper formally defines a coded caching system where some users are offline, and
investigates the optimal performance with and without demand privacy against
colluding users. For this novel coded caching model with offline users,
achievable and converse bounds are proposed. These bounds are shown to meet
under certain conditions, and otherwise to be to within a constant
multiplicative gap of one another. In addition, the proposed achievable schemes
have lower subpacketization and lower load compared to baseline schemes (that
trivially extend known schemes so as to accommodate for privacy) in some memory
regimes.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06898" title="Abstract">arXiv:2401.06898</a> [<a href="/pdf/2401.06898" title="Download PDF">pdf</a>, <a href="/format/2401.06898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Always-Sparse Training by Growing Connections with Guided Stochastic  Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heddes%2C+M">Mike Heddes</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+N">Narayan Srinivasa</a>, 
<a href="/search/cs?searchtype=author&query=Givargis%2C+T">Tony Givargis</a>, 
<a href="/search/cs?searchtype=author&query=Nicolau%2C+A">Alexandru Nicolau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The excessive computational requirements of modern artificial neural networks
(ANNs) are posing limitations on the machines that can run them. Sparsification
of ANNs is often motivated by time, memory and energy savings only during model
inference, yielding no benefits during training. A growing body of work is now
focusing on providing the benefits of model sparsification also during
training. While these methods greatly improve the training efficiency, the
training algorithms yielding the most accurate models still materialize the
dense weights, or compute dense gradients during training. We propose an
efficient, always-sparse training algorithm with excellent scaling to larger
and sparser models, supported by its linear time complexity with respect to the
model width during training and inference. Moreover, our guided stochastic
exploration algorithm improves over the accuracy of previous sparse training
methods. We evaluate our method on CIFAR-10/100 and ImageNet using ResNet, VGG,
and ViT models, and compare it against a range of sparsification methods.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06899" title="Abstract">arXiv:2401.06899</a> [<a href="/pdf/2401.06899" title="Download PDF">pdf</a>, <a href="/ps/2401.06899" title="Download PostScript">ps</a>, <a href="/format/2401.06899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyses and Concerns in Precision Medicine: A Statistical Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaofei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
<p class="mathjax">This article explores the critical role of statistical analysis in precision
medicine. It discusses how personalized healthcare is enhanced by statistical
methods that interpret complex, multidimensional datasets, focusing on
predictive modeling, machine learning algorithms, and data visualization
techniques. The paper addresses challenges in data integration and
interpretation, particularly with diverse data sources like electronic health
records (EHRs) and genomic data. It also delves into ethical considerations
such as patient privacy and data security. In addition, the paper highlights
the evolution of statistical analysis in medicine, core statistical
methodologies in precision medicine, and future directions in the field,
emphasizing the integration of artificial intelligence (AI) and machine
learning (ML).
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06901" title="Abstract">arXiv:2401.06901</a> [<a href="/pdf/2401.06901" title="Download PDF">pdf</a>, <a href="/format/2401.06901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced safety filter based on SOS Control Barrier and Lyapunov  Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Schneeberger%2C+M">Michael Schneeberger</a>, 
<a href="/search/eess?searchtype=author&query=Mastellone%2C+S">Silvia Mastellone</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 11 figures, submitted to IEEE Transactions on Control Systems Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a novel safety filter framework based on Control Barrier
Functions (CBFs) and Control Lyapunov-like Functions (CLFs). The CBF guarantees
forward invariance of the safe set, constraining system trajectories within
state constraints, while the CLF guides the system away from unsafe states
towards a nominal region, preserving the performance of a nominal controller.
The first part of this work focuses on determining compatible CBF and CLF in
the presence of linear or quadratic input constraints. This is achieved by
formulating the CBF and CLF conditions, along with the input constraints, as
Sum of Squares (SOS) constraints using Putinar's Positivstellensatz. For
solving the resulting SOS optimization problem, we employ an alternating
algorithm that simultaneously searches for a feasible controller in the class
of rational functions of the state. The second part of this work details the
implementation of the safety filter as a Quadratically Constrained Quadratic
Program (QCQP), whose constraints encode the CBF and CLF conditions as well as
the input constraints. To avoid the chattering effect and guarantee the
uniqueness and Lipschitz continuity of solutions, the state-dependent
inequality constraints of the QCQP are selected to be sufficiently regular.
Finally, we demonstrate the method on a detailed case study involving the
control of a three-phase ac/dc power converter connected to an infinite bus.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06908" title="Abstract">arXiv:2401.06908</a> [<a href="/pdf/2401.06908" title="Download PDF">pdf</a>, <a href="/ps/2401.06908" title="Download PostScript">ps</a>, <a href="/format/2401.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-hop Relaying with Mixed Half and Full Duplex Relays for Offloading  to MEC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mach%2C+P">Pavel Mach</a>, 
<a href="/search/cs?searchtype=author&query=Becvar%2C+Z">Zdenek Becvar</a>, 
<a href="/search/cs?searchtype=author&query=Nikooroo%2C+M">Mohammadsaleh Nikooroo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Paper presented at IEEE GLOBECOM Workshop 2023 (4th Workshop on
  Emerging Topics in 6G Communications)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this paper, we focus on offloading a computing task from a user equipment
(UE) to a multi-access edge computing (MEC) server via multi-hop relaying. We
assume a general relaying case where relays are energy-constrained devices,
such as other UEs, internet of things (IoT) devices, or unmanned aerial
vehicles. To this end, we formulate the problem as a minimization of the sum
energy consumed by the energy-constrained devices under the constraint on the
maximum requested time of the task processing. Then, we propose a multi-hop
relaying combining half and full duplexes at each individual relay involved in
the offloading. We proof that the proposed multi-hop relaying is convex, thus
it can be optimized by conventional convex optimization methods. We show our
proposal outperforms existing multi-hop relaying schemes in terms of
probability that tasks are processed within required time by up to 38\% and, at
the same time, decreases energy consumption by up to 28%.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06910" title="Abstract">arXiv:2401.06910</a> [<a href="/pdf/2401.06910" title="Download PDF">pdf</a>, <a href="/format/2401.06910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InRanker: Distilled Rankers for Zero-shot Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laitz%2C+T">Thiago Laitz</a>, 
<a href="/search/cs?searchtype=author&query=Papakostas%2C+K">Konstantinos Papakostas</a>, 
<a href="/search/cs?searchtype=author&query=Lotufo%2C+R">Roberto Lotufo</a>, 
<a href="/search/cs?searchtype=author&query=Nogueira%2C+R">Rodrigo Nogueira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Despite multi-billion parameter neural rankers being common components of
state-of-the-art information retrieval pipelines, they are rarely used in
production due to the enormous amount of compute required for inference. In
this work, we propose a new method for distilling large rankers into their
smaller versions focusing on out-of-domain effectiveness. We introduce
InRanker, a version of monoT5 distilled from monoT5-3B with increased
effectiveness on out-of-domain scenarios. Our key insight is to use language
models and rerankers to generate as much as possible synthetic "in-domain"
training data, i.e., data that closely resembles the data that will be seen at
retrieval time. The pipeline consists of two distillation phases that do not
require additional user queries or manual annotations: (1) training on existing
supervised soft teacher labels, and (2) training on teacher soft labels for
synthetic queries generated using a large language model. Consequently, models
like monoT5-60M and monoT5-220M improved their effectiveness by using the
teacher's knowledge, despite being 50x and 13x smaller, respectively. Models
and code are available at https://github.com/unicamp-dl/InRanker.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06913" title="Abstract">arXiv:2401.06913</a> [<a href="/pdf/2401.06913" title="Download PDF">pdf</a>, <a href="/format/2401.06913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Microphone Conversion: Mitigating Device Variability in Sound Event  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ryu%2C+M">Myeonghoon Ryu</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+H">Hongseok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Suji Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+H">Han Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this study, we introduce a new augmentation technique to enhance the
resilience of sound event classification (SEC) systems against device
variability through the use of CycleGAN. We also present a unique dataset to
evaluate this method. As SEC systems become increasingly common, it is crucial
that they work well with audio from diverse recording devices. Our method
addresses limited device diversity in training data by enabling unpaired
training to transform input spectrograms as if they are recorded on a different
device. Our experiments show that our approach outperforms existing methods in
generalization by 5.2% - 11.5% in weighted f1 score. Additionally, it surpasses
the current methods in adaptability across diverse recording devices by
achieving a 6.5% - 12.8% improvement in weighted f1 score.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06915" title="Abstract">arXiv:2401.06915</a> [<a href="/pdf/2401.06915" title="Download PDF">pdf</a>, <a href="/format/2401.06915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DocFinQA: A Long-Context Financial Reasoning Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reddy%2C+V">Varshini Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+V+D">Viet Dac Lai</a>, 
<a href="/search/cs?searchtype=author&query=Tanner%2C+C">Chris Tanner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Research in quantitative reasoning within the financial domain indeed
necessitates the use of realistic tasks and data, primarily because of the
significant impact of decisions made in business and finance. Financial
professionals often interact with documents hundreds of pages long, but most
research datasets drastically reduce this context length. To address this, we
introduce a long-document financial QA task. We augment 7,621 questions from
the existing FinQA dataset with full-document context, extending the average
context length for each question from under 700 words in FinQA to 123k words in
DocFinQA. We conduct extensive experiments of retrieval-based QA pipelines and
long-context language models on the augmented data. Our results show that
DocFinQA provides challenges for even the strongest, state-of-the-art systems.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06916" title="Abstract">arXiv:2401.06916</a> [<a href="/pdf/2401.06916" title="Download PDF">pdf</a>, <a href="/format/2401.06916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analytical Framework for Modeling and Synthesizing Malicious Attacks  on ACC Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shian Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
<p class="mathjax">While emerging adaptive cruise control (ACC) technologies are making their
way into more vehicles, they also expose a vulnerability to potential malicious
cyberattacks. Previous research has typically focused on constant or stochastic
attacks without explicitly addressing their malicious and covert
characteristics. As a result, these attacks may inadvertently benefit the
compromised vehicles, inconsistent with real-world scenarios. In contrast, we
establish an analytical framework to model and synthesize a range of candidate
attacks, offering a physical interpretation from the attacker's standpoint.
Specifically, we introduce a mathematical framework that describes mixed
traffic scenarios, comprising ACC vehicles and human-driven vehicles (HDVs),
grounded in car-following dynamics. Within this framework, we synthesize and
integrate a class of false data injection attacks into ACC sensor measurements,
influencing traffic flow dynamics. As a first-of-its-kind study, this work
provides an analytical characterization of attacks, emphasizing their malicious
and stealthy attributes while explicitly accounting for vehicle driving
behavior, thereby yielding a set of candidate attacks with physical
interpretability. To demonstrate the modeling process, we perform a series of
numerical simulations to holistically assess the effects of attacks on
car-following dynamics, traffic efficiency, and vehicular fuel consumption. The
primary findings indicate that strategically synthesized candidate attacks can
cause significant disruptions to the traffic flow while altering the driving
behavior of ACC vehicles in a subtle fashion to remain stealthy, which is
supported by a series of analytical results.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06918" title="Abstract">arXiv:2401.06918</a> [<a href="/pdf/2401.06918" title="Download PDF">pdf</a>, <a href="/format/2401.06918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> H-CMRH: a novel inner product free hybrid Krylov method for large-scale  inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brown%2C+A+N">Ariana N. Brown</a>, 
<a href="/search/math?searchtype=author&query=Landman%2C+M+S">Malena Sabat&#xe9; Landman</a>, 
<a href="/search/math?searchtype=author&query=Nagy%2C+J+G">James G. Nagy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This study investigates the iterative regularization properties of two Krylov
methods for solving large-scale ill-posed problems: the changing minimal
residual Hessenberg method (CMRH) and a novel hybrid variant called the hybrid
changing minimal residual Hessenberg method (H-CMRH). Both methods share the
advantages of avoiding inner products, making them efficient and highly
parallelizable, and particularly suited for implementations that exploit
randomization and mixed precision arithmetic. Theoretical results and extensive
numerical experiments suggest that H-CMRH exhibits comparable performance to
the established hybrid GMRES method in terms of stabilizing semiconvergence,
but H-CMRH has does not require any inner products, and requires less work and
storage per iteration.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06920" title="Abstract">arXiv:2401.06920</a> [<a href="/pdf/2401.06920" title="Download PDF">pdf</a>, <a href="/format/2401.06920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing GPT-4 and Open-Source Language Models in Misinformation  Mitigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vergho%2C+T">Tyler Vergho</a>, 
<a href="/search/cs?searchtype=author&query=Godbout%2C+J">Jean-Francois Godbout</a>, 
<a href="/search/cs?searchtype=author&query=Rabbany%2C+R">Reihaneh Rabbany</a>, 
<a href="/search/cs?searchtype=author&query=Pelrine%2C+K">Kellin Pelrine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent large language models (LLMs) have been shown to be effective for
misinformation detection. However, the choice of LLMs for experiments varies
widely, leading to uncertain conclusions. In particular, GPT-4 is known to be
strong in this domain, but it is closed source, potentially expensive, and can
show instability between different versions. Meanwhile, alternative LLMs have
given mixed results. In this work, we show that Zephyr-7b presents a
consistently viable alternative, overcoming key limitations of commonly used
approaches like Llama-2 and GPT-3.5. This provides the research community with
a solid open-source option and shows open-source models are gradually catching
up on this task. We then highlight how GPT-3.5 exhibits unstable performance,
such that this very widely used model could provide misleading results in
misinformation detection. Finally, we validate new tools including approaches
to structured output and the latest version of GPT-4 (Turbo), showing they do
not compromise performance, thus unlocking them for future research and
potentially enabling more complex pipelines for misinformation mitigation.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06922" title="Abstract">arXiv:2401.06922</a> [<a href="/pdf/2401.06922" title="Download PDF">pdf</a>, <a href="/format/2401.06922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open RAN LSTM Traffic Prediction and Slice Management using Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+F">Fatemeh Lotfi</a>, 
<a href="/search/cs?searchtype=author&query=Afghah%2C+F">Fatemeh Afghah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to publish in the IEEE Asilomar Conference on Signals, Systems, and Computers, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">With emerging applications such as autonomous driving, smart cities, and
smart factories, network slicing has become an essential component of 5G and
beyond networks as a means of catering to a service-aware network. However,
managing different network slices while maintaining quality of services (QoS)
is a challenge in a dynamic environment. To address this issue, this paper
leverages the heterogeneous experiences of distributed units (DUs) in ORAN
systems and introduces a novel approach to ORAN slicing xApp using distributed
deep reinforcement learning (DDRL). Additionally, to enhance the
decision-making performance of the RL agent, a prediction rApp based on long
short-term memory (LSTM) is incorporated to provide additional information from
the dynamic environment to the xApp. Simulation results demonstrate significant
improvements in network performance, particularly in reducing QoS violations.
This emphasizes the importance of using the prediction rApp and distributed
actors' information jointly as part of a dynamic xApp.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06923" title="Abstract">arXiv:2401.06923</a> [<a href="/pdf/2401.06923" title="Download PDF">pdf</a>, <a href="/format/2401.06923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimally Supervised Learning using Topological Projections in  Self-Organizing Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zimeng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Ororbia%2C+A">Alexander Ororbia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rui Li</a>, 
<a href="/search/cs?searchtype=author&query=Desell%2C+T">Travis Desell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Parameter prediction is essential for many applications, facilitating
insightful interpretation and decision-making. However, in many real life
domains, such as power systems, medicine, and engineering, it can be very
expensive to acquire ground truth labels for certain datasets as they may
require extensive and expensive laboratory testing. In this work, we introduce
a semi-supervised learning approach based on topological projections in
self-organizing maps (SOMs), which significantly reduces the required number of
labeled data points to perform parameter prediction, effectively exploiting
information contained in large unlabeled datasets. Our proposed method first
trains SOMs on unlabeled data and then a minimal number of available labeled
data points are ultimately assigned to key best matching units (BMU). The
values estimated for newly-encountered data points are computed utilizing the
average of the $n$ closest labeled data points in the SOM's U-matrix in tandem
with a topological shortest path distance calculation scheme. Our results
indicate that the proposed semi-supervised model significantly outperforms
traditional regression techniques, including linear and polynomial regression,
Gaussian process regression, K-nearest neighbors, as well as various deep
neural network models.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06925" title="Abstract">arXiv:2401.06925</a> [<a href="/pdf/2401.06925" title="Download PDF">pdf</a>, <a href="/ps/2401.06925" title="Download PostScript">ps</a>, <a href="/format/2401.06925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Latent Selection with Structural Causal Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Leihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zoeter%2C+O">Onno Zoeter</a>, 
<a href="/search/cs?searchtype=author&query=Mooij%2C+J+M">Joris M. Mooij</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Selection bias is ubiquitous in real-world data, and can lead to misleading
results if not dealt with properly. We introduce a conditioning operation on
Structural Causal Models (SCMs) to model latent selection from a causal
perspective. We show that the conditioning operation transforms an SCM with the
presence of an explicit latent selection mechanism into an SCM without such
selection mechanism, which partially encodes the causal semantics of the
selected subpopulation according to the original SCM. Furthermore, we show that
this conditioning operation preserves the simplicity, acyclicity, and linearity
of SCMs, and commutes with marginalization. Thanks to these properties,
combined with marginalization and intervention, the conditioning operation
offers a valuable tool for conducting causal reasoning tasks within causal
models where latent details have been abstracted away. We demonstrate by
example how classical results of causal inference can be generalized to include
selection bias and how the conditioning operation helps with modeling of
real-world problems.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06930" title="Abstract">arXiv:2401.06930</a> [<a href="/pdf/2401.06930" title="Download PDF">pdf</a>, <a href="/format/2401.06930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PizzaCommonSense: Learning to Model Commonsense Reasoning about  Intermediate Steps in Cooking Recipes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diallo%2C+A">Aissatou Diallo</a>, 
<a href="/search/cs?searchtype=author&query=Bikakis%2C+A">Antonis Bikakis</a>, 
<a href="/search/cs?searchtype=author&query=Dickens%2C+L">Luke Dickens</a>, 
<a href="/search/cs?searchtype=author&query=Hunter%2C+A">Anthony Hunter</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+R">Rob Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The data is available at: <a href="https://github.com/adiallo07/PizzaCommonsense">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Decoding the core of procedural texts, exemplified by cooking recipes, is
crucial for intelligent reasoning and instruction automation. Procedural texts
can be comprehensively defined as a sequential chain of steps to accomplish a
task employing resources. From a cooking perspective, these instructions can be
interpreted as a series of modifications to a food preparation, which initially
comprises a set of ingredients. These changes involve transformations of
comestible resources. For a model to effectively reason about cooking recipes,
it must accurately discern and understand the inputs and outputs of
intermediate steps within the recipe. Aiming to address this, we present a new
corpus of cooking recipes enriched with descriptions of intermediate steps of
the recipes that explicate the input and output for each step. We discuss the
data collection process, investigate and provide baseline models based on T5
and GPT-3.5. This work presents a challenging task and insight into commonsense
reasoning and procedural text generation.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06935" title="Abstract">arXiv:2401.06935</a> [<a href="/pdf/2401.06935" title="Download PDF">pdf</a>, <a href="/format/2401.06935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiTTenS: A Dataset for Evaluating Misgendering in Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinson%2C+K">Kevin Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Kudugunta%2C+S">Sneha Kudugunta</a>, 
<a href="/search/cs?searchtype=author&query=Stella%2C+R">Romina Stella</a>, 
<a href="/search/cs?searchtype=author&query=Dev%2C+S">Sunipa Dev</a>, 
<a href="/search/cs?searchtype=author&query=Bastings%2C+J">Jasmijn Bastings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GitHub repository <a href="https://github.com/google-research-datasets/mittens">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Misgendering is the act of referring to someone in a way that does not
reflect their gender identity. Translation systems, including foundation models
capable of translation, can produce errors that result in misgendering harms.
To measure the extent of such potential harms when translating into and out of
English, we introduce a dataset, MiTTenS, covering 26 languages from a variety
of language families and scripts, including several traditionally
underpresented in digital resources. The dataset is constructed with
handcrafted passages that target known failure patterns, longer synthetically
generated passages, and natural passages sourced from multiple domains. We
demonstrate the usefulness of the dataset by evaluating both dedicated neural
machine translation systems and foundation models, and show that all systems
exhibit errors resulting in misgendering harms, even in high resource
languages.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06936" title="Abstract">arXiv:2401.06936</a> [<a href="/pdf/2401.06936" title="Download PDF">pdf</a>, <a href="/format/2401.06936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Sampling of Rare Events using a Neural Network Bias  Potential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+X">Xinru Hua</a>, 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+R">Rasool Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Blanchet%2C+J">Jose Blanchet</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wei Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">In the field of computational physics and material science, the efficient
sampling of rare events occurring at atomic scale is crucial. It aids in
understanding mechanisms behind a wide range of important phenomena, including
protein folding, conformal changes, chemical reactions and materials diffusion
and deformation. Traditional simulation methods, such as Molecular Dynamics and
Monte Carlo, often prove inefficient in capturing the timescale of these rare
events by brute force. In this paper, we introduce a practical approach by
combining the idea of importance sampling with deep neural networks (DNNs) that
enhance the sampling of these rare events. In particular, we approximate the
variance-free bias potential function with DNNs which is trained to maximize
the probability of rare event transition under the importance potential
function. This method is easily scalable to high-dimensional problems and
provides robust statistical guarantees on the accuracy of the estimated
probability of rare event transition. Furthermore, our algorithm can actively
generate and learn from any successful samples, which is a novel improvement
over existing methods. Using a 2D system as a test bed, we provide comparisons
between results obtained from different training strategies, traditional Monte
Carlo sampling and numerically solved optimal bias potential function under
different temperatures. Our numerical results demonstrate the efficacy of the
DNN-based importance sampling of rare events.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06945" title="Abstract">arXiv:2401.06945</a> [<a href="/pdf/2401.06945" title="Download PDF">pdf</a>, <a href="/format/2401.06945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge-Centric Templatic Views of Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cachola%2C+I">Isabel Cachola</a>, 
<a href="/search/cs?searchtype=author&query=Cucerzan%2C+S">Silviu Cucerzan</a>, 
<a href="/search/cs?searchtype=author&query=Herring%2C+A">Allen Herring</a>, 
<a href="/search/cs?searchtype=author&query=Mijovic%2C+V">Vuksan Mijovic</a>, 
<a href="/search/cs?searchtype=author&query=Oveson%2C+E">Erik Oveson</a>, 
<a href="/search/cs?searchtype=author&query=Jauhar%2C+S+K">Sujay Kumar Jauhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Authors seeking to communicate with broader audiences often compose their
ideas about the same underlying knowledge in different documents and formats --
for example, as slide decks, newsletters, reports, brochures, etc. Prior work
in document generation has generally considered the creation of each separate
format to be different a task, developing independent methods for generation
and evaluation. This approach is suboptimal for the advancement of AI-supported
content authoring from both research and application perspectives because it
leads to fragmented learning processes, redundancy in models and methods, and
disjointed evaluation. Thus, in our work, we consider each of these documents
to be templatic views of the same underlying knowledge, and we aim to unify the
generation and evaluation of these templatic views of documents. We begin by
introducing an LLM-powered method to extract the most important information
from an input document and represent this information in a structured format.
We show that this unified representation can be used to generate multiple
templatic views with no supervision and with very little guidance, improving
over strong baselines. We additionally introduce a unified evaluation method
that is template agnostic, and can be adapted to building document generators
for heterogeneous downstream applications. Finally, we conduct a human
evaluation, which shows that humans prefer 82% of the downstream documents
generated with our method. Furthermore, the newly proposed evaluation metric
correlates more highly with human judgement than prior metrics, while providing
a unified evaluation method.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06946" title="Abstract">arXiv:2401.06946</a> [<a href="/pdf/2401.06946" title="Download PDF">pdf</a>, <a href="/ps/2401.06946" title="Download PostScript">ps</a>, <a href="/format/2401.06946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Object Detection and High-Resolution Traffic Parameters Extraction  Using Low-Resolution LiDAR Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Aboah%2C+A">Armstrong Aboah</a>, 
<a href="/search/cs?searchtype=author&query=Adu-Gyamfi%2C+Y">Yaw Adu-Gyamfi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 11 figures. This paper has been submitted for consideration for presentation at the 103rd Annual Meeting of the Transportation Research Board, January 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traffic volume data collection is a crucial aspect of transportation
engineering and urban planning, as it provides vital insights into traffic
patterns, congestion, and infrastructure efficiency. Traditional manual methods
of traffic data collection are both time-consuming and costly. However, the
emergence of modern technologies, particularly Light Detection and Ranging
(LiDAR), has revolutionized the process by enabling efficient and accurate data
collection. Despite the benefits of using LiDAR for traffic data collection,
previous studies have identified two major limitations that have impeded its
widespread adoption. These are the need for multiple LiDAR systems to obtain
complete point cloud information of objects of interest, as well as the
labor-intensive process of annotating 3D bounding boxes for object detection
tasks. In response to these challenges, the current study proposes an
innovative framework that alleviates the need for multiple LiDAR systems and
simplifies the laborious 3D annotation process. To achieve this goal, the study
employed a single LiDAR system, that aims at reducing the data acquisition cost
and addressed its accompanying limitation of missing point cloud information by
developing a Point Cloud Completion (PCC) framework to fill in missing point
cloud information using point density. Furthermore, we also used zero-shot
learning techniques to detect vehicles and pedestrians, as well as proposed a
unique framework for extracting low to high features from the object of
interest, such as height, acceleration, and speed. Using the 2D bounding box
detection and extracted height information, this study is able to generate 3D
bounding boxes automatically without human intervention.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06947" title="Abstract">arXiv:2401.06947</a> [<a href="/pdf/2401.06947" title="Download PDF">pdf</a>, <a href="/format/2401.06947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter-Efficient Detoxification with Contrastive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+T">Tong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+S">Semih Yavuz</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The field of natural language generation has witnessed significant
advancements in recent years, including the development of controllable text
generation techniques. However, controlling the attributes of the generated
text remains a challenge, especially when aiming to avoid undesirable behavior
such as toxicity. In this work, we introduce Detoxification Generator
(DETOXIGEN), an inference-time algorithm that steers the generation away from
unwanted styles. DETOXIGEN is an ensemble of a pre-trained language model
(generator) and a detoxifier. The detoxifier is trained intentionally on the
toxic data representative of the undesirable attribute, encouraging it to
generate text in that style exclusively. During the actual generation, we use
the trained detoxifier to produce undesirable tokens for the generator to
contrast against at each decoding step. This approach directly informs the
generator to avoid generating tokens that the detoxifier considers highly
likely. We evaluate DETOXIGEN on the commonly used REALTOXICITYPROMPTS
benchmark (Gehman et al., 2020) with various language models as generators. We
find that it significantly outperforms previous approaches in detoxification
metrics while not compromising on the generation quality. Moreover, the
detoxifier is obtained by soft prompt-tuning using the same backbone language
model as the generator. Hence, DETOXIGEN requires only a tiny amount of extra
weights from the virtual tokens of the detoxifier to be loaded into GPU memory
while decoding, making it a promising lightweight, practical, and
parameter-efficient detoxification strategy.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06948" title="Abstract">arXiv:2401.06948</a> [<a href="/pdf/2401.06948" title="Download PDF">pdf</a>, <a href="/format/2401.06948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Accurate Zero-Training Classification for Tabular Engineering  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Picard%2C+C">Cyril Picard</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Faez Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">In engineering design, navigating complex decision-making landscapes demands
a thorough exploration of the design, performance, and constraint spaces, often
impeded by resource-intensive simulations. Data-driven methods can mitigate
this challenge by harnessing historical data to delineate feasible domains,
accelerate optimization, or evaluate designs. However, the implementation of
these methods usually demands machine-learning expertise and multiple trials to
choose the right method and hyperparameters. This makes them less accessible
for numerous engineering situations. Additionally, there is an inherent
trade-off between training speed and accuracy, with faster methods sometimes
compromising precision. In our paper, we demonstrate that a recently released
general-purpose transformer-based classification model, TabPFN, is both fast
and accurate. Notably, it requires no dataset-specific training to assess new
tabular data. TabPFN is a Prior-Data Fitted Network, which undergoes a one-time
offline training across a broad spectrum of synthetic datasets and performs
in-context learning. We evaluated TabPFN's efficacy across eight engineering
design classification problems, contrasting it with seven other algorithms,
including a state-of-the-art AutoML method. For these classification
challenges, TabPFN consistently outperforms in speed and accuracy. It is also
the most data-efficient and provides the added advantage of being
differentiable and giving uncertainty estimates. Our findings advocate for the
potential of pre-trained models that learn from synthetic data and require no
domain-specific tuning to make data-driven engineering design accessible to a
broader community and open ways to efficient general-purpose models valid
across applications. Furthermore, we share a benchmark problem set for
evaluating new classification algorithms in engineering design.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06949" title="Abstract">arXiv:2401.06949</a> [<a href="/pdf/2401.06949" title="Download PDF">pdf</a>, <a href="/format/2401.06949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and  Characterization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Darvish%2C+K">Kourosh Darvish</a>, 
<a href="/search/cs?searchtype=author&query=Skreta%2C+M">Marta Skreta</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuchi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yoshikawa%2C+N">Naruki Yoshikawa</a>, 
<a href="/search/cs?searchtype=author&query=Som%2C+S">Sagnik Som</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanovic%2C+M">Miroslav Bogdanovic</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+H">Han Hao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoping Xu</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Al&#xe1;n Aspuru-Guzik</a>, 
<a href="/search/cs?searchtype=author&query=Garg%2C+A">Animesh Garg</a>, 
<a href="/search/cs?searchtype=author&query=Shkurti%2C+F">Florian Shkurti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chemistry experimentation is often resource- and labor-intensive. Despite the
many benefits incurred by the integration of advanced and special-purpose lab
equipment, many aspects of experimentation are still manually conducted by
chemists, for example, polishing an electrode in electrochemistry experiments.
Traditional lab automation infrastructure faces challenges when it comes to
flexibly adapting to new chemistry experiments. To address this issue, we
propose a human-friendly and flexible robotic system, ORGANA, that automates a
diverse set of chemistry experiments. It is capable of interacting with
chemists in the lab through natural language, using Large Language Models
(LLMs). ORGANA keeps scientists informed by providing timely reports that
incorporate statistical analyses. Additionally, it actively engages with users
when necessary for disambiguation or troubleshooting. ORGANA can reason over
user input to derive experiment goals, and plan long sequences of both
high-level tasks and low-level robot actions while using feedback from the
visual perception of the environment. It also supports scheduling and parallel
execution for experiments that require resource allocation and coordination
between multiple robots and experiment stations. We show that ORGANA
successfully conducts a diverse set of chemistry experiments, including
solubility assessment, pH measurement, recrystallization, and electrochemistry
experiments. For the latter, we show that ORGANA robustly executes a
long-horizon plan, comprising 19 steps executed in parallel, to characterize
the electrochemical properties of quinone derivatives, a class of molecules
used in rechargeable flow batteries. Our user study indicates that ORGANA
significantly improves many aspects of user experience while reducing their
physical workload. More details about ORGANA can be found at
https://ac-rad.github.io/organa/.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06951" title="Abstract">arXiv:2401.06951</a> [<a href="/pdf/2401.06951" title="Download PDF">pdf</a>, <a href="/format/2401.06951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E^2-LLM: Efficient and Extreme Length Extension of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zhiqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Ge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiakai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Que%2C+H">Haoran Que</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yukang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wenbo Su</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tiezheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Typically, training LLMs with long context sizes is computationally
expensive, requiring extensive training hours and GPU resources. Existing
long-context extension methods usually need additional training procedures to
support corresponding long-context windows, where the long-context training
data (e.g., 32k) is needed, and high GPU training costs are assumed. To address
the aforementioned issues, we propose an Efficient and Extreme length extension
method for Large Language Models, called E 2 -LLM, with only one training
procedure and dramatically reduced computation cost, which also removes the
need to collect long-context data. Concretely, first, the training data of our
E 2 -LLM only requires a short length (e.g., 4k), which reduces the tuning cost
greatly. Second, the training procedure on the short training context window is
performed only once time, and we can support different evaluation context
windows at inference. Third, in E 2 - LLM, based on RoPE position embeddings,
we introduce two different augmentation methods on the scale and position index
parameters for different samples in training. It aims to make the model more
robust to the different relative differences when directly interpolating the
arbitrary context length at inference. Comprehensive experimental results on
multiple benchmark datasets demonstrate the effectiveness of our E 2 -LLM on
challenging long-context tasks.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06952" title="Abstract">arXiv:2401.06952</a> [<a href="/pdf/2401.06952" title="Download PDF">pdf</a>, <a href="/format/2401.06952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Scalable Train Timetable Rescheduling with  Graph Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+P">Peng Yue</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yaochu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xuewu Dai</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhenhua Feng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+D">Dongliang Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Train timetable rescheduling (TTR) aims to promptly restore the original
operation of trains after unexpected disturbances or disruptions. Currently,
this work is still done manually by train dispatchers, which is challenging to
maintain performance under various problem instances. To mitigate this issue,
this study proposes a reinforcement learning-based approach to TTR, which makes
the following contributions compared to existing work. First, we design a
simple directed graph to represent the TTR problem, enabling the automatic
extraction of informative states through graph neural networks. Second, we
reformulate the construction process of TTR's solution, not only decoupling the
decision model from the problem size but also ensuring the generated scheme's
feasibility. Third, we design a learning curriculum for our model to handle the
scenarios with different levels of delay. Finally, a simple local search method
is proposed to assist the learned decision model, which can significantly
improve solution quality with little additional computation cost, further
enhancing the practical value of our method. Extensive experimental results
demonstrate the effectiveness of our method. The learned decision model can
achieve better performance for various problems with varying degrees of train
delay and different scales when compared to handcrafted rules and
state-of-the-art solvers.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06953" title="Abstract">arXiv:2401.06953</a> [<a href="/pdf/2401.06953" title="Download PDF">pdf</a>, <a href="/format/2401.06953" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDriveScore: Federated Scoring Driving Behavior with a Mixture of  Metric Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lin Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Scoring the driving performance of various drivers on a unified scale, based
on how safe or economical they drive on their daily trips, is essential for the
driver profile task. Connected vehicles provide the opportunity to collect
real-world driving data, which is advantageous for constructing scoring models.
However, the lack of pre-labeled scores impede the use of supervised regression
models and the data privacy issues hinder the way of traditionally
data-centralized learning on the cloud side for model training. To address
them, an unsupervised scoring method is presented without the need for labels
while still preserving fairness and objectiveness compared to subjective
scoring strategies. Subsequently, a federated learning framework based on
vehicle-cloud collaboration is proposed as a privacy-friendly alternative to
centralized learning. This framework includes a consistently federated version
of the scoring method to reduce the performance degradation of the global
scoring model caused by the statistical heterogeneous challenge of local data.
Theoretical and experimental analysis demonstrate that our federated scoring
model is consistent with the utility of the centrally learned counterpart and
is effective in evaluating driving performance.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06954" title="Abstract">arXiv:2401.06954</a> [<a href="/pdf/2401.06954" title="Download PDF">pdf</a>, <a href="/format/2401.06954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging the Preference Gap between Retrievers and LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ke%2C+Z">Zixuan Ke</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weize Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated superior results across a wide
range of tasks, while retrieval has long been established as an effective means
of obtaining task-relevant information for humans. Retrieval-augmented
Generation (RAG) are known for their effectiveness in knowledge-intensive tasks
by locating relevant information and placing it within the context window of
the LLM. However, the relationship between retrievers and LLMs is still
under-investigated. Most existing work treats the retriever and the LLM as
independent components and leaves a gap between retrieving human-friendly
information and assembling a LLM-friendly context. In this work, we examine a
novel bridge model, validate the ranking and selection assumptions in
retrievers in the context of RAG, and propose a training framework that chains
together supervised and reinforcement learning to learn a bridge model.
Empirical results demonstrate the effectiveness of our method in both
question-answering and personalized generation tasks.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06957" title="Abstract">arXiv:2401.06957</a> [<a href="/pdf/2401.06957" title="Download PDF">pdf</a>, <a href="/format/2401.06957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EVOKE: Emotion Enabled Virtual Avatar Mapping Using Optimized Knowledge  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+M">Maryam Nadeem</a>, 
<a href="/search/cs?searchtype=author&query=Imam%2C+R">Raza Imam</a>, 
<a href="/search/cs?searchtype=author&query=Al-Refai%2C+R">Rouqaiah Al-Refai</a>, 
<a href="/search/cs?searchtype=author&query=Chkir%2C+M">Meriem Chkir</a>, 
<a href="/search/cs?searchtype=author&query=Hoda%2C+M">Mohamad Hoda</a>, 
<a href="/search/cs?searchtype=author&query=Saddik%2C+A+E">Abdulmotaleb El Saddik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at IEEE 42nd International Conference on Consumer Electronics (ICCE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As virtual environments continue to advance, the demand for immersive and
emotionally engaging experiences has grown. Addressing this demand, we
introduce Emotion enabled Virtual avatar mapping using Optimized KnowledgE
distillation (EVOKE), a lightweight emotion recognition framework designed for
the seamless integration of emotion recognition into 3D avatars within virtual
environments. Our approach leverages knowledge distillation involving
multi-label classification on the publicly available DEAP dataset, which covers
valence, arousal, and dominance as primary emotional classes. Remarkably, our
distilled model, a CNN with only two convolutional layers and 18 times fewer
parameters than the teacher model, achieves competitive results, boasting an
accuracy of 87% while demanding far less computational resources. This
equilibrium between performance and deployability positions our framework as an
ideal choice for virtual environment systems. Furthermore, the multi-label
classification outcomes are utilized to map emotions onto custom-designed 3D
avatars.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06960" title="Abstract">arXiv:2401.06960</a> [<a href="/pdf/2401.06960" title="Download PDF">pdf</a>, <a href="/format/2401.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer for Object Re-Identification: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Mang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuoyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Crandall%2C+D">David Crandall</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Object Re-Identification (Re-ID) aims to identify and retrieve specific
objects from varying viewpoints. For a prolonged period, this field has been
predominantly driven by deep convolutional neural networks. In recent years,
the Transformer has witnessed remarkable advancements in computer vision,
prompting an increasing body of research to delve into the application of
Transformer in Re-ID. This paper provides a comprehensive review and in-depth
analysis of the Transformer-based Re-ID. In categorizing existing works into
Image/Video-Based Re-ID, Re-ID with limited data/annotations, Cross-Modal
Re-ID, and Special Re-ID Scenarios, we thoroughly elucidate the advantages
demonstrated by the Transformer in addressing a multitude of challenges across
these domains. Considering the trending unsupervised Re-ID, we propose a new
Transformer baseline, UntransReID, achieving state-of-the-art performance on
both single-/cross modal tasks. Besides, this survey also covers a wide range
of Re-ID research objects, including progress in animal Re-ID. Given the
diversity of species in animal Re-ID, we devise a standardized experimental
benchmark and conduct extensive experiments to explore the applicability of
Transformer for this task to facilitate future research. Finally, we discuss
some important yet under-investigated open issues in the big foundation model
era, we believe it will serve as a new handbook for researchers in this field.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06961" title="Abstract">arXiv:2401.06961</a> [<a href="/pdf/2401.06961" title="Download PDF">pdf</a>, <a href="/format/2401.06961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs&#x27;  Mathematical Reasoning Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yujun Mao</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yilun Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website at <a href="https://yujunmao1.github.io/CHAMP/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent large language models (LLMs) have shown indications of mathematical
reasoning ability. However it has not been clear how they would fare on more
challenging competition-level problems. And while self-generated verbalizations
of intermediate reasoning steps (i.e., chain-of-thought prompting) have been
shown to be helpful, whether LLMs can make use of helpful side information such
as problem-specific hints has not been investigated before. In this paper, we
propose a challenging benchmark dataset for enabling such analyses. The Concept
and Hint-Annotated Math Problems (CHAMP) consists of high school math
competition problems, annotated with concepts, or general math facts, and
hints, or problem-specific tricks. These annotations allow us to explore the
effects of additional information, such as relevant hints, misleading concepts,
or related problems. This benchmark is difficult, with the best model only
scoring 58.1% in standard settings. With concepts and hints, performance
sometimes improves, indicating that some models can make use of such side
information. We further annotate model-generated solutions for their
correctness. Using this corpus, we find that models often arrive at the correct
final answer through wrong reasoning steps. In addition, we test whether models
are able to verify these solutions, and find that most models struggle. The
dataset and code are available on the project website.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06969" title="Abstract">arXiv:2401.06969</a> [<a href="/pdf/2401.06969" title="Download PDF">pdf</a>, <a href="/format/2401.06969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation for Large-Vocabulary Object Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Ling Shao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Large-vocabulary object detectors (LVDs) aim to detect objects of many
categories, which learn super objectness features and can locate objects
accurately while applied to various downstream data. However, LVDs often
struggle in recognizing the located objects due to domain discrepancy in data
distribution and object vocabulary. At the other end, recent vision-language
foundation models such as CLIP demonstrate superior open-vocabulary recognition
capability. This paper presents KGD, a Knowledge Graph Distillation technique
that exploits the implicit knowledge graphs (KG) in CLIP for effectively
adapting LVDs to various downstream domains. KGD consists of two consecutive
stages: 1) KG extraction that employs CLIP to encode downstream domain data as
nodes and their feature distances as edges, constructing KG that inherits the
rich semantic relations in CLIP explicitly; and 2) KG encapsulation that
transfers the extracted KG into LVDs to enable accurate cross-domain object
classification. In addition, KGD can extract both visual and textual KG
independently, providing complementary vision and language knowledge for object
localization and object classification in detection tasks over various
downstream domains. Experiments over multiple widely adopted detection
benchmarks show that KGD outperforms the state-of-the-art consistently by large
margins.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06970" title="Abstract">arXiv:2401.06970</a> [<a href="/pdf/2401.06970" title="Download PDF">pdf</a>, <a href="/format/2401.06970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TemporalAugmenter: An Ensemble Recurrent Based Deep Learning Approach  for Signal Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+N">Nelly Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Zekios%2C+C+L">Constantinos L. Zekios</a>, 
<a href="/search/cs?searchtype=author&query=Asadizanjani%2C+N">Navid Asadizanjani</a>, 
<a href="/search/cs?searchtype=author&query=ElSayed%2C+Z">Zag ElSayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures, 9 tables, under review process
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
<p class="mathjax">Ensemble modeling has been widely used to solve complex problems as it helps
to improve overall performance and generalization. In this paper, we propose a
novel TemporalAugmenter approach based on ensemble modeling for augmenting the
temporal information capturing for long-term and short-term dependencies in
data integration of two variations of recurrent neural networks in two learning
streams to obtain the maximum possible temporal extraction. Thus, the proposed
model augments the extraction of temporal dependencies. In addition, the
proposed approach reduces the preprocessing and prior stages of feature
extraction, which reduces the required energy to process the models built upon
the proposed TemporalAugmenter approach, contributing towards green AI.
Moreover, the proposed model can be simply integrated into various domains
including industrial, medical, and human-computer interaction applications. Our
proposed approach empirically evaluated the speech emotion recognition,
electrocardiogram signal, and signal quality examination tasks as three
different signals with varying complexity and different temporal dependency
features.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06974" title="Abstract">arXiv:2401.06974</a> [<a href="/pdf/2401.06974" title="Download PDF">pdf</a>, <a href="/format/2401.06974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A metric for characterizing the arm nonuse workspace in poststroke  individuals using a robot arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dennler%2C+N">Nathaniel Dennler</a>, 
<a href="/search/cs?searchtype=author&query=Cain%2C+A">Amelia Cain</a>, 
<a href="/search/cs?searchtype=author&query=De+Guzman%2C+E">Erica De Guzman</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+C">Claudia Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Winstein%2C+C+J">Carolee J. Winstein</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M+J">Maja J. Matari&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Science Robotics at <a href="https://www.science.org/doi/10.1126/scirobotics.adf7723">this https URL</a> on November 15th, 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Science Robotics 8, eadf7723(2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">An over-reliance on the less-affected limb for functional tasks at the
expense of the paretic limb and in spite of recovered capacity is an
often-observed phenomenon in survivors of hemispheric stroke. The difference
between capacity for use and actual spontaneous use is referred to as arm
nonuse. Obtaining an ecologically valid evaluation of arm nonuse is challenging
because it requires the observation of spontaneous arm choice for different
tasks, which can easily be influenced by instructions, presumed expectations,
and awareness that one is being tested. To better quantify arm nonuse, we
developed the Bimanual Arm Reaching Test with a Robot (BARTR) for
quantitatively assessing arm nonuse in chronic stroke survivors. The BARTR is
an instrument that utilizes a robot arm as a means of remote and unbiased data
collection of nuanced spatial data for clinical evaluations of arm nonuse. This
approach shows promise for determining the efficacy of interventions designed
to reduce paretic arm nonuse and enhance functional recovery after stroke. We
show that the BARTR satisfies the criteria of an appropriate metric for
neurorehabilitative contexts: it is valid, reliable, and simple to use.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06975" title="Abstract">arXiv:2401.06975</a> [<a href="/pdf/2401.06975" title="Download PDF">pdf</a>, <a href="/format/2401.06975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class-Imbalanced Semi-Supervised Learning for Large-Scale Point Cloud  Semantic Segmentation via Decoupling Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shaohui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yunhang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lizhuang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semi-supervised learning (SSL), thanks to the significant reduction of data
annotation costs, has been an active research topic for large-scale 3D scene
understanding. However, the existing SSL-based methods suffer from severe
training bias, mainly due to class imbalance and long-tail distributions of the
point cloud data. As a result, they lead to a biased prediction for the tail
class segmentation. In this paper, we introduce a new decoupling optimization
framework, which disentangles feature representation learning and classifier in
an alternative optimization manner to shift the bias decision boundary
effectively. In particular, we first employ two-round pseudo-label generation
to select unlabeled points across head-to-tail classes. We further introduce
multi-class imbalanced focus loss to adaptively pay more attention to feature
learning across head-to-tail classes. We fix the backbone parameters after
feature learning and retrain the classifier using ground-truth points to update
its parameters. Extensive experiments demonstrate the effectiveness of our
method outperforming previous state-of-the-art methods on both indoor and
outdoor 3D point cloud datasets (i.e., S3DIS, ScanNet-V2, Semantic3D, and
SemanticKITTI) using 1% and 1pt evaluation.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06977" title="Abstract">arXiv:2401.06977</a> [<a href="/pdf/2401.06977" title="Download PDF">pdf</a>, <a href="/format/2401.06977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Singing the Body Electric: The Impact of Robot Embodiment on User  Expectations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dennler%2C+N">Nathaniel Dennler</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>, 
<a href="/search/cs?searchtype=author&query=Matari%C4%87%2C+M">Maja Matari&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the RSS Workshop on Social Intelligence in Humans and Robots, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Users develop mental models of robots to conceptualize what kind of
interactions they can have with those robots. The conceptualizations are often
formed before interactions with the robot and are based only on observing the
robot's physical design. As a result, understanding conceptualizations formed
from physical design is necessary to understand how users intend to interact
with the robot. We propose to use multimodal features of robot embodiments to
predict what kinds of expectations users will have about a given robot's social
and physical capabilities. We show that using such features provides
information about general mental models of the robots that generalize across
socially interactive robots. We describe how these models can be incorporated
into interaction design and physical design for researchers working with
socially interactive robots.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06978" title="Abstract">arXiv:2401.06978</a> [<a href="/pdf/2401.06978" title="Download PDF">pdf</a>, <a href="/format/2401.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENTED: Enhanced Neural Texture Extraction and Distribution for  Reference-based Blind Face Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lau%2C+Y">Yuen-Fui Lau</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhefan Rao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present ENTED, a new framework for blind face restoration that aims to
restore high-quality and realistic portrait images. Our method involves
repairing a single degraded input image using a high-quality reference image.
We utilize a texture extraction and distribution framework to transfer
high-quality texture features between the degraded input and reference image.
However, the StyleGAN-like architecture in our framework requires high-quality
latent codes to generate realistic images. The latent code extracted from the
degraded input image often contains corrupted features, making it difficult to
align the semantic information from the input with the high-quality textures
from the reference. To overcome this challenge, we employ two special
techniques. The first technique, inspired by vector quantization, replaces
corrupted semantic features with high-quality code words. The second technique
generates style codes that carry photorealistic texture information from a more
informative latent space developed using the high-quality features in the
reference image's manifold. Extensive experiments conducted on synthetic and
real-world datasets demonstrate that our method produces results with more
realistic contextual details and outperforms state-of-the-art methods. A
thorough ablation study confirms the effectiveness of each proposed module.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06979" title="Abstract">arXiv:2401.06979</a> [<a href="/pdf/2401.06979" title="Download PDF">pdf</a>, <a href="/ps/2401.06979" title="Download PostScript">ps</a>, <a href="/format/2401.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-aware Attention Reshaping: Enhance Generalization of Neural  Solver for Large-scale Vehicle Routing Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Ya-Hui Jia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Neng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Y">Yi Mei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural solvers based on attention mechanism have demonstrated remarkable
effectiveness in solving vehicle routing problems. However, in the
generalization process from small scale to large scale, we find a phenomenon of
the dispersion of attention scores in existing neural solvers, which leads to
poor performance. To address this issue, this paper proposes a distance-aware
attention reshaping method, assisting neural solvers in solving large-scale
vehicle routing problems. Specifically, without the need for additional
training, we utilize the Euclidean distance information between current nodes
to adjust attention scores. This enables a neural solver trained on small-scale
instances to make rational choices when solving a large-scale problem.
Experimental results show that the proposed method significantly outperforms
existing state-of-the-art neural solvers on the large-scale CVRPLib dataset.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06980" title="Abstract">arXiv:2401.06980</a> [<a href="/pdf/2401.06980" title="Download PDF">pdf</a>, <a href="/format/2401.06980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Unsupervised and Supervised Training for Automatic Speech  Recognition via Bilevel Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saif%2C+A+F+M">A F M Saif</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiaodong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Han Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Songtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Kingsbury%2C+B">Brian Kingsbury</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted in ICASSP-2024 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper, we present a novel bilevel optimization-based training
approach to training acoustic models for automatic speech recognition (ASR)
tasks that we term {bi-level joint unsupervised and supervised training
(BL-JUST)}. {BL-JUST employs a lower and upper level optimization with an
unsupervised loss and a supervised loss respectively, leveraging recent
advances in penalty-based bilevel optimization to solve this challenging ASR
problem with affordable complexity and rigorous convergence guarantees.} To
evaluate BL-JUST, extensive experiments on the LibriSpeech and TED-LIUM v2
datasets have been conducted. BL-JUST achieves superior performance over the
commonly used pre-training followed by fine-tuning strategy.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06981" title="Abstract">arXiv:2401.06981</a> [<a href="/pdf/2401.06981" title="Download PDF">pdf</a>, <a href="/ps/2401.06981" title="Download PostScript">ps</a>, <a href="/format/2401.06981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Matroid Intersection: Submodular Water-Filling and Matroidal  Welfare Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hathcock%2C+D">Daniel Hathcock</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Billy Jin</a>, 
<a href="/search/cs?searchtype=author&query=Patton%2C+K">Kalen Patton</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Sherry Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Zlatin%2C+M">Michael Zlatin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study two problems in online matroid intersection. First, we consider the
problem of maximizing the size of a common independent set between a general
matroid and a partition matroid whose parts arrive online. This captures the
classic online bipartite matching problem when both matroids are partition
matroids. Our main result is a $(1 - \frac{1}{e})$-competitive algorithm for
the fractional version of this problem. This applies even for the poly-matroid
setting, where the rank function of the offline matroid is replaced with a
general monotone submodular function. The key new ingredient for this result is
the construction of a ''water level'' vector for poly-matroids, which allows us
to generalize the classic water-filling algorithm for online bipartite
matching. This construction reveals connections to submodular utility
allocation markets and principal partition sequences of matroids.
<br />Our second result concerns the Online Submodular Welfare Maximization (OSWM)
problem, in which items arriving online are allocated among a set of agents
with the goal of maximizing their overall utility. If the utility function of
each agent is a monotone, submodular function over the set of available items,
then a simple greedy algorithm achieves a competitive ratio of $\frac{1}{2}$.
Kapralov, Post, and Vondr\'ak showed that in this case, no polynomial time
algorithm achieves a competitive ratio of $\frac{1}{2} + \varepsilon$ for any
$\varepsilon &gt; 0$ unless NP = RP (SODA, 2013). We extend the RANKING algorithm
of Karp, Vazirani, and Vazirani (STOC, 1990) to achieve an optimal
$(1-\frac{1}{e})$-competitive algorithm for OSWM in the case that the utility
function of each agent is the rank function of a matroid.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06982" title="Abstract">arXiv:2401.06982</a> [<a href="/pdf/2401.06982" title="Download PDF">pdf</a>, <a href="/format/2401.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Recommender Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jujia Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiyan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Teng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fuli Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems often grapple with noisy implicit feedback. Most studies
alleviate the noise issues from data cleaning perspective such as data
resampling and reweighting, but they are constrained by heuristic assumptions.
Another denoising avenue is from model perspective, which proactively injects
noises into user-item interactions and enhance the intrinsic denoising ability
of models. However, this kind of denoising process poses significant challenges
to the recommender model's representation capacity to capture noise patterns.
To address this issue, we propose Denoising Diffusion Recommender Model (DDRM),
which leverages multi-step denoising process based on diffusion models to
robustify user and item embeddings from any recommender models. DDRM injects
controlled Gaussian noises in the forward process and iteratively removes
noises in the reverse denoising process, thereby improving embedding robustness
against noisy feedback. To achieve this target, the key lies in offering
appropriate guidance to steer the reverse denoising process and providing a
proper starting point to start the forward-reverse process during inference. In
particular, we propose a dedicated denoising module that encodes collaborative
information as denoising guidance. Besides, in the inference stage, DDRM
utilizes the average embeddings of users' historically liked items as the
starting point rather than using pure noise since pure noise lacks
personalization, which increases the difficulty of the denoising process.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06986" title="Abstract">arXiv:2401.06986</a> [<a href="/pdf/2401.06986" title="Download PDF">pdf</a>, <a href="/format/2401.06986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning driving style embedding from GPS-derived moving patterns for  driver identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lin Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Learning fingerprint-like driving style representations is crucial to
accurately identify who is behind the wheel in open driving situations. This
study explores the learning of driving styles with GPS signals that are
currently available in connected vehicles for short-term driver identification.
First, an input driving trajectory is windowed into subtrajectories with fixed
time lengths. Then, each subtrajectory is further divided into overlapping
dynamic segments. For each segment, the local features are obtained by
combining statistical and state transitional patterns. Finally, the driving
style embedded in each subtrajectory is learned with the proposed regularized
recurrent neural network (RNN) for short-term driver identification. We
evaluate the impacts of key factors and the effectiveness of the proposed
approach on the identification performance of 5 and 10 drivers. The results
show that our proposed neural network structure, which complements movement
statistics (MS) with state transitions (ST), provides better prediction
performance than existing deep learning methods.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06989" title="Abstract">arXiv:2401.06989</a> [<a href="/pdf/2401.06989" title="Download PDF">pdf</a>, <a href="/format/2401.06989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Coreset for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivasubramanian%2C+D">Durga Sivasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Nagalapatti%2C+L">Lokesh Nagalapatti</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+R">Rishabh Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Ramakrishnan%2C+G">Ganesh Ramakrishnan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Federated Learning (FL) is used to learn machine learning models with data
that is partitioned across multiple clients, including resource-constrained
edge devices. It is therefore important to devise solutions that are efficient
in terms of compute, communication, and energy consumption, while ensuring
compliance with the FL framework's privacy requirements. Conventional
approaches to these problems select a weighted subset of the training dataset,
known as coreset, and learn by fitting models on it. Such coreset selection
approaches are also known to be robust to data noise. However, these approaches
rely on the overall statistics of the training data and are not easily
extendable to the FL setup.
<br />In this paper, we propose an algorithm called Gradient based Coreset for
Robust and Efficient Federated Learning (GCFL) that selects a coreset at each
client, only every $K$ communication rounds and derives updates only from it,
assuming the availability of a small validation dataset at the server. We
demonstrate that our coreset selection technique is highly effective in
accounting for noise in clients' data. We conduct experiments using four
real-world datasets and show that GCFL is (1) more compute and energy efficient
than FL, (2) robust to various kinds of noise in both the feature space and
labels, (3) preserves the privacy of the validation dataset, and (4) introduces
a small communication overhead but achieves significant gains in performance,
particularly in cases when the clients' data is noisy.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06992" title="Abstract">arXiv:2401.06992</a> [<a href="/pdf/2401.06992" title="Download PDF">pdf</a>, <a href="/format/2401.06992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Feature Fusion Network for Enhancing Image Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaiqun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoling Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yonggang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+P">Peng Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Data Compression Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image compression has been applied in the fields of image storage and video
broadcasting. However, it's formidably tough to distinguish the subtle quality
differences between those distorted images generated by different algorithms.
In this paper, we propose a new image quality assessment framework to decide
which image is better in an image group. To capture the subtle differences, a
fine-grained network is adopted to acquire multi-scale features. Subsequently,
we design a cross subtract block for separating and gathering the information
within positive and negative image pairs. Enabling image comparison in feature
space. After that, a progressive feature fusion block is designed, which fuses
multi-scale features in a novel progressive way. Hierarchical spatial 2D
features can thus be processed gradually. Experimental results show that
compared with the current mainstream image quality assessment methods, the
proposed network can achieve more accurate image quality assessment and ranks
second in the benchmark of CLIC in the image perceptual model track.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06994" title="Abstract">arXiv:2401.06994</a> [<a href="/pdf/2401.06994" title="Download PDF">pdf</a>, <a href="/format/2401.06994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniVision: A Unified Framework for Vision-Centric 3D Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yu Hong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Huayuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+D">Danjiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guangzhi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yong Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The past few years have witnessed the rapid development of vision-centric 3D
perception in autonomous driving. Although the 3D perception models share many
structural and conceptual similarities, there still exist gaps in their feature
representations, data formats, and objectives, posing challenges for unified
and efficient 3D perception framework design. In this paper, we present
UniVision, a simple and efficient framework that unifies two major tasks in
vision-centric 3D perception, \ie, occupancy prediction and object detection.
Specifically, we propose an explicit-implicit view transform module for
complementary 2D-3D feature transformation. We propose a local-global feature
extraction and fusion module for efficient and adaptive voxel and BEV feature
extraction, enhancement, and interaction. Further, we propose a joint
occupancy-detection data augmentation strategy and a progressive loss weight
adjustment strategy which enables the efficiency and stability of the
multi-task framework training. We conduct extensive experiments for different
perception tasks on four public benchmarks, including nuScenes LiDAR
segmentation, nuScenes detection, OpenOccupancy, and Occ3D. UniVision achieves
state-of-the-art results with +1.5 mIoU, +1.8 NDS, +1.5 mIoU, and +1.8 mIoU
gains on each benchmark, respectively. We believe that the UniVision framework
can serve as a high-performance baseline for the unified vision-centric 3D
perception task. The code will be available at
\url{https://github.com/Cc-Hy/UniVision}.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06995" title="Abstract">arXiv:2401.06995</a> [<a href="/pdf/2401.06995" title="Download PDF">pdf</a>, <a href="/ps/2401.06995" title="Download PostScript">ps</a>, <a href="/format/2401.06995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Visually Attentive Splice Localization Network with Multi-Domain  Feature Extractor and Multi-Receptive Field Upsampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Ankit Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+D+K">Dinesh Kumar Vishwakarma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image splice manipulation presents a severe challenge in today's society.
With easy access to image manipulation tools, it is easier than ever to modify
images that can mislead individuals, organizations or society. In this work, a
novel, "Visually Attentive Splice Localization Network with Multi-Domain
Feature Extractor and Multi-Receptive Field Upsampler" has been proposed. It
contains a unique "visually attentive multi-domain feature extractor" (VA-MDFE)
that extracts attentional features from the RGB, edge and depth domains. Next,
a "visually attentive downsampler" (VA-DS) is responsible for fusing and
downsampling the multi-domain features. Finally, a novel "visually attentive
multi-receptive field upsampler" (VA-MRFU) module employs multiple receptive
field-based convolutions to upsample attentional features by focussing on
different information scales. Experimental results conducted on the public
benchmark dataset CASIA v2.0 prove the potency of the proposed model. It
comfortably beats the existing state-of-the-arts by achieving an IoU score of
0.851, pixel F1 score of 0.9195 and pixel AUC score of 0.8989.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06998" title="Abstract">arXiv:2401.06998</a> [<a href="/pdf/2401.06998" title="Download PDF">pdf</a>, <a href="/ps/2401.06998" title="Download PostScript">ps</a>, <a href="/format/2401.06998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Effective Image Forensics via A Novel Computationally Efficient  Framework and A New Image Splice Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Ankit Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+D+K">Dinesh Kumar Vishwakarma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Splice detection models are the need of the hour since splice manipulations
can be used to mislead, spread rumors and create disharmony in society.
However, there is a severe lack of image splicing datasets, which restricts the
capabilities of deep learning models to extract discriminative features without
overfitting. This manuscript presents two-fold contributions toward splice
detection. Firstly, a novel splice detection dataset is proposed having two
variants. The two variants include spliced samples generated from code and
through manual editing. Spliced images in both variants have corresponding
binary masks to aid localization approaches. Secondly, a novel
Spatio-Compression Lightweight Splice Detection Framework is proposed for
accurate splice detection with minimum computational cost. The proposed
dual-branch framework extracts discriminative spatial features from a
lightweight spatial branch. It uses original resolution compression data to
extract double compression artifacts from the second branch, thereby making it
'information preserving.' Several CNNs are tested in combination with the
proposed framework on a composite dataset of images from the proposed dataset
and the CASIA v2.0 dataset. The best model accuracy of 0.9382 is achieved and
compared with similar state-of-the-art methods, demonstrating the superiority
of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06999" title="Abstract">arXiv:2401.06999</a> [<a href="/pdf/2401.06999" title="Download PDF">pdf</a>, <a href="/ps/2401.06999" title="Download PostScript">ps</a>, <a href="/format/2401.06999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Datasets, Clues and State-of-the-Arts for Multimedia Forensics: An  Extensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+A">Ankit Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+D+K">Dinesh Kumar Vishwakarma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the large chunks of social media data being created daily and the
parallel rise of realistic multimedia tampering methods, detecting and
localising tampering in images and videos has become essential. This survey
focusses on approaches for tampering detection in multimedia data using deep
learning models. Specifically, it presents a detailed analysis of benchmark
datasets for malicious manipulation detection that are publicly available. It
also offers a comprehensive list of tampering clues and commonly used deep
learning architectures. Next, it discusses the current state-of-the-art
tampering detection methods, categorizing them into meaningful types such as
deepfake detection methods, splice tampering detection methods, copy-move
tampering detection methods, etc. and discussing their strengths and
weaknesses. Top results achieved on benchmark datasets, comparison of deep
learning approaches against traditional methods and critical insights from the
recent tampering detection methods are also discussed. Lastly, the research
gaps, future direction and conclusion are discussed to provide an in-depth
understanding of the tampering detection research arena.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07001" title="Abstract">arXiv:2401.07001</a> [<a href="/pdf/2401.07001" title="Download PDF">pdf</a>, <a href="/format/2401.07001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV-assisted Emergency Integrated Sensing and Communication Networks: A  CNN-based Rapid Deployment Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lianming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Luyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruoguang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">UAV-assisted integrated sensing and communication (ISAC) network is crucial
for post-disaster emergency rescue. The speed of UAV deployment will directly
impact rescue results. However, the ISAC UAV deployment in emergency scenarios
is difficult to solve, which contradicts the rapid deployment. In this paper,
we propose a two-stage deployment framework to achieve rapid ISAC UAV
deployment in emergency scenarios, which consists of an offline stage and an
online stage. Specifically, in the offline stage, we first formulate the ISAC
UAV deployment problem and define the ISAC utility as the objective function,
which integrates communication rate and localization accuracy. Secondly, we
develop a dynamic particle swarm optimization (DPSO) algorithm to construct an
optimized UAV deployment dataset. Finally, we train a convolutional neural
network (CNN) model with this dataset, which replaces the time-consuming DPSO
algorithm. In the online stage, the trained CNN model can be used to make quick
decisions for the ISAC UAV deployment. The simulation results indicate that the
trained CNN model achieves superior ISAC performance compared to the classic
particle swarm optimization algorithm. Additionally, it significantly reduces
the deployment time by more than 96%.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07003" title="Abstract">arXiv:2401.07003</a> [<a href="/pdf/2401.07003" title="Download PDF">pdf</a>, <a href="/format/2401.07003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Solutions for Oscillatory Fredholm Integral  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+J">Jie Jiang</a>, 
<a href="/search/math?searchtype=author&query=Xu%2C+Y">Yuesheng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We studied the use of deep neural networks (DNNs) in the numerical solution
of the oscillatory Fredholm integral equation of the second kind. It is known
that the solution of the equation exhibits certain oscillatory behaviors due to
the oscillation of the kernel. It was pointed out recently that standard DNNs
favour low frequency functions, and as a result, they often produce poor
approximation for functions containing high frequency components. We addressed
this issue in this study. We first developed a numerical method for solving the
equation with DNNs as an approximate solution by designing a numerical
quadrature that tailors to computing oscillatory integrals involving DNNs. We
proved that the error of the DNN approximate solution of the equation is
bounded by the training loss and the quadrature error. We then proposed a
multi-grade deep learning (MGDL) model to overcome the spectral bias issue of
neural networks. Numerical experiments demonstrate that the MGDL model is
effective in extracting multiscale information of the oscillatory solution and
overcoming the spectral bias issue from which a standard DNN model suffers.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07004" title="Abstract">arXiv:2401.07004</a> [<a href="/pdf/2401.07004" title="Download PDF">pdf</a>, <a href="/format/2401.07004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending LLMs&#x27; Context Window with 100 Samples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are known to have limited extrapolation ability
beyond their pre-trained context window, constraining their application in
downstream tasks with lengthy inputs. Recent studies have sought to extend
LLMs' context window by modifying rotary position embedding (RoPE), a popular
position encoding method adopted by well-known LLMs such as LLaMA, PaLM, and
GPT-NeoX. However, prior works like Position Interpolation (PI) and YaRN are
resource-intensive and lack comparative experiments to assess their
applicability. In this work, we identify the inherent need for LLMs' attention
entropy (i.e. the information entropy of attention scores) to maintain
stability and introduce a novel extension to RoPE which combines adjusting
RoPE's base frequency and scaling the attention logits to help LLMs efficiently
adapt to a larger context window. We validate the superiority of our method in
both fine-tuning performance and robustness across different context window
sizes on various context-demanding tasks. Notably, our method extends the
context window of LLaMA-2-7B-Chat to 16,384 with only 100 samples and 6
training steps, showcasing extraordinary efficiency. Finally, we also explore
how data compositions and training curricula affect context window extension
for specific downstream tasks, suggesting fine-tuning LLMs with lengthy
conversations as a good starting point. We release our code and SFT data at
https://github.com/GAIR-NLP/Entropy-ABF.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07009" title="Abstract">arXiv:2401.07009</a> [<a href="/pdf/2401.07009" title="Download PDF">pdf</a>, <a href="/format/2401.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Extraction of Uyghur Medicine Knowledge with Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Quan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huaibin Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages,6 figures,Has been accepted by Tsinghua Science and Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Medical knowledge extraction methods based on edge computing deploy deep
learning models on edge devices to achieve localized entity and relation
extraction. This approach avoids transferring substantial sensitive data to
cloud data centers, effectively safeguarding the privacy of healthcare
services. However, existing relation extraction methods mainly employ a
sequential pipeline approach, which classifies relations between determined
entities after entity recognition. This mode faces challenges such as error
propagation between tasks, insufficient consideration of dependencies between
the two subtasks, and the neglect of interrelations between different relations
within a sentence. To address these challenges, a joint extraction model with
parameter sharing in edge computing is proposed, named CoEx-Bert. This model
leverages shared parameterization between two models to jointly extract
entities and relations. Specifically, CoEx-Bert employs two models, each
separately sharing hidden layer parameters, and combines these two loss
functions for joint backpropagation to optimize the model parameters.
Additionally, it effectively resolves the issue of entity overlapping when
extracting knowledge from unstructured Uyghur medical texts by considering
contextual relations. Finally, this model is deployed on edge devices for
real-time extraction and inference of Uyghur medical knowledge. Experimental
results demonstrate that CoEx-Bert outperforms existing state-of-the-art
methods, achieving accuracy, recall, and F1 scores of 90.65\%, 92.45\%, and
91.54\%, respectively, in the Uyghur traditional medical literature dataset.
These improvements represent a 6.45\% increase in accuracy, a 9.45\% increase
in recall, and a 7.95\% increase in F1 score compared to the baseline.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07012" title="Abstract">arXiv:2401.07012</a> [<a href="/pdf/2401.07012" title="Download PDF">pdf</a>, <a href="/ps/2401.07012" title="Download PostScript">ps</a>, <a href="/format/2401.07012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An ADRC-Incorporated Stochastic Gradient Descent Algorithm for Latent  Factor Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinli Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">High-dimensional and incomplete (HDI) matrix contains many complex
interactions between numerous nodes. A stochastic gradient descent (SGD)-based
latent factor analysis (LFA) model is remarkably effective in extracting
valuable information from an HDI matrix. However, such a model commonly
encounters the problem of slow convergence because a standard SGD algorithm
only considers the current learning error to compute the stochastic gradient
without considering the historical and future state of the learning error. To
address this critical issue, this paper innovatively proposes an
ADRC-incorporated SGD (ADS) algorithm by refining the instance learning error
by considering the historical and future state by following the principle of an
ADRC controller. With it, an ADS-based LFA model is further achieved for fast
and accurate latent factor analysis on an HDI matrix. Empirical studies on two
HDI datasets demonstrate that the proposed model outperforms the
state-of-the-art LFA models in terms of computational efficiency and accuracy
for predicting the missing data of an HDI matrix.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07013" title="Abstract">arXiv:2401.07013</a> [<a href="/pdf/2401.07013" title="Download PDF">pdf</a>, <a href="/format/2401.07013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation for Closed-Source Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hehong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Closed-source language models such as GPT-4 have achieved remarkable
performance. Many recent studies focus on enhancing the capabilities of smaller
models through knowledge distillation from closed-source language models.
However, due to the incapability to directly access the weights, hidden states,
and output distributions of these closed-source models, the distillation can
only be performed by fine-tuning smaller models with data samples generated by
closed-source language models, which constrains the effectiveness of knowledge
distillation. In this paper, we propose to estimate the output distributions of
closed-source language models within a Bayesian estimation framework, involving
both prior and posterior estimation. The prior estimation aims to derive a
prior distribution by utilizing the corpus generated by closed-source language
models, while the posterior estimation employs a proxy model to update the
prior distribution and derive a posterior distribution. By leveraging the
estimated output distribution of closed-source language models, traditional
knowledge distillation can be executed. Experimental results demonstrate that
our method surpasses the performance of current models directly fine-tuned on
data generated by closed-source language models.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07014" title="Abstract">arXiv:2401.07014</a> [<a href="/pdf/2401.07014" title="Download PDF">pdf</a>, <a href="/format/2401.07014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak Labeling for Cropland Mapping in Africa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hacheme%2C+G+Q">Gilles Quentin Hacheme</a>, 
<a href="/search/cs?searchtype=author&query=Zaytar%2C+A">Akram Zaytar</a>, 
<a href="/search/cs?searchtype=author&query=Tadesse%2C+G+A">Girmaw Abebe Tadesse</a>, 
<a href="/search/cs?searchtype=author&query=Robinson%2C+C">Caleb Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Dodhia%2C+R">Rahul Dodhia</a>, 
<a href="/search/cs?searchtype=author&query=Ferres%2C+J+M+L">Juan M. Lavista Ferres</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+S">Stephen Wood</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cropland mapping can play a vital role in addressing environmental,
agricultural, and food security challenges. However, in the context of Africa,
practical applications are often hindered by the limited availability of
high-resolution cropland maps. Such maps typically require extensive human
labeling, thereby creating a scalability bottleneck. To address this, we
propose an approach that utilizes unsupervised object clustering to refine
existing weak labels, such as those obtained from global cropland maps. The
refined labels, in conjunction with sparse human annotations, serve as training
data for a semantic segmentation network designed to identify cropland areas.
We conduct experiments to demonstrate the benefits of the improved weak labels
generated by our method. In a scenario where we train our model with only 33
human-annotated labels, the F_1 score for the cropland category increases from
0.53 to 0.84 when we add the mined negative labels.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07017" title="Abstract">arXiv:2401.07017</a> [<a href="/pdf/2401.07017" title="Download PDF">pdf</a>, <a href="/ps/2401.07017" title="Download PostScript">ps</a>, <a href="/format/2401.07017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic performance of double and four circulant codes with small  hull dimension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aliabadi%2C+Z">Zohreh Aliabadi</a>, 
<a href="/search/cs?searchtype=author&query=Kalayc%C4%B1%2C+T">Tekg&#xfc;l Kalayc&#x131;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">We study the asymptotic behavior of double and four circulant codes, which
are quasi-cyclic codes of index two and four respectively. Exact enumeration
results are derived for these families of codes with the prescribed hull
dimension. These formulas, in turn, are the most used tools to prove the good
behavior of double circulant and four circulant codes asymptotically.
Computational results on the code families in consideration are provided as
well.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07022" title="Abstract">arXiv:2401.07022</a> [<a href="/pdf/2401.07022" title="Download PDF">pdf</a>, <a href="/format/2401.07022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-Enabled Anomaly Detection and Information Completion for Social  Network Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+F">Fan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Quan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huaibin Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, Has been accepted by Wireless Network
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">In the rapidly advancing information era, various human behaviors are being
precisely recorded in the form of data, including identity information,
criminal records, and communication data. Law enforcement agencies can
effectively maintain social security and precisely combat criminal activities
by analyzing the aforementioned data. In comparison to traditional data
analysis methods, deep learning models, relying on the robust computational
power in cloud centers, exhibit higher accuracy in extracting data features and
inferring data. However, within the architecture of cloud centers, the
transmission of data from end devices introduces significant latency, hindering
real-time inference of data. Furthermore, low-latency edge computing
architectures face limitations in direct deployment due to relatively weak
computing and storage capacities of nodes. To address these challenges, a
lightweight distributed knowledge graph completion architecture is proposed.
Firstly, we introduce a lightweight distributed knowledge graph completion
architecture that utilizes knowledge graph embedding for data analysis.
Subsequently, to filter out substandard data, a personnel data quality
assessment method named PDQA is proposed. Lastly, we present a model pruning
algorithm that significantly reduces the model size while maximizing
performance, enabling lightweight deployment. In experiments, we compare the
effects of 11 advanced models on completing the knowledge graph of public
security personnel information. The results indicate that the RotatE model
outperforms other models significantly in knowledge graph completion, with the
pruned model size reduced by 70\%, and hits@10 reaching 86.97\%.}
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07028" title="Abstract">arXiv:2401.07028</a> [<a href="/pdf/2401.07028" title="Download PDF">pdf</a>, <a href="/format/2401.07028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image edge enhancement for effective image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bu%2C+T">Tianhao Bu</a>, 
<a href="/search/cs?searchtype=author&query=Lazarou%2C+M">Michalis Lazarou</a>, 
<a href="/search/cs?searchtype=author&query=Stathaki%2C+T">Tania Stathaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at VISIGRAPP: VISAPP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image classification has been a popular task due to its feasibility in
real-world applications. Training neural networks by feeding them RGB images
has demonstrated success over it. Nevertheless, improving the classification
accuracy and computational efficiency of this process continues to present
challenges that researchers are actively addressing. A widely popular embraced
method to improve the classification performance of neural networks is to
incorporate data augmentations during the training process. Data augmentations
are simple transformations that create slightly modified versions of the
training data and can be very effective in training neural networks to mitigate
overfitting and improve their accuracy performance. In this study, we draw
inspiration from high-boost image filtering and propose an edge
enhancement-based method as means to enhance both accuracy and training speed
of neural networks. Specifically, our approach involves extracting high
frequency features, such as edges, from images within the available dataset and
fusing them with the original images, to generate new, enriched images. Our
comprehensive experiments, conducted on two distinct datasets CIFAR10 and
CALTECH101, and three different network architectures ResNet-18, LeNet-5 and
CNN-9 demonstrates the effectiveness of our proposed method.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07031" title="Abstract">arXiv:2401.07031</a> [<a href="/pdf/2401.07031" title="Download PDF">pdf</a>, <a href="/format/2401.07031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Security Vulnerability Repair Using Reinforcement Learning with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+N+T">Nafis Tanveer Islam</a>, 
<a href="/search/cs?searchtype=author&query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">With the recent advancement of Large Language Models (LLMs), generating
functionally correct code has become less complicated for a wide array of
developers. While using LLMs has sped up the functional development process, it
poses a heavy risk to code security. Code generation with proper security
measures using LLM is a significantly more challenging task than functional
code generation. Security measures may include adding a pair of lines of code
with the original code, consisting of null pointer checking or prepared
statements for SQL injection prevention. Currently, available code repair LLMs
generate code repair by supervised fine-tuning, where the model looks at
cross-entropy loss. However, the original and repaired codes are mostly similar
in functionality and syntactically, except for a few (1-2) lines, which act as
security measures. This imbalance between the lines needed for security
measures and the functional code enforces the supervised fine-tuned model to
prioritize generating functional code without adding proper security measures,
which also benefits the model by resulting in minimal loss. Therefore, in this
work, for security hardening and strengthening of generated code from LLMs, we
propose a reinforcement learning-based method for program-specific repair with
the combination of semantic and syntactic reward mechanisms that focus heavily
on adding security and functional measures in the code, respectively.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07033" title="Abstract">arXiv:2401.07033</a> [<a href="/pdf/2401.07033" title="Download PDF">pdf</a>, <a href="/format/2401.07033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk-aware Adaptive Virtual CPU Oversubscription in Microsoft Cloud via  Prototypical Human-in-the-loop Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mayukh Das</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fangkai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Junjie Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BChle%2C+V">Victor R&#xfc;hle</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+C">Chetan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Cortez%2C+E">Eli Cortez</a>, 
<a href="/search/cs?searchtype=author&query=Goiri%2C+%C3%8D">&#xcd;&#xf1;igo Goiri</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Oversubscription is a prevalent practice in cloud services where the system
offers more virtual resources, such as virtual cores in virtual machines, to
users or applications than its available physical capacity for reducing revenue
loss due to unused/redundant capacity. While oversubscription can potentially
lead to significant enhancement in efficient resource utilization, the caveat
is that it comes with the risks of overloading and introducing jitter at the
level of physical nodes if all the co-located virtual machines have high
utilization. Thus suitable oversubscription policies which maximize utilization
while mitigating risks are paramount for cost-effective seamless cloud
experiences. Most cloud platforms presently rely on static heuristics-driven
decisions about oversubscription activation and limits, which either leads to
overloading or stranded resources. Designing an intelligent oversubscription
policy that can adapt to resource utilization patterns and jointly optimizes
benefits and risks is, largely, an unsolved problem. We address this challenge
with our proposed novel HuMan-in-the-loop Protoypical Imitation Learning
(ProtoHAIL) framework that exploits approximate symmetries in utilization
patterns to learn suitable policies. Also, our human-in-the-loop
(knowledge-infused) training allows for learning safer policies that are robust
to noise and sparsity. Our empirical investigations on real data show orders of
magnitude reduction in risk and significant increase in benefits (saving
stranded cores) in Microsoft cloud platform for 1st party (internal services).
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07035" title="Abstract">arXiv:2401.07035</a> [<a href="/pdf/2401.07035" title="Download PDF">pdf</a>, <a href="/format/2401.07035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causative Insights into Open Source Software Security using Large  Language Code Embeddings and Semantic Vulnerability Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+N+T">Nafis Tanveer Islam</a>, 
<a href="/search/cs?searchtype=author&query=De+La+Torre+Parra%2C+G">Gonzalo De La Torre Parra</a>, 
<a href="/search/cs?searchtype=author&query=Manual%2C+D">Dylan Manual</a>, 
<a href="/search/cs?searchtype=author&query=Jadliwala%2C+M">Murtuza Jadliwala</a>, 
<a href="/search/cs?searchtype=author&query=Najafirad%2C+P">Peyman Najafirad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Open Source Software (OSS) security and resilience are worldwide phenomena
hampering economic and technological innovation. OSS vulnerabilities can cause
unauthorized access, data breaches, network disruptions, and privacy
violations, rendering any benefits worthless. While recent deep-learning
techniques have shown great promise in identifying and localizing
vulnerabilities in source code, it is unclear how effective these research
techniques are from a usability perspective due to a lack of proper
methodological analysis. Usually, these methods offload a developer's task of
classifying and localizing vulnerable code; still, a reasonable study to
measure the actual effectiveness of these systems to the end user has yet to be
conducted. To address the challenge of proper developer training from the prior
methods, we propose a system to link vulnerabilities to their root cause,
thereby intuitively educating the developers to code more securely.
Furthermore, we provide a comprehensive usability study to test the
effectiveness of our system in fixing vulnerabilities and its capability to
assist developers in writing more secure code. We demonstrate the effectiveness
of our system by showing its efficacy in helping developers fix source code
with vulnerabilities. Our study shows a 24% improvement in code repair
capabilities compared to previous methods. We also show that, when trained by
our system, on average, approximately 9% of the developers naturally tend to
write more secure code with fewer vulnerabilities.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07037" title="Abstract">arXiv:2401.07037</a> [<a href="/pdf/2401.07037" title="Download PDF">pdf</a>, <a href="/format/2401.07037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xCoT: Cross-lingual Instruction Tuning for Cross-lingual  Chain-of-Thought Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chai%2C+L">Linzheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiannian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaqi Bai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qiyao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Chain-of-thought (CoT) has emerged as a powerful technique to elicit
reasoning in large language models and improve a variety of downstream tasks.
CoT mainly demonstrates excellent performance in English, but its usage in
low-resource languages is constrained due to poor language generalization. To
bridge the gap among different languages, we propose a cross-lingual
instruction fine-tuning framework (xCOT) to transfer knowledge from
high-resource languages to low-resource languages. Specifically, the
multilingual instruction training data (xCOT-INSTRUCT) is created to encourage
the semantic alignment of multiple languages. We introduce cross-lingual
in-context few-shot learning (xICL)) to accelerate multilingual agreement in
instruction tuning, where some fragments of source languages in examples are
randomly substituted by their counterpart translations of target languages.
During multilingual instruction tuning, we adopt the randomly online CoT
strategy to enhance the multilingual reasoning ability of the large language
model by first translating the query to another language and then answering in
English. To further facilitate the language transfer, we leverage the
high-resource CoT to supervise the training of low-resource languages with
cross-lingual distillation. Experimental results on previous benchmarks
demonstrate the superior performance of xCoT in reducing the gap among
different languages, highlighting its potential to reduce the cross-lingual
gap.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07042" title="Abstract">arXiv:2401.07042</a> [<a href="/pdf/2401.07042" title="Download PDF">pdf</a>, <a href="/ps/2401.07042" title="Download PostScript">ps</a>, <a href="/format/2401.07042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GEML: A Grammar-based Evolutionary Machine Learning Approach for  Design-Pattern Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbudo%2C+R">Rafael Barbudo</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+A">Aurora Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Servant%2C+F">Francisco Servant</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+R">Jos&#xe9; Ra&#xfa;l Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 18 tables, 10 figures, journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Systems and Software, Volume 175, May 2021, 110919
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Design patterns (DPs) are recognised as a good practice in software
development. However, the lack of appropriate documentation often hampers
traceability, and their benefits are blurred among thousands of lines of code.
Automatic methods for DP detection have become relevant but are usually based
on the rigid analysis of either software metrics or specific properties of the
source code. We propose GEML, a novel detection approach based on evolutionary
machine learning using software properties of diverse nature. Firstly, GEML
makes use of an evolutionary algorithm to extract those characteristics that
better describe the DP, formulated in terms of human-readable rules, whose
syntax is conformant with a context-free grammar. Secondly, a rule-based
classifier is built to predict whether new code contains a hidden DP
implementation. GEML has been validated over five DPs taken from a public
repository recurrently adopted by machine learning studies. Then, we increase
this number up to 15 diverse DPs, showing its effectiveness and robustness in
terms of detection capability. An initial parameter study served to tune a
parameter setup whose performance guarantees the general applicability of this
approach without the need to adjust complex parameters to a specific pattern.
Finally, a demonstration tool is also provided.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07044" title="Abstract">arXiv:2401.07044</a> [<a href="/pdf/2401.07044" title="Download PDF">pdf</a>, <a href="/format/2401.07044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BP(&#x3bb;): Online Learning via Synthetic Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pemberton%2C+J">Joseph Pemberton</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+R+P">Rui Ponte Costa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Training recurrent neural networks typically relies on backpropagation
through time (BPTT). BPTT depends on forward and backward passes to be
completed, rendering the network locked to these computations before loss
gradients are available. Recently, Jaderberg et al. proposed synthetic
gradients to alleviate the need for full BPTT. In their implementation
synthetic gradients are learned through a mixture of backpropagated gradients
and bootstrapped synthetic gradients, analogous to the temporal difference (TD)
algorithm in Reinforcement Learning (RL). However, as in TD learning, heavy use
of bootstrapping can result in bias which leads to poor synthetic gradient
estimates. Inspired by the accumulate $\mathrm{TD}(\lambda)$ in RL, we propose
a fully online method for learning synthetic gradients which avoids the use of
BPTT altogether: accumulate $BP(\lambda)$. As in accumulate
$\mathrm{TD}(\lambda)$, we show analytically that accumulate
$\mathrm{BP}(\lambda)$ can control the level of bias by using a mixture of
temporal difference errors and recursively defined eligibility traces. We next
demonstrate empirically that our model outperforms the original implementation
for learning synthetic gradients in a variety of tasks, and is particularly
suited for capturing longer timescales. Finally, building on recent work we
reflect on accumulate $\mathrm{BP}(\lambda)$ as a principle for learning in
biological circuits. In summary, inspired by RL principles we introduce an
algorithm capable of bias-free online learning via synthetic gradients.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07051" title="Abstract">arXiv:2401.07051</a> [<a href="/pdf/2401.07051" title="Download PDF">pdf</a>, <a href="/format/2401.07051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COIN: Chance-Constrained Imitation Learning for Uncertainty-aware  Adaptive Resource Oversubscription Policy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+M">Mayukh Das</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fangkai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Duo%2C+C">Chao Duo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+B">Bo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Si Qin</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+C">Chetan Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qingwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rajmohan%2C+S">Saravan Rajmohan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We address the challenge of learning safe and robust decision policies in
presence of uncertainty in context of the real scientific problem of adaptive
resource oversubscription to enhance resource efficiency while ensuring safety
against resource congestion risk.
<br />Traditional supervised prediction or forecasting models are ineffective in
learning adaptive policies whereas standard online optimization or
reinforcement learning is difficult to deploy on real systems. Offline methods
such as imitation learning (IL) are ideal since we can directly leverage
historical resource usage telemetry. But, the underlying aleatoric uncertainty
in such telemetry is a critical bottleneck.
<br />We solve this with our proposed novel chance-constrained imitation learning
framework, which ensures implicit safety against uncertainty in a principled
manner via a combination of stochastic (chance) constraints on resource
congestion risk and ensemble value functions. This leads to substantial
($\approx 3-4\times$) improvement in resource efficiency and safety in many
oversubscription scenarios, including resource management in cloud services.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07052" title="Abstract">arXiv:2401.07052</a> [<a href="/pdf/2401.07052" title="Download PDF">pdf</a>, <a href="/format/2401.07052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling citation concentration through a mixture of Leimkuhler curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-D%C3%A9niz%2C+E">Emilio G&#xf3;mez-D&#xe9;niz</a>, 
<a href="/search/cs?searchtype=author&query=Dorta-Gonz%C3%A1lez%2C+P">Pablo Dorta-Gonz&#xe1;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 2 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Applications (stat.AP)

</div>
<p class="mathjax">When a graphical representation of the cumulative percentage of total
citations to articles, ordered from most cited to least cited, is plotted
against the cumulative percentage of articles, we obtain a Leimkuhler curve. In
this study, we noticed that standard Leimkuhler functions may not be sufficient
to provide accurate fits to various empirical informetrics data. Therefore, we
introduce a new approach to Leimkuhler curves by fitting a known probability
density function to the initial Leimkuhler curve, taking into account the
presence of a heterogeneity factor. As a significant contribution to the
existing literature, we introduce a pair of mixture distributions (called PG
and PIG) to bibliometrics. In addition, we present closed-form expressions for
Leimkuhler curves. {Some measures of citation concentration are examined
empirically for the basic models (based on the Power {and Pareto
distributions}) and the mixed models derived from {these}.} An application to
two sources of informetric data was conducted to see how the mixing models
outperform the standard basic models. The different models were fitted using
non-linear least squares estimation.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07053" title="Abstract">arXiv:2401.07053</a> [<a href="/pdf/2401.07053" title="Download PDF">pdf</a>, <a href="/format/2401.07053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptoring: Adapter Generation to Provide an Alternative API for a  Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reimann%2C+L">Lars Reimann</a>, 
<a href="/search/cs?searchtype=author&query=Kniesel-W%C3%BCnsche%2C+G">G&#xfc;nter Kniesel-W&#xfc;nsche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the International Conference on Software Analysis, Evolution and Reengineering (SANER 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Third-party libraries are a cornerstone of fast application development. To
enable efficient use, libraries must provide a well-designed API. An obscure
API instead slows down the learning process and can lead to erroneous use.
<br />The usual approach to improve the API of a library is to edit its code
directly, either keeping the old API but deprecating it (temporarily increasing
the API size) or dropping it (introducing breaking changes). If maintainers are
unwilling to make such changes, others need to create a hard fork, which they
can refactor. But then it is difficult to incorporate changes to the original
library, such as bug fixes or performance improvements.
<br />In this paper, we instead explore the use of the adapter pattern to provide a
new API as a new library that calls the original library internally. This
allows the new library to leverage all implementation changes to the original
library, at no additional cost. We call this approach adaptoring. To make the
approach practical, we identify API transformations for which adapter code can
be generated automatically, and investigate which transformations can be
inferred automatically, based on the documentation and usage patterns of the
original library. For cases where automated inference is not possible, we
present a tool that lets developers manually specify API transformations.
Finally, we consider the issue of migrating the generated adapters if the
original library introduces breaking changes. We implemented our approach for
Python, demonstrating its effectiveness to quickly provide an alternative API
even for large libraries.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07055" title="Abstract">arXiv:2401.07055</a> [<a href="/pdf/2401.07055" title="Download PDF">pdf</a>, <a href="/format/2401.07055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagrammatic Algebra of First Order Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonchi%2C+F">Filippo Bonchi</a>, 
<a href="/search/cs?searchtype=author&query=Di+Giorgio%2C+A">Alessandro Di Giorgio</a>, 
<a href="/search/cs?searchtype=author&query=Haydon%2C+N">Nathan Haydon</a>, 
<a href="/search/cs?searchtype=author&query=Sobocinski%2C+P">Pawel Sobocinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">We introduce the calculus of neo-Peircean relations, a string diagrammatic
extension of the calculus of binary relations that has the same expressivity as
first order logic and comes with a complete axiomatisation. The axioms are
obtained by combining two well known categorical structures: cartesian and
linear bicategories.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07056" title="Abstract">arXiv:2401.07056</a> [<a href="/pdf/2401.07056" title="Download PDF">pdf</a>, <a href="/format/2401.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aquarium: A Comprehensive Framework for Exploring Predator-Prey Dynamics  through Multi-Agent Reinforcement Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/cs?searchtype=author&query=Erpelding%2C+Y">Yannick Erpelding</a>, 
<a href="/search/cs?searchtype=author&query=Ritz%2C+F">Fabian Ritz</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Illium%2C+S">Steffen Illium</a>, 
<a href="/search/cs?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICAART
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Recent advances in Multi-Agent Reinforcement Learning have prompted the
modeling of intricate interactions between agents in simulated environments. In
particular, the predator-prey dynamics have captured substantial interest and
various simulations been tailored to unique requirements. To prevent further
time-intensive developments, we introduce Aquarium, a comprehensive Multi-Agent
Reinforcement Learning environment for predator-prey interaction, enabling the
study of emergent behavior. Aquarium is open source and offers a seamless
integration of the PettingZoo framework, allowing a quick start with proven
algorithm implementations. It features physics-based agent movement on a
two-dimensional, edge-wrapping plane. The agent-environment interaction
(observations, actions, rewards) and the environment settings (agent speed,
prey reproduction, predator starvation, and others) are fully customizable.
Besides a resource-efficient visualization, Aquarium supports to record video
files, providing a visual comprehension of agent behavior. To demonstrate the
environment's capabilities, we conduct preliminary studies which use PPO to
train multiple prey agents to evade a predator. In accordance to the
literature, we find Individual Learning to result in worse performance than
Parameter Sharing, which significantly improves coordination and
sample-efficiency.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07058" title="Abstract">arXiv:2401.07058</a> [<a href="/pdf/2401.07058" title="Download PDF">pdf</a>, <a href="/format/2401.07058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does More Advice Help? The Effects of Second Opinions in AI-Assisted  Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhuoran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">AI assistance in decision-making has become popular, yet people's
inappropriate reliance on AI often leads to unsatisfactory human-AI
collaboration performance. In this paper, through three pre-registered,
randomized human subject experiments, we explore whether and how the provision
of {second opinions} may affect decision-makers' behavior and performance in
AI-assisted decision-making. We find that if both the AI model's decision
recommendation and a second opinion are always presented together,
decision-makers reduce their over-reliance on AI while increase their
under-reliance on AI, regardless whether the second opinion is generated by a
peer or another AI model. However, if decision-makers have the control to
decide when to solicit a peer's second opinion, we find that their active
solicitations of second opinions have the potential to mitigate over-reliance
on AI without inducing increased under-reliance in some cases. We conclude by
discussing the implications of our findings for promoting effective human-AI
collaborations in decision-making.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07059" title="Abstract">arXiv:2401.07059</a> [<a href="/pdf/2401.07059" title="Download PDF">pdf</a>, <a href="/ps/2401.07059" title="Download PostScript">ps</a>, <a href="/format/2401.07059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classifying Proposals of Decentralized Autonomous Organizations Using  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+C">Christian Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Miranda%2C+M">Marcos Miranda</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guangye Cao</a>, 
<a href="/search/cs?searchtype=author&query=Arentoft%2C+G">Gustav Arentoft</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+D+W">Doo Wan Nam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Our study demonstrates the effective use of Large Language Models (LLMs) for
automating the classification of complex datasets. We specifically target
proposals of Decentralized Autonomous Organizations (DAOs), as the
classification of this data requires the understanding of context and,
therefore, depends on human expertise, leading to high costs associated with
the task. The study applies an iterative approach to specify categories and
further refine them and the prompt in each iteration, which led to an accuracy
rate of 95% in classifying a set of 100 proposals. With this, we demonstrate
the potential of LLMs to automate data labeling tasks that depend on textual
context effectively.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07061" title="Abstract">arXiv:2401.07061</a> [<a href="/pdf/2401.07061" title="Download PDF">pdf</a>, <a href="/format/2401.07061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-View Data Hallucination with Semantic Relation Guidance for  Few-Shot Image Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hefeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guangzhi Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Ziyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Ling Tian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning to recognize novel concepts from just a few image samples is very
challenging as the learned model is easily overfitted on the few data and
results in poor generalizability. One promising but underexplored solution is
to compensate the novel classes by generating plausible samples. However, most
existing works of this line exploit visual information only, rendering the
generated data easy to be distracted by some challenging factors contained in
the few available samples. Being aware of the semantic information in the
textual modality that reflects human concepts, this work proposes a novel
framework that exploits semantic relations to guide dual-view data
hallucination for few-shot image recognition. The proposed framework enables
generating more diverse and reasonable data samples for novel classes through
effective information transfer from base classes. Specifically, an
instance-view data hallucination module hallucinates each sample of a novel
class to generate new data by employing local semantic correlated attention and
global semantic feature fusion derived from base classes. Meanwhile, a
prototype-view data hallucination module exploits semantic-aware measure to
estimate the prototype of a novel class and the associated distribution from
the few samples, which thereby harvests the prototype as a more stable sample
and enables resampling a large number of samples. We conduct extensive
experiments and comparisons with state-of-the-art methods on several popular
few-shot benchmarks to verify the effectiveness of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07062" title="Abstract">arXiv:2401.07062</a> [<a href="/pdf/2401.07062" title="Download PDF">pdf</a>, <a href="/format/2401.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dirichlet-Based Prediction Calibration for Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zong%2C+C">Chen-Chen Zong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ye-Wen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+M">Ming-Kun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Sheng-Jun Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning with noisy labels can significantly hinder the generalization
performance of deep neural networks (DNNs). Existing approaches address this
issue through loss correction or example selection methods. However, these
methods often rely on the model's predictions obtained from the softmax
function, which can be over-confident and unreliable. In this study, we
identify the translation invariance of the softmax function as the underlying
cause of this problem and propose the \textit{Dirichlet-based Prediction
Calibration} (DPC) method as a solution. Our method introduces a calibrated
softmax function that breaks the translation invariance by incorporating a
suitable constant in the exponent term, enabling more reliable model
predictions. To ensure stable model training, we leverage a Dirichlet
distribution to assign probabilities to predicted labels and introduce a novel
evidence deep learning (EDL) loss. The proposed loss function encourages
positive and sufficiently large logits for the given label, while penalizing
negative and small logits for other labels, leading to more distinct logits and
facilitating better example selection based on a large-margin criterion.
Through extensive experiments on diverse benchmark datasets, we demonstrate
that DPC achieves state-of-the-art performance. The code is available at
https://github.com/chenchenzong/DPC.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07063" title="Abstract">arXiv:2401.07063</a> [<a href="/pdf/2401.07063" title="Download PDF">pdf</a>, <a href="/format/2401.07063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACAV: A Framework for Automatic Causality Analysis in Autonomous Vehicle  Accident Recordings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huijia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Poskitt%2C+C+M">Christopher M. Poskitt</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jun Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the IEEE/ACM 46th International Conference on Software Engineering (ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rapid progress of autonomous vehicles~(AVs) has brought the prospect of a
driverless future closer than ever. Recent fatalities, however, have emphasized
the importance of safety validation through large-scale testing. Multiple
approaches achieve this fully automatically using high-fidelity simulators,
i.e., by generating diverse driving scenarios and evaluating autonomous driving
systems~(ADSs) against different test oracles. While effective at finding
violations, these approaches do not identify the decisions and actions that
\emph{caused} them -- information that is critical for improving the safety of
ADSs. To address this challenge, we propose ACAV, an automated framework
designed to conduct causality analysis for AV accident recordings in two
stages. First, we apply feature extraction schemas based on the messages
exchanged between ADS modules, and use a weighted voting method to discard
frames of the recording unrelated to the accident. Second, we use safety
specifications to identify safety-critical frames and deduce causal events by
applying CAT -- our causal analysis tool -- to a station-time graph. We
evaluate ACAV on the Apollo ADS, finding that it can identify five distinct
types of causal events in 93.64% of 110 accident recordings generated by an AV
testing engine. We further evaluated ACAV on 1206 accident recordings collected
from versions of Apollo injected with specific faults, finding that it can
correctly identify causal events in 96.44% of the accidents triggered by
prediction errors, and 85.73% of the accidents triggered by planning errors.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07065" title="Abstract">arXiv:2401.07065</a> [<a href="/pdf/2401.07065" title="Download PDF">pdf</a>, <a href="/ps/2401.07065" title="Download PostScript">ps</a>, <a href="/format/2401.07065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Graph Convolutional Network for Dynamic Graph Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Ling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Dynamic graphs (DG) describe dynamic interactions between entities in many
practical scenarios. Most existing DG representation learning models combine
graph convolutional network and sequence neural network, which model
spatial-temporal dependencies through two different types of neural networks.
However, this hybrid design cannot well capture the spatial-temporal continuity
of a DG. In this paper, we propose a tensor graph convolutional network to
learn DG representations in one convolution framework based on the tensor
product with the following two-fold ideas: a) representing the information of
DG by tensor form; b) adopting tensor product to design a tensor graph
convolutional network modeling spatial-temporal feature simultaneously.
Experiments on real-world DG datasets demonstrate that our model obtains
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07066" title="Abstract">arXiv:2401.07066</a> [<a href="/pdf/2401.07066" title="Download PDF">pdf</a>, <a href="/format/2401.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of Volatile Organic Compounds by Differential Mobility  Spectrometry Based on Continuity of Alpha Curves
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rauhameri%2C+A">Anton Rauhameri</a>, 
<a href="/search/cs?searchtype=author&query=Robi%C3%B1os%2C+A">Angelo Robi&#xf1;os</a>, 
<a href="/search/cs?searchtype=author&query=Anttalainen%2C+O">Osmo Anttalainen</a>, 
<a href="/search/cs?searchtype=author&query=Salpavaara%2C+T">Timo Salpavaara</a>, 
<a href="/search/cs?searchtype=author&query=Rantala%2C+J">Jussi Rantala</a>, 
<a href="/search/cs?searchtype=author&query=Surakka%2C+V">Veikko Surakka</a>, 
<a href="/search/cs?searchtype=author&query=Kallio%2C+P">Pasi Kallio</a>, 
<a href="/search/cs?searchtype=author&query=Vehkaoja%2C+A">Antti Vehkaoja</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+P">Philipp M&#xfc;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Background: Classification of volatile organic compounds (VOCs) is of
interest in many fields. Examples include but are not limited to medicine,
detection of explosives, and food quality control. Measurements collected with
electronic noses can be used for classification and analysis of VOCs. One type
of electronic noses that has seen considerable development in recent years is
Differential Mobility Spectrometry (DMS). DMS yields measurements that are
visualized as dispersion plots that contain traces, also known as alpha curves.
Current methods used for analyzing DMS dispersion plots do not usually utilize
the information stored in the continuity of these traces, which suggests that
alternative approaches should be investigated.
<br />Results: In this work, for the first time, dispersion plots were interpreted
as a series of measurements evolving sequentially. Thus, it was hypothesized
that time-series classification algorithms can be effective for classification
and analysis of dispersion plots. An extensive dataset of 900 dispersion plots
for five chemicals measured at five flow rates and two concentrations was
collected. The data was used to analyze the classification performance of six
algorithms. According to our hypothesis, the highest classification accuracy of
88\% was achieved by a Long-Short Term Memory neural network, which supports
our hypothesis.
<br />Significance: A new concept for approaching classification tasks of
dispersion plots is presented and compared with other well-known classification
algorithms. This creates a new angle of view for analysis and classification of
the dispersion plots. In addition, a new dataset of dispersion plots is openly
shared to public.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07072" title="Abstract">arXiv:2401.07072</a> [<a href="/pdf/2401.07072" title="Download PDF">pdf</a>, <a href="/format/2401.07072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InterEvo-TR: Interactive Evolutionary Test Generation With Readability  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delgado-P%C3%A9rez%2C+P">Pedro Delgado-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Ram%C3%ADrez%2C+A">Aurora Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Valle-G%C3%B3mez%2C+K+J">Kevin J. Valle-G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Medina-Bulo%2C+I">Inmaculada Medina-Bulo</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+J+R">Jos&#xe9; Ra&#xfa;l Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 5 tables, journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Software Engineering (Volume: 49, Issue: 4,
  01 April 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Automated test case generation has proven to be useful to reduce the usually
high expenses of software testing. However, several studies have also noted the
skepticism of testers regarding the comprehension of generated test suites when
compared to manually designed ones. This fact suggests that involving testers
in the test generation process could be helpful to increase their acceptance of
automatically-produced test suites. In this paper, we propose incorporating
interactive readability assessments made by a tester into EvoSuite, a
widely-known evolutionary test generation tool. Our approach, InterEvo-TR,
interacts with the tester at different moments during the search and shows
different test cases covering the same coverage target for their subjective
evaluation. The design of such an interactive approach involves a schedule of
interaction, a method to diversify the selected targets, a plan to save and
handle the readability values, and some mechanisms to customize the level of
engagement in the revision, among other aspects. To analyze the potential and
practicability of our proposal, we conduct a controlled experiment in which 39
participants, including academics, professional developers, and student
collaborators, interact with InterEvo-TR. Our results show that the strategy to
select and present intermediate results is effective for the purpose of
readability assessment. Furthermore, the participants' actions and responses to
a questionnaire allowed us to analyze the aspects influencing test code
readability and the benefits and limitations of an interactive approach in the
context of test case generation, paving the way for future developments based
on interactivity.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07074" title="Abstract">arXiv:2401.07074</a> [<a href="/pdf/2401.07074" title="Download PDF">pdf</a>, <a href="/format/2401.07074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detachment Problem -- Application in Prevention of Information Leakage  in Stock Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hansen%2C+H">Henri Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Kanniainen%2C+J">Juho Kanniainen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In this paper, we introduce the Detachment Problem. It can be seen as a
generalized Vaccination Problem. The aim is to optimally cut the individuals'
ties to circles that connect them to others, to minimize the overall
information transfer in a social network. When an individual is isolated from a
particular circle, it leads to the elimination of the connections to all the
members of that circle, yet the connections to other circles remain. This
approach contrasts with the conventional vaccination problem, in which a subset
of vertices is totally eliminated. In our case, the connections of individuals
to their circles are selectively, rather than entirely, eliminated.
Contextually, this article focuses on private information flows, specifically
within networks formed by memberships in circles of insiders in companies. Our
quasi-empirical study uses simulated information flows on an observable
network, and the statistical properties of the simulated information flows are
matched with real-world data. In a broader context, this paper presents the
Detachment Problem as a versatile approach for optimal social distancing,
applicable across various scenarios. We propose and define a concept of
expected proportional outside influence, or EPOI, as measure of how widespread
information leak is. We also implement a greedy algorithm for finding a set of
detachments to minimize EPOI. For comparison, we devise a simple heuristic
based on minimal cut, to separate the most influential circles from each other.
We provide evidence that the greedy algorithm is not optimal, and it is
sometimes outperformed by the simple heuristic minimum cut algorithm, However,
the greedy algorithm outperforms the cut algorithm in most cases. Further
avenues of research are discussed.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07078" title="Abstract">arXiv:2401.07078</a> [<a href="/pdf/2401.07078" title="Download PDF">pdf</a>, <a href="/format/2401.07078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PUB: A Pragmatics Understanding Benchmark for Assessing LLMs&#x27; Pragmatics  Capabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sravanthi%2C+S+L">Settaluri Lakshmi Sravanthi</a>, 
<a href="/search/cs?searchtype=author&query=Doshi%2C+M">Meet Doshi</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+T+P">Tankala Pavan Kalyan</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+R">Rudra Murthy</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Pushpak Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Dabre%2C+R">Raj Dabre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">LLMs have demonstrated remarkable capability for understanding semantics, but
they often struggle with understanding pragmatics. To demonstrate this fact, we
release a Pragmatics Understanding Benchmark (PUB) dataset consisting of
fourteen tasks in four pragmatics phenomena, namely, Implicature,
Presupposition, Reference, and Deixis. We curated high-quality test sets for
each task, consisting of Multiple Choice Question Answers (MCQA). PUB includes
a total of 28k data points, 6.1k of which have been created by us, and the rest
are adapted from existing datasets. We evaluated nine models varying in the
number of parameters and type of training. Our study indicates that fine-tuning
for instruction-following and chat significantly enhances the pragmatics
capabilities of smaller language models. However, for larger models, the base
versions perform comparably with their chat-adapted counterparts. Additionally,
there is a noticeable performance gap between human capabilities and model
capabilities. Furthermore, unlike the consistent performance of humans across
various tasks, the models demonstrate variability in their proficiency, with
performance levels fluctuating due to different hints and the complexities of
tasks within the same dataset. Overall, the benchmark aims to provide a
comprehensive evaluation of LLM's ability to handle real-world language tasks
that require pragmatic reasoning.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07080" title="Abstract">arXiv:2401.07080</a> [<a href="/pdf/2401.07080" title="Download PDF">pdf</a>, <a href="/format/2401.07080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GoMatching: A Simple Baseline for Video Text Spotting via Long and Short  Term Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haibin He</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+M">Maoyuan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Juhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Beyond the text detection and recognition tasks in image text spotting, video
text spotting presents an augmented challenge with the inclusion of tracking.
While advanced end-to-end trainable methods have shown commendable performance,
the pursuit of multi-task optimization may pose the risk of producing
sub-optimal outcomes for individual tasks. In this paper, we highlight a main
bottleneck in the state-of-the-art video text spotter: the limited recognition
capability. In response to this issue, we propose to efficiently turn an
off-the-shelf query-based image text spotter into a specialist on video and
present a simple baseline termed GoMatching, which focuses the training efforts
on tracking while maintaining strong recognition performance. To adapt the
image text spotter to video datasets, we add a rescoring head to rescore each
detected instance's confidence via efficient tuning, leading to a better
tracking candidate pool. Additionally, we design a long-short term matching
module, termed LST-Matcher, to enhance the spotter's tracking capability by
integrating both long- and short-term matching results via Transformer. Based
on the above simple designs, GoMatching achieves impressive performance on two
public benchmarks, e.g., setting a new record on the ICDAR15-video dataset, and
one novel test set with arbitrary-shaped text, while saving considerable
training budgets. The code will be released at
https://github.com/Hxyz-123/GoMatching.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07081" title="Abstract">arXiv:2401.07081</a> [<a href="/pdf/2401.07081" title="Download PDF">pdf</a>, <a href="/format/2401.07081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6Rover: Leveraging Reinforcement Learning-based Address Pattern Mining  Approach for Discovering Active Targets in IPv6 Unseeded Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhichao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yanan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Ning Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The discovery of active IPv6 addresses represents a pivotal challenge in IPv6
network survey, as it is a prerequisite for downstream tasks such as network
topology measurements and security analysis. With the rapid spread of IPv6
networks in recent years, many researchers have focused on improving the hit
rate, efficiency, and coverage of IPv6 scanning methods, resulting in
considerable advancements. However, existing approaches remain heavily
dependent on seed addresses, thereby limiting their effectiveness in unseeded
prefixes. Consequently, this paper proposes 6Rover, a reinforcement
learning-based model for active address discovery in unseeded environments. To
overcome the reliance on seeded addresses, 6Rover constructs patterns with
higher generality that reflects the actual address allocation strategies of
network administrators, thereby avoiding biased transfers of patterns from
seeded to unseeded prefixes. After that, 6Rover employs a multi-armed bandit
model to optimize the probing resource allocation when applying patterns to
unseeded spaces. It models the challenge of discovering optimal patterns in
unseeded spaces as an exploration-exploitation dilemma, and progressively
uncover the potential patterns applied in unseeded spaces, leading to the
efficient discovery of active addresses without seed address as the prior
knowledge. Experiments on large-scale unseeded datasets show that 6Rover has a
higher hit rate than existing methods in the absence of any seed addresses as
prior knowledge. In real network environments, 6Rover achieved a 5% - 8% hit
rate in seedless spaces with 100 million budget scale, representing an
approximate 200\% improvement over the existing state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07084" title="Abstract">arXiv:2401.07084</a> [<a href="/pdf/2401.07084" title="Download PDF">pdf</a>, <a href="/format/2401.07084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScripTONES: Sentiment-Conditioned Music Generation for Movie Scripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Veerendranath%2C+V">Vishruth Veerendranath</a>, 
<a href="/search/cs?searchtype=author&query=Masti%2C+V">Vibha Masti</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+U">Utkarsh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+H">Hrishit Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+G">Gowri Srinivasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at NeurIPS 2023 - ML For Audio workshop. To appear in proceedings of AIML Systems 2023 - Generative AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Film scores are considered an essential part of the film cinematic
experience, but the process of film score generation is often expensive and
infeasible for small-scale creators. Automating the process of film score
composition would provide useful starting points for music in small projects.
In this paper, we propose a two-stage pipeline for generating music from a
movie script. The first phase is the Sentiment Analysis phase where the
sentiment of a scene from the film script is encoded into the valence-arousal
continuous space. The second phase is the Conditional Music Generation phase
which takes as input the valence-arousal vector and conditionally generates
piano MIDI music to match the sentiment. We study the efficacy of various music
generation architectures by performing a qualitative user survey and propose
methods to improve sentiment-conditioning in VAE architectures.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07085" title="Abstract">arXiv:2401.07085</a> [<a href="/pdf/2401.07085" title="Download PDF">pdf</a>, <a href="/format/2401.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Does Feature Learning Happen? Perspective from an Analytically  Solvable Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yizhou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ziyin%2C+L">Liu Ziyin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We identify and solve a hidden-layer model that is analytically tractable at
any finite width and whose limits exhibit both the kernel phase and the feature
learning phase. We analyze the phase diagram of this model in all possible
limits of common hyperparameters including width, layer-wise learning rates,
scale of output, and scale of initialization. We apply our result to analyze
how and when feature learning happens in both infinite and finite-width models.
Three prototype mechanisms of feature learning are identified: (1) learning by
alignment, (2) learning by disalignment, and (3) learning by rescaling. In
sharp contrast, neither of these mechanisms is present when the model is in the
kernel regime. This discovery explains why large initialization often leads to
worse performance. Lastly, we empirically demonstrate that discoveries we made
for this analytical model also appear in nonlinear networks in real tasks.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07087" title="Abstract">arXiv:2401.07087</a> [<a href="/pdf/2401.07087" title="Download PDF">pdf</a>, <a href="/format/2401.07087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Adversarial Attacks against Latent Diffusion Model from the  Perspective of Adversarial Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junxi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Junhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaohua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, many studies utilized adversarial examples (AEs) to raise the cost
of malicious image editing and copyright violation powered by latent diffusion
models (LDMs). Despite their successes, a few have studied the surrogate model
they used to generate AEs. In this paper, from the perspective of adversarial
transferability, we investigate how the surrogate model's property influences
the performance of AEs for LDMs. Specifically, we view the time-step sampling
in the Monte-Carlo-based (MC-based) adversarial attack as selecting surrogate
models. We find that the smoothness of surrogate models at different time steps
differs, and we substantially improve the performance of the MC-based AEs by
selecting smoother surrogate models. In the light of the theoretical framework
on adversarial transferability in image classification, we also conduct a
theoretical analysis to explain why smooth surrogate models can also boost AEs
for LDMs.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07091" title="Abstract">arXiv:2401.07091</a> [<a href="/pdf/2401.07091" title="Download PDF">pdf</a>, <a href="/format/2401.07091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Inter-group Criteria for Clustering with Minimum Size  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laber%2C+E+S">Eduardo S. Laber</a>, 
<a href="/search/cs?searchtype=author&query=Murtinho%2C+L">Lucas Murtinho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Neurips 2023. 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Internal measures that are used to assess the quality of a clustering usually
take into account intra-group and/or inter-group criteria. There are many
papers in the literature that propose algorithms with provable approximation
guarantees for optimizing the former. However, the optimization of inter-group
criteria is much less understood.
<br />Here, we contribute to the state-of-the-art of this literature by devising
algorithms with provable guarantees for the maximization of two natural
inter-group criteria, namely the minimum spacing and the minimum spanning tree
spacing. The former is the minimum distance between points in different groups
while the latter captures separability through the cost of the minimum spanning
tree that connects all groups. We obtain results for both the unrestricted
case, in which no constraint on the clusters is imposed, and for the
constrained case where each group is required to have a minimum number of
points. Our constraint is motivated by the fact that the popular Single
Linkage, which optimizes both criteria in the unrestricted case, produces
clusterings with many tiny groups.
<br />To complement our work, we present an empirical study with 10 real datasets,
providing evidence that our methods work very well in practical settings.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07098" title="Abstract">arXiv:2401.07098</a> [<a href="/pdf/2401.07098" title="Download PDF">pdf</a>, <a href="/format/2401.07098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Multi-Stage Prompting Approach for Language Agnostic MCQ  Generation using GPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+S">Subhankar Maity</a>, 
<a href="/search/cs?searchtype=author&query=Deroy%2C+A">Aniket Deroy</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Sudeshna Sarkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR 2024(short paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce a multi-stage prompting approach (MSP) for the generation of
multiple choice questions (MCQs), harnessing the capabilities of GPT models
such as text-davinci-003 and GPT-4, renowned for their excellence across
various NLP tasks. Our approach incorporates the innovative concept of
chain-of-thought prompting, a progressive technique in which the GPT model is
provided with a series of interconnected cues to guide the MCQ generation
process. Automated evaluations consistently demonstrate the superiority of our
proposed MSP method over the traditional single-stage prompting (SSP) baseline,
resulting in the production of high-quality distractors. Furthermore, the
one-shot MSP technique enhances automatic evaluation results, contributing to
improved distractor generation in multiple languages, including English,
German, Bengali, and Hindi. In human evaluations, questions generated using our
approach exhibit superior levels of grammaticality, answerability, and
difficulty, highlighting its efficacy in various languages.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07100" title="Abstract">arXiv:2401.07100</a> [<a href="/pdf/2401.07100" title="Download PDF">pdf</a>, <a href="/format/2401.07100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation in Uplink Multi STAR-RIS-aided NOMA System via  Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Javadi%2C+S">Sepideh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Farhadi%2C+A">Armin Farhadi</a>, 
<a href="/search/cs?searchtype=author&query=Mili%2C+M+R">Mohammad Robat Mili</a>, 
<a href="/search/cs?searchtype=author&query=Jorswieck%2C+E">Eduard Jorswieck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) is a novel technology which enables the full-space coverage by
splitting the incident signal into reflected and transmitted signals. In this
letter, a multi STAR-RIS-aided system using non-orthogonal multiple access
(NOMA) in an uplink transmission is considered, where the multi-order
reflections among multiple STAR-RISs assist the transmission from the
single-antenna users to the multi-antenna base station (BS). Specifically, the
total sum rate maximization problem is solved by jointly optimizing the active
beamforming, power allocation, transmission and reflection beamforming at the
STAR-RIS, and user-STAR-RIS association indicator. To solve the non-convex
optimization problem, a novel deep reinforcement learning algorithm is proposed
which is the combination of meta-learning and deep deterministic policy
gradient (DDPG), namely Meta-DDPG. Numerical results demonstrate that the
proposed Meta-DDPG algorithm outperforms the conventional DDPG algorithm.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07102" title="Abstract">arXiv:2401.07102</a> [<a href="/pdf/2401.07102" title="Download PDF">pdf</a>, <a href="/format/2401.07102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolving Code with A Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemberg%2C+E">Erik Hemberg</a>, 
<a href="/search/cs?searchtype=author&query=Moskal%2C+S">Stephen Moskal</a>, 
<a href="/search/cs?searchtype=author&query=O%27Reilly%2C+U">Una-May O&#x27;Reilly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Algorithms that use Large Language Models (LLMs) to evolve code arrived on
the Genetic Programming (GP) scene very recently. We present LLM GP, a
formalized LLM-based evolutionary algorithm designed to evolve code. Like GP,
it uses evolutionary operators, but its designs and implementations of those
operators radically differ from GP's because they enlist an LLM, using
prompting and the LLM's pre-trained pattern matching and sequence completion
capability. We also present a demonstration-level variant of LLM GP and share
its code. By addressing algorithms that range from the formal to hands-on, we
cover design and LLM-usage considerations as well as the scientific challenges
that arise when using an LLM for genetic programming.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07103" title="Abstract">arXiv:2401.07103</a> [<a href="/pdf/2401.07103" title="Download PDF">pdf</a>, <a href="/format/2401.07103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for NLG Evaluation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+T">Tao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jia-Chen Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Chongyang Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the rapidly evolving domain of Natural Language Generation (NLG)
evaluation, introducing Large Language Models (LLMs) has opened new avenues for
assessing generated content quality, e.g., coherence, creativity, and context
relevance. This survey aims to provide a thorough overview of leveraging LLMs
for NLG evaluation, a burgeoning area that lacks a systematic analysis. We
propose a coherent taxonomy for organizing existing LLM-based evaluation
metrics, offering a structured framework to understand and compare these
methods. Our detailed exploration includes critically assessing various
LLM-based methodologies, as well as comparing their strengths and limitations
in evaluating NLG outputs. By discussing unresolved challenges, including bias,
robustness, domain-specificity, and unified evaluation, this survey seeks to
offer insights to researchers and advocate for fairer and more advanced NLG
evaluation techniques.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07105" title="Abstract">arXiv:2401.07105</a> [<a href="/pdf/2401.07105" title="Download PDF">pdf</a>, <a href="/format/2401.07105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plenz%2C+M">Moritz Plenz</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+A">Anette Frank</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While Language Models have become workhorses for NLP, their interplay with
textual knowledge graphs (KGs) - structured memories of general or domain
knowledge - is actively researched. Current embedding methodologies for such
graphs typically either (i) linearize graphs for embedding them using
sequential Language Models (LMs), which underutilize structural information, or
(ii) use Graph Neural Networks (GNNs) to preserve graph structure, while GNNs
cannot represent textual features as well as a pre-trained LM could. In this
work we introduce a novel language model, the Graph Language Model (GLM), that
integrates the strengths of both approaches, while mitigating their weaknesses.
The GLM parameters are initialized from a pretrained LM, to facilitate nuanced
understanding of individual concepts and triplets. Simultaneously, its
architectural design incorporates graph biases, thereby promoting effective
knowledge distribution within the graph. Empirical evaluations on relation
classification tasks on ConceptNet subgraphs reveal that GLM embeddings surpass
both LM- and GNN-based baselines in supervised and zero-shot settings.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07106" title="Abstract">arXiv:2401.07106</a> [<a href="/pdf/2401.07106" title="Download PDF">pdf</a>, <a href="/format/2401.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directed Regular and Context-Free Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganardi%2C+M">Moses Ganardi</a>, 
<a href="/search/cs?searchtype=author&query=Saglam%2C+I">Irmak Saglam</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">We study the problem of deciding whether a given language is directed. A
language $L$ is \emph{directed} if every pair of words in $L$ have a common
(scattered) superword in $L$. Deciding directedness is a fundamental problem in
connection with ideal decompositions of downward closed sets. Another
motivation is that deciding whether two \emph{directed} context-free languages
have the same downward closures can be decided in polynomial time, whereas for
general context-free languages, this problem is known to be coNEXP-complete.
<br />We show that the directedness problem for regular languages, given as NFAs,
belongs to $AC^1$, and thus polynomial time. Moreover, it is NL-complete for
fixed alphabet sizes. Furthermore, we show that for context-free languages, the
directedness problem is PSPACE-complete.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07108" title="Abstract">arXiv:2401.07108</a> [<a href="/pdf/2401.07108" title="Download PDF">pdf</a>, <a href="/format/2401.07108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated construction of projection-based reduced-order models via  incremental approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Agouzal%2C+E">Eki Agouzal</a>, 
<a href="/search/math?searchtype=author&query=Taddei%2C+T">Tommaso Taddei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present an accelerated greedy strategy for training of projection-based
reduced-order models for parametric steady and unsteady partial differential
equations. Our approach exploits hierarchical approximate proper orthogonal
decomposition to speed up the construction of the empirical test space for
least-square Petrov-Galerkin formulations, a progressive construction of the
empirical quadrature rule based on a warm start of the non-negative
least-square algorithm, and a two-fidelity sampling strategy to reduce the
number of expensive greedy iterations. We illustrate the performance of our
method for two test cases: a two-dimensional compressible inviscid flow past a
LS89 blade at moderate Mach number, and a three-dimensional nonlinear mechanics
problem to predict the long-time structural response of the standard section of
a nuclear containment building under external loading.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07114" title="Abstract">arXiv:2401.07114</a> [<a href="/pdf/2401.07114" title="Download PDF">pdf</a>, <a href="/format/2401.07114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Sampson Approximations for Geometric Estimation Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rydell%2C+F">Felix Rydell</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+A">Ang&#xe9;lica Torres</a>, 
<a href="/search/cs?searchtype=author&query=Larsson%2C+V">Viktor Larsson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Many problems in computer vision can be formulated as geometric estimation
problems, i.e. given a collection of measurements (e.g. point correspondences)
we wish to fit a model (e.g. an essential matrix) that agrees with our
observations. This necessitates some measure of how much an observation
``agrees" with a given model. A natural choice is to consider the smallest
perturbation that makes the observation exactly satisfy the constraints.
However, for many problems, this metric is expensive or otherwise intractable
to compute. The so-called Sampson error approximates this geometric error
through a linearization scheme. For epipolar geometry, the Sampson error is a
popular choice and in practice known to yield very tight approximations of the
corresponding geometric residual (the reprojection error).
<br />In this paper we revisit the Sampson approximation and provide new
theoretical insights as to why and when this approximation works, as well as
provide explicit bounds on the tightness under some mild assumptions. Our
theoretical results are validated in several experiments on real data and in
the context of different geometric estimation tasks.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07115" title="Abstract">arXiv:2401.07115</a> [<a href="/pdf/2401.07115" title="Download PDF">pdf</a>, <a href="/ps/2401.07115" title="Download PostScript">ps</a>, <a href="/format/2401.07115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open Models, Closed Minds? On Agents Capabilities in Mimicking Human  Personalities through Open Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=La+Cava%2C+L">Lucio La Cava</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+D">Davide Costa</a>, 
<a href="/search/cs?searchtype=author&query=Tagarelli%2C+A">Andrea Tagarelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The emergence of unveiling human-like behaviors in Large Language Models
(LLMs) has led to a closer connection between NLP and human psychology, leading
to a proliferation of computational agents. Scholars have been studying the
inherent personalities displayed by LLM agents and attempting to incorporate
human traits and behaviors into them. However, these efforts have primarily
focused on commercially-licensed LLMs, neglecting the widespread use and
notable advancements seen in Open LLMs. This work aims to address this gap by
conducting a comprehensive examination of the ability of agents to emulate
human personalities using Open LLMs. To achieve this, we generate a set of ten
LLM Agents based on the most representative Open models and subject them to a
series of assessments concerning the Myers-Briggs Type Indicator (MBTI) test.
Our approach involves evaluating the intrinsic personality traits of Open LLM
agents and determining the extent to which these agents can mimic human
personalities when conditioned by specific personalities and roles. Our
findings unveil that: $(i)$ each Open LLM agent showcases distinct human
personalities; $(ii)$ personality-conditioned prompting produces varying
effects on the agents, with only few successfully mirroring the imposed
personality, while most of them being ``closed-minded'' (i.e., they retain
their intrinsic traits); $(iii)$ combining role and personality conditioning
can enhance the agents' ability to mimic human personalities; and $(iv)$
personalities typically associated with the role of teacher tend to be emulated
with greater accuracy. Our work represents a step up in understanding the dense
relationship between NLP and human psychology through the lens of Open LLMs.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07118" title="Abstract">arXiv:2401.07118</a> [<a href="/pdf/2401.07118" title="Download PDF">pdf</a>, <a href="/format/2401.07118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring of Discrete and Continuous Input Control for AI-enhanced  Assistive Robotic Arms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pascher%2C+M">Max Pascher</a>, 
<a href="/search/cs?searchtype=author&query=Zinta%2C+K">Kevin Zinta</a>, 
<a href="/search/cs?searchtype=author&query=Gerken%2C+J">Jens Gerken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Robotic arms, integral in domestic care for individuals with motor
impairments, enable them to perform Activities of Daily Living (ADLs)
independently, reducing dependence on human caregivers. These collaborative
robots require users to manage multiple Degrees-of-Freedom (DoFs) for tasks
like grasping and manipulating objects. Conventional input devices, typically
limited to two DoFs, necessitate frequent and complex mode switches to control
individual DoFs. Modern adaptive controls with feed-forward multi-modal
feedback reduce the overall task completion time, number of mode switches, and
cognitive load. Despite the variety of input devices available, their
effectiveness in adaptive settings with assistive robotics has yet to be
thoroughly assessed. This study explores three different input devices by
integrating them into an established XR framework for assistive robotics,
evaluating them and providing empirical insights through a preliminary study
for future developments.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07119" title="Abstract">arXiv:2401.07119</a> [<a href="/pdf/2401.07119" title="Download PDF">pdf</a>, <a href="/format/2401.07119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curator: Efficient Indexing for Multi-Tenant Vector Databases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Yicheng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongji Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenjun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Maggs%2C+B+M">Bruce M. Maggs</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+D">Danyang Zhuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vector databases have emerged as key enablers for bridging intelligent
applications with unstructured data, providing generic search and management
support for embedding vectors extracted from the raw unstructured data. As
multiple data users can share the same database infrastructure, multi-tenancy
support for vector databases is increasingly desirable. This hinges on an
efficient filtered search operation, i.e., only querying the vectors accessible
to a particular tenant. Multi-tenancy in vector databases is currently achieved
by building either a single, shared index among all tenants, or a per-tenant
index. The former optimizes for memory efficiency at the expense of search
performance, while the latter does the opposite. Instead, this paper presents
Curator, an in-memory vector index design tailored for multi-tenant queries
that simultaneously achieves the two conflicting goals, low memory overhead and
high performance for queries, vector insertion, and deletion. Curator indexes
each tenant's vectors with a tenant-specific clustering tree and encodes these
trees compactly as sub-trees of a shared clustering tree. Each tenant's
clustering tree adapts dynamically to its unique vector distribution, while
maintaining a low per-tenant memory footprint. Our evaluation, based on two
widely used data sets, confirms that Curator delivers search performance on par
with per-tenant indexing, while maintaining memory consumption at the same
level as metadata filtering on a single, shared index.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07120" title="Abstract">arXiv:2401.07120</a> [<a href="/pdf/2401.07120" title="Download PDF">pdf</a>, <a href="/format/2401.07120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI-enabled Quantum Computing Networks and Intelligent  Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yuan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yulan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+C">Chao Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Han Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum computing networks enable scalable collaboration and secure
information exchange among multiple classical and quantum computing nodes while
executing large-scale generative AI computation tasks and advanced quantum
algorithms. Quantum computing networks overcome limitations such as the number
of qubits and coherence time of entangled pairs and offer advantages for
generative AI infrastructure, including enhanced noise reduction through
distributed processing and improved scalability by connecting multiple quantum
devices. However, efficient resource allocation in quantum computing networks
is a critical challenge due to factors including qubit variability and network
complexity. In this article, we propose an intelligent resource allocation
framework for quantum computing networks to improve network scalability with
minimized resource costs. To achieve scalability in quantum computing networks,
we formulate the resource allocation problem as stochastic programming,
accounting for the uncertain fidelities of qubits and entangled pairs.
Furthermore, we introduce state-of-the-art reinforcement learning (RL)
algorithms, from generative learning to quantum machine learning for optimal
quantum resource allocation to resolve the proposed stochastic resource
allocation problem efficiently. Finally, we optimize the resource allocation in
heterogeneous quantum computing networks supporting quantum generative learning
applications and propose a multi-agent RL-based algorithm to learn the optimal
resource allocation policies without prior knowledge.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07121" title="Abstract">arXiv:2401.07121</a> [<a href="/pdf/2401.07121" title="Download PDF">pdf</a>, <a href="/format/2401.07121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-preserving neural networks in data-driven rheological models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Parolini%2C+N">Nicola Parolini</a>, 
<a href="/search/math?searchtype=author&query=Poiatti%2C+A">Andrea Poiatti</a>, 
<a href="/search/math?searchtype=author&query=Vene%27%2C+J">Julian Vene&#x27;</a>, 
<a href="/search/math?searchtype=author&query=Verani%2C+M">Marco Verani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication in the SIAM Journal on Scientific Computing, 22 pages, 7 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">In this paper we address the importance and the impact of employing structure
preserving neural networks as surrogate of the analytical physics-based models
typically employed to describe the rheology of non-Newtonian fluids in Stokes
flows. In particular, we propose and test on real-world scenarios a novel
strategy to build data-driven rheological models based on the use of
Input-Output Convex Neural Networks (ICNNs), a special class of feedforward
neural network scalar valued functions that are convex with respect to their
inputs. Moreover, we show, through a detailed campaign of numerical
experiments, that the use of ICNNs is of paramount importance to guarantee the
well-posedness of the associated non-Newtonian Stokes differential problem.
Finally, building upon a novel perturbation result for non-Newtonian Stokes
problems, we study the impact of our data-driven ICNN based rheological model
on the accuracy of the finite element approximation.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07122" title="Abstract">arXiv:2401.07122</a> [<a href="/pdf/2401.07122" title="Download PDF">pdf</a>, <a href="/format/2401.07122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Federated Learning with Asynchronous Parameter Sharing for  Large-scale IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haihui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+M">Minghua Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peiran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaibin Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures, to appear in IEEE Internet of Things Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Federated learning (FL) enables wireless terminals to collaboratively learn a
shared parameter model while keeping all the training data on devices per se.
Parameter sharing consists of synchronous and asynchronous ways: the former
transmits parameters as blocks or frames and waits until all transmissions
finish, whereas the latter provides messages about the status of pending and
failed parameter transmission requests. Whatever synchronous or asynchronous
parameter sharing is applied, the learning model shall adapt to distinct
network architectures as an improper learning model will deteriorate learning
performance and, even worse, lead to model divergence for the asynchronous
transmission in resource-limited large-scale Internet-of-Things (IoT) networks.
This paper proposes a decentralized learning model and develops an asynchronous
parameter-sharing algorithm for resource-limited distributed IoT networks. This
decentralized learning model approaches a convex function as the number of
nodes increases, and its learning process converges to a global stationary
point with a higher probability than the centralized FL model. Moreover, by
jointly accounting for the convergence bound of federated learning and the
transmission delay of wireless communications, we develop a node scheduling and
bandwidth allocation algorithm to minimize the transmission delay. Extensive
simulation results corroborate the effectiveness of the distributed algorithm
in terms of fast learning model convergence and low transmission delay.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07123" title="Abstract">arXiv:2401.07123</a> [<a href="/pdf/2401.07123" title="Download PDF">pdf</a>, <a href="/format/2401.07123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Agent Too Many: User Perspectives on Approaches to Multi-agent  Conversational AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clarke%2C+C">Christopher Clarke</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+K">Karthik Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Talamonti%2C+W">Walter Talamonti</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yiping Kang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lingjia Tang</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+J">Jason Mars</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Conversational agents have been gaining increasing popularity in recent
years. Influenced by the widespread adoption of task-oriented agents such as
Apple Siri and Amazon Alexa, these agents are being deployed into various
applications to enhance user experience. Although these agents promote "ask me
anything" functionality, they are typically built to focus on a single or
finite set of expertise. Given that complex tasks often require more than one
expertise, this results in the users needing to learn and adopt multiple
agents. One approach to alleviate this is to abstract the orchestration of
agents in the background. However, this removes the option of choice and
flexibility, potentially harming the ability to complete tasks. In this paper,
we explore these different interaction experiences (one agent for all) vs (user
choice of agents) for conversational AI. We design prototypes for each,
systematically evaluating their ability to facilitate task completion. Through
a series of conducted user studies, we show that users have a significant
preference for abstracting agent orchestration in both system usability and
system performance. Additionally, we demonstrate that this mode of interaction
is able to provide quality responses that are rated within 1% of human-selected
answers.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07124" title="Abstract">arXiv:2401.07124</a> [<a href="/pdf/2401.07124" title="Download PDF">pdf</a>, <a href="/ps/2401.07124" title="Download PostScript">ps</a>, <a href="/format/2401.07124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concrete Surface Crack Detection with Convolutional-based Deep Learning  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zadeh%2C+S+S">Sara Shomal Zadeh</a>, 
<a href="/search/cs?searchtype=author&query=birgani%2C+S+A">Sina Aalipour birgani</a>, 
<a href="/search/cs?searchtype=author&query=Khorshidi%2C+M">Meisam Khorshidi</a>, 
<a href="/search/cs?searchtype=author&query=Kooban%2C+F">Farhad Kooban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, Journal paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Novel Research in Civil Structural and
  Earth Sciences, Vol. 10, Issue 3, (2023) pp: (25-35)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Effective crack detection is pivotal for the structural health monitoring and
inspection of buildings. This task presents a formidable challenge to computer
vision techniques due to the inherently subtle nature of cracks, which often
exhibit low-level features that can be easily confounded with background
textures, foreign objects, or irregularities in construction. Furthermore, the
presence of issues like non-uniform lighting and construction irregularities
poses significant hurdles for autonomous crack detection during building
inspection and monitoring. Convolutional neural networks (CNNs) have emerged as
a promising framework for crack detection, offering high levels of accuracy and
precision. Additionally, the ability to adapt pre-trained networks through
transfer learning provides a valuable tool for users, eliminating the need for
an in-depth understanding of algorithm intricacies. Nevertheless, it is
imperative to acknowledge the limitations and considerations when deploying
CNNs, particularly in contexts where the outcomes carry immense significance,
such as crack detection in buildings. In this paper, our approach to surface
crack detection involves the utilization of various deep-learning models.
Specifically, we employ fine-tuning techniques on pre-trained deep learning
architectures: VGG19, ResNet50, Inception V3, and EfficientNetV2. These models
are chosen for their established performance and versatility in image analysis
tasks. We compare deep learning models using precision, recall, and F1 scores.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07128" title="Abstract">arXiv:2401.07128</a> [<a href="/pdf/2401.07128" title="Download PDF">pdf</a>, <a href="/format/2401.07128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EHRAgent: Code Empowers Large Language Models for Complex Tabular  Reasoning on Electronic Health Records
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+W">Wenqi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yuchen Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jieyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanda Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+J">Joyce Ho</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+D">May D. Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have demonstrated exceptional capabilities in
planning and tool utilization as autonomous agents, but few have been developed
for medical problem-solving. We propose EHRAgent1, an LLM agent empowered with
a code interface, to autonomously generate and execute code for complex
clinical tasks within electronic health records (EHRs). First, we formulate an
EHR question-answering task into a tool-use planning process, efficiently
decomposing a complicated task into a sequence of manageable actions. By
integrating interactive coding and execution feedback, EHRAgent learns from
error messages and improves the originally generated code through iterations.
Furthermore, we enhance the LLM agent by incorporating long-term memory, which
allows EHRAgent to effectively select and build upon the most relevant
successful cases from past experiences. Experiments on two real-world EHR
datasets show that EHRAgent outperforms the strongest LLM agent baseline by
36.48% and 12.41%, respectively. EHRAgent leverages the emerging few-shot
learning capabilities of LLMs, enabling autonomous code generation and
execution to tackle complex clinical tasks with minimal demonstrations.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07132" title="Abstract">arXiv:2401.07132</a> [<a href="/pdf/2401.07132" title="Download PDF">pdf</a>, <a href="/format/2401.07132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Mixed FEM for the Stokes eigenvalue problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boffi%2C+D">Daniele Boffi</a>, 
<a href="/search/math?searchtype=author&query=Khan%2C+A">Arbaz Khan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we discuss the optimal convergence of a standard adaptive
scheme based on mixed finite element approximation to the solution of the
eigenvalue problem associated with the Stokes equations. The proofs of the
quasi-orthogonality and the discrete reliability are presented. Our numerical
experiments confirm the efficacy of the proposed adaptive scheme.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07139" title="Abstract">arXiv:2401.07139</a> [<a href="/pdf/2401.07139" title="Download PDF">pdf</a>, <a href="/format/2401.07139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Blind Super-Resolution for Satellite Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yi Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Q">Qiangqiang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE TGRS
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Geoscience and Remote Sensing, vol. 61, pp.
  1-16, 2023, Art no. 5516316
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent efforts have witnessed remarkable progress in Satellite Video
Super-Resolution (SVSR). However, most SVSR methods usually assume the
degradation is fixed and known, e.g., bicubic downsampling, which makes them
vulnerable in real-world scenes with multiple and unknown degradations. To
alleviate this issue, blind SR has thus become a research hotspot.
Nevertheless, existing approaches are mainly engaged in blur kernel estimation
while losing sight of another critical aspect for VSR tasks: temporal
compensation, especially compensating for blurry and smooth pixels with vital
sharpness from severely degraded satellite videos. Therefore, this paper
proposes a practical Blind SVSR algorithm (BSVSR) to explore more sharp cues by
considering the pixel-wise blur levels in a coarse-to-fine manner.
Specifically, we employed multi-scale deformable convolution to coarsely
aggregate the temporal redundancy into adjacent frames by window-slid
progressive fusion. Then the adjacent features are finely merged into
mid-feature using deformable attention, which measures the blur levels of
pixels and assigns more weights to the informative pixels, thus inspiring the
representation of sharpness. Moreover, we devise a pyramid spatial
transformation module to adjust the solution space of sharp mid-feature,
resulting in flexible feature adaptation in multi-level domains. Quantitative
and qualitative evaluations on both simulated and real-world satellite videos
demonstrate that our BSVSR performs favorably against state-of-the-art
non-blind and blind SR models. Code will be available at
https://github.com/XY-boy/Blind-Satellite-VSR
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07140" title="Abstract">arXiv:2401.07140</a> [<a href="/pdf/2401.07140" title="Download PDF">pdf</a>, <a href="/ps/2401.07140" title="Download PostScript">ps</a>, <a href="/format/2401.07140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical Approximation of Riesz-Feller Operators on $\mathbb R$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cuesta%2C+C+M">Carlota M. Cuesta</a>, 
<a href="/search/math?searchtype=author&query=de+la+Hoz%2C+F">Francisco de la Hoz</a>, 
<a href="/search/math?searchtype=author&query=Girona%2C+I">Ivan Girona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 4 figures, 2 Matlab listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we develop an accurate pseudospectral method to approximate
numerically the Riesz-Feller operator $D_\gamma^\alpha$ on $\mathbb R$, where
$\alpha\in(0,2)$, and $|\gamma|\le\min\{\alpha, 2 - \alpha\}$. This operator
can be written as a linear combination of the Weyl-Marchaud derivatives
$\mathcal{D}^{\alpha}$ and $\overline{\mathcal{D}^\alpha}$, when
$\alpha\in(0,1)$, and of $\partial_x\mathcal{D}^{\alpha-1}$ and
$\partial_x\overline{\mathcal{D}^{\alpha-1}}$, when $\alpha\in(1,2)$.
<br />Given the so-called Higgins functions $\lambda_k(x) = ((ix-1)/(ix+1))^k$,
where $k\in\mathbb Z$, we compute explicitly, using complex variable
techniques, $\mathcal{D}^{\alpha}[\lambda_k](x)$,
$\overline{\mathcal{D}^\alpha}[\lambda_k](x)$,
$\partial_x\mathcal{D}^{\alpha-1}[\lambda_k](x)$,
$\partial_x\overline{\mathcal{D}^{\alpha-1}}[\lambda_k](x)$ and
$D_\gamma^\alpha[\lambda_k](x)$, in terms of the Gaussian hypergeometric
function ${}_2F_1$, and relate these results to previous ones for the
fractional Laplacian. This enables us to approximate
$\mathcal{D}^{\alpha}[u](x)$, $\overline{\mathcal{D}^\alpha}[u](x)$,
$\partial_x\mathcal{D}^{\alpha-1}[u](x)$,
$\partial_x\overline{\mathcal{D}^{\alpha-1}}[u](x)$ and
$D_\gamma^\alpha[u](x)$, for bounded continuous functions $u(x)$. Finally, we
simulate a nonlinear Riesz-Feller fractional diffusion equation, characterized
by having front propagating solutions whose speed grows exponentially in time.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07141" title="Abstract">arXiv:2401.07141</a> [<a href="/pdf/2401.07141" title="Download PDF">pdf</a>, <a href="/format/2401.07141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secrecy Coding for the Binary Symmetric Wiretap Channel via Linear  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikkhah%2C+A">Ali Nikkhah</a>, 
<a href="/search/cs?searchtype=author&query=Shoushtari%2C+M">Morteza Shoushtari</a>, 
<a href="/search/cs?searchtype=author&query=Akhbari%2C+B">Bahareh Akhbari</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+W+K">Willie K. Harrison</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible Journal publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we use a linear programming (LP) optimization approach to
evaluate the equivocation for a wiretap channel where the main channel is
noiseless, and the wiretap channel is a binary symmetric channel (BSC). Using
this technique, we present an analytical limit for the achievable secrecy rate
in the finite blocklength regime that is tighter than traditional fundamental
limits. We also propose a secrecy coding technique that outperforms random
binning codes. When there is one overhead bit, this coding technique is optimum
and achieves the analytical limit. For cases with additional bits of overhead,
our coding scheme can achieve equivocation rates close to the new limit.
Furthermore, we evaluate the patterns of the generator matrix and the
parity-check matrix for linear codes and we present binning techniques for both
linear and non-linear codes using two different approaches: recursive and
non-recursive. To our knowledge, this is the first optimization solution for
secrecy coding obtained through linear programming.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07142" title="Abstract">arXiv:2401.07142</a> [<a href="/pdf/2401.07142" title="Download PDF">pdf</a>, <a href="/format/2401.07142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAC 2.0: A Corrupt and Correct Logic Locking Technique Resilient to  Structural Analysis Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+L">Levent Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Yasin%2C+M">Muhammad Yasin</a>, 
<a href="/search/cs?searchtype=author&query=Pagliarini%2C+S">Samuel Pagliarini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Logic locking proposed to protect integrated circuits from serious hardware
threats has been studied extensively over a decade. In these years, many
efficient logic locking techniques have been proven to be broken. The
state-of-the-art logic locking techniques, including the prominent corrupt and
correct (CAC) technique, are resilient to satisfiability (SAT)-based and
removal attacks, but vulnerable to structural analysis attacks. To overcome
this drawback, this paper introduces an improved version of CAC, called CAC
2.0, which increases the search space of structural analysis attacks using
obfuscation. To do so, CAC 2.0 locks the original circuit twice, one after
another, on different nodes with different number of protected primary inputs
using CAC, while hiding original protected primary inputs among decoy primary
inputs. This paper also introduces an open source logic locking tool, called
HIID, equipped with well-known techniques including CAC 2.0. Our experiments
show that CAC 2.0 is resilient to existing SAT-based, removal, and structural
analysis attacks. To achieve this, it increases the number of key inputs at
most 4x and the gate-level area between 30.2% and 0.8% on circuits with low and
high complexity with respect to CAC.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07143" title="Abstract">arXiv:2401.07143</a> [<a href="/pdf/2401.07143" title="Download PDF">pdf</a>, <a href="/ps/2401.07143" title="Download PostScript">ps</a>, <a href="/format/2401.07143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Prognostic Malfunction Based Processor for Autonomous Landing  Guidance Assistance System Using FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+H+O">Hossam O. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Wyatt%2C+D">David Wyatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in: IEEE Access ( Volume: 12) - Page(s): 2113 - 2122
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The demand for more developed and agile urban taxi drones is increasing
rapidly nowadays to sustain crowded cities and their traffic issues. The
critical factor for spreading such technology could be related to the safety
criteria that must be considered. One of the most critical safety aspects for
such vertical and/or Short Take-Off and Landing (V/STOL) drones is related to
safety during the landing stage, in which most of the recent flight accidents
have occurred. This paper focused on solving this issue by proposing
decentralized processing cores that could improve the landing failure rate by
depending on a Fuzzy Logic System (FLS) and additional Digital Signal
Processing (DSP) elements. Also, the proposed system will enhance the safety
factor during the landing stages by adding a self-awareness feature in case a
certain sensor malfunction occurs using the proposed Adaptive Prognostic
Malfunction Unit (APMU). This proposed coarse-grained Autonomous Landing
Guidance Assistance System (ALGAS4) processing architecture has been optimized
using different optimization techniques. The ALGAS4 architecture has been
designed completely using VHDL, and the targeted FPGA was the INTEL Cyclone V
5CGXFC9D6F27C7 chip. According to the synthesis findings of the INTEL Quartus
Prime software, the maximum working frequency of the ALGAS4 system is 278.24
MHz. In addition, the proposed ALGAS4 system could maintain a maximum computing
performance of approximately 74.85 GOPS while using just 166.56 mW for dynamic
and I/O power dissipation.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07145" title="Abstract">arXiv:2401.07145</a> [<a href="/pdf/2401.07145" title="Download PDF">pdf</a>, <a href="/ps/2401.07145" title="Download PostScript">ps</a>, <a href="/format/2401.07145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable and Efficient Methods for Uncertainty Estimation and Reduction  in Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+T">Soyed Tuhin Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural networks (NNs) can achieved high performance in various fields such as
computer vision, and natural language processing. However, deploying NNs in
resource-constrained safety-critical systems has challenges due to uncertainty
in the prediction caused by out-of-distribution data, and hardware
non-idealities. To address the challenges of deploying NNs in
resource-constrained safety-critical systems, this paper summarizes the (4th
year) PhD thesis work that explores scalable and efficient methods for
uncertainty estimation and reduction in deep learning, with a focus on
Computation-in-Memory (CIM) using emerging resistive non-volatile memories. We
tackle the inherent uncertainties arising from out-of-distribution inputs and
hardware non-idealities, crucial in maintaining functional safety in automated
decision-making systems. Our approach encompasses problem-aware training
algorithms, novel NN topologies, and hardware co-design solutions, including
dropout-based \emph{binary} Bayesian Neural Networks leveraging spintronic
devices and variational inference techniques. These innovations significantly
enhance OOD data detection, inference accuracy, and energy efficiency, thereby
contributing to the reliability and robustness of NN implementations.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07147" title="Abstract">arXiv:2401.07147</a> [<a href="/pdf/2401.07147" title="Download PDF">pdf</a>, <a href="/format/2401.07147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choiceless Computation and Symmetry: Limitations of Definability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pago%2C+B">Benedikt Pago</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at CSL 2021
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 29th EACSL Annual Conference on Computer Science Logic (CSL 2021).
  Leibniz International Proceedings in Informatics (LIPIcs), Volume 183, pp.
  33:1-33:21, Schloss Dagstuhl - Leibniz-Zentrum f\"ur Informatik (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The search for a logic capturing PTIME is a long standing open problem in
finite model theory. One of the most promising candidate logics for this is
Choiceless Polynomial Time with counting (CPT). Abstractly speaking, CPT is an
isomorphism-invariant computation model working with hereditarily finite sets
as data structures. While it is easy to check that the evaluation of
CPT-sentences is possible in polynomial time, the converse has been open for
more than 20 years: Can every PTIME-decidable property of finite structures be
expressed in CPT? We attempt to make progress towards a negative answer and
show that Choiceless Polynomial Time cannot compute a preorder with colour
classes of logarithmic size in every hypercube. The reason is that such
preorders have super-polynomially many automorphic images, which makes it
impossible for CPT to define them. While the computation of such a preorder is
not a decision problem that would immediately separate P and CPT, it is
significant for the following reason: The so-called Cai-F\"urer-Immerman (CFI)
problem is one of the standard benchmarks for logics and maybe best known for
separating fixed-point logic with counting (FPC) from P. Hence, it is natural
to consider this also a potential candidate for the separation of CPT and P.
The strongest known positive result in this regard says that CPT is able to
solve CFI if a preorder with logarithmically sized colour classes is present in
the input structure. Our result implies that this approach cannot be
generalised to unordered inputs. In other words, CFI on unordered hypercubes is
a PTIME-problem which provably cannot be tackled with the state-of-the-art
choiceless algorithmic techniques.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07148" title="Abstract">arXiv:2401.07148</a> [<a href="/pdf/2401.07148" title="Download PDF">pdf</a>, <a href="/format/2401.07148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Effectiveness of Binary-Level CFI Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaidya%2C+R+K">Ruturaj K. Vaidya</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+P+A">Prasad A. Kulkarni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 9 tables, Part of this work is to be published in 16th International Symposium on Foundations &amp; Practice of Security (FPS - 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Memory corruption is an important class of vulnerability that can be
leveraged to craft control flow hijacking attacks. Control Flow Integrity (CFI)
provides protection against such attacks. Application of type-based CFI
policies requires information regarding the number and type of function
arguments. Binary-level type recovery is inherently speculative, which
motivates the need for an evaluation framework to assess the effectiveness of
binary-level CFI techniques compared with their source-level counterparts,
where such type information is fully and accurately accessible. In this work,
we develop a novel, generalized and extensible framework to assess how the
program analysis information we get from state-of-the-art binary analysis tools
affects the efficacy of type-based CFI techniques. We introduce new and
insightful metrics to quantitatively compare source independent CFI policies
with their ground truth source aware counterparts. We leverage our framework to
evaluate binary-level CFI policies implemented using program analysis
information extracted from the IDA Pro binary analyzer and compared with the
ground truth information obtained from the LLVM compiler, and present our
observations.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07154" title="Abstract">arXiv:2401.07154</a> [<a href="/pdf/2401.07154" title="Download PDF">pdf</a>, <a href="/format/2401.07154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Command and Control Channels Using Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kakkar%2C+A">Akshay Kakkar</a>, 
<a href="/search/cs?searchtype=author&query=Redino%2C+C">Christopher Redino</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Abdul Rahman</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+A">Ajinsyam S</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+R">Ryan Clark</a>, 
<a href="/search/cs?searchtype=author&query=Radke%2C+D">Daniel Radke</a>, 
<a href="/search/cs?searchtype=author&query=Cody%2C+T">Tyler Cody</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lanxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bowen%2C+E">Edward Bowen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SoutheastCon 2023. IEEE, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Command and control (C2) paths for issuing commands to malware are sometimes
the only indicators of its existence within networks. Identifying potential C2
channels is often a manually driven process that involves a deep understanding
of cyber tradecraft. Efforts to improve discovery of these channels through
using a reinforcement learning (RL) based approach that learns to automatically
carry out C2 attack campaigns on large networks, where multiple defense layers
are in place serves to drive efficiency for network operators. In this paper,
we model C2 traffic flow as a three-stage process and formulate it as a Markov
decision process (MDP) with the objective to maximize the number of valuable
hosts whose data is exfiltrated. The approach also specifically models payload
and defense mechanisms such as firewalls which is a novel contribution. The
attack paths learned by the RL agent can in turn help the blue team identify
high-priority vulnerabilities and develop improved defense strategies. The
method is evaluated on a large network with more than a thousand hosts and the
results demonstrate that the agent can effectively learn attack paths while
avoiding firewalls.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07157" title="Abstract">arXiv:2401.07157</a> [<a href="/pdf/2401.07157" title="Download PDF">pdf</a>, <a href="/ps/2401.07157" title="Download PostScript">ps</a>, <a href="/format/2401.07157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A matrix pencil approach to the Morgan&#x27;s problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vafiadis%2C+D">Dimitris Vafiadis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The problem of decoupling a nonsquare state space system by state feedback
with singular input transformation is considered. The problem is solved by
conducting a finite search for decouplable square systems, appropriately
derived from the original. Decoupling feedback on any of these systems defines
the decoupling feedback for the original. The issue of fixed poles is also
considered and the possibility of selecting the uncontrollable poles is
investigated.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07159" title="Abstract">arXiv:2401.07159</a> [<a href="/pdf/2401.07159" title="Download PDF">pdf</a>, <a href="/format/2401.07159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Oliaro%2C+G">Gabriele Oliaro</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yong Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Finetuning large language models (LLMs) has been empirically effective on a
variety of downstream tasks. Existing approaches to finetuning an LLM either
focus on parameter-efficient finetuning, which only updates a small number of
trainable parameters, or attempt to reduce the memory footprint during the
training phase of the finetuning. Typically, the memory footprint during
finetuning stems from three contributors: model weights, optimizer states, and
intermediate activations. However, existing works still require considerable
memory and none can simultaneously mitigate memory footprint for all three
sources. In this paper, we present Quantized Side Tuing (QST), which enables
memory-efficient and fast finetuning of LLMs by operating through a dual-stage
process. First, QST quantizes an LLM's model weights into 4-bit to reduce the
memory footprint of the LLM's original weights; QST also introduces a side
network separated from the LLM, which utilizes the hidden states of the LLM to
make task-specific predictions. Using a separate side network avoids performing
backpropagation through the LLM, thus reducing the memory requirement of the
intermediate activations. Furthermore, QST leverages several low-rank adaptors
and gradient-free downsample modules to significantly reduce the trainable
parameters, so as to save the memory footprint of the optimizer states.
Experiments show that QST can reduce the total memory footprint by up to 2.3
$\times$ and speed up the finetuning process by up to 3 $\times$ while
achieving competent performance compared with the state-of-the-art. When it
comes to full finetuning, QST can reduce the total memory footprint up to 7
$\times$.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07162" title="Abstract">arXiv:2401.07162</a> [<a href="/pdf/2401.07162" title="Download PDF">pdf</a>, <a href="/ps/2401.07162" title="Download PostScript">ps</a>, <a href="/format/2401.07162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pipelet: Practical Streamlined Blockchain Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karihaloo%2C+V">Vivek Karihaloo</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Ruchi Shah</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Panruo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Laszka%2C+A">Aron Laszka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Fueled by the increasing popularity of proof-of-stake blockchains, there has
been increasing interest and progress in permissioned consensus protocols,
which could provide a simpler alternative to existing protocols, such as Paxos
and PBFT. In particular, the recently proposed Streamlet protocol provides a
surprisingly simple and streamlined consensus protocol, which crystallizes
years of research in simplifying and improving classic consensus protocols.
While the simplicity of Streamlet is a major accomplishment, the protocol lacks
certain practical features, such as working without synchronized clocks and
supporting a stable block proposer, which limits its applicability. In this
paper, we strive to approach the simplicity of Streamlet and the performance of
PaLa, by introducing Pipelet, a streamlined version of the PaLa protocol. We
formally prove the consistency and liveness of the Pipelet protocol in a
partially synchronous communication model.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07163" title="Abstract">arXiv:2401.07163</a> [<a href="/pdf/2401.07163" title="Download PDF">pdf</a>, <a href="/ps/2401.07163" title="Download PostScript">ps</a>, <a href="/format/2401.07163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Method of Pixel-level In-situ U-value Measurement for Building  Envelopes Based on Infrared Thermography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yu Hou</a>, 
<a href="/search/cs?searchtype=author&query=Soibelman%2C+L">Lucio Soibelman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at 2023 ASCE International Conference on Computing in Civil Engineering (i3CE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The potential energy loss of aging buildings traps building owners in a cycle
of underfunding operations and overpaying maintenance costs. Energy auditors
intending to generate an energy model of a target building for performance
assessment may struggle to obtain accurate results as the spatial distribution
of temperatures is not considered when calculating the U-value of the building
envelope. This paper proposes a pixel-level method based on infrared
thermography (IRT) that considers two-dimensional (2D) spatial temperature
distributions of the outdoor and indoor surfaces of the target wall to generate
a 2D U-value map of the wall. The result supports that the proposed method can
better reflect the actual thermal insulation performance of the target wall
compared to the current IRT-based methods that use a single-point room
temperature as input.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07164" title="Abstract">arXiv:2401.07164</a> [<a href="/pdf/2401.07164" title="Download PDF">pdf</a>, <a href="/format/2401.07164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3QFP: Efficient neural implicit surface reconstruction using  Tri-Quadtrees and Fourier feature Positional encoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shuo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mielle%2C+M">Malcolm Mielle</a>, 
<a href="/search/cs?searchtype=author&query=Lilienthal%2C+A+J">Achim J. Lilienthal</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+M">Martin Magnusson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Neural implicit surface representations are currently receiving a lot of
interest as a means to achieve high-fidelity surface reconstruction at a low
memory cost, compared to traditional explicit representations.However,
state-of-the-art methods still struggle with excessive memory usage and
non-smooth surfaces. This is particularly problematic in large-scale
applications with sparse inputs, as is common in robotics use cases. To address
these issues, we first introduce a sparse structure, \emph{tri-quadtrees},
which represents the environment using learnable features stored in three
planar quadtree projections. Secondly, we concatenate the learnable features
with a Fourier feature positional encoding. The combined features are then
decoded into signed distance values through a small multi-layer perceptron. We
demonstrate that this approach facilitates smoother reconstruction with a
higher completion ratio with fewer holes. Compared to two recent baselines, one
implicit and one explicit, our approach requires only 10\%--50\% as much
memory, while achieving competitive quality.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07167" title="Abstract">arXiv:2401.07167</a> [<a href="/pdf/2401.07167" title="Download PDF">pdf</a>, <a href="/ps/2401.07167" title="Download PostScript">ps</a>, <a href="/format/2401.07167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polar Codes for CQ Channels: Decoding via Belief-Propagation with  Quantum Messages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+A">Avijit Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Brandsen%2C+S">S. Brandsen</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+H+D">Henry D. Pfister</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This paper considers the design and decoding of polar codes for general
classical-quantum (CQ) channels. It focuses on decoding via belief-propagation
with quantum messages (BPQM) and, in particular, the idea of paired-measurement
BPQM (PM-BPQM) decoding. Since the PM-BPQM decoder admits a classical density
evolution (DE) analysis, one can use DE to design a polar code for any CQ
channel and then efficiently compute the trade-off between code rate and error
probability. We have also implemented and tested a classical simulation of our
PM-BPQM decoder for polar codes. While the decoder can be implemented
efficiently on a quantum computer, simulating the decoder on a classical
computer actually has exponential complexity. Thus, simulation results for the
decoder are somewhat limited and are included primarily to validate our
theoretical results.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07175" title="Abstract">arXiv:2401.07175</a> [<a href="/pdf/2401.07175" title="Download PDF">pdf</a>, <a href="/format/2401.07175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Adaptation for Sustainable Soil Management using Causal and  Contrastive Constraint Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Somya Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Swati Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Padilha%2C+R">Rafael Padilha</a>, 
<a href="/search/cs?searchtype=author&query=Kiciman%2C+E">Emre Kiciman</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Ranveer Chandra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips workshop on Tackling Climate Change 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Monitoring organic matter is pivotal for maintaining soil health and can help
inform sustainable soil management practices. While sensor-based soil
information offers higher-fidelity and reliable insights into organic matter
changes, sampling and measuring sensor data is cost-prohibitive. We propose a
multi-modal, scalable framework that can estimate organic matter from remote
sensing data, a more readily available data source while leveraging sparse soil
information for improving generalization. Using the sensor data, we preserve
underlying causal relations among sensor attributes and organic matter.
Simultaneously we leverage inherent structure in the data and train the model
to discriminate among domains using contrastive learning. This causal and
contrastive constraint minimization ensures improved generalization and
adaptation to other domains. We also shed light on the interpretability of the
framework by identifying attributes that are important for improving
generalization. Identifying these key soil attributes that affect organic
matter will aid in efforts to standardize data collection efforts.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07179" title="Abstract">arXiv:2401.07179</a> [<a href="/pdf/2401.07179" title="Download PDF">pdf</a>, <a href="/format/2401.07179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting GDP in Europe with Textual Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbaglia%2C+L">Luca Barbaglia</a>, 
<a href="/search/cs?searchtype=author&query=Consoli%2C+S">Sergio Consoli</a>, 
<a href="/search/cs?searchtype=author&query=Manzan%2C+S">Sebastiano Manzan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures, published in Journal of Applied Econometrics (Early view)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We evaluate the informational content of news-based sentiment indicators for
forecasting Gross Domestic Product (GDP) and other macroeconomic variables of
the five major European economies. Our data set includes over 27 million
articles for 26 major newspapers in 5 different languages. The evidence
indicates that these sentiment indicators are significant predictors to
forecast macroeconomic variables and their predictive content is robust to
controlling for other indicators available to forecasters in real-time.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07181" title="Abstract">arXiv:2401.07181</a> [<a href="/pdf/2401.07181" title="Download PDF">pdf</a>, <a href="/format/2401.07181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning from LLM Feedback to Counteract Goal  Misgeneralization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barj%2C+H+N+E">Houda Nait El Barj</a>, 
<a href="/search/cs?searchtype=author&query=Sautory%2C+T">Theophile Sautory</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce a method to address goal misgeneralization in reinforcement
learning (RL), leveraging Large Language Model (LLM) feedback during training.
Goal misgeneralization, a type of robustness failure in RL occurs when an agent
retains its capabilities out-of-distribution yet pursues a proxy rather than
the intended one. Our approach utilizes LLMs to analyze an RL agent's policies
during training and identify potential failure scenarios. The RL agent is then
deployed in these scenarios, and a reward model is learnt through the LLM
preferences and feedback. This LLM-informed reward model is used to further
train the RL agent on the original dataset. We apply our method to a maze
navigation task, and show marked improvements in goal generalization,
especially in cases where true and proxy goals are somewhat distinguishable and
behavioral biases are pronounced. This study demonstrates how the LLM, despite
its lack of task proficiency, can efficiently supervise RL agents, providing
scalable oversight and valuable insights for enhancing goal-directed learning
in RL through the use of LLMs.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07183" title="Abstract">arXiv:2401.07183</a> [<a href="/pdf/2401.07183" title="Download PDF">pdf</a>, <a href="/format/2401.07183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Herd Behavior in Optimal Investment: A Dual-Agent Approach with  Investment Opinion and Rational Decision Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huisheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC); Mathematical Finance (q-fin.MF); Portfolio Management (q-fin.PM)

</div>
<p class="mathjax">In this paper, we study the optimal investment problem involving two agents,
where the decision of one agent is influenced by the other. To measure the
distance between two agents' decisions, we introduce the average deviation. We
formulate the stochastic optimal control problem considering herd behavior and
derive the analytical solution through the variational method. We theoretically
analyze the impact of users' herd behavior on the optimal decision by
decomposing it into their rational decisions, which is called the rational
decision decomposition. Furthermore, to quantify the preference for their
rational decision over that of the other agent, we introduce the agent's
investment opinion. Our study is validated through simulations on real stock
data.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07188" title="Abstract">arXiv:2401.07188</a> [<a href="/pdf/2401.07188" title="Download PDF">pdf</a>, <a href="/format/2401.07188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Left-right Discrepancy for Adversarial Attack on Stereo Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+X">Xiaofei Hui</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+B">Beijia Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lilith%2C+N">Nimrod Lilith</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S">Sameer Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Stereo matching neural networks often involve a Siamese structure to extract
intermediate features from left and right images. The similarity between these
intermediate left-right features significantly impacts the accuracy of
disparity estimation. In this paper, we introduce a novel adversarial attack
approach that generates perturbation noise specifically designed to maximize
the discrepancy between left and right image features. Extensive experiments
demonstrate the superior capability of our method to induce larger prediction
errors in stereo neural networks, e.g. outperforming existing state-of-the-art
attack methods by 219% MAE on the KITTI dataset and 85% MAE on the Scene Flow
dataset. Additionally, we extend our approach to include a proxy network
black-box attack method, eliminating the need for access to stereo neural
network. This method leverages an arbitrary network from a different vision
task as a proxy to generate adversarial noise, effectively causing the stereo
network to produce erroneous predictions. Our findings highlight a notable
sensitivity of stereo networks to discrepancies in shallow layer features,
offering valuable insights that could guide future research in enhancing the
robustness of stereo vision systems.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07190" title="Abstract">arXiv:2401.07190</a> [<a href="/pdf/2401.07190" title="Download PDF">pdf</a>, <a href="/format/2401.07190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inroads to a Structured Data Natural Language Bijection and the role of  LLM annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vente%2C+B">Blake Vente</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Graduate Coursework
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work finds limited evidence supporting the theory that using multiple
tasks with sequence-to-sequence transformer language models can improve
performance on some metrics. In particular, the multi-task generalist t5-small
outperforms the specialist t5-small with a $F_1$ of $0.771$ up from $0.692$,
which may point to underlying cross-task knowledge generalization. This further
suggests that even with the same network, "re-using" the same data in a
different way may lead to higher performance in some metrics. However, the
inverse task alone is likely only an optimization strategy, since it does not
yield a significant general improvement at the model sizes explored in this
work. Also, adding $\approx 4500$ LLM annotated records (interlaced with the
$12800$ WebNLG training records) does not substantially change automatic metric
performance compared to the same t5-small model without the synthetic data.
This may be due to a learning capacity bottleneck on account of model size, and
decreases observed may be due to distributional differences in the corpora.
Future research using larger models or human evaluation is required to more
fully explain the mechanisms contributing to performance on these tasks.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07193" title="Abstract">arXiv:2401.07193</a> [<a href="/pdf/2401.07193" title="Download PDF">pdf</a>, <a href="/format/2401.07193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse wave-number-dependent source problems for the Helmholtz equation  with partial information on radiating period
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hongxia Guo</a>, 
<a href="/search/math?searchtype=author&query=Hu%2C+G">Guanghui Hu</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+G">Guanqiu Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.07459">arXiv:2305.07459</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper addresses a factorization method for imaging the support of a
wave-number-dependent source function from multi-frequency data measured at a
finite pair of symmetric receivers in opposite directions. The source function
is given by the inverse Fourier transform of a compactly supported
time-dependent source whose initial moment or terminal moment for radiating is
unknown. Using the multi-frequency far-field data at two opposite observation
directions, we provide a computational criterion for characterizing the
smallest strip containing the support and perpendicular to the directions. A
new parameter is incorporated into the design of test functions for indicating
the unknown moment. The data from a finite pair of opposite directions can be
used to recover the $\Theta$-convex polygon of the support. Uniqueness in
recovering the convex hull of the support is obtained as a by-product of our
analysis using all observation directions. Similar results are also discussed
with the multi-frequency near-field data from a finite pair of observation
positions in three dimensions. We further comment on possible extensions to
source functions with two disconnected supports. Extensive numerical tests in
both two and three dimensions are implemented to show effectiveness and
feasibility of the approach. The theoretical framework explored here should be
seen as the frequency-domain analysis for inverse source problems in the time
domain.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07194" title="Abstract">arXiv:2401.07194</a> [<a href="/pdf/2401.07194" title="Download PDF">pdf</a>, <a href="/format/2401.07194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Allocation of Industry 4.0 Micro-Service Applications across  Serverless Fog Federation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hussain%2C+R+F">Razin Farhan Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Salehi%2C+M+A">Mohsen Amini Salehi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Future Generation Computer Systems (FGCS) Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The Industry 4.0 revolution has been made possible via AI-based applications
(e.g., for automation and maintenance) deployed on the serverless edge (aka
fog) computing platforms at the industrial sites -- where the data is
generated. Nevertheless, fulfilling the fault-intolerant and real-time
constraints of Industry 4.0 applications on resource-limited fog systems in
remote industrial sites (e.g., offshore oil fields) that are uncertain,
disaster-prone, and have no cloud access is challenging. It is this challenge
that our research aims at addressing. We consider the inelastic nature of the
fog systems, software architecture of the industrial applications
(micro-service-based versus monolithic), and scarcity of human experts in
remote sites. To enable cloud-like elasticity, our approach is to dynamically
and seamlessly (i.e., without human intervention) federate nearby fog systems.
Then, we develop serverless resource allocation solutions that are cognizant of
the applications' software architecture, their latency requirements, and
distributed nature of the underlying infrastructure. We propose methods to
seamlessly and optimally partition micro-service-based application across the
federated fog. Our experimental evaluation express that not only the elasticity
is overcome in a serverless manner, but also our developed application
partitioning method can serve around 20% more tasks on-time than the existing
methods in the literature.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07196" title="Abstract">arXiv:2401.07196</a> [<a href="/pdf/2401.07196" title="Download PDF">pdf</a>, <a href="/ps/2401.07196" title="Download PostScript">ps</a>, <a href="/format/2401.07196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How sharp are error bounds? --lower bounds on quadrature worst-case  errors for analytic functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goda%2C+T">Takashi Goda</a>, 
<a href="/search/math?searchtype=author&query=Kazashi%2C+Y">Yoshihito Kazashi</a>, 
<a href="/search/math?searchtype=author&query=Tanaka%2C+K">Ken&#x27;ichiro Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, no figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Numerical integration over the real line for analytic functions is studied.
Our main focus is on the sharpness of the error bounds. We first derive two
general lower estimates for the worst-case integration error, and then apply
these to establish lower bounds for various quadrature rules. These bounds turn
out to be either novel or improve upon existing results, leading to lower
bounds that closely match upper bounds for various formulas. Specifically, for
the suitably truncated trapezoidal rule, we improve upon general lower bounds
on the worst-case error obtained by Sugihara [\textit{Numer. Math.}, 75 (1997),
pp.~379--395] and provide exceptionally sharp lower bounds apart from a
polynomial factor, in particular show that the worst-case error for the
trapezoidal rule by Sugihara is not improvable more than a polynomial factor.
Additionally, our research reveals a discrepancy between the error decay of the
trapezoidal rule and Sugihara's lower bound for general numerical integration
rules, introducing a new open problem. Moreover, Gauss--Hermite quadrature is
proven sub-optimal under the decay conditions on integrands we consider, a
result not deducible from upper-bound arguments alone. Furthermore, to
establish the near-optimality of the suitably scaled Gauss--Legendre and
Clenshaw--Curtis quadratures, we generalize a recent result of Trefethen
[\textit{SIAM Rev.}, 64 (2022), pp.~132--150] for the upper error bounds in
terms of the decay conditions.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07200" title="Abstract">arXiv:2401.07200</a> [<a href="/pdf/2401.07200" title="Download PDF">pdf</a>, <a href="/format/2401.07200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Compressed Image Representation as a Perceptual Proxy: A Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen-Hsiu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Ja-Ling Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We propose an end-to-end learned image compression codec wherein the analysis
transform is jointly trained with an object classification task. This study
affirms that the compressed latent representation can predict human perceptual
distance judgments with an accuracy comparable to a custom-tailored DNN-based
quality metric. We further investigate various neural encoders and demonstrate
the effectiveness of employing the analysis transform as a perceptual loss
network for image tasks beyond quality judgments. Our experiments show that the
off-the-shelf neural encoder proves proficient in perceptual modeling without
needing an additional VGG network. We expect this research to serve as a
valuable reference developing of a semantic-aware and coding-efficient neural
encoder.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07201" title="Abstract">arXiv:2401.07201</a> [<a href="/pdf/2401.07201" title="Download PDF">pdf</a>, <a href="/ps/2401.07201" title="Download PostScript">ps</a>, <a href="/format/2401.07201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Multi-fingered Kinematic Model for Dual-arm Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2401.06610">arXiv:2401.06610</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Bimanual manipulation needs robots to be sensitive on the grasp force which
is hard to be accurately detected. This paper proposes RL framework for
enhancing the grasp quality during the bimanual manipulation. This framework is
based on finger configurations and its feedback. After that, the grasp quality
is evaluated by the reward mechanism for the hands to determine strategies.
There are 2 strategies, simultaneous and interleaved strategies, which will be
determined in this framework to manipulate objects. In this paper, the contour
and centroid of objects to the robot are unknown. Through the RL framework,
robots can perceive hand-object relation and then optimize fingers
configurations. The simulations and experiments showed that this framework can
improve the success rates and finger motion accuracy.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07205" title="Abstract">arXiv:2401.07205</a> [<a href="/pdf/2401.07205" title="Download PDF">pdf</a>, <a href="/format/2401.07205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crafter: Facial Feature Crafting against Inversion-based Identity Theft  on Deep Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhe Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liyao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinbing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chenghu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the increased capabilities at the edge (e.g., mobile device) and more
stringent privacy requirement, it becomes a recent trend for deep
learning-enabled applications to pre-process sensitive raw data at the edge and
transmit the features to the backend cloud for further processing. A typical
application is to run machine learning (ML) services on facial images collected
from different individuals. To prevent identity theft, conventional methods
commonly rely on an adversarial game-based approach to shed the identity
information from the feature. However, such methods can not defend against
adaptive attacks, in which an attacker takes a countermove against a known
defence strategy. We propose Crafter, a feature crafting mechanism deployed at
the edge, to protect the identity information from adaptive model inversion
attacks while ensuring the ML tasks are properly carried out in the cloud. The
key defence strategy is to mislead the attacker to a non-private prior from
which the attacker gains little about the private identity. In this case, the
crafted features act like poison training samples for attackers with adaptive
model updates. Experimental results indicate that Crafter successfully defends
both basic and possible adaptive attacks, which can not be achieved by
state-of-the-art adversarial game-based methods.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07207" title="Abstract">arXiv:2401.07207</a> [<a href="/pdf/2401.07207" title="Download PDF">pdf</a>, <a href="/format/2401.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Domain Adaptation Using Compact Internal Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A major technique for tackling unsupervised domain adaptation involves
mapping data points from both the source and target domains into a shared
embedding space. The mapping encoder to the embedding space is trained such
that the embedding space becomes domain agnostic, allowing a classifier trained
on the source domain to generalize well on the target domain. To further
enhance the performance of unsupervised domain adaptation (UDA), we develop an
additional technique which makes the internal distribution of the source domain
more compact, thereby improving the model's ability to generalize in the target
domain.We demonstrate that by increasing the margins between data
representations for different classes in the embedding space, we can improve
the model performance for UDA. To make the internal representation more
compact, we estimate the internally learned multi-modal distribution of the
source domain as Gaussian mixture model (GMM). Utilizing the estimated GMM, we
enhance the separation between different classes in the source domain, thereby
mitigating the effects of domain shift. We offer theoretical analysis to
support outperofrmance of our method. To evaluate the effectiveness of our
approach, we conduct experiments on widely used UDA benchmark UDA datasets. The
results indicate that our method enhances model generalizability and
outperforms existing techniques.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07208" title="Abstract">arXiv:2401.07208</a> [<a href="/pdf/2401.07208" title="Download PDF">pdf</a>, <a href="/format/2401.07208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhanced Few-Shot Class-Incremental Learning via Ensemble Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Mingli Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Baoyuan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot class-incremental learning (FSCIL) aims to continually fit new
classes with limited training data, while maintaining the performance of
previously learned classes. The main challenges are overfitting the rare new
training samples and forgetting old classes. While catastrophic forgetting has
been extensively studied, the overfitting problem has attracted less attention
in FSCIL. To tackle overfitting challenge, we design a new ensemble model
framework cooperated with data augmentation to boost generalization. In this
way, the enhanced model works as a library storing abundant features to
guarantee fast adaptation to downstream tasks. Specifically, the multi-input
multi-output ensemble structure is applied with a spatial-aware data
augmentation strategy, aiming at diversifying the feature extractor and
alleviating overfitting in incremental sessions. Moreover, self-supervised
learning is also integrated to further improve the model generalization.
Comprehensive experimental results show that the proposed method can indeed
mitigate the overfitting problem in FSCIL, and outperform the state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07209" title="Abstract">arXiv:2401.07209</a> [<a href="/pdf/2401.07209" title="Download PDF">pdf</a>, <a href="/ps/2401.07209" title="Download PostScript">ps</a>, <a href="/format/2401.07209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Visual Learning Analytics for Supporting Equity in STEM  Classrooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raza%2C+A">Ali Raza</a>, 
<a href="/search/cs?searchtype=author&query=Penuel%2C+W+R">William R. Penuel</a>, 
<a href="/search/cs?searchtype=author&query=Sumner%2C+T">Tamara Sumner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Poster Proceedings IEEE Visualization 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Supporting equitable instruction is an important issue for teachers attending
diverse STEM classrooms. Visual learning analytics along with effective student
survey measures can support providing on time feedback to teachers in making
instruction more culturally relevant to all students. We adopted a
user-centered approach, where we engaged seven middle school science teachers
in iterative testing of thirty data visualizations disaggregated over markers
such as gender and race for implementation of selected displays in a visual
learning analytics tool- Student Electronic Exit Ticket (SEET). This process
helped us gather insights into teachers' sensemaking in identifying patterns of
student data related to gender and race, selecting and improving the design of
the feedback displays for the SEET [10].
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07211" title="Abstract">arXiv:2401.07211</a> [<a href="/pdf/2401.07211" title="Download PDF">pdf</a>, <a href="/format/2401.07211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Analysis of Smartphone and Standard Tools for Touch  Perception Assessment Across Multiple Body Sites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adenekan%2C+R+A+G">Rachel A. G. Adenekan</a>, 
<a href="/search/cs?searchtype=author&query=Reyes%2C+A+G">Alejandrina Gonzalez Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+K+T">Kyle T. Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Kodali%2C+S">Sreela Kodali</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>, 
<a href="/search/cs?searchtype=author&query=Nunez%2C+C+M">Cara M. Nunez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, paper under minor revision in IEEE Transactions on Haptics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Tactile perception plays an important role in activities of daily living, and
it can be impaired in individuals with medical conditions. The most common
tools used to assess tactile sensation, the Semmes-Weinstein monofilaments and
the 128 Hz tuning fork, have poor repeatability and resolution. Long term, we
aim to provide a repeatable, high-resolution testing platform that can be used
to assess vibrotactile perception through smartphones without the need for an
experimenter to be present to conduct the test. We present a smartphone-based
vibration perception measurement platform and compare its performance to
measurements from standard monofilament and tuning fork tests. We conducted a
user study with 36 healthy adults in which we tested each tool on the hand,
wrist, and foot, to assess how well our smartphone-based vibration perception
thresholds (VPTs) detect known trends obtained from standard tests. The
smartphone platform detected statistically significant changes in VPT between
the index finger and the foot and also between the feet of younger adults and
older adults. Our smartphone-based VPT had a moderate correlation to tuning
fork-based VPT. A long-term objective of this work is to develop an accessible
smartphone-based platform that can be used to measure disease progression and
regression.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07212" title="Abstract">arXiv:2401.07212</a> [<a href="/pdf/2401.07212" title="Download PDF">pdf</a>, <a href="/format/2401.07212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiHPQ: Hierarchical Hyperbolic Product Quantization for Unsupervised  Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zexuan Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiahong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yankai Chen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Existing unsupervised deep product quantization methods primarily aim for the
increased similarity between different views of the identical image, whereas
the delicate multi-level semantic similarities preserved between images are
overlooked. Moreover, these methods predominantly focus on the Euclidean space
for computational convenience, compromising their ability to map the
multi-level semantic relationships between images effectively. To mitigate
these shortcomings, we propose a novel unsupervised product quantization method
dubbed \textbf{Hi}erarchical \textbf{H}yperbolic \textbf{P}roduct
\textbf{Q}uantization (HiHPQ), which learns quantized representations by
incorporating hierarchical semantic similarity within hyperbolic geometry.
Specifically, we propose a hyperbolic product quantizer, where the hyperbolic
codebook attention mechanism and the quantized contrastive learning on the
hyperbolic product manifold are introduced to expedite quantization.
Furthermore, we propose a hierarchical semantics learning module, designed to
enhance the distinction between similar and non-matching images for a query by
utilizing the extracted hierarchical semantics as an additional training
supervision. Experiments on benchmarks show that our proposed method
outperforms state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07213" title="Abstract">arXiv:2401.07213</a> [<a href="/pdf/2401.07213" title="Download PDF">pdf</a>, <a href="/ps/2401.07213" title="Download PostScript">ps</a>, <a href="/format/2401.07213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-agnostic Single Image Dehazing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Honglei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shaohui Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single image dehazing is a challenging ill-posed problem. Existing datasets
for training deep learning-based methods can be generated by hand-crafted or
synthetic schemes. However, the former often suffers from small scales, while
the latter forces models to learn scene depth instead of haze distribution,
decreasing their dehazing ability. To overcome the problem, we propose a simple
yet novel synthetic method to decouple the relationship between haze density
and scene depth, by which a depth-agnostic dataset (DA-HAZE) is generated.
Meanwhile, a Global Shuffle Strategy (GSS) is proposed for generating
differently scaled datasets, thereby enhancing the generalization ability of
the model. Extensive experiments indicate that models trained on DA-HAZE
achieve significant improvements on real-world benchmarks, with less
discrepancy between SOTS and DA-SOTS (the test set of DA-HAZE). Additionally,
Depth-agnostic dehazing is a more complicated task because of the lack of depth
prior. Therefore, an efficient architecture with stronger feature modeling
ability and fewer computational costs is necessary. We revisit the U-Net-based
architectures for dehazing, in which dedicatedly designed blocks are
incorporated. However, the performances of blocks are constrained by limited
feature fusion methods. To this end, we propose a Convolutional Skip Connection
(CSC) module, allowing vanilla feature fusion methods to achieve promising
results with minimal costs. Extensive experimental results demonstrate that
current state-of-the-art methods. equipped with CSC can achieve better
performance and reasonable computational expense, whether the haze distribution
is relevant to the scene depth.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07216" title="Abstract">arXiv:2401.07216</a> [<a href="/pdf/2401.07216" title="Download PDF">pdf</a>, <a href="/format/2401.07216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Walert: Putting Conversational Search Knowledge into Action by Building  and Evaluating a Large Language Model-Powered Chatbot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherumanal%2C+S+P">Sachin Pathiyan Cherumanal</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Abushaqra%2C+F+M">Futoon M. Abushaqra</a>, 
<a href="/search/cs?searchtype=author&query=de+Paula%2C+A+F+M">Angel Felipe Magnossao de Paula</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+K">Kaixin Ji</a>, 
<a href="/search/cs?searchtype=author&query=Hettiachchi%2C+D">Danula Hettiachchi</a>, 
<a href="/search/cs?searchtype=author&query=Trippas%2C+J+R">Johanne R. Trippas</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+H">Halil Ali</a>, 
<a href="/search/cs?searchtype=author&query=Scholer%2C+F">Falk Scholer</a>, 
<a href="/search/cs?searchtype=author&query=Spina%2C+D">Damiano Spina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 2024 ACM SIGIR CHIIR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Creating and deploying customized applications is crucial for operational
success and enriching user experiences in the rapidly evolving modern business
world. A prominent facet of modern user experiences is the integration of
chatbots or voice assistants. The rapid evolution of Large Language Models
(LLMs) has provided a powerful tool to build conversational applications. We
present Walert, a customized LLM-based conversational agent able to answer
frequently asked questions about computer science degrees and programs at RMIT
University. Our demo aims to showcase how conversational information-seeking
researchers can effectively communicate the benefits of using best practices to
stakeholders interested in developing and deploying LLM-based chatbots. These
practices are well-known in our community but often overlooked by practitioners
who may not have access to this knowledge. The methodology and resources used
in this demo serve as a bridge to facilitate knowledge transfer from experts,
address industry professionals' practical needs, and foster a collaborative
environment. The data and code of the demo are available at
https://github.com/rmit-ir/walert.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07218" title="Abstract">arXiv:2401.07218</a> [<a href="/pdf/2401.07218" title="Download PDF">pdf</a>, <a href="/format/2401.07218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Event-based Monocular Depth Estimation using Cross-modal  Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lina Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bofeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+F">Feng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wanlong Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IROS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">An event camera is a novel vision sensor that can capture per-pixel
brightness changes and output a stream of asynchronous ``events''. It has
advantages over conventional cameras in those scenes with high-speed motions
and challenging lighting conditions because of the high temporal resolution,
high dynamic range, low bandwidth, low power consumption, and no motion blur.
Therefore, several supervised monocular depth estimation from events is
proposed to address scenes difficult for conventional cameras. However, depth
annotation is costly and time-consuming. In this paper, to lower the annotation
cost, we propose a self-supervised event-based monocular depth estimation
framework named EMoDepth. EMoDepth constrains the training process using the
cross-modal consistency from intensity frames that are aligned with events in
the pixel coordinate. Moreover, in inference, only events are used for
monocular depth prediction. Additionally, we design a multi-scale
skip-connection architecture to effectively fuse features for depth estimation
while maintaining high inference speed. Experiments on MVSEC and DSEC datasets
demonstrate that our contributions are effective and that the accuracy can
outperform existing supervised event-based and unsupervised frame-based
methods.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07220" title="Abstract">arXiv:2401.07220</a> [<a href="/pdf/2401.07220" title="Download PDF">pdf</a>, <a href="/ps/2401.07220" title="Download PostScript">ps</a>, <a href="/format/2401.07220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of 2D Homography for High Resolution Traffic Data Collection  using CCTV Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Daud%2C+A">Abdulateef Daud</a>, 
<a href="/search/cs?searchtype=author&query=Mussah%2C+A+R">Abdul Rashid Mussah</a>, 
<a href="/search/cs?searchtype=author&query=Adu-Gyamfi%2C+Y">Yaw Adu-Gyamfi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 9 figures, this paper was submitted for consideration for presentation at the 102nd Annual Meeting of the Transportation Research Board, January 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic cameras remain the primary source data for surveillance activities
such as congestion and incident monitoring. To date, State agencies continue to
rely on manual effort to extract data from networked cameras due to limitations
of the current automatic vision systems including requirements for complex
camera calibration and inability to generate high resolution data. This study
implements a three-stage video analytics framework for extracting
high-resolution traffic data such vehicle counts, speed, and acceleration from
infrastructure-mounted CCTV cameras. The key components of the framework
include object recognition, perspective transformation, and vehicle trajectory
reconstruction for traffic data collection. First, a state-of-the-art vehicle
recognition model is implemented to detect and classify vehicles. Next, to
correct for camera distortion and reduce partial occlusion, an algorithm
inspired by two-point linear perspective is utilized to extracts the region of
interest (ROI) automatically, while a 2D homography technique transforms the
CCTV view to bird's-eye view (BEV). Cameras are calibrated with a two-layer
matrix system to enable the extraction of speed and acceleration by converting
image coordinates to real-world measurements. Individual vehicle trajectories
are constructed and compared in BEV using two time-space-feature-based object
trackers, namely Motpy and BYTETrack. The results of the current study showed
about +/- 4.5% error rate for directional traffic counts, less than 10% MSE for
speed bias between camera estimates in comparison to estimates from probe data
sources. Extracting high-resolution data from traffic cameras has several
implications, ranging from improvements in traffic management and identify
dangerous driving behavior, high-risk areas for accidents, and other safety
concerns, enabling proactive measures to reduce accidents and fatalities.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07222" title="Abstract">arXiv:2401.07222</a> [<a href="/pdf/2401.07222" title="Download PDF">pdf</a>, <a href="/ps/2401.07222" title="Download PostScript">ps</a>, <a href="/format/2401.07222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Data-Driven Predictive Control for Unknown Linear Time-Invariant  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+K">Kaijian Hu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+T">Tao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents a new robust data-driven predictive control scheme for
unknown linear time-invariant systems by using input-state-output or
input-output data based on whether the state is measurable. To remove the need
for the persistently exciting (PE) condition of a sufficiently high order on
pre-collected data, a set containing all systems capable of generating such
data is constructed. Then, at each time step, an upper bound of a given
objective function is derived for all systems in the set, and a feedback
controller is designed to minimize this bound. The optimal control gain at each
time step is determined by solving a set of linear matrix inequalities. We
prove that if the synthesis problem is feasible at the initial time step, it
remains feasible for all future time steps. Unlike current data-driven
predictive control schemes based on behavioral system theory, our approach
requires less stringent conditions for the pre-collected data, facilitating
easier implementation. Further, the proposed predictive control scheme features
an infinite prediction horizon, potentially resulting in superior overall
control performance compared to existing methods with finite prediction
horizons. The effectiveness of our proposed methods is demonstrated through
application to an unknown and unstable batch reactor.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07224" title="Abstract">arXiv:2401.07224</a> [<a href="/pdf/2401.07224" title="Download PDF">pdf</a>, <a href="/format/2401.07224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vehicle Selection for C-V2X Mode 4 Based Federated Edge Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+P">Pingyi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Q">Qiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Huiling Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been submitted to IEEE Systems Journal. The source code has been released at: <a href="https://github.com/qiongwu86/Vehicle-selection-for-C-V2X.git">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Federated learning (FL) is a promising technology for vehicular networks to
protect vehicles' privacy in Internet of Vehicles (IoV). Vehicles with limited
computation capacity may face a large computational burden associated with FL.
Federated edge learning (FEEL) systems are introduced to solve such a problem.
In FEEL systems, vehicles adopt the cellular-vehicle to everything (C-V2X) mode
4 to upload encrypted data to road side units' (RSUs)' cache queue. Then RSUs
train the data transmitted by vehicles, update the locally model
hyperparameters and send back results to vehicles, thus vehicles' computational
burden can be released. However, each RSU has limited cache queue. To maintain
the stability of cache queue and maximize the accuracy of model, it is
essential to select appropriate vehicles to upload data. The vehicle selection
method for FEEL systems faces challenges due to the random departure of data
from the cache queue caused by the stochastic channel and the different system
status of vehicles, such as remaining data amount, transmission delay, packet
collision probability and survival ability. This paper proposes a vehicle
selection method for FEEL systems that aims to maximize the accuracy of model
while keeping the cache queue stable. Extensive simulation experiments
demonstrate that our proposed method outperforms other baseline selection
methods.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07228" title="Abstract">arXiv:2401.07228</a> [<a href="/pdf/2401.07228" title="Download PDF">pdf</a>, <a href="/format/2401.07228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lawson-time-splitting extended Fourier pseudospectral method for the  Gross-Pitaevskii equation with time-dependent low regularity potential
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+B">Bo Lin</a>, 
<a href="/search/math?searchtype=author&query=Ma%2C+Y">Ying Ma</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+C">Chushan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a Lawson-time-splitting extended Fourier pseudospectral (LTSeFP)
method for the numerical integration of the Gross-Pitaevskii equation with
time-dependent potential that is of low regularity in space. For the spatial
discretization of low regularity potential, we use an extended Fourier
pseudospectral (eFP) method, i.e., we compute the discrete Fourier transform of
the low regularity potential in an extended window. For the temporal
discretization, to efficiently implement the eFP method for time-dependent low
regularity potential, we combine the standard time-splitting method with a
Lawson-type exponential integrator to integrate potential and nonlinearity
differently. The LTSeFP method is both accurate and efficient: it achieves
first-order convergence in time and optimal-order convergence in space in
$L^2$-norm under low regularity potential, while the computational cost is
comparable to the standard time-splitting Fourier pseudospectral method.
Theoretically, we also prove such convergence orders for a large class of
spatially low regularity time-dependent potential. Extensive numerical results
are reported to confirm the error estimates and to demonstrate the superiority
of our method.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07230" title="Abstract">arXiv:2401.07230</a> [<a href="/pdf/2401.07230" title="Download PDF">pdf</a>, <a href="/format/2401.07230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Emotional Disclosure via Diary-keeping in Quarantine on  Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yue Deng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Changyang He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, In Proceedings of The Eleventh International Symposium of Chinese CHI (Chinese CHI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Quarantine is a widely-adopted measure during health crises caused by
highly-contagious diseases like COVID-19, yet it poses critical challenges to
public mental health. Given this context, emotional disclosure on social media
in the form of keeping a diary emerges as a popular way for individuals to
express emotions and record their mental health status. However, the
exploration of emotional disclosure via diary-keeping on social media during
quarantine is underexplored, understanding which could be beneficial to
facilitate emotional connections and enlighten health intervention measures.
Focusing on this particular form of self-disclosure, this work proposes a
quantitative approach to figure out the prevalence and changing patterns of
emotional disclosure during quarantine, and the possible factors contributing
to the negative emotions. We collected 58, 796 posts with the "Quarantine
Diary" keyword on Weibo, a popular social media website in China. Through text
classification, we capture diverse emotion categories that characterize public
emotion disclosure during quarantine, such as annoyed, anxious, boring, happy,
hopeful and appreciative. Based on temporal analysis, we uncover the changing
patterns of emotional disclosure from long-term perspectives and period-based
perspectives (e.g., the gradual decline of all negative emotions and the
upsurge of the annoyed emotion near the end of quarantine). Leveraging topic
modeling, we also encapsulate the possible influencing factors of negative
emotions, such as freedom restriction and solitude, and uncertainty of
infection and supply. We reflect on how our findings could deepen the
understanding of mental health on social media and further provide practical
and design implications to mitigate mental health issues during quarantine.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07231" title="Abstract">arXiv:2401.07231</a> [<a href="/pdf/2401.07231" title="Download PDF">pdf</a>, <a href="/format/2401.07231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of Prior Knowledge to Discover Causal Additive Models with  Unobserved Variables and its Application to Time Series Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maeda%2C+T+N">Takashi Nicholas Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Shohei%2C+S">Shimizu Shohei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper proposes two methods for causal additive models with unobserved
variables (CAM-UV). CAM-UV assumes that the causal functions take the form of
generalized additive models and that latent confounders are present. First, we
propose a method that leverages prior knowledge for efficient causal discovery.
Then, we propose an extension of this method for inferring causality in time
series data. The original CAM-UV algorithm differs from other existing causal
function models in that it does not seek the causal order between observed
variables, but rather aims to identify the causes for each observed variable.
Therefore, the first proposed method in this paper utilizes prior knowledge,
such as understanding that certain variables cannot be causes of specific
others. Moreover, by incorporating the prior knowledge that causes precedes
their effects in time, we extend the first algorithm to the second method for
causal discovery in time series data. We validate the first proposed method by
using simulated data to demonstrate that the accuracy of causal discovery
increases as more prior knowledge is accumulated. Additionally, we test the
second proposed method by comparing it with existing time series causal
discovery methods, using both simulated data and real-world data.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07234" title="Abstract">arXiv:2401.07234</a> [<a href="/pdf/2401.07234" title="Download PDF">pdf</a>, <a href="/format/2401.07234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effects of Data Imbalance Under a Federated Learning Approach for  Credit Risk Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+J">Jordan Tay</a>, 
<a href="/search/cs?searchtype=author&query=Baiz%2C+P">Pedro Baiz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Credit risk forecasting plays a crucial role for commercial banks and other
financial institutions in granting loans to customers and minimise the
potential loss. However, traditional machine learning methods require the
sharing of sensitive client information with an external server to build a
global model, potentially posing a risk of security threats and privacy
leakage. A newly developed privacy-preserving distributed machine learning
technique known as Federated Learning (FL) allows the training of a global
model without the necessity of accessing private local data directly. This
investigation examined the feasibility of federated learning in credit risk
assessment and showed the effects of data imbalance on model performance. Two
neural network architectures, Multilayer Perceptron (MLP) and Long Short-Term
Memory (LSTM), and one tree ensemble architecture, Extreme Gradient Boosting
(XGBoost), were explored across three different datasets under various
scenarios involving different numbers of clients and data distribution
configurations. We demonstrate that federated models consistently outperform
local models on non-dominant clients with smaller datasets. This trend is
especially pronounced in highly imbalanced data scenarios, yielding a
remarkable average improvement of 17.92% in model performance. However, for
dominant clients (clients with more data), federated models may not exhibit
superior performance, suggesting the need for special incentives for this type
of clients to encourage their participation.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07237" title="Abstract">arXiv:2401.07237</a> [<a href="/pdf/2401.07237" title="Download PDF">pdf</a>, <a href="/format/2401.07237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Event Sequence Knowledge From Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wadhwa%2C+S">Somin Wadhwa</a>, 
<a href="/search/cs?searchtype=author&query=Hassanzadeh%2C+O">Oktie Hassanzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharjya%2C+D">Debarun Bhattacharjya</a>, 
<a href="/search/cs?searchtype=author&query=Barker%2C+K">Ken Barker</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jian Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Event sequence models have been found to be highly effective in the analysis
and prediction of events. Building such models requires availability of
abundant high-quality event sequence data. In certain applications, however,
clean structured event sequences are not available, and automated sequence
extraction results in data that is too noisy and incomplete. In this work, we
explore the use of Large Language Models (LLMs) to generate event sequences
that can effectively be used for probabilistic event model construction. This
can be viewed as a mechanism of distilling event sequence knowledge from LLMs.
Our approach relies on a Knowledge Graph (KG) of event concepts with partial
causal relations to guide the generative language model for causal event
sequence generation. We show that our approach can generate high-quality event
sequences, filling a knowledge gap in the input KG. Furthermore, we explore how
the generated sequences can be leveraged to discover useful and more complex
structured knowledge from pattern mining and probabilistic event models. We
release our sequence generation code and evaluation framework, as well as
corpus of event sequence data.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07240" title="Abstract">arXiv:2401.07240</a> [<a href="/pdf/2401.07240" title="Download PDF">pdf</a>, <a href="/format/2401.07240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCDet: Dynamic Cross-based 3D Object Detector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhiyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, significant progress has been made in the research of 3D object
detection. However, most prior studies have focused on the utilization of
center-based or anchor-based label assignment schemes. Alternative label
assignment strategies remain unexplored in 3D object detection. We find that
the center-based label assignment often fails to generate sufficient positive
samples for training, while the anchor-based label assignment tends to
encounter an imbalanced issue when handling objects of varying scales. To solve
these issues, we introduce a dynamic cross label assignment (DCLA) scheme,
which dynamically assigns positive samples for each object from a cross-shaped
region, thus providing sufficient and balanced positive samples for training.
Furthermore, to address the challenge of accurately regressing objects with
varying scales, we put forth a rotation-weighted Intersection over Union
(RWIoU) metric to replace the widely used L1 metric in regression loss.
Extensive experiments demonstrate the generality and effectiveness of our DCLA
and RWIoU-based regression loss. The Code will be available at
https://github.com/Say2L/DCDet.git.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07242" title="Abstract">arXiv:2401.07242</a> [<a href="/pdf/2401.07242" title="Download PDF">pdf</a>, <a href="/ps/2401.07242" title="Download PostScript">ps</a>, <a href="/format/2401.07242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing Sumsets is Hard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nadimpalli%2C+S">Shivam Nadimpalli</a>, 
<a href="/search/cs?searchtype=author&query=Randolph%2C+T">Tim Randolph</a>, 
<a href="/search/cs?searchtype=author&query=Servedio%2C+R+A">Rocco A. Servedio</a>, 
<a href="/search/cs?searchtype=author&query=Zamir%2C+O">Or Zamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
<p class="mathjax">A subset $S$ of the Boolean hypercube $\mathbb{F}_2^n$ is a *sumset* if $S =
\{a + b : a, b\in A\}$ for some $A \subseteq \mathbb{F}_2^n$. Sumsets are
central objects of study in additive combinatorics, featuring in several
influential results. We prove a lower bound of $\Omega(2^{n/2})$ for the number
of queries needed to test whether a Boolean function $f:\mathbb{F}_2^n \to
\{0,1\}$ is the indicator function of a sumset. Our lower bound for testing
sumsets follows from sharp bounds on the related problem of *shift testing*,
which may be of independent interest. We also give a near-optimal {$2^{O(n/2)}
\cdot \mathrm{poly}(n)$}-query algorithm for a smoothed analysis formulation of
the sumset *refutation* problem.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07245" title="Abstract">arXiv:2401.07245</a> [<a href="/pdf/2401.07245" title="Download PDF">pdf</a>, <a href="/format/2401.07245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIMIC: Mask Image Pre-training with Mix Contrastive Fine-tuning for  Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaobao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaojiang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A">Alex Kot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cutting-edge research in facial expression recognition (FER) currently favors
the utilization of convolutional neural networks (CNNs) backbone which is
supervisedly pre-trained on face recognition datasets for feature extraction.
However, due to the vast scale of face recognition datasets and the high cost
associated with collecting facial labels, this pre-training paradigm incurs
significant expenses. Towards this end, we propose to pre-train vision
Transformers (ViTs) through a self-supervised approach on a mid-scale general
image dataset. In addition, when compared with the domain disparity existing
between face datasets and FER datasets, the divergence between general datasets
and FER datasets is more pronounced. Therefore, we propose a contrastive
fine-tuning approach to effectively mitigate this domain disparity.
Specifically, we introduce a novel FER training paradigm named Mask Image
pre-training with MIx Contrastive fine-tuning (MIMIC). In the initial phase, we
pre-train the ViT via masked image reconstruction on general images.
Subsequently, in the fine-tuning stage, we introduce a mix-supervised
contrastive learning process, which enhances the model with a more extensive
range of positive samples by the mixing strategy. Through extensive experiments
conducted on three benchmark datasets, we demonstrate that our MIMIC
outperforms the previous training paradigm, showing its capability to learn
better representations. Remarkably, the results indicate that the vanilla ViT
can achieve impressive performance without the need for intricate,
auxiliary-designed modules. Moreover, when scaling up the model size, MIMIC
exhibits no performance saturation and is superior to the current
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07246" title="Abstract">arXiv:2401.07246</a> [<a href="/pdf/2401.07246" title="Download PDF">pdf</a>, <a href="/ps/2401.07246" title="Download PostScript">ps</a>, <a href="/format/2401.07246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delayed finite-dimensional observer-based control of 2D linear parabolic  PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Fridman%2C+E">Emilia Fridman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Recently, a constructive method was suggested for finite-dimensional
observer-based control of 1D linear heat equation, which is robust to
input/output delays. In this paper, we aim to extend this method to the 2D case
with general time-varying input/output delays (known output delay and unknown
input delay) or sawtooth delays (that correspond to network-based control). We
use the modal decomposition approach and consider boundary or non-local sensing
together with non-local actuation, or Neumann actuation with non-local sensing.
To compensate the output delay that appears in the infinite-dimensional part of
the closed-loop system, for the first time for delayed PDEs we suggest a vector
Lyapunov functional combined with the recently introduced vector Halanay
inequality. We provide linear matrix inequality (LMI) conditions for finding
the observer dimension and upper bounds on delays that preserve the exponential
stability. We prove that the LMIs are always feasible for large enough observer
dimension and small enough upper bounds on delays. A numerical example
demonstrates the efficiency of our method and shows that the employment of
vector Halanay's inequality allows for larger delays than the classical scalar
Halanay inequality for comparatively large observer dimension.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07249" title="Abstract">arXiv:2401.07249</a> [<a href="/pdf/2401.07249" title="Download PDF">pdf</a>, <a href="/format/2401.07249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imputation with Inter-Series Information from Prototypes for Irregular  Sampled Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liantao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenwu Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Irregularly sampled time series are ubiquitous, presenting significant
challenges for analysis due to missing values. Despite existing methods address
imputation, they predominantly focus on leveraging intra-series information,
neglecting the potential benefits that inter-series information could provide,
such as reducing uncertainty and memorization effect. To bridge this gap, we
propose PRIME, a Prototype Recurrent Imputation ModEl, which integrates both
intra-series and inter-series information for imputing missing values in
irregularly sampled time series. Our framework comprises a prototype memory
module for learning inter-series information, a bidirectional gated recurrent
unit utilizing prototype information for imputation, and an attentive
prototypical refinement module for adjusting imputations. We conducted
extensive experiments on three datasets, and the results underscore PRIME's
superiority over the state-of-the-art models by up to 26% relative improvement
on mean square error.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07250" title="Abstract">arXiv:2401.07250</a> [<a href="/pdf/2401.07250" title="Download PDF">pdf</a>, <a href="/format/2401.07250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stabilizing Sharpness-aware Minimization Through A Simple  Renormalization Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chengli Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiangshe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junmin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yunda Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, sharpness-aware minimization (SAM) has attracted a lot of attention
because of its surprising effectiveness in improving generalization
performance.However, training neural networks with SAM can be highly unstable
since the loss does not decrease along the direction of the exact gradient at
the current point, but instead follows the direction of a surrogate gradient
evaluated at another point nearby. To address this issue, we propose a simple
renormalization strategy, dubbed StableSAM, so that the norm of the surrogate
gradient maintains the same as that of the exact gradient. Our strategy is easy
to implement and flexible enough to integrate with SAM and its variants, almost
at no computational cost. With elementary tools from convex optimization and
learning theory, we also conduct a theoretical analysis of sharpness-aware
training, revealing that compared to stochastic gradient descent (SGD), the
effectiveness of SAM is only assured in a limited regime of learning rate. In
contrast, we show how StableSAM extends this regime of learning rate and when
it can consistently perform better than SAM with minor modification. Finally,
we demonstrate the improved performance of StableSAM on several representative
data sets and tasks.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07251" title="Abstract">arXiv:2401.07251</a> [<a href="/pdf/2401.07251" title="Download PDF">pdf</a>, <a href="/format/2401.07251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Landmark Detection on Human Point Clouds: A Benchmark and A Dual  Cascade Point Transformer Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shuyi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiaojiang Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D landmark detection plays a pivotal role in various applications such as 3D
registration, pose estimation, and virtual try-on. While considerable success
has been achieved in 2D human landmark detection or pose estimation, there is a
notable scarcity of reported works on landmark detection in unordered 3D point
clouds. This paper introduces a novel challenge, namely 3D landmark detection
on human point clouds, presenting two primary contributions. Firstly, we
establish a comprehensive human point cloud dataset, named HPoint103, designed
to support the 3D landmark detection community. This dataset comprises 103
human point clouds created with commercial software and actors, each manually
annotated with 11 stable landmarks. Secondly, we propose a Dual Cascade Point
Transformer (D-CPT) model for precise point-based landmark detection. D-CPT
gradually refines the landmarks through cascade Transformer decoder layers
across the entire point cloud stream, simultaneously enhancing landmark
coordinates with a RefineNet over local regions. Comparative evaluations with
popular point-based methods on HPoint103 and the public dataset DHP19
demonstrate the dramatic outperformance of our D-CPT. Additionally, the
integration of our RefineNet into existing methods consistently improves
performance.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07255" title="Abstract">arXiv:2401.07255</a> [<a href="/pdf/2401.07255" title="Download PDF">pdf</a>, <a href="/format/2401.07255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust from Ethical Point of View: Exploring Dynamics Through  Multiagent-Driven Cognitive Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tariverdi%2C+A">Abbas Tariverdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
<p class="mathjax">The paper begins by exploring the rationality of ethical trust as a
foundational concept. This involves distinguishing between trust and
trustworthiness and delving into scenarios where trust is both rational and
moral. It lays the groundwork for understanding the complexities of trust
dynamics in decision-making scenarios. Following this theoretical groundwork,
we introduce an agent-based simulation framework that investigates these
dynamics of ethical trust, specifically in the context of a disaster response
scenario. These agents, utilizing emotional models like Plutchik's Wheel of
Emotions and memory learning mechanisms, are tasked with allocating limited
resources in disaster-affected areas. The model, which embodies the principles
discussed in the first section, integrates cognitive load management, Big Five
personality traits, and structured interactions within networked or
hierarchical settings. It also includes feedback loops and simulates external
events to evaluate their impact on the formation and evolution of trust among
agents. Through our simulations, we demonstrate the intricate interplay of
cognitive, emotional, and social factors in ethical decision-making. These
insights shed light on the behaviors and resilience of trust networks in crisis
situations, emphasizing the role of rational and moral considerations in the
development of trust among autonomous agents. This study contributes to the
field by offering an understanding of trust dynamics in socio-technical systems
and by providing a robust, adaptable framework capable of addressing ethical
dilemmas in disaster response and beyond. The implementation of the algorithms
presented in this paper is available at this GitHub repository:
\url{https://github.com/abbas-tari/ethical-trust-cognitive-modeling}.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07256" title="Abstract">arXiv:2401.07256</a> [<a href="/pdf/2401.07256" title="Download PDF">pdf</a>, <a href="/format/2401.07256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergency Localization for Mobile Ground Users: An Adaptive UAV  Trajectory Planning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiafan He</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Luyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lianming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wendi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">In emergency search and rescue scenarios, the quick location of trapped
people is essential. However, disasters can render the Global Positioning
System (GPS) unusable. Unmanned aerial vehicles (UAVs) with localization
devices can serve as mobile anchors due to their agility and high line-of-sight
(LoS) probability. Nonetheless, the number of available UAVs during the initial
stages of disaster relief is limited, and innovative methods are needed to
quickly plan UAV trajectories to locate non-uniformly distributed dynamic
targets while ensuring localization accuracy. To address this challenge, we
design a single UAV localization method without hovering, use the maximum
likelihood estimation (MLE) method to estimate the location of mobile users and
define the upper bound of the localization error by considering users'
movement.Combining this localization method and localization error-index, we
utilize the enhanced particle swarm optimization (EPSO) algorithm and edge
access strategy to develop a low complexity localization-oriented adaptive
trajectory planning algorithm. Simulation results demonstrate that our method
outperforms other baseline algorithms, enabling faster localization without
compromising localization accuracy.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07257" title="Abstract">arXiv:2401.07257</a> [<a href="/pdf/2401.07257" title="Download PDF">pdf</a>, <a href="/format/2401.07257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightweight Modality Adaptation to Sequential Recommendation via  Correlation Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hengchang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qijiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kan%2C+M">Min-Yen Kan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In Sequential Recommenders (SR), encoding and utilizing modalities in an
end-to-end manner is costly in terms of modality encoder sizes. Two-stage
approaches can mitigate such concerns, but they suffer from poor performance
due to modality forgetting, where the sequential objective overshadows modality
representation. We propose a lightweight knowledge distillation solution that
preserves both merits: retaining modality information and maintaining high
efficiency. Specifically, we introduce a novel method that enhances the
learning of embeddings in SR through the supervision of modality correlations.
The supervision signals are distilled from the original modality
representations, including both (1) holistic correlations, which quantify their
overall associations, and (2) dissected correlation types, which refine their
relationship facets (honing in on specific aspects like color or shape
consistency). To further address the issue of modality forgetting, we propose
an asynchronous learning step, allowing the original information to be retained
longer for training the representation learning module. Our approach is
compatible with various backbone architectures and outperforms the top
baselines by 6.8% on average. We empirically demonstrate that preserving
original feature associations from modality encoders significantly boosts
task-specific recommendation adaptation. Additionally, we find that larger
modality encoders (e.g., Large Language Models) contain richer feature sets
which necessitate more fine-grained modeling to reach their full performance
potential.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07261" title="Abstract">arXiv:2401.07261</a> [<a href="/pdf/2401.07261" title="Download PDF">pdf</a>, <a href="/format/2401.07261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LookAhead: Preventing DeFi Attacks via Unveiling Adversarial Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shoupeng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+T">Tianyu Tu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">DeFi incidents stemming from various smart contract vulnerabilities have
culminated in financial damages exceeding 3 billion USD. The attacks causing
such incidents commonly commence with the deployment of adversarial contracts,
subsequently leveraging these contracts to execute adversarial transactions
that exploit vulnerabilities in victim contracts. Existing defense mechanisms
leverage heuristic or machine learning algorithms to detect adversarial
transactions, but they face significant challenges in detecting private
adversarial transactions. Namely, attackers can send adversarial transactions
directly to miners, evading visibility within the blockchain network and
effectively bypassing the detection. In this paper, we propose a new direction
for detecting DeFi attacks, i.e., detecting adversarial contracts instead of
adversarial transactions, allowing us to proactively identify potential attack
intentions, even if they employ private adversarial transactions. Specifically,
we observe that most adversarial contracts follow a similar pattern, e.g.,
anonymous fund source, closed-source, frequent token-related function calls.
Based on this observation, we build a machine learning classifier that can
effectively distinguish adversarial contracts from benign ones. We build a
dataset consists of features extracted from 304 adversarial contracts and
13,000 benign contracts. Based on this dataset, we evaluate different
classifiers, the results of which show that our method for identifying DeFi
adversarial contracts performs exceptionally well. For example, the F1-Score
for LightGBM-based classifier is 0.9434, with a remarkably low false positive
rate of only 0.12%.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07263" title="Abstract">arXiv:2401.07263</a> [<a href="/pdf/2401.07263" title="Download PDF">pdf</a>, <a href="/format/2401.07263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BET: Explaining Deep Reinforcement Learning through The Error-Prone  Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wubing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Mao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yongxing Su</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an early version of a paper that submitted to IJCAI 2024 8 pages, 4 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite the impressive capabilities of Deep Reinforcement Learning (DRL)
agents in many challenging scenarios, their black-box decision-making process
significantly limits their deployment in safety-sensitive domains. Several
previous self-interpretable works focus on revealing the critical states of the
agent's decision. However, they cannot pinpoint the error-prone states. To
address this issue, we propose a novel self-interpretable structure, named
Backbone Extract Tree (BET), to better explain the agent's behavior by identify
the error-prone states. At a high level, BET hypothesizes that states in which
the agent consistently executes uniform decisions exhibit a reduced propensity
for errors. To effectively model this phenomenon, BET expresses these states
within neighborhoods, each defined by a curated set of representative states.
Therefore, states positioned at a greater distance from these representative
benchmarks are more prone to error. We evaluate BET in various popular RL
environments and show its superiority over existing self-interpretable models
in terms of explanation fidelity. Furthermore, we demonstrate a use case for
providing explanations for the agents in StarCraft II, a sophisticated
multi-agent cooperative game. To the best of our knowledge, we are the first to
explain such a complex scenarios using a fully transparent structure.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07271" title="Abstract">arXiv:2401.07271</a> [<a href="/pdf/2401.07271" title="Download PDF">pdf</a>, <a href="/format/2401.07271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpineCLUE: Automatic Vertebrae Identification Using Contrastive Learning  and Uncertainty Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Junxian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tonglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+C">Cheng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+Y">Youyong Kong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Vertebrae identification in arbitrary fields-of-view plays a crucial role in
diagnosing spine disease. Most spine CT contain only local regions, such as the
neck, chest, and abdomen. Therefore, identification should not depend on
specific vertebrae or a particular number of vertebrae being visible. Existing
methods at the spine-level are unable to meet this challenge. In this paper, we
propose a three-stage method to address the challenges in 3D CT vertebrae
identification at vertebrae-level. By sequentially performing the tasks of
vertebrae localization, segmentation, and identification, the anatomical prior
information of the vertebrae is effectively utilized throughout the process.
Specifically, we introduce a dual-factor density clustering algorithm to
acquire localization information for individual vertebra, thereby facilitating
subsequent segmentation and identification processes. In addition, to tackle
the issue of interclass similarity and intra-class variability, we pre-train
our identification network by using a supervised contrastive learning method.
To further optimize the identification results, we estimated the uncertainty of
the classification network and utilized the message fusion module to combine
the uncertainty scores, while aggregating global information about the spine.
Our method achieves state-of-the-art results on the VerSe19 and VerSe20
challenge benchmarks. Additionally, our approach demonstrates outstanding
generalization performance on an collected dataset containing a wide range of
abnormal cases.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07272" title="Abstract">arXiv:2401.07272</a> [<a href="/pdf/2401.07272" title="Download PDF">pdf</a>, <a href="/format/2401.07272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> City Scene Super-Resolution via Geometric Error Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhengyang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Super-resolution techniques are crucial in improving image granularity,
particularly in complex urban scenes, where preserving geometric structures is
vital for data-informed cultural heritage applications. In this paper, we
propose a city scene super-resolution method via geometric error minimization.
The geometric-consistent mechanism leverages the Hough Transform to extract
regular geometric features in city scenes, enabling the computation of
geometric errors between low-resolution and high-resolution images. By
minimizing mixed mean square error and geometric align error during the
super-resolution process, the proposed method efficiently restores details and
geometric regularities. Extensive validations on the SET14, BSD300, Cityscapes
and GSV-Cities datasets demonstrate that the proposed method outperforms
existing state-of-the-art methods, especially in urban scenes.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07278" title="Abstract">arXiv:2401.07278</a> [<a href="/pdf/2401.07278" title="Download PDF">pdf</a>, <a href="/format/2401.07278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Semantic Segmentation using Redesigned Self-Training for  White Blood Cel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luu%2C+V+Q">Vinh Quoc Luu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D+K">Duy Khanh Le</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+T">Huy Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+T">Minh Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T+T">Thinh Tien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dinh%2C+V+Q">Vinh Quang Dinh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence (AI) in healthcare, especially in white blood cell
cancer diagnosis, is hindered by two primary challenges: the lack of
large-scale labeled datasets for white blood cell (WBC) segmentation and
outdated segmentation methods. To address the first challenge, a
semi-supervised learning framework should be brought to efficiently annotate
the large dataset. In this work, we address this issue by proposing a novel
self-training pipeline with the incorporation of FixMatch. We discover that by
incorporating FixMatch in the self-training pipeline, the performance improves
in the majority of cases. Our performance achieved the best performance with
the self-training scheme with consistency on DeepLab-V3 architecture and
ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC
datasets, respectively.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07282" title="Abstract">arXiv:2401.07282</a> [<a href="/pdf/2401.07282" title="Download PDF">pdf</a>, <a href="/ps/2401.07282" title="Download PostScript">ps</a>, <a href="/format/2401.07282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Half-Space Modeling with Reflecting Surface in Molecular Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kamber%2C+A">Anil Kamber</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+H+B">H. Birkan Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Pusane%2C+A+E">Ali Emre Pusane</a>, 
<a href="/search/cs?searchtype=author&query=Tugcu%2C+T">Tuna Tugcu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Molecular communications is a technique emulated by researchers, which has
already been used by the nature for millions of years. In Molecular
Communications via Diffusion (MCvD), messenger molecules are emitted by a
transmitter and propagate in the fluidic environment in a random manner. In
biological systems, the environment can be considered a bounded space,
surrounded by different structures, such as tissues and organs. The propagation
of molecules is affected by these structures in the environment, which reflect
the molecules upon collision. Hence, understanding the behavior of MCvD systems
near reflecting surfaces is important for modeling molecular communication
systems analytically. However, deriving the channel response of MCvD systems
with an absorbing spherical receiver requires solving the diffusion equation in
3-D space in the presence of a reflecting boundary, which is extremely
challenging. Therefore, derivation of the channel response in a bounded
environment has remained one of the unanswered questions in the literature. In
this paper, a method to model molecular communication systems near reflecting
surfaces is proposed, and an analytical closed-form solution for the channel
response is derived.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07283" title="Abstract">arXiv:2401.07283</a> [<a href="/pdf/2401.07283" title="Download PDF">pdf</a>, <a href="/format/2401.07283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FROST-BRDF: A Fast and Robust Optimal Sampling Technique for BRDF  Acquisition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miandji%2C+E">Ehsan Miandji</a>, 
<a href="/search/cs?searchtype=author&query=Tongbuasirilai%2C+T">Tanaboon Tongbuasirilai</a>, 
<a href="/search/cs?searchtype=author&query=Hajisharif%2C+S">Saghi Hajisharif</a>, 
<a href="/search/cs?searchtype=author&query=Kavoosighafi%2C+B">Behnaz Kavoosighafi</a>, 
<a href="/search/cs?searchtype=author&query=Unger%2C+J">Jonas Unger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Visualization and Computer Graphics (IEEE TVCG)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Efficient and accurate BRDF acquisition of real world materials is a
challenging research problem that requires sampling millions of incident light
and viewing directions. To accelerate the acquisition process, one needs to
find a minimal set of sampling directions such that the recovery of the full
BRDF is accurate and robust given such samples. In this paper, we formulate
BRDF acquisition as a compressed sensing problem, where the sensing operator is
one that performs sub-sampling of the BRDF signal according to a set of optimal
sample directions. To solve this problem, we propose the Fast and Robust
Optimal Sampling Technique (FROST) for designing a provably optimal
sub-sampling operator that places light-view samples such that the recovery
error is minimized. FROST casts the problem of designing an optimal
sub-sampling operator for compressed sensing into a sparse representation
formulation under the Multiple Measurement Vector (MMV) signal model. The
proposed reformulation is exact, i.e. without any approximations, hence it
converts an intractable combinatorial problem into one that can be solved with
standard optimization techniques. As a result, FROST is accompanied by strong
theoretical guarantees from the field of compressed sensing. We perform a
thorough analysis of FROST-BRDF using a 10-fold cross-validation with publicly
available BRDF datasets and show significant advantages compared to the
state-of-the-art with respect to reconstruction quality. Finally, FROST is
simple, both conceptually and in terms of implementation, it produces
consistent results at each run, and it is at least two orders of magnitude
faster than the prior art.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07284" title="Abstract">arXiv:2401.07284</a> [<a href="/pdf/2401.07284" title="Download PDF">pdf</a>, <a href="/format/2401.07284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Domain Adaptation through Extended-Text Reading Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Ting Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shengyue Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haizhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Feng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Deqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+F">Fuzhen Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To enhance the domain-specific capabilities of large language models,
continued pre-training on a domain-specific corpus is a prevalent method.
Recent work demonstrates that adapting models using reading comprehension data
formatted by regex-based patterns can significantly improve performance on
domain-specific tasks. However, regex-based patterns are incapable of parsing
raw corpora using domain-specific knowledge. Furthermore, the question and
answer pairs are extracted directly from the corpus in predefined formats
offers limited context. To address this limitation, we improve reading
comprehension via LLM and clustering. LLM focuses on leveraging domain
knowledge within the corpus to refine comprehension stage, while clustering
supplies relevant knowledge by extending the context to enrich reading stage.
Additionally, our method incorporates parameter-efficient fine-tuning to
improve the efficiency of domain adaptation. In comparison to AdaptLLM, our
method achieves an improvement exceeding 5% in domain-specific tasks. Our code
will available at https://github.com/microsoft/LMOps.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07286" title="Abstract">arXiv:2401.07286</a> [<a href="/pdf/2401.07286" title="Download PDF">pdf</a>, <a href="/format/2401.07286" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CANDLE: Iterative Conceptualization and Instantiation Distillation from  Large Language Models for Commonsense Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+T">Tianqing Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Haochen Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenxuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Baixuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaowei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiaxin Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiayang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chunkit Chan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The sequential process of conceptualization and instantiation is essential to
generalizable commonsense reasoning as it allows the application of existing
knowledge to unfamiliar scenarios. However, existing works tend to undervalue
the step of instantiation and heavily rely on pre-built concept taxonomies and
human annotations to collect both types of knowledge, resulting in a lack of
instantiated knowledge to complete reasoning, high cost, and limited
scalability. To tackle these challenges, we introduce CANDLE, a distillation
framework that iteratively performs contextualized conceptualization and
instantiation over commonsense knowledge bases by instructing large language
models to generate both types of knowledge with critic filtering. By applying
CANDLE to ATOMIC, we construct a comprehensive knowledge base comprising six
million conceptualizations and instantiated commonsense knowledge triples. Both
types of knowledge are firmly rooted in the original ATOMIC dataset, and
intrinsic evaluations demonstrate their exceptional quality and diversity.
Empirical results indicate that distilling CANDLE on student models provides
benefits across four downstream tasks. Our code, data, and models are publicly
available at https://github.com/HKUST-KnowComp/CANDLE.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07288" title="Abstract">arXiv:2401.07288</a> [<a href="/pdf/2401.07288" title="Download PDF">pdf</a>, <a href="/format/2401.07288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Coded-Uncoded Caching in Multi-Access Networks with Non-uniform  Demands
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheshjavani%2C+A+G">Abdollah Ghaffari Sheshjavani</a>, 
<a href="/search/cs?searchtype=author&query=Khonsari%2C+A">Ahmad Khonsari</a>, 
<a href="/search/cs?searchtype=author&query=Moradian%2C+M">Masoumeh Moradian</a>, 
<a href="/search/cs?searchtype=author&query=Shariatpanahi%2C+S+P">Seyed Pooya Shariatpanahi</a>, 
<a href="/search/cs?searchtype=author&query=Hassanpour%2C+S+B">Seyedeh Bahereh Hassanpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">To address the massive growth of data traffic over cellular networks,
increasing spatial reuse of the frequency spectrum by the deployment of small
base stations (SBSs) has been considered. For rapid deployment of SBSs in the
networks, caching popular content along with new coded caching schemes are
proposed. To maximize the cellular network's capacity, densifying it with small
base stations is inevitable. In ultra-dense cellular networks, coverage of SBSs
may overlap. To this aim, the multi-access caching system, where users
potentially can access multiple cache nodes simultaneously, has attracted more
attention in recent years. Most previous works on multi-access coded caching,
only consider specific conditions such as cyclic wrap-around network
topologies. In this paper, we investigate caching in ultra-dense cellular
networks, where different users can access different numbers of caches under
non-uniform content popularity distribution, and propose Multi-Access Hybrid
coded-uncoded Caching (MAHC). We formulate the optimization problem of the
proposed scheme for general network topologies and evaluate it for 2-SBS
network scenarios. The numerical and simulation results show that the proposed
MAHC scheme outperforms optimal conventional uncoded and previous multi-access
coded caching (MACC) schemes.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07290" title="Abstract">arXiv:2401.07290</a> [<a href="/pdf/2401.07290" title="Download PDF">pdf</a>, <a href="/format/2401.07290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing a Data Science System for Text Reuse Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahadevan%2C+A">Ananth Mahadevan</a>, 
<a href="/search/cs?searchtype=author&query=Mathioudakis%2C+M">Michael Mathioudakis</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A4kel%C3%A4%2C+E">Eetu M&#xe4;kel&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Tolonen%2C+M">Mikko Tolonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Early Draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Text reuse is a methodological element of fundamental importance in
humanities research: pieces of text that re-appear across different documents,
verbatim or paraphrased, provide invaluable information about the historical
spread and evolution of ideas. Large modern digitized corpora enable the joint
analysis of text collections that span entire centuries and the detection of
large-scale patterns, impossible to detect with traditional small-scale
analysis. For this opportunity to materialize, it is necessary to develop
efficient data science systems that perform the corresponding analysis tasks.
<br />In this paper, we share insights from ReceptionReader, a system for analyzing
text reuse in large historical corpora. The system is built upon billions of
instances of text reuses from large digitized corpora of 18th-century texts.
Its main functionality is to perform downstream text reuse analysis tasks, such
as finding reuses that stem from a given article or identifying the most reused
quotes from a set of documents, with each task expressed as a database query.
For the purposes of the paper, we discuss the related design choices including
various database normalization levels and query execution frameworks, such as
distributed data processing (Apache Spark), indexed row store engine (MariaDB
Aria), and compressed column store engine (MariaDB Columnstore). Moreover, we
present an extensive evaluation with various metrics of interest (latency,
storage size, and computing costs) for varying workloads, and we offer insights
from the trade-offs we observed and the choices that emerged as optimal in our
setting. In summary, our results show that (1) for the workloads that are most
relevant to text-reuse analysis, the MariaDB Aria framework emerges as the
overall optimal choice, (2) big data processing (Apache Spark) is irreplaceable
for all processing stages of the system's pipeline.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07291" title="Abstract">arXiv:2401.07291</a> [<a href="/pdf/2401.07291" title="Download PDF">pdf</a>, <a href="/format/2401.07291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A domain decomposition method for stochastic evolution equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Buckwar%2C+E">Evelyn Buckwar</a>, 
<a href="/search/math?searchtype=author&query=Djurdjevac%2C+A">Ana Djurdjevac</a>, 
<a href="/search/math?searchtype=author&query=Eisenmann%2C+M">Monika Eisenmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">In recent years, SPDEs have become a well-studied field in mathematics. With
their increase in popularity, it becomes important to efficiently approximate
their solutions. Thus, our goal is a contribution towards the development of
efficient and practical time-stepping methods for SPDEs.
<br />Operator splitting schemes are a powerful tool for deterministic and
stochastic differential equations. An example is given by domain decomposition
schemes, where we split the domain into sub-domains. Instead of solving one
expensive problem on the entire domain, we deal with cheaper problems on the
sub-domains. This is particularly useful in modern computer architectures, as
the sub-problems may often be solved in parallel. While splitting methods have
already been used to study domain decomposition methods for deterministic PDEs,
this is a new approach for SPDEs.
<br />We provide an abstract convergence analysis of a splitting scheme for
stochastic evolution equations and state a domain decomposition scheme as an
application of the setting. The theoretical results are verified through
numerical experiments.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07300" title="Abstract">arXiv:2401.07300</a> [<a href="/pdf/2401.07300" title="Download PDF">pdf</a>, <a href="/format/2401.07300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Physics Model Bias Correction with Data-Driven Reduced Order  Modelling Techniques: Application to Nuclear Case Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Riva%2C+S">Stefano Riva</a>, 
<a href="/search/math?searchtype=author&query=Introini%2C+C">Carolina Introini</a>, 
<a href="/search/math?searchtype=author&query=Cammi%2C+A">Antonio Cammi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Nowadays, interest in combining mathematical knowledge about phenomena and
data from the physical system is growing. Past research was devoted to
developing so-called high-fidelity models, intending to make them able to catch
most of the physical phenomena occurring in the system. Nevertheless, models
will always be affected by uncertainties related, for example, to the
parameters and inevitably limited by the underlying simplifying hypotheses on,
for example, geometry and mathematical equations; thus, in a way, there exists
an upper threshold of model performance. Now, research in many engineering
sectors also focuses on the so-called data-driven modelling, which aims at
extracting information from available data to combine it with the mathematical
model. Focusing on the nuclear field, interest in this approach is also related
to the Multi-Physics modelling of nuclear reactors. Due to the multiple physics
involved and their mutual and complex interactions, developing accurate and
stable models both from the physical and numerical point of view remains a
challenging task despite the advancements in computational hardware and
software, and combining the available mathematical model with data can further
improve the performance and the accuracy of the former.
<br />This work investigates this aspect by applying two Data-Driven Reduced Order
Modelling (DDROM) techniques, the Generalised Empirical Interpolation Method
and the Parametrised-Background Data-Weak formulation, to literature benchmark
nuclear case studies. The main goal of this work is to assess the possibility
of using data to perform model bias correction, that is, verifying the
reliability of DDROM approaches in improving the model performance and accuracy
through the information provided by the data. The obtained numerical results
are promising, foreseeing further investigation of the DDROM approach to
nuclear industrial cases.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07301" title="Abstract">arXiv:2401.07301</a> [<a href="/pdf/2401.07301" title="Download PDF">pdf</a>, <a href="/format/2401.07301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Language Model Can Self-correct
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haixia Han</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jie Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qianyu He</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generative Language Models (LMs) such as ChatGPT have exhibited remarkable
performance across various downstream tasks. Nevertheless, one of their most
prominent drawbacks is generating inaccurate or false information with a
confident tone. Previous studies have devised sophisticated pipelines and
prompts to induce large LMs to exhibit the capability for self-correction.
However, large LMs are explicitly prompted to verify and modify its answers
separately rather than completing all steps spontaneously like humans.
Moreover, these complex prompts are extremely challenging for small LMs to
follow. In this paper, we introduce the \underline{I}ntrinsic
\underline{S}elf-\underline{C}orrection (ISC) in generative language models,
aiming to correct the initial output of LMs in a self-triggered manner, even
for those small LMs with 6 billion parameters. Specifically, we devise a
pipeline for constructing self-correction data and propose Partial Answer
Masking (PAM), aiming to endow the model with the capability for intrinsic
self-correction through fine-tuning. We conduct experiments using LMs with
parameters sizes ranging from 6 billion to 13 billion in two tasks, including
commonsense reasoning and factual knowledge reasoning. Our experiments
demonstrate that the outputs generated using ISC outperform those generated
without self-correction. We believe that the output quality of even small LMs
can be further improved by empowering them with the ability to intrinsic
self-correct.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07308" title="Abstract">arXiv:2401.07308</a> [<a href="/pdf/2401.07308" title="Download PDF">pdf</a>, <a href="/ps/2401.07308" title="Download PostScript">ps</a>, <a href="/format/2401.07308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structured Acyclic Nets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alahmadi%2C+M">Mohammed Alahmadi</a>, 
<a href="/search/cs?searchtype=author&query=Alharbi%2C+S">Salma Alharbi</a>, 
<a href="/search/cs?searchtype=author&query=Alharbi%2C+T">Talal Alharbi</a>, 
<a href="/search/cs?searchtype=author&query=Almutairi%2C+N">Nadiyah Almutairi</a>, 
<a href="/search/cs?searchtype=author&query=Alshammari%2C+T">Tuwailaa Alshammari</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+A">Anirban Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Koutny%2C+M">Maciej Koutny</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/cs?searchtype=author&query=Randell%2C+B">Brian Randell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The concept of structured occurrence nets is an extension of that of
occurrence nets which are directed acyclic graphs that represent causality and
concurrency information concerning a single execution of a distributed system.
The formalism of structured occurrence nets has been introduced to facilitate
the portrayal and analysis of the behaviours, and in particular failures, of
complex evolving systems. Such systems are composed of a large number of
sub-systems which may proceed concurrently and interact with each other and
with the external environment while their behaviour is subject to modification
by other systems. The purpose of this paper is to provide an extension of
structured occurrence nets to include models built up of acyclic nets rather
than occurrence nets.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07310" title="Abstract">arXiv:2401.07310</a> [<a href="/pdf/2401.07310" title="Download PDF">pdf</a>, <a href="/format/2401.07310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Large Language Models Over Transformer Models for Detecting  Bengali Depressive Social Media Text: A Comprehensive Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+A+K">Ahmadul Karim Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Sujon%2C+M+S+R">Md. Saidur Rahman Sujon</a>, 
<a href="/search/cs?searchtype=author&query=Shafi%2C+M+S+S">Md. Shirajus Salekin Shafi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmmad%2C+T">Tasin Ahmmad</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sifat Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Hasib%2C+K+M">Khan Md Hasib</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+F+M">Faisal Muhammad Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In an era where the silent struggle of underdiagnosed depression pervades
globally, our research delves into the crucial link between mental health and
social media. This work focuses on early detection of depression, particularly
in extroverted social media users, using LLMs such as GPT 3.5, GPT 4 and our
proposed GPT 3.5 fine-tuned model DepGPT, as well as advanced Deep learning
models(LSTM, Bi-LSTM, GRU, BiGRU) and Transformer models(BERT, BanglaBERT,
SahajBERT, BanglaBERT-Base). The study categorized Reddit and X datasets into
"Depressive" and "Non-Depressive" segments, translated into Bengali by native
speakers with expertise in mental health, resulting in the creation of the
Bengali Social Media Depressive Dataset (BSMDD). Our work provides full
architecture details for each model and a methodical way to assess their
performance in Bengali depressive text categorization using zero-shot and
few-shot learning techniques. Our work demonstrates the superiority of
SahajBERT and Bi-LSTM with FastText embeddings in their respective domains also
tackles explainability issues with transformer models and emphasizes the
effectiveness of LLMs, especially DepGPT, demonstrating flexibility and
competence in a range of learning contexts. According to the experiment
results, the proposed model, DepGPT, outperformed not only Alpaca Lora 7B in
zero-shot and few-shot scenarios but also every other model, achieving a
near-perfect accuracy of 0.9796 and an F1-score of 0.9804, high recall, and
exceptional precision. Although competitive, GPT-3.5 Turbo and Alpaca Lora 7B
show relatively poorer effectiveness in zero-shot and few-shot situations. The
work emphasizes the effectiveness and flexibility of LLMs in a variety of
linguistic circumstances, providing insightful information about the complex
field of depression detection models.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07312" title="Abstract">arXiv:2401.07312</a> [<a href="/pdf/2401.07312" title="Download PDF">pdf</a>, <a href="/format/2401.07312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Nonlinear Collaboration between Human and AI Agents: A  Co-design Framework for Creative Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J+R">JiayiZhou. Renzhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Junxiu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Weiwei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingcaui Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Creative design is a nonlinear process where designers generate diverse ideas
in the pursuit of an open-ended goal and converge towards consensus through
iterative remixing. In contrast, AI-powered design tools often employ a linear
sequence of incremental and precise instructions to approximate design
objectives. Such operations violate customary creative design practices and
thus hinder AI agents' ability to complete creative design tasks. To explore
better human-AI co-design tools, we first summarize human designers' practices
through a formative study with 12 design experts. Taking graphic design as a
representative scenario, we formulate a nonlinear human-AI co-design framework
and develop a proof-of-concept prototype, OptiMuse. We evaluate OptiMuse and
validate the nonlinear framework through a comparative study. We notice a
subconscious change in people's attitudes towards AI agents, shifting from
perceiving them as mere executors to regarding them as opinionated colleagues.
This shift effectively fostered the exploration and reflection processes of
individual designers.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07314" title="Abstract">arXiv:2401.07314</a> [<a href="/pdf/2401.07314" title="Download PDF">pdf</a>, <a href="/format/2401.07314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapGPT: Map-Guided Prompting for Unified Vision-and-Language Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiaqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Bingqian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Zhenhua Chai</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xiaodan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K+K">Kwan-Yee K. Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Embodied agents equipped with GPT as their brain have exhibited extraordinary
thinking and decision-making abilities across various tasks. However, existing
zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT
to handle excessive environmental information and select potential locations
within localized environments, without constructing an effective
''global-view'' (e.g., a commonly-used map) for the agent to understand the
overall environment. In this work, we present a novel map-guided GPT-based
path-planning agent, dubbed MapGPT, for the zero-shot VLN task. Specifically,
we convert a topological map constructed online into prompts to encourage
map-guided global exploration, and require the agent to explicitly output and
update multi-step path planning to avoid getting stuck in local exploration.
Extensive experiments demonstrate that our MapGPT is effective, achieving
impressive performance on both the R2R and REVERIE datasets (38.8% and 28.4%
success rate, respectively) and showcasing the newly emerged global thinking
and path planning capabilities of the GPT model. Unlike previous VLN agents,
which require separate parameters fine-tuning or specific prompt design to
accommodate various instruction styles across different datasets, our MapGPT is
more unified as it can adapt to different instruction styles seamlessly, which
is the first of its kind in this field.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07316" title="Abstract">arXiv:2401.07316</a> [<a href="/pdf/2401.07316" title="Download PDF">pdf</a>, <a href="/format/2401.07316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Privacy-relevant Source Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Feiyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=%C3%98stvold%2C+B+M">Bjarte M. &#xd8;stvold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 2nd International Workshop on Mining Software Repositories Applications for Privacy and Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Privacy code review is a critical process that enables developers and legal
experts to ensure compliance with data protection regulations. However, the
task is challenging due to resource constraints. To address this, we introduce
the concept of privacy-relevant methods - specific methods in code that are
directly involved in the processing of personal data. We then present an
automated approach to assist in code review by identifying and categorizing
these privacy-relevant methods in source code.
<br />Using static analysis, we identify a set of methods based on their
occurrences in 50 commonly used libraries. We then rank these methods according
to their frequency of invocation with actual personal data in the top 30 GitHub
applications. The highest-ranked methods are the ones we designate as
privacy-relevant in practice. For our evaluation, we examined 100 open-source
applications and found that our approach identifies fewer than 5% of the
methods as privacy-relevant for personal data processing. This reduces the time
required for code reviews. Case studies on Signal Desktop and Cal.com further
validate the effectiveness of our approach in aiding code reviewers to produce
enhanced reports that facilitate compliance with privacy regulations.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07319" title="Abstract">arXiv:2401.07319</a> [<a href="/pdf/2401.07319" title="Download PDF">pdf</a>, <a href="/ps/2401.07319" title="Download PostScript">ps</a>, <a href="/format/2401.07319" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The MacWilliams Identity for Krawtchouk Association Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedlander%2C+I">Izzy Friedlander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The MacWilliams Identity is a well established theorem relating the weight
enumerator of a code to the weight enumerator of its dual. The ability to use a
known weight enumerator to generate the weight enumerator of another through a
simple transform proved highly effective and efficient. An equivalent relation
was also developed by Delsarte which linked the eigenvalues of any association
scheme to the eigenvalues of it's dual association scheme but this was less
practical to use in reality. A functional transform was developed for some
specific association schemes including those based on the rank metric, the skew
rank metric and Hermitian matrices. In this paper those results are unified
into a single consistent theory applied to these "Krawtchouk association
schemes" using a $b$-algebra. The derivatives formed using the $b$-algebra have
also been applied to derive the moments of the weight distribution for any code
within these association schemes.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07322" title="Abstract">arXiv:2401.07322</a> [<a href="/pdf/2401.07322" title="Download PDF">pdf</a>, <a href="/format/2401.07322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RSUD20K: A Dataset for Road Scene Understanding In Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zunair%2C+H">Hasib Zunair</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Shakib Khan</a>, 
<a href="/search/cs?searchtype=author&query=Hamza%2C+A+B">A. Ben Hamza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Road scene understanding is crucial in autonomous driving, enabling machines
to perceive the visual environment. However, recent object detectors tailored
for learning on datasets collected from certain geographical locations struggle
to generalize across different locations. In this paper, we present RSUD20K, a
new dataset for road scene understanding, comprised of over 20K high-resolution
images from the driving perspective on Bangladesh roads, and includes 130K
bounding box annotations for 13 objects. This challenging dataset encompasses
diverse road scenes, narrow streets and highways, featuring objects from
different viewpoints and scenes from crowded environments with densely
cluttered objects and various weather conditions. Our work significantly
improves upon previous efforts, providing detailed annotations and increased
object complexity. We thoroughly examine the dataset, benchmarking various
state-of-the-art object detectors and exploring large vision models as image
annotators.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07323" title="Abstract">arXiv:2401.07323</a> [<a href="/pdf/2401.07323" title="Download PDF">pdf</a>, <a href="/ps/2401.07323" title="Download PostScript">ps</a>, <a href="/format/2401.07323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MapNeXt: Revisiting Training and Scaling Practices for Online Vectorized  HD Map Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Toyota Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-Definition (HD) maps are pivotal to autopilot navigation. Integrating
the capability of lightweight HD map construction at runtime into a
self-driving system recently emerges as a promising direction. In this surge,
vision-only perception stands out, as a camera rig can still perceive the
stereo information, let alone its appealing signature of portability and
economy. The latest MapTR architecture solves the online HD map construction
task in an end-to-end fashion but its potential is yet to be explored. In this
work, we present a full-scale upgrade of MapTR and propose MapNeXt, the next
generation of HD map learning architecture, delivering major contributions from
the model training and scaling perspectives. After shedding light on the
training dynamics of MapTR and exploiting the supervision from map elements
thoroughly, MapNeXt-Tiny raises the mAP of MapTR-Tiny from 49.0% to 54.8%,
without any architectural modifications. Enjoying the fruit of map segmentation
pre-training, MapNeXt-Base further lifts the mAP up to 63.9% that has already
outperformed the prior art, a multi-modality MapTR, by 1.4% while being
$\sim1.8\times$ faster. Towards pushing the performance frontier to the next
level, we draw two conclusions on practical model scaling: increased query
favors a larger decoder network for adequate digestion; a large backbone
steadily promotes the final accuracy without bells and whistles. Building upon
these two rules of thumb, MapNeXt-Huge achieves state-of-the-art performance on
the challenging nuScenes benchmark. Specifically, we push the mapless
vision-only single-model performance to be over 78% for the first time,
exceeding the best model from existing methods by 16%.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07324" title="Abstract">arXiv:2401.07324</a> [<a href="/pdf/2401.07324" title="Download PDF">pdf</a>, <a href="/format/2401.07324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small LLMs Are Weak Tool Learners: A Multi-LLM Agent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weizhou Shen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongzhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Ming Yan</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+X">Xiaojun Quan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hehong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fei Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> On progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large Language Model (LLM) agents significantly extend the capabilities of
standalone LLMs, empowering them to interact with external tools (e.g., APIs,
functions) and complete complex tasks in a self-directed fashion. The challenge
of tool use demands that LLMs not only understand user queries and generate
answers but also excel in task planning, memory management, tool invocation,
and result summarization. While traditional approaches focus on training a
single LLM with all these capabilities, performance limitations become
apparent, particularly with smaller models. Moreover, the entire LLM may
require retraining when tools are updated. To overcome these challenges, we
propose a novel strategy that decomposes the aforementioned capabilities into a
planner, caller, and summarizer. Each component is implemented by a single LLM
that focuses on a specific capability and collaborates with other components to
accomplish the task. This modular framework facilitates individual updates and
the potential use of smaller LLMs for building each capability. To effectively
train this framework, we introduce a two-stage training paradigm. First, we
fine-tune a backbone LLM on the entire dataset without discriminating
sub-tasks, providing the model with a comprehensive understanding of the task.
Second, the fine-tuned LLM is used to instantiate the planner, caller, and
summarizer respectively, which are continually fine-tuned on respective
sub-tasks. Evaluation across various tool-use benchmarks illustrates that our
proposed multi-LLM framework surpasses the traditional single-LLM approach,
highlighting its efficacy and advantages in tool learning.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07329" title="Abstract">arXiv:2401.07329</a> [<a href="/pdf/2401.07329" title="Download PDF">pdf</a>, <a href="/format/2401.07329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based UNet enabled Lightweight Image Semantic Communication  System over Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+G">Guoxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Haonan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+N">Nuocheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+C">Changchuan Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, accepted by IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper studies the problem of the lightweight image semantic
communication system that is deployed on Internet of Things (IoT) devices. In
the considered system model, devices must use semantic communication techniques
to support user behavior recognition in ultimate video service with high data
transmission efficiency. However, it is computationally expensive for IoT
devices to deploy semantic codecs due to the complex calculation processes of
deep learning (DL) based codec training and inference. To make it affordable
for IoT devices to deploy semantic communication systems, we propose an
attention-based UNet enabled lightweight image semantic communication (LSSC)
system, which achieves low computational complexity and small model size. In
particular, we first let the LSSC system train the codec at the edge server to
reduce the training computation load on IoT devices. Then, we introduce the
convolutional block attention module (CBAM) to extract the image semantic
features and decrease the number of downsampling layers thus reducing the
floating-point operations (FLOPs). Finally, we experimentally adjust the
structure of the codec and find out the optimal number of downsampling layers.
Simulation results show that the proposed LSSC system can reduce the semantic
codec FLOPs by 14%, and reduce the model size by 55%, with a sacrifice of 3%
accuracy, compared to the baseline. Moreover, the proposed scheme can achieve a
higher transmission accuracy than the traditional communication scheme in the
low channel signal-to-noise (SNR) region.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07331" title="Abstract">arXiv:2401.07331</a> [<a href="/pdf/2401.07331" title="Download PDF">pdf</a>, <a href="/format/2401.07331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid Estimation of Left Ventricular Contractility with a  Physics-Informed Neural Network Inverse Modeling Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naghavi%2C+E">Ehsan Naghavi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Choy%2C+J+S">Jenny S. Choy</a>, 
<a href="/search/cs?searchtype=author&query=Kassab%2C+G">Ghassan Kassab</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungik Baek</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+L">Lik-Chuan Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Physics-based computer models based on numerical solution of the governing
equations generally cannot make rapid predictions, which in turn, limits their
applications in the clinic. To address this issue, we developed a
physics-informed neural network (PINN) model that encodes the physics of a
closed-loop blood circulation system embedding a left ventricle (LV). The PINN
model is trained to satisfy a system of ordinary differential equations (ODEs)
associated with a lumped parameter description of the circulatory system. The
model predictions have a maximum error of less than 5% when compared to those
obtained by solving the ODEs numerically. An inverse modeling approach using
the PINN model is also developed to rapidly estimate model parameters (in
$\sim$ 3 mins) from single-beat LV pressure and volume waveforms. Using
synthetic LV pressure and volume waveforms generated by the PINN model with
different model parameter values, we show that the inverse modeling approach
can recover the corresponding ground truth values, which suggests that the
model parameters are unique. The PINN inverse modeling approach is then applied
to estimate LV contractility indexed by the end-systolic elastance $E_{es}$
using waveforms acquired from 11 swine models, including waveforms acquired
before and after administration of dobutamine (an inotropic agent) in 3
animals. The estimated $E_{es}$ is about 58% to 284% higher for the data
associated with dobutamine compared to those without, which implies that this
approach can be used to estimate LV contractility using single-beat
measurements. The PINN inverse modeling can potentially be used in the clinic
to simultaneously estimate LV contractility and other physiological parameters
from single-beat measurements.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07333" title="Abstract">arXiv:2401.07333</a> [<a href="/pdf/2401.07333" title="Download PDF">pdf</a>, <a href="/format/2401.07333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided  Sequence Reordering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yakun Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">The language model (LM) approach based on acoustic and linguistic prompts,
such as VALL-E, has achieved remarkable progress in the field of zero-shot
audio generation. However, existing methods still have some limitations: 1)
repetitions, transpositions, and omissions in the output synthesized speech due
to limited alignment constraints between audio and phoneme tokens; 2)
challenges of fine-grained control over the synthesized speech with
autoregressive (AR) language model; 3) infinite silence generation due to the
nature of AR-based decoding, especially under the greedy strategy. To alleviate
these issues, we propose ELLA-V, a simple but efficient LM-based zero-shot
text-to-speech (TTS) framework, which enables fine-grained control over
synthesized audio at the phoneme level. The key to ELLA-V is interleaving
sequences of acoustic and phoneme tokens, where phoneme tokens appear ahead of
the corresponding acoustic tokens. The experimental findings reveal that our
model outperforms VALL-E in terms of accuracy and delivers more stable results
using both greedy and sampling-based decoding strategies. The code of ELLA-V
will be open-sourced after cleanups. Audio samples are available at
https://ereboas.github.io/ELLAV/.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07339" title="Abstract">arXiv:2401.07339</a> [<a href="/pdf/2401.07339" title="Download PDF">pdf</a>, <a href="/format/2401.07339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems  for Real-World Repo-level Coding Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kechi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Ge Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xianjie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have shown promise in automated code generation
but typically excel only in simpler tasks such as generating standalone code
units. Real-world software development, however, often involves complex code
repositories (named repo) with complex dependencies and extensive
documentation. To fill this gap, our research pivots towards evaluating LLMs in
a more realistic setting -- real-world repo-level code generation. We introduce
CodeAgentBench, a manually curated benchmark for repo-level code generation.
This benchmark comprises five high-quality Python projects, encompassing a
total of 101 samples. We assess nine leading LLMs on repo-level tasks and
observe a decline in their performance. To tackle this, we present CodeAgent, a
novel LLM-based agent framework that employs external tools for effective
repo-level code generation. CodeAgent integrates five programming tools,
enabling interaction with software artifacts for information retrieval, code
symbol navigation, and code testing. We implement four agent strategies to
optimize these tools' usage. Our experiments on CodeAgentBench show that
CodeAgent enhances LLM performance significantly, with improvements ranging
from 18.1\% to 250\%. Further tests on the HumanEval benchmark confirm
CodeAgent's adaptability and efficacy across various code generation tasks.
Notably, CodeAgent outperforms commercial products like Github Copilot,
showcasing superior accuracy and efficiency. These results demonstrate
CodeAgent's robust capabilities in code generation, highlighting its potential
for real-world repo-level coding challenges.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07340" title="Abstract">arXiv:2401.07340</a> [<a href="/pdf/2401.07340" title="Download PDF">pdf</a>, <a href="/ps/2401.07340" title="Download PostScript">ps</a>, <a href="/format/2401.07340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Afterlives of Shakespeare and Company in Online Social Readership
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antoniak%2C+M">Maria Antoniak</a>, 
<a href="/search/cs?searchtype=author&query=Mimno%2C+D">David Mimno</a>, 
<a href="/search/cs?searchtype=author&query=Thalken%2C+R">Rosamond Thalken</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+M">Melanie Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Wilkens%2C+M">Matthew Wilkens</a>, 
<a href="/search/cs?searchtype=author&query=Yauney%2C+G">Gregory Yauney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The growth of social reading platforms such as Goodreads and LibraryThing
enables us to analyze reading activity at very large scale and in remarkable
detail. But twenty-first century systems give us a perspective only on
contemporary readers. Meanwhile, the digitization of the lending library
records of Shakespeare and Company provides a window into the reading activity
of an earlier, smaller community in interwar Paris. In this article, we explore
the extent to which we can make comparisons between the Shakespeare and Company
and Goodreads communities. By quantifying similarities and differences, we can
identify patterns in how works have risen or fallen in popularity across these
datasets. We can also measure differences in how works are received by
measuring similarities and differences in co-reading patterns. Finally, by
examining the complete networks of co-readership, we can observe changes in the
overall structures of literary reception.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07341" title="Abstract">arXiv:2401.07341</a> [<a href="/pdf/2401.07341" title="Download PDF">pdf</a>, <a href="/ps/2401.07341" title="Download PostScript">ps</a>, <a href="/format/2401.07341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary weights spanning trees and the $k$-red spanning tree problem in  linear time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hochbaum%2C+D+S">Dorit S. Hochbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We address here spanning tree problems on a graph with binary edge weights.
For a general weighted graph the minimum spanning tree is solved in
super-linear running time, even when the edges of the graph are pre-sorted. A
related problem, of finding a spanning tree with a pre-specified sum of
weights, is NP-hard. In contrast, for a graph with binary weights associated
with the edges, it is shown that the minimum spanning tree and finding a
spanning tree with a given total sum, are solvable in linear time with simple
algorithms.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07343" title="Abstract">arXiv:2401.07343</a> [<a href="/pdf/2401.07343" title="Download PDF">pdf</a>, <a href="/format/2401.07343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Preserving Intrusion Detection in Software-defined VANET using  Federated Learning with BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahsan%2C+S+I">Shakil Ibne Ahsan</a>, 
<a href="/search/cs?searchtype=author&query=Legg%2C+P">Phil Legg</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+S+M+I">S M Iftekharul Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2312.04956">arXiv:2312.04956</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The absence of robust security protocols renders the VANET (Vehicle ad-hoc
Networks) network open to cyber threats by compromising passengers and road
safety. Intrusion Detection Systems (IDS) are widely employed to detect network
security threats. With vehicles' high mobility on the road and diverse
environments, VANETs devise ever-changing network topologies, lack privacy and
security, and have limited bandwidth efficiency. The absence of privacy
precautions, End-to-End Encryption methods, and Local Data Processing systems
in VANET also present many privacy and security difficulties. So, assessing
whether a novel real-time processing IDS approach can be utilized for this
emerging technology is crucial. The present study introduces a novel approach
for intrusion detection using Federated Learning (FL) capabilities in
conjunction with the BERT model for sequence classification (FL-BERT). The
significance of data privacy is duly recognized. According to FL methodology,
each client has its own local model and dataset. They train their models
locally and then send the model's weights to the server. After aggregation, the
server aggregates the weights from all clients to update a global model. After
aggregation, the global model's weights are shared with the clients. This
practice guarantees the secure storage of sensitive raw data on individual
clients' devices, effectively protecting privacy. After conducting the
federated learning procedure, we assessed our models' performance using a
separate test dataset. The FL-BERT technique has yielded promising results,
opening avenues for further investigation in this particular area of research.
We reached the result of our approaches by comparing existing research works
and found that FL-BERT is more effective for privacy and security concerns. Our
results suggest that FL-BERT is a promising technique for enhancing attack
detection.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07348" title="Abstract">arXiv:2401.07348</a> [<a href="/pdf/2401.07348" title="Download PDF">pdf</a>, <a href="/ps/2401.07348" title="Download PostScript">ps</a>, <a href="/format/2401.07348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI in EU Law: Liability, Privacy, Intellectual Property, and  Cybersecurity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Novelli%2C+C">Claudio Novelli</a>, 
<a href="/search/cs?searchtype=author&query=Casolari%2C+F">Federico Casolari</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+P">Philipp Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Spedicato%2C+G">Giorgio Spedicato</a>, 
<a href="/search/cs?searchtype=author&query=Floridi%2C+L">Luciano Floridi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Generative AI, particularly through Large Language Models
(LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI
landscape. Advanced LLMs exhibit multimodality, handling diverse data formats,
thereby broadening their application scope. However, the complexity and
emergent autonomy of these models introduce challenges in predictability and
legal compliance. This paper delves into the legal and regulatory implications
of Generative AI and LLMs in the European Union context, analyzing aspects of
liability, privacy, intellectual property, and cybersecurity. It critically
examines the adequacy of the existing and proposed EU legislation, including
the Artificial Intelligence Act (AIA) draft, in addressing the unique
challenges posed by Generative AI in general and LLMs in particular. The paper
identifies potential gaps and shortcomings in the legislative framework and
proposes recommendations to ensure the safe and compliant deployment of
generative models, ensuring they align with the EU's evolving digital landscape
and legal standards.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07353" title="Abstract">arXiv:2401.07353</a> [<a href="/pdf/2401.07353" title="Download PDF">pdf</a>, <a href="/format/2401.07353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Engineering Fair and Equitable Software Systems for Managing  Low-Altitude Airspace Authorizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohar%2C+U">Usman Gohar</a>, 
<a href="/search/cs?searchtype=author&query=Hunter%2C+M+C">Michael C. Hunter</a>, 
<a href="/search/cs?searchtype=author&query=Marczak-Czajka%2C+A">Agnieszka Marczak-Czajka</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+R+R">Robyn R. Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+M+B">Myra B. Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Cleland-Huang%2C+J">Jane Cleland-Huang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICSE-SEIS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Small Unmanned Aircraft Systems (sUAS) have gained widespread adoption across
a diverse range of applications. This has introduced operational complexities
within shared airspaces and an increase in reported incidents, raising safety
concerns. In response, the U.S. Federal Aviation Administration (FAA) is
developing a UAS Traffic Management (UTM) system to control access to airspace
based on an sUAS's predicted ability to safely complete its mission. However, a
fully automated system capable of swiftly approving or denying flight requests
can be prone to bias and must consider safety, transparency, and fairness to
diverse stakeholders. In this paper, we present an initial study that explores
stakeholders' perspectives on factors that should be considered in an automated
system. Results indicate flight characteristics and environmental conditions
were perceived as most important but pilot and drone capabilities should also
be considered. Further, several respondents indicated an aversion to any
AI-supported automation, highlighting the need for full transparency in
automated decision-making. Results provide a societal perspective on the
challenges of automating UTM flight authorization decisions and help frame the
ongoing design of a solution acceptable to the broader sUAS community.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07356" title="Abstract">arXiv:2401.07356</a> [<a href="/pdf/2401.07356" title="Download PDF">pdf</a>, <a href="/format/2401.07356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BUGSPHP: A dataset for Automated Program Repair in PHP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramod%2C+K+D">K.D. Pramod</a>, 
<a href="/search/cs?searchtype=author&query=De+Silva%2C+W+T+N">W.T.N. De Silva</a>, 
<a href="/search/cs?searchtype=author&query=Thabrew%2C+W+U+K">W.U.K. Thabrew</a>, 
<a href="/search/cs?searchtype=author&query=Shariffdeen%2C+R">Ridwan Shariffdeen</a>, 
<a href="/search/cs?searchtype=author&query=Wickramanayake%2C+S">Sandareka Wickramanayake</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Automated Program Repair (APR) improves developer productivity by saving
debugging and bug-fixing time. While APR has been extensively explored for
C/C++ and Java programs, there is little research on bugs in PHP programs due
to the lack of a benchmark PHP bug dataset. This is surprising given that PHP
has been one of the most widely used server-side languages for over two
decades, being used in a variety of contexts such as e-commerce, social
networking, and content management. This paper presents a benchmark dataset of
PHP bugs on real-world applications called BUGSPHP, which can enable research
on analysis, testing, and repair for PHP programs. The dataset consists of
training and test datasets, separately curated from GitHub and processed
locally. The training dataset includes more than 600,000 bug-fixing commits.
The test dataset contains 513 manually validated bug-fixing commits equipped
with developer-provided test cases to assess patch correctness.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07358" title="Abstract">arXiv:2401.07358</a> [<a href="/pdf/2401.07358" title="Download PDF">pdf</a>, <a href="/format/2401.07358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Machine Learning for Discerning AI-Generated Synthetic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yizhi Hao</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+A+X">Amando Xu Cong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of digital media, the advent of AI-generated synthetic images
has introduced significant challenges in distinguishing between real and
fabricated visual content. These images, often indistinguishable from authentic
ones, pose a threat to the credibility of digital media, with potential
implications for disinformation and fraud. Our research addresses this
challenge by employing machine learning techniques to discern between
AI-generated and genuine images. Central to our approach is the CIFAKE dataset,
a comprehensive collection of images labeled as "Real" and "Fake". We refine
and adapt advanced deep learning architectures like ResNet, VGGNet, and
DenseNet, utilizing transfer learning to enhance their precision in identifying
synthetic images. We also compare these with a baseline model comprising a
vanilla Support Vector Machine (SVM) and a custom Convolutional Neural Network
(CNN). The experimental results were significant, demonstrating that our
optimized deep learning models outperform traditional methods, with DenseNet
achieving an accuracy of 97.74%. Our application study contributes by applying
and optimizing these advanced models for synthetic image detection, conducting
a comparative analysis using various metrics, and demonstrating their superior
capability in identifying AI-generated images over traditional machine learning
techniques. This research not only advances the field of digital media
integrity but also sets a foundation for future explorations into the ethical
and technical dimensions of AI-generated content in digital media.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07359" title="Abstract">arXiv:2401.07359</a> [<a href="/pdf/2401.07359" title="Download PDF">pdf</a>, <a href="/ps/2401.07359" title="Download PostScript">ps</a>, <a href="/format/2401.07359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability and Interpretability in Science and Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scorzato%2C+L">Luigi Scorzato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); History and Philosophy of Physics (physics.hist-ph)

</div>
<p class="mathjax">In recent years, the question of the reliability of Machine Learning (ML)
methods has acquired significant importance, and the analysis of the associated
uncertainties has motivated a growing amount of research. However, most of
these studies have applied standard error analysis to ML models, and in
particular Deep Neural Network (DNN) models, which represent a rather
significant departure from standard scientific modelling. It is therefore
necessary to integrate the standard error analysis with a deeper
epistemological analysis of the possible differences between DNN models and
standard scientific modelling and the possible implications of these
differences in the assessment of reliability. This article offers several
contributions. First, it emphasises the ubiquitous role of model assumptions
(both in ML and traditional Science) against the illusion of theory-free
science. Secondly, model assumptions are analysed from the point of view of
their (epistemic) complexity, which is shown to be language-independent. It is
argued that the high epistemic complexity of DNN models hinders the estimate of
their reliability and also their prospect of long-term progress. Some potential
ways forward are suggested. Thirdly, this article identifies the close relation
between a model's epistemic complexity and its interpretability, as introduced
in the context of responsible AI. This clarifies in which sense, and to what
extent, the lack of understanding of a model (black-box problem) impacts its
interpretability in a way that is independent of individual skills. It also
clarifies how interpretability is a precondition for assessing the reliability
of any model, which cannot be based on statistical analysis alone. This article
focuses on the comparison between traditional scientific models and DNN models.
But, Random Forest and Logistic Regression models are also briefly considered.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07360" title="Abstract">arXiv:2401.07360</a> [<a href="/pdf/2401.07360" title="Download PDF">pdf</a>, <a href="/format/2401.07360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promptformer: Prompted Conformer Transducer for ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duarte-Torres%2C+S">Sergio Duarte-Torres</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Arunasish Sen</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+A">Aman Rana</a>, 
<a href="/search/cs?searchtype=author&query=Drude%2C+L">Lukas Drude</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Alanis%2C+A">Alejandro Gomez-Alanis</a>, 
<a href="/search/cs?searchtype=author&query=Schwarz%2C+A">Andreas Schwarz</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4del%2C+L">Leif R&#xe4;del</a>, 
<a href="/search/cs?searchtype=author&query=Leutnant%2C+V">Volker Leutnant</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Context cues carry information which can improve multi-turn interactions in
automatic speech recognition (ASR) systems. In this paper, we introduce a novel
mechanism inspired by hyper-prompting to fuse textual context with acoustic
representations in the attention mechanism. Results on a test set with
multi-turn interactions show that our method achieves 5.9% relative word error
rate reduction (rWERR) over a strong baseline. We show that our method does not
degrade in the absence of context and leads to improvements even if the model
is trained without context. We further show that leveraging a pre-trained
sentence-piece model for context embedding generation can outperform an
external BERT model.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07361" title="Abstract">arXiv:2401.07361</a> [<a href="/pdf/2401.07361" title="Download PDF">pdf</a>, <a href="/format/2401.07361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Summation on the Sphere with Applications to the Barotropic  Vorticity Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+A">Anthony Chen</a>, 
<a href="/search/math?searchtype=author&query=Jablonowski%2C+C">Christiane Jablonowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Atmospheric and Oceanic Physics (physics.ao-ph); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Fast summation refers to a family of techniques for approximating $O(N^2)$
sums in $O(N\log{N})$ or $O(N)$ time. These techniques have traditionally found
wide use in astrophysics and electrostatics in calculating the forces in a
$N$-body problem. In this work, we present a spherical tree code, and apply it
to the problem of efficiently solving the barotropic vorticity equation.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07363" title="Abstract">arXiv:2401.07363</a> [<a href="/pdf/2401.07363" title="Download PDF">pdf</a>, <a href="/format/2401.07363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PersonalityChat: Conversation Distillation for Personalized Dialog  Modeling with Facts and Traits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lotfi%2C+E">Ehsan Lotfi</a>, 
<a href="/search/cs?searchtype=author&query=De+Bruyn%2C+M">Maxime De Bruyn</a>, 
<a href="/search/cs?searchtype=author&query=Buhmann%2C+J">Jeska Buhmann</a>, 
<a href="/search/cs?searchtype=author&query=Daelemans%2C+W">Walter Daelemans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> GEM workshop @ EMNLP23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The new wave of Large Language Models (LLM) has offered an efficient tool to
curate sizeable conversational datasets. So far studies have mainly focused on
task-oriented or generic open-domain dialogs, and have not fully explored the
ability of LLMs in following complicated prompts. In this work, we focus on
personalization, and employ LLMs to curate a dataset which is difficult and
costly to crowd-source: PersonalityChat is a synthetic conversational dataset
based upon the popular PersonaChat dataset, but conditioned on both personas
and (Big-5) personality traits. Evaluating models fine-tuned on this dataset,
we show that the personality trait labels can be used for trait-based
personalization of generative dialogue models. We also perform a head-to-head
comparison between PersonalityChat and PersonaChat, and show that training on
the distilled dataset results in more fluent and coherent dialog agents in the
small-model regime.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07364" title="Abstract">arXiv:2401.07364</a> [<a href="/pdf/2401.07364" title="Download PDF">pdf</a>, <a href="/format/2401.07364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar  Nonlinear Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Osher%2C+S+J">Stanley J. Osher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Can we build a single large model for a wide range of PDE-related scientific
learning tasks? Can this model generalize to new PDEs, even of new forms,
without any fine-tuning? In-context operator learning and the corresponding
model In-Context Operator Networks (ICON) [1] represent an initial exploration
of these questions. The capability of ICON regarding the first question has
been demonstrated in [1]. In this paper, we explore the second question by
investigating the generalization capabilities of ICON for conservation laws, a
family of PDEs with temporal evolution. We show the positive answer to the
second question, i.e., ICON can generalize well to some PDEs with new forms
without any fine-tuning. We also show how to broaden the range of problems that
ICON can address, by transforming functions and equations to ICON's capability
scope. We believe that the progress in this paper is a significant step towards
the goal of training a foundation model for PDE-related tasks under the
in-context operator learning framework.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07367" title="Abstract">arXiv:2401.07367</a> [<a href="/pdf/2401.07367" title="Download PDF">pdf</a>, <a href="/format/2401.07367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Learning for NLP with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuesong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> init report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human annotation of training samples is expensive, laborious, and sometimes
challenging, especially for Natural Language Processing (NLP) tasks. To reduce
the labeling cost and enhance the sample efficiency, Active Learning (AL)
technique can be used to label as few samples as possible to reach a reasonable
or similar results. To reduce even more costs and with the significant advances
of Large Language Models (LLMs), LLMs can be a good candidate to annotate
samples. This work investigates the accuracy and cost of using LLMs (GPT-3.5
and GPT-4) to label samples on 3 different datasets. A consistency-based
strategy is proposed to select samples that are potentially incorrectly labeled
so that human annotations can be used for those samples in AL settings, and we
call it mixed annotation strategy. Then we test performance of AL under two
different settings: (1) using human annotations only; (2) using the proposed
mixed annotation strategy. The accuracy of AL models under 3 AL query
strategies are reported on 3 text classification datasets, i.e., AG's News,
TREC-6, and Rotten Tomatoes. On AG's News and Rotten Tomatoes, the models
trained with the mixed annotation strategy achieves similar or better results
compared to that with human annotations. The method reveals great potentials of
LLMs as annotators in terms of accuracy and cost efficiency in active learning
settings.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07368" title="Abstract">arXiv:2401.07368</a> [<a href="/pdf/2401.07368" title="Download PDF">pdf</a>, <a href="/format/2401.07368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Zero-Trust Machine Learning Green Architecture for Healthcare  IoT Cybersecurity: Review, Analysis, and Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ElSayed%2C+Z">Zag ElSayed</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+N">Nelly Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Bay%2C+S">Sajjad Bay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 4 tables, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The integration of Internet of Things (IoT) devices in healthcare
applications has revolutionized patient care, monitoring, and data management.
The Global IoT in Healthcare Market value is $252.2 Billion in 2023. However,
the rapid involvement of these devices brings information security concerns
that pose critical threats to patient privacy and the integrity of healthcare
data. This paper introduces a novel machine learning (ML) based architecture
explicitly designed to address and mitigate security vulnerabilities in IoT
devices within healthcare applications. By leveraging advanced convolution ML
architecture, the proposed architecture aims to proactively monitor and detect
potential threats, ensuring the confidentiality and integrity of sensitive
healthcare information while minimizing the cost and increasing the portability
specialized for healthcare and emergency environments. The experimental results
underscore the accuracy of up to 93.6% for predicting various attacks based on
the results demonstrate a zero-day detection accuracy simulated using the
CICIoT2023 dataset and reduces the cost by a factor of x10. The significance of
our approach is in fortifying the security posture of IoT devices and
maintaining a robust implementation of trustful healthcare systems.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07369" title="Abstract">arXiv:2401.07369</a> [<a href="/pdf/2401.07369" title="Download PDF">pdf</a>, <a href="/format/2401.07369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoVO-MPC: Theoretical Analysis of Sampling-based MPC and Optimal  Covariance Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+Z">Zeji Yi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chaoyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+G">Guanqi He</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+G">Guannan Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guanya Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Sampling-based Model Predictive Control (MPC) has been a practical and
effective approach in many domains, notably model-based reinforcement learning,
thanks to its flexibility and parallelizability. Despite its appealing
empirical performance, the theoretical understanding, particularly in terms of
convergence analysis and hyperparameter tuning, remains absent. In this paper,
we characterize the convergence property of a widely used sampling-based MPC
method, Model Predictive Path Integral Control (MPPI). We show that MPPI enjoys
at least linear convergence rates when the optimization is quadratic, which
covers time-varying LQR systems. We then extend to more general nonlinear
systems. Our theoretical analysis directly leads to a novel sampling-based MPC
algorithm, CoVariance-Optimal MPC (CoVo-MPC) that optimally schedules the
sampling covariance to optimize the convergence rate. Empirically, CoVo-MPC
significantly outperforms standard MPPI by 43-54% in both simulations and
real-world quadrotor agile control tasks. Videos and Appendices are available
at \url{https://lecar-lab.github.io/CoVO-MPC/}.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07370" title="Abstract">arXiv:2401.07370</a> [<a href="/pdf/2401.07370" title="Download PDF">pdf</a>, <a href="/format/2401.07370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of Synthetic Images for Pedestrian Detection Using a Sequence  of GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seib%2C+V">Viktor Seib</a>, 
<a href="/search/cs?searchtype=author&query=Roosen%2C+M">Malte Roosen</a>, 
<a href="/search/cs?searchtype=author&query=Germann%2C+I">Ida Germann</a>, 
<a href="/search/cs?searchtype=author&query=Wirtz%2C+S">Stefan Wirtz</a>, 
<a href="/search/cs?searchtype=author&query=Paulus%2C+D">Dietrich Paulus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Creating annotated datasets demands a substantial amount of manual effort. In
this proof-of-concept work, we address this issue by proposing a novel image
generation pipeline. The pipeline consists of three distinct generative
adversarial networks (previously published), combined in a novel way to augment
a dataset for pedestrian detection. Despite the fact that the generated images
are not always visually pleasant to the human eye, our detection benchmark
reveals that the results substantially surpass the baseline. The presented
proof-of-concept work was done in 2020 and is now published as a technical
report after a three years retention period.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07371" title="Abstract">arXiv:2401.07371</a> [<a href="/pdf/2401.07371" title="Download PDF">pdf</a>, <a href="/ps/2401.07371" title="Download PostScript">ps</a>, <a href="/format/2401.07371" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-driven Resilience Framework of Directionality Configuration based  on Topological Credentials in Road Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kays%2C+H+M+I">H M Imran Kays</a>, 
<a href="/search/cs?searchtype=author&query=Momin%2C+K+A">Khondhaker Al Momin</a>, 
<a href="/search/cs?searchtype=author&query=Muraleetharan%2C+K+K+%22">K.K. &quot;Muralee&quot; Muraleetharan</a>, 
<a href="/search/cs?searchtype=author&query=Sadri%2C+A+M">Arif Mohaimin Sadri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 103rd Transportation Research Board (TRB) Annual Meeting
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Roadway reconfiguration is a crucial aspect of transportation planning,
aiming to enhance traffic flow, reduce congestion, and improve overall road
network performance with existing infrastructure and resources. This paper
presents a novel roadway reconfiguration technique by integrating optimization
based Brute Force search approach and decision support framework to rank
various roadway configurations for better performance. The proposed framework
incorporates a multi-criteria decision analysis (MCDA) approach, combining
input from generated scenarios during the optimization process. By utilizing
data from optimization, the model identifies total betweenness centrality
(TBC), system travel time (STT), and total link traffic flow (TLTF) as the most
influential decision variables. The developed framework leverages graph theory
to model the transportation network topology and apply network science metrics
as well as stochastic user equilibrium traffic assignment to assess the impact
of each roadway configuration on the overall network performance. To rank the
roadway configurations, the framework employs machine learning algorithms, such
as ridge regression, to determine the optimal weights for each criterion (i.e.,
TBC, STT, TLTF). Moreover, the network-based analysis ensures that the selected
configurations not only optimize individual roadway segments but also enhance
system-level efficiency, which is particularly helpful as the increasing
frequency and intensity of natural disasters and other disruptive events
underscore the critical need for resilient transportation networks. By
integrating multi-criteria decision analysis, machine learning, and network
science metrics, the proposed framework would enable transportation planners to
make informed and data-driven decisions, leading to more sustainable,
efficient, and resilient roadway configurations.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07378" title="Abstract">arXiv:2401.07378</a> [<a href="/pdf/2401.07378" title="Download PDF">pdf</a>, <a href="/format/2401.07378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient approximation of Earth Mover&#x27;s Distance Based on Nearest  Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+G">Guangyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ruyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peixian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danny Chen</a>, 
<a href="/search/cs?searchtype=author&query=Niemier%2C+M">Michael Niemier</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">X.Sharon Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Earth Mover's Distance (EMD) is an important similarity measure between two
distributions, used in computer vision and many other application domains.
However, its exact calculation is computationally and memory intensive, which
hinders its scalability and applicability for large-scale problems. Various
approximate EMD algorithms have been proposed to reduce computational costs,
but they suffer lower accuracy and may require additional memory usage or
manual parameter tuning. In this paper, we present a novel approach, NNS-EMD,
to approximate EMD using Nearest Neighbor Search (NNS), in order to achieve
high accuracy, low time complexity, and high memory efficiency. The NNS
operation reduces the number of data points compared in each NNS iteration and
offers opportunities for parallel processing. We further accelerate NNS-EMD via
vectorization on GPU, which is especially beneficial for large datasets. We
compare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD
algorithms on image classification and retrieval tasks. We also apply NNS-EMD
to calculate transport mapping and realize color transfer between images.
NNS-EMD can be 44x to 135x faster than the exact EMD implementation, and
achieves superior accuracy, speedup, and memory efficiency over existing
approximate EMD methods.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07382" title="Abstract">arXiv:2401.07382</a> [<a href="/pdf/2401.07382" title="Download PDF">pdf</a>, <a href="/format/2401.07382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRLC: Reinforcement Learning with Dense Rewards from LLM Critic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+M">Meng Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+L">Lei Shu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wichers%2C+N">Nevan Wichers</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yinxiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lei Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning (RL) can align language models with non-differentiable
reward signals, such as human preferences. However, a major challenge arises
from the sparsity of these reward signals - typically, there is only one reward
for the entire generation. This sparsity of rewards can lead to inefficient and
unstable learning. In this paper, we introduce a novel framework leveraging the
critique ability of LLMs to produce dense rewards throughout the learning
process. Our approach incorporates a critic language model alongside the policy
model. This critic is prompted with the task description, question, policy
model's output, and environment's reward signal as input, and provides token or
span-level dense rewards that reflect the quality of each segment of the
output. We assess our approach on three text generation tasks: sentiment
control, language model detoxification, and summarization. Experimental results
show that incorporating artificial dense rewards in training yields consistent
performance gains over the PPO baseline with holistic rewards. Furthermore, in
a setting where the same model serves as both policy and critic, we demonstrate
that "self-critique" rewards also boost learning efficiency.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07386" title="Abstract">arXiv:2401.07386</a> [<a href="/pdf/2401.07386" title="Download PDF">pdf</a>, <a href="/ps/2401.07386" title="Download PostScript">ps</a>, <a href="/format/2401.07386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do machines learn? Evaluating the AIcon2abs method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Queiroz%2C+R+L">Rubens Lacerda Queiroz</a>, 
<a href="/search/cs?searchtype=author&query=Lima%2C+C">Cabral Lima</a>, 
<a href="/search/cs?searchtype=author&query=Sampaio%2C+F+F">Fabio Ferrentini Sampaio</a>, 
<a href="/search/cs?searchtype=author&query=Lima%2C+P+M+V">Priscila Machado Vieira Lima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This paper evaluates AIcon2abs (Queiroz et al., 2021), a recently proposed
method that enables awareness among the general public on machine learning.
Such is possible due to the use of WiSARD, an easily understandable machine
learning mechanism, thus requiring little effort and no technical background
from the target users. WiSARD is adherent to digital computing; training
consists of writing to RAM-type memories, and classification consists of
reading from these memories. The model enables easy visualization and
understanding of training and classification tasks' internal realization
through ludic activities. Furthermore, the WiSARD model does not require an
Internet connection for training and classification, and it can learn from a
few or one example. This feature makes it easier to observe the machine,
increasing its accuracy on a particular task with each new example used. WiSARD
can also create "mental images" of what it has learned so far, evidencing key
features pertaining to a given class. The assessment of the AIcon2abs method's
effectiveness was conducted through the evaluation of a remote course with a
workload of approximately 6 hours. It was completed by thirty-four Brazilian
subjects: 5 children between 8 and 11 years old; 5 adolescents between 12 and
17 years old; and 24 adults between 21 and 72 years old. Data analysis adopted
a hybrid approach. AIcon2abs was well-rated by almost 100% of the research
subjects, and the data collected revealed quite satisfactory results concerning
the intended outcomes. This research has been approved by the CEP/HUCFF/FM/UFRJ
Human Research Ethics Committee.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07387" title="Abstract">arXiv:2401.07387</a> [<a href="/pdf/2401.07387" title="Download PDF">pdf</a>, <a href="/format/2401.07387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising network interactions through device agnostic models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manneschi%2C+L">Luca Manneschi</a>, 
<a href="/search/cs?searchtype=author&query=Vidamour%2C+I+T">Ian T. Vidamour</a>, 
<a href="/search/cs?searchtype=author&query=Stenning%2C+K+D">Kilian D. Stenning</a>, 
<a href="/search/cs?searchtype=author&query=Gartside%2C+J+C">Jack C. Gartside</a>, 
<a href="/search/cs?searchtype=author&query=Swindells%2C+C">Charles Swindells</a>, 
<a href="/search/cs?searchtype=author&query=Venkat%2C+G">Guru Venkat</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+D">David Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Stepney%2C+S">Susan Stepney</a>, 
<a href="/search/cs?searchtype=author&query=Branford%2C+W+R">Will R. Branford</a>, 
<a href="/search/cs?searchtype=author&query=Hayward%2C+T">Thomas Hayward</a>, 
<a href="/search/cs?searchtype=author&query=Ellis%2C+M+O">Matt O Ellis</a>, 
<a href="/search/cs?searchtype=author&query=Vasilaki%2C+E">Eleni Vasilaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Physically implemented neural networks hold the potential to achieve the
performance of deep learning models by exploiting the innate physical
properties of devices as computational tools. This exploration of physical
processes for computation requires to also consider their intrinsic dynamics,
which can serve as valuable resources to process information. However, existing
computational methods are unable to extend the success of deep learning
techniques to parameters influencing device dynamics, which often lack a
precise mathematical description. In this work, we formulate a universal
framework to optimise interactions with dynamic physical systems in a fully
data-driven fashion. The framework adopts neural stochastic differential
equations as differentiable digital twins, effectively capturing both
deterministic and stochastic behaviours of devices. Employing differentiation
through the trained models provides the essential mathematical estimates for
optimizing a physical neural network, harnessing the intrinsic temporal
computation abilities of its physical nodes. To accurately model real devices'
behaviours, we formulated neural-SDE variants that can operate under a variety
of experimental settings. Our work demonstrates the framework's applicability
through simulations and physical implementations of interacting dynamic
devices, while highlighting the importance of accurately capturing system
stochasticity for the successful deployment of a physically defined neural
network.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07389" title="Abstract">arXiv:2401.07389</a> [<a href="/pdf/2401.07389" title="Download PDF">pdf</a>, <a href="/format/2401.07389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Rapid Review of Clustering Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hui Yin</a>, 
<a href="/search/cs?searchtype=author&query=Aryani%2C+A">Amir Aryani</a>, 
<a href="/search/cs?searchtype=author&query=Petrie%2C+S">Stephen Petrie</a>, 
<a href="/search/cs?searchtype=author&query=Nambissan%2C+A">Aishwarya Nambissan</a>, 
<a href="/search/cs?searchtype=author&query=Astudillo%2C+A">Aland Astudillo</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shengyuan Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Clustering algorithms aim to organize data into groups or clusters based on
the inherent patterns and similarities within the data. They play an important
role in today's life, such as in marketing and e-commerce, healthcare, data
organization and analysis, and social media. Numerous clustering algorithms
exist, with ongoing developments introducing new ones. Each algorithm possesses
its own set of strengths and weaknesses, and as of now, there is no universally
applicable algorithm for all tasks. In this work, we analyzed existing
clustering algorithms and classify mainstream algorithms across five different
dimensions: underlying principles and characteristics, data point assignment to
clusters, dataset capacity, predefined cluster numbers and application area.
This classification facilitates researchers in understanding clustering
algorithms from various perspectives and helps them identify algorithms
suitable for solving specific tasks. Finally, we discussed the current trends
and potential future directions in clustering algorithms. We also identified
and discussed open challenges and unresolved issues in the field.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07390" title="Abstract">arXiv:2401.07390</a> [<a href="/pdf/2401.07390" title="Download PDF">pdf</a>, <a href="/format/2401.07390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knee or ROC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wendt%2C+V">Veronica Wendt</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Byunggu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+C">Caleb Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junwhan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Self-attention transformers have demonstrated accuracy for image
classification with smaller data sets. However, a limitation is that tests
to-date are based upon single class image detection with known representation
of image populations. For instances where the input image classes may be
greater than one and test sets that lack full information on representation of
image populations, accuracy calculations must adapt. The Receiver Operating
Characteristic (ROC) accuracy thresh-old can address the instances of
multi-class input images. However, this approach is unsuitable in instances
where image population representation is unknown. We consider calculating
accuracy using the knee method to determine threshold values on an ad-hoc
basis. Results of ROC curve and knee thresholds for a multi-class data set,
created from CIFAR-10 images, are discussed for multi-class image detection.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07392" title="Abstract">arXiv:2401.07392</a> [<a href="/pdf/2401.07392" title="Download PDF">pdf</a>, <a href="/format/2401.07392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strong Inductive Bias: Gzip for binary image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scilipoti%2C+M">Marco Scilipoti</a>, 
<a href="/search/cs?searchtype=author&query=Fuster%2C+M">Marina Fuster</a>, 
<a href="/search/cs?searchtype=author&query=Ramele%2C+R">Rodrigo Ramele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning networks have become the de-facto standard in Computer Vision
for industry and research. However, recent developments in their cousin,
Natural Language Processing (NLP), have shown that there are areas where
parameter-less models with strong inductive biases can serve as computationally
cheaper and simpler alternatives. We propose such a model for binary image
classification: a nearest neighbor classifier combined with a general purpose
compressor like Gzip. We test and compare it against popular deep learning
networks like Resnet, EfficientNet and Mobilenet and show that it achieves
better accuracy and utilizes significantly less space, more than two order of
magnitude, within a few-shot setting. As a result, we believe that this
underlines the untapped potential of models with stronger inductive biases in
few-shot scenarios.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07393" title="Abstract">arXiv:2401.07393</a> [<a href="/pdf/2401.07393" title="Download PDF">pdf</a>, <a href="/format/2401.07393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Optimization Algorithm for Buffer and Splitter Minimization in  Phase-Skipping Adiabatic Quantum-Flux-Parametron Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aviles%2C+R+S">Robert S. Aviles</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P+A">Peter A. Beerel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Adiabatic Quantum-Flux-Parametron (AQFP) logic is a promising emerging device
technology that promises six orders of magnitude lower power than CMOS.
However, AQFP is challenged by operation at only ultra-low temperatures, has
high latency and area, and requires a complex clocking scheme. In particular,
every logic gate, buffer, and splitter must be clocked and each pair of
connected clocked gates requires overlapping alternating current (AC) clock
signals. In particular, clocked buffers need to be used to balance
re-convergent logic paths, a problem that is exacerbated by every multi-node
fanout needing a tree of clocked splitters. To reduce circuit area many works
have proposed buffer and splitter insertion optimization algorithms and recent
works have demonstrated a phase-skipping clocking scheme that reduces latency
and area. This paper proposes the first algorithm to optimize buffer and
splitter insertion for circuits that adopt phase-skipping and demonstrate the
resulting performance improvements for a suite of AQFP benchmark circuits.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07395" title="Abstract">arXiv:2401.07395</a> [<a href="/pdf/2401.07395" title="Download PDF">pdf</a>, <a href="/format/2401.07395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Beta Scoring in Deep Active Learning for  Multi-Label Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+D">Ngoc Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lan Du</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Within the scope of natural language processing, the domain of multi-label
text classification is uniquely challenging due to its expansive and uneven
label distribution. The complexity deepens due to the demand for an extensive
set of annotated data for training an advanced deep learning model, especially
in specialized fields where the labeling task can be labor-intensive and often
requires domain-specific knowledge. Addressing these challenges, our study
introduces a novel deep active learning strategy, capitalizing on the Beta
family of proper scoring rules within the Expected Loss Reduction framework. It
computes the expected increase in scores using the Beta Scoring Rules, which
are then transformed into sample vector representations. These vector
representations guide the diverse selection of informative samples, directly
linking this process to the model's expected proper score. Comprehensive
evaluations across both synthetic and real datasets reveal our method's
capability to often outperform established acquisition techniques in
multi-label text classification, presenting encouraging outcomes across various
architectural and dataset scenarios.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07398" title="Abstract">arXiv:2401.07398</a> [<a href="/pdf/2401.07398" title="Download PDF">pdf</a>, <a href="/format/2401.07398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross Domain Early Crop Mapping using CropGAN and CNN Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hui Huang</a>, 
<a href="/search/cs?searchtype=author&query=State%2C+R">Radu State</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Driven by abundant satellite imagery, machine learning-based approaches have
recently been promoted to generate high-resolution crop cultivation maps to
support many agricultural applications. One of the major challenges faced by
these approaches is the limited availability of ground truth labels. In the
absence of ground truth, existing work usually adopts the "direct transfer
strategy" that trains a classifier using historical labels collected from other
regions and then applies the trained model to the target region. Unfortunately,
the spectral features of crops exhibit inter-region and inter-annual
variability due to changes in soil composition, climate conditions, and crop
progress, the resultant models perform poorly on new and unseen regions or
years. This paper presents the Crop Generative Adversarial Network (CropGAN) to
address the above cross-domain issue. Our approach does not need labels from
the target domain. Instead, it learns a mapping function to transform the
spectral features of the target domain to the source domain (with labels) while
preserving their local structure. The classifier trained by the source domain
data can be directly applied to the transformed data to produce high-accuracy
early crop maps of the target domain. Comprehensive experiments across various
regions and years demonstrate the benefits and effectiveness of the proposed
approach. Compared with the widely adopted direct transfer strategy, the F1
score after applying the proposed CropGAN is improved by 13.13% - 50.98%
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07402" title="Abstract">arXiv:2401.07402</a> [<a href="/pdf/2401.07402" title="Download PDF">pdf</a>, <a href="/format/2401.07402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Implicity Neural Representation with Fourier Bases  Reparameterized Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kexuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuhang Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implicit Neural Representation (INR) as a mighty representation paradigm has
achieved success in various computer vision tasks recently. Due to the
low-frequency bias issue of vanilla multi-layer perceptron (MLP), existing
methods have investigated advanced techniques, such as positional encoding and
periodic activation function, to improve the accuracy of INR. In this paper, we
connect the network training bias with the reparameterization technique and
theoretically prove that weight reparameterization could provide us a chance to
alleviate the spectral bias of MLP. Based on our theoretical analysis, we
propose a Fourier reparameterization method which learns coefficient matrix of
fixed Fourier bases to compose the weights of MLP. We evaluate the proposed
Fourier reparameterization method on different INR tasks with various MLP
architectures, including vanilla MLP, MLP with positional encoding and MLP with
advanced activation function, etc. The superiority approximation results on
different MLP architectures clearly validate the advantage of our proposed
method. Armed with our Fourier reparameterization method, better INR with more
textures and less artifacts can be learned from the training data.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07404" title="Abstract">arXiv:2401.07404</a> [<a href="/pdf/2401.07404" title="Download PDF">pdf</a>, <a href="/format/2401.07404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness-aware Photovoltaic Generation Limits for Voltage Regulation in  Power Distribution Networks using Conservative Linear Approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gupta%2C+R+K">Rahul K. Gupta</a>, 
<a href="/search/eess?searchtype=author&query=Buason%2C+P">Paprapee Buason</a>, 
<a href="/search/eess?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages (to appear in the 8th Texas Power and Energy Conference, February 12-13, 2024.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes a framework for fairly curtailing photovoltaic (PV)
plants in response to the over-voltage problem in PV-rich distribution
networks. The framework imposes PV generation limits to avoid overvoltages.
These limits are computed a day ahead of real-time operations by solving an
offline stochastic optimization problem using forecasted scenarios for PV
generation and load demand. The framework minimizes the overall curtailment
while considering fairness by reducing disparities in curtailments among
different PV owners. We model the distribution grid constraints using a
conservative linear approximation (CLA) of the AC power flow equations which is
computed using a set of sampled power injections from the day-ahead predicted
scenarios. The proposed framework is numerically validated on a CIGRE benchmark
network interfaced with a large number of PV plants. We compare the performance
of the proposed framework versus an alternative formulation that does not
incorporate fairness considerations. To this end, we assess tradeoffs between
fairness, as quantified with the Jain Fairness Index (JFI), and the total
curtailed energy.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07408" title="Abstract">arXiv:2401.07408</a> [<a href="/pdf/2401.07408" title="Download PDF">pdf</a>, <a href="/format/2401.07408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Language and Graph Learning of Adsorption Configuration in  Catalysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ock%2C+J">Janghoon Ock</a>, 
<a href="/search/cs?searchtype=author&query=Magar%2C+R">Rishikesh Magar</a>, 
<a href="/search/cs?searchtype=author&query=Antony%2C+A">Akshay Antony</a>, 
<a href="/search/cs?searchtype=author&query=Farimani%2C+A+B">Amir Barati Farimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Adsorption energy, a reactivity descriptor, should be accurately assessed for
efficient catalyst screening. This evaluation requires determining the lowest
energy across various adsorption configurations on the catalytic surface. While
graph neural networks (GNNs) have gained popularity as a machine learning
approach for computing the energy of catalyst systems, they rely heavily on
atomic spatial coordinates and often lack clarity in their interpretations.
Recent advancements in language models have broadened their applicability to
predicting catalytic properties, allowing us to bypass the complexities of
graph representation. These models are adept at handling textual data, making
it possible to incorporate observable features in a human-readable format.
However, language models encounter challenges in accurately predicting the
energy of adsorption configurations, typically showing a high mean absolute
error (MAE) of about 0.71 eV. Our study addresses this limitation by
introducing a self-supervised multi-modal learning approach, termed
graph-assisted pretraining. This method significantly reduces the MAE to 0.35
eV through a combination of data augmentation, achieving comparable accuracy
with DimeNet++ while using 0.4% of its training data size. Furthermore, the
Transformer encoder at the core of the language model can provide insights into
the feature focus through its attention scores. This analysis shows that our
multimodal training effectively redirects the model's attention toward relevant
adsorption configurations from adsorbate-related features, enhancing prediction
accuracy and interpretability.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07410" title="Abstract">arXiv:2401.07410</a> [<a href="/pdf/2401.07410" title="Download PDF">pdf</a>, <a href="/format/2401.07410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Task DNS Security Analysis via High-Order Heterogeneous Graph  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+M">Meng Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">DNS is an essential Internet infrastructure to support network applications
and services, but is also a significant tool exploited by various cyberattacks.
Existing DNS security analysis techniques mostly focus on one specific task
associated with one single entity (e.g., domain) via conventional feature
engineering. They rely heavily on the labor-intensive feature selection and
largely ignore the intrinsic correlations among the heterogeneous DNS entities
(e.g., domain and IP). In this paper, I explore the potential of heterogeneous
graph embedding to automatically learn the behavior features of multiple DNS
entities, and to simultaneously support more than one security tasks.
Considering the joint optimization of malicious domain detection and IP
reputation evaluation as an example, I propose a novel joint DNS embedding
(JDE) model to formulate the DNS query behavior via a similarity-enhanced graph
with heterogeneous entities. The random walk technique is applied to the
heterogeneous graph to comprehensively explore the hidden homogeneous and
heterogeneous high-order proximities among domains and IPs. Extensive
experiments on real DNS traffic demonstrate that the joint optimization of
multiple tasks with the latent high-order proximities can lead to better
security analysis performance for all the tasks than respectively optimizing
each single task with the observable low-order proximity.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07411" title="Abstract">arXiv:2401.07411</a> [<a href="/pdf/2401.07411" title="Download PDF">pdf</a>, <a href="/format/2401.07411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Startup Delay Aware Short Video Ordering: Problem, Model, and A  Reinforcement Learning based Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhipeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongxiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baoxian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Short video applications have attracted billions of users on the Internet and
can satisfy diverse users' fragmented spare time with content-rich and
duration-short videos. To achieve fast playback at user side, existing short
video systems typically enforce burst transmission of initial segment of each
video when being requested for improved quality of user experiences. However,
such a way of burst transmissions can cause unexpected large startup delays at
user side. This is because users may frequently switch videos when sequentially
watching a list of short videos recommended by the server side, which can cause
excessive burst transmissions of initial segments of different short videos and
thus quickly deplete the network transmission capacity. In this paper, we adopt
token bucket to characterize the video transmission path between video server
and each user, and accordingly study how to effectively reduce the startup
delay of short videos by effectively arranging the viewing order of a video
list at the server side. We formulate the optimal video ordering problem for
minimizing the maximum video startup delay as a combinatorial optimization
problem and prove its NP-hardness. We accordingly propose a Partially Shared
Actor Critic reinforcement learning algorithm (PSAC) to learn optimized video
ordering strategy. Numerical results based on a real dataset provided by a
large-scale short video service provider demonstrate that the proposed PSAC
algorithm can significantly reduce the video startup delay compared to baseline
algorithms.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07414" title="Abstract">arXiv:2401.07414</a> [<a href="/pdf/2401.07414" title="Download PDF">pdf</a>, <a href="/format/2401.07414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging the power of transformers for guilt detection in text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meque%2C+A+G+M">Abdul Gafar Manuel Meque</a>, 
<a href="/search/cs?searchtype=author&query=Angel%2C+J">Jason Angel</a>, 
<a href="/search/cs?searchtype=author&query=Sidorov%2C+G">Grigori Sidorov</a>, 
<a href="/search/cs?searchtype=author&query=Gelbukh%2C+A">Alexander Gelbukh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, language models and deep learning techniques have
revolutionized natural language processing tasks, including emotion detection.
However, the specific emotion of guilt has received limited attention in this
field. In this research, we explore the applicability of three
transformer-based language models for detecting guilt in text and compare their
performance for general emotion detection and guilt detection. Our proposed
model outformed BERT and RoBERTa models by two and one points respectively.
Additionally, we analyze the challenges in developing accurate guilt-detection
models and evaluate our model's effectiveness in detecting related emotions
like "shame" through qualitative analysis of results.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07417" title="Abstract">arXiv:2401.07417</a> [<a href="/pdf/2401.07417" title="Download PDF">pdf</a>, <a href="/ps/2401.07417" title="Download PostScript">ps</a>, <a href="/format/2401.07417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Examination of Network and Contract-Based Blockchain  Storage Solutions for Decentralized Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lipeng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure, published in Proceedings of the 3rd International Conference on Digital Economy and Computer Application (DECA 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 3rd International Conference on Digital Economy
  and Computer Application (DECA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Decentralized applications (DApps), which are innovative blockchain-powered
software systems designed to serve as the fundamental building blocks for the
next generation of Internet services, have witnessed exponential growth in
recent years. This paper thoroughly compares and analyzes two blockchain-based
decentralized storage networks (DSNs), which are crucial foundations for DApp
and blockchain ecosystems. The study examines their respective mechanisms for
data persistence, strategies for enforcing data retention, and token economics.
In addition to delving into technical details, the suitability of each storage
solution for decentralized application development is assessed, taking into
consideration network performance, storage costs, and existing use cases. By
evaluating these factors, the paper aims to provide insights into the
effectiveness of these technologies in supporting the desirable properties of
truly decentralized blockchain applications. In conclusion, the findings of
this research are discussed and synthesized, offering valuable perspectives on
the capabilities of these technologies. It sheds light on their potential to
facilitate the development of DApps and provides an understanding of the
ongoing trends in blockchain development.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07426" title="Abstract">arXiv:2401.07426</a> [<a href="/pdf/2401.07426" title="Download PDF">pdf</a>, <a href="/format/2401.07426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Planning for the Abstraction and Reasoning Corpus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+C">Chao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lipovetzky%2C+N">Nir Lipovetzky</a>, 
<a href="/search/cs?searchtype=author&query=Ehinger%2C+K+A">Krista A. Ehinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024 (extended version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The Abstraction and Reasoning Corpus (ARC) is a general artificial
intelligence benchmark that poses difficulties for pure machine learning
methods due to its requirement for fluid intelligence with a focus on reasoning
and abstraction. In this work, we introduce an ARC solver, Generalized Planning
for Abstract Reasoning (GPAR). It casts an ARC problem as a generalized
planning (GP) problem, where a solution is formalized as a planning program
with pointers. We express each ARC problem using the standard Planning Domain
Definition Language (PDDL) coupled with external functions representing
object-centric abstractions. We show how to scale up GP solvers via domain
knowledge specific to ARC in the form of restrictions over the actions model,
predicates, arguments and valid structure of planning programs. Our experiments
demonstrate that GPAR outperforms the state-of-the-art solvers on the
object-centric tasks of the ARC, showing the effectiveness of GP and the
expressiveness of PDDL to model ARC problems. The challenges provided by the
ARC benchmark motivate research to advance existing GP solvers and understand
new relations with other planning computational models. Code is available at
github.com/you68681/GPAR.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07427" title="Abstract">arXiv:2401.07427</a> [<a href="/pdf/2401.07427" title="Download PDF">pdf</a>, <a href="/ps/2401.07427" title="Download PostScript">ps</a>, <a href="/format/2401.07427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMC&#x27;24 &quot;Analysis and Synthesis of the Disturbance Observer-based Robust  Force Control Systems in State Space&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Emre%2C+S">Sariyildiz Emre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper extends the result of my previous papers on the analysis and
synthesis of disturbance observer based robust control systems in state space.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07429" title="Abstract">arXiv:2401.07429</a> [<a href="/pdf/2401.07429" title="Download PDF">pdf</a>, <a href="/format/2401.07429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Boolean Constraint Propagation for Efficient SAT-Solving on  FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Govindasamy%2C+H">Hariprasadh Govindasamy</a>, 
<a href="/search/cs?searchtype=author&query=Esfandiari%2C+B">Babak Esfandiari</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+P">Paulo Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">We present a hardware-accelerated SAT solver targeting processor/Field
Programmable Gate Arrays (FPGA) SoCs. Our solution accelerates the most
expensive subroutine of the Davis-Putnam-Logemann-Loveland (DPLL) algorithm,
Boolean Constraint Propagation (BCP) through fine-grained FPGA parallelism.
Unlike prior state-of-the-art solutions, our solver eliminates costly clause
look-up operations by assigning clauses directly to clause processors on the
FPGA and dividing large formulas into smaller partitions manageable by FPGA.
Partitions are hot-swapped during runtime as required and the supported formula
size is limited only by available external memory, not on-chip FPGA memory. We
evaluate our solver on a Xilinx Zynq platform with results showing quicker
execution time across various formula sizes, subject to formula partitioning
strategy. Compared to prior state-of-the-art, we achieve 1.7x and 1.1x speed up
on BCP for 2 representative benchmarks and up to 6x total speedup over
software-only implementation.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07430" title="Abstract">arXiv:2401.07430</a> [<a href="/pdf/2401.07430" title="Download PDF">pdf</a>, <a href="/ps/2401.07430" title="Download PostScript">ps</a>, <a href="/format/2401.07430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMC&#x27;24 &quot;A Novel Stiffness Modulation Mechanism for Energy Efficient  Variable Stiffness Actuators&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emre%2C+S">Sariyildiz Emre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper presents a new stiffness modulation mechanism that enables
infinite-range stiffness modulation in a fast manner. The proposed stiffness
modulation mechanism can help improve many robot environment interaction
applications such as human-robot collaboration and robotic rehabilitation.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07433" title="Abstract">arXiv:2401.07433</a> [<a href="/pdf/2401.07433" title="Download PDF">pdf</a>, <a href="/format/2401.07433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Successive-Cancellation Decoding of 2 x 2 Kernel Non-Binary Polar  Codes: Identification, Decoding and Simplification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farsiabi%2C+A">Ali Farsiabi</a>, 
<a href="/search/cs?searchtype=author&query=Ebrahimzad%2C+H">Hamid Ebrahimzad</a>, 
<a href="/search/cs?searchtype=author&query=Ardakani%2C+M">Masoud Ardakani</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuandong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Non-binary polar codes (NBPCs) decoded by successive cancellation (SC)
algorithm have remarkable bit-error-rate performance compared to the binary
polar codes (BPCs). Due to the serial nature, SC decoding suffers from large
latency. The latency issue in BPCs has been the topic of extensive research and
it has been notably resolved by the introduction of fast SC-based decoders.
However, the vast majority of research on NBPCs is devoted to issues concerning
design and efficient implementation. In this paper, we propose fast SC decoding
for NBPCs constructed based on 2 x 2 kernels. In particular, we identify
various non-binary special nodes in the SC decoding tree of NBPCs and propose
their fast decoding. This way, we avoid traversing the full decoding tree and
significantly reduce the decoding delay compared to symbol-by-symbol SC
decoding. We also propose a simplified NBPC structure that facilitates the
procedure of non-binary fast SC decoding. Using our proposed fast non-binary
decoder, we observed an improvement of up to 95% in latency concerning the
original SC decoding. This is while our proposed fast SC decoder for NBPCs
incurs no error-rate loss.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07437" title="Abstract">arXiv:2401.07437</a> [<a href="/pdf/2401.07437" title="Download PDF">pdf</a>, <a href="/format/2401.07437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoNuS: Boundary Mining for Nuclei Segmentation with Partial Point Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Medical Imaging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nuclei segmentation is a fundamental prerequisite in the digital pathology
workflow. The development of automated methods for nuclei segmentation enables
quantitative analysis of the wide existence and large variances in nuclei
morphometry in histopathology images. However, manual annotation of tens of
thousands of nuclei is tedious and time-consuming, which requires significant
amount of human effort and domain-specific expertise. To alleviate this
problem, in this paper, we propose a weakly-supervised nuclei segmentation
method that only requires partial point labels of nuclei. Specifically, we
propose a novel boundary mining framework for nuclei segmentation, named BoNuS,
which simultaneously learns nuclei interior and boundary information from the
point labels. To achieve this goal, we propose a novel boundary mining loss,
which guides the model to learn the boundary information by exploring the
pairwise pixel affinity in a multiple-instance learning manner. Then, we
consider a more challenging problem, i.e., partial point label, where we
propose a nuclei detection module with curriculum learning to detect the
missing nuclei with prior morphological knowledge. The proposed method is
validated on three public datasets, MoNuSeg, CPM, and CoNIC datasets.
Experimental results demonstrate the superior performance of our method to the
state-of-the-art weakly-supervised nuclei segmentation methods. Code:
https://github.com/hust-linyi/bonus.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07439" title="Abstract">arXiv:2401.07439</a> [<a href="/pdf/2401.07439" title="Download PDF">pdf</a>, <a href="/format/2401.07439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask-adaptive Gated Convolution and Bi-directional Progressive Fusion  Network for Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tingxuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jiacheng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shizhuo Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tong">Tong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongyue Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth completion is a critical task for handling depth images with missing
pixels, which can negatively impact further applications. Recent approaches
have utilized Convolutional Neural Networks (CNNs) to reconstruct depth images
with the assistance of color images. However, vanilla convolution has
non-negligible drawbacks in handling missing pixels. To solve this problem, we
propose a new model for depth completion based on an encoder-decoder structure.
Our model introduces two key components: the Mask-adaptive Gated Convolution
(MagaConv) architecture and the Bi-directional Progressive Fusion (BP-Fusion)
module. The MagaConv architecture is designed to acquire precise depth features
by modulating convolution operations with iteratively updated masks, while the
BP-Fusion module progressively integrates depth and color features, utilizing
consecutive bi-directional fusion structures in a global perspective. Extensive
experiments on popular benchmarks, including NYU-Depth V2, DIML, and SUN RGB-D,
demonstrate the superiority of our model over state-of-the-art methods. We
achieved remarkable performance in completing depth maps and outperformed
existing approaches in terms of accuracy and reliability.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07440" title="Abstract">arXiv:2401.07440</a> [<a href="/pdf/2401.07440" title="Download PDF">pdf</a>, <a href="/format/2401.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fairness of Redistricting Ghost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jia-Wei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Amenta%2C+N">Nina Amenta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We explore the fairness of a redistricting game introduced by Mixon and
Villar, which provides a two-party protocol for dividing a state into electoral
districts, without the participation of an impartial independent authority. We
analyze the game in an abstract setting that ignores the geographic
distribution of voters and assumes that voter preferences are fixed and known.
We first show that the minority player can always win at least $p-1$ districts,
where $p$ is proportional to the percentage of minority voters, and that when
the minority is large they can win more than $p$ districts. We also show that a
"cracking" strategy by the majority party limits the number of districts the
minority player can win as a function of the size of the minority.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07441" title="Abstract">arXiv:2401.07441</a> [<a href="/pdf/2401.07441" title="Download PDF">pdf</a>, <a href="/format/2401.07441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability Analysis of ChatGPT-based Sentiment Analysis in AI Quality  Assurance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+T">Tinghui Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=MaungMaung%2C+A">AprilPyone MaungMaung</a>, 
<a href="/search/cs?searchtype=author&query=Konishi%2C+K">Koichi Konishi</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yoshiki Seo</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the era of large AI models, the complex architecture and vast parameters
present substantial challenges for effective AI quality management (AIQM), e.g.
large language model (LLM). This paper focuses on investigating the quality
assurance of a specific LLM-based AI product--a ChatGPT-based sentiment
analysis system. The study delves into stability issues related to both the
operation and robustness of the expansive AI model on which ChatGPT is based.
Experimental analysis is conducted using benchmark datasets for sentiment
analysis. The results reveal that the constructed ChatGPT-based sentiment
analysis system exhibits uncertainty, which is attributed to various
operational factors. It demonstrated that the system also exhibits stability
issues in handling conventional small text attacks involving robustness.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07444" title="Abstract">arXiv:2401.07444</a> [<a href="/pdf/2401.07444" title="Download PDF">pdf</a>, <a href="/ps/2401.07444" title="Download PostScript">ps</a>, <a href="/format/2401.07444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-cost, Lightweight Electronic Flow Regulators for Throttling Liquid  Rocket Engines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+V">Vint Lee</a>, 
<a href="/search/eess?searchtype=author&query=Roy%2C+S">Sohom Roy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 15 figures, Presented at the 74th International Astronautical Congress (IAC), Baku, Azerbaijan, 2-6 October 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">For small-scale liquid rockets, pressure-fed systems are commonly favoured
due to their simplicity and low weight. In such systems, accurate regulation of
both tank and injector pressures over a wide range of upstream pressures is
critical $-$ more accurate regulation allows for higher engine efficiency and
minimal tank mass, thus improving flight performance. However, existing methods
such as dome-loaded pressure regulators are inflexible, or require extensive
characterization to function accurately. These methods also suffer from limited
orifice size, droop, and slow reaction times, making them unsuitable for
throttling by adjusting pressures in flight, which are increasingly important
as propulsively landing rockets become more common. To overcome these
challenges, we designed an electronic pressure regulator (eReg), a multi-input
multi-output system utilising closed loop feedback to accurately control
downstream pressures. Our design is simple, low-cost and robust: with a single
ball valve actuated by a motor, we regulate both gaseous pressurant and
cryogenic liquid propellant at high flow rates (1.14 kg/s of liquid; 0.39 kg/s
of gas) and upstream pressures (310 bar). Using 2 eRegs to regulate propellant
tank pressures, and 2 eRegs for regulating propellant flow to the engine, we
demonstrated our system's ability, in a static fire test, to regulate pressures
accurately (within 0.2 bar) while simultaneously throttling our engine. To the
best of our knowledge, this is the first time any undergraduate team has
successfully throttled a liquid bipropellant engine.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07445" title="Abstract">arXiv:2401.07445</a> [<a href="/pdf/2401.07445" title="Download PDF">pdf</a>, <a href="/format/2401.07445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GACE: Learning Graph-Based Cross-Page Ads Embedding For Click-Through  Rate Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuliang Du</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Congyun Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yujiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingbo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+T">Tao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+P">Piqi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Cong Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Predicting click-through rate (CTR) is the core task of many ads online
recommendation systems, which helps improve user experience and increase
platform revenue. In this type of recommendation system, we often encounter two
main problems: the joint usage of multi-page historical advertising data and
the cold start of new ads. In this paper, we proposed GACE, a graph-based
cross-page ads embedding generation method. It can warm up and generate the
representation embedding of cold-start and existing ads across various pages.
Specifically, we carefully build linkages and a weighted undirected graph model
considering semantic and page-type attributes to guide the direction of feature
fusion and generation. We designed a variational auto-encoding task as
pre-training module and generated embedding representations for new and old ads
based on this task. The results evaluated in the public dataset AliEC from
RecBole and the real-world industry dataset from Alipay show that our GACE
method is significantly superior to the SOTA method. In the online A/B test,
the click-through rate on three real-world pages from Alipay has increased by
3.6%, 2.13%, and 3.02%, respectively. Especially in the cold-start task, the
CTR increased by 9.96%, 7.51%, and 8.97%, respectively.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07446" title="Abstract">arXiv:2401.07446</a> [<a href="/pdf/2401.07446" title="Download PDF">pdf</a>, <a href="/format/2401.07446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized RIS-aided mmWave Massive MIMO Channel Estimation with Uniform  Planar Arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Cunhua Pan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangzhou Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we investigate a cascaded channel estimation method for a
millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) system
aided by a reconfigurable intelligent surface (RIS) with the BS equipped with
low-resolution analog-to-digital converters (ADCs), where the BS and the RIS
are both equipped with a uniform planar array (UPA). Due to the sparse property
of mmWave channel, the channel estimation can be solved as a compressed sensing
(CS) problem. However, the low-resolution quantization cause severe information
loss of signals, and traditional CS algorithms are unable to work well. To
recovery the signal and the sparse angular domain channel from quantization, we
introduce Bayesian inference and efficient vector approximate message passing
(VAMP) algorithm to solve the quantize output CS problem. To further improve
the efficiency of the VAMP algorithm, a Fast Fourier Transform (FFT) based fast
computation method is derived. Simulation results demonstrate the effectiveness
and the accuracy of the proposed cascaded channel estimation method for the
RIS-aided mmWave massive MIMO system with few-bit ADCs. Furthermore, the
proposed channel estimation method can reach an acceptable performance gap
between the low-resolution ADCs and the infinite ADCs for the low
signal-to-noise ratio (SNR), which implies the applicability of few-bit ADCs in
practice.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07447" title="Abstract">arXiv:2401.07447</a> [<a href="/pdf/2401.07447" title="Download PDF">pdf</a>, <a href="/ps/2401.07447" title="Download PostScript">ps</a>, <a href="/format/2401.07447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Taec: a Manually annotated text dataset for trait and phenotype  extraction and entity linking in wheat breeding literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9dellec%2C+C">Claire N&#xe9;dellec</a>, 
<a href="/search/cs?searchtype=author&query=Sauvion%2C+C">Clara Sauvion</a>, 
<a href="/search/cs?searchtype=author&query=Bossy%2C+R">Robert Bossy</a>, 
<a href="/search/cs?searchtype=author&query=Borovikova%2C+M">Mariya Borovikova</a>, 
<a href="/search/cs?searchtype=author&query=Del%C3%A9ger%2C+L">Louise Del&#xe9;ger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Wheat varieties show a large diversity of traits and phenotypes. Linking them
to genetic variability is essential for shorter and more efficient wheat
breeding programs. Newly desirable wheat variety traits include disease
resistance to reduce pesticide use, adaptation to climate change, resistance to
heat and drought stresses, or low gluten content of grains. Wheat breeding
experiments are documented by a large body of scientific literature and
observational data obtained in-field and under controlled conditions. The
cross-referencing of complementary information from the literature and
observational data is essential to the study of the genotype-phenotype
relationship and to the improvement of wheat selection. The scientific
literature on genetic marker-assisted selection describes much information
about the genotype-phenotype relationship. However, the variety of expressions
used to refer to traits and phenotype values in scientific articles is a hinder
to finding information and cross-referencing it. When trained adequately by
annotated examples, recent text mining methods perform highly in named entity
recognition and linking in the scientific domain. While several corpora contain
annotations of human and animal phenotypes, currently, no corpus is available
for training and evaluating named entity recognition and entity-linking methods
in plant phenotype literature. The Triticum aestivum trait Corpus is a new gold
standard for traits and phenotypes of wheat. It consists of 540 PubMed
references fully annotated for trait, phenotype, and species named entities
using the Wheat Trait and Phenotype Ontology and the species taxonomy of the
National Center for Biotechnology Information. A study of the performance of
tools trained on the Triticum aestivum trait Corpus shows that the corpus is
suitable for the training and evaluation of named entity recognition and
linking.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07448" title="Abstract">arXiv:2401.07448</a> [<a href="/pdf/2401.07448" title="Download PDF">pdf</a>, <a href="/format/2401.07448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Logic Enabled Personalized Federated Learning Through Property  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Ziyan An</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T+T">Taylor T. Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Meiyi Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in federated learning (FL) have greatly facilitated the
development of decentralized collaborative applications, particularly in the
domain of Artificial Intelligence of Things (AIoT). However, a critical aspect
missing from the current research landscape is the ability to enable
data-driven client models with symbolic reasoning capabilities. Specifically,
the inherent heterogeneity of participating client devices poses a significant
challenge, as each client exhibits unique logic reasoning properties. Failing
to consider these device-specific specifications can result in critical
properties being missed in the client predictions, leading to suboptimal
performance. In this work, we propose a new training paradigm that leverages
temporal logic reasoning to address this issue. Our approach involves enhancing
the training process by incorporating mechanically generated logic expressions
for each FL client. Additionally, we introduce the concept of aggregation
clusters and develop a partitioning algorithm to effectively group clients
based on the alignment of their temporal reasoning properties. We evaluate the
proposed method on two tasks: a real-world traffic volume prediction task
consisting of sensory data from fifteen states and a smart city multi-task
prediction utilizing synthetic data. The evaluation results exhibit clear
improvements, with performance accuracy improved by up to 54% across all
sequential prediction models.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07450" title="Abstract">arXiv:2401.07450</a> [<a href="/pdf/2401.07450" title="Download PDF">pdf</a>, <a href="/format/2401.07450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Fashion Design with Multi-stage Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhifeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=li%2C+H">Hao li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Huiming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Ying Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Cross-modal fashion synthesis and editing offer intelligent support to
fashion designers by enabling the automatic generation and local modification
of design drafts.While current diffusion models demonstrate commendable
stability and controllability in image synthesis,they still face significant
challenges in generating fashion design from abstract design elements and
fine-grained editing.Abstract sensory expressions, \eg office, business, and
party, form the high-level design concepts, while measurable aspects like
sleeve length, collar type, and pant length are considered the low-level
attributes of clothing.Controlling and editing fashion images using lengthy
text descriptions poses a difficulty.In this paper, we propose HieraFashDiff,a
novel fashion design method using the shared multi-stage diffusion model
encompassing high-level design concepts and low-level clothing attributes in a
hierarchical structure.Specifically, we categorized the input text into
different levels and fed them in different time step to the diffusion model
according to the criteria of professional clothing designers.HieraFashDiff
allows designers to add low-level attributes after high-level prompts for
interactive editing incrementally.In addition, we design a differentiable loss
function in the sampling process with a mask to keep non-edit
areas.Comprehensive experiments performed on our newly conducted Hierarchical
fashion dataset,demonstrate that our proposed method outperforms other
state-of-the-art competitors.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07451" title="Abstract">arXiv:2401.07451</a> [<a href="/pdf/2401.07451" title="Download PDF">pdf</a>, <a href="/format/2401.07451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zone-Specific CSI Feedback for Massive MIMO: A Situation-Aware Deep  Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Datasets and code files will be available on the DeepMIMO website: <a href="https://www.deepmimo.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Massive MIMO basestations, operating with frequency-division duplexing (FDD),
require the users to feedback their channel state information (CSI) in order to
design the precoding matrices. Given the powerful capabilities of deep neural
networks in learning quantization codebooks, utilizing these networks in
compressing the channels and reducing the massive MIMO CSI feedback overhead
has recently gained increased interest. Learning one model, however, for the
full cell or sector may not be optimal as the channel distribution could change
significantly from one \textit{zone} (an area or region) to another. In this
letter, we introduce the concept of \textit{zone-specific} CSI feedback. By
partitioning the site space into multiple channel zones, the underlying channel
distribution can be efficiently leveraged to reduce the CSI feedback. This
concept leverages the implicit or explicit user position information to select
the right zone-specific model and its parameters. To facilitate the evaluation
of associated overhead, we introduce two novel metrics named \textit{model
parameters transmission rate} (MPTR) and \textit{model parameters update rate}
(MPUR). They jointly provide important insights and guidance for the system
design and deployment. Simulation results show that significant gains could be
achieved by the proposed framework. For example, using the large-scale Boston
downtown scenario of DeepMIMO, the proposed zone-specific CSI feedback approach
can on average achieve around 6dB NMSE gain compared to the other solutions,
while keeping the same model complexity.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07453" title="Abstract">arXiv:2401.07453</a> [<a href="/pdf/2401.07453" title="Download PDF">pdf</a>, <a href="/format/2401.07453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Editing at Scale leads to Gradual and Catastrophic Forgetting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshat Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Anurag Rao</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G">Gopala Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Editing knowledge in large language models is an attractive capability to
have which allows us to correct incorrectly learnt facts during pre-training,
as well as update the model with an ever-growing list of new facts. While
existing model editing techniques have shown promise, they are usually
evaluated using metrics for reliability, specificity and generalization over
one or few edits. We argue that for model editing to have practical utility, we
must be able to make multiple edits to the same model. With this in mind, we
evaluate the current model editing methods at scale, focusing on two state of
the art methods: ROME and MEMIT. We find that as the model is edited
sequentially with multiple facts, it continually forgets previously edited
facts and the ability to perform downstream tasks. This forgetting happens in
two phases -- an initial gradual but progressive forgetting phase followed by
abrupt or catastrophic forgetting phase. Both gradual and catastrophic
forgetting limit the usefulness of model editing methods at scale -- the former
making model editing less effective as multiple edits are made to the model
while the latter caps the scalability of such model editing methods. Our
analysis also highlights other key limitations of ROME and MEMIT at scale. With
our work, we push for the development and evaluation of model editing methods
keeping scalability in mind.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07454" title="Abstract">arXiv:2401.07454</a> [<a href="/pdf/2401.07454" title="Download PDF">pdf</a>, <a href="/format/2401.07454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolutionary Multi-Objective Diversity Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+A+V">Anh Viet Do</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+A">Aneta Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Creating diverse sets of high quality solutions has become an important
problem in recent years. Previous works on diverse solutions problems consider
solutions' objective quality and diversity where one is regarded as the
optimization goal and the other as the constraint. In this paper, we treat this
problem as a bi-objective optimization problem, which is to obtain a range of
quality-diversity trade-offs. To address this problem, we frame the
evolutionary process as evolving a population of populations, and present a
suitable general implementation scheme that is compatible with existing
evolutionary multi-objective search methods. We realize the scheme in NSGA-II
and SPEA2, and test the methods on various instances of maximum coverage,
maximum cut and minimum vertex cover problems. The resulting non-dominated
populations exhibit rich qualitative features, giving insights into the
optimization instances and the quality-diversity trade-offs they induce.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07456" title="Abstract">arXiv:2401.07456</a> [<a href="/pdf/2401.07456" title="Download PDF">pdf</a>, <a href="/format/2401.07456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Only Send What You Need: Learning to Communicate Efficiently in  Federated Multilingual Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Y">Yun-Wei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+D">Dong-Jun Han</a>, 
<a href="/search/cs?searchtype=author&query=Brinton%2C+C+G">Christopher G. Brinton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) is a promising approach for solving multilingual
tasks, potentially enabling clients with their own language-specific data to
collaboratively construct a high-quality neural machine translation (NMT)
model. However, communication constraints in practical network systems present
challenges for exchanging large-scale NMT engines between FL parties. In this
paper, we propose a meta-learning-based adaptive parameter selection
methodology, MetaSend, that improves the communication efficiency of model
transmissions from clients during FL-based multilingual NMT training. Our
approach learns a dynamic threshold for filtering parameters prior to
transmission without compromising the NMT model quality, based on the tensor
deviations of clients between different FL rounds. Through experiments on two
NMT datasets with different language distributions, we demonstrate that
MetaSend obtains substantial improvements over baselines in translation quality
in the presence of a limited communication budget.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07457" title="Abstract">arXiv:2401.07457</a> [<a href="/pdf/2401.07457" title="Download PDF">pdf</a>, <a href="/format/2401.07457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Concept-Guided Prompt Learning for Generalization in Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Ke Yu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yushun Tang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhihai He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contrastive Language-Image Pretraining (CLIP) model has exhibited remarkable
efficacy in establishing cross-modal connections between texts and images,
yielding impressive performance across a broad spectrum of downstream
applications through fine-tuning. However, for generalization tasks, the
current fine-tuning methods for CLIP, such as CoOp and CoCoOp, demonstrate
relatively low performance on some fine-grained datasets. We recognize the
underlying reason is that these previous methods only projected global features
into the prompt, neglecting the various visual concepts, such as colors,
shapes, and sizes, which are naturally transferable across domains and play a
crucial role in generalization tasks. To address this issue, in this work, we
propose Concept-Guided Prompt Learning (CPL) for vision-language models.
Specifically, we leverage the well-learned knowledge of CLIP to create a visual
concept cache to enable concept-guided prompting. In order to refine the text
features, we further develop a projector that transforms multi-level visual
features into text features. We observe that this concept-guided prompt
learning approach is able to achieve enhanced consistency between visual and
linguistic modalities. Extensive experimental results demonstrate that our CPL
method significantly improves generalization capabilities compared to the
current state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07459" title="Abstract">arXiv:2401.07459</a> [<a href="/pdf/2401.07459" title="Download PDF">pdf</a>, <a href="/format/2401.07459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Segmentation in Multiple Adverse Weather Conditions with Domain  Knowledge Retention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wending Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+R+T">Robby T. Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation's performance is often compromised when applied to
unlabeled adverse weather conditions. Unsupervised domain adaptation is a
potential approach to enhancing the model's adaptability and robustness to
adverse weather. However, existing methods encounter difficulties when
sequentially adapting the model to multiple unlabeled adverse weather
conditions. They struggle to acquire new knowledge while also retaining
previously learned knowledge.To address these problems, we propose a semantic
segmentation method for multiple adverse weather conditions that incorporates
adaptive knowledge acquisition, pseudolabel blending, and weather composition
replay. Our adaptive knowledge acquisition enables the model to avoid learning
from extreme images that could potentially cause the model to forget. In our
approach of blending pseudo-labels, we not only utilize the current model but
also integrate the previously learned model into the ongoing learning process.
This collaboration between the current teacher and the previous model enhances
the robustness of the pseudo-labels for the current target. Our weather
composition replay mechanism allows the model to continuously refine its
previously learned weather information while simultaneously learning from the
new target domain. Our method consistently outperforms the stateof-the-art
methods, and obtains the best performance with averaged mIoU (%) of 65.7 and
the lowest forgetting (%) of 3.6 against 60.1 and 11.3, on the ACDC datasets
for a four-target continual multi-target domain adaptation.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07465" title="Abstract">arXiv:2401.07465</a> [<a href="/pdf/2401.07465" title="Download PDF">pdf</a>, <a href="/format/2401.07465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power Flow Analysis Using Deep Neural Networks in Three-Phase Unbalanced  Smart Distribution Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+D">Deepak Tiwari</a>, 
<a href="/search/eess?searchtype=author&query=Zideh%2C+M+J">Mehdi Jabbari Zideh</a>, 
<a href="/search/eess?searchtype=author&query=Talreja%2C+V">Veeru Talreja</a>, 
<a href="/search/eess?searchtype=author&query=Verma%2C+V">Vishal Verma</a>, 
<a href="/search/eess?searchtype=author&query=Solanki%2C+S+K">Sarika K. Solanki</a>, 
<a href="/search/eess?searchtype=author&query=Solanki%2C+J">Jignesh Solanki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Most power systems' approaches are currently tending towards stochastic and
probabilistic methods due to the high variability of renewable sources and the
stochastic nature of loads. Conventional power flow (PF) approaches such as
forward-backward sweep (FBS) and Newton-Raphson require a high number of
iterations to solve non-linear PF equations making them computationally very
intensive. PF is the most important study performed by utility, required in all
stages of the power system, especially in operations and planning. This paper
discusses the applications of deep learning (DL) to predict PF solutions for
three-phase unbalanced power distribution grids. Three deep neural networks
(DNNs); Radial Basis Function Network (RBFnet), Multi-Layer Perceptron (MLP),
and Convolutional Neural Network (CNN), are proposed in this paper to predict
PF solutions. The PF problem is formulated as a multi-output regression model
where two or more output values are predicted based on the inputs. The training
and testing data are generated through the OpenDSS-MATLAB COM interface. These
methods are completely data-driven where the training relies on reducing the
mismatch at each node without the need for the knowledge of the system. The
novelty of the proposed methodology is that the models can accurately predict
the PF solutions for the unbalanced distribution grids with mutual coupling and
are robust to different R/X ratios, topology changes as well as generation and
load variability introduced by the integration of distributed energy resources
(DERs) and electric vehicles (EVs). To test the efficacy of the DNN models,
they are applied to IEEE 4-node and 123-node test cases, and the American
Electric Power (AEP) feeder model. The PF results for RBFnet, MLP, and CNN
models are discussed in this paper demonstrating that all three DNN models
provide highly accurate results in predicting PF solutions.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07466" title="Abstract">arXiv:2401.07466</a> [<a href="/pdf/2401.07466" title="Download PDF">pdf</a>, <a href="/format/2401.07466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Instructions Are Not Always Helpful: Assessing the Efficacy of  Instruction Fine-tuning for Software Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yusuf%2C+I+N+B">Imam Nur Bani Yusuf</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lingxiao Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Software, while beneficial, poses potential cybersecurity risks due to
inherent vulnerabilities. Detecting these vulnerabilities is crucial, and deep
learning has shown promise as an effective tool for this task due to its
ability to perform well without extensive feature engineering. However, a
challenge in deploying deep learning for vulnerability detection is the limited
availability of training data. Recent research highlights the deep learning
efficacy in diverse tasks. This success is attributed to instruction
fine-tuning, a technique that remains under-explored in the context of
vulnerability detection. This paper investigates the capability of models,
specifically a recent language model, to generalize beyond the programming
languages used in their training data. It also examines the role of natural
language instructions in enhancing this generalization. Our study evaluates the
model performance on a real-world dataset to predict vulnerable code. We
present key insights and lessons learned, contributing to understanding the
deep learning application in software vulnerability detection.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07467" title="Abstract">arXiv:2401.07467</a> [<a href="/pdf/2401.07467" title="Download PDF">pdf</a>, <a href="/format/2401.07467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selection Improvements for the Parallel Iterative Algorithm for Stable  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wynn%2C+S">Scott Wynn</a>, 
<a href="/search/cs?searchtype=author&query=Kyritsis%2C+A">Alec Kyritsis</a>, 
<a href="/search/cs?searchtype=author&query=Alberi%2C+S">Stephora Alberi</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+E">Enyue Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Sequential algorithms for the Stable Matching Problem are often too slow in
the context of some large scale applications like switch scheduling. Parallel
architectures can offer a notable decrease in runtime complexity. We propose a
stable matching algorithm using n^2 processors that converges in O(nlog(n))
average runtime. The algorithm is structurally based on the Parallel Iterative
Improvement (PII) algorithm, which successfully finds a stable matching in
approximately 90% of cases. We suggest alternative selection methods for pairs
in the PII algorithm, called Right-Minimum and Dynamic Selection, resulting in
full convergence over 3.3 million trials and generally much faster termination.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07468" title="Abstract">arXiv:2401.07468</a> [<a href="/pdf/2401.07468" title="Download PDF">pdf</a>, <a href="/format/2401.07468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CarSpeedNet: A Deep Neural Network-based Car Speed Estimation from  Smartphone Accelerometer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Or%2C+B">Barak Or</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this study, a novel deep neural network (DNN) architecture, CarSpeedNet,
is introduced to estimate car speed using three-axis accelerometer data from
smartphones. Utilizing 13 hours of data collected from smartphones mounted in
vehicles navigating through various regions in Israel, the CarSpeedNet
effectively learns the relationship between measured smartphone acceleration
and car speed. Ground truth speed data was obtained at 1[Hz] from the GPS
receiver in the smartphones. The proposed model enables high-frequency speed
estimation, incorporating historical inputs. Our trained model demonstrates
exceptional accuracy in car speed estimation, achieving a precision of less
than 0.72[m/s] during an extended driving test, solely relying on smartphone
accelerometer data without any connectivity to the car.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07469" title="Abstract">arXiv:2401.07469</a> [<a href="/pdf/2401.07469" title="Download PDF">pdf</a>, <a href="/ps/2401.07469" title="Download PostScript">ps</a>, <a href="/format/2401.07469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Hierarchical Feature Sparse Framework for Occluded Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yihu Song</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaishi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Most existing methods tackle the problem of occluded person re-identification
(ReID) by utilizing auxiliary models, resulting in a complicated and
inefficient ReID framework that is unacceptable for real-time applications. In
this work, a speed-up person ReID framework named SUReID is proposed to
mitigate occlusion interference while speeding up inference. The SUReID
consists of three key components: hierarchical token sparsification (HTS)
strategy, non-parametric feature alignment knowledge distillation (NPKD), and
noise occlusion data augmentation (NODA). The HTS strategy works by pruning the
redundant tokens in the vision transformer to achieve highly effective
self-attention computation and eliminate interference from occlusions or
background noise. However, the pruned tokens may contain human part features
that contaminate the feature representation and degrade the performance. To
solve this problem, the NPKD is employed to supervise the HTS strategy,
retaining more discriminative tokens and discarding meaningless ones.
Furthermore, the NODA is designed to introduce more noisy samples, which
further trains the ability of the HTS to disentangle different tokens.
Experimental results show that the SUReID achieves superior performance with
surprisingly fast inference.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07470" title="Abstract">arXiv:2401.07470</a> [<a href="/pdf/2401.07470" title="Download PDF">pdf</a>, <a href="/ps/2401.07470" title="Download PostScript">ps</a>, <a href="/format/2401.07470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing deep learning models for the identification of enhancers and  super-enhancers based on genomic and epigenomic features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahani%2C+Z">Zahra Ahani</a>, 
<a href="/search/cs?searchtype=author&query=Tash%2C+M+S">Moein Shahiki Tash</a>, 
<a href="/search/cs?searchtype=author&query=Mezquita%2C+Y+L">Yoel Ledo Mezquita</a>, 
<a href="/search/cs?searchtype=author&query=Angel%2C+J">Jason Angel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures, 6 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper provides an extensive examination of a sizable dataset of English
tweets focusing on nine widely recognized cryptocurrencies, specifically
Cardano, Binance, Bitcoin, Dogecoin, Ethereum, Fantom, Matic, Shiba, and
Ripple. Our primary objective was to conduct a psycholinguistic and emotion
analysis of social media content associated with these cryptocurrencies. To
enable investigators to make more informed decisions. The study involved
comparing linguistic characteristics across the diverse digital coins, shedding
light on the distinctive linguistic patterns that emerge within each coin's
community. To achieve this, we utilized advanced text analysis techniques.
Additionally, our work unveiled an intriguing Understanding of the interplay
between these digital assets within the cryptocurrency community. By examining
which coin pairs are mentioned together most frequently in the dataset, we
established correlations between different cryptocurrencies. To ensure the
reliability of our findings, we initially gathered a total of 832,559 tweets
from Twitter. These tweets underwent a rigorous preprocessing stage, resulting
in a refined dataset of 115,899 tweets that were used for our analysis.
Overall, our research offers valuable Perception into the linguistic nuances of
various digital coins' online communities and provides a deeper understanding
of their interactions in the cryptocurrency space.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07472" title="Abstract">arXiv:2401.07472</a> [<a href="/pdf/2401.07472" title="Download PDF">pdf</a>, <a href="/format/2401.07472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Decentralized Design of Initialization-free Distributed Network  Size Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Donggil Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+T">Taekyoo Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+S">Seungjoon Lee</a>, 
<a href="/search/eess?searchtype=author&query=Shim%2C+H">Hyungbo Shim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, we propose a distributed scheme for estimating the network
size, which refers to the total number of agents in a network. By leveraging a
synchronization technique for multi-agent systems, we devise an agent dynamics
that ensures convergence to an equilibrium point located near the network size
regardless of its initial condition. Our approach is based on an assumption
that each agent has a unique identifier, and an estimation algorithm for
obtaining the largest identifier value. By adopting this approach, we
successfully implement the agent dynamics in a fully decentralized manner,
ensuring accurate network size estimation even when some agents join or leave
the network.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07475" title="Abstract">arXiv:2401.07475</a> [<a href="/pdf/2401.07475" title="Download PDF">pdf</a>, <a href="/format/2401.07475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GWPT: A Green Word-Embedding-based POS Tagger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chengwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+R">Runqi Pang</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+C+-+J">C.-C. Jay Kuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As a fundamental tool for natural language processing (NLP), the
part-of-speech (POS) tagger assigns the POS label to each word in a sentence. A
novel lightweight POS tagger based on word embeddings is proposed and named
GWPT (green word-embedding-based POS tagger) in this work. Following the green
learning (GL) methodology, GWPT contains three modules in cascade: 1)
representation learning, 2) feature learning, and 3) decision learning modules.
The main novelty of GWPT lies in representation learning. It uses
non-contextual or contextual word embeddings, partitions embedding dimension
indices into low-, medium-, and high-frequency sets, and represents them with
different N-grams. It is shown by experimental results that GWPT offers
state-of-the-art accuracies with fewer model parameters and significantly lower
computational complexity in both training and inference as compared with
deep-learning-based methods.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07477" title="Abstract">arXiv:2401.07477</a> [<a href="/pdf/2401.07477" title="Download PDF">pdf</a>, <a href="/format/2401.07477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CascadeV-Det: Cascade Point Voting for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Anchor-free object detectors are highly efficient in performing point-based
prediction without the need for extra post-processing of anchors. However,
different from the 2D grids, the 3D points used in these detectors are often
far from the ground truth center, making it challenging to accurately regress
the bounding boxes. To address this issue, we propose a Cascade Voting
(CascadeV) strategy that provides high-quality 3D object detection with
point-based prediction. Specifically, CascadeV performs cascade detection using
a novel Cascade Voting decoder that combines two new components: Instance Aware
Voting (IA-Voting) and a Cascade Point Assignment (CPA) module. The IA-Voting
module updates the object features of updated proposal points within the
bounding box using conditional inverse distance weighting. This approach
prevents features from being aggregated outside the instance and helps improve
the accuracy of object detection. Additionally, since model training can suffer
from a lack of proposal points with high centerness, we have developed the CPA
module to narrow down the positive assignment threshold with cascade stages.
This approach relaxes the dependence on proposal centerness in the early stages
while ensuring an ample quantity of positives with high centerness in the later
stages. Experiments show that FCAF3D with our CascadeV achieves
state-of-the-art 3D object detection results with 70.4\% mAP@0.25 and 51.6\%
mAP@0.5 on SUN RGB-D and competitive results on ScanNet. Code will be released
at https://github.com/Sharpiless/CascadeV-Det
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07479" title="Abstract">arXiv:2401.07479</a> [<a href="/pdf/2401.07479" title="Download PDF">pdf</a>, <a href="/format/2401.07479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Interference-Aware Codebook Learning in Millimeter Wave  MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Alkhateeb%2C+A">Ahmed Alkhateeb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Dataset and code files are available on the DeepMIMO website <a href="https://www.deepmimo.net/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Beam codebooks are integral components of the future millimeter wave (mmWave)
multiple input multiple output (MIMO) system to relax the reliance on the
instantaneous channel state information (CSI). The design of these codebooks,
therefore, becomes one of the fundamental problems for these systems, and the
well-designed codebooks play key roles in enabling efficient and reliable
communications. Prior work has primarily focused on the codebook learning
problem within a single cell/network and under stationary interference. In this
work, we generalize the interference-aware codebook learning problem to
networks with multiple cells/basestations. One of the key differences compared
to the single-cell codebook learning problem is that the underlying environment
becomes non-stationary, as the behavior of one base station will influence the
learning of the others. Moreover, to encompass some of the challenging
scenarios, information exchange between the different learning nodes is not
allowed, which leads to a fully decentralized system with significantly
increased learning difficulties. To tackle the non-stationarity, the averaging
of the measurements is used to estimate the interference nulling performance of
a particular beam, based on which a decision rule is provided. Furthermore, we
theoretically justify the adoption of such estimator and prove that it is a
sufficient statistic for the underlying quantity of interest in an asymptotic
sense. Finally, a novel reward function based on averaging is proposed to fully
decouple the learning of the multiple agents running at different nodes.
Simulation results show that the developed solution is capable of learning
well-shaped codebook patterns for different networks that significantly
suppress the interference without information exchange, highlighting ...
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07482" title="Abstract">arXiv:2401.07482</a> [<a href="/pdf/2401.07482" title="Download PDF">pdf</a>, <a href="/ps/2401.07482" title="Download PostScript">ps</a>, <a href="/format/2401.07482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contrast Based Feature Selection Algorithm for High-dimensional Data  set in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunxu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Feature selection is an important process in machine learning and knowledge
discovery. By selecting the most informative features and eliminating
irrelevant ones, the performance of learning algorithms can be improved and the
extraction of meaningful patterns and insights from data can be facilitated.
However, most existing feature selection methods, when applied to large
datasets, encountered the bottleneck of high computation costs. To address this
problem, we propose a novel filter feature selection method, ContrastFS, which
selects discriminative features based on the discrepancies features shown
between different classes. We introduce a dimensionless quantity as a surrogate
representation to summarize the distributional individuality of certain
classes, based on this quantity we evaluate features and study the correlation
among them. We validate effectiveness and efficiency of our approach on several
widely studied benchmark datasets, results show that the new method performs
favorably with negligible computation in comparison with other state-of-the-art
feature selection methods.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07487" title="Abstract">arXiv:2401.07487</a> [<a href="/pdf/2401.07487" title="Download PDF">pdf</a>, <a href="/format/2401.07487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robo-ABC: Affordance Generalization Beyond Categories via Semantic  Correspondence for Robot Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yuanchen Ju</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaizhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Mingrun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Enabling robotic manipulation that generalizes to out-of-distribution scenes
is a crucial step toward open-world embodied intelligence. For human beings,
this ability is rooted in the understanding of semantic correspondence among
objects, which naturally transfers the interaction experience of familiar
objects to novel ones. Although robots lack such a reservoir of interaction
experience, the vast availability of human videos on the Internet may serve as
a valuable resource, from which we extract an affordance memory including the
contact points. Inspired by the natural way humans think, we propose Robo-ABC:
when confronted with unfamiliar objects that require generalization, the robot
can acquire affordance by retrieving objects that share visual or semantic
similarities from the affordance memory. The next step is to map the contact
points of the retrieved objects to the new object. While establishing this
correspondence may present formidable challenges at first glance, recent
research finds it naturally arises from pre-trained diffusion models, enabling
affordance mapping even across disparate object categories. Through the
Robo-ABC framework, robots may generalize to manipulate out-of-category objects
in a zero-shot manner without any manual annotation, additional training, part
segmentation, pre-coded knowledge, or viewpoint restrictions. Quantitatively,
Robo-ABC significantly enhances the accuracy of visual affordance retrieval by
a large margin of 31.6% compared to state-of-the-art (SOTA) end-to-end
affordance models. We also conduct real-world experiments of cross-category
object-grasping tasks. Robo-ABC achieved a success rate of 85.7%, proving its
capacity for real-world tasks.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07488" title="Abstract">arXiv:2401.07488</a> [<a href="/pdf/2401.07488" title="Download PDF">pdf</a>, <a href="/ps/2401.07488" title="Download PostScript">ps</a>, <a href="/format/2401.07488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Selection via Maximizing Distances between Class Conditional  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunxu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">For many data-intensive tasks, feature selection is an important
preprocessing step. However, most existing methods do not directly and
intuitively explore the intrinsic discriminative information of features. We
propose a novel feature selection framework based on the distance between class
conditional distributions, measured by integral probability metrics (IPMs). Our
framework directly explores the discriminative information of features in the
sense of distributions for supervised classification. We analyze the
theoretical and practical aspects of IPMs for feature selection, construct
criteria based on IPMs. We propose several variant feature selection methods of
our framework based on the 1-Wasserstein distance and implement them on real
datasets from different domains. Experimental results show that our framework
can outperform state-of-the-art methods in terms of classification accuracy and
robustness to perturbations.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07490" title="Abstract">arXiv:2401.07490</a> [<a href="/pdf/2401.07490" title="Download PDF">pdf</a>, <a href="/ps/2401.07490" title="Download PostScript">ps</a>, <a href="/format/2401.07490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Existence of MMS Allocations with Mixed Manna
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+K">Kevin Hsu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Maximin share (MMS) allocations are a popular relaxation of envy-free
allocations that have received wide attention in the context of the fair
division of indivisible items. Although MMS allocations can fail to exist [1],
previous work has found conditions under which they exist. Specifically, MMS
allocations exist whenever $m \leq n+5$ in the context of goods allocation, and
this bound is tight in the sense that MMS allocations can fail to exist when $m
= n+6$ [2]. Unfortunately, the technique used to establish this result does not
generalize readily to the chores and mixed manna settings. This paper
generalizes this result to the chores setting and provides a partial solution
for the mixed manna setting. Our results depend on the presence of certain
types of agents. Specifically, an agent $i$ is a goods agent (resp. chores
agent) if every item is a good (resp. chore) to $i$, and a non-negative mixed
agent if $i$ is neither a goods nor a chores agent and the MMS guarantee of $i$
is non-negative. In this paper, we prove that an MMS allocation exists if $m
\leq n+5$ and there exists a goods agent, a non-negative mixed agent, or only
chores agents.
<br />[1] David Kurokawa, Ariel D Procaccia, and Junxing Wang. When can the maximin
share guarantee be guaranteed? In Thirtieth AAAI Conference on Artificial
Intelligence, 2016.
<br />[2] Uriel Feige, Ariel Sapir, and Laliv Tauber. A tight negative example for
mms fair allocations. In International Conference on Web and Internet
Economics, pages 355-372. Springer, 2021.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07493" title="Abstract">arXiv:2401.07493</a> [<a href="/pdf/2401.07493" title="Download PDF">pdf</a>, <a href="/ps/2401.07493" title="Download PostScript">ps</a>, <a href="/format/2401.07493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Patch Dynamics Scheme in Equation-free Multiscale Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karmakar%2C+T+K">T. K. Karmakar</a>, 
<a href="/search/math?searchtype=author&query=Dalal%2C+D+C">D. C. Dalal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">There is a class of problems that exhibit smooth behavior on macroscopic
scales, where only a microscopic evolution law is known. Patch dynamics scheme
of `equation-free multiscale modelling' is one of the techniques, which aims to
extract the macroscopic information using such known time-dependent microscopic
model simulation in patches (which is a fraction of the space-time domain) that
reduces the computational complexity. Here, extrapolation time step has an
important role to reduce the error at macroscopic level. In this study, a
generalized patch dynamics (GPD) scheme is proposed by distributing the
gap-tooth timesteppers (GTTs) within each long (macroscopic) time step. This
distribution is done in two ways, namely, GPD schemes of type-I and type-II.
The proposed GPD scheme is based on three different time scales namely, micro,
meso and macro to predict the system level behaviours. The GPD scheme of both
types are capable of providing better accuracy with less computation time
compared to the usual patch dynamics (UPD) scheme. The physical behaviours of
the problems can be more appropriately addressed by the GPD scheme as one may
use a non-uniform (variable) distribution of gap-tooth timesteppers (GTTs), as
well as the extrapolation times based on the physics of the problem. Where the
UPD scheme fails to converge for a long extrapolation time, both types of GPD
schemes can be successfully applied. The whole method has been analyzed
successfully for the one-dimensional reaction-diffusion problem.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07494" title="Abstract">arXiv:2401.07494</a> [<a href="/pdf/2401.07494" title="Download PDF">pdf</a>, <a href="/format/2401.07494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering  Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pravin%2C+P+S">P S Pravin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhe Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
<p class="mathjax">Computational efficiency and adversarial robustness are critical factors in
real-world engineering applications. Yet, conventional neural networks often
fall short in addressing both simultaneously, or even separately. Drawing
insights from natural physical systems and existing literature, it is known
that an input convex architecture enhances computational efficiency, while a
Lipschitz-constrained architecture bolsters adversarial robustness. By
leveraging the strengths of convexity and Lipschitz continuity, we develop a
novel network architecture, termed Input Convex Lipschitz Recurrent Neural
Network. This model outperforms existing recurrent units across a spectrum of
engineering tasks in terms of computational efficiency and adversarial
robustness. These tasks encompass a benchmark MNIST image classification,
real-world solar irradiance prediction for Solar PV system planning at LHT
Holdings in Singapore, and real-time Model Predictive Control optimization for
a chemical reactor.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07496" title="Abstract">arXiv:2401.07496</a> [<a href="/pdf/2401.07496" title="Download PDF">pdf</a>, <a href="/format/2401.07496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Rank Gradient Compression with Error Feedback for MIMO Wireless  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mingzhao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongzhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Simeone%2C+O">Osvaldo Simeone</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+D">Dingzhu Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 27 references, submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper presents a novel approach to enhance the communication efficiency
of federated learning (FL) in multiple input and multiple output (MIMO)
wireless systems. The proposed method centers on a low-rank matrix
factorization strategy for local gradient compression based on alternating
least squares, along with over-the-air computation and error feedback. The
proposed protocol, termed over-the-air low-rank compression (Ota-LC), is
demonstrated to have lower computation cost and lower communication overhead as
compared to existing benchmarks while guaranteeing the same inference
performance. As an example, when targeting a test accuracy of 80% on the
Cifar-10 dataset, Ota-LC achieves a reduction in total communication costs of
at least 30% when contrasted with benchmark schemes, while also reducing the
computational complexity order by a factor equal to the sum of the dimension of
the gradients.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07500" title="Abstract">arXiv:2401.07500</a> [<a href="/pdf/2401.07500" title="Download PDF">pdf</a>, <a href="/format/2401.07500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Deep Learning and Satellite Imagery for Post-Buyout Land  Cover Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Otal%2C+H+T">Hakan T. Otal</a>, 
<a href="/search/cs?searchtype=author&query=Zavar%2C+E">Elyse Zavar</a>, 
<a href="/search/cs?searchtype=author&query=Binder%2C+S+B">Sherri B. Binder</a>, 
<a href="/search/cs?searchtype=author&query=Greer%2C+A">Alex Greer</a>, 
<a href="/search/cs?searchtype=author&query=Canbaz%2C+M+A">M. Abdullah Canbaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Environmental disasters such as floods, hurricanes, and wildfires have
increasingly threatened communities worldwide, prompting various mitigation
strategies. Among these, property buyouts have emerged as a prominent approach
to reducing vulnerability to future disasters. This strategy involves
governments purchasing at-risk properties from willing sellers and converting
the land into open space, ostensibly reducing future disaster risk and impact.
However, the aftermath of these buyouts, particularly concerning land-use
patterns and community impacts, remains under-explored. This research aims to
fill this gap by employing innovative techniques like satellite imagery
analysis and deep learning to study these patterns. To achieve this goal, we
employed FEMA's Hazard Mitigation Grant Program (HMGP) buyout dataset,
encompassing over 41,004 addresses of these buyout properties from 1989 to
2017. Leveraging Google's Maps Static API, we gathered 40,053 satellite images
corresponding to these buyout lands. Subsequently, we implemented five
cutting-edge machine learning models to evaluate their performance in
classifying land cover types. Notably, this task involved multi-class
classification, and our model achieved an outstanding ROC-AUC score of 98.86%
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07502" title="Abstract">arXiv:2401.07502</a> [<a href="/pdf/2401.07502" title="Download PDF">pdf</a>, <a href="/format/2401.07502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Oil Spill Detection Based on Object Detector and Adapted  Segment Anything Model from SAR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+M+S">Man Sing Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guoqiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kwok%2C+C+Y+T">Coco Yin Tung Kwok</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+K">Kang Zou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic segmentation-based methods have attracted extensive attention in oil
spill detection from SAR images. However, the existing approaches require a
large number of finely annotated segmentation samples in the training stage. To
alleviate this issue, we propose a composite oil spill detection framework,
SAM-OIL, comprising an object detector (e.g., YOLOv8), an adapted Segment
Anything Model (SAM), and an Ordered Mask Fusion (OMF) module. SAM-OIL is the
first application of the powerful SAM in oil spill detection. Specifically, the
SAM-OIL strategy uses YOLOv8 to obtain the categories and bounding boxes of oil
spill-related objects, then inputs bounding boxes into the adapted SAM to
retrieve category-agnostic masks, and finally adopts the Ordered Mask Fusion
(OMF) module to fuse the masks and categories. The adapted SAM, combining a
frozen SAM with a learnable Adapter module, can enhance SAM's ability to
segment ambiguous objects. The OMF module, a parameter-free method, can
effectively resolve pixel category conflicts within SAM. Experimental results
demonstrate that SAM-OIL surpasses existing semantic segmentation-based oil
spill detection methods, achieving mIoU of 69.52%. The results also indicated
that both OMF and Adapter modules can effectively improve the accuracy in
SAM-OIL.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07503" title="Abstract">arXiv:2401.07503</a> [<a href="/pdf/2401.07503" title="Download PDF">pdf</a>, <a href="/format/2401.07503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolMERLIN: Self-Supervised Polarimetric Complex SAR Image Despeckling  with Masked Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kato%2C+S">Shunya Kato</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+M">Masaki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Ishiguro%2C+K">Katsuhiko Ishiguro</a>, 
<a href="/search/cs?searchtype=author&query=Cummings%2C+S">Sol Cummings</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear on IEEE Geoscience and Remote Sensing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despeckling is a crucial noise reduction task in improving the quality of
synthetic aperture radar (SAR) images. Directly obtaining noise-free SAR images
is a challenging task that has hindered the development of accurate despeckling
algorithms. The advent of deep learning has facilitated the study of denoising
models that learn from only noisy SAR images. However, existing methods deal
solely with single-polarization images and cannot handle the multi-polarization
images captured by modern satellites. In this work, we present an extension of
the existing model for generating single-polarization SAR images to handle
multi-polarization SAR images. Specifically, we propose a novel self-supervised
despeckling approach called channel masking, which exploits the relationship
between polarizations. Additionally, we utilize a spatial masking method that
addresses pixel-to-pixel correlations to further enhance the performance of our
approach. By effectively incorporating multiple polarization information, our
method surpasses current state-of-the-art methods in quantitative evaluation in
both synthetic and real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07510" title="Abstract">arXiv:2401.07510</a> [<a href="/pdf/2401.07510" title="Download PDF">pdf</a>, <a href="/ps/2401.07510" title="Download PostScript">ps</a>, <a href="/format/2401.07510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing ChatGPT for Biology and Medicine: A Complete Review of  Biomedical Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 3 figures, Biophysics Reports
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">ChatGPT explores a strategic blueprint of question answering (QA) in
delivering medical diagnosis, treatment recommendations, and other healthcare
support. This is achieved through the increasing incorporation of medical
domain data via natural language processing (NLP) and multimodal paradigms. By
transitioning the distribution of text, images, videos, and other modalities
from the general domain to the medical domain, these techniques have expedited
the progress of medical domain question answering (MDQA). They bridge the gap
between human natural language and sophisticated medical domain knowledge or
expert manual annotations, handling large-scale, diverse, unbalanced, or even
unlabeled data analysis scenarios in medical contexts. Central to our focus is
the utilizing of language models and multimodal paradigms for medical question
answering, aiming to guide the research community in selecting appropriate
mechanisms for their specific medical research requirements. Specialized tasks
such as unimodal-related question answering, reading comprehension, reasoning,
diagnosis, relation extraction, probability modeling, and others, as well as
multimodal-related tasks like vision question answering, image caption,
cross-modal retrieval, report summarization, and generation, are discussed in
detail. Each section delves into the intricate specifics of the respective
method under consideration. This paper highlights the structures and
advancements of medical domain explorations against general domain methods,
emphasizing their applications across different tasks and datasets. It also
outlines current challenges and opportunities for future medical domain
research, paving the way for continued innovation and application in this
rapidly evolving field.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07511" title="Abstract">arXiv:2401.07511</a> [<a href="/pdf/2401.07511" title="Download PDF">pdf</a>, <a href="/format/2401.07511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space Networking Kit: A Novel Simulation Platform for Emerging LEO  Mega-constellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangtong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaodong Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Menglong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper presents SNK, a novel simulation platform designed to evaluate the
network performance of constellation systems for global Internet services. SNK
offers realtime communication visualization and supports the simulation of
routing between edge node of network. The platform enables the evaluation of
routing and network performance metrics such as latency, stretch, network
capacity, and throughput under different network structures and density. The
effectiveness of SNK is demonstrated through various simulation cases,
including the routing between fixed edge stations or mobile edge stations and
analysis of space network structures.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07515" title="Abstract">arXiv:2401.07515</a> [<a href="/pdf/2401.07515" title="Download PDF">pdf</a>, <a href="/format/2401.07515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Purely Data-Driven Massive MIMO Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hao Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Le Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To enhance the performance of massive multi-input multi-output (MIMO)
detection using deep learning, prior research primarily adopts a model-driven
methodology, integrating deep neural networks (DNNs) with traditional iterative
detectors. Despite these efforts, achieving a purely data-driven detector has
remained elusive, primarily due to the inherent complexities arising from the
problem's high dimensionality. This paper introduces ChannelNet, a simple yet
effective purely data-driven massive MIMO detector. ChannelNet embeds the
channel matrix into the network as linear layers rather than viewing it as
input, enabling scalability to massive MIMO scenarios. ChannelNet is
computationally efficient and has a computational complexity of
$\mathcal{O}(N_t N_r)$, where $N_t$ and $N_r$ represent the numbers of transmit
and receive antennas, respectively. Despite the low computation complexity,
ChannelNet demonstrates robust empirical performance, matching or surpassing
state-of-the-art detectors in various scenarios. In addition, theoretical
insights establish ChannelNet as a universal approximator in probability for
any continuous permutation-equivariant functions. ChannelNet demonstrates that
designing deep learning based massive MIMO detectors can be purely data-driven
and free from the constraints posed by the conventional iterative frameworks as
well as the channel and noise distribution models.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07516" title="Abstract">arXiv:2401.07516</a> [<a href="/pdf/2401.07516" title="Download PDF">pdf</a>, <a href="/format/2401.07516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Link Prediction Using Graph Embedding Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fard%2C+S+H">Sanaz Hasanzadeh Fard</a>, 
<a href="/search/cs?searchtype=author&query=Ghassemi%2C+M">Mohammad Ghassemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graphs are a powerful representation tool in machine learning applications,
with link prediction being a key task in graph learning. Temporal link
prediction in dynamic networks is of particular interest due to its potential
for solving complex scientific and real-world problems. Traditional approaches
to temporal link prediction have focused on finding the aggregation of dynamics
of the network as a unified output. In this study, we propose a novel
perspective on temporal link prediction by defining nodes as Newtonian objects
and incorporating the concept of velocity to predict network dynamics. By
computing more specific dynamics of each node, rather than overall dynamics, we
improve both accuracy and explainability in predicting future connections. We
demonstrate the effectiveness of our approach using two datasets, including 17
years of co-authorship data from PubMed. Experimental results show that our
temporal graph embedding dynamics approach improves downstream classification
models' ability to predict future collaboration efficacy in co-authorship
networks by 17.34% (AUROC improvement relative to the baseline model).
Furthermore, our approach offers an interpretable layer over traditional
approaches to address the temporal link prediction problem.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07517" title="Abstract">arXiv:2401.07517</a> [<a href="/pdf/2401.07517" title="Download PDF">pdf</a>, <a href="/format/2401.07517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Protocol Location Forwarding (MPLF) for Space Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiangtong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Menglong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The structure and routing architecture design is critical for achieving low
latency and high capacity in future LEO space networks (SNs). Existing studies
mainly focus on topologies of space networks, but there is a lack of analysis
on constellation structures, which can greatly affect network performance. In
addition, some routing architectures are designed for networks with a small
number of network nodes such as Iridium while they introduce significant
network overhead for high-density networks (i.e., mega-constellation networks
containing thousands of satellites). In this paper, we conduct the
quantitatively study on the design of network structure and routing
architecture in space. The high density, high dynamics, and large scale nature
of emerging Space Networks (SNs) pose significant challenges, such as unstable
routing paths, low network reachability, high latency, and large jitter. To
alleviate the above challenges, we design the structure of space network to
maximum the connectivity through wisely adjusting the inter-plane inter
satellite link. We further propose Multi-Protocol Location Forwarding (MPLF), a
distributed routing architecture, targeting at minimizing the propagation
latency with a distributed, convergence-free routing paradigm, while keeping
routing stable and maximum the path diversity. Comprehensive experiments are
conducted on a customized platform \textit{Space Networking Kits} (SNK) which
demonstrate that our solution can outperform existing related schemes by about
14\% reduction of propagation latency and 66\% reduction of hops-count on
average, while sustaining a high path diversity with only $O(1)$ time
complexity.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07518" title="Abstract">arXiv:2401.07518</a> [<a href="/pdf/2401.07518" title="Download PDF">pdf</a>, <a href="/format/2401.07518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Natural Language Processing for Education: Taxonomy,  Systematic Review, and Future Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hanyue Du</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xuesong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Weining Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aoying Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Natural Language Processing (NLP) aims to analyze the text via techniques in
the computer science field. It serves the applications in healthcare, commerce,
and education domains. Particularly, NLP has been applied to the education
domain to help teaching and learning. In this survey, we review recent advances
in NLP with a focus on solving problems related to the education domain. In
detail, we begin with introducing the relevant background. Then, we present the
taxonomy of NLP in the education domain. Next, we illustrate the task
definition, challenges, and corresponding techniques based on the above
taxonomy. After that, we showcase some off-the-shelf demonstrations in this
domain and conclude with future directions.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07519" title="Abstract">arXiv:2401.07519</a> [<a href="/pdf/2401.07519" title="Download PDF">pdf</a>, <a href="/format/2401.07519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InstantID: Zero-shot Identity-Preserving Generation in Seconds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qixun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zekui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Anthony Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report, project page available at <a href="https://instantid.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">There has been significant progress in personalized image synthesis with
methods such as Textual Inversion, DreamBooth, and LoRA. Yet, their real-world
applicability is hindered by high storage demands, lengthy fine-tuning
processes, and the need for multiple reference images. Conversely, existing ID
embedding-based methods, while requiring only a single forward inference, face
challenges: they either necessitate extensive fine-tuning across numerous model
parameters, lack compatibility with community pre-trained models, or fail to
maintain high face fidelity. Addressing these limitations, we introduce
InstantID, a powerful diffusion model-based solution. Our plug-and-play module
adeptly handles image personalization in various styles using just a single
facial image, while ensuring high fidelity. To achieve this, we design a novel
IdentityNet by imposing strong semantic and weak spatial conditions,
integrating facial and landmark images with textual prompts to steer the image
generation. InstantID demonstrates exceptional performance and efficiency,
proving highly beneficial in real-world applications where identity
preservation is paramount. Moreover, our work seamlessly integrates with
popular pre-trained text-to-image diffusion models like SD1.5 and SDXL, serving
as an adaptable plugin. Our codes and pre-trained checkpoints will be available
at https://github.com/InstantID/InstantID.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07521" title="Abstract">arXiv:2401.07521</a> [<a href="/pdf/2401.07521" title="Download PDF">pdf</a>, <a href="/format/2401.07521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CREAD: A Classification-Restoration Framework with Error Adaptive  Discretization for Watch Time Prediction in Video Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhaoying Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoshuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yincheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+K">Kaiqiao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Ben Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The watch time is a significant indicator of user satisfaction in video
recommender systems. However, the prediction of watch time as a target variable
is often hindered by its highly imbalanced distribution with a scarcity of
observations for larger target values and over-populated samples for small
values. State-of-the-art watch time prediction models discretize the continuous
watch time into a set of buckets in order to consider the distribution of watch
time. However, it is highly uninvestigated how these discrete buckets should be
created from the continuous watch time distribution, and existing
discretization approaches suffer from either a large learning error or a large
restoration error. To address this challenge, we propose a
Classification-Restoration framework with Error-Adaptive-Discretization (CREAD)
to accurately predict the watch time. The proposed framework contains a
discretization module, a classification module, and a restoration module. It
predicts the watch time through multiple classification problems. The
discretization process is a key contribution of the CREAD framework. We
theoretically analyze the impacts of the discretization on the learning error
and the restoration error, and then propose the error-adaptive discretization
(EAD) technique to better balance the two errors, which achieves better
performance over traditional discretization approaches. We conduct detailed
offline evaluations on a public dataset and an industrial dataset, both showing
performance gains through the proposed approach. Moreover, We have fully
launched our framework to Kwai App, an online video platform, which resulted in
a significant increase in users' video watch time by 0.29% through A/B testing.
These results highlight the effectiveness of the CREAD framework in watch time
prediction in video recommender systems.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07525" title="Abstract">arXiv:2401.07525</a> [<a href="/pdf/2401.07525" title="Download PDF">pdf</a>, <a href="/format/2401.07525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAROT: A Hierarchical Framework with Multitask Co-Pretraining on  Semi-Structured Data towards Effective Person-Job Fit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yihan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Lun Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shi Han</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yushu Du</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yanbin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024 camera ready. 5 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Person-job fit is an essential part of online recruitment platforms in
serving various downstream applications like Job Search and Candidate
Recommendation. Recently, pretrained large language models have further
enhanced the effectiveness by leveraging richer textual information in user
profiles and job descriptions apart from user behavior features and job
metadata. However, the general domain-oriented design struggles to capture the
unique structural information within user profiles and job descriptions,
leading to a loss of latent semantic correlations. We propose TAROT, a
hierarchical multitask co-pretraining framework, to better utilize structural
and semantic information for informative text embeddings. TAROT targets
semi-structured text in profiles and jobs, and it is co-pretained with
multi-grained pretraining tasks to constrain the acquired semantic information
at each level. Experiments on a real-world LinkedIn dataset show significant
performance improvements, proving its effectiveness in person-job fit tasks.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07526" title="Abstract">arXiv:2401.07526</a> [<a href="/pdf/2401.07526" title="Download PDF">pdf</a>, <a href="/format/2401.07526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Editing Arbitrary Propositions in LLMs without Subject Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feigenbaum%2C+I">Itai Feigenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Arpit%2C+D">Devansh Arpit</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weiran Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Savarese%2C+S">Silvio Savarese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Model (LLM) editing modifies factual information in LLMs.
Locate-and-Edit (L\&amp;E) methods accomplish this by finding where relevant
information is stored within the neural network, and editing the weights at
that location. The goal of editing is to modify the response of an LLM to a
proposition independently of its phrasing, while not modifying its response to
other related propositions. Existing methods are limited to binary
propositions, which represent straightforward binary relations between a
subject and an object. Furthermore, existing methods rely on semantic subject
labels, which may not be available or even be well-defined in practice. In this
paper, we show that both of these issues can be effectively skirted with a
simple and fast localization method called Gradient Tracing (GT). This
localization method allows editing arbitrary propositions instead of just
binary ones, and does so without the need for subject labels. As propositions
always have a truth value, our experiments prompt an LLM as a boolean
classifier, and edit its T/F response to propositions. Our method applies GT
for location tracing, and then edit the model at that location using a mild
variant of Rank-One Model Editing (ROME). On datasets of binary propositions
derived from the CounterFact dataset, we show that our method -- without access
to subject labels -- performs close to state-of-the-art L\&amp;E methods which has
access subject labels. We then introduce a new dataset, Factual Accuracy
Classification Test (FACT), which includes non-binary propositions and for
which subject labels are not generally applicable, and therefore is beyond the
scope of existing L\&amp;E methods. Nevertheless, we show that with our method
editing is possible on FACT.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07527" title="Abstract">arXiv:2401.07527</a> [<a href="/pdf/2401.07527" title="Download PDF">pdf</a>, <a href="/format/2401.07527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One for All: Toward Unified Foundation Models for Earth Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhitong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fahong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Foundation models characterized by extensive parameters and trained on
large-scale datasets have demonstrated remarkable efficacy across various
downstream tasks for remote sensing data. Current remote sensing foundation
models typically specialize in a single modality or a specific spatial
resolution range, limiting their versatility for downstream datasets. While
there have been attempts to develop multi-modal remote sensing foundation
models, they typically employ separate vision encoders for each modality or
spatial resolution, necessitating a switch in backbones contingent upon the
input data. To address this issue, we introduce a simple yet effective method,
termed OFA-Net (One-For-All Network): employing a single, shared Transformer
backbone for multiple data modalities with different spatial resolutions. Using
the masked image modeling mechanism, we pre-train a single Transformer backbone
on a curated multi-modal dataset with this simple design. Then the backbone
model can be used in different downstream tasks, thus forging a path towards a
unified foundation backbone model in Earth vision. The proposed method is
evaluated on 12 distinct downstream tasks and demonstrates promising
performance.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07529" title="Abstract">arXiv:2401.07529</a> [<a href="/pdf/2401.07529" title="Download PDF">pdf</a>, <a href="/format/2401.07529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of  Multimodal Large Language Models in Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Y">Yusheng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Heyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongcheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multimodal Large Language Models (MLLMs) have shown their remarkable
abilities in visual perception and understanding recently. However, how to
comprehensively evaluate the capabilities of MLLMs remains a challenge. Most of
the existing benchmarks predominantly focus on assessing perception, cognition,
and reasoning, neglecting the abilities of self-awareness, referring to the
model's recognition of its own capability boundary. In our study, we focus on
self-awareness in image perception and introduce the knowledge quadrant for
MLLMs, which clearly defines the knowns and unknowns in perception. Based on
this, we propose a novel benchmark specifically designed to evaluate the
Self-Aware capabilities in Perception for MLLMs(MM-SAP). MM-SAP encompasses
three distinct sub-datasets, each focusing on different aspects of
self-awareness. We evaluated eight well-known MLLMs using MM-SAP, analyzing
their self-awareness and providing detailed insights. Code and data are
available at https://github.com/YHWmz/MM-SAP
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07532" title="Abstract">arXiv:2401.07532</a> [<a href="/pdf/2401.07532" title="Download PDF">pdf</a>, <a href="/format/2401.07532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view MidiVAE: Fusing Track- and Bar-view Representations for Long  Multi-track Symbolic Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+B">Boshi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+B">Binzhu Sha</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+Y">Yaolong Ju</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Shiyin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Variational Autoencoders (VAEs) constitute a crucial component of neural
symbolic music generation, among which some works have yielded outstanding
results and attracted considerable attention. Nevertheless, previous VAEs still
encounter issues with overly long feature sequences and generated results lack
contextual coherence, thus the challenge of modeling long multi-track symbolic
music still remains unaddressed. To this end, we propose Multi-view MidiVAE, as
one of the pioneers in VAE methods that effectively model and generate long
multi-track symbolic music. The Multi-view MidiVAE utilizes the two-dimensional
(2-D) representation, OctupleMIDI, to capture relationships among notes while
reducing the feature sequences length. Moreover, we focus on instrumental
characteristics and harmony as well as global and local information about the
musical composition by employing a hybrid variational encoding-decoding
strategy to integrate both Track- and Bar-view MidiVAE features. Objective and
subjective experimental results on the CocoChorales dataset demonstrate that,
compared to the baseline, Multi-view MidiVAE exhibits significant improvements
in terms of modeling long multi-track symbolic music.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07533" title="Abstract">arXiv:2401.07533</a> [<a href="/pdf/2401.07533" title="Download PDF">pdf</a>, <a href="/ps/2401.07533" title="Download PostScript">ps</a>, <a href="/format/2401.07533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Indirect Effects of Interactive Systems Within Systems  of Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bornes%2C+L">Laetitia Bornes</a> (LII), 
<a href="/search/cs?searchtype=author&query=Letondal%2C+C">Catherine Letondal</a> (LII), 
<a href="/search/cs?searchtype=author&query=Vingerhoeds%2C+R">Rob Vingerhoeds</a> (ISAE-SUPAERO)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> INSIGHT - International Council on Systems Engineering (INCOSE),
  2023, 26 (4), pp.18-21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Until recently, research into the sustainable design of interactive systems
has primarily focused on the direct material impact of a system, through
improving its energy efficiency and optimizing its lifecycle. Yet the way a
system is designed and marketed often has wider repercussions, such as rebound
effects, and systemic change in practices. These effects are harder to assess
(and to anticipate) than the direct physical impact of the construction and use
of the system itself. Current tools are unable to account for the complexity of
these effects: the underlying causal mechanisms, their multi-level nature,
their different temporalities, and the variety of their consequences
(environmental and societal). This is why we are seeking to develop a specific
methodology and tool, inspired by systemic design and system dynamics. These
are intended for decision-makers and designers of interactive systems within
systems of systems (for example, in the fields of agricultural robotics or
public transportation). In this paper, we present this modeling approach and
our prototype tool through the example of a second-hand clothing sales
platform.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07534" title="Abstract">arXiv:2401.07534</a> [<a href="/pdf/2401.07534" title="Download PDF">pdf</a>, <a href="/format/2401.07534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Potential of Large Language Models in Self-adaptive  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Nianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Weyns%2C+D">Danny Weyns</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Tei%2C+K">Kenji Tei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by SEAMS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Large Language Models (LLMs), with their abilities in knowledge acquisition
and reasoning, can potentially enhance the various aspects of Self-adaptive
Systems (SAS). Yet, the potential of LLMs in SAS remains largely unexplored and
ambiguous, due to the lack of literature from flagship conferences or journals
in the field, such as SEAMS and TAAS. The interdisciplinary nature of SAS
suggests that drawing and integrating ideas from related fields, such as
software engineering and autonomous agents, could unveil innovative research
directions for LLMs within SAS. To this end, this paper reports the results of
a literature review of studies in relevant fields, summarizes and classifies
the studies relevant to SAS, and outlines their potential to specific aspects
of SAS.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07539" title="Abstract">arXiv:2401.07539</a> [<a href="/pdf/2401.07539" title="Download PDF">pdf</a>, <a href="/format/2401.07539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Assessment of Containers Running on Top of Virtual Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aqasizade%2C+H">Hossein Aqasizade</a>, 
<a href="/search/cs?searchtype=author&query=Ataie%2C+E">Ehsan Ataie</a>, 
<a href="/search/cs?searchtype=author&query=Bastam%2C+M">Mostafa Bastam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR); Performance (cs.PF)

</div>
<p class="mathjax">Over the past two decades, the cloud computing paradigm has gradually
attracted more popularity due to its efficient resource usage and simple
service access model. Virtualization technology is the fundamental element of
cloud computing that brings several benefits to cloud users and providers, such
as workload isolation, energy efficiency, server consolidation, and cost
reduction. This paper examines the combination of operating system-level
virtualization (containers) and hardware-level virtualization (virtual
machines). To this end, the performance of containers running on top of virtual
machines is experimentally compared with standalone virtual machines and
containers based on different hardware resources, including the processor, main
memory, disk, and network in a real testbed by running the most commonly used
benchmarks. Paravirtualization and full virtualization as well as type 1 and
type 2 hypervisors are covered in this study. In addition, three prevalent
containerization platforms are examined.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07540" title="Abstract">arXiv:2401.07540</a> [<a href="/pdf/2401.07540" title="Download PDF">pdf</a>, <a href="/format/2401.07540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study Features via Exploring Distribution Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Chunxu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we present a novel framework for data redundancy measurement
based on probabilistic modeling of datasets, and a new criterion for redundancy
detection that is resilient to noise. We also develop new methods for data
redundancy reduction using both deterministic and stochastic optimization
techniques. Our framework is flexible and can handle different types of
features, and our experiments on benchmark datasets demonstrate the
effectiveness of our methods. We provide a new perspective on feature
selection, and propose effective and robust approaches for both supervised and
unsupervised learning problems.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07541" title="Abstract">arXiv:2401.07541</a> [<a href="/pdf/2401.07541" title="Download PDF">pdf</a>, <a href="/format/2401.07541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DynaHull: Density-centric Dynamic Point Filtering in Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habibiroudkenar%2C+P">Pejman Habibiroudkenar</a>, 
<a href="/search/cs?searchtype=author&query=Ojala%2C+R">Risto Ojala</a>, 
<a href="/search/cs?searchtype=author&query=Tammi%2C+K">Kari Tammi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In the field of indoor robotics, accurately navigating and mapping in dynamic
environments using point clouds can be a challenging task due to the presence
of dynamic points. These dynamic points are often represented by people in
indoor environments, but in industrial settings with moving machinery, there
can be various types of dynamic points. This study introduces DynaHull, a novel
technique designed to enhance indoor mapping accuracy by effectively removing
dynamic points from point clouds. DynaHull works by leveraging the observation
that, over multiple scans, stationary points have a higher density compared to
dynamic ones. Furthermore, DynaHull addresses mapping challenges related to
unevenly distributed points by clustering the map into smaller sections. In
each section, the density factor of each point is determined by dividing the
number of neighbors by the volume these neighboring points occupy using a
convex hull method. The algorithm removes the dynamic points using an adaptive
threshold based on the point count of each cluster, thus reducing the false
positives. The performance of DynaHull was compared to state-of-the-art
techniques, such as ERASOR, Removert, OctoMap, and a baseline statistical
outlier removal from Open3D, by comparing each method to the ground truth map
created during a low activity period in which only a few dynamic points were
present. The results indicated that DynaHull outperformed these techniques in
various metrics, noticeably in the Earth Mover's Distance. This research
contributes to indoor robotics by providing efficient methods for dynamic point
removal, essential for accurate mapping and localization in dynamic
environments.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07542" title="Abstract">arXiv:2401.07542</a> [<a href="/pdf/2401.07542" title="Download PDF">pdf</a>, <a href="/format/2401.07542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Image- and Geometric-based Deep Learning for Shape Regression:  A Comparison to Pixel-level Methods for Segmentation in Chest X-Ray
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keuth%2C+R">Ron Keuth</a>, 
<a href="/search/cs?searchtype=author&query=Heinrich%2C+M">Mattias Heinrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to German Conference on Medical Image Computing 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When solving a segmentation task, shaped-base methods can be beneficial
compared to pixelwise classification due to geometric understanding of the
target object as shape, preventing the generation of anatomical implausible
predictions in particular for corrupted data. In this work, we propose a novel
hybrid method that combines a lightweight CNN backbone with a geometric neural
network (Point Transformer) for shape regression. Using the same CNN encoder,
the Point Transformer reaches segmentation quality on per with current
state-of-the-art convolutional decoders ($4\pm1.9$ vs $3.9\pm2.9$ error in mm
and $85\pm13$ vs $88\pm10$ Dice), but crucially, is more stable w.r.t image
distortion, starting to outperform them at a corruption level of 30%.
Furthermore, we include the nnU-Net as an upper baseline, which has $3.7\times$
more trainable parameters than our proposed method.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07543" title="Abstract">arXiv:2401.07543</a> [<a href="/pdf/2401.07543" title="Download PDF">pdf</a>, <a href="/format/2401.07543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Must: Maximizing Latent Capacity of Spatial Transcriptomics Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zelin Zang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+C">Chenrui Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages and 6 figures, plus 27 pages and 14 figures in appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatial transcriptomics (ST) technologies have revolutionized the study of
gene expression patterns in tissues by providing multimodality data in
transcriptomic, spatial, and morphological, offering opportunities for
understanding tissue biology beyond transcriptomics. However, we identify the
modality bias phenomenon in ST data species, i.e., the inconsistent
contribution of different modalities to the labels leads to a tendency for the
analysis methods to retain the information of the dominant modality. How to
mitigate the adverse effects of modality bias to satisfy various downstream
tasks remains a fundamental challenge. This paper introduces Multiple-modality
Structure Transformation, named MuST, a novel methodology to tackle the
challenge. MuST integrates the multi-modality information contained in the ST
data effectively into a uniform latent space to provide a foundation for all
the downstream tasks. It learns intrinsic local structures by topology
discovery strategy and topology fusion loss function to solve the
inconsistencies among different modalities. Thus, these topology-based and deep
learning techniques provide a solid foundation for a variety of analytical
tasks while coordinating different modalities. The effectiveness of MuST is
assessed by performance metrics and biological significance. The results show
that it outperforms existing state-of-the-art methods with clear advantages in
the precision of identifying and preserving structures of tissues and
biomarkers. MuST offers a versatile toolkit for the intricate analysis of
complex biological systems.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07544" title="Abstract">arXiv:2401.07544</a> [<a href="/pdf/2401.07544" title="Download PDF">pdf</a>, <a href="/format/2401.07544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> See the Unseen: Better Context-Consistent Knowledge-Editing by Noises
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Youcheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuicheng Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Knowledge-editing updates knowledge of large language models (LLMs) and
contributes to the interpretability and application of LLMs. However, knowledge
applying is context-consistent: LLMs can recall the same knowledge in different
contexts. Existing works ignore this property and the editing lacks
generalization. In this paper, we empirically find that the effects of
different contexts upon LLMs in recalling the same knowledge follow a
Gaussian-like distribution. We then sample Gaussian noises to simulate the
effects of different contexts when updating LLMs. By such, we can make LLMs see
the unseen contexts where the edited knowledge will be applied, therefore
improving the editing generalization. Experimental results on three LLMs
demonstrate the effectiveness of our methods and also distinguish our methods
from the others of fine-tuning LLMs by noises.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07548" title="Abstract">arXiv:2401.07548</a> [<a href="/pdf/2401.07548" title="Download PDF">pdf</a>, <a href="/format/2401.07548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rabin Games and Colourful Universal Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+R">Rupak Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Saglam%2C+I">Irmak Saglam</a>, 
<a href="/search/cs?searchtype=author&query=Thejaswini%2C+K+S">K. S. Thejaswini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 4 figures. Accepted at TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)

</div>
<p class="mathjax">We provide an algorithm to solve Rabin and Streett games over graphs with $n$
vertices, $m$ edges, and $k$ colours that runs in
$\tilde{O}\left(mn(k!)^{1+o(1)} \right)$ time and $O(nk\log k \log n)$ space,
where $\tilde{O}$ hides poly-logarithmic factors. Our algorithm is an
improvement by a super quadratic dependence on $k!$ from the currently best
known run time of $O\left(mn^2(k!)^{2+o(1)}\right)$, obtained by converting a
Rabin game into a parity game, while simultaneously improving its exponential
space requirement.
<br />Our main technical ingredient is a characterisation of progress measures for
Rabin games using \emph{colourful trees} and a combinatorial construction of
succinctly-represented, universal colourful trees. Colourful universal trees
are generalisations of universal trees used by Jurdzi\'{n}ski and Lazi\'{c}
(2017) to solve parity games, as well as of Rabin progress measures of Klarlund
and Kozen (1991). Our algorithm for Rabin games is a progress measure lifting
algorithm where the lifting is performed on succinct, colourful, universal
trees.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07549" title="Abstract">arXiv:2401.07549</a> [<a href="/pdf/2401.07549" title="Download PDF">pdf</a>, <a href="/format/2401.07549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computability of extender sets in multidimensional subshifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Callard%2C+A">Antonin Callard</a>, 
<a href="/search/cs?searchtype=author&query=Salomon%2C+L+P">L&#xe9;o Paviet Salomon</a>, 
<a href="/search/cs?searchtype=author&query=Vanier%2C+P">Pascal Vanier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages + appendix, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Dynamical Systems (math.DS)

</div>
<p class="mathjax">Subshifts are colorings of $\mathbb{Z}^d$ defined by families of forbidden
patterns. Given a subshift and a finite pattern, its extender set is the set of
admissible completions of this pattern. It has been conjectured that the
behavior of extender sets, and in particular their growth called extender
entropy (<a href="/abs/1711.07515">arXiv:1711.07515</a>), could provide a way to separate the classes of
sofic and effective subshifts. We prove here that both classes have the same
possible extender entropies: exactly the $\Pi_3$ real numbers of $[0,+\infty)$.
We also consider computational properties of extender entropies for subshifts
with some language or dynamical properties: computable language, minimal and
some mixing properties.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07551" title="Abstract">arXiv:2401.07551</a> [<a href="/pdf/2401.07551" title="Download PDF">pdf</a>, <a href="/format/2401.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Semi-Supervised Learning for Self-learning Open-World Classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+W">Wenjuan Xi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xin Song</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weili Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Data Mining (ICDM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Existing semi-supervised learning (SSL) methods assume that labeled and
unlabeled data share the same class space. However, in real-world applications,
unlabeled data always contain classes not present in the labeled set, which may
cause classification performance degradation of known classes. Therefore,
open-world SSL approaches are researched to handle the presence of multiple
unknown classes in the unlabeled data, which aims to accurately classify known
classes while fine-grained distinguishing different unknown classes. To address
this challenge, in this paper, we propose an open-world SSL method for
Self-learning Open-world Classes (SSOC), which can explicitly self-learn
multiple unknown classes. Specifically, SSOC first defines class center tokens
for both known and unknown classes and autonomously learns token
representations according to all samples with the cross-attention mechanism. To
effectively discover novel classes, SSOC further designs a pairwise similarity
loss in addition to the entropy loss, which can wisely exploit the information
available in unlabeled data from instances' predictions and relationships.
Extensive experiments demonstrate that SSOC outperforms the state-of-the-art
baselines on multiple popular classification benchmarks. Specifically, on the
ImageNet-100 dataset with a novel ratio of 90%, SSOC achieves a remarkable 22%
improvement.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07553" title="Abstract">arXiv:2401.07553</a> [<a href="/pdf/2401.07553" title="Download PDF">pdf</a>, <a href="/format/2401.07553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning with Free-form Natural Language Constraints  and Pre-Trained Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xingzhou Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Safe reinforcement learning (RL) agents accomplish given tasks while adhering
to specific constraints. Employing constraints expressed via
easily-understandable human language offers considerable potential for
real-world applications due to its accessibility and non-reliance on domain
expertise. Previous safe RL methods with natural language constraints typically
adopt a recurrent neural network, which leads to limited capabilities when
dealing with various forms of human language input. Furthermore, these methods
often require a ground-truth cost function, necessitating domain expertise for
the conversion of language constraints into a well-defined cost function that
determines constraint violation. To address these issues, we proposes to use
pre-trained language models (LM) to facilitate RL agents' comprehension of
natural language constraints and allow them to infer costs for safe policy
learning. Through the use of pre-trained LMs and the elimination of the need
for a ground-truth cost, our method enhances safe policy learning under a
diverse set of human-derived free-form natural language constraints.
Experiments on grid-world navigation and robot control show that the proposed
method can achieve strong performance while adhering to given constraints. The
usage of pre-trained LMs allows our method to comprehend complicated
constraints and learn safe policies without the need for ground-truth cost at
any stage of training or evaluation. Extensive ablation studies are conducted
to demonstrate the efficacy of each part of our method.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07558" title="Abstract">arXiv:2401.07558</a> [<a href="/pdf/2401.07558" title="Download PDF">pdf</a>, <a href="/format/2401.07558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedRFQ: Prototype-Based Federated Learning with Reduced Redundancy,  Minimal Failure, and Enhanced Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Biwei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minghui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongxiao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiuzhen Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning is a powerful technique that enables collaborative
learning among different clients. Prototype-based federated learning is a
specific approach that improves the performance of local models under non-IID
(non-Independently and Identically Distributed) settings by integrating class
prototypes. However, prototype-based federated learning faces several
challenges, such as prototype redundancy and prototype failure, which limit its
accuracy. It is also susceptible to poisoning attacks and server malfunctions,
which can degrade the prototype quality. To address these issues, we propose
FedRFQ, a prototype-based federated learning approach that aims to reduce
redundancy, minimize failures, and improve \underline{q}uality. FedRFQ
leverages a SoftPool mechanism, which effectively mitigates prototype
redundancy and prototype failure on non-IID data. Furthermore, we introduce the
BFT-detect, a BFT (Byzantine Fault Tolerance) detectable aggregation algorithm,
to ensure the security of FedRFQ against poisoning attacks and server
malfunctions. Finally, we conduct experiments on three different datasets,
namely MNIST, FEMNIST, and CIFAR-10, and the results demonstrate that FedRFQ
outperforms existing baselines in terms of accuracy when handling non-IID data.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07559" title="Abstract">arXiv:2401.07559</a> [<a href="/pdf/2401.07559" title="Download PDF">pdf</a>, <a href="/ps/2401.07559" title="Download PostScript">ps</a>, <a href="/format/2401.07559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eco-driving Intelligent Systems and Algorithms: A Patent Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zhipeng Ma</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%B8rgensen%2C+B+N">Bo N&#xf8;rregaard J&#xf8;rgensen</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z+G">Zheng Grace Ma</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 8th International Conference on Power and Renewable Energy
  (ICPRE 2023), IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The transportation industry remains a significant contributor to greenhouse
gas emissions, highlighting the requirement for intelligent systems to enhance
vehicle energy efficiency. The intellectual property rights of developed
systems should be protected by patents. However, there is no patent overview of
eco-driving intelligent systems. Unlike a scientific article, a patent
documentation indicates both novelty and commercialization potential of an
inventor. To address this research gap, this paper provides a patent overview
of eco-driving intelligent systems and algorithms. 424 patents in the Google
Patent database are analyzed. The patent analysis results show that the top
three Cooperative Patent Classifications are: Y02T - climate change mitigation
technologies related to transportation (50.7%), B60W - Conjoint control of
vehicle subunits of different types or different functions (34.4%) and B60L -
Propulsion of electrically-propelled vehicles (20.2%). 219 patents were filed
after 2016 when deep learning became popular and can be categorized into five
groups: vehicle energy management, smart driving, ecological and sustainable
driving, fuel consumption reduction, and driving behavior optimization.
Furthermore, all 219 patents involve the physical components of the intelligent
system and/or novel machine learning/deep learning algorithms. Moreover, over
70% of them are granted by the China National Intellectual Property
Administration.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07565" title="Abstract">arXiv:2401.07565</a> [<a href="/pdf/2401.07565" title="Download PDF">pdf</a>, <a href="/format/2401.07565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Call graph discovery in binary programs from unknown instruction set  architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pettersen%2C+H">H&#xe5;vard Pettersen</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+D">Donn Morrison</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> PETTERSEN, H{\aa}vard; MORRISON, Donn. Call graph discovery in
  binary programs from unknown instruction set architectures. In: Norsk
  IKT-konferanse for forskning og utdanning. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This study addresses the challenge of reverse engineering binaries from
unknown instruction set architectures, a complex task with potential
implications for software maintenance and cyber-security. We focus on the tasks
of detecting candidate call and return opcodes for automatic extraction of call
graphs in order to simplify the reverse engineering process. Empirical testing
on a small dataset of binary files from different architectures demonstrates
that the approach can accurately detect specific opcodes under conditions of
noisy data. The method lays the groundwork for a valuable tool for reverse
engineering where the reverse engineer has minimal a priori knowledge of the
underlying instruction set architecture.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07567" title="Abstract">arXiv:2401.07567</a> [<a href="/pdf/2401.07567" title="Download PDF">pdf</a>, <a href="/format/2401.07567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-Conflict Sample Synthesis and Adversarial Removal Debias Strategy  for Temporal Sentence Grounding in Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+Z">Zhaobo Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yibo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+X">Xiaowen Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuhui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weigang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qingming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Temporal Sentence Grounding in Video (TSGV) is troubled by dataset bias
issue, which is caused by the uneven temporal distribution of the target
moments for samples with similar semantic components in input videos or query
texts. Existing methods resort to utilizing prior knowledge about bias to
artificially break this uneven distribution, which only removes a limited
amount of significant language biases. In this work, we propose the
bias-conflict sample synthesis and adversarial removal debias strategy
(BSSARD), which dynamically generates bias-conflict samples by explicitly
leveraging potentially spurious correlations between single-modality features
and the temporal position of the target moments. Through adversarial training,
its bias generators continuously introduce biases and generate bias-conflict
samples to deceive its grounding model. Meanwhile, the grounding model
continuously eliminates the introduced biases, which requires it to model
multi-modality alignment information. BSSARD will cover most kinds of coupling
relationships and disrupt language and visual biases simultaneously. Extensive
experiments on Charades-CD and ActivityNet-CD demonstrate the promising
debiasing capability of BSSARD. Source codes are available at
https://github.com/qzhb/BSSARD.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07571" title="Abstract">arXiv:2401.07571</a> [<a href="/pdf/2401.07571" title="Download PDF">pdf</a>, <a href="/format/2401.07571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bi-Pyramid Multimodal Fusion Method for the Diagnosis of Bipolar  Disorders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Sheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Shan An</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fengmei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+W">Wenshu Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Feng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiren Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous research on the diagnosis of Bipolar disorder has mainly focused on
resting-state functional magnetic resonance imaging. However, their accuracy
can not meet the requirements of clinical diagnosis. Efficient multimodal
fusion strategies have great potential for applications in multimodal data and
can further improve the performance of medical diagnosis models. In this work,
we utilize both sMRI and fMRI data and propose a novel multimodal diagnosis
model for bipolar disorder. The proposed Patch Pyramid Feature Extraction
Module extracts sMRI features, and the spatio-temporal pyramid structure
extracts the fMRI features. Finally, they are fused by a fusion module to
output diagnosis results with a classifier. Extensive experiments show that our
proposed method outperforms others in balanced accuracy from 0.657 to 0.732 on
the OpenfMRI dataset, and achieves the state of the art.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07572" title="Abstract">arXiv:2401.07572</a> [<a href="/pdf/2401.07572" title="Download PDF">pdf</a>, <a href="/format/2401.07572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In this study, we tackle the challenge of classifying the object category in
point clouds, which previous works like PointCLIP struggle to address due to
the inherent limitations of the CLIP architecture. Our approach leverages GPT-4
Vision (GPT-4V) to overcome these challenges by employing its advanced
generative abilities, enabling a more adaptive and robust classification
process. We adapt the application of GPT-4V to process complex 3D data,
enabling it to achieve zero-shot recognition capabilities without altering the
underlying model architecture. Our methodology also includes a systematic
strategy for point cloud image visualization, mitigating domain gap and
enhancing GPT-4V's efficiency. Experimental validation demonstrates our
approach's superiority in diverse scenarios, setting a new benchmark in
zero-shot point cloud classification.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07575" title="Abstract">arXiv:2401.07575</a> [<a href="/pdf/2401.07575" title="Download PDF">pdf</a>, <a href="/format/2401.07575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cascaded Cross-Modal Transformer for Audio-Textual Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ristea%2C+N">Nicolae-Catalin Ristea</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+A">Andrei Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Ionescu%2C+R+T">Radu Tudor Ionescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speech classification tasks often require powerful language understanding
models to grasp useful features, which becomes problematic when limited
training data is available. To attain superior classification performance, we
propose to harness the inherent value of multimodal representations by
transcribing speech using automatic speech recognition (ASR) models and
translating the transcripts into different languages via pretrained translation
models. We thus obtain an audio-textual (multimodal) representation for each
data sample. Subsequently, we combine language-specific Bidirectional Encoder
Representations from Transformers (BERT) with Wav2Vec2.0 audio features via a
novel cascaded cross-modal transformer (CCMT). Our model is based on two
cascaded transformer blocks. The first one combines text-specific features from
distinct languages, while the second one combines acoustic features with
multilingual features previously learned by the first transformer block. We
employed our system in the Requests Sub-Challenge of the ACM Multimedia 2023
Computational Paralinguistics Challenge. CCMT was declared the winning
solution, obtaining an unweighted average recall (UAR) of 65.41% and 85.87% for
complaint and request detection, respectively. Moreover, we applied our
framework on the Speech Commands v2 and HarperValleyBank dialog data sets,
surpassing previous studies reporting results on these benchmarks. Our code is
freely available for download at: https://github.com/ristea/ccmt.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07576" title="Abstract">arXiv:2401.07576</a> [<a href="/pdf/2401.07576" title="Download PDF">pdf</a>, <a href="/format/2401.07576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TDD Without Tears: Towards Test Case Generation from Requirements  through Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takerngsaksiri%2C+W">Wannita Takerngsaksiri</a>, 
<a href="/search/cs?searchtype=author&query=Charakorn%2C+R">Rujikorn Charakorn</a>, 
<a href="/search/cs?searchtype=author&query=Tantithamthavorn%2C+C">Chakkrit Tantithamthavorn</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Test-driven development (TDD) is a widely-employed software development
practice that mandates writing test cases based on requirements before writing
the actual code. While writing test cases is the centerpiece of TDD, it is
time-consuming, expensive, and often shunned by developers. To address these
issues associated with TDD, automated test case generation approaches have
recently been investigated. Such approaches take source code as input, but not
the requirements. Therefore, existing work does not fully support true TDD, as
actual code is required to generate test cases. In addition, current deep
learning-based test case generation approaches are trained with one learning
objective, i.e., to generate test cases that are exactly matched with the
ground-truth test cases. However, such approaches may limit the model's ability
to generate different yet correct test cases. In this paper, we introduce
PyTester, a Text-to-Testcase generation approach that can automatically
generate syntactically correct, executable, complete, and effective test cases
while being aligned with a given natural language requirement. We evaluate
PyTester on the public APPS benchmark dataset, and the results show that our
Deep RL approach enables PyTester, a small language model, to outperform much
larger language models like GPT3.5, StarCoder, and InCoder. Our findings
suggest that future research could consider improving small over large LMs for
better resource efficiency by integrating the SE domain knowledge into the
design of reinforcement learning architecture.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07577" title="Abstract">arXiv:2401.07577</a> [<a href="/pdf/2401.07577" title="Download PDF">pdf</a>, <a href="/format/2401.07577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A greedy heuristic for graph burning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-D%C3%ADaz%2C+J">Jes&#xfa;s Garc&#xed;a-D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Cornejo-Acosta%2C+J+A">Jos&#xe9; Alejandro Cornejo-Acosta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">Given a graph $G$, the optimization version of the graph burning problem
seeks for a sequence of vertices, $(u_1,u_2,...,u_k) \in V(G)^k$, with minimum
$k$ and such that every $v \in V(G)$ has distance at most $k-i$ to some vertex
$u_i$. The length $k$ of the optimal solution is known as the burning number
and is denoted by $b(G)$, an invariant that helps quantify the graph's
vulnerability to contagion. This paper explores the advantages and limitations
of an $\mathcal{O}(mn + kn^2)$ deterministic greedy heuristic for this problem,
where $n$ is the graph's order, $m$ is the graph's size, and $k$ is a guess on
$b(G)$. This heuristic is based on the relationship between the graph burning
problem and the clustered maximum coverage problem, and despite having
limitations on paths and cycles, it found most of the optimal and best-known
solutions of benchmark and synthetic graphs with up to 102400 vertices.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07578" title="Abstract">arXiv:2401.07578</a> [<a href="/pdf/2401.07578" title="Download PDF">pdf</a>, <a href="/format/2401.07578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confounded Budgeted Causal Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jamshidi%2C+F">Fateme Jamshidi</a>, 
<a href="/search/cs?searchtype=author&query=Etesami%2C+J">Jalal Etesami</a>, 
<a href="/search/cs?searchtype=author&query=Kiyavash%2C+N">Negar Kiyavash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study the problem of learning 'good' interventions in a stochastic
environment modeled by its underlying causal graph. Good interventions refer to
interventions that maximize rewards. Specifically, we consider the setting of a
pre-specified budget constraint, where interventions can have non-uniform
costs. We show that this problem can be formulated as maximizing the expected
reward for a stochastic multi-armed bandit with side information. We propose an
algorithm to minimize the cumulative regret in general causal graphs. This
algorithm trades off observations and interventions based on their costs to
achieve the optimal reward. This algorithm generalizes the state-of-the-art
methods by allowing non-uniform costs and hidden confounders in the causal
graph. Furthermore, we develop an algorithm to minimize the simple regret in
the budgeted setting with non-uniform costs and also general causal graphs. We
provide theoretical guarantees, including both upper and lower bounds, as well
as empirical evaluations of our algorithms. Our empirical results showcase that
our algorithms outperform the state of the art.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07579" title="Abstract">arXiv:2401.07579</a> [<a href="/pdf/2401.07579" title="Download PDF">pdf</a>, <a href="/format/2401.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PMFSNet: Polarized Multi-scale Feature Self-attention Network For  Lightweight Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jiahui Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+W">Wenhong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yuanlun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhijia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+J">Jie Ou</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+T">Taoran Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current state-of-the-art medical image segmentation methods prioritize
accuracy but often at the expense of increased computational demands and larger
model sizes. Applying these large-scale models to the relatively limited scale
of medical image datasets tends to induce redundant computation, complicating
the process without the necessary benefits. This approach not only adds
complexity but also presents challenges for the integration and deployment of
lightweight models on edge devices. For instance, recent transformer-based
models have excelled in 2D and 3D medical image segmentation due to their
extensive receptive fields and high parameter count. However, their
effectiveness comes with a risk of overfitting when applied to small datasets
and often neglects the vital inductive biases of Convolutional Neural Networks
(CNNs), essential for local feature representation. In this work, we propose
PMFSNet, a novel medical imaging segmentation model that effectively balances
global and local feature processing while avoiding the computational redundancy
typical in larger models. PMFSNet streamlines the UNet-based hierarchical
structure and simplifies the self-attention mechanism's computational
complexity, making it suitable for lightweight applications. It incorporates a
plug-and-play PMFS block, a multi-scale feature enhancement module based on
attention mechanisms, to capture long-term dependencies. Extensive
comprehensive results demonstrate that even with a model (less than 1 million
parameters), our method achieves superior performance in various segmentation
tasks across different data scales. It achieves (IoU) metrics of 84.68%,
82.02%, and 78.82% on public datasets of teeth CT (CBCT), ovarian tumors
ultrasound(MMOTU), and skin lesions dermoscopy images (ISIC 2018),
respectively. The source code is available at
https://github.com/yykzjh/PMFSNet.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07582" title="Abstract">arXiv:2401.07582</a> [<a href="/pdf/2401.07582" title="Download PDF">pdf</a>, <a href="/format/2401.07582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geo-locating Road Objects using Inverse Haversine Formula with NVIDIA  Driveworks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shami%2C+M+B">Mamoona Birkhez Shami</a>, 
<a href="/search/cs?searchtype=author&query=Kiss%2C+G">Gabriel Kiss</a>, 
<a href="/search/cs?searchtype=author&query=Haakonsen%2C+T+A">Trond Arve Haakonsen</a>, 
<a href="/search/cs?searchtype=author&query=Lindseth%2C+F">Frank Lindseth</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Norsk IKT-konferanse for forskning og utdanning. No. 1. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Geolocation is integral to the seamless functioning of autonomous vehicles
and advanced traffic monitoring infrastructures. This paper introduces a
methodology to geolocate road objects using a monocular camera, leveraging the
NVIDIA DriveWorks platform. We use the Centimeter Positioning Service (CPOS)
and the inverse Haversine formula to geo-locate road objects accurately. The
real-time algorithm processing capability of the NVIDIA DriveWorks platform
enables instantaneous object recognition and spatial localization for Advanced
Driver Assistance Systems (ADAS) and autonomous driving platforms. We present a
measurement pipeline suitable for autonomous driving (AD) platforms and provide
detailed guidelines for calibrating cameras using NVIDIA DriveWorks.
Experiments were carried out to validate the accuracy of the proposed method
for geolocating targets in both controlled and dynamic settings. We show that
our approach can locate targets with less than 1m error when the AD platform is
stationary and less than 4m error at higher speeds (i.e. up to 60km/h) within a
15m radius.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07584" title="Abstract">arXiv:2401.07584</a> [<a href="/pdf/2401.07584" title="Download PDF">pdf</a>, <a href="/format/2401.07584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaboratively Self-supervised Video Representation Learning for Action  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhifan Wan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Lanqing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Stephen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shuzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+S">Shiguang Shan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Considering the close connection between action recognition and human pose
estimation, we design a Collaboratively Self-supervised Video Representation
(CSVR) learning framework specific to action recognition by jointly considering
generative pose prediction and discriminative context matching as pretext
tasks. Specifically, our CSVR consists of three branches: a generative pose
prediction branch, a discriminative context matching branch, and a video
generating branch. Among them, the first one encodes dynamic motion feature by
utilizing Conditional-GAN to predict the human poses of future frames, and the
second branch extracts static context features by pulling the representations
of clips and compressed key frames from the same video together while pushing
apart the pairs from different videos. The third branch is designed to recover
the current video frames and predict the future ones, for the purpose of
collaboratively improving dynamic motion features and static context features.
Extensive experiments demonstrate that our method achieves state-of-the-art
performance on the UCF101 and HMDB51 datasets.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07586" title="Abstract">arXiv:2401.07586</a> [<a href="/pdf/2401.07586" title="Download PDF">pdf</a>, <a href="/format/2401.07586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum for Crowd Counting -- Is it Worthy?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Menouar%2C+H">Hamid Menouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamila%2C+R">Ridha Hamila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of the paper in 19th International Conference on Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-19 February 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in deep learning techniques have achieved remarkable
performance in several computer vision problems. A notably intuitive technique
called Curriculum Learning (CL) has been introduced recently for training deep
learning models. Surprisingly, curriculum learning achieves significantly
improved results in some tasks but marginal or no improvement in others. Hence,
there is still a debate about its adoption as a standard method to train
supervised learning models. In this work, we investigate the impact of
curriculum learning in crowd counting using the density estimation method. We
performed detailed investigations by conducting 112 experiments using six
different CL settings using eight different crowd models. Our experiments show
that curriculum learning improves the model learning performance and shortens
the convergence time.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07589" title="Abstract">arXiv:2401.07589</a> [<a href="/pdf/2401.07589" title="Download PDF">pdf</a>, <a href="/format/2401.07589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Scene Segmentation for Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hurtado%2C+J+V">Juana Valeria Hurtado</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Deep Learning for Robot Perception and Cognition, chapter 12, pp.
  279-311, Elsevier, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Comprehensive scene understanding is a critical enabler of robot autonomy.
Semantic segmentation is one of the key scene understanding tasks which is
pivotal for several robotics applications including autonomous driving,
domestic service robotics, last mile delivery, amongst many others. Semantic
segmentation is a dense prediction task that aims to provide a scene
representation in which each pixel of an image is assigned a semantic class
label. Therefore, semantic segmentation considers the full scene context,
incorporating the object category, location, and shape of all the scene
elements, including the background. Numerous algorithms have been proposed for
semantic segmentation over the years. However, the recent advances in deep
learning combined with the boost in the computational capacity and the
availability of large-scale labeled datasets have led to significant advances
in semantic segmentation. In this chapter, we introduce the task of semantic
segmentation and present the deep learning techniques that have been proposed
to address this task over the years. We first define the task of semantic
segmentation and contrast it with other closely related scene understanding
problems. We detail different algorithms and architectures for semantic
segmentation and the commonly employed loss functions. Furthermore, we present
an overview of datasets, benchmarks, and metrics that are used in semantic
segmentation. We conclude the chapter with a discussion of challenges and
opportunities for further research in this area.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07591" title="Abstract">arXiv:2401.07591</a> [<a href="/pdf/2401.07591" title="Download PDF">pdf</a>, <a href="/format/2401.07591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Crowd Counting with Pix2Pix GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+A">Muhammad Asif Khan</a>, 
<a href="/search/cs?searchtype=author&query=Menouar%2C+H">Hamid Menouar</a>, 
<a href="/search/cs?searchtype=author&query=Hamila%2C+R">Ridha Hamila</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version of the paper in 19th International Conference on Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-29 Feb, 2024,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most state-of-the-art crowd counting methods use color (RGB) images to learn
the density map of the crowd. However, these methods often struggle to achieve
higher accuracy in densely crowded scenes with poor illumination. Recently,
some studies have reported improvement in the accuracy of crowd counting models
using a combination of RGB and thermal images. Although multimodal data can
lead to better predictions, multimodal data might not be always available
beforehand. In this paper, we propose the use of generative adversarial
networks (GANs) to automatically generate thermal infrared (TIR) images from
color (RGB) images and use both to train crowd counting models to achieve
higher accuracy. We use a Pix2Pix GAN network first to translate RGB images to
TIR images. Our experiments on several state-of-the-art crowd counting models
and benchmark crowd datasets report significant improvement in accuracy.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07595" title="Abstract">arXiv:2401.07595</a> [<a href="/pdf/2401.07595" title="Download PDF">pdf</a>, <a href="/format/2401.07595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E3x: $\mathrm{E}(3)$-Equivariant Deep Learning Made Easy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unke%2C+O+T">Oliver T. Unke</a>, 
<a href="/search/cs?searchtype=author&query=Maennel%2C+H">Hartmut Maennel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">This work introduces E3x, a software package for building neural networks
that are equivariant with respect to the Euclidean group $\mathrm{E}(3)$,
consisting of translations, rotations, and reflections of three-dimensional
space. Compared to ordinary neural networks, $\mathrm{E}(3)$-equivariant models
promise benefits whenever input and/or output data are quantities associated
with three-dimensional objects. This is because the numeric values of such
quantities (e.g. positions) typically depend on the chosen coordinate system.
Under transformations of the reference frame, the values change predictably,
but the underlying rules can be difficult to learn for ordinary machine
learning models. With built-in $\mathrm{E}(3)$-equivariance, neural networks
are guaranteed to satisfy the relevant transformation rules exactly, resulting
in superior data efficiency and accuracy. The code for E3x is available from
https://github.com/google-research/e3x.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07598" title="Abstract">arXiv:2401.07598</a> [<a href="/pdf/2401.07598" title="Download PDF">pdf</a>, <a href="/format/2401.07598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aggarwal%2C+D">Divyanshu Aggarwal</a>, 
<a href="/search/cs?searchtype=author&query=Sathe%2C+A">Ashutosh Sathe</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+S">Sunayana Sitaram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 23 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Parameter efficient finetuning has emerged as a viable solution for improving
the performance of Large Language Models without requiring massive resources
and compute. Prior work on multilingual evaluation has shown that there is a
large gap between the performance of LLMs on English and other languages.
Further, there is also a large gap between the performance of smaller
open-source models and larger LLMs. Finetuning can be an effective way to
bridge this gap and make language models more equitable. In this work, we
finetune the LLaMA-7B and Mistral-7B models on synthetic multilingual
instruction tuning data to determine its effect on model performance on five
downstream tasks covering twenty three languages in all. Additionally, we
experiment with various parameters, such as rank for low-rank adaptation and
values of quantisation to determine their effects on downstream performance and
find that higher rank and higher quantisation values benefit low-resource
languages. We find that parameter efficient finetuning of smaller open source
models sometimes bridges the gap between the performance of these models and
the larger ones, however, English performance can take a hit. We also find that
finetuning sometimes improves performance on low-resource languages, while
degrading performance on high-resource languages.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07599" title="Abstract">arXiv:2401.07599</a> [<a href="/pdf/2401.07599" title="Download PDF">pdf</a>, <a href="/format/2401.07599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Koo Dataset: An Indian Microblogging Platform With Global Ambitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mekacher%2C+A">Amin Mekacher</a>, 
<a href="/search/cs?searchtype=author&query=Falkenberg%2C+M">Max Falkenberg</a>, 
<a href="/search/cs?searchtype=author&query=Baronchelli%2C+A">Andrea Baronchelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Increasingly, alternative platforms are playing a key role in the social
media ecosystem. Koo, a microblogging platform based in India, has emerged as a
major new social network hosting high profile politicians from several
countries (India, Brazil, Nigeria) and many internationally renowned
celebrities. This paper presents the largest publicly available Koo dataset,
spanning from the platform's founding in early 2020 to September 2023,
providing detailed metadata for 72M posts, 75M comments, 40M shares, 284M likes
and 1.4M user profiles. Along with the release of the dataset, we provide an
overview of the platform including a discussion of the news ecosystem on the
platform, hashtag usage and user engagement. Our results highlight the pivotal
role that new platforms play in shaping online communities in emerging
economies and the Global South, connecting local politicians and public figures
with their followers. With Koo's ambition to become the town hall for diverse
non-English speaking communities, our dataset offers new opportunities for
studying social media beyond a Western context.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07602" title="Abstract">arXiv:2401.07602</a> [<a href="/pdf/2401.07602" title="Download PDF">pdf</a>, <a href="/format/2401.07602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tensor Alternating Anderson-Richardson method for solving multilinear  systems with M-tensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Niu%2C+J">Jing Niu</a>, 
<a href="/search/math?searchtype=author&query=Du%2C+L">Lei Du</a>, 
<a href="/search/math?searchtype=author&query=Sogabe%2C+T">Tomohiro Sogabe</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+S">Shao-Liang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">It is well-known that a multilinear system with a nonsingular M-tensor and a
positive right-hand side has a unique positive solution. Tensor splitting
methods generalizing the classical iterative methods for linear systems have
been proposed for finding the unique positive solution. The Alternating
Anderson-Richardson (AAR) method is an effective method to accelerate the
classical iterative methods. In this study, we apply the idea of AAR for
finding the unique positive solution quickly. We first present a tensor
Richardson method based on tensor regular splittings, then apply Anderson
acceleration to the tensor Richardson method and derive a tensor
Anderson-Richardson method, finally, we periodically employ the tensor
Anderson-Richardson method within the tensor Richardson method and propose a
tensor AAR method. Numerical experiments show that the proposed method is
effective in accelerating tensor splitting methods.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07603" title="Abstract">arXiv:2401.07603</a> [<a href="/pdf/2401.07603" title="Download PDF">pdf</a>, <a href="/format/2401.07603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task robot data for dual-arm fine manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Heecheol Kim</a>, 
<a href="/search/cs?searchtype=author&query=Ohmura%2C+Y">Yoshiyuki Ohmura</a>, 
<a href="/search/cs?searchtype=author&query=Kuniyoshi%2C+Y">Yasuo Kuniyoshi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, The dataset is available at <a href="https://sites.google.com/view/multi-task-fine">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of robotic manipulation, deep imitation learning is recognized
as a promising approach for acquiring manipulation skills. Additionally,
learning from diverse robot datasets is considered a viable method to achieve
versatility and adaptability. In such research, by learning various tasks,
robots achieved generality across multiple objects. However, such multi-task
robot datasets have mainly focused on single-arm tasks that are relatively
imprecise, not addressing the fine-grained object manipulation that robots are
expected to perform in the real world. This paper introduces a dataset of
diverse object manipulations that includes dual-arm tasks and/or tasks
requiring fine manipulation. To this end, we have generated dataset with 224k
episodes (150 hours, 1,104 language instructions) which includes dual-arm fine
tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data
is publicly available. Additionally, this dataset includes visual attention
signals as well as dual-action labels, a signal that separates actions into a
robust reaching trajectory and precise interaction with objects, and language
instructions to achieve robust and precise object manipulation. We applied the
dataset to our Dual-Action and Attention (DAA), a model designed for
fine-grained dual arm manipulation tasks and robust against covariate shifts.
The model was tested with over 7k total trials in real robot manipulation
tasks, demonstrating its capability in fine manipulation.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07606" title="Abstract">arXiv:2401.07606</a> [<a href="/pdf/2401.07606" title="Download PDF">pdf</a>, <a href="/ps/2401.07606" title="Download PostScript">ps</a>, <a href="/format/2401.07606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RedEx: Beyond Fixed Representation Methods via Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daniely%2C+A">Amit Daniely</a>, 
<a href="/search/cs?searchtype=author&query=Schain%2C+M">Mariano Schain</a>, 
<a href="/search/cs?searchtype=author&query=Yehudai%2C+G">Gilad Yehudai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Optimizing Neural networks is a difficult task which is still not well
understood. On the other hand, fixed representation methods such as kernels and
random features have provable optimization guarantees but inferior performance
due to their inherent inability to learn the representations. In this paper, we
aim at bridging this gap by presenting a novel architecture called RedEx
(Reduced Expander Extractor) that is as expressive as neural networks and can
also be trained in a layer-wise fashion via a convex program with semi-definite
constraints and optimization guarantees. We also show that RedEx provably
surpasses fixed representation methods, in the sense that it can efficiently
learn a family of target functions which fixed representation methods cannot.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07611" title="Abstract">arXiv:2401.07611</a> [<a href="/pdf/2401.07611" title="Download PDF">pdf</a>, <a href="/format/2401.07611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Near Optimal Deployment of Service Function Chains in  Edge-to-Cloud Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behravesh%2C+R">Rasoul Behravesh</a>, 
<a href="/search/cs?searchtype=author&query=Breitgand%2C+D">David Breitgand</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+D+H">Dean H. Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Raz%2C+D">Danny Raz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Mobile edge computing offers a myriad of opportunities to innovate and
introduce novel applications, thereby enhancing user experiences considerably.
A critical issue extensively investigated in this domain is efficient
deployment of Service Function Chains (SFCs) across the physical network,
spanning from the edge to the cloud. This problem is known to be NP-hard. As a
result of its practical importance, there is significant interest in the
development of high-quality sub-optimal solutions.
<br />In this paper, we consider this problem and propose a novel near-optimal
heuristic that is extremely efficient and scalable. We compare our solution to
the state-of-the-art heuristic and to the theoretical optimum. In our
large-scale evaluations, we use realistic topologies which were previously
reported in the literature. We demonstrate that the execution time offered by
our solution grows slowly as the number of Virtual Network Function (VNF)
forwarding graph embedding requests grows, and it handles one million requests
in slightly more than 20 seconds for 100 nodes and 150 edges physical topology.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07612" title="Abstract">arXiv:2401.07612</a> [<a href="/pdf/2401.07612" title="Download PDF">pdf</a>, <a href="/ps/2401.07612" title="Download PostScript">ps</a>, <a href="/format/2401.07612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Signed-Prompt: A New Approach to Prevent Prompt Injection Attacks  Against LLM-Integrated Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suo%2C+X">Xuchen Suo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The critical challenge of prompt injection attacks in Large Language Models
(LLMs) integrated applications, a growing concern in the Artificial
Intelligence (AI) field. Such attacks, which manipulate LLMs through natural
language inputs, pose a significant threat to the security of these
applications. Traditional defense strategies, including output and input
filtering, as well as delimiter use, have proven inadequate. This paper
introduces the 'Signed-Prompt' method as a novel solution. The study involves
signing sensitive instructions within command segments by authorized users,
enabling the LLM to discern trusted instruction sources. The paper presents a
comprehensive analysis of prompt injection attack patterns, followed by a
detailed explanation of the Signed-Prompt concept, including its basic
architecture and implementation through both prompt engineering and fine-tuning
of LLMs. Experiments demonstrate the effectiveness of the Signed-Prompt method,
showing substantial resistance to various types of prompt injection attacks,
thus validating its potential as a robust defense strategy in AI security.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07616" title="Abstract">arXiv:2401.07616</a> [<a href="/pdf/2401.07616" title="Download PDF">pdf</a>, <a href="/ps/2401.07616" title="Download PostScript">ps</a>, <a href="/format/2401.07616" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model checking strategy-controlled systems in rewriting logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio%2C+R">Rub&#xe9;n Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Oliet%2C+N">Narciso Mart&#xed;-Oliet</a>, 
<a href="/search/cs?searchtype=author&query=Pita%2C+I">Isabel Pita</a>, 
<a href="/search/cs?searchtype=author&query=Verdejo%2C+A">Alberto Verdejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Autom. Softw. Eng. 29(1) (2022) article 7
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Rewriting logic and its implementation Maude are an expressive framework for
the formal specification and verification of software and other kinds of
systems. Concurrency is naturally represented by nondeterministic local
transformations produced by the application of rewriting rules over algebraic
terms in an equational theory. Some aspects of the global behavior of the
systems or additional constraints sometimes require restricting this
nondeterminism. Rewriting strategies are used as a higher-level and modular
resource to cleanly capture these requirements, which can be easily expressed
in Maude with an integrated strategy language. However, strategy-aware
specifications cannot be verified with the builtin LTL model checker, making
strategies less useful and attractive.
<br />In this paper, we discuss model checking for strategy-controlled systems, and
present a strategy-aware extension of the Maude LTL model checker. The
expressivity of the strategy language is discussed in relation to model
checking, the model checker is illustrated with multiple application examples,
and its performance is compared.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07629" title="Abstract">arXiv:2401.07629</a> [<a href="/pdf/2401.07629" title="Download PDF">pdf</a>, <a href="/format/2401.07629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained Prototypes Distillation for Few-Shot Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+H">Haonan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhenghao Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot object detection (FSOD) aims at extending a generic detector for
novel object detection with only a few training examples. It attracts great
concerns recently due to the practical meanings. Meta-learning has been
demonstrated to be an effective paradigm for this task. In general, methods
based on meta-learning employ an additional support branch to encode novel
examples (a.k.a. support images) into class prototypes, which are then fused
with query branch to facilitate the model prediction. However, the class-level
prototypes are difficult to precisely generate, and they also lack detailed
information, leading to instability in performance.New methods are required to
capture the distinctive local context for more robust novel object detection.
To this end, we propose to distill the most representative support features
into fine-grained prototypes. These prototypes are then assigned into query
feature maps based on the matching results, modeling the detailed feature
relations between two branches. This process is realized by our Fine-Grained
Feature Aggregation (FFA) module. Moreover, in terms of high-level feature
fusion, we propose Balanced Class-Agnostic Sampling (B-CAS) strategy and
Non-Linear Fusion (NLF) module from differenct perspectives. They are
complementary to each other and depict the high-level feature relations more
effectively. Extensive experiments on PASCAL VOC and MS COCO benchmarks show
that our method sets a new state-of-the-art performance in most settings. Our
code is available at https://github.com/wangchen1801/FPD.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07631" title="Abstract">arXiv:2401.07631</a> [<a href="/pdf/2401.07631" title="Download PDF">pdf</a>, <a href="/format/2401.07631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-parameter debordering of Waring rank
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dutta%2C+P">Pranjal Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Gesmundo%2C+F">Fulvio Gesmundo</a>, 
<a href="/search/cs?searchtype=author&query=Ikenmeyer%2C+C">Christian Ikenmeyer</a>, 
<a href="/search/cs?searchtype=author&query=Jindal%2C+G">Gorav Jindal</a>, 
<a href="/search/cs?searchtype=author&query=Lysikov%2C+V">Vladimir Lysikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages; accepted at STACS 2024; this is an edited part of the preprint <a href="/abs/2211.07055">arXiv:2211.07055</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Border complexity measures are defined via limits (or topological closures),
so that any function which can approximated arbitrarily closely by low
complexity functions itself has low border complexity. Debordering is the task
of proving an upper bound on some non-border complexity measure in terms of a
border complexity measure, thus getting rid of limits.
<br />Debordering is at the heart of understanding the difference between Valiant's
determinant vs permanent conjecture, and Mulmuley and Sohoni's variation which
uses border determinantal complexity. The debordering of matrix multiplication
tensors by Bini played a pivotal role in the development of efficient matrix
multiplication algorithms. Consequently, debordering finds applications in both
establishing computational complexity lower bounds and facilitating algorithm
design. Currently, very few debordering results are known.
<br />In this work, we study the question of debordering the border Waring rank of
polynomials. Waring and border Waring rank are very well studied measures in
the context of invariant theory, algebraic geometry, and matrix multiplication
algorithms. For the first time, we obtain a Waring rank upper bound that is
exponential in the border Waring rank and only linear in the degree. All
previous known results were exponential in the degree. For polynomials with
constant border Waring rank, our results imply an upper bound on the Waring
rank linear in degree, which previously was only known for polynomials with
border Waring rank at most 5.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07636" title="Abstract">arXiv:2401.07636</a> [<a href="/pdf/2401.07636" title="Download PDF">pdf</a>, <a href="/ps/2401.07636" title="Download PostScript">ps</a>, <a href="/format/2401.07636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Isomorphism Testing of Rooted Trees in Linear Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindeberg%2C+A">Anna Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The AHU-algorithm solves the computationally difficult graph isomorphism
problem for rooted trees, and does so with a linear time complexity. Although
the AHU-algorithm has remained state of the art for almost 50 years, it has
been criticized for being unclearly presented, and no complete proof of
correctness has been given. In this text, that gap is filled: we formalize the
algorithm's main point of assigning and compressing labels to provide a
characterization of isomorphic rooted trees, and then proceed with proving the
correctness and optimal runtime of the AHU-algorithm.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07639" title="Abstract">arXiv:2401.07639</a> [<a href="/pdf/2401.07639" title="Download PDF">pdf</a>, <a href="/format/2401.07639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compute-Efficient Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9meth%2C+G">G&#xe1;bor N&#xe9;meth</a>, 
<a href="/search/cs?searchtype=author&query=Matuszka%2C+T">Tam&#xe1;s Matuszka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Active learning, a powerful paradigm in machine learning, aims at reducing
labeling costs by selecting the most informative samples from an unlabeled
dataset. However, the traditional active learning process often demands
extensive computational resources, hindering scalability and efficiency. In
this paper, we address this critical issue by presenting a novel method
designed to alleviate the computational burden associated with active learning
on massive datasets. To achieve this goal, we introduce a simple, yet effective
method-agnostic framework that outlines how to strategically choose and
annotate data points, optimizing the process for efficiency while maintaining
model performance. Through case studies, we demonstrate the effectiveness of
our proposed method in reducing computational costs while maintaining or, in
some cases, even surpassing baseline model outcomes. Code is available at
https://github.com/aimotive/Compute-Efficient-Active-Learning.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07640" title="Abstract">arXiv:2401.07640</a> [<a href="/pdf/2401.07640" title="Download PDF">pdf</a>, <a href="/ps/2401.07640" title="Download PostScript">ps</a>, <a href="/format/2401.07640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Directed Ear Anonymity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milani%2C+M+G">Marcelo Garlet Milani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We define and study a new structural parameter for directed graphs, which we
call \emph{ear anonymity}. Our parameter aims to generalize the useful
properties of \emph{funnels} to larger digraph classes. In particular, funnels
are exactly the acyclic digraphs with ear anonymity one. We prove that
computing the ear anonymity of a digraph is \NP/-hard and that it can be solved
in $O(m(n + m))$-time on acyclic digraphs (where \(n\) is the number of
vertices and \(m\) is the number of arcs in the input digraph). It remains open
where exactly in the polynomial hierarchy the problem of computing ear
anonymity lies, however for a related problem we manage to show
$\Sigma_2^p$-completeness.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07641" title="Abstract">arXiv:2401.07641</a> [<a href="/pdf/2401.07641" title="Download PDF">pdf</a>, <a href="/format/2401.07641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwinTextSpotter v2: Towards Better Synergy for Scene Text Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Mingxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+D">Dezhi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhenghao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chongyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2203.10209">arXiv:2203.10209</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">End-to-end scene text spotting, which aims to read the text in natural
images, has garnered significant attention in recent years. However, recent
state-of-the-art methods usually incorporate detection and recognition simply
by sharing the backbone, which does not directly take advantage of the feature
interaction between the two tasks. In this paper, we propose a new end-to-end
scene text spotting framework termed SwinTextSpotter v2, which seeks to find a
better synergy between text detection and recognition. Specifically, we enhance
the relationship between two tasks using novel Recognition Conversion and
Recognition Alignment modules. Recognition Conversion explicitly guides text
localization through recognition loss, while Recognition Alignment dynamically
extracts text features for recognition through the detection predictions. This
simple yet effective design results in a concise framework that requires
neither an additional rectification module nor character-level annotations for
the arbitrarily-shaped text. Furthermore, the parameters of the detector are
greatly reduced without performance degradation by introducing a Box Selection
Schedule. Qualitative and quantitative experiments demonstrate that
SwinTextSpotter v2 achieved state-of-the-art performance on various
multilingual (English, Chinese, and Vietnamese) benchmarks. The code will be
available at
\href{https://github.com/mxin262/SwinTextSpotterv2}{SwinTextSpotter v2}.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07644" title="Abstract">arXiv:2401.07644</a> [<a href="/pdf/2401.07644" title="Download PDF">pdf</a>, <a href="/format/2401.07644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Optimization in STAR-RIS-Aided SWIPT with RSMA via  Meta-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amiri%2C+M">Mojtaba Amiri</a>, 
<a href="/search/cs?searchtype=author&query=Vaezpour%2C+E">Elaheh Vaezpour</a>, 
<a href="/search/cs?searchtype=author&query=Javadi%2C+S">Sepideh Javadi</a>, 
<a href="/search/cs?searchtype=author&query=Mili%2C+M+R">Mohammad Robat Mili</a>, 
<a href="/search/cs?searchtype=author&query=Yanikomeroglu%2C+H">Halim Yanikomeroglu</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) is a cutting-edge concept for the sixth-generation (6G) wireless
networks. In this letter, we propose a novel system that incorporates STAR-RIS
with simultaneous wireless information and power transfer (SWIPT) using rate
splitting multiple access (RSMA). The proposed system facilitates communication
from a multi-antenna base station (BS) to single-antenna users in a downlink
transmission. The BS concurrently sends energy and information signals to
multiple energy harvesting receivers (EHRs) and information data receivers
(IDRs) with the support of a deployed STAR-RIS. Furthermore, a multi-objective
optimization is introduced to strike a balance between users' sum rate and the
total harvested energy. To achieve this, an optimization problem is formulated
to optimize the energy/information beamforming vectors at the BS, the phase
shifts at the STAR-RIS, and the common message rate. Subsequently, we employ a
meta deep deterministic policy gradient (Meta-DDPG) approach to solve the
complex problem. Simulation results validate that the proposed algorithm
significantly enhances both data rate and harvested energy in comparison to
conventional DDPG.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07654" title="Abstract">arXiv:2401.07654</a> [<a href="/pdf/2401.07654" title="Download PDF">pdf</a>, <a href="/format/2401.07654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Models for Biomedical Image Segmentation: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Theodore Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yanbo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Usuyama%2C+N">Naoto Usuyama</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+C">Cliff Wong</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria-Pang%2C+A">Alberto Santamaria-Pang</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+H">Hoifung Poon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent advancements in biomedical image analysis have been significantly
driven by the Segment Anything Model (SAM). This transformative technology,
originally developed for general-purpose computer vision, has found rapid
application in medical image processing. Within the last year, marked by over
100 publications, SAM has demonstrated its prowess in zero-shot learning
adaptations for medical imaging. The fundamental premise of SAM lies in its
capability to segment or identify objects in images without prior knowledge of
the object type or imaging modality. This approach aligns well with tasks
achievable by the human visual system, though its application in non-biological
vision contexts remains more theoretically challenging. A notable feature of
SAM is its ability to adjust segmentation according to a specified resolution
scale or area of interest, akin to semantic priming. This adaptability has
spurred a wave of creativity and innovation in applying SAM to medical imaging.
Our review focuses on the period from April 1, 2023, to September 30, 2023, a
critical first six months post-initial publication. We examine the adaptations
and integrations of SAM necessary to address longstanding clinical challenges,
particularly in the context of 33 open datasets covered in our analysis. While
SAM approaches or achieves state-of-the-art performance in numerous
applications, it falls short in certain areas, such as segmentation of the
carotid artery, adrenal glands, optic nerve, and mandible bone. Our survey
delves into the innovative techniques where SAM's foundational approach excels
and explores the core concepts in translating and applying these models
effectively in diverse medical imaging scenarios.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07655" title="Abstract">arXiv:2401.07655</a> [<a href="/pdf/2401.07655" title="Download PDF">pdf</a>, <a href="/format/2401.07655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLAD: A Unified Model for Multi-system Log Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+R">Runqiang Zang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hongcheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tieqiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Liangfan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In spite of the rapid advancements in unsupervised log anomaly detection
techniques, the current mainstream models still necessitate specific training
for individual system datasets, resulting in costly procedures and limited
scalability due to dataset size, thereby leading to performance bottlenecks.
Furthermore, numerous models lack cognitive reasoning capabilities, posing
challenges in direct transferability to similar systems for effective anomaly
detection. Additionally, akin to reconstruction networks, these models often
encounter the "identical shortcut" predicament, wherein the majority of system
logs are classified as normal, erroneously predicting normal classes when
confronted with rare anomaly logs due to reconstruction errors.
<br />To address the aforementioned issues, we propose MLAD, a novel anomaly
detection model that incorporates semantic relational reasoning across multiple
systems. Specifically, we employ Sentence-bert to capture the similarities
between log sequences and convert them into highly-dimensional learnable
semantic vectors. Subsequently, we revamp the formulas of the Attention layer
to discern the significance of each keyword in the sequence and model the
overall distribution of the multi-system dataset through appropriate vector
space diffusion. Lastly, we employ a Gaussian mixture model to highlight the
uncertainty of rare words pertaining to the "identical shortcut" problem,
optimizing the vector space of the samples using the maximum expectation model.
Experiments on three real-world datasets demonstrate the superiority of MLAD.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07656" title="Abstract">arXiv:2401.07656</a> [<a href="/pdf/2401.07656" title="Download PDF">pdf</a>, <a href="/ps/2401.07656" title="Download PostScript">ps</a>, <a href="/format/2401.07656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Explainable and Better Performing Representations of POMDP  Strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bork%2C+A">Alexander Bork</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+D">Debraj Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+K">Kush Grover</a>, 
<a href="/search/cs?searchtype=author&query=Kretinsky%2C+J">Jan Kretinsky</a>, 
<a href="/search/cs?searchtype=author&query=Mohr%2C+S">Stefanie Mohr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report for the submission to TACAS 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Strategies for partially observable Markov decision processes (POMDP)
typically require memory. One way to represent this memory is via automata. We
present a method to learn an automaton representation of a strategy using the
L*-algorithm. Compared to the tabular representation of a strategy, the
resulting automaton is dramatically smaller and thus also more explainable.
Moreover, in the learning process, our heuristics may even improve the
strategy's performance. In contrast to approaches that synthesize an automaton
directly from the POMDP thereby solving it, our approach is incomparably more
scalable.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07657" title="Abstract">arXiv:2401.07657</a> [<a href="/pdf/2401.07657" title="Download PDF">pdf</a>, <a href="/format/2401.07657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empirical Evidence for the Fragment level Understanding on Drug  Molecular Structure of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiuyuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 workshop: Large Language Models for Biological Discoveries (LLMs4Bio)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">AI for drug discovery has been a research hotspot in recent years, and
SMILES-based language models has been increasingly applied in drug molecular
design. However, no work has explored whether and how language models
understand the chemical spatial structure from 1D sequences. In this work, we
pre-train a transformer model on chemical language and fine-tune it toward drug
design objectives, and investigate the correspondence between high-frequency
SMILES substrings and molecular fragments. The results indicate that language
models can understand chemical structures from the perspective of molecular
fragments, and the structural knowledge learned through fine-tuning is
reflected in the high-frequency SMILES substrings generated by the model.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07658" title="Abstract">arXiv:2401.07658</a> [<a href="/pdf/2401.07658" title="Download PDF">pdf</a>, <a href="/format/2401.07658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Evaluation of Localization Techniques for Autonomous Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+T+Y">Tian Yi Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ghignone%2C+E">Edoardo Ghignone</a>, 
<a href="/search/cs?searchtype=author&query=Baumann%2C+N">Nicolas Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the Design, Automation and Test in Europe Conference 2024 as an extended abstract
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This work introduces SynPF, an MCL-based algorithm tailored for high-speed
racing environments. Benchmarked against Cartographer, a state-of-the-art
pose-graph SLAM algorithm, SynPF leverages synergies from previous
particle-filtering methods and synthesizes them for the high-performance racing
domain. Our extensive in-field evaluations reveal that while Cartographer
excels under nominal conditions, it struggles when subjected to wheel-slip, a
common phenomenon in a racing scenario due to varying grip levels and
aggressive driving behaviour. Conversely, SynPF demonstrates robustness in
these challenging conditions and a low-latency computation time of 1.25 ms on
on-board computers without a GPU. Using the F1TENTH platform, a 1:10 scaled
autonomous racing vehicle, this work not only highlights the vulnerabilities of
existing algorithms in high-speed scenarios, tested up until 7.6 m/s, but also
emphasizes the potential of SynPF as a viable alternative, especially in
deteriorating odometry conditions.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07663" title="Abstract">arXiv:2401.07663</a> [<a href="/pdf/2401.07663" title="Download PDF">pdf</a>, <a href="/format/2401.07663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selene: Pioneering Automated Proof in Software Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shuai Lu</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+N">Nan Duan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Ensuring correctness is a pivotal aspect of software engineering. Among the
various strategies available, software verification offers a definitive
assurance of correctness. Nevertheless, writing verification proofs is
resource-intensive and manpower-consuming, and there is a great need to
automate this process. We introduce Selene in this paper, which is the first
project-level automated proof benchmark constructed based on the real-world
industrial-level project of the seL4 operating system microkernel. Selene
provides a comprehensive framework for end-to-end evaluation and a lightweight
verification environment. Our experimental results with advanced LLMs, such as
GPT-3.5-turbo and GPT-4, highlight the capabilities of large language models
(LLMs) in the domain of automated proof generation. Additionally, our further
proposed augmentations indicate that the challenges presented by Selene can be
mitigated in future research endeavors.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07669" title="Abstract">arXiv:2401.07669</a> [<a href="/pdf/2401.07669" title="Download PDF">pdf</a>, <a href="/format/2401.07669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FiGCLIP: Fine-Grained CLIP Adaptation via Densely Annotated Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%2C+D+S">Darshan Singh S</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+Z">Zeeshan Khan</a>, 
<a href="/search/cs?searchtype=author&query=Tapaswi%2C+M">Makarand Tapaswi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While contrastive language image pretraining (CLIP) have exhibited impressive
performance by learning highly semantic and generalized representations, recent
works have exposed a fundamental drawback in its syntactic properties, that
includes interpreting fine-grained attributes, actions, spatial relations,
states, and details that require compositional reasoning. One reason for this
is that natural captions often do not capture all the visual details of a
scene. This leads to unaddressed visual concepts being misattributed to the
wrong words. And the pooled image and text features, ends up acting as a bag of
words, hence losing the syntactic information. In this work, we ask: Is it
possible to enhance CLIP's fine-grained and syntactic abilities without
compromising its semantic properties? We show that this is possible by adapting
CLIP efficiently on a high-quality, comprehensive, and relatively small
dataset. We demonstrate our adaptation strategy on VidSitu, a video situation
recognition dataset annotated with verbs and rich semantic role labels (SRL).
We use the SRL and verb information to create rule-based detailed captions,
making sure they capture most of the visual concepts. Combined with hard
negatives and hierarchical losses, these annotations allow us to learn a
powerful visual representation, dubbed Fine-Grained CLIP (FiGCLIP), that
preserves semantic understanding while being detail-oriented. We evaluate on
five diverse vision-language tasks in both fine-tuning and zero-shot settings,
achieving consistent improvements over the base CLIP model.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07671" title="Abstract">arXiv:2401.07671</a> [<a href="/pdf/2401.07671" title="Download PDF">pdf</a>, <a href="/format/2401.07671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLSA-CIM: A Cross-Layer Scheduling Approach for Computing-in-Memory  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelke%2C+R">Rebecca Pelke</a>, 
<a href="/search/cs?searchtype=author&query=Cubero-Cascante%2C+J">Jose Cubero-Cascante</a>, 
<a href="/search/cs?searchtype=author&query=Bosbach%2C+N">Nils Bosbach</a>, 
<a href="/search/cs?searchtype=author&query=Staudigl%2C+F">Felix Staudigl</a>, 
<a href="/search/cs?searchtype=author&query=Leupers%2C+R">Rainer Leupers</a>, 
<a href="/search/cs?searchtype=author&query=Joseph%2C+J+M">Jan Moritz Joseph</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">The demand for efficient machine learning (ML) accelerators is growing
rapidly, driving the development of novel computing concepts such as resistive
random access memory (RRAM)-based tiled computing-in-memory (CIM)
architectures. CIM allows to compute within the memory unit, resulting in
faster data processing and reduced power consumption. Efficient compiler
algorithms are essential to exploit the potential of tiled CIM architectures.
While conventional ML compilers focus on code generation for CPUs, GPUs, and
other von Neumann architectures, adaptations are needed to cover CIM
architectures. Cross-layer scheduling is a promising approach, as it enhances
the utilization of CIM cores, thereby accelerating computations. Although
similar concepts are implicitly used in previous work, there is a lack of clear
and quantifiable algorithmic definitions for cross-layer scheduling for tiled
CIM architectures. To close this gap, we present CLSA-CIM, a cross-layer
scheduling algorithm for tiled CIM architectures. We integrate CLSA-CIM with
existing weight-mapping strategies and compare performance against
state-of-the-art (SOTA) scheduling algorithms. CLSA-CIM improves the
utilization by up to 17.9 x , resulting in an overall speedup increase of up to
29.2 x compared to SOTA.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07674" title="Abstract">arXiv:2401.07674</a> [<a href="/pdf/2401.07674" title="Download PDF">pdf</a>, <a href="/ps/2401.07674" title="Download PostScript">ps</a>, <a href="/format/2401.07674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Evaluation of Kubernetes Networking Approaches across  Constraint Edge Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koukis%2C+G">Georgios Koukis</a> (1 and 3), 
<a href="/search/cs?searchtype=author&query=Skaperas%2C+S">Sotiris Skaperas</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Kapetanidou%2C+I+A">Ioanna Angeliki Kapetanidou</a> (1 and 3), 
<a href="/search/cs?searchtype=author&query=Mamatas%2C+L">Lefteris Mamatas</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Tsaoussidis%2C+V">Vassilis Tsaoussidis</a> (1 and 3) ((1) Department of Electrical and Computer Engineering, Democritus University of Thrace, Xanthi, Greece, (2) Department of Applied Informatics, University of Macedonia, Thessaloniki Greece, (3) Athena Research and Innovation Center, Greece)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted: Proc. IEEE Int. Conf. Comput. Commun. ICCN Workshops (INFOCOM ICCN WKSHPS), Vancouver, Canada, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Kubernetes (K8s) serves as a mature orchestration system for the seamless
deployment and management of containerized applications spanning across cloud
and edge environments. Since high-performance connectivity and minimal resource
utilization become critical factors as we approach the edge, evaluating the
performance of K8s networking in this context is essential. This paper
contributes to this effort, by conducting a qualitative and quantitative
performance evaluation of diverse Container Network Interface (CNI) plugins
within different K8s environments, incorporating lightweight implementations
designed for the Edge. Our experimental assessment was conducted in two
distinct (intra- and inter-host) scenarios, revealing interesting insights for
both researchers and practitioners. For example, the deployment of plugins
across lightweight distributions does not necessarily lead to resource
utilization improvements, e.g., in terms of CPU/memory or throughput.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07677" title="Abstract">arXiv:2401.07677</a> [<a href="/pdf/2401.07677" title="Download PDF">pdf</a>, <a href="/format/2401.07677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Information Flow Control by Construction for  Component-Based Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=R%C3%B8nneberg%2C+R+C">Rasmus Carl R&#xf8;nneberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Secure software architecture is increasingly important in a data-driven
world. When security is neglected sensitive information might leak through
unauthorized access. To mitigate this software architects needs tools and
methods to quantify security risks in complex systems. This paper presents
doctoral research in its early stages concerned with creating constructive
methods for building secure component-based systems from a quantitative
information flow specification. This research aim at developing a method that
allows software architects to develop secure systems from a repository of
secure components. Planned contributions are refinement rules for secure
development of components from a specification and well-formedness rules for
secure composition of said components.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07680" title="Abstract">arXiv:2401.07680</a> [<a href="/pdf/2401.07680" title="Download PDF">pdf</a>, <a href="/format/2401.07680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategies, model checking and branching-time properties in Maude
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio%2C+R">Rub&#xe9;n Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Oliet%2C+N">Narciso Mart&#xed;-Oliet</a>, 
<a href="/search/cs?searchtype=author&query=Pita%2C+I">Isabel Pita</a>, 
<a href="/search/cs?searchtype=author&query=Verdejo%2C+A">Alberto Verdejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Log. Algebraic Methods Program. 123 (2021) article 100700
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Rewriting logic and its implementation Maude are a natural and expressive
framework for the specification of concurrent systems and logics. Its
nondeterministic local transformations are described by rewriting rules, which
can be controlled at a higher level using a builtin strategy language added to
Maude~3. This specification resource would not be of much interest without
tools to analyze their models, so in a previous work, we extended the Maude LTL
model checker to verify strategy-controlled systems. In this paper, CTL* and
$\mu$-calculus are added to the repertoire of supported logics, after
discussing which adaptations are needed for branching-time properties. The new
extension relies on some external model checkers that are exposed the Maude
models through general and efficient connections, profitable for future
extensions and further applications. The performance of these model checkers is
compared.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07682" title="Abstract">arXiv:2401.07682</a> [<a href="/pdf/2401.07682" title="Download PDF">pdf</a>, <a href="/ps/2401.07682" title="Download PostScript">ps</a>, <a href="/format/2401.07682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cash and Card Acceptance in Retail Payments: Motivations and Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vandak%2C+S">Samuel Vandak</a>, 
<a href="/search/cs?searchtype=author&query=Goodell%2C+G">Geoffrey Goodell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 19 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computational Engineering, Finance, and Science (cs.CE); General Finance (q-fin.GN)

</div>
<p class="mathjax">The landscape of payment methods in retail is a complex and evolving area.
Vendors are motivated to conduct an appropriate analysis to decide what payment
methods to accept out of a vast range of options. Many factors are included in
this decision process, some qualitative and some quantitative. The following
research project investigates vendors' acceptance of cards and cash from
various viewpoints, all chosen to represent a novel perspective, including the
barriers and preferences for each and correlations with external demographic
factors. We observe that lower interchange fees, limited in this instance by
the regulatory framework, play a crucial role in facilitating merchants'
acceptance of card payments. The regulatory constraints on interchange fees
create a favorable cost structure for merchants, making card payment adoption
financially feasible. However, additional factors like technological readiness
and consumer preferences might also play a significant role in their
decision-making process. We also note that aggregate Merchant Service Providers
(MSPs) have positively impacted the payment landscape by offering more
competitive fee rates, particularly beneficial for small merchants and
entrepreneurs. However, associated risks, such as account freezes or abrupt
terminations, pose challenges and often lack transparency. Last, the
quantitative analysis of the relationship between demographic variables and
acceptance of payment types is presented. This analysis combines the current
landscape of payment acceptance in the UK with data from the most recent census
from 2021. We show that the unemployment rates shape card and cash acceptance,
age affects contactless preference, and work-from-home impacts credit card
preference.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07683" title="Abstract">arXiv:2401.07683</a> [<a href="/pdf/2401.07683" title="Download PDF">pdf</a>, <a href="/format/2401.07683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assisted Knowledge Graph Authoring: Human-Supervised Knowledge Graph  Construction from Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gohsen%2C+M">Marcel Gohsen</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+B">Benno Stein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at CHIIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Encyclopedic knowledge graphs, such as Wikidata, host an extensive repository
of millions of knowledge statements. However, domain-specific knowledge from
fields such as history, physics, or medicine is significantly underrepresented
in those graphs. Although few domain-specific knowledge graphs exist (e.g.,
Pubmed for medicine), developing specialized retrieval applications for many
domains still requires constructing knowledge graphs from scratch. To
facilitate knowledge graph construction, we introduce WAKA: a Web application
that allows domain experts to create knowledge graphs through the medium with
which they are most familiar: natural language.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07685" title="Abstract">arXiv:2401.07685</a> [<a href="/pdf/2401.07685" title="Download PDF">pdf</a>, <a href="/format/2401.07685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Human-Powered Public Display that Nudges Social Biking via Motion  Gesturing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+B+V+D">Binh Vinh Duc Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Moere%2C+A+V">Andrew Vande Moere</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The WeWatt bike serves as an energy station that enables passers-by to charge
their mobile devices through physical activity. However, despite multiple
people using it simultaneously, the bike is typically used individually. To
address this limitation, we developed the WeWattTree, an installation utilising
human-powered energy to filter environmental air. Through the orchestration of
subtle motion gestures, our goal is to entice passers-by to participate and
encourage them to socially interact, synchronising their pace. In this
work-in-progress, we provide insights into the prototyping process, combining
physical experimentation and computational simulation, and delve into the
underlying concepts of our grammar of motion gestures. We highlight how a
single design effectively merged multiple functionalities, how the role of
material characteristics shaped the interaction design, and discuss the
potential for social performances as captivating public displays.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07691" title="Abstract">arXiv:2401.07691</a> [<a href="/pdf/2401.07691" title="Download PDF">pdf</a>, <a href="/format/2401.07691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Single-Nucleotide Polymorphisms (SNPs) using Bilinear  Group Accumulators in Batch Mode
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buchanan%2C+W+J">William J Buchanan</a>, 
<a href="/search/cs?searchtype=author&query=Grierson%2C+S">Sam Grierson</a>, 
<a href="/search/cs?searchtype=author&query=Uribe%2C+D">Daniel Uribe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Biometric data is often highly sensitive, and a leak of this data can lead to
serious privacy breaches. Some of the most sensitive of this type of data
relates to the usage of DNA data on individuals. A leak of this type of data
without consent could lead to privacy breaches of data protection laws. Along
with this, there have been several recent data breaches related to the leak of
DNA information, including from 23andMe and Ancestry. It is thus fundamental
that a citizen should have the right to know if their DNA data is contained
within a DNA database and ask for it to be removed if they are concerned about
its usage. This paper outlines a method of hashing the core information
contained within the data stores - known as Single-Nucleotide Polymorphisms
(SNPs) - into a bilinear group accumulator in batch mode, which can then be
searched by a trusted entity for matches. The time to create the witness proof
and to verify were measured at 0.86 ms and 10.90 ms, respectively.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07696" title="Abstract">arXiv:2401.07696</a> [<a href="/pdf/2401.07696" title="Download PDF">pdf</a>, <a href="/format/2401.07696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Automatic Translation of Machine Learning Visual Insights to  Analytical Assertions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shome%2C+A">Arumoy Shome</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+L">Luis Cruz</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">We present our vision for developing an automated tool capable of translating
visual properties observed in Machine Learning (ML) visualisations into Python
assertions. The tool aims to streamline the process of manually verifying these
visualisations in the ML development cycle, which is critical as real-world
data and assumptions often change post-deployment. In a prior study, we mined
$54,070$ Jupyter notebooks from Github and created a catalogue of $269$
semantically related visualisation-assertion (VA) pairs. Building on this
catalogue, we propose to build a taxonomy that organises the VA pairs based on
ML verification tasks. The input feature space comprises of a rich source of
information mined from the Jupyter notebooks -- visualisations, Python source
code, and associated markdown text. The effectiveness of various AI models,
including traditional NLP4Code models and modern Large Language Models, will be
compared using established machine translation metrics and evaluated through a
qualitative study with human participants. The paper also plans to address the
challenge of extending the existing VA pair dataset with additional pairs from
Kaggle and to compare the tool's effectiveness with commercial generative AI
models like ChatGPT. This research not only contributes to the field of ML
system validation but also explores novel ways to leverage AI for automating
and enhancing software engineering practices in ML.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07697" title="Abstract">arXiv:2401.07697</a> [<a href="/pdf/2401.07697" title="Download PDF">pdf</a>, <a href="/format/2401.07697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data vs. Model Machine Learning Fairness Testing: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shome%2C+A">Arumoy Shome</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+L">Luis Cruz</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
<p class="mathjax">Although several fairness definitions and bias mitigation techniques exist in
the literature, all existing solutions evaluate fairness of Machine Learning
(ML) systems after the training stage. In this paper, we take the first steps
towards evaluating a more holistic approach by testing for fairness both before
and after model training. We evaluate the effectiveness of the proposed
approach and position it within the ML development lifecycle, using an
empirical analysis of the relationship between model dependent and independent
fairness metrics. The study uses 2 fairness metrics, 4 ML algorithms, 5
real-world datasets and 1600 fairness evaluation cycles. We find a linear
relationship between data and model fairness metrics when the distribution and
the size of the training data changes. Our results indicate that testing for
fairness prior to training can be a ``cheap'' and effective means of catching a
biased data collection process early; detecting data drifts in production
systems and minimising execution of full training cycles thus reducing
development time and costs.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07698" title="Abstract">arXiv:2401.07698</a> [<a href="/pdf/2401.07698" title="Download PDF">pdf</a>, <a href="/format/2401.07698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Learning of Piecewise Polynomial Signed Distance Fields for  Manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%C4%87%2C+A">Ante Mari&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Calinon%2C+S">Sylvain Calinon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Reasoning about distance is indispensable for establishing or avoiding
contact in manipulation tasks. To this end, we present an online method for
learning implicit representations of signed distance using piecewise polynomial
basis functions. Starting from an arbitrary prior shape, our approach
incrementally constructs a continuous representation from incoming point cloud
data. It offers fast access to distance and analytical gradients without the
need to store training data. We assess the accuracy of our model on a diverse
set of household objects and compare it to neural network and Gaussian process
counterparts. Distance reconstruction and real-time updates are further
evaluated in a physical experiment by simultaneously collecting sparse point
cloud data and using the evolving model to control a manipulator.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07702" title="Abstract">arXiv:2401.07702</a> [<a href="/pdf/2401.07702" title="Download PDF">pdf</a>, <a href="/format/2401.07702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting open-source and commercial language models for grammatical  error correction of English learner text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davis%2C+C">Christopher Davis</a>, 
<a href="/search/cs?searchtype=author&query=Caines%2C+A">Andrew Caines</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+%C3%98">&#xd8;istein Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Taslimipoor%2C+S">Shiva Taslimipoor</a>, 
<a href="/search/cs?searchtype=author&query=Yannakoudakis%2C+H">Helen Yannakoudakis</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Bryant%2C+C">Christopher Bryant</a>, 
<a href="/search/cs?searchtype=author&query=Rei%2C+M">Marek Rei</a>, 
<a href="/search/cs?searchtype=author&query=Buttery%2C+P">Paula Buttery</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages with appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Thanks to recent advances in generative AI, we are able to prompt large
language models (LLMs) to produce texts which are fluent and grammatical. In
addition, it has been shown that we can elicit attempts at grammatical error
correction (GEC) from LLMs when prompted with ungrammatical input sentences. We
evaluate how well LLMs can perform at GEC by measuring their performance on
established benchmark datasets. We go beyond previous studies, which only
examined GPT* models on a selection of English GEC datasets, by evaluating
seven open-source and three commercial LLMs on four established GEC benchmarks.
We investigate model performance and report results against individual error
types. Our results indicate that LLMs do not always outperform supervised
English GEC models except in specific contexts -- namely commercial LLMs on
benchmarks annotated with fluency corrections as opposed to minimal edits. We
find that several open-source models outperform commercial ones on minimal edit
benchmarks, and that in some settings zero-shot prompting is just as
competitive as few-shot prompting.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07704" title="Abstract">arXiv:2401.07704</a> [<a href="/pdf/2401.07704" title="Download PDF">pdf</a>, <a href="/format/2401.07704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Paradox of Function Header Comments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oxenhorn%2C+A">Arthur Oxenhorn</a>, 
<a href="/search/cs?searchtype=author&query=Mor%2C+A">Almog Mor</a>, 
<a href="/search/cs?searchtype=author&query=Stern%2C+U">Uri Stern</a>, 
<a href="/search/cs?searchtype=author&query=Feitelson%2C+D+G">Dror G. Feitelson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures plus 23 inlined graphs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Perhaps the most widely used form of code documentation is function header
comments. We performed a large-scale survey of 367 developers to catalog their
expectations from such documentation and to chronicle actual practice.
Paradoxically, we found that developers appreciate the value of header comments
and estimate that they are worth the investment in time, but nevertheless they
tend not to write such documentation in their own code. Reasons for not writing
header comments vary from the belief that code should be self-documenting to
concern that documentation will not be kept up-to-date. A possible outcome of
this situation is that developers may evade requirements to write documentation
by using templates to generate worthless comments that do not provide any real
information. We define a simple metric for information-less documentation based
on its similarity to the function signature. Applying this to 21,140 files in
GitHub Python projects shows that most functions are undocumented, but when
header comments are written they typically do contain additional information
beyond the function signature.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07709" title="Abstract">arXiv:2401.07709</a> [<a href="/pdf/2401.07709" title="Download PDF">pdf</a>, <a href="/format/2401.07709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Diffusion-Based Image Editing with Instant Attention  Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Siyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiji Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jing He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chaoyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhipeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diffusion-based Image Editing (DIE) is an emerging research hot-spot, which
often applies a semantic mask to control the target area for diffusion-based
editing. However, most existing solutions obtain these masks via manual
operations or off-line processing, greatly reducing their efficiency. In this
paper, we propose a novel and efficient image editing method for Text-to-Image
(T2I) diffusion models, termed Instant Diffusion Editing(InstDiffEdit). In
particular, InstDiffEdit aims to employ the cross-modal attention ability of
existing diffusion models to achieve instant mask guidance during the diffusion
steps. To reduce the noise of attention maps and realize the full automatics,
we equip InstDiffEdit with a training-free refinement scheme to adaptively
aggregate the attention distributions for the automatic yet accurate mask
generation. Meanwhile, to supplement the existing evaluations of DIE, we
propose a new benchmark called Editing-Mask to examine the mask accuracy and
local editing ability of existing methods. To validate InstDiffEdit, we also
conduct extensive experiments on ImageNet and Imagen, and compare it with a
bunch of the SOTA methods. The experimental results show that InstDiffEdit not
only outperforms the SOTA methods in both image quality and editing results,
but also has a much faster inference speed, i.e., +5 to +6 times. Our code
available at https://anonymous.4open.science/r/InstDiffEdit-C306/
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07710" title="Abstract">arXiv:2401.07710</a> [<a href="/pdf/2401.07710" title="Download PDF">pdf</a>, <a href="/ps/2401.07710" title="Download PostScript">ps</a>, <a href="/format/2401.07710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Go-Explore for Residential Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junlin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mannion%2C+P">Patrick Mannion</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+K">Karl Mason</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning is commonly applied in residential energy management,
particularly for optimizing energy costs. However, RL agents often face
challenges when dealing with deceptive and sparse rewards in the energy control
domain, especially with stochastic rewards. In such situations, thorough
exploration becomes crucial for learning an optimal policy. Unfortunately, the
exploration mechanism can be misled by deceptive reward signals, making
thorough exploration difficult. Go-Explore is a family of algorithms which
combines planning methods and reinforcement learning methods to achieve
efficient exploration. We use the Go-Explore algorithm to solve the cost-saving
task in residential energy management problems and achieve an improvement of up
to 19.84\% compared to the well-known reinforcement learning algorithms.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07711" title="Abstract">arXiv:2401.07711</a> [<a href="/pdf/2401.07711" title="Download PDF">pdf</a>, <a href="/format/2401.07711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Nonparametric Tensor Decomposition for Binary and Count Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zerui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Toshihisa Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In numerous applications, binary reactions or event counts are observed and
stored within high-order tensors. Tensor decompositions (TDs) serve as a
powerful tool to handle such high-dimensional and sparse data. However, many
traditional TDs are explicitly or implicitly designed based on the Gaussian
distribution, which is unsuitable for discrete data. Moreover, most TDs rely on
predefined multi-linear structures, such as CP and Tucker formats. Therefore,
they may not be effective enough to handle complex real-world datasets. To
address these issues, we propose ENTED, an \underline{E}fficient
\underline{N}onparametric \underline{TE}nsor \underline{D}ecomposition for
binary and count tensors. Specifically, we first employ a nonparametric
Gaussian process (GP) to replace traditional multi-linear structures. Next, we
utilize the \pg augmentation which provides a unified framework to establish
conjugate models for binary and count distributions. Finally, to address the
computational issue of GPs, we enhance the model by incorporating sparse
orthogonal variational inference of inducing points, which offers a more
effective covariance approximation within GPs and stochastic natural gradient
updates for nonparametric models. We evaluate our model on several real-world
tensor completion tasks, considering binary and count datasets. The results
manifest both better performance and computational advantages of the proposed
model.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07713" title="Abstract">arXiv:2401.07713</a> [<a href="/pdf/2401.07713" title="Download PDF">pdf</a>, <a href="/format/2401.07713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximations to Study the Impact of the Service Discipline in Systems  with Redundancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gast%2C+N">Nicolas Gast</a> (POLARIS, UGA), 
<a href="/search/cs?searchtype=author&query=van+Houdt%2C+B">Benny van Houdt</a> (UA)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the ACM on Measurement and Analysis of Computing
  Systems , 2024, 8 (1)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>

</div>
<p class="mathjax">As job redundancy has been recognized as an effective means to improve
performance of large-scale computer systems, queueing systems with redundancy
have been studied by various authors. Existing results include methods to
compute the queue length distribution and response time but only when the
service discipline is First-Come-First-Served (FCFS). For other service
disciplines, such as Processor Sharing (PS), or Last-Come-First-Served (LCFS),
only the stability conditions are known. In this paper we develop the first
methods to approximate the queue length distribution in a queueing system with
redundancy under various service disciplines. We focus on a system with
exponential job sizes, i.i.d. copies, and a large number of servers. We first
derive a mean field approximation that is independent of the scheduling policy.
In order to study the impact of service discipline, we then derive refinements
of this approximation to specific scheduling policies. In the case of Processor
Sharing, we provide a pair and a triplet approximation. The pair approximation
can be regarded as a refinement of the classic mean field approximation and
takes the service discipline into account, while the triplet approximation
further refines the pair approximation. We also develop a pair approximation
for three other service disciplines: First-Come-First-Served, Limited Processor
Sharing and Last-Come-First-Served. We present numerical evidence that shows
that all the approximations presented in the paper are highly accurate, but
that none of them are asymptotically exact (as the number of servers goes to
infinity). This makes these approximations suitable to study the impact of the
service discipline on the queue length distribution. Our results show that FCFS
yields the shortest queue length, and that the differences are more substantial
at higher loads.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07717" title="Abstract">arXiv:2401.07717</a> [<a href="/pdf/2401.07717" title="Download PDF">pdf</a>, <a href="/ps/2401.07717" title="Download PostScript">ps</a>, <a href="/format/2401.07717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Pragmatical Approach to Anomaly Detection Evaluation in Edge Cloud  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Skaperas%2C+S">Sotiris Skaperas</a> (1 and 3), 
<a href="/search/cs?searchtype=author&query=Koukis%2C+G">George Koukis</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Kapetanidou%2C+I+A">Ioanna Angeliki Kapetanidou</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Tsaoussidis%2C+V">Vassilis Tsaoussidis</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Mamatas%2C+L">Lefteris Mamatas</a> (1 and 3) ((1) Department of Applied Informatics, University of Macedonia, Thessaloniki Greece, (2) Department of Electrical and Computer Engineering, Democritus University of Thrace, Greece, (3) Athena Research and Innovation Center, Greece)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted: Proc. IEEE Int. Conf. Comput. Commun. ICCN Workshops (INFOCOM ICCN WKSHPS), Vancouver, Canada, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Anomaly detection (AD) has been recently employed in the context of edge
cloud computing, e.g., for intrusion detection and identification of
performance issues. However, state-of-the-art anomaly detection procedures do
not systematically consider restrictions and performance requirements inherent
to the edge, such as system responsiveness and resource consumption. In this
paper, we attempt to investigate the performance of change-point based
detectors, i.e., a class of lightweight and accurate AD methods, in relation to
the requirements of edge cloud systems. Firstly, we review the theoretical
properties of two major categories of change point approaches, i.e., Bayesian
and cumulative sum (CUSUM), also discussing their suitability for edge systems.
Secondly, we introduce a novel experimental methodology and apply it over two
distinct edge cloud test-beds to evaluate the performance of such mechanisms in
real-world edge environments. Our experimental results reveal important
insights and trade-offs for the applicability and the online performance of the
selected change point detectors.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07718" title="Abstract">arXiv:2401.07718</a> [<a href="/pdf/2401.07718" title="Download PDF">pdf</a>, <a href="/ps/2401.07718" title="Download PostScript">ps</a>, <a href="/format/2401.07718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Social Media Big Data Can Improve Suicide Prevention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peshkovskaya%2C+A">Anastasia Peshkovskaya</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu-Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In the light of increasing clues on social media impact on self-harm and
suicide risks, there is still no evidence on who are and how factually engaged
in suicide-related online behaviors. This study reports new findings of
high-performance supercomputing investigation of publicly accessible big data
sourced from one of the world-largest social networking site. Three-month
supercomputer searching resulted in 570,156 young adult users who consumed
suicide-related information on social media. Most of them were 21-24 year olds
with higher share of females (58%) of predominantly younger age. Every eight
user was alarmingly engrossed with up to 15 suicide-related online groups.
Evidently, suicide groups on social media are highly underrated public health
issue that might weaken the prevention efforts. Suicide prevention strategies
that target social media users must be implemented extensively. While major gap
in functional understanding of technologies relevance for use in public mental
health still exists, current findings act for better understanding digital
technologies utility for translational advance and offer relevant
evidence-based framework for improving suicide prevention in general
population.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07721" title="Abstract">arXiv:2401.07721</a> [<a href="/pdf/2401.07721" title="Download PDF">pdf</a>, <a href="/format/2401.07721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Transformer GANs with Graph Masked Modeling for Architectural  Layout Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Ling Shao</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TPAMI, an extended version of a paper published in CVPR2023. arXiv admin note: substantial text overlap with <a href="/abs/2303.08225">arXiv:2303.08225</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a novel graph Transformer generative adversarial network (GTGAN)
to learn effective graph node relations in an end-to-end fashion for
challenging graph-constrained architectural layout generation tasks. The
proposed graph-Transformer-based generator includes a novel graph Transformer
encoder that combines graph convolutions and self-attentions in a Transformer
to model both local and global interactions across connected and non-connected
graph nodes. Specifically, the proposed connected node attention (CNA) and
non-connected node attention (NNA) aim to capture the global relations across
connected nodes and non-connected nodes in the input graph, respectively. The
proposed graph modeling block (GMB) aims to exploit local vertex interactions
based on a house layout topology. Moreover, we propose a new node
classification-based discriminator to preserve the high-level semantic and
discriminative node features for different house components. To maintain the
relative spatial relationships between ground truth and predicted graphs, we
also propose a novel graph-based cycle-consistency loss. Finally, we propose a
novel self-guided pre-training method for graph representation learning. This
approach involves simultaneous masking of nodes and edges at an elevated mask
ratio (i.e., 40%) and their subsequent reconstruction using an asymmetric
graph-centric autoencoder architecture. This method markedly improves the
model's learning proficiency and expediency. Experiments on three challenging
graph-constrained architectural layout generation tasks (i.e., house layout
generation, house roof generation, and building layout generation) with three
public datasets demonstrate the effectiveness of the proposed method in terms
of objective quantitative scores and subjective visual realism. New
state-of-the-art results are established by large margins on these three tasks.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07722" title="Abstract">arXiv:2401.07722</a> [<a href="/pdf/2401.07722" title="Download PDF">pdf</a>, <a href="/format/2401.07722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Preferences from Demonstrations in Multi-Objective Residential  Energy Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Junlin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mannion%2C+P">Patrick Mannion</a>, 
<a href="/search/cs?searchtype=author&query=Mason%2C+K">Karl Mason</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">It is often challenging for a user to articulate their preferences accurately
in multi-objective decision-making problems. Demonstration-based preference
inference (DemoPI) is a promising approach to mitigate this problem.
Understanding the behaviours and values of energy customers is an example of a
scenario where preference inference can be used to gain insights into the
values of energy customers with multiple objectives, e.g. cost and comfort. In
this work, we applied the state-of-art DemoPI method, i.e., the dynamic
weight-based preference inference (DWPI) algorithm in a multi-objective
residential energy consumption setting to infer preferences from energy
consumption demonstrations by simulated users following a rule-based approach.
According to our experimental results, the DWPI model achieves accurate
demonstration-based preference inferring in three scenarios. These advancements
enhance the usability and effectiveness of multi-objective reinforcement
learning (MORL) in energy management, enabling more intuitive and user-friendly
preference specifications, and opening the door for DWPI to be applied in
real-world settings.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07725" title="Abstract">arXiv:2401.07725</a> [<a href="/pdf/2401.07725" title="Download PDF">pdf</a>, <a href="/ps/2401.07725" title="Download PostScript">ps</a>, <a href="/format/2401.07725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects Investigation of MAC and PHY Layer Parameters on the Performance  of IEEE 802.15.6 CSMA/CA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddik%2C+M+A">Md. Abubakar Siddik</a>, 
<a href="/search/cs?searchtype=author&query=Hasi%2C+M+A+A">Most. Anju Ara Hasi</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+R">Md. Rajiul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Nitu%2C+J+A">Jakia Akter Nitu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages. arXiv admin note: substantial text overlap with <a href="/abs/2209.00247">arXiv:2209.00247</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The recently released IEEE 802.15.6 standard specifies several physical (PHY)
layer and medium access control (MAC) layer protocols for variety of medical
and non-medical applications of Wireless Body Area Networks (WBAN). The most
suitable way for enhancing network performance is to be the choice of different
MAC and PHY parameters based on quality of service (QoS) requirements of
different applications. The impact of different MAC and PHY parameters on the
network performance and the trade-off relationship between the parameters are
essential to overcome the limitations of exiting carrier sense multiple access
with collision avoidance (CSMA/CA) scheme of IEEE 802.15.6 standard. To address
this issue, we develop a Markov chain-based analytical model of IEEE 802.15.6
CSMA/CA for all user priorities (UPs) and apply this general model to different
network scenarios to investigate the effects of the packet arrival rate,
channel condition, payload size, access phase length, access mechanism and
number of nodes on the performance parameters viz. reliability, normalized
throughput, energy consumption and average access delay. Moreover, we conclude
the effectiveness of different access phases, access mechanisms and user
priorities of intra-WBAN.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07726" title="Abstract">arXiv:2401.07726</a> [<a href="/pdf/2401.07726" title="Download PDF">pdf</a>, <a href="/format/2401.07726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preserving Power Optimizations Across the High Level Synthesis of  Distinct Application-Specific Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia%2C+P">Paulo Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We evaluate the use of software interpretation to push High Level Synthesis
of application-specific accelerators toward a higher level of abstraction. Our
methodology is supported by a formal power consumption model that computes the
power consumption of accelerator components, accurately predicting the power
consumption on new designs from prior optimization estimations. We demonstrate
how our approach simplifies the re-use of power optimizations across distinct
designs, by leveraging the higher level of design abstraction, using two
accelerators representative of the robotics domain, implemented through the
Bambu High Level Synthesis tool. Results support the research hypothesis,
achieving predictions accurate within +/- 1%.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07727" title="Abstract">arXiv:2401.07727</a> [<a href="/pdf/2401.07727" title="Download PDF">pdf</a>, <a href="/format/2401.07727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HexaGen3D: StableDiffusion is just one step away from Fast and Diverse  Text-to-3D Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mercier%2C+A">Antoine Mercier</a>, 
<a href="/search/cs?searchtype=author&query=Nakhli%2C+R">Ramin Nakhli</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+M">Mahesh Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Yasarla%2C+R">Rajeev Yasarla</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Porikli%2C+F">Fatih Porikli</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+G">Guillaume Berger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite the latest remarkable advances in generative modeling, efficient
generation of high-quality 3D assets from textual prompts remains a difficult
task. A key challenge lies in data scarcity: the most extensive 3D datasets
encompass merely millions of assets, while their 2D counterparts contain
billions of text-image pairs. To address this, we propose a novel approach
which harnesses the power of large, pretrained 2D diffusion models. More
specifically, our approach, HexaGen3D, fine-tunes a pretrained text-to-image
model to jointly predict 6 orthographic projections and the corresponding
latent triplane. We then decode these latents to generate a textured mesh.
HexaGen3D does not require per-sample optimization, and can infer high-quality
and diverse objects from textual prompts in 7 seconds, offering significantly
better quality-to-latency trade-offs when comparing to existing approaches.
Furthermore, HexaGen3D demonstrates strong generalization to new objects or
compositions.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07729" title="Abstract">arXiv:2401.07729</a> [<a href="/pdf/2401.07729" title="Download PDF">pdf</a>, <a href="/format/2401.07729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-Interactions: Pretext Tasks for Interactive Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharyya%2C+P">Prarthana Bhattacharyya</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Czarnecki%2C+K">Krzysztof Czarnecki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures, submitted to IV-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This paper addresses motion forecasting in multi-agent environments, pivotal
for ensuring safety of autonomous vehicles. Traditional as well as recent
data-driven marginal trajectory prediction methods struggle to properly learn
non-linear agent-to-agent interactions. We present SSL-Interactions that
proposes pretext tasks to enhance interaction modeling for trajectory
prediction. We introduce four interaction-aware pretext tasks to encapsulate
various aspects of agent interactions: range gap prediction, closest distance
prediction, direction of movement prediction, and type of interaction
prediction. We further propose an approach to curate interaction-heavy
scenarios from datasets. This curated data has two advantages: it provides a
stronger learning signal to the interaction model, and facilitates generation
of pseudo-labels for interaction-centric pretext tasks. We also propose three
new metrics specifically designed to evaluate predictions in interactive
scenes. Our empirical evaluations indicate SSL-Interactions outperforms
state-of-the-art motion forecasting methods quantitatively with up to 8%
improvement, and qualitatively, for interaction-heavy scenarios.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07732" title="Abstract">arXiv:2401.07732</a> [<a href="/pdf/2401.07732" title="Download PDF">pdf</a>, <a href="/format/2401.07732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Popularity in location games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fournier%2C+G">Ga&#xeb;tan Fournier</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+M">Marc Schr&#xf6;der</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study a variant of the Hotelling-Downs model of spatial competition
between firms where consumer choices are influenced by their individual
preferences as well as the popularity of the firms. In general, a multiplicity
of market equilibria might exist due to the popularity effect. To elucidate
firm decision-making, we explore three distinct behavioral attitudes towards
this multiplicity of equilibria: optimistic, neutral, and pessimistic. For each
behavior, we characterize the set of Nash equilibria and measure the impact of
the selfish behavior on the social welfare by means of the price of anarchy and
price of stability.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07743" title="Abstract">arXiv:2401.07743</a> [<a href="/pdf/2401.07743" title="Download PDF">pdf</a>, <a href="/format/2401.07743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating and model checking membrane systems using strategies in Maude
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio%2C+R">Rub&#xe9;n Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Oliet%2C+N">Narciso Mart&#xed;-Oliet</a>, 
<a href="/search/cs?searchtype=author&query=Pita%2C+I">Isabel Pita</a>, 
<a href="/search/cs?searchtype=author&query=Verdejo%2C+A">Alberto Verdejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Logic. Algebr. Program 124 (2022) article 100727
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Membrane systems are a biologically-inspired computational model based on the
structure of biological cells and the way chemicals interact and traverse their
membranes. Although their dynamics are described by rules, encoding membrane
systems into rewriting logic is not straightforward due to its complex control
mechanisms. Multiple alternatives have been proposed in the literature and
implemented in the Maude specification language. The recent release of the
Maude strategy language and its associated strategy-aware model checker allow
specifying these systems more easily, so that they become executable and
verifiable for free. An easily-extensible interactive environment transforms
membrane specifications into rewrite theories controlled by appropriate
strategies, and allows simulating and verifying membrane computations by means
of them.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07744" title="Abstract">arXiv:2401.07744</a> [<a href="/pdf/2401.07744" title="Download PDF">pdf</a>, <a href="/format/2401.07744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Machine Learning and Ontology: A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghidalia%2C+S">Sarah Ghidalia</a>, 
<a href="/search/cs?searchtype=author&query=Narsis%2C+O+L">Ouassila Labbani Narsis</a>, 
<a href="/search/cs?searchtype=author&query=Bertaux%2C+A">Aur&#xe9;lie Bertaux</a>, 
<a href="/search/cs?searchtype=author&query=Nicolle%2C+C">Christophe Nicolle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Motivated by the desire to explore the process of combining inductive and
deductive reasoning, we conducted a systematic literature review of articles
that investigate the integration of machine learning and ontologies. The
objective was to identify diverse techniques that incorporate both inductive
reasoning (performed by machine learning) and deductive reasoning (performed by
ontologies) into artificial intelligence systems. Our review, which included
the analysis of 128 studies, allowed us to identify three main categories of
hybridization between machine learning and ontologies: learning-enhanced
ontologies, semantic data mining, and learning and reasoning systems. We
provide a comprehensive examination of all these categories, emphasizing the
various machine learning algorithms utilized in the studies. Furthermore, we
compared our classification with similar recent work in the field of hybrid AI
and neuro-symbolic approaches.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07745" title="Abstract">arXiv:2401.07745</a> [<a href="/pdf/2401.07745" title="Download PDF">pdf</a>, <a href="/format/2401.07745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MaskClustering: View Consensus based Mask Graph Clustering for  Open-Vocabulary 3D Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiazhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Open-vocabulary 3D instance segmentation has emerged as a frontier topic due
to its capability to segment 3D instances beyond a predefined set of
categories. However, compared to significant progress in the 2D domain, methods
for 3D open-vocabulary instance segmentation are hindered by the limited scale
of high-quality annotated 3D data. To harness the capabilities of 2D models,
recent efforts have focused on merging 2D masks based on metrics such as
geometric and semantic similarity to form 3D instances. In contrast to these
local metrics, we propose a novel metric called view consensus to better
exploit multi-view observation. The key insight is that two 2D masks should be
considered as belonging to the same instance if a considerable number of other
2D masks from other views contain both these two masks. Based on this metric,
we build a global mask graph and iteratively cluster masks, prioritizing mask
pairs with solid view consensus. The corresponding 3D points cluster of these
2D mask clusters can be regarded as 3D instances, along with the fused
open-vocabulary features from clustered 2D masks. Through this multi-view
verification and fusion mechanism, our method effectively leverages the prior
instance knowledge from massive 2D masks predicted by visual foundation models,
eliminating the need for training on 3D data. Experiments on publicly available
datasets, including ScanNet200 and MatterPort3D, demonstrate that our method
achieves state-of-the-art performance in both open-vocabulary instance
segmentation and class-agnostic mask generation. Our project page is at
https://pku-epic.github.io/MaskClustering.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07746" title="Abstract">arXiv:2401.07746</a> [<a href="/pdf/2401.07746" title="Download PDF">pdf</a>, <a href="/format/2401.07746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity-based background removal for STORM super-resolution images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valera%2C+P">Patris Valera</a>, 
<a href="/search/cs?searchtype=author&query=Vizca%C3%ADno%2C+J+P">Josu&#xe9; Page Vizca&#xed;no</a>, 
<a href="/search/cs?searchtype=author&query=Lasser%2C+T">Tobias Lasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Single-molecule localization microscopy techniques, like stochastic optical
reconstruction microscopy (STORM), visualize biological specimens by
stochastically exciting sparse blinking emitters. The raw images suffer from
unwanted background fluorescence, which must be removed to achieve
super-resolution. We introduce a sparsity-based background removal method by
adapting a neural network (SLNet) from a different microscopy domain. The SLNet
computes a low-rank representation of the images, and then, by subtracting it
from the raw images, the sparse component is computed, representing the frames
without the background. We compared our approach with widely used background
removal methods, such as the median background removal or the rolling ball
algorithm, on two commonly used STORM datasets, one glial cell, and one
microtubule dataset. The SLNet delivers STORM frames with less background,
leading to higher emitters' localization precision and higher-resolution
reconstructed images than commonly used methods. Notably, the SLNet is
lightweight and easily trainable (&lt;5 min). Since it is trained in an
unsupervised manner, no prior information is required and can be applied to any
STORM dataset. We uploaded a pre-trained SLNet to the Bioimage model zoo,
easily accessible through ImageJ. Our results show that our sparse
decomposition method could be an essential and efficient STORM pre-processing
tool.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07749" title="Abstract">arXiv:2401.07749</a> [<a href="/pdf/2401.07749" title="Download PDF">pdf</a>, <a href="/ps/2401.07749" title="Download PostScript">ps</a>, <a href="/format/2401.07749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metalevel transformation of strategies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rubio%2C+R">Rub&#xe9;n Rubio</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%AD-Oliet%2C+N">Narciso Mart&#xed;-Oliet</a>, 
<a href="/search/cs?searchtype=author&query=Pita%2C+I">Isabel Pita</a>, 
<a href="/search/cs?searchtype=author&query=Verdejo%2C+A">Alberto Verdejo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Logic. Algebr. Program 124 (2022) article 100728
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In the reflective Maude specification language, based on rewriting logic, a
strategy language has been introduced to control rule rewriting while avoiding
complex and verbose metalevel programs. However, just as multiple levels of
reflection are required for some metaprogramming tasks, reflective manipulation
and generation of strategies are convenient in multiple situations. Some
examples of reflective strategy transformations are presented, which implement
special forms of evaluation or extend the strategy language while preserving
its advantages.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07753" title="Abstract">arXiv:2401.07753</a> [<a href="/pdf/2401.07753" title="Download PDF">pdf</a>, <a href="/format/2401.07753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-light Stereo Image Enhancement and De-noising in the Low-frequency  Information Enhanced Image Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Minghua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiangdong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Shuangli Du</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xuefei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+J">Jiahao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yiguang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unlike single image task, stereo image enhancement can use another view
information, and its key stage is how to perform cross-view feature interaction
to extract useful information from another view. However, complex noise in
low-light image and its impact on subsequent feature encoding and interaction
are ignored by the existing methods. In this paper, a method is proposed to
perform enhancement and de-noising simultaneously. First, to reduce unwanted
noise interference, a low-frequency information enhanced module (IEM) is
proposed to suppress noise and produce a new image space. Additionally, a
cross-channel and spatial context information mining module (CSM) is proposed
to encode long-range spatial dependencies and to enhance inter-channel feature
interaction. Relying on CSM, an encoder-decoder structure is constructed,
incorporating cross-view and cross-scale feature interactions to perform
enhancement in the new image space. Finally, the network is trained with the
constraints of both spatial and frequency domain losses. Extensive experiments
on both synthesized and real datasets show that our method obtains better
detail recovery and noise removal compared with state-of-the-art methods. In
addition, a real stereo image enhancement dataset is captured with stereo
camera ZED2. The code and dataset are publicly available at:
https://www.github.com/noportraits/LFENet.
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07756" title="Abstract">arXiv:2401.07756</a> [<a href="/pdf/2401.07756" title="Download PDF">pdf</a>, <a href="/format/2401.07756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Probability Selection and Power Allocation for Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marnissi%2C+O">Ouiame Marnissi</a>, 
<a href="/search/cs?searchtype=author&query=Hammouti%2C+H+E">Hajar EL Hammouti</a>, 
<a href="/search/cs?searchtype=author&query=Bergou%2C+E+H">El Houcine Bergou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we study the performance of federated learning over wireless
networks, where devices with a limited energy budget train a machine learning
model. The federated learning performance depends on the selection of the
clients participating in the learning at each round. Most existing studies
suggest deterministic approaches for the client selection, resulting in
challenging optimization problems that are usually solved using heuristics, and
therefore without guarantees on the quality of the final solution. We formulate
a new probabilistic approach to jointly select clients and allocate power
optimally so that the expected number of participating clients is maximized. To
solve the problem, a new alternating algorithm is proposed, where at each step,
the closed-form solutions for user selection probabilities and power
allocations are obtained. Our numerical results show that the proposed approach
achieves a significant performance in terms of energy consumption, completion
time and accuracy as compared to the studied benchmarks.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07760" title="Abstract">arXiv:2401.07760</a> [<a href="/pdf/2401.07760" title="Download PDF">pdf</a>, <a href="/format/2401.07760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the importance of Data Scale in Pretraining Arabic Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaddar%2C+A">Abbas Ghaddar</a>, 
<a href="/search/cs?searchtype=author&query=Langlais%2C+P">Philippe Langlais</a>, 
<a href="/search/cs?searchtype=author&query=Rezagholizadeh%2C+M">Mehdi Rezagholizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pretraining monolingual language models have been proven to be vital for
performance in Arabic Natural Language Processing (NLP) tasks. In this paper,
we conduct a comprehensive study on the role of data in Arabic Pretrained
Language Models (PLMs). More precisely, we reassess the performance of a suite
of state-of-the-art Arabic PLMs by retraining them on massive-scale,
high-quality Arabic corpora. We have significantly improved the performance of
the leading Arabic encoder-only BERT-base and encoder-decoder T5-base models on
the ALUE and ORCA leaderboards, thereby reporting state-of-the-art results in
their respective model categories. In addition, our analysis strongly suggests
that pretraining data by far is the primary contributor to performance,
surpassing other factors. Our models and source code are publicly available at
https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/JABER-PyTorch.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07761" title="Abstract">arXiv:2401.07761</a> [<a href="/pdf/2401.07761" title="Download PDF">pdf</a>, <a href="/ps/2401.07761" title="Download PostScript">ps</a>, <a href="/format/2401.07761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Matchings in Practice: A Constraint Programming Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaohong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+N">Naoyuki Yamada</a>, 
<a href="/search/cs?searchtype=author&query=Takenami%2C+Y">Yoshihiro Takenami</a>, 
<a href="/search/cs?searchtype=author&query=Moriwaki%2C+D">Daisuke Moriwaki</a>, 
<a href="/search/cs?searchtype=author&query=Yokoo%2C+M">Makoto Yokoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study a practical two-sided matching problem of allocating children to
daycare centers, which has significant social implications. We are cooperating
with several municipalities in Japan and our goal is to devise a reliable and
trustworthy clearing algorithm to deal with the problem. In this paper, we
describe the design of our new algorithm that minimizes the number of unmatched
children while ensuring stability. We evaluate our algorithm using real-life
data sets, and experimental results demonstrate that our algorithm surpasses
the commercial software that currently dominates the market in terms of both
the number of matched children and the number of blocking coalitions (measuring
stability). Our findings have been reported to local governments, and some are
considering adopting our proposed algorithm in the near future, instead of the
existing solution. Moreover, our model and algorithm have broader applicability
to other important matching markets, such as hospital-doctor matching with
couples and school choice with siblings.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07762" title="Abstract">arXiv:2401.07762</a> [<a href="/pdf/2401.07762" title="Download PDF">pdf</a>, <a href="/ps/2401.07762" title="Download PostScript">ps</a>, <a href="/format/2401.07762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Regressive Model with Exogenous Input--ARX--based traffic-flow  prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jun Ying</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xin Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zihan Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Traffic flow prediction is widely used in travel decision making, traffic
control, roadway system planning, business sectors, and government agencies.
ARX models have proved to be highly effective and versatile. In this research,
we investigated the applications of ARX models in prediction for real traffic
flow in New York City. The ARX models were constructed by linear/polynomial or
neural networks. Comparative studies were carried out based on the results by
the efficiency, accuracy, and training computational demand of the algorithms.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07764" title="Abstract">arXiv:2401.07764</a> [<a href="/pdf/2401.07764" title="Download PDF">pdf</a>, <a href="/format/2401.07764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Large Language Model Agents Meet 6G Networks: Perception,  Grounding, and Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minrui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dusit%2C+N">Niyato Dusit</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zehui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shiwen Mao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Z">Zhu Han</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+I">Dong In Kim</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">AI agents based on multimodal large language models (LLMs) are expected to
revolutionize human-computer interaction and offer more personalized assistant
services across various domains like healthcare, education, manufacturing, and
entertainment. Deploying LLM agents in 6G networks enables users to access
previously expensive AI assistant services via mobile devices democratically,
thereby reducing interaction latency and better preserving user privacy.
Nevertheless, the limited capacity of mobile devices constrains the
effectiveness of deploying and executing local LLMs, which necessitates
offloading complex tasks to global LLMs running on edge servers during
long-horizon interactions. In this article, we propose a split learning system
for LLM agents in 6G networks leveraging the collaboration between mobile
devices and edge servers, where multiple LLMs with different roles are
distributed across mobile devices and edge servers to perform user-agent
interactive tasks collaboratively. In the proposed system, LLM agents are split
into perception, grounding, and alignment modules, facilitating inter-module
communications to meet extended user requirements on 6G network functions,
including integrated sensing and communication, digital twins, and
task-oriented communications. Furthermore, we introduce a novel model caching
algorithm for LLMs within the proposed system to improve model utilization in
context, thus reducing network costs of the collaborative mobile and edge LLM
agents.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07768" title="Abstract">arXiv:2401.07768</a> [<a href="/pdf/2401.07768" title="Download PDF">pdf</a>, <a href="/ps/2401.07768" title="Download PostScript">ps</a>, <a href="/format/2401.07768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Hilbert-Poincar&#xe9; series of affine semi-regular polynomial  sequences and related Gr&#xf6;bner bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kudo%2C+M">Momonari Kudo</a>, 
<a href="/search/cs?searchtype=author&query=Yokoyama%2C+K">Kazuhiro Yokoyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, Comments are welcome!
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Mathematical Foundations for Post-Quantum Cryptography (T. Takagi
  et al. eds), Mathematics for Industry, Springer, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Commutative Algebra (math.AC); Algebraic Geometry (math.AG)

</div>
<p class="mathjax">Gr\"{o}bner bases are nowadays central tools for solving various problems in
commutative algebra and algebraic geometry. A typical use of Gr\"{o}bner bases
is the multivariate polynomial system solving, which enables us to construct
algebraic attacks against post-quantum cryptographic protocols. Therefore, the
determination of the complexity of computing Gr\"{o}bner bases is very
important both in theory and in practice: One of the most important cases is
the case where input polynomials compose an (overdetermined) affine
semi-regular sequence. The first part of this paper aims to present a survey on
the Gr\"{o}bner basis computation and its complexity. In the second part, we
shall give an explicit formula on the (truncated) Hilbert-Poincar\'{e} series
associated to the homogenization of an affine semi-regular sequence. Based on
the formula, we also study (reduced) Gr\"{o}bner bases of the ideals generated
by an affine semi-regular sequence and its homogenization. Some of our results
are considered to give mathematically rigorous proofs of the correctness of
methods for computing Gr\"{o}bner bases of the ideal generated by an affine
semi-regular sequence.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07769" title="Abstract">arXiv:2401.07769</a> [<a href="/pdf/2401.07769" title="Download PDF">pdf</a>, <a href="/format/2401.07769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Evolutional Instant Interest Network for CTR Prediction in  Trigger-Induced Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhibo Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Luwei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+W">Wei Ning</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, reviewing of the 17th ACM International Conference on Web Search and Data Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The recommendation has been playing a key role in many industries, e.g.,
e-commerce, streaming media, social media, etc. Recently, a new recommendation
scenario, called Trigger-Induced Recommendation (TIR), where users are able to
explicitly express their instant interests via trigger items, is emerging as an
essential role in many e-commerce platforms, e.g., Alibaba.com and Amazon.
Without explicitly modeling the user's instant interest, traditional
recommendation methods usually obtain sub-optimal results in TIR. Even though
there are a few methods considering the trigger and target items simultaneously
to solve this problem, they still haven't taken into account temporal
information of user behaviors, the dynamic change of user instant interest when
the user scrolls down and the interactions between the trigger and target
items. To tackle these problems, we propose a novel method -- Deep Evolutional
Instant Interest Network (DEI2N), for click-through rate prediction in TIR
scenarios. Specifically, we design a User Instant Interest Modeling Layer to
predict the dynamic change of the intensity of instant interest when the user
scrolls down. Temporal information is utilized in user behavior modeling.
Moreover, an Interaction Layer is introduced to learn better interactions
between the trigger and target items. We evaluate our method on several offline
and real-world industrial datasets. Experimental results show that our proposed
DEI2N outperforms state-of-the-art baselines. In addition, online A/B testing
demonstrates the superiority over the existing baseline in real-world
production environments.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07770" title="Abstract">arXiv:2401.07770</a> [<a href="/pdf/2401.07770" title="Download PDF">pdf</a>, <a href="/format/2401.07770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing the Unseen: Visual Common Sense for Semantic Placement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramrakhya%2C+R">Ram Ramrakhya</a>, 
<a href="/search/cs?searchtype=author&query=Kembhavi%2C+A">Aniruddha Kembhavi</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Kira%2C+Z">Zsolt Kira</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kuo-Hao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Weihs%2C+L">Luca Weihs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer vision tasks typically involve describing what is present in an
image (e.g. classification, detection, segmentation, and captioning). We study
a visual common sense task that requires understanding what is not present.
Specifically, given an image (e.g. of a living room) and name of an object
("cushion"), a vision system is asked to predict semantically-meaningful
regions (masks or bounding boxes) in the image where that object could be
placed or is likely be placed by humans (e.g. on the sofa). We call this task:
Semantic Placement (SP) and believe that such common-sense visual understanding
is critical for assitive robots (tidying a house), and AR devices
(automatically rendering an object in the user's space). Studying the invisible
is hard. Datasets for image description are typically constructed by curating
relevant images and asking humans to annotate the contents of the image;
neither of those two steps are straightforward for objects not present in the
image. We overcome this challenge by operating in the opposite direction: we
start with an image of an object in context from web, and then remove that
object from the image via inpainting. This automated pipeline converts
unstructured web data into a dataset comprising pairs of images with/without
the object. Using this, we collect a novel dataset, with ${\sim}1.3$M images
across $9$ object categories, and train a SP prediction model called CLIP-UNet.
CLIP-UNet outperforms existing VLMs and baselines that combine semantic priors
with object detectors on real-world and simulated images. In our user studies,
we find that the SP masks predicted by CLIP-UNet are favored $43.7\%$ and
$31.3\%$ times when comparing against the $4$ SP baselines on real and
simulated images. In addition, we demonstrate leveraging SP mask predictions
from CLIP-UNet enables downstream applications like building tidying robots in
indoor environments.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07777" title="Abstract">arXiv:2401.07777</a> [<a href="/pdf/2401.07777" title="Download PDF">pdf</a>, <a href="/format/2401.07777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Transfer Learning for Acceptability Judgements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Buonaiuto%2C+G">Giuseppe Buonaiuto</a>, 
<a href="/search/cs?searchtype=author&query=Guarasci%2C+R">Raffaele Guarasci</a>, 
<a href="/search/cs?searchtype=author&query=Minutolo%2C+A">Aniello Minutolo</a>, 
<a href="/search/cs?searchtype=author&query=De+Pietro%2C+G">Giuseppe De Pietro</a>, 
<a href="/search/cs?searchtype=author&query=Esposito%2C+M">Massimo Esposito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Physics (physics.comp-ph); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Hybrid quantum-classical classifiers promise to positively impact critical
aspects of natural language processing tasks, particularly
classification-related ones. Among the possibilities currently investigated,
quantum transfer learning, i.e., using a quantum circuit for fine-tuning
pre-trained classical models for a specific task, is attracting significant
attention as a potential platform for proving quantum advantage.
<br />This work shows potential advantages, both in terms of performance and
expressiveness, of quantum transfer learning algorithms trained on embedding
vectors extracted from a large language model to perform classification on a
classical Linguistics task: acceptability judgments. Acceptability judgment is
the ability to determine whether a sentence is considered natural and
well-formed by a native speaker. The approach has been tested on sentences
extracted from ItaCoLa, a corpus that collects Italian sentences labeled with
their acceptability judgment. The evaluation phase shows results for the
quantum transfer learning pipeline comparable to state-of-the-art classical
transfer learning algorithms, proving current quantum computers' capabilities
to tackle NLP tasks for ready-to-use applications. Furthermore, a qualitative
linguistic analysis, aided by explainable AI methods, reveals the capabilities
of quantum transfer learning algorithms to correctly classify complex and more
structured sentences, compared to their classical counterpart. This finding
sets the ground for a quantifiable quantum advantage in NLP in the near future.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07780" title="Abstract">arXiv:2401.07780</a> [<a href="/pdf/2401.07780" title="Download PDF">pdf</a>, <a href="/format/2401.07780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Soft Constrained MPC Value Functions: Efficient MPC Design and  Implementation providing Stability and Safety Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chatzikiriakos%2C+N">Nicolas Chatzikiriakos</a>, 
<a href="/search/eess?searchtype=author&query=Wabersich%2C+K+P">Kim P. Wabersich</a>, 
<a href="/search/eess?searchtype=author&query=Berkel%2C+F">Felix Berkel</a>, 
<a href="/search/eess?searchtype=author&query=Pauli%2C+P">Patricia Pauli</a>, 
<a href="/search/eess?searchtype=author&query=Iannelli%2C+A">Andrea Iannelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Model Predictive Control (MPC) can be applied to safety-critical control
problems, providing closed-loop safety and performance guarantees.
Implementation of MPC controllers requires solving an optimization problem at
every sampling instant, which is challenging to execute on embedded hardware.
To address this challenge, we propose a framework that combines a tightened
soft constrained MPC formulation with supervised learning to approximate the
MPC value function. This combination enables us to obtain a corresponding
optimal control law, which can be implemented efficiently on embedded
platforms. The framework ensures stability and constraint satisfaction for
various nonlinear systems. While the design effort is similar to that of
nominal MPC, the proposed formulation provides input-to-state stability (ISS)
with respect to the approximation error of the value function. Furthermore, we
prove that the value function corresponding to the soft constrained MPC problem
is Lipschitz continuous for Lipschitz continuous systems, even if the optimal
control law may be discontinuous. This serves two purposes: First, it allows to
relate approximation errors to a sufficiently large constraint tightening to
obtain constraint satisfaction guarantees. Second, it paves the way for an
efficient supervised learning procedure to obtain a continuous value function
approximation. We demonstrate the effectiveness of the method using a nonlinear
numerical example.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07781" title="Abstract">arXiv:2401.07781</a> [<a href="/pdf/2401.07781" title="Download PDF">pdf</a>, <a href="/format/2401.07781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards A Better Metric for Text-to-Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J+Z">Jay Zhangjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Guian Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D+J">David Junhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jia-Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yuchao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wynne Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://showlab.github.io/T2VScore/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative models have demonstrated remarkable capability in synthesizing
high-quality text, images, and videos. For video generation, contemporary
text-to-video models exhibit impressive capabilities, crafting visually
stunning videos. Nonetheless, evaluating such videos poses significant
challenges. Current research predominantly employs automated metrics such as
FVD, IS, and CLIP Score. However, these metrics provide an incomplete analysis,
particularly in the temporal assessment of video content, thus rendering them
unreliable indicators of true video quality. Furthermore, while user studies
have the potential to reflect human perception accurately, they are hampered by
their time-intensive and laborious nature, with outcomes that are often tainted
by subjective bias. In this paper, we investigate the limitations inherent in
existing metrics and introduce a novel evaluation pipeline, the Text-to-Video
Score (T2VScore). This metric integrates two pivotal criteria: (1) Text-Video
Alignment, which scrutinizes the fidelity of the video in representing the
given text description, and (2) Video Quality, which evaluates the video's
overall production caliber with a mixture of experts. Moreover, to evaluate the
proposed metrics and facilitate future improvements on them, we present the
TVGE dataset, collecting human judgements of 2,543 text-to-video generated
videos on the two criteria. Experiments on the TVGE dataset demonstrate the
superiority of the proposed T2VScore on offering a better metric for
text-to-video generation.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07783" title="Abstract">arXiv:2401.07783</a> [<a href="/pdf/2401.07783" title="Download PDF">pdf</a>, <a href="/format/2401.07783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity and Embodiment Integrity for Modern Robots: A Conceptual  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giaretta%2C+A">Alberto Giaretta</a>, 
<a href="/search/cs?searchtype=author&query=Loutfi%2C+A">Amy Loutfi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Modern robots are stepping away from monolithic entities built using ad-hoc
sensors and actuators, due to new technologies and communication paradigms,
such as the Internet of Things (IoT) and the Robotic Operating System (ROS).
Using such paradigms, robots can be built by acquiring heterogeneous standard
devices and putting them in communication with each other. This approach brings
high degrees of modularity, but it also yields uncertainty of providing
cybersecurity assurances, and guarantees on the integrity of the embodiment. In
this paper, we first illustrate how cyberattacks on different devices can have
radically different consequences on the robot's ability to complete its tasks
and preserve its embodiment. We also claim that modern robots should have
self-awareness for what it concerns such aspects, and formulate the different
characteristics that robots should integrate for doing so. Then, we show that
achieving these propositions requires that robots possess at least three
properties that conceptually link devices and tasks. Last, we reflect on how
these three properties could be achieved in a larger conceptual framework.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07784" title="Abstract">arXiv:2401.07784</a> [<a href="/pdf/2401.07784" title="Download PDF">pdf</a>, <a href="/format/2401.07784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Certifiable Mutual Localization and Trajectory Planning for  Bearing-Based Robot Swarm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingjian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xiangyong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fei Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Bearing measurements,as the most common modality in nature, have recently
gained traction in multi-robot systems to enhance mutual localization and swarm
collaboration. Despite their advantages, challenges such as sensory noise,
obstacle occlusion, and uncoordinated swarm motion persist in real-world
scenarios, potentially leading to erroneous state estimation and undermining
the system's flexibility, practicality, and robustness.In response to these
challenges, in this paper we address theoretical and practical problem related
to both mutual localization and swarm planning.Firstly, we propose a
certifiable mutual localization algorithm.It features a concise problem
formulation coupled with lossless convex relaxation, enabling independence from
initial values and globally optimal relative pose recovery.Then, to explore how
detection noise and swarm motion influence estimation optimality, we conduct a
comprehensive analysis on the interplay between robots' mutual spatial
relationship and mutual localization. We develop a differentiable metric
correlated with swarm trajectories to explicitly evaluate the noise resistance
of optimal estimation.By establishing a finite and pre-computable threshold for
this metric and accordingly generating swarm trajectories, the estimation
optimality can be strictly guaranteed under arbitrary noise. Based on these
findings, an optimization-based swarm planner is proposed to generate safe and
smooth trajectories, with consideration of both inter-robot visibility and
estimation optimality.Through numerical simulations, we evaluate the optimality
and certifiablity of our estimator, and underscore the significance of our
planner in enhancing estimation performance.The results exhibit considerable
potential of our methods to pave the way for advanced closed-loop intelligence
in swarm systems.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07787" title="Abstract">arXiv:2401.07787</a> [<a href="/pdf/2401.07787" title="Download PDF">pdf</a>, <a href="/ps/2401.07787" title="Download PostScript">ps</a>, <a href="/format/2401.07787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving OCR Quality in 19th Century Historical Documents Using a  Combined Machine Learning Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fleischhacker%2C+D">David Fleischhacker</a>, 
<a href="/search/cs?searchtype=author&query=Goederle%2C+W">Wolfgang Goederle</a>, 
<a href="/search/cs?searchtype=author&query=Kern%2C+R">Roman Kern</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 23 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper addresses a major challenge to historical research on the 19th
century. Large quantities of sources have become digitally available for the
first time, while extraction techniques are lagging behind. Therefore, we
researched machine learning (ML) models to recognise and extract complex data
structures in a high-value historical primary source, the Schematismus. It
records every single person in the Habsburg civil service above a certain
hierarchical level between 1702 and 1918 and documents the genesis of the
central administration over two centuries. Its complex and intricate structure
as well as its enormous size have so far made any more comprehensive analysis
of the administrative and social structure of the later Habsburg Empire on the
basis of this source impossible. We pursued two central objectives: Primarily,
the improvement of the OCR quality, for which we considered an improved
structure recognition to be essential; in the further course, it turned out
that this also made the extraction of the data structure possible. We chose
Faster R-CNN as base for the ML architecture for structure recognition. In
order to obtain the required amount of training data quickly and economically,
we synthesised Hof- und Staatsschematismus-style data, which we used to train
our model. The model was then fine-tuned with a smaller set of manually
annotated historical source data. We then used Tesseract-OCR, which was further
optimised for the style of our documents, to complete the combined structure
extraction and OCR process. Results show a significant decrease in the two
standard parameters of OCR-performance, WER and CER (where lower values are
better). Combined structure detection and fine-tuned OCR improved CER and WER
values by remarkable 71.98 percent (CER) respectively 52.49 percent (WER).
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07788" title="Abstract">arXiv:2401.07788</a> [<a href="/pdf/2401.07788" title="Download PDF">pdf</a>, <a href="/format/2401.07788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activations and Gradients Compression for Model-Parallel Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudakov%2C+M">Mikhail Rudakov</a>, 
<a href="/search/cs?searchtype=author&query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="/search/cs?searchtype=author&query=Kholodov%2C+Y">Yaroslav Kholodov</a>, 
<a href="/search/cs?searchtype=author&query=Gasnikov%2C+A">Alexander Gasnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures, 5 tables, Doklady Rossijskoj akademii nauk: <a href="https://journals.rcsi.science/2686-9543/article/view/247111">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Large neural networks require enormous computational clusters of machines.
Model-parallel training, when the model architecture is partitioned
sequentially between workers, is a popular approach for training modern models.
Information compression can be applied to decrease workers communication time,
as it is often a bottleneck in such systems. This work explores how
simultaneous compression of activations and gradients in model-parallel
distributed training setup affects convergence. We analyze compression methods
such as quantization and TopK compression, and also experiment with error
compensation techniques. Moreover, we employ TopK with AQ-SGD per-batch error
feedback approach. We conduct experiments on image classification and language
model fine-tuning tasks. Our findings demonstrate that gradients require milder
compression rates than activations. We observe that $K=10\%$ is the lowest TopK
compression level, which does not harm model convergence severely. Experiments
also show that models trained with TopK perform well only when compression is
also applied during inference. We find that error feedback techniques do not
improve model-parallel training compared to plain compression, but allow model
inference without compression with almost no quality drop. Finally, when
applied with the AQ-SGD approach, TopK stronger than with $ K=30\%$ worsens
model performance significantly.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07793" title="Abstract">arXiv:2401.07793</a> [<a href="/pdf/2401.07793" title="Download PDF">pdf</a>, <a href="/format/2401.07793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flexibly Scaling Large Language Models Contexts Through Extensible  Tokenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+N">Ninglu Shao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+S">Shitao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peitian Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are in need of sufficient contexts to handle
many critical applications, such as retrieval augmented generation and few-shot
learning. However, due to the constrained window size, the LLMs can only access
to the information within a limited context. Although the size of context
window can be extended by fine-tuning, it will result in a substantial cost in
both training and inference stage. In this paper, we present Extensible
Tokenization as an alternative method which realizes the flexible scaling of
LLMs' context. Extensible Tokenization stands as a midware in between of the
tokenized context and the LLM, which transforms the raw token embeddings into
the extensible embeddings. Such embeddings provide a more compact
representation for the long context, on top of which the LLM is able to
perceive more information with the same context window. Extensible Tokenization
is also featured by its flexibility: the scaling factor can be flexibly
determined within a feasible scope, leading to the extension of an arbitrary
context length at the inference time. Besides, Extensible Tokenization is
introduced as a drop-in component, which can be seamlessly plugged into not
only the LLM itself and but also its fine-tuned derivatives, bringing in the
extended contextual information while fully preserving the LLM's existing
capabilities. We perform comprehensive experiments on long-context language
modeling and understanding tasks, which verify Extensible Tokenization as an
effective, efficient, flexible, and compatible method to extend LLM's context.
Our model and source code will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07796" title="Abstract">arXiv:2401.07796</a> [<a href="/pdf/2401.07796" title="Download PDF">pdf</a>, <a href="/format/2401.07796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing Echocardiography Images and Medical Records for Continuous  Patient Stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Painchaud%2C+N">Nathan Painchaud</a>, 
<a href="/search/cs?searchtype=author&query=Courand%2C+P">Pierre-Yves Courand</a>, 
<a href="/search/cs?searchtype=author&query=Jodoin%2C+P">Pierre-Marc Jodoin</a>, 
<a href="/search/cs?searchtype=author&query=Duchateau%2C+N">Nicolas Duchateau</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+O">Olivier Bernard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, submitted to IEEE TMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning now enables automatic and robust extraction of cardiac function
descriptors from echocardiographic sequences, such as ejection fraction or
strain. These descriptors provide fine-grained information that physicians
consider, in conjunction with more global variables from the clinical record,
to assess patients' condition. Drawing on novel transformer models applied to
tabular data (e.g., variables from electronic health records), we propose a
method that considers all descriptors extracted from medical records and
echocardiograms to learn the representation of a difficult-to-characterize
cardiovascular pathology, namely hypertension. Our method first projects each
variable into its own representation space using modality-specific approaches.
These standardized representations of multimodal data are then fed to a
transformer encoder, which learns to merge them into a comprehensive
representation of the patient through a pretext task of predicting a clinical
rating. This pretext task is formulated as an ordinal classification to enforce
a pathological continuum in the representation space. We observe the major
trends along this continuum for a cohort of 239 hypertensive patients to
describe, with unprecedented gradation, the effect of hypertension on a number
of cardiac function descriptors. Our analysis shows that i) pretrained weights
from a foundation model allow to reach good performance (83% accuracy) even
with limited data (less than 200 training samples), ii) trends across the
population are reproducible between trainings, and iii) for descriptors whose
interactions with hypertension are well documented, patterns are consistent
with prior physiological knowledge.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07801" title="Abstract">arXiv:2401.07801</a> [<a href="/pdf/2401.07801" title="Download PDF">pdf</a>, <a href="/format/2401.07801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pedestrian Detection in Low-Light Conditions: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghari%2C+B">Bahareh Ghari</a>, 
<a href="/search/cs?searchtype=author&query=Tourani%2C+A">Ali Tourani</a>, 
<a href="/search/cs?searchtype=author&query=Shahbahrami%2C+A">Asadollah Shahbahrami</a>, 
<a href="/search/cs?searchtype=author&query=Gaydadjiev%2C+G">Georgi Gaydadjiev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 3 tables, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pedestrian detection remains a critical problem in various domains, such as
computer vision, surveillance, and autonomous driving. In particular, accurate
and instant detection of pedestrians in low-light conditions and reduced
visibility is of utmost importance for autonomous vehicles to prevent accidents
and save lives. This paper aims to comprehensively survey various pedestrian
detection approaches, baselines, and datasets that specifically target
low-light conditions. The survey discusses the challenges faced in detecting
pedestrians at night and explores state-of-the-art methodologies proposed in
recent years to address this issue. These methodologies encompass a diverse
range, including deep learning-based, feature-based, and hybrid approaches,
which have shown promising results in enhancing pedestrian detection
performance under challenging lighting conditions. Furthermore, the paper
highlights current research directions in the field and identifies potential
solutions that merit further investigation by researchers. By thoroughly
examining pedestrian detection techniques in low-light conditions, this survey
seeks to contribute to the advancement of safer and more reliable autonomous
driving systems and other applications related to pedestrian safety.
Accordingly, most of the current approaches in the field use deep
learning-based image fusion methodologies (i.e., early, halfway, and late
fusion) for accurate and reliable pedestrian detection. Moreover, the majority
of the works in the field (approximately 48%) have been evaluated on the KAIST
dataset, while the real-world video feeds recorded by authors have been used in
less than six percent of the works.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07803" title="Abstract">arXiv:2401.07803</a> [<a href="/pdf/2401.07803" title="Download PDF">pdf</a>, <a href="/format/2401.07803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncovering the Full Potential of Visual Grounding Methods in VQA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+D">Daniel Reich</a>, 
<a href="/search/cs?searchtype=author&query=Schultz%2C+T">Tanja Schultz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual Grounding (VG) methods in Visual Question Answering (VQA) attempt to
improve VQA performance by strengthening a model's reliance on
question-relevant visual information. The presence of such relevant information
in the visual input is typically assumed in training and testing. This
assumption, however, is inherently flawed when dealing with imperfect image
representations common in large-scale VQA, where the information carried by
visual features frequently deviates from expected ground-truth contents. As a
result, training and testing of VG-methods is performed with largely inaccurate
data, which obstructs proper assessment of their potential benefits.
<br />In this work, we demonstrate that current evaluation schemes for VG-methods
are problematic due to the flawed assumption of availability of relevant visual
information. Our experiments show that the potential benefits of these methods
are severely underestimated as a result.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07805" title="Abstract">arXiv:2401.07805</a> [<a href="/pdf/2401.07805" title="Download PDF">pdf</a>, <a href="/format/2401.07805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A consistent diffuse-interface model for two-phase flow problems with  rapid evaporation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schreter-Fleischhacker%2C+M">Magdalena Schreter-Fleischhacker</a>, 
<a href="/search/cs?searchtype=author&query=Munch%2C+P">Peter Munch</a>, 
<a href="/search/cs?searchtype=author&query=Much%2C+N">Nils Much</a>, 
<a href="/search/cs?searchtype=author&query=Kronbichler%2C+M">Martin Kronbichler</a>, 
<a href="/search/cs?searchtype=author&query=Wall%2C+W+A">Wolfgang A. Wall</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+C">Christoph Meier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">We present accurate and mathematically consistent formulations of a
diffuse-interface model for two-phase flow problems involving rapid
evaporation. The model addresses challenges including discontinuities in the
density field by several orders of magnitude, leading to high velocity and
pressure jumps across the liquid-vapor interface, along with dynamically
changing interface topologies. To this end, we integrate an incompressible
Navier--Stokes solver combined with a conservative level-set formulation and a
regularized, i.e., diffuse, representation of discontinuities into a
matrix-free adaptive finite element framework. The achievements are three-fold:
First, this work proposes mathematically consistent definitions for the
level-set transport velocity in the diffuse interface region by extrapolating
the velocity from the liquid or gas phase, which exhibit superior prediction
accuracy for the evaporated mass and the resulting interface dynamics compared
to a local velocity evaluation, especially for highly curved interfaces.
Second, we show that accurate prediction of the evaporation-induced pressure
jump requires a consistent, namely a reciprocal, density interpolation across
the interface, which satisfies local mass conservation. Third, the combination
of diffuse interface models for evaporation with standard Stokes-type
constitutive relations for viscous flows leads to significant pressure
artifacts in the diffuse interface region. To mitigate these, we propose a
modification for such constitutive model types. Through selected analytical and
numerical examples, the aforementioned properties are validated. The presented
model promises new insights in simulation-based prediction of melt-vapor
interactions in thermal multiphase flows such as in laser-based powder bed
fusion of metals.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07806" title="Abstract">arXiv:2401.07806</a> [<a href="/pdf/2401.07806" title="Download PDF">pdf</a>, <a href="/ps/2401.07806" title="Download PostScript">ps</a>, <a href="/format/2401.07806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal experimental design via gradient flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jin%2C+R">Ruhui Jin</a>, 
<a href="/search/math?searchtype=author&query=Guerra%2C+M">Martin Guerra</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+Q">Qin Li</a>, 
<a href="/search/math?searchtype=author&query=Wright%2C+S">Stephen Wright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Optimal experimental design (OED) has far-reaching impacts in many scientific
domains. We study OED over a continuous-valued design space, a setting that
occurs often in practice. Optimization of a distributional function over an
infinite-dimensional probability measure space is conceptually distinct from
the discrete OED tasks that are conventionally tackled. We propose techniques
based on optimal transport and Wasserstein gradient flow. A practical
computational approach is derived from the Monte Carlo simulation, which
transforms the infinite-dimensional optimization problem to a
finite-dimensional problem over Euclidean space, to which gradient descent can
be applied. We discuss first-order criticality and study the convexity
properties of the OED objective. We apply our algorithm to the tomography
inverse problem, where the solution reveals optimal sensor placements for
imaging.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07807" title="Abstract">arXiv:2401.07807</a> [<a href="/pdf/2401.07807" title="Download PDF">pdf</a>, <a href="/format/2401.07807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Higher Order Unfitted Space-Time Finite Element Method for Coupled  Surface-Bulk problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Heimann%2C+F">Fabian Heimann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a higher order space-time unfitted finite element method for
convection-diffusion problems on coupled (surface and bulk) domains. In that
way, we combine a method suggested by Heimann, Lehrenfeld, Preu{\ss} (SIAM J.
Sci. Comput. 45(2), 2023, B139 - B165) for the bulk case with a method
suggested by Sass, Reusken (Comput. Math. Appl. 146(15), 2023, 253-270) for the
surface case. The geometry is allowed to change with time, and the higher order
discrete approximation of this geometry is ensured by a time-dependent
isoparametric mapping. The space-time discretisation approach allows for
straightforward handling of arbitrary high orders. In that way, we also
generalise results of Hansbo, Larson, Zahedi (Comput. Methods Appl. Mech.
Engrg. 307, 2016, 96-116) to higher orders. The convergence of the proposed
higher order discretisations is confirmed numerically.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07810" title="Abstract">arXiv:2401.07810</a> [<a href="/pdf/2401.07810" title="Download PDF">pdf</a>, <a href="/format/2401.07810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consolidating Strategies for Countering Hate Speech Using Persuasive  Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Sougata Saha</a>, 
<a href="/search/cs?searchtype=author&query=Srihari%2C+R">Rohini Srihari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Hateful comments are prevalent on social media platforms. Although tools for
automatically detecting, flagging, and blocking such false, offensive, and
harmful content online have lately matured, such reactive and brute force
methods alone provide short-term and superficial remedies while the
perpetrators persist. With the public availability of large language models
which can generate articulate synthetic and engaging content at scale, there
are concerns about the rapid growth of dissemination of such malicious content
on the web. There is now a need to focus on deeper, long-term solutions that
involve engaging with the human perpetrator behind the source of the content to
change their viewpoint or at least bring down the rhetoric using persuasive
means. To do that, we propose defining and experimenting with controllable
strategies for generating counter-arguments to hateful comments in online
conversations. We experiment with controlling response generation using
features based on (i) argument structure and reasoning-based Walton argument
schemes, (ii) counter-argument speech acts, and (iii) human
characteristics-based qualities such as Big-5 personality traits and human
values. Using automatic and human evaluations, we determine the best
combination of features that generate fluent, argumentative, and logically
sound arguments for countering hate. We further share the developed
computational models for automatically annotating text with such features, and
a silver-standard annotated version of an existing hate speech dialog corpora.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07812" title="Abstract">arXiv:2401.07812</a> [<a href="/pdf/2401.07812" title="Download PDF">pdf</a>, <a href="/format/2401.07812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wikidata as a seed for Web Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kunpeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Diefenbach%2C+D">Dennis Diefenbach</a>, 
<a href="/search/cs?searchtype=author&query=Gourru%2C+A">Antoine Gourru</a>, 
<a href="/search/cs?searchtype=author&query=Gravier%2C+C">Christophe Gravier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Wikidata has grown to a knowledge graph with an impressive size. To date, it
contains more than 17 billion triples collecting information about people,
places, films, stars, publications, proteins, and many more. On the other side,
most of the information on the Web is not published in highly structured data
repositories like Wikidata, but rather as unstructured and semi-structured
content, more concretely in HTML pages containing text and tables. Finding,
monitoring, and organizing this data in a knowledge graph is requiring
considerable work from human editors. The volume and complexity of the data
make this task difficult and time-consuming. In this work, we present a
framework that is able to identify and extract new facts that are published
under multiple Web domains so that they can be proposed for validation by
Wikidata editors. The framework is relying on question-answering technologies.
We take inspiration from ideas that are used to extract facts from textual
collections and adapt them to extract facts from Web pages. For achieving this,
we demonstrate that language models can be adapted to extract facts not only
from textual collections but also from Web pages. By exploiting the information
already contained in Wikidata the proposed framework can be trained without the
need for any additional learning signals and can extract new facts for a wide
range of properties and domains. Following this path, Wikidata can be used as a
seed to extract facts on the Web. Our experiments show that we can achieve a
mean performance of 84.07 at F1-score. Moreover, our estimations show that we
can potentially extract millions of facts that can be proposed for human
validation. The goal is to help editors in their daily tasks and contribute to
the completion of the Wikidata knowledge graph.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07815" title="Abstract">arXiv:2401.07815</a> [<a href="/pdf/2401.07815" title="Download PDF">pdf</a>, <a href="/format/2401.07815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anti-Context-Free languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Card%C3%B3%2C+C">Carles Card&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 17 figures, to appear at Journal of Automata, languages and combinatorics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Context-free languages can be characterized in several ways. This article
studies projective linearisations of languages of simple dependency trees,
i.e., dependency trees in which a node can govern at most one node with a given
syntactic function. We prove that the projective linearisations of local
languages of simple dependency trees coincide with the context-free languages.
<br />Simple dependency trees suggest alternative dual notions of locality and
projectivity, which permits defining a dual language for each context-free
language. We call this new class of languages anti-context-free. These
languages are related to some linguistic constructions exhibiting the so-called
cross-serial dependencies that were historically important for the development
of computational linguistics. We propose that this duality could be a relevant
linguistic phenomenon.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07817" title="Abstract">arXiv:2401.07817</a> [<a href="/pdf/2401.07817" title="Download PDF">pdf</a>, <a href="/format/2401.07817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Question Translation Training for Better Multilingual Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fei Yuan</a>, 
<a href="/search/cs?searchtype=author&query=She%2C+S">Shuaijie She</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Birch%2C+A">Alexandra Birch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models show compelling performance on reasoning tasks but they
tend to perform much worse in languages other than English. This is
unsurprising given that their training data largely consists of English text
and instructions. A typical solution is to translate instruction data into all
languages of interest, and then train on the resulting multilingual data, which
is called translate-training. This approach not only incurs high cost, but also
results in poorly translated data due to the non-standard formatting of
chain-of-thought and mathematical reasoning instructions. In this paper, we
explore the benefits of question alignment, where we train the model to
translate reasoning questions into English by finetuning on X-English question
data. In this way we perform targetted, in-domain language alignment which
makes best use of English instruction data to unlock the LLMs' multilingual
reasoning abilities. Experimental results on LLaMA2-13B show that question
alignment leads to consistent improvements over the translate-training
approach: an average improvement of 11.3\% and 16.1\% accuracy across ten
languages on the MGSM and MSVAMP maths reasoning benchmarks (The project will
be available at: https://github.com/NJUNLP/QAlign).
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07819" title="Abstract">arXiv:2401.07819</a> [<a href="/pdf/2401.07819" title="Download PDF">pdf</a>, <a href="/format/2401.07819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enforcing contraction via data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+Z">Zhongjie Hu</a>, 
<a href="/search/eess?searchtype=author&query=De+Persis%2C+C">Claudio De Persis</a>, 
<a href="/search/eess?searchtype=author&query=Tesi%2C+P">Pietro Tesi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We present data-based conditions for enforcing contractivity via feedback
control and obtain desired asymptotic properties of the closed-loop system. We
focus on unknown nonlinear control systems whose vector fields are expressible
via a dictionary of functions and derive data-dependent semidefinite programs
whose solution returns the controller that guarantees contractivity. When data
are perturbed by disturbances that are linear combination of sinusoids of known
frequencies (but unknown amplitude and phase) and constants, we remarkably
obtain conditions for contractivity that do not depend on the magnitude of the
disturbances, with imaginable positive consequences for the synthesis of the
controller. Finally, we show how to design from data an integral controller for
nonlinear systems that achieves constant reference tracking and constant
disturbance rejection.
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07823" title="Abstract">arXiv:2401.07823</a> [<a href="/pdf/2401.07823" title="Download PDF">pdf</a>, <a href="/format/2401.07823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A three-grid high-order immersed finite element method for the analysis  of CAD models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Febrianto%2C+E">Eky Febrianto</a>, 
<a href="/search/math?searchtype=author&query=Sistek%2C+J">Jakub Sistek</a>, 
<a href="/search/math?searchtype=author&query=Kus%2C+P">Pavel Kus</a>, 
<a href="/search/math?searchtype=author&query=Kecman%2C+M">Matija Kecman</a>, 
<a href="/search/math?searchtype=author&query=Cirak%2C+F">Fehmi Cirak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">The automated finite element analysis of complex CAD models using
boundary-fitted meshes is rife with difficulties. Immersed finite element
methods are intrinsically more robust but usually less accurate. In this work,
we introduce an efficient, robust, high-order immersed finite element method
for complex CAD models. Our approach relies on three adaptive structured grids:
a geometry grid for representing the implicit geometry, a finite element grid
for discretising physical fields and a quadrature grid for evaluating the
finite element integrals. The geometry grid is a sparse VDB (Volumetric Dynamic
B+ tree) grid that is highly refined close to physical domain boundaries. The
finite element grid consists of a forest of octree grids distributed over
several processors, and the quadrature grid in each finite element cell is an
octree grid constructed in a bottom-up fashion. We discretise physical fields
on the finite element grid using high-order Lagrange basis functions. The
resolution of the quadrature grid ensures that finite element integrals are
evaluated with sufficient accuracy and that any sub-grid geometric features,
like small holes or corners, are resolved up to a desired resolution. The
conceptual simplicity and modularity of our approach make it possible to reuse
open-source libraries, i.e. openVDB and p4est for implementing the geometry and
finite element grids, respectively, and BDDCML for iteratively solving the
discrete systems of equations in parallel using domain decomposition. We
demonstrate the efficiency and robustness of the proposed approach by solving
the Poisson equation on domains given by complex CAD models and discretised
with tens of millions of degrees of freedom.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07825" title="Abstract">arXiv:2401.07825</a> [<a href="/pdf/2401.07825" title="Download PDF">pdf</a>, <a href="/ps/2401.07825" title="Download PostScript">ps</a>, <a href="/format/2401.07825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phenotyping calcification in vascular tissues using artificial  intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezanpour%2C+M">Mehdi Ramezanpour</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+A+M">Anne M. Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Tobe%2C+Y">Yasutaka Tobe</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiaowei Jia</a>, 
<a href="/search/cs?searchtype=author&query=Cebral%2C+J+R">Juan R. Cebral</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Data Analysis, Statistics and Probability (physics.data-an); Quantitative Methods (q-bio.QM); Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">Vascular calcification is implicated as an important factor in major adverse
cardiovascular events (MACE), including heart attack and stroke. A controversy
remains over how to integrate the diverse forms of vascular calcification into
clinical risk assessment tools. Even the commonly used calcium score for
coronary arteries, which assumes risk scales positively with total
calcification, has important inconsistencies. Fundamental studies are needed to
determine how risk is influenced by the diverse calcification phenotypes.
However, studies of these kinds are hindered by the lack of high-throughput,
objective, and non-destructive tools for classifying calcification in imaging
data sets. Here, we introduce a new classification system for phenotyping
calcification along with a semi-automated, non-destructive pipeline that can
distinguish these phenotypes in even atherosclerotic tissues. The pipeline
includes a deep-learning-based framework for segmenting lipid pools in noisy
micro-CT images and an unsupervised clustering framework for categorizing
calcification based on size, clustering, and topology. This approach is
illustrated for five vascular specimens, providing phenotyping for thousands of
calcification particles across as many as 3200 images in less than seven hours.
Average Dice Similarity Coefficients of 0.96 and 0.87 could be achieved for
tissue and lipid pool, respectively, with training and validation needed on
only 13 images despite the high heterogeneity in these tissues. By introducing
an efficient and comprehensive approach to phenotyping calcification, this work
enables large-scale studies to identify a more reliable indicator of the risk
of cardiovascular events, a leading cause of global mortality and morbidity.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07835" title="Abstract">arXiv:2401.07835</a> [<a href="/pdf/2401.07835" title="Download PDF">pdf</a>, <a href="/format/2401.07835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $q$-ary Sequential Locally Recoverable Codes from the Product  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baghban%2C+A">Akram Baghban</a>, 
<a href="/search/cs?searchtype=author&query=Newman%2C+M">Marc Newman</a>, 
<a href="/search/cs?searchtype=author&query=Horlemann%2C+A">Anna-Lena Horlemann</a>, 
<a href="/search/cs?searchtype=author&query=Ghiyasvand%2C+M">Mehdi Ghiyasvand</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work focuses on sequential locally recoverable codes (SLRCs), a special
family of locally repairable codes, capable of correcting multiple code symbol
erasures, which are commonly used for distributed storage systems. First, we
construct an extended $q$-ary family of non-binary SLRCs using code products
with a novel maximum number of recoverable erasures $t$ and a minimal repair
alternativity $A$. Second, we study how MDS and BCH codes can be used to
construct $q$-ary SLRCs. Finally, we compare our codes to other LRCs.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07836" title="Abstract">arXiv:2401.07836</a> [<a href="/pdf/2401.07836" title="Download PDF">pdf</a>, <a href="/ps/2401.07836" title="Download PostScript">ps</a>, <a href="/format/2401.07836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two Types of AI Existential Risk: Decisive and Accumulative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kasirzadeh%2C+A">Atoosa Kasirzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The conventional discourse on existential risks (x-risks) from AI typically
focuses on abrupt, dire events caused by advanced AI systems, particularly
those that might achieve or surpass human-level intelligence. These events have
severe consequences that either lead to human extinction or irreversibly
cripple human civilization to a point beyond recovery. This discourse, however,
often neglects the serious possibility of AI x-risks manifesting incrementally
through a series of smaller yet interconnected disruptions, gradually crossing
critical thresholds over time. This paper contrasts the conventional "decisive
AI x-risk hypothesis" with an "accumulative AI x-risk hypothesis." While the
former envisions an overt AI takeover pathway, characterized by scenarios like
uncontrollable superintelligence, the latter suggests a different causal
pathway to existential catastrophes. This involves a gradual accumulation of
critical AI-induced threats such as severe vulnerabilities and systemic erosion
of econopolitical structures. The accumulative hypothesis suggests a boiling
frog scenario where incremental AI risks slowly converge, undermining
resilience until a triggering event results in irreversible collapse. Through
systems analysis, this paper examines the distinct assumptions differentiating
these two hypotheses. It is then argued that the accumulative view reconciles
seemingly incompatible perspectives on AI risks. The implications of
differentiating between these causal pathways -- the decisive and the
accumulative -- for the governance of AI risks as well as long-term AI safety
are discussed.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07841" title="Abstract">arXiv:2401.07841</a> [<a href="/pdf/2401.07841" title="Download PDF">pdf</a>, <a href="/format/2401.07841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Simulation at Machine Level: A Systematic Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Deubert%2C+D">Darius Deubert</a>, 
<a href="/search/eess?searchtype=author&query=Klingel%2C+L">Lars Klingel</a>, 
<a href="/search/eess?searchtype=author&query=Selig%2C+A">Andreas Selig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures, submitted to Springer - The International Journal on Advanced Manufacturing Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The importance of simulation at machine level in industrial environments is
steadily increasing especially in the design and commissioning phase. Using
models during the operation phase together with the real machine or plant is
referred to as online simulation. Online simulation is used for system
monitoring, predictive analyses, decision support or online optimization and
therefore has various advantages and a wide field of applications. This paper
has the aim to characterize online simulation at machine level in industrial
automation focusing on key technologies and common applications. Therefore, a
set of 65 relevant publications, which are focusing on this subject, is found
by database search, expert consultation, and snowballing. As key technological
aspects, the used model types, interfaces and platforms, and the aspects of
initialization and synchronization are further investigated. The results are
interpreted and limitations, knowledge gaps and future prospects are discussed.
The potential of online simulation at machine level especially arises due to
the increasing availability of component and machine models from the design and
commissioning phase, which can be reused for online simulation. Remaining
challenges are identified concerning implementation, simulation platforms,
model maintenance and especially in the field of synchronization.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07842" title="Abstract">arXiv:2401.07842</a> [<a href="/pdf/2401.07842" title="Download PDF">pdf</a>, <a href="/ps/2401.07842" title="Download PostScript">ps</a>, <a href="/format/2401.07842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Performance and Management Gaps with Satellite Internet:  Challenges, Approaches, and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+P">Peng Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the IAB Workshop on Barriers to Internet Access of Services (BIAS) 2024. Available at: <a href="https://www.ietf.org/slides/slides-biasws-closing-the-performance-and-management-gaps-with-satellite-internet-challenges-approaches-and-future-directions-01.pdf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Recent advancements in low-Earth orbit (LEO) satellites represented by large
constellations and advanced payloads provide great promises for enabling beyond
5G and 6G telecommunications and high-quality and ubiquitous Internet
connectivity to everyone anywhere on Earth. LEO satellite networks are
envisioned to bridge the urban-rural connectivity gap for the digital divide.
However, the digital divide can hardly be closed by only providing connectivity
to rural and remote areas. Various unprecedented challenges brought by the
emerging satellite Internet still need to be resolved, such as inconsistent
end-to-end performance guarantees and a lack of efficient management and
operations in these areas, which are referred to as "performance gap" and
"management gap", respectively. This position paper will briefly discuss these
gaps, approaches to addressing the gaps, and some research directions based on
our recent works.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07844" title="Abstract">arXiv:2401.07844</a> [<a href="/pdf/2401.07844" title="Download PDF">pdf</a>, <a href="/ps/2401.07844" title="Download PostScript">ps</a>, <a href="/format/2401.07844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The ODE Method for Stochastic Approximation and Reinforcement Learning  with Markovian Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuze Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shangtong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stochastic approximation is a class of algorithms that update a vector
iteratively, incrementally, and stochastically, including, e.g., stochastic
gradient descent and temporal difference learning. One fundamental challenge in
analyzing a stochastic approximation algorithm is to establish its stability,
i.e., to show that the stochastic vector iterates are bounded almost surely. In
this paper, we extend the celebrated Borkar-Meyn theorem for stability from the
Martingale difference noise setting to the Markovian noise setting, which
greatly improves its applicability in reinforcement learning, especially in
those off-policy reinforcement learning algorithms with linear function
approximation and eligibility traces. Central to our analysis is the
diminishing asymptotic rate of change of a few functions, which is implied by
both a form of strong law of large numbers and a commonly used V4 Lyapunov
drift condition and trivially holds if the Markov chain is finite and
irreducible.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07847" title="Abstract">arXiv:2401.07847</a> [<a href="/pdf/2401.07847" title="Download PDF">pdf</a>, <a href="/format/2401.07847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Milestones in Bengali Sentiment Analysis leveraging Transformer-models:  Fundamentals, Challenges and Future Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Saptarshi Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+S">Shreya Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Tamiti%2C+T+I">Tarikul Islam Tamiti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment Analysis (SA) refers to the task of associating a view polarity
(usually, positive, negative, or neutral; or even fine-grained such as slightly
angry, sad, etc.) to a given text, essentially breaking it down to a supervised
(since we have the view labels apriori) classification task. Although heavily
studied in resource-rich languages such as English thus pushing the SOTA by
leaps and bounds, owing to the arrival of the Transformer architecture, the
same cannot be said for resource-poor languages such as Bengali (BN). For a
language spoken by roughly 300 million people, the technology enabling them to
run trials on their favored tongue is severely lacking. In this paper, we
analyze the SOTA for SA in Bengali, particularly, Transformer-based models. We
discuss available datasets, their drawbacks, the nuances associated with
Bengali i.e. what makes this a challenging language to apply SA on, and finally
provide insights for future direction to mitigate the limitations in the field.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07851" title="Abstract">arXiv:2401.07851</a> [<a href="/pdf/2401.07851" title="Download PDF">pdf</a>, <a href="/format/2401.07851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Efficiency in Large Language Model Inference: A Comprehensive  Survey of Speculative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Heming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qingxiu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Peiyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">To mitigate the high inference latency stemming from autoregressive decoding
in Large Language Models (LLMs), Speculative Decoding has emerged as a novel
decoding paradigm for LLM inference. In each decoding step, this method first
efficiently drafts several future tokens and then verifies them in parallel.
Unlike autoregressive decoding, Speculative Decoding facilitates the
simultaneous decoding of multiple tokens per step, thereby accelerating
inference. This paper presents a comprehensive overview and analysis of this
promising decoding paradigm. We begin by providing a formal definition and
formulation of Speculative Decoding. Then, we organize in-depth discussions on
its key facets, including current leading techniques, the challenges faced, and
potential future directions in this field. We aim for this work to serve as a
catalyst for further research on Speculative Decoding, ultimately contributing
to more efficient LLM inference.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07853" title="Abstract">arXiv:2401.07853</a> [<a href="/pdf/2401.07853" title="Download PDF">pdf</a>, <a href="/format/2401.07853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeCAF: VLM-empowered Collaborative Active Finetuning with Training  Objective Awareness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zefan Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Huanrui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gudovskiy%2C+D">Denis Gudovskiy</a>, 
<a href="/search/cs?searchtype=author&query=Okuno%2C+T">Tomoyuki Okuno</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+Y">Yohei Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+B">Baobao Chang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuan Du</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+L">Li Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Finetuning a pretrained vision model (PVM) is a common technique for learning
downstream vision tasks. The conventional finetuning process with the randomly
sampled data points results in diminished training efficiency. To address this
drawback, we propose a novel approach, VLM-empowered Collaborative Active
Finetuning (VeCAF). VeCAF optimizes a parametric data selection model by
incorporating the training objective of the model being tuned. Effectively,
this guides the PVM towards the performance goal with improved data and
computational efficiency. As vision-language models (VLMs) have achieved
significant advancements by establishing a robust connection between image and
language domains, we exploit the inherent semantic richness of the text
embedding space and utilize text embedding of pretrained VLM models to augment
PVM image features for better data selection and finetuning. Furthermore, the
flexibility of text-domain augmentation gives VeCAF a unique ability to handle
out-of-distribution scenarios without external augmented data. Extensive
experiments show the leading performance and high efficiency of VeCAF that is
superior to baselines in both in-distribution and out-of-distribution image
classification tasks. On ImageNet, VeCAF needs up to 3.3x less training batches
to reach the target performance compared to full finetuning and achieves 2.8%
accuracy improvement over SOTA methods with the same number of batches.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07854" title="Abstract">arXiv:2401.07854</a> [<a href="/pdf/2401.07854" title="Download PDF">pdf</a>, <a href="/format/2401.07854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $M^{2}$Fusion: Bayesian-based Multimodal Multi-level Fusion on  Colorectal Cancer Microsatellite Instability Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Quan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiawen Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lisha Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zaiyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Colorectal cancer (CRC) micro-satellite instability (MSI) prediction on
histopathology images is a challenging weakly supervised learning task that
involves multi-instance learning on gigapixel images. To date, radiology images
have proven to have CRC MSI information and efficient patient imaging
techniques. Different data modalities integration offers the opportunity to
increase the accuracy and robustness of MSI prediction. Despite the progress in
representation learning from the whole slide images (WSI) and exploring the
potential of making use of radiology data, CRC MSI prediction remains a
challenge to fuse the information from multiple data modalities (e.g.,
pathology WSI and radiology CT image). In this paper, we propose $M^{2}$Fusion:
a Bayesian-based multimodal multi-level fusion pipeline for CRC MSI. The
proposed fusion model $M^{2}$Fusion is capable of discovering more novel
patterns within and across modalities that are beneficial for predicting MSI
than using a single modality alone, as well as other fusion methods. The
contribution of the paper is three-fold: (1) $M^{2}$Fusion is the first
pipeline of multi-level fusion on pathology WSI and 3D radiology CT image for
MSI prediction; (2) CT images are the first time integrated into multimodal
fusion for CRC MSI prediction; (3) feature-level fusion strategy is evaluated
on both Transformer-based and CNN-based method. Our approach is validated on
cross-validation of 352 cases and outperforms either feature-level (0.8177 vs.
0.7908) or decision-level fusion strategy (0.8177 vs. 0.7289) on AUC score.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07855" title="Abstract">arXiv:2401.07855</a> [<a href="/pdf/2401.07855" title="Download PDF">pdf</a>, <a href="/format/2401.07855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Tip Mount for Soft Growing Eversion Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suulker%2C+C">Cem Suulker</a>, 
<a href="/search/cs?searchtype=author&query=Skach%2C+S">Sophie Skach</a>, 
<a href="/search/cs?searchtype=author&query=Kaleel%2C+D">Danyaal Kaleel</a>, 
<a href="/search/cs?searchtype=author&query=Abrar%2C+T">Taqi Abrar</a>, 
<a href="/search/cs?searchtype=author&query=Murtaza%2C+Z">Zain Murtaza</a>, 
<a href="/search/cs?searchtype=author&query=Suulker%2C+D">Dilara Suulker</a>, 
<a href="/search/cs?searchtype=author&query=Althoefer%2C+K">Kaspar Althoefer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA) MW02: Soft Growing Robots Workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Here we present a flexible tip mount for eversion (vine) robots. This soft
cap allows attaching a payload to an eversion robot while allowing moving
through narrow openings, as well as the eversion of protruding objects, and
expanded surfaces.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07861" title="Abstract">arXiv:2401.07861</a> [<a href="/pdf/2401.07861" title="Download PDF">pdf</a>, <a href="/format/2401.07861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PATSMA: Parameter Auto-tuning for Shared Memory Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+J+B">Joao B. Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+F+H+S">Felipe H. S. da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Xavier-de-Souza%2C+S">Samuel Xavier-de-Souza</a>, 
<a href="/search/cs?searchtype=author&query=Assis%2C+I+A+S">Italo A. S. Assis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Programs with high levels of complexity often face challenges in adjusting
execution parameters, particularly when these parameters vary based on the
execution context. These dynamic parameters significantly impact the program's
performance, such as loop granularity, which can vary depending on factors like
the execution environment, program input, or the choice of compiler. Given the
expensive nature of testing each case individually, one viable solution is to
automate parameter adjustments using optimization methods. This article
introduces PATSMA, a parameter auto-tuning tool that leverages Coupled
Simulated Annealing (CSA) and Nelder-Mead (NM) optimization methods to
fine-tune existing parameters in an application. We demonstrate how auto-tuning
can contribute to the real-time optimization of parallel algorithms designed
for shared memory systems. PATSMA is a C++ library readily available under the
MIT license.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07862" title="Abstract">arXiv:2401.07862</a> [<a href="/pdf/2401.07862" title="Download PDF">pdf</a>, <a href="/format/2401.07862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Neural-Operator Backstepping Control of a Benchmark Hyperbolic  PDE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lamarque%2C+M">Maxence Lamarque</a>, 
<a href="/search/eess?searchtype=author&query=Bhan%2C+L">Luke Bhan</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yuanyuan Shi</a>, 
<a href="/search/eess?searchtype=author&query=Krstic%2C+M">Miroslav Krstic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16.5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Dynamical Systems (math.DS); Optimization and Control (math.OC)

</div>
<p class="mathjax">To stabilize PDEs, feedback controllers require gain kernel functions, which
are themselves governed by PDEs. Furthermore, these gain-kernel PDEs depend on
the PDE plants' functional coefficients. The functional coefficients in PDE
plants are often unknown. This requires an adaptive approach to PDE control,
i.e., an estimation of the plant coefficients conducted concurrently with
control, where a separate PDE for the gain kernel must be solved at each
timestep upon the update in the plant coefficient function estimate. Solving a
PDE at each timestep is computationally expensive and a barrier to the
implementation of real-time adaptive control of PDEs. Recently, results in
neural operator (NO) approximations of functional mappings have been introduced
into PDE control, for replacing the computation of the gain kernel with a
neural network that is trained, once offline, and reused in real-time for rapid
solution of the PDEs. In this paper, we present the first result on applying
NOs in adaptive PDE control, presented for a benchmark 1-D hyperbolic PDE with
recirculation. We establish global stabilization via Lyapunov analysis, in the
plant and parameter error states, and also present an alternative approach, via
passive identifiers, which avoids the strong assumptions on kernel
differentiability. We then present numerical simulations demonstrating
stability and observe speedups up to three orders of magnitude, highlighting
the real-time efficacy of neural operators in adaptive control. Our code
(Github) is made publicly available for future researchers.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07867" title="Abstract">arXiv:2401.07867</a> [<a href="/pdf/2401.07867" title="Download PDF">pdf</a>, <a href="/format/2401.07867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Authorship Obfuscation in Multilingual Machine-Generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macko%2C+D">Dominik Macko</a>, 
<a href="/search/cs?searchtype=author&query=Moro%2C+R">Robert Moro</a>, 
<a href="/search/cs?searchtype=author&query=Uchendu%2C+A">Adaku Uchendu</a>, 
<a href="/search/cs?searchtype=author&query=Srba%2C+I">Ivan Srba</a>, 
<a href="/search/cs?searchtype=author&query=Lucas%2C+J+S">Jason Samuel Lucas</a>, 
<a href="/search/cs?searchtype=author&query=Yamashita%2C+M">Michiharu Yamashita</a>, 
<a href="/search/cs?searchtype=author&query=Tripto%2C+N+I">Nafis Irtiza Tripto</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Dongwon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Simko%2C+J">Jakub Simko</a>, 
<a href="/search/cs?searchtype=author&query=Bielikova%2C+M">Maria Bielikova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">High-quality text generation capability of latest Large Language Models
(LLMs) causes concerns about their misuse (e.g., in massive generation/spread
of disinformation). Machine-generated text (MGT) detection is important to cope
with such threats. However, it is susceptible to authorship obfuscation (AO)
methods, such as paraphrasing, which can cause MGTs to evade detection. So far,
this was evaluated only in monolingual settings. Thus, the susceptibility of
recently proposed multilingual detectors is still unknown. We fill this gap by
comprehensively benchmarking the performance of 10 well-known AO methods,
attacking 37 MGT detection methods against MGTs in 11 languages (i.e., 10
$\times$ 37 $\times$ 11 = 4,070 combinations). We also evaluate the effect of
data augmentation on adversarial robustness using obfuscated texts. The results
indicate that all tested AO methods can cause detection evasion in all tested
languages, where homoglyph attacks are especially successful.
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07868" title="Abstract">arXiv:2401.07868</a> [<a href="/pdf/2401.07868" title="Download PDF">pdf</a>, <a href="/format/2401.07868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consolidating Trees of Robotic Plans Generated Using Large Language  Models to Improve Reliability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakib%2C+M+S">Md Sadman Sakib</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yu Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">The inherent probabilistic nature of Large Language Models (LLMs) introduces
an element of unpredictability, raising concerns about potential discrepancies
in their output. This paper introduces an innovative approach aims to generate
correct and optimal robotic task plans for diverse real-world demands and
scenarios. LLMs have been used to generate task plans, but they are unreliable
and may contain wrong, questionable, or high-cost steps. The proposed approach
uses LLM to generate a number of task plans as trees and amalgamates them into
a graph by removing questionable paths. Then an optimal task tree can be
retrieved to circumvent questionable and high-cost nodes, thereby improving
planning accuracy and execution efficiency. The approach is further improved by
incorporating a large knowledge network. Leveraging GPT-4 further, the
high-level task plan is converted into a low-level Planning Domain Definition
Language (PDDL) plan executable by a robot. Evaluation results highlight the
superior accuracy and efficiency of our approach compared to previous
methodologies in the field of task planning.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07870" title="Abstract">arXiv:2401.07870</a> [<a href="/pdf/2401.07870" title="Download PDF">pdf</a>, <a href="/format/2401.07870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JumpCoder: Go Beyond Autoregressive Coder via Online Modification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mouxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+H">Hao Tian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaoxue Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianling Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">While existing code large language models (code LLMs) exhibit impressive
capabilities in code generation, their autoregressive sequential generation
inherently lacks reversibility. This limitation hinders them from timely
correcting previous missing statements during coding as humans do, often
leading to error propagation and suboptimal performance. We introduce
JumpCoder, a novel modelagnostic framework that enables online modification and
non-sequential generation to augment the code LLMs. The key idea behind
JumpCoder is to insert new code into the currently generated code when
necessary during generation, which is achieved through an auxiliary infilling
model that works in tandem with the code LLM. Since identifying the best infill
position beforehand is intractable, we adopt an infill-first, judge-later
strategy, which experiments with filling at the $k$ most critical positions
following the generation of each line, and uses an Abstract Syntax Tree (AST)
parser alongside the Generation Model Scoring to effectively judge the validity
of each potential infill. Extensive experiments using six state-of-the-art code
LLMs across multiple benchmarks consistently indicate significant improvements
over all baselines. Notably, JumpCoder assists code LLMs in achieving up to a
3.6% increase in Pass@1 for Python, 6.3% for Java, and 3.7% for C++ in the
multilingual HumanEval benchmarks. Our code is public at
https://github.com/Keytoyze/JumpCoder.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07871" title="Abstract">arXiv:2401.07871</a> [<a href="/pdf/2401.07871" title="Download PDF">pdf</a>, <a href="/format/2401.07871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Predictive Maintenance: A Survey of Current Methods,  Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cummins%2C+L">Logan Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Sommers%2C+A">Alex Sommers</a>, 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+S+B">Somayeh Bakhtiari Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sudip Mittal</a>, 
<a href="/search/cs?searchtype=author&query=Jabour%2C+J">Joseph Jabour</a>, 
<a href="/search/cs?searchtype=author&query=Seale%2C+M">Maria Seale</a>, 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+S">Shahram Rahimi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Predictive maintenance is a well studied collection of techniques that aims
to prolong the life of a mechanical system by using artificial intelligence and
machine learning to predict the optimal time to perform maintenance. The
methods allow maintainers of systems and hardware to reduce financial and time
costs of upkeep. As these methods are adopted for more serious and potentially
life-threatening applications, the human operators need trust the predictive
system. This attracts the field of Explainable AI (XAI) to introduce
explainability and interpretability into the predictive system. XAI brings
methods to the field of predictive maintenance that can amplify trust in the
users while maintaining well-performing systems. This survey on explainable
predictive maintenance (XPM) discusses and presents the current methods of XAI
as applied to predictive maintenance while following the Preferred Reporting
Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines. We
categorize the different XPM methods into groups that follow the XAI
literature. Additionally, we include current challenges and a discussion on
future research directions in XPM.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07872" title="Abstract">arXiv:2401.07872</a> [<a href="/pdf/2401.07872" title="Download PDF">pdf</a>, <a href="/format/2401.07872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The What, Why, and How of Context Length Extension Techniques in Large  Language Models -- A Detailed Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pawar%2C+S">Saurav Pawar</a>, 
<a href="/search/cs?searchtype=author&query=Tonmoy%2C+S+M+T+I">S.M Towhidul Islam Tonmoy</a>, 
<a href="/search/cs?searchtype=author&query=Zaman%2C+S+M+M">S M Mehedi Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+V">Vinija Jain</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amitava Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The advent of Large Language Models (LLMs) represents a notable breakthrough
in Natural Language Processing (NLP), contributing to substantial progress in
both text comprehension and generation. However, amidst these advancements, it
is noteworthy that LLMs often face a limitation in terms of context length
extrapolation. Understanding and extending the context length for LLMs is
crucial in enhancing their performance across various NLP applications. In this
survey paper, we delve into the multifaceted aspects of exploring why it is
essential, and the potential transformations that superior techniques could
bring to NLP applications. We study the inherent challenges associated with
extending context length and present an organized overview of the existing
strategies employed by researchers. Additionally, we discuss the intricacies of
evaluating context extension techniques and highlight the open challenges that
researchers face in this domain. Furthermore, we explore whether there is a
consensus within the research community regarding evaluation standards and
identify areas where further agreement is needed. This comprehensive survey
aims to serve as a valuable resource for researchers, guiding them through the
nuances of context length extension techniques and fostering discussions on
future advancements in this evolving field.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07874" title="Abstract">arXiv:2401.07874</a> [<a href="/pdf/2401.07874" title="Download PDF">pdf</a>, <a href="/format/2401.07874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do stable neural networks exist for classification problems? -- A new  view on stability in AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z+N+D">Z. N. D. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+A+C">A. C. Hansen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Functional Analysis (math.FA)

</div>
<p class="mathjax">In deep learning (DL) the instability phenomenon is widespread and well
documented, most commonly using the classical measure of stability, the
Lipschitz constant. While a small Lipchitz constant is traditionally viewed as
guarantying stability, it does not capture the instability phenomenon in DL for
classification well. The reason is that a classification function -- which is
the target function to be approximated -- is necessarily discontinuous, thus
having an 'infinite' Lipchitz constant. As a result, the classical approach
will deem every classification function unstable, yet basic classification
functions a la 'is there a cat in the image?' will typically be locally very
'flat' -- and thus locally stable -- except at the decision boundary. The lack
of an appropriate measure of stability hinders a rigorous theory for stability
in DL, and consequently, there are no proper approximation theoretic results
that can guarantee the existence of stable networks for classification
functions. In this paper we introduce a novel stability measure
$\mathscr{S}(f)$, for any classification function $f$, appropriate to study the
stability of discontinuous functions and their approximations. We further prove
two approximation theorems: First, for any $\epsilon &gt; 0$ and any
classification function $f$ on a \emph{compact set}, there is a neural network
(NN) $\psi$, such that $\psi - f \neq 0$ only on a set of measure $&lt; \epsilon$,
moreover, $\mathscr{S}(\psi) \geq \mathscr{S}(f) - \epsilon$ (as accurate and
stable as $f$ up to $\epsilon$). Second, for any classification function $f$
and $\epsilon &gt; 0$, there exists a NN $\psi$ such that $\psi = f$ on the set of
points that are at least $\epsilon$ away from the decision boundary.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07875" title="Abstract">arXiv:2401.07875</a> [<a href="/pdf/2401.07875" title="Download PDF">pdf</a>, <a href="/format/2401.07875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safely and Autonomously Cutting Meat with a Collaborative Robot Arm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wright%2C+R">Ryan Wright</a>, 
<a href="/search/cs?searchtype=author&query=Parekh%2C+S">Sagar Parekh</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R">Robin White</a>, 
<a href="/search/cs?searchtype=author&query=Losey%2C+D+P">Dylan P. Losey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Labor shortages in the United States are impacting a number of industries
including the meat processing sector. Collaborative technologies that work
alongside humans while increasing production abilities may support the industry
by enhancing automation and improving job quality. However, existing automation
technologies used in the meat industry have limited collaboration potential,
low flexibility, and high cost. The objective of this work was to explore the
use of a robot arm to collaboratively work alongside a human and complete tasks
performed in a meat processing facility. Toward this objective, we demonstrated
proof-of-concept approaches to ensure human safety while exploring the capacity
of the robot arm to perform example meat processing tasks. In support of human
safety, we developed a knife instrumentation system to detect when the cutting
implement comes into contact with meat within the collaborative space. To
demonstrate the capability of the system to flexibly conduct a variety of basic
meat processing tasks, we developed vision and control protocols to execute
slicing, trimming, and cubing of pork loins. We also collected a subjective
evaluation of the actions from experts within the U.S. meat processing
industry. On average the experts rated the robot's performance as adequate.
Moreover, the experts generally preferred the cuts performed in collaboration
with a human worker to cuts completed autonomously, highlighting the benefits
of robotic technologies that assist human workers rather than replace them.
Video demonstrations of our proposed framework can be found here:
https://youtu.be/56mdHjjYMVc
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07877" title="Abstract">arXiv:2401.07877</a> [<a href="/pdf/2401.07877" title="Download PDF">pdf</a>, <a href="/ps/2401.07877" title="Download PostScript">ps</a>, <a href="/format/2401.07877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMBRE: Entity-aware Masking for Biomedical Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Verspoor%2C+K">Karin Verspoor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Information extraction techniques, including named entity recognition (NER)
and relation extraction (RE), are crucial in many domains to support making
sense of vast amounts of unstructured text data by identifying and connecting
relevant information. Such techniques can assist researchers in extracting
valuable insights. In this paper, we introduce the Entity-aware Masking for
Biomedical Relation Extraction (EMBRE) method for biomedical relation
extraction, as applied in the context of the BioRED challenge Task 1, in which
human-annotated entities are provided as input. Specifically, we integrate
entity knowledge into a deep neural network by pretraining the backbone model
with an entity masking objective. We randomly mask named entities for each
instance and let the model identify the masked entity along with its type. In
this way, the model is capable of learning more specific knowledge and more
robust representations. Then, we utilize the pre-trained model as our backbone
to encode language representations and feed these representations into two
multilayer perceptron (MLPs) to predict the logits for relation and novelty,
respectively. The experimental results demonstrate that our proposed method can
improve the performances of entity pair, relation and novelty extraction over
our baseline.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07879" title="Abstract">arXiv:2401.07879</a> [<a href="/pdf/2401.07879" title="Download PDF">pdf</a>, <a href="/format/2401.07879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoupled Spatial and Temporal Processing for Resource Efficient  Multichannel Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Ashutosh Pandey</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Buye Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We present a novel model designed for resource-efficient multichannel speech
enhancement in the time domain, with a focus on low latency, lightweight, and
low computational requirements. The proposed model incorporates explicit
spatial and temporal processing within deep neural network (DNN) layers.
Inspired by frequency-dependent multichannel filtering, our spatial filtering
process applies multiple trainable filters to each hidden unit across the
spatial dimension, resulting in a multichannel output. The temporal processing
is applied over a single-channel output stream from the spatial processing
using a Long Short-Term Memory (LSTM) network. The output from the temporal
processing stage is then further integrated into the spatial dimension through
elementwise multiplication. This explicit separation of spatial and temporal
processing results in a resource-efficient network design. Empirical findings
from our experiments show that our proposed model significantly outperforms
robust baseline models while demanding far fewer parameters and computations,
while achieving an ultra-low algorithmic latency of just 2 milliseconds.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07882" title="Abstract">arXiv:2401.07882</a> [<a href="/pdf/2401.07882" title="Download PDF">pdf</a>, <a href="/format/2401.07882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Importance of Neural Wiener Filter for Resource Efficient  Multichannel Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+T">Tsun-An Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Donley%2C+J">Jacob Donley</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D">Daniel Wong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Buye Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pandey%2C+A">Ashutosh Pandey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">We introduce a time-domain framework for efficient multichannel speech
enhancement, emphasizing low latency and computational efficiency. This
framework incorporates two compact deep neural networks (DNNs) surrounding a
multichannel neural Wiener filter (NWF). The first DNN enhances the speech
signal to estimate NWF coefficients, while the second DNN refines the output
from the NWF. The NWF, while conceptually similar to the traditional
frequency-domain Wiener filter, undergoes a training process optimized for
low-latency speech enhancement, involving fine-tuning of both analysis and
synthesis transforms. Our research results illustrate that the NWF output,
having minimal nonlinear distortions, attains performance levels akin to those
of the first DNN, deviating from conventional Wiener filter paradigms. Training
all components jointly outperforms sequential training, despite its simplicity.
Consequently, this framework achieves superior performance with fewer
parameters and reduced computational demands, making it a compelling solution
for resource-efficient multichannel speech enhancement.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07883" title="Abstract">arXiv:2401.07883</a> [<a href="/pdf/2401.07883" title="Download PDF">pdf</a>, <a href="/format/2401.07883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Chronicles of RAG: The Retriever, the Chunk and the Generator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finardi%2C+P">Paulo Finardi</a>, 
<a href="/search/cs?searchtype=author&query=Avila%2C+L">Leonardo Avila</a>, 
<a href="/search/cs?searchtype=author&query=Castaldoni%2C+R">Rodrigo Castaldoni</a>, 
<a href="/search/cs?searchtype=author&query=Gengo%2C+P">Pedro Gengo</a>, 
<a href="/search/cs?searchtype=author&query=Larcher%2C+C">Celio Larcher</a>, 
<a href="/search/cs?searchtype=author&query=Piau%2C+M">Marcos Piau</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+P">Pablo Costa</a>, 
<a href="/search/cs?searchtype=author&query=Carid%C3%A1%2C+V">Vinicius Carid&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 15 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Retrieval Augmented Generation (RAG) has become one of the most popular
paradigms for enabling LLMs to access external data, and also as a mechanism
for grounding to mitigate against hallucinations. When implementing RAG you can
face several challenges like effective integration of retrieval models,
efficient representation learning, data diversity, computational efficiency
optimization, evaluation, and quality of text generation. Given all these
challenges, every day a new technique to improve RAG appears, making it
unfeasible to experiment with all combinations for your problem. In this
context, this paper presents good practices to implement, optimize, and
evaluate RAG for the Brazilian Portuguese language, focusing on the
establishment of a simple pipeline for inference and experiments. We explored a
diverse set of methods to answer questions about the first Harry Potter book.
To generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview,
gpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the
retriever, our approach achieved an improvement of MRR@10 by 35.4% compared to
the baseline. When optimizing the input size in the application, we observed
that it is possible to further enhance it by 2.4%. Finally, we present the
complete architecture of the RAG with our recommendations. As result, we moved
from a baseline of 57.88% to a maximum relative score of 98.61%.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07886" title="Abstract">arXiv:2401.07886</a> [<a href="/pdf/2401.07886" title="Download PDF">pdf</a>, <a href="/format/2401.07886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Best-Effort LLM Serving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+S">Siddharth Jha</a>, 
<a href="/search/cs?searchtype=author&query=Hooper%2C+C">Coleman Hooper</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Keutzer%2C+K">Kurt Keutzer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Many applications must provide low-latency LLM service to users or risk
unacceptable user experience. However, over-provisioning resources to serve
fluctuating request patterns is often prohibitively expensive. In this work, we
present a best-effort serving system that employs deep reinforcement learning
to adjust service quality based on the task distribution and system load. Our
best-effort system can maintain availability with over 10x higher client
request rates, serves above 96% of peak performance 4.1x more often, and serves
above 98% of peak performance 2.3x more often than static serving on
unpredictable workloads. Our learned router is robust to shifts in both the
arrival and task distribution. Compared to static serving, learned best-effort
serving allows for cost-efficient serving through increased hardware utility.
Additionally, we argue that learned best-effort LLM serving is applicable in
wide variety of settings and provides application developers great flexibility
to meet their specific needs.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07888" title="Abstract">arXiv:2401.07888</a> [<a href="/pdf/2401.07888" title="Download PDF">pdf</a>, <a href="/format/2401.07888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multifidelity domain decomposition-based physics-informed neural  networks for time-dependent problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Heinlein%2C+A">Alexander Heinlein</a>, 
<a href="/search/math?searchtype=author&query=Howard%2C+A+A">Amanda A. Howard</a>, 
<a href="/search/math?searchtype=author&query=Beecroft%2C+D">Damien Beecroft</a>, 
<a href="/search/math?searchtype=author&query=Stinis%2C+P">Panos Stinis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multiscale problems are challenging for neural network-based discretizations
of differential equations, such as physics-informed neural networks (PINNs).
This can be (partly) attributed to the so-called spectral bias of neural
networks. To improve the performance of PINNs for time-dependent problems, a
combination of multifidelity stacking PINNs and domain decomposition-based
finite basis PINNs are employed. In particular, to learn the high-fidelity part
of the multifidelity model, a domain decomposition in time is employed. The
performance is investigated for a pendulum and a two-frequency problem as well
as the Allen-Cahn equation. It can be observed that the domain decomposition
approach clearly improves the PINN and stacking PINN approaches.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07889" title="Abstract">arXiv:2401.07889</a> [<a href="/pdf/2401.07889" title="Download PDF">pdf</a>, <a href="/ps/2401.07889" title="Download PostScript">ps</a>, <a href="/format/2401.07889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Techniques to Identify Hand Gestures amidst Forearm  Muscle Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+R">Ryan Cho</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+S">Sunil Patel</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+K+T">Kyu Taek Cho</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaejin Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">This study investigated the use of forearm EMG data for distinguishing eight
hand gestures, employing the Neural Network and Random Forest algorithms on
data from ten participants. The Neural Network achieved 97 percent accuracy
with 1000-millisecond windows, while the Random Forest achieved 85 percent
accuracy with 200-millisecond windows. Larger window sizes improved gesture
classification due to increased temporal resolution. The Random Forest
exhibited faster processing at 92 milliseconds, compared to the Neural
Network's 124 milliseconds. In conclusion, the study identified a Neural
Network with a 1000-millisecond stream as the most accurate (97 percent), and a
Random Forest with a 200-millisecond stream as the most efficient (85 percent).
Future research should focus on increasing sample size, incorporating more hand
gestures, and exploring different feature extraction methods and modeling
algorithms to enhance system accuracy and efficiency.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07890" title="Abstract">arXiv:2401.07890</a> [<a href="/pdf/2401.07890" title="Download PDF">pdf</a>, <a href="/format/2401.07890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Strategy for Implementing description Temporal Dynamic Algorithms in  Dynamic Knowledge Graphs by SPIN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahbazi%2C+A">Alireza Shahbazi</a>, 
<a href="/search/cs?searchtype=author&query=Mirsanei%2C+S+A">Seyyed Ahmad Mirsanei</a>, 
<a href="/search/cs?searchtype=author&query=Sarraf%2C+M+H+K+M">Malikeh Haj Khan Mirzaye Sarraf</a>, 
<a href="/search/cs?searchtype=author&query=Bidgoli%2C+B+M">Behrouz Minaei Bidgoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Planning and reasoning about actions and processes, in addition to reasoning
about propositions, are important issues in recent logical and computer science
studies. The widespread use of actions in everyday life such as IoT, semantic
web services, etc., and the limitations and issues in the action formalisms are
two factors that lead us to study about how actions are represented.
<br />Since 2007, there was some ideas to integrate Description Logic (DL) and
action formalisms for representing both static and dynamic knowledge. In
meanwhile, time is an important factor in dynamic situations, and actions
change states over time. In this study, on the one hand, we examined related
logical structures such as extensions of description logics (DLs), temporal
formalisms, and action formalisms. On the other hand, we analyzed possible
tools for designing and developing the Knowledge and Action Base (KAB).
<br />For representation and reasoning about actions, we embedded actions into DLs
(such as Dynamic-ALC and its extensions). We propose a terminable algorithm for
action projection, planning, checking the satisfiability, consistency,
realizability, and executability, and also querying from KAB. Actions in this
framework were modeled with SPIN and added to state space. This framework has
also been implemented as a plugin for the Prot\'eg\'e ontology editor.
<br />During the last two decades, various algorithms have been presented, but due
to the high computational complexity, we face many problems in implementing
dynamic ontologies. In addition, an algorithm to detect the inconsistency of
actions' effects was not explicitly stated. In the proposed strategy, the
interactions of actions with other parts of modeled knowledge, and a method to
check consistency between the effects of actions are presented. With this
framework, the ramification problem can be well handled in future works.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07892" title="Abstract">arXiv:2401.07892</a> [<a href="/pdf/2401.07892" title="Download PDF">pdf</a>, <a href="/format/2401.07892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Fuzzy Framework for Emotion Recognition using EEG Signals and  Emotion Representation in Type-2 Fuzzy VAD Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asif%2C+M">Mohammad Asif</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+N">Noman Ali</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Sudhakar Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Dandawate%2C+A">Anushka Dandawate</a>, 
<a href="/search/cs?searchtype=author&query=Tiwary%2C+U+S">Uma Shanker Tiwary</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recently, the representation of emotions in the Valence, Arousal and
Dominance (VAD) space has drawn enough attention. However, the complex nature
of emotions and the subjective biases in self-reported values of VAD make the
emotion model too specific to a particular experiment. This study aims to
develop a generic model representing emotions using a fuzzy VAD space and
improve emotion recognition by utilizing this representation. We partitioned
the crisp VAD space into a fuzzy VAD space using low, medium and high type-2
fuzzy dimensions to represent emotions. A framework that integrates fuzzy VAD
space with EEG data has been developed to recognize emotions. The EEG features
were extracted using spatial and temporal feature vectors from time-frequency
spectrograms, while the subject-reported values of VAD were also considered.
The study was conducted on the DENS dataset, which includes a wide range of
twenty-four emotions, along with EEG data and subjective ratings. The study was
validated using various deep fuzzy framework models based on type-2 fuzzy
representation, cuboid probabilistic lattice representation and unsupervised
fuzzy emotion clusters. These models resulted in emotion recognition accuracy
of 96.09\%, 95.75\% and 95.31\%, respectively, for the classes of 24 emotions.
The study also included an ablation study, one with crisp VAD space and the
other without VAD space. The result with crisp VAD space performed better,
while the deep fuzzy framework outperformed both models. The model was extended
to predict cross-subject cases of emotions, and the results with 78.37\%
accuracy are promising, proving the generality of our model. The generic nature
of the developed model, along with its successful cross-subject predictions,
gives direction for real-world applications in the areas such as affective
computing, human-computer interaction, and mental health monitoring.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07897" title="Abstract">arXiv:2401.07897</a> [<a href="/pdf/2401.07897" title="Download PDF">pdf</a>, <a href="/ps/2401.07897" title="Download PostScript">ps</a>, <a href="/format/2401.07897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pitfalls of Defining Hallucination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Deemter%2C+K">Kees van Deemter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Computational Linguistics on 30 Dec. 2023. (9 Pages.)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite impressive advances in Natural Language Generation (NLG) and Large
Language Models (LLMs), researchers are still unclear about important aspects
of NLG evaluation. To substantiate this claim, I examine current
classifications of hallucination and omission in Data-text NLG, and I propose a
logic-based synthesis of these classfications. I conclude by highlighting some
remaining limitations of all current thinking about hallucination and by
discussing implications for LLMs.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07898" title="Abstract">arXiv:2401.07898</a> [<a href="/pdf/2401.07898" title="Download PDF">pdf</a>, <a href="/format/2401.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Maximal Configurations and Their Variants Using Code Metrics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+T">Tuba Yavuz</a> (1), 
<a href="/search/cs?searchtype=author&query=Khor%2C+C">Chin Khor</a> (2), Ken (Yihang)Bai (1), 
<a href="/search/cs?searchtype=author&query=Lutz%2C+R">Robyn Lutz</a> (2) ((1) University of Florida, (2) Iowa State University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Testing configurable systems continues to be challenging and costly.
Generation of configurations for testing tends to use either techniques based
on semantic sampling (e.g., logical formulas over configuration variables,
often called presence conditions) or structural code metrics (e.g., code
coverage). In this paper we describe our hybrid approaches that combine these
two kinds of techniques to good effect. We present new configuration-generation
algorithms that leverage constraint solving (SAT and MaxSAT) and configuration
fuzzing, and implement our approach in a configuration-generation framework,
CONFIZZ. CONFIZZ both enables the generation of maximal configurations (maximal
sets of presence conditions that can be satisfied together) and performs
code-metric guided configuration fuzzing. Results from evaluation on BusyBox, a
highly configurable benchmark, show that our MaxSAT-based configuration
generation achieves better coverage for several code metrics. Results also show
that, when high coverage of multiple configurations is needed, CONFIZZ's
presence-condition fuzzing outperforms alternatives.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07914" title="Abstract">arXiv:2401.07914</a> [<a href="/pdf/2401.07914" title="Download PDF">pdf</a>, <a href="/format/2401.07914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graphical Symplectic Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Booth%2C+R+I">Robert I. Booth</a>, 
<a href="/search/cs?searchtype=author&query=Carette%2C+T">Titouan Carette</a>, 
<a href="/search/cs?searchtype=author&query=Comfort%2C+C">Cole Comfort</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 63 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT); Symplectic Geometry (math.SG); Quantum Physics (quant-ph)

</div>
<p class="mathjax">We give complete presentations for the dagger-compact props of affine
Lagrangian and coisotropic relations over an arbitrary field. This provides a
unified family of graphical languages for both affinely constrained classical
mechanical systems, as well as odd-prime-dimensional stabiliser quantum
circuits. To this end, we present affine Lagrangian relations by a particular
class of undirected coloured graphs. In order to reason about composite
systems, we introduce a powerful scalable notation where the vertices of these
graphs are themselves coloured by graphs. In the setting of stabiliser quantum
mechanics, this scalable notation gives an extremely concise description of
graph states, which can be composed via ``phased spider fusion.'' Likewise, in
the classical mechanical setting of electrical circuits, we show that impedance
matrices for reciprocal networks are presented in essentially the same way.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07915" title="Abstract">arXiv:2401.07915</a> [<a href="/pdf/2401.07915" title="Download PDF">pdf</a>, <a href="/format/2401.07915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Survey of Learning Approaches for Robotic In-Hand Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+A+I">Abraham Itzhak Weinberg</a>, 
<a href="/search/cs?searchtype=author&query=Shirizly%2C+A">Alon Shirizly</a>, 
<a href="/search/cs?searchtype=author&query=Azulay%2C+O">Osher Azulay</a>, 
<a href="/search/cs?searchtype=author&query=Sintov%2C+A">Avishai Sintov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Human dexterity is an invaluable capability for precise manipulation of
objects in complex tasks. The capability of robots to similarly grasp and
perform in-hand manipulation of objects is critical for their use in the ever
changing human environment, and for their ability to replace manpower. In
recent decades, significant effort has been put in order to enable in-hand
manipulation capabilities to robotic systems. Initial robotic manipulators
followed carefully programmed paths, while later attempts provided a solution
based on analytical modeling of motion and contact. However, these have failed
to provide practical solutions due to inability to cope with complex
environments and uncertainties. Therefore, the effort has shifted to
learning-based approaches where data is collected from the real world or
through a simulation, during repeated attempts to complete various tasks. The
vast majority of learning approaches focused on learning data-based models that
describe the system to some extent or Reinforcement Learning (RL). RL, in
particular, has seen growing interest due to the remarkable ability to generate
solutions to problems with minimal human guidance. In this survey paper, we
track the developments of learning approaches for in-hand manipulations and,
explore the challenges and opportunities. This survey is designed both as an
introduction for novices in the field with a glossary of terms as well as a
guide of novel advances for advanced practitioners.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07923" title="Abstract">arXiv:2401.07923</a> [<a href="/pdf/2401.07923" title="Download PDF">pdf</a>, <a href="/format/2401.07923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Word Boundary Information Isn&#x27;t Useful for Encoder Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gow-Smith%2C+E">Edward Gow-Smith</a>, 
<a href="/search/cs?searchtype=author&query=Phelps%2C+D">Dylan Phelps</a>, 
<a href="/search/cs?searchtype=author&query=Madabushi%2C+H+T">Harish Tayyar Madabushi</a>, 
<a href="/search/cs?searchtype=author&query=Scarton%2C+C">Carolina Scarton</a>, 
<a href="/search/cs?searchtype=author&query=Villavicencio%2C+A">Aline Villavicencio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">All existing transformer-based approaches to NLP using subword tokenisation
algorithms encode whitespace (word boundary information) through the use of
special space symbols (such as \#\# or \_) forming part of tokens. These
symbols have been shown to a) lead to reduced morphological validity of
tokenisations, and b) give substantial vocabulary redundancy. As such, removing
these symbols has been shown to have a beneficial effect on the processing of
morphologically complex words for transformer encoders in the pretrain-finetune
paradigm. In this work, we explore whether word boundary information is at all
useful to such models. In particular, we train transformer encoders across four
different training scales, and investigate several alternative approaches to
including word boundary information, evaluating on a range of tasks across
different domains and problem set-ups: GLUE (for sentence-level
classification), NER (for token-level classification), and two classification
datasets involving complex words (Superbizarre and FLOTA). Overall, through an
extensive experimental setup that includes the pre-training of 29 models, we
find no substantial improvements from our alternative approaches, suggesting
that modifying tokenisers to remove word boundary information isn't leading to
a loss of useful information.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07927" title="Abstract">arXiv:2401.07927</a> [<a href="/pdf/2401.07927" title="Download PDF">pdf</a>, <a href="/format/2401.07927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Explain Themselves?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madsen%2C+A">Andreas Madsen</a>, 
<a href="/search/cs?searchtype=author&query=Chandar%2C+S">Sarath Chandar</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+S">Siva Reddy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Instruction-tuned large language models (LLMs) excel at many tasks, and will
even provide explanations for their behavior. Since these models are directly
accessible to the public, there is a risk that convincing and wrong
explanations can lead to unsupported confidence in LLMs. Therefore,
interpretability-faithfulness of self-explanations is an important
consideration for AI Safety. Assessing the interpretability-faithfulness of
these explanations, termed self-explanations, is challenging as the models are
too complex for humans to annotate what is a correct explanation. To address
this, we propose employing self-consistency checks as a measure of
faithfulness. For example, if an LLM says a set of words is important for
making a prediction, then it should not be able to make the same prediction
without these words. While self-consistency checks are a common approach to
faithfulness, they have not previously been applied to LLM's self-explanations.
We apply self-consistency checks to three types of self-explanations:
counterfactuals, importance measures, and redactions. Our work demonstrate that
faithfulness is both task and model dependent, e.g., for sentiment
classification, counterfactual explanations are more faithful for Llama2,
importance measures for Mistral, and redaction for Falcon 40B. Finally, our
findings are robust to prompt-variations.
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07928" title="Abstract">arXiv:2401.07928</a> [<a href="/pdf/2401.07928" title="Download PDF">pdf</a>, <a href="/ps/2401.07928" title="Download PostScript">ps</a>, <a href="/format/2401.07928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lexicon for Studying Radicalization in Incel Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+E">Emily Klein</a>, 
<a href="/search/cs?searchtype=author&query=Golbeck%2C+J">Jennifer Golbeck</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Incels are an extremist online community of men who believe in an ideology
rooted in misogyny, racism, the glorification of violence, and dehumanization.
In their online forums, they use an extensive, evolving cryptolect - a set of
ingroup terms that have meaning within the group, reflect the ideology,
demonstrate membership in the community, and are difficult for outsiders to
understand. This paper presents a lexicon with terms and definitions for common
incel root words, prefixes, and affixes. The lexicon is text-based for use in
automated analysis and is derived via a Qualitative Content Analysis of the
most frequent incel words, their structure, and their meaning on five of the
most active incel communities from 2016 to 2023. This lexicon will support
future work examining radicalization and deradicalization/disengagement within
the community.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07929" title="Abstract">arXiv:2401.07929</a> [<a href="/pdf/2401.07929" title="Download PDF">pdf</a>, <a href="/ps/2401.07929" title="Download PostScript">ps</a>, <a href="/format/2401.07929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Based Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akanda%2C+M+R+K">Md Rakibul Karim Akanda</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+J">Joshua Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Jackson%2C+T">Treylin Jackson</a>, 
<a href="/search/cs?searchtype=author&query=Gray%2C+M">Milijah Gray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Machine learning based object detection as well as tracking that object have
been performed in this paper. The authors were able to set a range of interest
(ROI) around an object using Open Computer Vision, better known as OpenCV. Next
a tracking algorithm has been used to maintain tracking on an object while
simultaneously operating two servo motors to keep the object centered in the
frame. Detailed procedure and code are included in this paper.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07930" title="Abstract">arXiv:2401.07930</a> [<a href="/pdf/2401.07930" title="Download PDF">pdf</a>, <a href="/format/2401.07930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Inter-dataset Code Duplication and Data Leakage in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+J+A+H">Jos&#xe9; Antonio Hern&#xe1;ndez L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+T">Tushar Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Varr%C3%B3%2C+D">D&#xe1;niel Varr&#xf3;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Motivation. Large language models (LLMs) have exhibited remarkable
proficiency in diverse software engineering (SE) tasks. Handling such tasks
typically involves acquiring foundational coding knowledge on large,
general-purpose datasets during a pre-training phase, and subsequently refining
on smaller, task-specific datasets as part of a fine-tuning phase.
<br />Problem statement. Data leakage is a well-known issue in training of machine
learning models. A manifestation of this issue is the intersection of the
training and testing splits. While intra-dataset code duplication examines this
intersection within a given dataset and has been addressed in prior research,
inter-dataset code duplication, which gauges the overlap between different
datasets, remains largely unexplored. If this phenomenon exists, it could
compromise the integrity of LLM evaluations because of the inclusion of
fine-tuning test samples that were already encountered during pre-training,
resulting in inflated performance metrics.
<br />Contribution. This paper explores the phenomenon of inter-dataset code
duplication and its impact on evaluating LLMs across diverse SE tasks.
<br />Study design. We conduct an empirical study using the CSN dataset, a widely
adopted pre-training dataset, and five fine-tuning datasets used for various SE
tasks. We first identify the intersection between the pre-training and
fine-tuning datasets using a deduplication process. Then, we fine-tune four
models pre-trained on CSN to evaluate their performance on samples encountered
during pre-training and those unseen during that phase.
<br />Results. Our findings reveal a potential threat to the evaluation of various
LLMs across multiple SE tasks, stemming from the inter-dataset code duplication
phenomenon. Moreover, we demonstrate that this threat is accentuated by factors
like the LLM's size and the chosen fine-tuning technique.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07931" title="Abstract">arXiv:2401.07931</a> [<a href="/pdf/2401.07931" title="Download PDF">pdf</a>, <a href="/format/2401.07931" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vertical Federated Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandal%2C+P+K">Paul K. Mandal</a>, 
<a href="/search/cs?searchtype=author&query=Leo%2C+C">Cole Leo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the popularization of AI solutions for image based problems, there has
been a growing concern for both data privacy and acquisition. In a large number
of cases, information is located on separate data silos and it can be difficult
for a developer to consolidate all of it in a fashion that is appropriate for
machine learning model development. Alongside this, a portion of these
localized data regions may not have access to a labelled ground truth. This
indicates that they have the capacity to reach conclusions numerically, but are
not able to assign classifications amid a lack of pertinent information. Such a
determination is often negligible, especially when attempting to develop image
based solutions that often necessitate this capability. With this being the
case, we propose an innovative vertical federated learning (VFL) model
architecture that can operate under this common set of conditions. This is the
first (and currently the only) implementation of a system that can work under
the constraints of a VFL environment and perform image segmentation while
maintaining nominal accuracies. We achieved this by utilizing an FCN that
boasts the ability to operate on federates that lack labelled data and
privately share the respective weights with a central server, that of which
hosts the necessary features for classification. Tests were conducted on the
CamVid dataset in order to determine the impact of heavy feature compression
required for the transfer of information between federates, as well as to reach
nominal conclusions about the overall performance metrics when working under
such constraints.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07935" title="Abstract">arXiv:2401.07935</a> [<a href="/pdf/2401.07935" title="Download PDF">pdf</a>, <a href="/format/2401.07935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6-DoF Grasp Pose Evaluation and Optimization via Transfer Learning from  NeRFs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%B3ti%2C+G">Gergely S&#xf3;ti</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wurll%2C+C">Christian Wurll</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+B">Bj&#xf6;rn Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We address the problem of robotic grasping of known and unknown objects using
implicit behavior cloning. We train a grasp evaluation model from a small
number of demonstrations that outputs higher values for grasp candidates that
are more likely to succeed in grasping. This evaluation model serves as an
objective function, that we maximize to identify successful grasps. Key to our
approach is the utilization of learned implicit representations of visual and
geometric features derived from a pre-trained NeRF. Though trained exclusively
in a simulated environment with simplified objects and 4-DoF top-down grasps,
our evaluation model and optimization procedure demonstrate generalization to
6-DoF grasps and novel objects both in simulation and in real-world settings,
without the need for additional data. Supplementary material is available at:
https://gergely-soti.github.io/grasp
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07936" title="Abstract">arXiv:2401.07936</a> [<a href="/pdf/2401.07936" title="Download PDF">pdf</a>, <a href="/format/2401.07936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Globally Convergent Algorithm for Neural Network Parameter  Optimization Based on Difference-of-Convex Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tschernutter%2C+D">Daniel Tschernutter</a>, 
<a href="/search/cs?searchtype=author&query=Kraus%2C+M">Mathias Kraus</a>, 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
<p class="mathjax">We propose an algorithm for optimizing the parameters of single hidden layer
neural networks. Specifically, we derive a blockwise difference-of-convex (DC)
functions representation of the objective function. Based on the latter, we
propose a block coordinate descent (BCD) approach that we combine with a
tailored difference-of-convex functions algorithm (DCA). We prove global
convergence of the proposed algorithm. Furthermore, we mathematically analyze
the convergence rate of parameters and the convergence rate in value (i.e., the
training loss). We give conditions under which our algorithm converges linearly
or even faster depending on the local shape of the loss function. We confirm
our theoretical derivations numerically and compare our algorithm against
state-of-the-art gradient-based solvers in terms of both training loss and test
loss.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07942" title="Abstract">arXiv:2401.07942</a> [<a href="/pdf/2401.07942" title="Download PDF">pdf</a>, <a href="/format/2401.07942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based Video Saliency Prediction with High Temporal Dimension  Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Morteza Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Palazzo%2C+S">Simone Palazzo</a>, 
<a href="/search/cs?searchtype=author&query=Spampinato%2C+C">Concetto Spampinato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">In recent years, finding an effective and efficient strategy for exploiting
spatial and temporal information has been a hot research topic in video
saliency prediction (VSP). With the emergence of spatio-temporal transformers,
the weakness of the prior strategies, e.g., 3D convolutional networks and
LSTM-based networks, for capturing long-range dependencies has been effectively
compensated. While VSP has drawn benefits from spatio-temporal transformers,
finding the most effective way for aggregating temporal features is still
challenging. To address this concern, we propose a transformer-based video
saliency prediction approach with high temporal dimension decoding network
(THTD-Net). This strategy accounts for the lack of complex hierarchical
interactions between features that are extracted from the transformer-based
spatio-temporal encoder: in particular, it does not require multiple decoders
and aims at gradually reducing temporal features' dimensions in the decoder.
This decoder-based architecture yields comparable performance to multi-branch
and over-complicated models on common benchmarks such as DHF1K, UCF-sports and
Hollywood-2.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07944" title="Abstract">arXiv:2401.07944</a> [<a href="/pdf/2401.07944" title="Download PDF">pdf</a>, <a href="/ps/2401.07944" title="Download PostScript">ps</a>, <a href="/format/2401.07944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+R+K">Rupak Kumar Das</a>, 
<a href="/search/cs?searchtype=author&query=Pedersen%2C+D+T">Dr. Ted Pedersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper uses the BERT model, which is a transformer-based architecture, to
solve task 4A, English Language, Sentiment Analysis in Twitter of SemEval2017.
BERT is a very powerful large language model for classification tasks when the
amount of training data is small. For this experiment, we have used the
BERT{\textsubscript{\tiny BASE}} model, which has 12 hidden layers. This model
provides better accuracy, precision, recall, and f1 score than the Naive Bayes
baseline model. It performs better in binary classification subtasks than the
multi-class classification subtasks. We also considered all kinds of ethical
issues during this experiment, as Twitter data contains personal and sensible
information. The dataset and code used in our experiment can be found in this
GitHub repository.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07947" title="Abstract">arXiv:2401.07947</a> [<a href="/pdf/2401.07947" title="Download PDF">pdf</a>, <a href="/ps/2401.07947" title="Download PostScript">ps</a>, <a href="/format/2401.07947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delivery Line Tracking Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akanda%2C+M+R+K">Md Rakibul Karim Akanda</a>, 
<a href="/search/cs?searchtype=author&query=Lazo%2C+J">Jason Lazo</a>, 
<a href="/search/cs?searchtype=author&query=Carter%2C+Q">Quintwon Carter</a>, 
<a href="/search/cs?searchtype=author&query=Roberts%2C+H">Haineef Roberts</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">The project we embarked on is making an electronic robot that can deliver a
package along a set route through infrared sensors. It uses the infrared
sensors to determine if the path it is following is correct or if it is off
course. This is determined by sending off a photon to reflect off the path and
determines if it is on a light surface by the amount of light emitted back or
if it is a dark surface by the amount of light that is not present. In addition
to following a line, the user can stop and start the robot at any interval
through the infrared remote control. The project is a combination of the
practical parts of machinery with the software part of coding in Arduino which
is a coding subsect of C++. This can lead to endless possibilities that could
help a wide variety of people from all ranges of life, especially with those
that live with disabilities
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07950" title="Abstract">arXiv:2401.07950</a> [<a href="/pdf/2401.07950" title="Download PDF">pdf</a>, <a href="/format/2401.07950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SciGLM: Training Scientific Language Models with Self-Reflective  Instruction Annotation and Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Ziniu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhoubian%2C+S">Sining Zhoubian</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhengxiao Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaiyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yisong Yue</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yuxiao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">\label{sec:abstract} Large Language Models (LLMs) have shown promise in
assisting scientific discovery. However, such applications are currently
limited by LLMs' deficiencies in understanding intricate scientific concepts,
deriving symbolic equations, and solving advanced numerical calculations. To
bridge these gaps, we introduce SciGLM, a suite of scientific language models
able to conduct college-level scientific reasoning. Central to our approach is
a novel self-reflective instruction annotation framework to address the data
scarcity challenge in the science domain. This framework leverages existing
LLMs to generate step-by-step reasoning for unlabelled scientific questions,
followed by a process of self-reflective critic-and-revise. Applying this
framework, we curated SciInstruct, a diverse and high-quality dataset
encompassing mathematics, physics, chemistry, and formal proofs. We fine-tuned
the ChatGLM family of language models with SciInstruct, enhancing their
capabilities in scientific and mathematical reasoning. Remarkably, SciGLM
consistently improves both the base model (ChatGLM3-6B-Base) and larger-scale
models (12B and 32B), without sacrificing the language understanding
capabilities of the base model. This makes SciGLM a suitable foundational model
to facilitate diverse scientific discovery tasks. For the benefit of the wider
research community, we release SciInstruct, SciGLM, alongside a self-reflective
framework and fine-tuning code at \url{https://github.com/THUDM/SciGLM}.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07951" title="Abstract">arXiv:2401.07951</a> [<a href="/pdf/2401.07951" title="Download PDF">pdf</a>, <a href="/format/2401.07951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Similarity using An Ensemble of Context-Sensitive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Z">Zukang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image similarity has been extensively studied in computer vision. In recently
years, machine-learned models have shown their ability to encode more semantics
than traditional multivariate metrics. However, in labelling similarity,
assigning a numerical score to a pair of images is less intuitive than
determining if an image A is closer to a reference image R than another image
B. In this work, we present a novel approach for building an image similarity
model based on labelled data in the form of A:R vs B:R. We address the
challenges of sparse sampling in the image space (R, A, B) and biases in the
models trained with context-based data by using an ensemble model. In
particular, we employed two ML techniques to construct such an ensemble model,
namely dimensionality reduction and MLP regressors. Our testing results show
that the ensemble model constructed performs ~5% better than the best
individual context-sensitive models. They also performed better than the model
trained with mixed imagery data as well as existing similarity models, e.g.,
CLIP and DINO. This work demonstrate that context-based labelling and model
training can be effective when an appropriate ensemble approach is used to
alleviate the limitation due to sparse sampling.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07955" title="Abstract">arXiv:2401.07955</a> [<a href="/pdf/2401.07955" title="Download PDF">pdf</a>, <a href="/format/2401.07955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Large Language Models&#x27; Limitations in Multiple-Choice  Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khatun%2C+A">Aisha Khatun</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+D+G">Daniel G. Brown</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The widespread adoption of Large Language Models (LLMs) has become
commonplace, particularly with the emergence of open-source models. More
importantly, smaller models are well-suited for integration into consumer
devices and are frequently employed either as standalone solutions or as
subroutines in various AI tasks. Despite their ubiquitous use, there is no
systematic analysis of their specific capabilities and limitations. In this
study, we tackle one of the most widely used tasks - answering Multiple Choice
Question (MCQ). We analyze 26 small open-source models and find that 65% of the
models do not understand the task, only 4 models properly select an answer from
the given choices, and only 5 of these models are choice order independent.
These results are rather alarming given the extensive use of MCQ tests with
these models. We recommend exercising caution and testing task understanding
before using MCQ to evaluate LLMs in any field whatsoever.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07958" title="Abstract">arXiv:2401.07958</a> [<a href="/pdf/2401.07958" title="Download PDF">pdf</a>, <a href="/format/2401.07958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GD-CAF: Graph Dual-stream Convolutional Attention Fusion for  Precipitation Nowcasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vatamany%2C+L">Lorand Vatamany</a>, 
<a href="/search/cs?searchtype=author&query=Mehrkanoon%2C+S">Siamak Mehrkanoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate precipitation nowcasting is essential for various purposes,
including flood prediction, disaster management, optimizing agricultural
activities, managing transportation routes and renewable energy. While several
studies have addressed this challenging task from a sequence-to-sequence
perspective, most of them have focused on a single area without considering the
existing correlation between multiple disjoint regions. In this paper, we
formulate precipitation nowcasting as a spatiotemporal graph sequence
nowcasting problem. In particular, we introduce Graph Dual-stream Convolutional
Attention Fusion (GD-CAF), a novel approach designed to learn from historical
spatiotemporal graph of precipitation maps and nowcast future time step ahead
precipitation at different spatial locations. GD-CAF consists of
spatio-temporal convolutional attention as well as gated fusion modules which
are equipped with depthwise-separable convolutional operations. This
enhancement enables the model to directly process the high-dimensional
spatiotemporal graph of precipitation maps and exploits higher-order
correlations between the data dimensions. We evaluate our model on seven years
of precipitation maps across Europe and its neighboring areas collected from
the ERA5 dataset, provided by Copernicus. The model receives a fully connected
graph in which each node represents historical observations from a specific
region on the map. Consequently, each node contains a 3D tensor with time,
height, and width dimensions. Experimental results demonstrate that the
proposed GD-CAF model outperforms the other examined models. Furthermore, the
averaged seasonal spatial and temporal attention scores over the test set are
visualized to provide additional insights about the strongest connections
between different regions or time steps. These visualizations shed light on the
decision-making process of our model.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07960" title="Abstract">arXiv:2401.07960</a> [<a href="/pdf/2401.07960" title="Download PDF">pdf</a>, <a href="/format/2401.07960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADMIn: Attacks on Dataset, Model and Input. A Threat Model for AI Based  Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vimal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Mayo%2C+J">Juliette Mayo</a>, 
<a href="/search/cs?searchtype=author&query=Bahiss%2C+K">Khadija Bahiss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Machine learning (ML) and artificial intelligence (AI) techniques have now
become commonplace in software products and services. When threat modelling a
system, it is therefore important that we consider threats unique to ML and AI
techniques, in addition to threats to our software. In this paper, we present a
threat model that can be used to systematically uncover threats to AI based
software. The threat model consists of two main parts, a model of the software
development process for AI based software and an attack taxonomy that has been
developed using attacks found in adversarial AI research. We apply the threat
model to two real life AI based software and discuss the process and the
threats found.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07962" title="Abstract">arXiv:2401.07962</a> [<a href="/pdf/2401.07962" title="Download PDF">pdf</a>, <a href="/format/2401.07962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cesium Tiles for High-realism Simulation and Comparing SLAM Results in  Corresponding Virtual and Real-world Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beam%2C+C">Chris Beam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jincheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kakavitsas%2C+N">Nicholas Kakavitsas</a>, 
<a href="/search/cs?searchtype=author&query=Hague%2C+C">Collin Hague</a>, 
<a href="/search/cs?searchtype=author&query=Wolek%2C+A">Artur Wolek</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+A">Andrew Willis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This article discusses the use of a simulated environment to predict
algorithm results in the real world. Simulators are crucial in allowing
researchers to test algorithms, sensor integration, and navigation systems
without deploying expensive hardware. This article examines how the AirSim
simulator, Unreal Engine, and Cesium plugin can be used to generate simulated
digital twin models of real-world locations. Several technical challenges in
completing the analysis are discussed and the technical solutions are detailed
in this article. Work investigates how to assess mapping results for a
real-life experiment using Cesium Tiles provided by digital twins of the
experimental location. This is accompanied by a description of a process for
duplicating real-world flights in simulation. The performance of these methods
is evaluated by analyzing real-life and experimental image telemetry with the
Direct Sparse Odometry (DSO) mapping algorithm. Results indicate that Cesium
Tiles environments can provide highly accurate models of ground truth geometry
after careful alignment. Further, results from real-life and simulated
telemetry analysis indicate that the virtual simulation results accurately
predict real-life results. Findings indicate that the algorithm results in real
life and in the simulated duplicate exhibited a high degree of similarity. This
indicates that the use of Cesium Tiles environments as a virtual digital twin
for real-life experiments will provide representative results for such
algorithms. The impact of this can be significant, potentially allowing
expansive virtual testing of robotic systems at specific deployment locations
to develop solutions that are tailored to the environment and potentially
outperforming solutions meant to work in completely generic environments.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07964" title="Abstract">arXiv:2401.07964</a> [<a href="/pdf/2401.07964" title="Download PDF">pdf</a>, <a href="/ps/2401.07964" title="Download PostScript">ps</a>, <a href="/format/2401.07964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-as-exploration: Navigating intelligence space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mollo%2C+D+C">Dimitri Coelho Mollo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Artificial Intelligence is a field that lives many lives, and the term has
come to encompass a motley collection of scientific and commercial endeavours.
In this paper, I articulate the contours of a rather neglected but central
scientific role that AI has to play, which I dub `AI-as-exploration'.The basic
thrust of AI-as-exploration is that of creating and studying systems that can
reveal candidate building blocks of intelligence that may differ from the forms
of human and animal intelligence we are familiar with. In other words, I
suggest that AI is one of the best tools we have for exploring intelligence
space, namely the space of possible intelligent systems. I illustrate the value
of AI-as-exploration by focusing on a specific case study, i.e., recent work on
the capacity to combine novel and invented concepts in humans and Large
Language Models. I show that the latter, despite showing human-level accuracy
in such a task, most probably solve it in ways radically different, but no less
relevant to intelligence research, to those hypothesised for humans.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07967" title="Abstract">arXiv:2401.07967</a> [<a href="/pdf/2401.07967" title="Download PDF">pdf</a>, <a href="/format/2401.07967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCMChaos: Improvising Rap Music with MCMC Methods and Chaos Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kimelman%2C+R+G">Robert G. Kimelman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">A novel freestyle rap software, MCMChaos 0.0.1, based on rap music
transcriptions created in previous research is presented. The software has
three different versions, each making use of different mathematical simulation
methods: collapsed gibbs sampler and lorenz attractor simulation. As far as we
know, these simulation methods have never been used in rap music generation
before. The software implements Python Text-to-Speech processing (pyttxs) to
convert text wrangled from the MCFlow corpus into English speech. In each
version, values simulated from each respective mathematical model alter the
rate of speech, volume, and (in the multiple voice case) the voice of the
text-to-speech engine on a line-by-line basis. The user of the software is
presented with a real-time graphical user interface (GUI) which instantaneously
changes the initial values read into the mathematical simulation methods.
Future research might attempt to allow for more user control and autonomy.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07977" title="Abstract">arXiv:2401.07977</a> [<a href="/pdf/2401.07977" title="Download PDF">pdf</a>, <a href="/ps/2401.07977" title="Download PostScript">ps</a>, <a href="/format/2401.07977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging External Knowledge Resources to Enable Domain-Specific  Comprehension
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+S">Saptarshi Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Heaton%2C+C">Connor Heaton</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumalya Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Machine Reading Comprehension (MRC) has been a long-standing problem in NLP
and, with the recent introduction of the BERT family of transformer based
language models, it has come a long way to getting solved. Unfortunately,
however, when BERT variants trained on general text corpora are applied to
domain-specific text, their performance inevitably degrades on account of the
domain shift i.e. genre/subject matter discrepancy between the training and
downstream application data. Knowledge graphs act as reservoirs for either open
or closed domain information and prior studies have shown that they can be used
to improve the performance of general-purpose transformers in domain-specific
applications. Building on existing work, we introduce a method using
Multi-Layer Perceptrons (MLPs) for aligning and integrating embeddings
extracted from knowledge graphs with the embeddings spaces of pre-trained
language models (LMs). We fuse the aligned embeddings with open-domain LMs BERT
and RoBERTa, and fine-tune them for two MRC tasks namely span detection
(COVID-QA) and multiple-choice questions (PubMedQA). On the COVID-QA dataset,
we see that our approach allows these models to perform similar to their
domain-specific counterparts, Bio/Sci-BERT, as evidenced by the Exact Match
(EM) metric. With regards to PubMedQA, we observe an overall improvement in
accuracy while the F1 stays relatively the same over the domain-specific
models.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07985" title="Abstract">arXiv:2401.07985</a> [<a href="/pdf/2401.07985" title="Download PDF">pdf</a>, <a href="/format/2401.07985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Digital Twins to Digital Twin Prototypes: Concepts, Formalization,  and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barbie%2C+A">Alexander Barbie</a>, 
<a href="/search/cs?searchtype=author&query=Hasselbring%2C+W">Wilhelm Hasselbring</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 20 Figures, 50 Object-Z schemes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The transformation to Industry 4.0 also transforms the processes of how we
develop intelligent manufacturing production systems. To advance the software
development of these new (embedded) software systems, digital twins may be
employed. However, there is no consensual definition of what a digital twin is.
In this paper, we give an overview of the current state of the digital twin
concept and formalize the digital twin concept using the Object-Z notation.
This formalization includes the concepts of physical twins, digital models,
digital templates, digital threads, digital shadows, digital twins, and digital
twin prototypes. The relationships between all these concepts are visualized as
UML class diagrams.
<br />Our digital twin prototype (DTP) approach supports engineers during the
development and automated testing of complex embedded software systems. This
approach enable engineers to test embedded software systems in a virtual
context, without the need of a connection to a physical object. In continuous
integration / continuous deployment pipelines such digital twin prototypes can
be used for automated integration testing and, thus, allow for an agile
verification and validation process.
<br />In this paper, we demonstrate and report on how to apply and implement a
digital twin by the example of two real-world field studies (ocean observation
systems and smart farming). For independent replication and extension of our
approach by other researchers, we provide a lab study published open source on
GitHub.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07986" title="Abstract">arXiv:2401.07986</a> [<a href="/pdf/2401.07986" title="Download PDF">pdf</a>, <a href="/ps/2401.07986" title="Download PostScript">ps</a>, <a href="/format/2401.07986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Class of Linear Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cherubini%2C+G">Giacomo Cherubini</a>, 
<a href="/search/cs?searchtype=author&query=Micheli%2C+G">Giacomo Micheli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">Let $n$ be a prime power, $r$ be a prime with $r\mid n-1$, and
$\varepsilon\in (0,1/2)$. Using the theory of multiplicative character sums and
superelliptic curves, we construct new codes over $\mathbb F_r$ having length
$n$, relative distance $(r-1)/r+O(n^{-\varepsilon})$ and rate
$n^{-1/2-\varepsilon}$. When $r=2$, our binary codes have exponential size when
compared to all previously known families of linear and non-linear codes with
relative distance asymptotic to $1/2$, such as Delsarte--Goethals codes.
Moreover, our codes are linear.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07991" title="Abstract">arXiv:2401.07991</a> [<a href="/pdf/2401.07991" title="Download PDF">pdf</a>, <a href="/format/2401.07991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Against Adversarial Attacks via Learning Confined Adversarial  Polytopes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamidi%2C+S+M">Shayan Mohajer Hamidi</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+L">Linfeng Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Deep neural networks (DNNs) could be deceived by generating
human-imperceptible perturbations of clean samples. Therefore, enhancing the
robustness of DNNs against adversarial attacks is a crucial task. In this
paper, we aim to train robust DNNs by limiting the set of outputs reachable via
a norm-bounded perturbation added to a clean sample. We refer to this set as
adversarial polytope, and each clean sample has a respective adversarial
polytope. Indeed, if the respective polytopes for all the samples are compact
such that they do not intersect the decision boundaries of the DNN, then the
DNN is robust against adversarial samples. Hence, the inner-working of our
algorithm is based on learning \textbf{c}onfined \textbf{a}dversarial
\textbf{p}olytopes (CAP). By conducting a thorough set of experiments, we
demonstrate the effectiveness of CAP over existing adversarial robustness
methods in improving the robustness of models against state-of-the-art attacks
including AutoAttack.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07992" title="Abstract">arXiv:2401.07992</a> [<a href="/pdf/2401.07992" title="Download PDF">pdf</a>, <a href="/format/2401.07992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing the MEV Game on a First-Come-First-Served Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96z%2C+B">Burak &#xd6;z</a>, 
<a href="/search/cs?searchtype=author&query=Gebele%2C+J">Jonas Gebele</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Parshant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Rezabek%2C+F">Filip Rezabek</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Maximal Extractable Value (MEV) searching has gained prominence on the
Ethereum blockchain since the surge in Decentralized Finance activities. In
Ethereum, MEV extraction primarily hinges on fee payments to block proposers.
However, in First-Come-First-Served (FCFS) blockchain networks, the focus
shifts to latency optimizations, akin to High-Frequency Trading in Traditional
Finance. This paper illustrates the dynamics of the MEV extraction game in an
FCFS network, specifically Algorand. We introduce an arbitrage detection
algorithm tailored to the unique time constraints of FCFS networks and assess
its effectiveness. Additionally, our experiments investigate potential
optimizations in Algorand's network layer to secure optimal execution
positions.
<br />Our analysis reveals that while the states of relevant trading pools are
updated approximately every six blocks on median, pursuing MEV at the block
state level is not viable on Algorand, as arbitrage opportunities are typically
executed within the blocks they appear. Our algorithm's performance under
varying time constraints underscores the importance of timing in arbitrage
discovery. Furthermore, our network-level experiments identify critical
transaction prioritization strategies for Algorand's FCFS network. Key among
these is reducing latency in connections with relays that are well-connected to
high-staked proposers.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07993" title="Abstract">arXiv:2401.07993</a> [<a href="/pdf/2401.07993" title="Download PDF">pdf</a>, <a href="/format/2401.07993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carrying over algorithm in transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruthoff%2C+J">Jorrit Kruthoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Addition is perhaps one of the simplest arithmetic tasks one can think of and
is usually performed using the carrying over algorithm. This algorithm consists
of two tasks: adding digits in the same position and carrying over a one
whenever necessary. We study how transformer models implement this algorithm
and how the two aforementioned tasks are allocated to different parts of the
network. We first focus on two-layer encoder-only models and show that the
carrying over algorithm is implemented in a modular fashion. The first layer is
mostly responsible for adding digits in the same position. The second layer
first decides, in the attention, which positions need a carried one or not, and
then performs the carrying of the one in the final MLP. We provide a simple way
of precisely identifying which neurons are responsible for that task. This
implementation of the carrying over algorithm occurs across a range of
hyperparameters for two as well as three-layer models. For small decoder-only
models, we observe the same implementation and provide suggestive evidence for
its existence in three 7B large language models.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07994" title="Abstract">arXiv:2401.07994</a> [<a href="/pdf/2401.07994" title="Download PDF">pdf</a>, <a href="/format/2401.07994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach for Automatic Program Repair using Round-Trip  Translation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+F+V">Fernando Vallecillos Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Grishina%2C+A">Anastasiia Grishina</a>, 
<a href="/search/cs?searchtype=author&query=Hort%2C+M">Max Hort</a>, 
<a href="/search/cs?searchtype=author&query=Moonen%2C+L">Leon Moonen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Research shows that grammatical mistakes in a sentence can be corrected by
translating it to another language and back using neural machine translation
with language models. We investigate whether this correction capability of
Large Language Models (LLMs) extends to Automatic Program Repair (APR). Current
generative models for APR are pre-trained on source code and fine-tuned for
repair. This paper proposes bypassing the fine-tuning step and using Round-Trip
Translation (RTT): translation of code from one programming language to another
programming or natural language, and back. We hypothesize that RTT with LLMs
restores the most commonly seen patterns in code during pre-training, i.e.,
performs a regression toward the mean, which removes bugs as they are a form of
noise w.r.t. the more frequent, natural, bug-free code in the training data. To
test this hypothesis, we employ eight recent LLMs pre-trained on code,
including the latest GPT versions, and four common program repair benchmarks in
Java. We find that RTT with English as an intermediate language repaired 101 of
164 bugs with GPT-4 on the HumanEval-Java dataset. Moreover, 46 of these are
unique bugs that are not repaired by other LLMs fine-tuned for APR. Our
findings highlight the viability of round-trip translation with LLMs as a
technique for automated program repair and its potential for research in
software engineering.
<br />Keywords: automated program repair, large language model, machine translation
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07995" title="Abstract">arXiv:2401.07995</a> [<a href="/pdf/2401.07995" title="Download PDF">pdf</a>, <a href="/format/2401.07995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Pulse of Fileless Cryptojacking Attacks: Malicious PowerShell  Scripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varlioglu%2C+S">Said Varlioglu</a>, 
<a href="/search/cs?searchtype=author&query=Elsayed%2C+N">Nelly Elsayed</a>, 
<a href="/search/cs?searchtype=author&query=Varlioglu%2C+E+R">Eva Ruhsar Varlioglu</a>, 
<a href="/search/cs?searchtype=author&query=Ozer%2C+M">Murat Ozer</a>, 
<a href="/search/cs?searchtype=author&query=ElSayed%2C+Z">Zag ElSayed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Fileless malware predominantly relies on PowerShell scripts, leveraging the
native capabilities of Windows systems to execute stealthy attacks that leave
no traces on the victim's system. The effectiveness of the fileless method lies
in its ability to remain operational on victim endpoints through memory
execution, even if the attacks are detected, and the original malicious scripts
are removed. Threat actors have increasingly utilized this technique,
particularly since 2017, to conduct cryptojacking attacks. With the emergence
of new Remote Code Execution (RCE) vulnerabilities in ubiquitous libraries,
widespread cryptocurrency mining attacks have become prevalent, often employing
fileless techniques. This paper provides a comprehensive analysis of PowerShell
scripts of fileless cryptojacking, dissecting the common malicious patterns
based on the MITRE ATT&amp;CK framework.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07996" title="Abstract">arXiv:2401.07996</a> [<a href="/pdf/2401.07996" title="Download PDF">pdf</a>, <a href="/format/2401.07996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Satisfiability of Context-free String Constraints with Subword-ordering  and Transducers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aiswarya%2C+C">C Aiswarya</a>, 
<a href="/search/cs?searchtype=author&query=Mal%2C+S">Soumodev Mal</a>, 
<a href="/search/cs?searchtype=author&query=Saivasan%2C+P">Prakash Saivasan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We study the satisfiability of string constraints where context-free
membership constraints may be imposed on variables. Additionally a variable may
be constrained to be a subword of a word obtained by shuffling variables and
their transductions. The satisfiability problem is known to be undecidable even
without rational transductions. It is known to be NExptime-complete without
transductions, if the subword relations between variables do not have a cyclic
dependency between them. We show that the satisfiability problem stays
decidable in this fragment even when rational transductions are added. It is
2NExptime-complete with context-free membership, and NExptime-complete with
only regular membership. For the lower bound we prove a technical lemma that is
of independent interest: The length of the shortest word in the intersection of
a pushdown automaton (of size $O(n)$) and $n$ finite-state automata (each of
size $O(n)$) can be double exponential in $n$.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08001" title="Abstract">arXiv:2401.08001</a> [<a href="/pdf/2401.08001" title="Download PDF">pdf</a>, <a href="/format/2401.08001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TT-SNN: Tensor Train Decomposition for Efficient Spiking Neural Network  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Donghyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+R">Ruokai Yin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Youngeun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Moitra%2C+A">Abhishek Moitra</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+P">Priyadarshini Panda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Spiking Neural Networks (SNNs) have gained significant attention as a
potentially energy-efficient alternative for standard neural networks with
their sparse binary activation. However, SNNs suffer from memory and
computation overhead due to spatio-temporal dynamics and multiple
backpropagation computations across timesteps during training. To address this
issue, we introduce Tensor Train Decomposition for Spiking Neural Networks
(TT-SNN), a method that reduces model size through trainable weight
decomposition, resulting in reduced storage, FLOPs, and latency. In addition,
we propose a parallel computation pipeline as an alternative to the typical
sequential tensor computation, which can be flexibly integrated into various
existing SNN architectures. To the best of our knowledge, this is the first of
its kind application of tensor decomposition in SNNs. We validate our method
using both static and dynamic datasets, CIFAR10/100 and N-Caltech101,
respectively. We also propose a TT-SNN-tailored training accelerator to fully
harness the parallelism in TT-SNN. Our results demonstrate substantial
reductions in parameter size (7.98X), FLOPs (9.25X), training time (17.7%), and
training energy (28.3%) during training for the N-Caltech101 dataset, with
negligible accuracy degradation.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08002" title="Abstract">arXiv:2401.08002</a> [<a href="/pdf/2401.08002" title="Download PDF">pdf</a>, <a href="/ps/2401.08002" title="Download PostScript">ps</a>, <a href="/format/2401.08002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovery of Generalizable TBI Phenotypes Using Multivariate Time-Series  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaderi%2C+H">Hamid Ghaderi</a>, 
<a href="/search/cs?searchtype=author&query=Foreman%2C+B">Brandon Foreman</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+C+K">Chandan K. Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Subbian%2C+V">Vignesh Subbian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 10 figures, 4 tables, submitted to Computers in Biology and Medicine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM); Applications (stat.AP)

</div>
<p class="mathjax">Traumatic Brain Injury (TBI) presents a broad spectrum of clinical
presentations and outcomes due to its inherent heterogeneity, leading to
diverse recovery trajectories and varied therapeutic responses. While many
studies have delved into TBI phenotyping for distinct patient populations,
identifying TBI phenotypes that consistently generalize across various settings
and populations remains a critical research gap. Our research addresses this by
employing multivariate time-series clustering to unveil TBI's dynamic
intricates. Utilizing a self-supervised learning-based approach to clustering
multivariate time-Series data with missing values (SLAC-Time), we analyzed both
the research-centric TRACK-TBI and the real-world MIMIC-IV datasets.
Remarkably, the optimal hyperparameters of SLAC-Time and the ideal number of
clusters remained consistent across these datasets, underscoring SLAC-Time's
stability across heterogeneous datasets. Our analysis revealed three
generalizable TBI phenotypes ({\alpha}, \b{eta}, and {\gamma}), each exhibiting
distinct non-temporal features during emergency department visits, and temporal
feature profiles throughout ICU stays. Specifically, phenotype {\alpha}
represents mild TBI with a remarkably consistent clinical presentation. In
contrast, phenotype \b{eta} signifies severe TBI with diverse clinical
manifestations, and phenotype {\gamma} represents a moderate TBI profile in
terms of severity and clinical diversity. Age is a significant determinant of
TBI outcomes, with older cohorts recording higher mortality rates. Importantly,
while certain features varied by age, the core characteristics of TBI
manifestations tied to each phenotype remain consistent across diverse
populations.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08003" title="Abstract">arXiv:2401.08003</a> [<a href="/pdf/2401.08003" title="Download PDF">pdf</a>, <a href="/format/2401.08003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jewelry Recognition via Encoder-Decoder Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcalde-Llergo%2C+J+M">Jos&#xe9; M. Alcalde-Llergo</a>, 
<a href="/search/cs?searchtype=author&query=Yeguas-Bol%C3%ADvar%2C+E">Enrique Yeguas-Bol&#xed;var</a>, 
<a href="/search/cs?searchtype=author&query=Zingoni%2C+A">Andrea Zingoni</a>, 
<a href="/search/cs?searchtype=author&query=Fuerte-Jurado%2C+A">Alejandro Fuerte-Jurado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, MetroXRAINE 2023 Conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Metrology for Extended
  Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE),
  Milano, Italy, 2023, pp. 116-121
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Jewelry recognition is a complex task due to the different styles and designs
of accessories. Precise descriptions of the various accessories is something
that today can only be achieved by experts in the field of jewelry. In this
work, we propose an approach for jewelry recognition using computer vision
techniques and image captioning, trying to simulate this expert human behavior
of analyzing accessories. The proposed methodology consist on using different
image captioning models to detect the jewels from an image and generate a
natural language description of the accessory. Then, this description is also
utilized to classify the accessories at different levels of detail. The
generated caption includes details such as the type of jewel, color, material,
and design. To demonstrate the effectiveness of the proposed method in
accurately recognizing different types of jewels, a dataset consisting of
images of accessories belonging to jewelry stores in C\'ordoba (Spain) has been
created. After testing the different image captioning architectures designed,
the final model achieves a captioning accuracy of 95\%. The proposed
methodology has the potential to be used in various applications such as
jewelry e-commerce, inventory management or automatic jewels recognition to
analyze people's tastes and social status.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08008" title="Abstract">arXiv:2401.08008</a> [<a href="/pdf/2401.08008" title="Download PDF">pdf</a>, <a href="/format/2401.08008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing the Needs of Homeless People Using Feature Selection and  Mining Association Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alcalde-Llergo%2C+J+M">Jos&#xe9; M. Alcalde-Llergo</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Mart%C3%ADnez%2C+C">Carlos Garc&#xed;a-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Vaquero-Abell%C3%A1n%2C+M">Manuel Vaquero-Abell&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Aparicio-Mart%C3%ADnez%2C+P">Pilar Aparicio-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Yeguas-Bol%C3%ADvar%2C+E">Enrique Yeguas-Bol&#xed;var</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 4 tables, MetroXRAINE 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE International Conference on Metrology for Extended
  Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE), Rome,
  Italy, 2022, pp. 568-573
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Homelessness is a social and health problem with great repercussions in
Europe. Many non-governmental organisations help homeless people by collecting
and analysing large amounts of information about them. However, these tasks are
not always easy to perform, and hinder other of the organisations duties. The
SINTECH project was created to tackle this issue proposing two different tools:
a mobile application to quickly and easily collect data; and a software based
on artificial intelligence which obtains interesting information from the
collected data. The first one has been distributed to some Spanish
organisations which are using it to conduct surveys of homeless people. The
second tool implements different feature selection and association rules mining
methods. These artificial intelligence techniques have allowed us to identify
the most relevant features and some interesting association rules from
previously collected homeless data.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08013" title="Abstract">arXiv:2401.08013</a> [<a href="/pdf/2401.08013" title="Download PDF">pdf</a>, <a href="/format/2401.08013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Day-to-Day Dynamical Approach to the Most Likely User Equilibrium  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianni Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Liyang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y+M">Yu Marco Nie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); General Economics (econ.GN)

</div>
<p class="mathjax">The lack of a unique user equilibrium (UE) route flow in traffic assignment
has posed a significant challenge to many transportation applications. The
maximum-entropy principle, which advocates for the consistent selection of the
most likely solution as a representative, is often used to address the
challenge. Built on a recently proposed day-to-day (DTD) discrete-time
dynamical model called cumulative logit (CULO), this study provides a new
behavioral underpinning for the maximum-entropy UE (MEUE) route flow. It has
been proven that CULO can reach a UE state without presuming travelers are
perfectly rational. Here, we further establish that CULO always converges to
the MEUE route flow if (i) travelers have zero prior information about routes
and thus are forced to give all routes an equal choice probability, or (ii) all
travelers gather information from the same source such that the so-called
general proportionality condition is satisfied. Thus, CULO may be used as a
practical solution algorithm for the MEUE problem. To put this idea into
practice, we propose to eliminate the route enumeration requirement of the
original CULO model through an iterative route discovery scheme. We also
examine the discrete-time versions of four popular continuous-time dynamical
models and compare them to CULO. The analysis shows that the replicator dynamic
is the only one that has the potential to reach the MEUE solution with some
regularity. The analytical results are confirmed through numerical experiments.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08014" title="Abstract">arXiv:2401.08014</a> [<a href="/pdf/2401.08014" title="Download PDF">pdf</a>, <a href="/format/2401.08014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Neural Network Compression via Dynamic Parameter Rank  Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Manish Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Heard%2C+J">Jamison Heard</a>, 
<a href="/search/cs?searchtype=author&query=Saber%2C+E">Eli Saber</a>, 
<a href="/search/cs?searchtype=author&query=Markopoulos%2C+P+P">Panos P. Markopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While Convolutional Neural Networks (CNNs) excel at learning complex
latent-space representations, their over-parameterization can lead to
overfitting and reduced performance, particularly with limited data. This,
alongside their high computational and memory demands, limits the applicability
of CNNs for edge deployment. Low-rank matrix approximation has emerged as a
promising approach to reduce CNN parameters, but its application presents
challenges including rank selection and performance loss. To address these
issues, we propose an efficient training method for CNN compression via dynamic
parameter rank pruning. Our approach integrates efficient matrix factorization
and novel regularization techniques, forming a robust framework for dynamic
rank reduction and model compression. We use Singular Value Decomposition (SVD)
to model low-rank convolutional filters and dense weight matrices and we
achieve model compression by training the SVD factors with back-propagation in
an end-to-end way. We evaluate our method on an array of modern CNNs, including
ResNet-18, ResNet-20, and ResNet-32, and datasets like CIFAR-10, CIFAR-100, and
ImageNet (2012), showcasing its applicability in computer vision. Our
experiments show that the proposed method can yield substantial storage savings
while maintaining or even enhancing classification performance.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08015" title="Abstract">arXiv:2401.08015</a> [<a href="/pdf/2401.08015" title="Download PDF">pdf</a>, <a href="/format/2401.08015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallel $k$-Core Decomposition with Batched Updates and Asynchronous  Reads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q+C">Quanquan C. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shun%2C+J">Julian Shun</a>, 
<a href="/search/cs?searchtype=author&query=Zablotchi%2C+I">Igor Zablotchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in PPoPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Maintaining a dynamic $k$-core decomposition is an important problem that
identifies dense subgraphs in dynamically changing graphs. Recent work by Liu
et al. [SPAA 2022] presents a parallel batch-dynamic algorithm for maintaining
an approximate $k$-core decomposition. In their solution, both reads and
updates need to be batched, and therefore each type of operation can incur high
latency waiting for the other type to finish. To tackle most real-world
workloads, which are dominated by reads, this paper presents a novel hybrid
concurrent-parallel dynamic $k$-core data structure where asynchronous reads
can proceed concurrently with batches of updates, leading to significantly
lower read latencies. Our approach is based on tracking causal dependencies
between updates, so that causally related groups of updates appear atomic to
concurrent readers. Our data structure guarantees linearizability and liveness
for both reads and updates, and maintains the same approximation guarantees as
prior work. Our experimental evaluation on a 30-core machine shows that our
approach reduces read latency by orders of magnitude compared to the
batch-dynamic algorithm, up to a $\left(4.05 \cdot 10^{5}\right)$-factor.
Compared to an unsynchronized (non-linearizable) baseline, our read latency
overhead is only up to a $3.21$-factor greater, while improving accuracy of
coreness estimates by up to a factor of $52.7$.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08016" title="Abstract">arXiv:2401.08016</a> [<a href="/pdf/2401.08016" title="Download PDF">pdf</a>, <a href="/format/2401.08016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Bandits with Stage-wise Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacchiano%2C+A">Aldo Pacchiano</a>, 
<a href="/search/cs?searchtype=author&query=Ghavamzadeh%2C+M">Mohammad Ghavamzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Bartlett%2C+P">Peter Bartlett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages. arXiv admin note: text overlap with <a href="/abs/2006.10185">arXiv:2006.10185</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">We study contextual bandits in the presence of a stage-wise constraint (a
constraint at each round), when the constraint must be satisfied both with high
probability and in expectation. Obviously the setting where the constraint is
in expectation is a relaxation of the one with high probability. We start with
the linear case where both the contextual bandit problem (reward function) and
the stage-wise constraint (cost function) are linear. In each of the high
probability and in expectation settings, we propose an upper-confidence bound
algorithm for the problem and prove a $T$-round regret bound for it. Our
algorithms balance exploration and constraint satisfaction using a novel idea
that scales the radii of the reward and cost confidence sets with different
scaling factors. We also prove a lower-bound for this constrained problem, show
how our algorithms and analyses can be extended to multiple constraints, and
provide simulations to validate our theoretical results. In the high
probability setting, we describe the minimum requirements for the action set in
order for our algorithm to be tractable. In the setting that the constraint is
in expectation, we further specialize our results to multi-armed bandits and
propose a computationally efficient algorithm for this setting with regret
analysis. Finally, we extend our results to the case where the reward and cost
functions are both non-linear. We propose an algorithm for this case and prove
a regret bound for it that characterize the function class complexity by the
eluder dimension.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08017" title="Abstract">arXiv:2401.08017</a> [<a href="/pdf/2401.08017" title="Download PDF">pdf</a>, <a href="/format/2401.08017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Object Detection by DETR via Information Augmentation and Adaptive  Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Ji Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The main challenge for small object detection algorithms is to ensure
accuracy while pursuing real-time performance. The RT-DETR model performs well
in real-time object detection, but performs poorly in small object detection
accuracy. In order to compensate for the shortcomings of the RT-DETR model in
small object detection, two key improvements are proposed in this study.
Firstly, The RT-DETR utilises a Transformer that receives input solely from the
final layer of Backbone features. This means that the Transformer's input only
receives semantic information from the highest level of abstraction in the Deep
Network, and ignores detailed information such as edges, texture or color
gradients that are critical to the location of small objects at lower levels of
abstraction. Including only deep features can introduce additional background
noise. This can have a negative impact on the accuracy of small object
detection. To address this issue, we propose the fine-grained path augmentation
method. This method helps to locate small objects more accurately by providing
detailed information to the deep network. So, the input to the transformer
contains both semantic and detailed information. Secondly, In RT-DETR, the
decoder takes feature maps of different levels as input after concatenating
them with equal weight. However, this operation is not effective in dealing
with the complex relationship of multi-scale information captured by feature
maps of different sizes. Therefore, we propose an adaptive feature fusion
algorithm that assigns learnable parameters to each feature map from different
levels. This allows the model to adaptively fuse feature maps from different
levels and effectively integrate feature information from different scales.
This enhances the model's ability to capture object features at different
scales, thereby improving the accuracy of detecting small objects.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08018" title="Abstract">arXiv:2401.08018</a> [<a href="/pdf/2401.08018" title="Download PDF">pdf</a>, <a href="/ps/2401.08018" title="Download PostScript">ps</a>, <a href="/format/2401.08018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effects of Virtual Hand Representation on the Typing Performance, Upper  Extremity Angle, and Neck Muscle Activity during Virtual Reality Typing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaman%2C+M">Mobasshira Zaman</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J">Jaejin Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study evaluated the effect of virtual hand representation on the typing
performance, upper extremity angle, neck muscle activity, and usability during
virtual reality (VR) typing. A total of 15 participants (7 females and 8 males)
performed a typing task with and without virtual hand representations. The
optical motion capture data was utilized to capture the upper extremity angles,
and electromyography device was used to collect the neck muscle activities
(left and right splenius capitis). The results showed that the typing
performance, upper extremity angle, neck muscle activity, and usability were
significantly different with and without virtual hand representations. With the
virtual hand representation, net typing speed (WPM) and usability increased
significantly by 171.4% and 25% compared to the without hand representation.
Without the virtual hand representation, participants showed increased wrist
extension, and decreased right shoulder abduction angles. The variability of
the neck rotation was increased while typing without the virtual hand
representation. The neck muscle activities were increased with the virtual hand
representation. The results suggest that typing with the virtual hand
representation could positively affect the typing performance and usability and
reduce the risk of the musculoskeletal disorders of the upper extremity. Future
study could explore the effect of the virtual hand representation for users
with varying levels of typing skills.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08019" title="Abstract">arXiv:2401.08019</a> [<a href="/pdf/2401.08019" title="Download PDF">pdf</a>, <a href="/ps/2401.08019" title="Download PostScript">ps</a>, <a href="/format/2401.08019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A polynomial algorithm for the most degree-central shortest path problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phosavanh%2C+J">Johnson Phosavanh</a>, 
<a href="/search/cs?searchtype=author&query=Matsypura%2C+D">Dmytro Matsypura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Optimization and Control (math.OC)

</div>
<p class="mathjax">The degree centrality of a node, defined to be the number of nodes adjacent
to it, can be used as a measure of importance of a node to the structure of a
network. This metric can be extended to paths in a network, where the degree
centrality of a path is defined to be the number of nodes adjacent to it. In
this paper, we reconsider the problem of finding the most degree-central
shortest path in an unweighted network. We propose a polynomial algorithm with
the worst-case running time of $O(|V|^3(\Delta(G))^2)$, where $|V|$ is the
number of vertices in the network and $\Delta(G)$ is the maximum degree of the
graph. We conduct a numerical study of our algorithm on synthetic and
real-world networks and compare our results to the existing literature. In
addition, we show that the same problem is NP-hard when a weighted graph is
considered.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08020" title="Abstract">arXiv:2401.08020</a> [<a href="/pdf/2401.08020" title="Download PDF">pdf</a>, <a href="/format/2401.08020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Belief Miner: A Methodology for Discovering Causal Beliefs and Causal  Illusions from General Populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salim%2C+S">Shahreen Salim</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+M+N">Md Naimul Hoque</a>, 
<a href="/search/cs?searchtype=author&query=Mueller%2C+K">Klaus Mueller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Causal belief is a cognitive practice that humans apply everyday to reason
about cause and effect relations between factors, phenomena, or events. Like
optical illusions, humans are prone to drawing causal relations between events
that are only coincidental (i.e., causal illusions). Researchers in domains
such as cognitive psychology and healthcare often use logistically expensive
experiments to understand causal beliefs and illusions. In this paper, we
propose Belief Miner, a crowdsourcing method for evaluating people's causal
beliefs and illusions. Our method uses the (dis)similarities between the causal
relations collected from the crowds and experts to surface the causal beliefs
and illusions. Through an iterative design process, we developed a web-based
interface for collecting causal relations from a target population. We then
conducted a crowdsourced experiment with 101 workers on Amazon Mechanical Turk
and Prolific using this interface and analyzed the collected data with Belief
Miner. We discovered a variety of causal beliefs and potential illusions, and
we report the design implications for future research.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08021" title="Abstract">arXiv:2401.08021</a> [<a href="/pdf/2401.08021" title="Download PDF">pdf</a>, <a href="/format/2401.08021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All the Way There and Back: Inertial-Based, Phone-in-Pocket Indoor  Wayfinding and Backtracking Apps for Blind Travelers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsai%2C+C+H">Chia Hsuan Tsai</a>, 
<a href="/search/cs?searchtype=author&query=Elyasi%2C+F">Fatemeh Elyasi</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Peng Ren</a>, 
<a href="/search/cs?searchtype=author&query=Manduchi%2C+R">Roberto Manduchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Chia Hsuan Tsai, Fatemeh Elyasi and Peng Ren contributed equally to this research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We introduce two iOS apps that have been designed to support wayfinding and
backtracking for blind travelers navigating in indoor building environments.
Wayfinding involves determining and following a route through the building's
corridors to reach a destination, and assumes that the app has access to the
floor plan of the building. Backtracking one's route, on the other hand,
requires no map knowledge. Our apps only use the inertial and magnetic sensors
of the smartphone, and thus require no infrastructure modification (e.g.,
installation and support of BLE beacons). Unlike systems that use the phone's
camera, users of our apps can conveniently keep their phone tucked inside a
pocket, while interacting with the apps using a smartwatch. Routing directions
are given via speech. Both apps were tested in a user study with seven blind
participants, who used them while navigating a campus building.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08022" title="Abstract">arXiv:2401.08022</a> [<a href="/pdf/2401.08022" title="Download PDF">pdf</a>, <a href="/format/2401.08022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preprocessing-based Kinodynamic Motion Planning Framework for  Intercepting Projectiles using a Robot Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+R">Ramkumar Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hanlan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qintong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Oza%2C+Y">Yash Oza</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+M+P">Manash Pratim Das</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+F">Fahad Islam</a>, 
<a href="/search/cs?searchtype=author&query=Saleem%2C+M+S">Muhammad Suhail Saleem</a>, 
<a href="/search/cs?searchtype=author&query=Choset%2C+H">Howie Choset</a>, 
<a href="/search/cs?searchtype=author&query=Likhachev%2C+M">Maxim Likhachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We are interested in studying sports with robots and starting with the
problem of intercepting a projectile moving toward a robot manipulator equipped
with a shield. To successfully perform this task, the robot needs to (i) detect
the incoming projectile, (ii) predict the projectile's future motion, (iii)
plan a minimum-time rapid trajectory that can evade obstacles and intercept the
projectile, and (iv) execute the planned trajectory. These four steps must be
performed under the manipulator's dynamic limits and extreme time constraints
(&lt;350ms in our setting) to successfully intercept the projectile. In addition,
we want these trajectories to be smooth to reduce the robot's joint torques and
the impulse on the platform on which it is mounted. To this end, we propose a
kinodynamic motion planning framework that preprocesses smooth trajectories
offline to allow real-time collision-free executions online. We present an
end-to-end pipeline along with our planning framework, including perception,
prediction, and execution modules. We evaluate our framework experimentally in
simulation and show that it has a higher blocking success rate than the
baselines. Further, we deploy our pipeline on a robotic system comprising an
industrial arm (ABB IRB-1600) and an onboard stereo camera (ZED 2i), which
achieves a 78% success rate in projectile interceptions.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08023" title="Abstract">arXiv:2401.08023</a> [<a href="/pdf/2401.08023" title="Download PDF">pdf</a>, <a href="/format/2401.08023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Channel State Information Prediction with Generative AI: Towards  Holographic Communication and Digital Radio Twin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haijian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R+Q">Rose Qingyang Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to IEEE for potential publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">As 5G technology becomes increasingly established, the anticipation for 6G is
growing, which promises to deliver faster and more reliable wireless
connections via cutting-edge radio technologies. However, efficient management
method of the large-scale antenna arrays deployed by those radio technologies
is crucial. Traditional management methods are mainly reactive, usually based
on feedback from users to adapt to the dynamic wireless channel. However, a
more promising approach lies in the prediction of spatial channel state
information (spatial-CSI), which is an all-inclusive channel characterization
and consists of all the feasible line-of-sight (LoS) and non-line-of-sight
(NLoS) paths between the transmitter (Tx) and receiver (Rx), with the
three-dimension (3D) trajectory, attenuation, phase shift, delay, and
polarization of each path. Advances in hardware and neural networks make it
possible to predict such spatial-CSI using precise environmental information,
and further look into the possibility of holographic communication, which
implies complete control over every aspect of the radio waves emitted. Based on
the integration of holographic communication and digital twin, we proposed a
new framework, digital radio twin, which takes advantages from both the digital
world and deterministic control over radio waves, supporting a wide range of
high-level applications. As a preliminary attempt towards this visionary
direction, in this paper, we explore the use of generative artificial
intelligence (AI) to pinpoint the valid paths in a given environment,
demonstrating promising results, and highlighting the potential of this
approach in driving forward the evolution of 6G wireless communication
technologies.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08025" title="Abstract">arXiv:2401.08025</a> [<a href="/pdf/2401.08025" title="Download PDF">pdf</a>, <a href="/format/2401.08025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using  Self-Imagination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akter%2C+S+N">Syeda Nahida Akter</a>, 
<a href="/search/cs?searchtype=author&query=Madaan%2C+A">Aman Madaan</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sangwu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nyberg%2C+E">Eric Nyberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">The potential of Vision-Language Models (\textsc{vlm}s) often remains
underutilized in handling complex text-based problems, particularly when these
problems could benefit from visual representation. Resonating with humans'
ability to solve complex text-based problems by (1) creating a visual diagram
from the problem and (2) deducing what steps they need to take to solve it, we
propose \textsc{Self-Imagine}. We leverage a single Vision-Language Model
(\textsc{vlm}) to generate a structured representation of the question using
HTML, then render the HTML as an image, and finally use the same \vlm to answer
the question using both the question and the image. Our approach does not
require any additional training data or training. We evaluate our approach in
three mathematics tasks and nine general-purpose reasoning tasks using
state-of-the-art \textsc{vlm}. Our approach boosts the performance of
\textsc{vlm} on all math tasks (\gsm: +4.62\%; \asdiv: +4.49\%; \svamp:
+9.30\%) and the majority of the general-purpose reasoning tasks by 0.4\% to
13.20\% while achieving comparable performance in other tasks.
<br />Code and data at https://github.com/snat1505027/self-imagine .
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08026" title="Abstract">arXiv:2401.08026</a> [<a href="/pdf/2401.08026" title="Download PDF">pdf</a>, <a href="/format/2401.08026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JustiLM: Few-shot Justification Generation for Explainable Fact-Checking  of Real-world Claims
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+F">Fengzhu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in TACL. This is a pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Justification is an explanation that supports the veracity assigned to a
claim in fact-checking. However, the task of justification generation is
previously oversimplified as summarization of fact-check article authored by
fact-checkers. Therefore, we propose a realistic approach to generate
justification based on retrieved evidence. We present a new benchmark dataset
called ExClaim for \underline{Ex}plainable fact-checking of real-world
\underline{Claim}s, and introduce JustiLM, a novel few-shot
\underline{Justi}fication generation based on retrieval-augmented
\underline{L}anguage \underline{M}odel by using fact-check articles as
auxiliary resource during training only. Experiments show that JustiLM achieves
promising performance in justification generation compared to strong baselines,
and can also enhance veracity classification with a straightforward extension.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08035" title="Abstract">arXiv:2401.08035</a> [<a href="/pdf/2401.08035" title="Download PDF">pdf</a>, <a href="/format/2401.08035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BanglaNet: Bangla Handwritten Character Recognition using Ensembling of  Convolutional Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+C">Chandrika Saha</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Md. Mostafijur Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Handwritten character recognition is a crucial task because of its abundant
applications. The recognition task of Bangla handwritten characters is
especially challenging because of the cursive nature of Bangla characters and
the presence of compound characters with more than one way of writing. In this
paper, a classification model based on the ensembling of several Convolutional
Neural Networks (CNN), namely, BanglaNet is proposed to classify Bangla basic
characters, compound characters, numerals, and modifiers. Three different
models based on the idea of state-of-the-art CNN models like Inception, ResNet,
and DenseNet have been trained with both augmented and non-augmented inputs.
Finally, all these models are averaged or ensembled to get the finishing model.
Rigorous experimentation on three benchmark Bangla handwritten characters
datasets, namely, CMATERdb, BanglaLekha-Isolated, and Ekush has exhibited
significant recognition accuracies compared to some recent CNN-based research.
The top-1 recognition accuracies obtained are 98.40%, 97.65%, and 97.32%, and
the top-3 accuracies are 99.79%, 99.74%, and 99.56% for CMATERdb,
BanglaLekha-Isolated, and Ekush datasets respectively.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08036" title="Abstract">arXiv:2401.08036</a> [<a href="/pdf/2401.08036" title="Download PDF">pdf</a>, <a href="/format/2401.08036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Lane Detection from Front or Surround-View using Joint-Modeling &amp;  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haibin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huabing Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D lanes offer a more comprehensive understanding of the road surface
geometry than 2D lanes, thereby providing crucial references for driving
decisions and trajectory planning. While many efforts aim to improve prediction
accuracy, we recognize that an efficient network can bring results closer to
lane modeling. However, if the modeling data is imprecise, the results might
not accurately capture the real-world scenario. Therefore, accurate lane
modeling is essential to align prediction results closely with the environment.
This study centers on efficient and accurate lane modeling, proposing a joint
modeling approach that combines Bezier curves and interpolation methods.
Furthermore, based on this lane modeling approach, we developed a Global2Local
Lane Matching method with Bezier Control-Point and Key-Point, which serve as a
comprehensive solution that leverages hierarchical features with two
mathematical models to ensure a precise match. We also introduce a novel 3D
Spatial Constructor, representing an exploration of 3D surround-view lane
detection research. The framework is suitable for front-view or surround-view
3D lane detection. By directly outputting the key points of lanes in 3D space,
it overcomes the limitations of anchor-based methods, enabling accurate
prediction of closed-loop or U-shaped lanes and effective adaptation to complex
road conditions. This innovative method establishes a new benchmark in
front-view 3D lane detection on the Openlane dataset and achieves competitive
performance in surround-view 2D lane detection on the Argoverse2 dataset.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08037" title="Abstract">arXiv:2401.08037</a> [<a href="/pdf/2401.08037" title="Download PDF">pdf</a>, <a href="/format/2401.08037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding factors behind IoT privacy -- A user&#x27;s perspective on RF  sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+D">Akash Deep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Brian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+L">Luis Garcia</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Mani Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While IoT sensors in physical spaces have provided utility and comfort in our
lives, their instrumentation in private and personal spaces has led to growing
concerns regarding privacy. The existing notion behind IoT privacy is that the
sensors whose data can easily be understood and interpreted by humans (such as
cameras) are more privacy-invasive than sensors that are not
human-understandable, such as RF (radio-frequency) sensors. However, given
recent advancements in machine learning, we can not only make sensitive
inferences on RF data but also translate between modalities. Thus, the existing
notions of privacy for IoT sensors need to be revisited. In this paper, our
goal is to understand what factors affect the privacy notions of a non-expert
user (someone who is not well-versed in privacy concepts). To this regard, we
conduct an online study of 162 participants from the USA to find out what
factors affect the privacy perception of a user regarding an RF-based device or
a sensor. Our findings show that a user's perception of privacy not only
depends upon the data collected by the sensor but also on the inferences that
can be made on that data, familiarity with the device and its form factor as
well as the control a user has over the device design and its data policies.
When the data collected by the sensor is not human-interpretable, it is the
inferences that can be made on the data and not the data itself that users care
about when making informed decisions regarding device privacy.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08038" title="Abstract">arXiv:2401.08038</a> [<a href="/pdf/2401.08038" title="Download PDF">pdf</a>, <a href="/format/2401.08038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calpric: Inclusive and Fine-grain Labeling of Privacy Policies with  Crowdsourcing and Active Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Wenjun Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Lie%2C+D">David Lie</a>, 
<a href="/search/cs?searchtype=author&query=Austin%2C+L">Lisa Austin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published at USENIX Security 2023; associated website: <a href="https://www.usenix.org/conference/usenixsecurity23/presentation/qiu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">A significant challenge to training accurate deep learning models on privacy
policies is the cost and difficulty of obtaining a large and comprehensive set
of training data. To address these challenges, we present Calpric , which
combines automatic text selection and segmentation, active learning and the use
of crowdsourced annotators to generate a large, balanced training set for
privacy policies at low cost. Automated text selection and segmentation
simplifies the labeling task, enabling untrained annotators from crowdsourcing
platforms, like Amazon's Mechanical Turk, to be competitive with trained
annotators, such as law students, and also reduces inter-annotator agreement,
which decreases labeling cost. Having reliable labels for training enables the
use of active learning, which uses fewer training samples to efficiently cover
the input space, further reducing cost and improving class and data category
balance in the data set. The combination of these techniques allows Calpric to
produce models that are accurate over a wider range of data categories, and
provide more detailed, fine-grain labels than previous work. Our crowdsourcing
process enables Calpric to attain reliable labeled data at a cost of roughly
$0.92-$1.71 per labeled text segment. Calpric 's training process also
generates a labeled data set of 16K privacy policy text segments across 9 Data
categories with balanced positive and negative samples.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08043" title="Abstract">arXiv:2401.08043</a> [<a href="/pdf/2401.08043" title="Download PDF">pdf</a>, <a href="/format/2401.08043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Semi-Dense 6-DoF Tracking of an Event Camera in Challenging  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+Y">Yi-Fan Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wanting Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kneip%2C+L">Laurent Kneip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by IEEE Transactions on Robotics (T-RO). arXiv admin note: text overlap with <a href="/abs/2202.02556">arXiv:2202.02556</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vision-based localization is a cost-effective and thus attractive solution
for many intelligent mobile platforms. However, its accuracy and especially
robustness still suffer from low illumination conditions, illumination changes,
and aggressive motion. Event-based cameras are bio-inspired visual sensors that
perform well in HDR conditions and have high temporal resolution, and thus
provide an interesting alternative in such challenging scenarios. While purely
event-based solutions currently do not yet produce satisfying mapping results,
the present work demonstrates the feasibility of purely event-based tracking if
an alternative sensor is permitted for mapping. The method relies on geometric
3D-2D registration of semi-dense maps and events, and achieves highly reliable
and accurate cross-modal tracking results. Practically relevant scenarios are
given by depth camera-supported tracking or map-based localization with a
semi-dense map prior created by a regular image-based visual SLAM or
structure-from-motion system. Conventional edge-based 3D-2D alignment is
extended by a novel polarity-aware registration that makes use of signed
time-surface maps (STSM) obtained from event streams. We furthermore introduce
a novel culling strategy for occluded points. Both modifications increase the
speed of the tracker and its robustness against occlusions or large view-point
variations. The approach is validated on many real datasets covering the
above-mentioned challenging conditions, and compared against similar solutions
realised with regular cameras.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08045" title="Abstract">arXiv:2401.08045</a> [<a href="/pdf/2401.08045" title="Download PDF">pdf</a>, <a href="/format/2401.08045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forging Vision Foundation Models for Autonomous Driving: Challenges,  Methodologies, and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yingjie Cai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jingming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+W">Weichao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+B">Bin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiqiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Huan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jiantao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lihui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingbing Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Github Repo: <a href="https://github.com/zhanghm1995/Forge_VFM4AD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The rise of large foundation models, trained on extensive datasets, is
revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4
showcase their adaptability by extracting intricate patterns and performing
effectively across diverse tasks, thereby serving as potent building blocks for
a wide range of AI applications. Autonomous driving, a vibrant front in AI
applications, remains challenged by the lack of dedicated vision foundation
models (VFMs). The scarcity of comprehensive training data, the need for
multi-sensor integration, and the diverse task-specific architectures pose
significant obstacles to the development of VFMs in this field. This paper
delves into the critical challenge of forging VFMs tailored specifically for
autonomous driving, while also outlining future directions. Through a
systematic analysis of over 250 papers, we dissect essential techniques for VFM
development, including data preparation, pre-training strategies, and
downstream task adaptation. Moreover, we explore key advancements such as NeRF,
diffusion models, 3D Gaussian Splatting, and world models, presenting a
comprehensive roadmap for future research. To empower researchers, we have
built and maintained https://github.com/zhanghm1995/Forge_VFM4AD, an
open-access repository constantly updated with the latest advancements in
forging VFMs for autonomous driving.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08046" title="Abstract">arXiv:2401.08046</a> [<a href="/pdf/2401.08046" title="Download PDF">pdf</a>, <a href="/format/2401.08046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Robustness of LLM-Synthetic Text Detectors for Academic  Writing: A Comprehensive Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuchen Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching-Chun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The emergence of large language models (LLMs), such as Generative Pre-trained
Transformer 4 (GPT-4) used by ChatGPT, has profoundly impacted the academic and
broader community. While these models offer numerous advantages in terms of
revolutionizing work and study methods, they have also garnered significant
attention due to their potential negative consequences. One example is
generating academic reports or papers with little to no human contribution.
Consequently, researchers have focused on developing detectors to address the
misuse of LLMs. However, most existing methods prioritize achieving higher
accuracy on restricted datasets, neglecting the crucial aspect of
generalizability. This limitation hinders their practical application in
real-life scenarios where reliability is paramount. In this paper, we present a
comprehensive analysis of the impact of prompts on the text generated by LLMs
and highlight the potential lack of robustness in one of the current
state-of-the-art GPT detectors. To mitigate these issues concerning the misuse
of LLMs in academic writing, we propose a reference-based Siamese detector
named Synthetic-Siamese which takes a pair of texts, one as the inquiry and the
other as the reference. Our method effectively addresses the lack of robustness
of previous detectors (OpenAI detector and DetectGPT) and significantly
improves the baseline performances in realistic academic writing scenarios by
approximately 67% to 95%.
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08047" title="Abstract">arXiv:2401.08047</a> [<a href="/pdf/2401.08047" title="Download PDF">pdf</a>, <a href="/format/2401.08047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Extractive Opinion Summarization Using Cover Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S+B+R">Somnath Basu Roy Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Monath%2C+N">Nicholas Monath</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Avinava Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Zaheer%2C+M">Manzil Zaheer</a>, 
<a href="/search/cs?searchtype=author&query=McCallum%2C+A">Andrew McCallum</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Amr Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Chaturvedi%2C+S">Snigdha Chaturvedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Extractive opinion summarization involves automatically producing a summary
of text about an entity (e.g., a product's reviews) by extracting
representative sentences that capture prevalent opinions in the review set.
Typically, in online marketplaces user reviews accrue over time, and opinion
summaries need to be updated periodically to provide customers with up-to-date
information. In this work, we study the task of extractive opinion
summarization in an incremental setting, where the underlying review set
evolves over time. Many of the state-of-the-art extractive opinion
summarization approaches are centrality-based, such as CentroidRank.
CentroidRank performs extractive summarization by selecting a subset of review
sentences closest to the centroid in the representation space as the summary.
However, these methods are not capable of operating efficiently in an
incremental setting, where reviews arrive one at a time. In this paper, we
present an efficient algorithm for accurately computing the CentroidRank
summaries in an incremental setting. Our approach, CoverSumm, relies on
indexing review representations in a cover tree and maintaining a reservoir of
candidate summary review sentences. CoverSumm's efficacy is supported by a
theoretical and empirical analysis of running time. Empirically, on a diverse
collection of data (both real and synthetically created to illustrate scaling
considerations), we demonstrate that CoverSumm is up to 25x faster than
baseline methods, and capable of adapting to nuanced changes in data
distribution. We also conduct human evaluations of the generated summaries and
find that CoverSumm is capable of producing informative summaries consistent
with the underlying review set.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08049" title="Abstract">arXiv:2401.08049</a> [<a href="/pdf/2401.08049" title="Download PDF">pdf</a>, <a href="/format/2401.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmoTalker: Emotionally Editable Talking Face Generation via Diffusion  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In recent years, the field of talking faces generation has attracted
considerable attention, with certain methods adept at generating virtual faces
that convincingly imitate human expressions. However, existing methods face
challenges related to limited generalization, particularly when dealing with
challenging identities. Furthermore, methods for editing expressions are often
confined to a singular emotion, failing to adapt to intricate emotions. To
overcome these challenges, this paper proposes EmoTalker, an emotionally
editable portraits animation approach based on the diffusion model. EmoTalker
modifies the denoising process to ensure preservation of the original
portrait's identity during inference. To enhance emotion comprehension from
text input, Emotion Intensity Block is introduced to analyze fine-grained
emotions and strengths derived from prompts. Additionally, a crafted dataset is
harnessed to enhance emotion comprehension within prompts. Experiments show the
effectiveness of EmoTalker in generating high-quality, emotionally customizable
facial expressions.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08053" title="Abstract">arXiv:2401.08053</a> [<a href="/pdf/2401.08053" title="Download PDF">pdf</a>, <a href="/format/2401.08053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCoFT: Self-Contrastive Fine-Tuning for Equitable Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Schaldenbrand%2C+P">Peter Schaldenbrand</a>, 
<a href="/search/cs?searchtype=author&query=Okogwu%2C+B">Beverley-Claire Okogwu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wenxuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+Y">Youngsik Yun</a>, 
<a href="/search/cs?searchtype=author&query=Hundt%2C+A">Andrew Hundt</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jihie Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jean Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate representation in media is known to improve the well-being of the
people who consume it. Generative image models trained on large web-crawled
datasets such as LAION are known to produce images with harmful stereotypes and
misrepresentations of cultures. We improve inclusive representation in
generated images by (1) engaging with communities to collect a culturally
representative dataset that we call the Cross-Cultural Understanding Benchmark
(CCUB) and (2) proposing a novel Self-Contrastive Fine-Tuning (SCoFT) method
that leverages the model's known biases to self-improve. SCoFT is designed to
prevent overfitting on small datasets, encode only high-level information from
the data, and shift the generated distribution away from misrepresentations
encoded in a pretrained model. Our user study conducted on 51 participants from
5 different countries based on their self-selected national cultural
affiliation shows that fine-tuning on CCUB consistently generates images with
higher cultural relevance and fewer stereotypes when compared to the Stable
Diffusion baseline, which is further improved with our SCoFT technique.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08054" title="Abstract">arXiv:2401.08054</a> [<a href="/pdf/2401.08054" title="Download PDF">pdf</a>, <a href="/format/2401.08054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile robot localization with GNSS multipath detection using  pseudorange residuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Taro Suzuki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an electronic version of an article published in ADVANCED ROBOTICS, 33(12):602-613, 2019. ADVANCED ROBOTICS is available online at: www.tandfonline.com/Article DOI: 10.1080/01691864.2019.1619622
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advanced Robotics, 33:12, 602-613, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes a novel positioning technique suitable for use in mobile
robots in urban environments in which large global navigation satellite system
(GNSS) positioning errors occur because of multipath signals. During GNSS
positioning, the GNSS satellites that are obstructed by buildings emit
reflection and diffraction signals, which are called non-line-of-sight (NLOS)
multipath signals. These multipath signals cause major positioning errors. The
key concept considered in this paper is the estimation of a user's position
using the likelihood of the position hypotheses computed from the GNSS
pseudoranges, consisting only of LOS signals based on the analysis of the
pseudorange residuals. To determine the NLOS GNSS signals from the pseudorange
residuals at the user's position, it is necessary to accurately determine the
position before the computation of the pseudorange residuals. This problem is
solved using a particle filter. We propose a likelihood estimation method using
the Mahalanobis distance between the hypotheses of the user's position computed
from only the LOS pseudoranges and the particles. To confirm the effectiveness
of the proposed technique, a positioning test was performed in a real-world
urban environment. The results demonstrated that the proposed method is
effective for accurately estimating the user's position in urban canyons.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08056" title="Abstract">arXiv:2401.08056</a> [<a href="/pdf/2401.08056" title="Download PDF">pdf</a>, <a href="/format/2401.08056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Tiny Object Detection in Aerial Images amidst Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haoran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruixiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Precise detection of tiny objects in remote sensing imagery remains a
significant challenge due to their limited visual information and frequent
occurrence within scenes. This challenge is further exacerbated by the
practical burden and inherent errors associated with manual annotation:
annotating tiny objects is laborious and prone to errors (i.e., label noise).
Training detectors for such objects using noisy labels often leads to
suboptimal performance, with networks tending to overfit on noisy labels. In
this study, we address the intricate issue of tiny object detection under noisy
label supervision. We systematically investigate the impact of various types of
noise on network training, revealing the vulnerability of object detectors to
class shifts and inaccurate bounding boxes for tiny objects. To mitigate these
challenges, we propose a DeNoising Tiny Object Detector (DN-TOD), which
incorporates a Class-aware Label Correction (CLC) scheme to address class
shifts and a Trend-guided Learning Strategy (TLS) to handle bounding box noise.
CLC mitigates inaccurate class supervision by identifying and filtering out
class-shifted positive samples, while TLS reduces noisy box-induced erroneous
supervision through sample reweighting and bounding box regeneration.
Additionally, Our method can be seamlessly integrated into both one-stage and
two-stage object detection pipelines. Comprehensive experiments conducted on
synthetic (i.e., noisy AI-TOD-v2.0 and DOTA-v2.0) and real-world (i.e., AI-TOD)
noisy datasets demonstrate the robustness of DN-TOD under various types of
label noise. Notably, when applied to the strong baseline RFLA, DN-TOD exhibits
a noteworthy performance improvement of 4.9 points under 40% mixed noise.
Datasets, codes, and models will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08058" title="Abstract">arXiv:2401.08058</a> [<a href="/pdf/2401.08058" title="Download PDF">pdf</a>, <a href="/format/2401.08058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Clinically Trustworthy Deep Learning: Applying Conformal  Prediction to Intracranial Hemorrhage Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamble%2C+C">Cooper Gamble</a>, 
<a href="/search/cs?searchtype=author&query=Faghani%2C+S">Shahriar Faghani</a>, 
<a href="/search/cs?searchtype=author&query=Erickson%2C+B+J">Bradley J. Erickson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As deep learning (DL) continues to demonstrate its ability in radiological
tasks, it is critical that we optimize clinical DL solutions to include safety.
One of the principal concerns in the clinical adoption of DL tools is trust.
This study aims to apply conformal prediction as a step toward trustworthiness
for DL in radiology. This is a retrospective study of 491 non-contrast head CTs
from the CQ500 dataset, in which three senior radiologists annotated slices
containing intracranial hemorrhage (ICH). The dataset was split into definite
and challenging subsets, where challenging images were defined to those in
which there was disagreement among readers. A DL model was trained on 146
patients (10,815 slices) from the definite data (training dataset) to perform
ICH localization and classification for five classes of ICH. To develop an
uncertainty-aware DL model, 1,546 cases of the definite data (calibration
dataset) was used for Mondrian conformal prediction (MCP). The
uncertainty-aware DL model was tested on 8,401 definite and challenging cases
to assess its ability to identify challenging cases. After the MCP procedure,
the model achieved an F1 score of 0.920 for ICH classification on the test
dataset. Additionally, it correctly identified 6,837 of the 6,856 total
challenging cases as challenging (99.7% accuracy). It did not incorrectly label
any definite cases as challenging. The uncertainty-aware ICH detector performs
on par with state-of-the-art models. MCP's performance in detecting challenging
cases demonstrates that it is useful in automated ICH detection and promising
for trustworthiness in radiological DL.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08061" title="Abstract">arXiv:2401.08061</a> [<a href="/pdf/2401.08061" title="Download PDF">pdf</a>, <a href="/format/2401.08061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting Ground-Level PM2.5 Prediction via Kriging-Based Pseudo-Label  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+L">Lei Duan</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Ziyang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Carlson%2C+D">David Carlson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, NeurIPS 2023 Workshop: Tackling Climate Change with Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Fusing abundant satellite data with sparse ground measurements constitutes a
major challenge in climate modeling. To address this, we propose a strategy to
augment the training dataset by introducing unlabeled satellite images paired
with pseudo-labels generated through a spatial interpolation technique known as
ordinary kriging, thereby making full use of the available satellite data
resources. We show that the proposed data augmentation strategy helps enhance
the performance of the state-of-the-art convolutional neural network-random
forest (CNN-RF) model by a reasonable amount, resulting in a noteworthy
improvement in spatial correlation and a reduction in prediction error.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08066" title="Abstract">arXiv:2401.08066</a> [<a href="/pdf/2401.08066" title="Download PDF">pdf</a>, <a href="/format/2401.08066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achieve Fairness without Demographics for Dermatological Disease  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiu%2C+C">Ching-Hao Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu-Jen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yawen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T">Tsung-Yi Ho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In medical image diagnosis, fairness has become increasingly crucial. Without
bias mitigation, deploying unfair AI would harm the interests of the
underprivileged population and potentially tear society apart. Recent research
addresses prediction biases in deep learning models concerning demographic
groups (e.g., gender, age, and race) by utilizing demographic (sensitive
attribute) information during training. However, many sensitive attributes
naturally exist in dermatological disease images. If the trained model only
targets fairness for a specific attribute, it remains unfair for other
attributes. Moreover, training a model that can accommodate multiple sensitive
attributes is impractical due to privacy concerns. To overcome this, we propose
a method enabling fair predictions for sensitive attributes during the testing
phase without using such information during training. Inspired by prior work
highlighting the impact of feature entanglement on fairness, we enhance the
model features by capturing the features related to the sensitive and target
attributes and regularizing the feature entanglement between corresponding
classes. This ensures that the model can only classify based on the features
related to the target attribute without relying on features associated with
sensitive attributes, thereby improving fairness and accuracy. Additionally, we
use disease masks from the Segment Anything Model (SAM) to enhance the quality
of the learned feature. Experimental results demonstrate that the proposed
method can improve fairness in classification compared to state-of-the-art
methods in two dermatological disease datasets.
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08067" title="Abstract">arXiv:2401.08067</a> [<a href="/pdf/2401.08067" title="Download PDF">pdf</a>, <a href="/ps/2401.08067" title="Download PostScript">ps</a>, <a href="/format/2401.08067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrajVis: a visual clinical decision support system to translate  artificial intelligence trajectory models in the precision management of  chronic kidney disease
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zuotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Ziyang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengyue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+N">Nanxin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Eadon%2C+M">Michael Eadon</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Q">Qianqian Song</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jing Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Objective: Our objective is to develop and validate TrajVis, an interactive
tool that assists clinicians in using artificial intelligence (AI) models to
leverage patients' longitudinal electronic medical records (EMR) for
personalized precision management of chronic disease progression. Methods: We
first perform requirement analysis with clinicians and data scientists to
determine the visual analytics tasks of the TrajVis system as well as its
design and functionalities. A graph AI model for chronic kidney disease (CKD)
trajectory inference named DEPOT is used for system development and
demonstration. TrajVis is implemented as a full-stack web application with
synthetic EMR data derived from the Atrium Health Wake Forest Baptist
Translational Data Warehouse and the Indiana Network for Patient Care research
database. A case study with a nephrologist and a user experience survey of
clinicians and data scientists are conducted to evaluate the TrajVis system.
Results: The TrajVis clinical information system is composed of four panels:
the Patient View for demographic and clinical information, the Trajectory View
to visualize the DEPOT-derived CKD trajectories in latent space, the Clinical
Indicator View to elucidate longitudinal patterns of clinical features and
interpret DEPOT predictions, and the Analysis View to demonstrate personal CKD
progression trajectories. System evaluations suggest that TrajVis supports
clinicians in summarizing clinical data, identifying individualized risk
predictors, and visualizing patient disease progression trajectories,
overcoming the barriers of AI implementation in healthcare. Conclusion: TrajVis
bridges the gap between the fast-growing AI/ML modeling and the clinical use of
such models for personalized and precision management of chronic diseases.
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08068" title="Abstract">arXiv:2401.08068</a> [<a href="/pdf/2401.08068" title="Download PDF">pdf</a>, <a href="/ps/2401.08068" title="Download PostScript">ps</a>, <a href="/format/2401.08068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning on Event Stream via an Elastic Net-incorporated  Tensor Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Beibei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiling Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yan Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event cameras are neuromorphic sensors that capture asynchronous and sparse
event stream when per-pixel brightness changes. The state-of-the-art processing
methods for event signals typically aggregate events into a frame or a grid.
However, events are dense in time, these works are limited to local information
of events due to the stacking. In this paper, we present a novel spatiotemporal
representation learning method which can capture the global correlations of all
events in the event stream simultaneously by tensor decomposition. In addition,
with the events are sparse in space, we propose an Elastic Net-incorporated
tensor network (ENTN) model to obtain more spatial and temporal details about
event stream. Empirically, the results indicate that our method can represent
the spatiotemporal correlation of events with high quality, and can achieve
effective results in applications like filtering noise compared with the
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08073" title="Abstract">arXiv:2401.08073</a> [<a href="/pdf/2401.08073" title="Download PDF">pdf</a>, <a href="/format/2401.08073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Xaminer: An Internet Cross-Layer Resilience Analysis Tool
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanathan%2C+A">Alagappan Ramanathan</a>, 
<a href="/search/cs?searchtype=author&query=Sankaran%2C+R">Rishika Sankaran</a>, 
<a href="/search/cs?searchtype=author&query=Jyothi%2C+S+A">Sangeetha Abdu Jyothi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">A resilient Internet infrastructure is critical in our highly interconnected
society. However, the Internet faces several vulnerabilities, ranging from
natural disasters to human activities, that can impact the physical layer and,
in turn, the higher network layers, such as IP links. In this paper, we
introduce Xaminer, the first Internet cross-layer resilience analysis tool, to
evaluate the interplay between physical- and network-layer failures. Using a
cross-layer Internet map and a failure event model, Xaminer generates a risk
profile encompassing a cross-layer impact report, critical infrastructure
identification at each layer, and the discovery of trends and patterns under
different failure event settings. Xaminer's key strengths lie in its
adaptability to diverse disaster scenarios, the ability to assess risks at
various granularities, and the capability to generate joint risk profiles for
multiple events. We demonstrate Xaminer's capabilities in cross-layer analysis
across a spectrum of disaster event models and regions, showcasing its
potential role in facilitating well-informed decision-making for resilience
planning and deployments.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08077" title="Abstract">arXiv:2401.08077</a> [<a href="/pdf/2401.08077" title="Download PDF">pdf</a>, <a href="/ps/2401.08077" title="Download PostScript">ps</a>, <a href="/format/2401.08077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based approach for Ethereum Price Prediction Using  Crosscurrency correlation and Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Shubham Singh</a>, 
<a href="/search/cs?searchtype=author&query=Bhat%2C+M">Mayur Bhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Pricing of Securities (q-fin.PR)

</div>
<p class="mathjax">The research delves into the capabilities of a transformer-based neural
network for Ethereum cryptocurrency price forecasting. The experiment runs
around the hypothesis that cryptocurrency prices are strongly correlated with
other cryptocurrencies and the sentiments around the cryptocurrency. The model
employs a transformer architecture for several setups from single-feature
scenarios to complex configurations incorporating volume, sentiment, and
correlated cryptocurrency prices. Despite a smaller dataset and less complex
architecture, the transformer model surpasses ANN and MLP counterparts on some
parameters. The conclusion presents a hypothesis on the illusion of causality
in cryptocurrency price movements driven by sentiments.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08079" title="Abstract">arXiv:2401.08079</a> [<a href="/pdf/2401.08079" title="Download PDF">pdf</a>, <a href="/format/2401.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Masking Contrastive Learning for vein recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Huafeng Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yiquan Wu</a>, 
<a href="/search/cs?searchtype=author&query=El-Yacoubi%2C+M+A">Mounim A. El-Yacoubi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangxiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vein recognition has received increasing attention due to its high security
and privacy. Recently, deep neural networks such as Convolutional neural
networks (CNN) and Transformers have been introduced for vein recognition and
achieved state-of-the-art performance. Despite the recent advances, however,
existing solutions for finger-vein feature extraction are still not optimal due
to scarce training image samples. To overcome this problem, in this paper, we
propose an adversarial masking contrastive learning (AMCL) approach, that
generates challenging samples to train a more robust contrastive learning model
for the downstream palm-vein recognition task, by alternatively optimizing the
encoder in the contrastive learning model and a set of latent variables. First,
a huge number of masks are generated to train a robust generative adversarial
network (GAN). The trained generator transforms a latent variable from the
latent variable space into a mask space. Then, we combine the trained generator
with a contrastive learning model to obtain our AMCL, where the generator
produces challenging masking images to increase the contrastive loss and the
contrastive learning model is trained based on the harder images to learn a
more robust feature representation. After training, the trained encoder in the
contrastive learning model is combined with a classification layer to build a
classifier, which is further fine-tuned on labeled training data for vein
recognition. The experimental results on three databases demonstrate that our
approach outperforms existing contrastive learning approaches in terms of
improving identification accuracy of vein classifiers and achieves
state-of-the-art recognition results.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08080" title="Abstract">arXiv:2401.08080</a> [<a href="/pdf/2401.08080" title="Download PDF">pdf</a>, <a href="/ps/2401.08080" title="Download PostScript">ps</a>, <a href="/format/2401.08080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximations of the integral of a class of sinusoidal composite  functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Costa%2C+A">Alberto Costa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Two approximations of the integral of a class of sinusoidal composite
functions, for which an explicit form does not exist, are derived. Numerical
experiments show that the proposed approximations yield an error that does not
depend on the width of the integration interval. Using such approximations,
definite integrals can be computed in almost real-time.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08081" title="Abstract">arXiv:2401.08081</a> [<a href="/pdf/2401.08081" title="Download PDF">pdf</a>, <a href="/format/2401.08081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Next Useful Location With Context-Awareness: The  State-Of-The-Art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nezhadettehad%2C+A">Alireza Nezhadettehad</a>, 
<a href="/search/cs?searchtype=author&query=Zaslavsky%2C+A">Arkady Zaslavsky</a>, 
<a href="/search/cs?searchtype=author&query=Abdur%2C+R">Rakib Abdur</a>, 
<a href="/search/cs?searchtype=author&query=Shaikh%2C+S+A">Siraj Ahmed Shaikh</a>, 
<a href="/search/cs?searchtype=author&query=Loke%2C+S+W">Seng W. Loke</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guang-Li Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+A">Alireza Hassani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Predicting the future location of mobile objects reinforces location-aware
services with proactive intelligence and helps businesses and decision-makers
with better planning and near real-time scheduling in different applications
such as traffic congestion control, location-aware advertisements, and
monitoring public health and well-being. The recent developments in the
smartphone and location sensors technology and the prevalence of using
location-based social networks alongside the improvements in artificial
intelligence and machine learning techniques provide an excellent opportunity
to exploit massive amounts of historical and real-time contextual information
to recognise mobility patterns and achieve more accurate and intelligent
predictions. This survey provides a comprehensive overview of the next useful
location prediction problem with context-awareness. First, we explain the
concepts of context and context-awareness and define the next location
prediction problem. Then we analyse nearly thirty studies in this field
concerning the prediction method, the challenges addressed, the datasets and
metrics used for training and evaluating the model, and the types of context
incorporated. Finally, we discuss the advantages and disadvantages of different
approaches, focusing on the usefulness of the predicted location and
identifying the open challenges and future work on this subject by introducing
two potential use cases of next location prediction in the automotive industry.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08083" title="Abstract">arXiv:2401.08083</a> [<a href="/pdf/2401.08083" title="Download PDF">pdf</a>, <a href="/format/2401.08083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UV-SAM: Adapting Segment Anything Model for Urban Village Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qingming Liao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Urban villages, defined as informal residential areas in or around urban
centers, are characterized by inadequate infrastructures and poor living
conditions, closely related to the Sustainable Development Goals (SDGs) on
poverty, adequate housing, and sustainable cities. Traditionally, governments
heavily depend on field survey methods to monitor the urban villages, which
however are time-consuming, labor-intensive, and possibly delayed. Thanks to
widely available and timely updated satellite images, recent studies develop
computer vision techniques to detect urban villages efficiently. However,
existing studies either focus on simple urban village image classification or
fail to provide accurate boundary information. To accurately identify urban
village boundaries from satellite images, we harness the power of the vision
foundation model and adapt the Segment Anything Model (SAM) to urban village
segmentation, named UV-SAM. Specifically, UV-SAM first leverages a small-sized
semantic segmentation model to produce mixed prompts for urban villages,
including mask, bounding box, and image representations, which are then fed
into SAM for fine-grained boundary identification. Extensive experimental
results on two datasets in China demonstrate that UV-SAM outperforms existing
baselines, and identification results over multiple years show that both the
number and area of urban villages are decreasing over time, providing deeper
insights into the development trends of urban villages and sheds light on the
vision foundation models for sustainable cities. The dataset and codes of this
study are available at https://github.com/tsinghua-fib-lab/UV-SAM.
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08086" title="Abstract">arXiv:2401.08086</a> [<a href="/pdf/2401.08086" title="Download PDF">pdf</a>, <a href="/format/2401.08086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Semantic Collaborative Cropping for User Generated Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yukun Su</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yiwen Cao</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingliang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+F">Fengyun Rao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingyao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">A large amount of User Generated Content (UGC) is uploaded to the Internet
daily and displayed to people world-widely through the client side (e.g.,
mobile and PC). This requires the cropping algorithms to produce the aesthetic
thumbnail within a specific aspect ratio on different devices. However,
existing image cropping works mainly focus on landmark or landscape images,
which fail to model the relations among the multi-objects with the complex
background in UGC. Besides, previous methods merely consider the aesthetics of
the cropped images while ignoring the content integrity, which is crucial for
UGC cropping. In this paper, we propose a Spatial-Semantic Collaborative
cropping network (S2CNet) for arbitrary user generated content accompanied by a
new cropping benchmark. Specifically, we first mine the visual genes of the
potential objects. Then, the suggested adaptive attention graph recasts this
task as a procedure of information association over visual nodes. The
underlying spatial and semantic relations are ultimately centralized to the
crop candidate through differentiable message passing, which helps our network
efficiently to preserve both the aesthetics and the content integrity.
Extensive experiments on the proposed UGCrop5K and other public datasets
demonstrate the superiority of our approach over state-of-the-art counterparts.
Our project is available at https://github.com/suyukun666/S2CNet.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08088" title="Abstract">arXiv:2401.08088</a> [<a href="/pdf/2401.08088" title="Download PDF">pdf</a>, <a href="/format/2401.08088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Document-level Translation of Large Language Model via  Translation Mixed-instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yachao Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Existing large language models (LLMs) for machine translation are typically
fine-tuned on sentence-level translation instructions and achieve satisfactory
performance at the sentence level. However, when applied to document-level
translation, these models face a significant challenge, particularly when
dealing with documents containing over 512 tokens. This challenge arises from
the issue of sentence-level coverage, where subsequent sentences in the
document remain untranslated. As a result, the document-level translation
capability of LLMs fine-tuned on sentence-level translation instructions is
significantly limited. We conjecture that the primary cause of LLMs' weak
document-level translation performance is the absence of document-to-document
mapping ability. To address the issue, we propose an approach that combines
sentence-level and document-level translation instructions of varying lengths
to fine-tune LLMs. Our proposed translation mixed-instructions enable LLMs
(Llama-2~7B and 13B) to maintain consistent translation performance from the
sentence level to documents containing as many as 2048 tokens. Extensive
experimental results show that the proposed approach significantly enhances the
document-level translation capabilities of LLMs on 10 language pairs,
effectively mitigating the sentence-level coverage issue in document-level
translation. Experimentation on discourse phenomena has demonstrated that our
document-level translation approach significantly improves translation quality,
both in terms of BLEU score and discourse coherence.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08089" title="Abstract">arXiv:2401.08089</a> [<a href="/pdf/2401.08089" title="Download PDF">pdf</a>, <a href="/format/2401.08089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study on Training and Developing Large Language Models for Behavior  Tree Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueying Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bin Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaodong Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This paper presents an innovative exploration of the application potential of
large language models (LLM) in addressing the challenging task of automatically
generating behavior trees (BTs) for complex tasks. The conventional manual BT
generation method is inefficient and heavily reliant on domain expertise. On
the other hand, existing automatic BT generation technologies encounter
bottlenecks related to task complexity, model adaptability, and reliability. In
order to overcome these challenges, we propose a novel methodology that
leverages the robust representation and reasoning abilities of LLMs. The core
contribution of this paper lies in the design of a BT generation framework
based on LLM, which encompasses the entire process, from data synthesis and
model training to application developing and data verification. Synthetic data
is introduced to train the BT generation model (BTGen model), enhancing its
understanding and adaptability to various complex tasks, thereby significantly
improving its overall performance. In order to ensure the effectiveness and
executability of the generated BTs, we emphasize the importance of data
verification and introduce a multilevel verification strategy. Additionally, we
explore a range of agent design and development schemes with LLM as the central
element. We hope that the work in this paper may provide a reference for the
researchers who are interested in BT generation based on LLMs.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08091" title="Abstract">arXiv:2401.08091</a> [<a href="/pdf/2401.08091" title="Download PDF">pdf</a>, <a href="/format/2401.08091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &#x27;One Style Does Not Regulate All&#x27;: Moderation Practices in Public and  Private WhatsApp Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahid%2C+F">Farhana Shahid</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+D">Dhruv Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Vashistha%2C+A">Aditya Vashistha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">WhatsApp is the largest social media platform in the Global South and is a
virulent force in global misinformation and political propaganda. Due to
end-to-end encryption WhatsApp can barely review any content and this often
pushes the responsibility of moderation towards group admins. Yet, little is
known about how WhatsApp group admins manage their groups, what factors and
values influence moderation decisions, and what challenges they face in
moderating their groups. To fill this gap, we interviewed admins of 32 diverse
groups and reviewed content from 30 public groups in India and Bangladesh. We
observed notable differences in the formation, members' behavior, and
moderation of public versus private groups, as well as in how WhatsApp admins
operate compared to those on other platforms. We used Baumrind's typology of
'parenting styles' as a lens to explore moderation practices in WhatsApp groups
and identified four moderation styles based on how responsive and controlling
the admins were and discuss design recommendations to help them better manage
problematic content in WhatsApp groups.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08092" title="Abstract">arXiv:2401.08092</a> [<a href="/pdf/2401.08092" title="Download PDF">pdf</a>, <a href="/format/2401.08092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Resource-efficient LLM and Multimodal Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+W">Wangsong Yin</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Dongqi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+R">Rongjie Yi</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Daliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qipeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bingyang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shihe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenyan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shangguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuanzhe Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Large foundation models, including large language models (LLMs), vision
transformers (ViTs), diffusion, and LLM-based multimodal models, are
revolutionizing the entire machine learning lifecycle, from training to
deployment. However, the substantial advancements in versatility and
performance these models offer come at a significant cost in terms of hardware
resources. To support the growth of these large models in a scalable and
environmentally sustainable way, there has been a considerable focus on
developing resource-efficient strategies. This survey delves into the critical
importance of such research, examining both algorithmic and systemic aspects.
It offers a comprehensive analysis and valuable insights gleaned from existing
literature, encompassing a broad array of topics from cutting-edge model
architectures and training/serving algorithms to practical system designs and
implementations. The goal of this survey is to provide an overarching
understanding of how current approaches are tackling the resource challenges
posed by large foundation models and to potentially inspire future
breakthroughs in this field.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08095" title="Abstract">arXiv:2401.08095</a> [<a href="/pdf/2401.08095" title="Download PDF">pdf</a>, <a href="/format/2401.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DurFlex-EVC: Duration-Flexible Emotional Voice Conversion with Parallel  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+H">Hyoung-Seok Oh</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+D">Deok-Hyun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seong-Whan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Emotional voice conversion (EVC) seeks to modify the emotional tone of a
speaker's voice while preserving the original linguistic content and the
speaker's unique vocal characteristics. Recent advancements in EVC have
involved the simultaneous modeling of pitch and duration, utilizing the
potential of sequence-to-sequence (seq2seq) models. To enhance reliability and
efficiency in conversion, this study shifts focus towards parallel speech
generation. We introduce Duration-Flexible EVC (DurFlex-EVC), which integrates
a style autoencoder and unit aligner. Traditional models, while incorporating
self-supervised learning (SSL) representations that contain both linguistic and
paralinguistic information, have neglected this dual nature, leading to reduced
controllability. Addressing this issue, we implement cross-attention to
synchronize these representations with various emotions. Additionally, a style
autoencoder is developed for the disentanglement and manipulation of style
elements. The efficacy of our approach is validated through both subjective and
objective evaluations, establishing its superiority over existing models in the
field.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08096" title="Abstract">arXiv:2401.08096</a> [<a href="/pdf/2401.08096" title="Download PDF">pdf</a>, <a href="/format/2401.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Disentangled Speech Representations with Contrastive Learning  and Time-Invariant Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yimin Deng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huaizhen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Voice conversion refers to transferring speaker identity with well-preserved
content. Better disentanglement of speech representations leads to better voice
conversion. Recent studies have found that phonetic information from input
audio has the potential ability to well represent content. Besides, the
speaker-style modeling with pre-trained models making the process more complex.
To tackle these issues, we introduce a new method named "CTVC" which utilizes
disentangled speech representations with contrastive learning and
time-invariant retrieval. Specifically, a similarity-based compression module
is used to facilitate a more intimate connection between the frame-level hidden
features and linguistic information at phoneme-level. Additionally, a
time-invariant retrieval is proposed for timbre extraction based on multiple
segmentations and mutual information. Experimental results demonstrate that
"CTVC" outperforms previous studies and improves the sound quality and
similarity of converted results.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08097" title="Abstract">arXiv:2401.08097</a> [<a href="/pdf/2401.08097" title="Download PDF">pdf</a>, <a href="/format/2401.08097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of Fairness Concerns in AI-based Mobile App Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nasab%2C+A+R">Ali Rezaei Nasab</a>, 
<a href="/search/cs?searchtype=author&query=Dashti%2C+M">Maedeh Dashti</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mansooreh Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Khalajzadeh%2C+H">Hourieh Khalajzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+C">Chetan Arora</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 images, 2 tables, Manuscript submitted to a Journal (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">With the growing application of AI-based systems in our lives and society,
there is a rising need to ensure that AI-based systems are developed and used
in a responsible way. Fairness is one of the socio-technical concerns that must
be addressed in AI-based systems for this purpose. Unfair AI-based systems,
particularly, unfair AI-based mobile apps, can pose difficulties for a
significant proportion of the global populace. This paper aims to deeply
analyze fairness concerns in AI-based app reviews. We first manually
constructed a ground-truth dataset including a statistical sample of fairness
and non-fairness reviews. Leveraging the ground-truth dataset, we then
developed and evaluated a set of machine learning and deep learning classifiers
that distinguish fairness reviews from non-fairness reviews. Our experiments
show that our best-performing classifier can detect fairness reviews with a
precision of 94%. We then applied the best-performing classifier on
approximately 9.5M reviews collected from 108 AI-based apps and identified
around 92K fairness reviews. While the fairness reviews appear in 23 app
categories, we found that the 'communication' and 'social' app categories have
the highest percentage of fairness reviews. Next, applying the K-means
clustering technique to the 92K fairness reviews, followed by manual analysis,
led to the identification of six distinct types of fairness concerns (e.g.,
'receiving different quality of features and services in different platforms
and devices' and 'lack of transparency and fairness in dealing with
user-generated content'). Finally, the manual analysis of 2,248 app owners'
responses to the fairness reviews identified six root causes (e.g., 'copyright
issues', 'external factors', 'development cost') that app owners report to
justify fairness concerns.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08099" title="Abstract">arXiv:2401.08099</a> [<a href="/pdf/2401.08099" title="Download PDF">pdf</a>, <a href="/format/2401.08099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inpainting Normal Maps for Lightstage data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+H">Hancheng Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Tiddeman%2C+B">Bernard Tiddeman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, CGVC Conference, The Eurographics Association
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Graphics and Visual Computing (CGVC), 2023, pp. 45-52
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">This study introduces a novel method for inpainting normal maps using a
generative adversarial network (GAN). Normal maps, often derived from a
lightstage, are crucial in performance capture but can have obscured areas due
to movement (e.g., by arms, hair, or props). Inpainting fills these missing
areas with plausible data. Our approach extends previous general image
inpainting techniques, employing a bow tie-like generator network and a
discriminator network, with alternating training phases. The generator aims to
synthesize images aligning with the ground truth and deceive the discriminator,
which differentiates between real and processed images. Periodically, the
discriminator undergoes retraining to enhance its ability to identify processed
images. Importantly, our method adapts to the unique characteristics of normal
map data, necessitating modifications to the loss function. We utilize a cosine
loss instead of mean squared error loss for generator training. Limited
training data availability, even with synthetic datasets, demands significant
augmentation, considering the specific nature of the input data. This includes
appropriate image flipping and in-plane rotations to accurately alter normal
vectors. Throughout training, we monitored key metrics such as average loss,
Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio
(PSNR) for the generator, along with average loss and accuracy for the
discriminator. Our findings suggest that the proposed model effectively
generates high-quality, realistic inpainted normal maps, suitable for
performance capture applications. These results establish a foundation for
future research, potentially involving more advanced networks and comparisons
with inpainting of source images used to create the normal maps.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08100" title="Abstract">arXiv:2401.08100</a> [<a href="/pdf/2401.08100" title="Download PDF">pdf</a>, <a href="/format/2401.08100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KTVIC: A Vietnamese Image Captioning Dataset on the Life Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+A">Anh-Cuong Pham</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+T">Thi-Hong Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Ha%2C+Q">Quang-Thuy Ha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Image captioning is a crucial task with applications in a wide range of
domains, including healthcare and education. Despite extensive research on
English image captioning datasets, the availability of such datasets for
Vietnamese remains limited, with only two existing datasets. In this study, we
introduce KTVIC, a comprehensive Vietnamese Image Captioning dataset focused on
the life domain, covering a wide range of daily activities. This dataset
comprises 4,327 images and 21,635 Vietnamese captions, serving as a valuable
resource for advancing image captioning in the Vietnamese language. We conduct
experiments using various deep neural networks as the baselines on our dataset,
evaluating them using the standard image captioning metrics, including BLEU,
METEOR, CIDEr, and ROUGE. Our findings underscore the effectiveness of the
proposed dataset and its potential contributions to the field of image
captioning in the Vietnamese context.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08102" title="Abstract">arXiv:2401.08102</a> [<a href="/pdf/2401.08102" title="Download PDF">pdf</a>, <a href="/format/2401.08102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DIFFRENT: A Diffusion Model for Recording Environment Transfer of Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Im%2C+J">Jaekwon Im</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+J">Juhan Nam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Properly setting up recording conditions, including microphone type and
placement, room acoustics, and ambient noise, is essential to obtaining the
desired acoustic characteristics of speech. In this paper, we propose
Diff-R-EN-T, a Diffusion model for Recording ENvironment Transfer which
transforms the input speech to have the recording conditions of a reference
speech while preserving the speech content. Our model comprises the content
enhancer, the recording environment encoder, and the diffusion decoder which
generates the target mel-spectrogram by utilizing both enhancer and encoder as
input conditions. We evaluate DiffRENT in the speech enhancement and acoustic
matching scenarios. The results show that DiffRENT generalizes well to unseen
environments and new speakers. Also, the proposed model achieves superior
performances in objective and subjective evaluation. Sound examples of our
proposed model are available online.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08103" title="Abstract">arXiv:2401.08103</a> [<a href="/pdf/2401.08103" title="Download PDF">pdf</a>, <a href="/format/2401.08103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving Ethics Trade-offs in Implementing Responsible AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+C">Conrad Sanderson</a>, 
<a href="/search/cs?searchtype=author&query=Schleiger%2C+E">Emma Schleiger</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+D">David Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Kuhnert%2C+P">Petra Kuhnert</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While the operationalisation of high-level AI ethics principles into
practical AI/ML systems has made progress, there is still a theory-practice gap
in managing tensions between the underlying AI ethics aspects. We cover five
approaches for addressing the tensions via trade-offs, ranging from rudimentary
to complex. The approaches differ in the types of considered context, scope,
methods for measuring contexts, and degree of justification. None of the
approaches is likely to be appropriate for all organisations, systems, or
applications. To address this, we propose a framework which consists of: (i)
proactive identification of tensions, (ii) prioritisation and weighting of
ethics aspects, (iii) justification and documentation of trade-off decisions.
The proposed framework aims to facilitate the implementation of well-rounded
AI/ML systems that are appropriate for potential regulatory requirements.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08104" title="Abstract">arXiv:2401.08104</a> [<a href="/pdf/2401.08104" title="Download PDF">pdf</a>, <a href="/format/2401.08104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reproducibility Study of Goldilocks: Just-Right Tuning of BERT for TAR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+X">Xinyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Koopman%2C+B">Bevan Koopman</a>, 
<a href="/search/cs?searchtype=author&query=Zuccon%2C+G">Guido Zuccon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECIR 2024 (reproducibility)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Screening documents is a tedious and time-consuming aspect of high-recall
retrieval tasks, such as compiling a systematic literature review, where the
goal is to identify all relevant documents for a topic. To help streamline this
process, many Technology-Assisted Review (TAR) methods leverage active learning
techniques to reduce the number of documents requiring review. BERT-based
models have shown high effectiveness in text classification, leading to
interest in their potential use in TAR workflows. In this paper, we investigate
recent work that examined the impact of further pre-training epochs on the
effectiveness and efficiency of a BERT-based active learning pipeline. We first
report that we could replicate the original experiments on two specific TAR
datasets, confirming some of the findings: importantly, that further
pre-training is critical to high effectiveness, but requires attention in terms
of selecting the correct training epoch. We then investigate the
generalisability of the pipeline on a different TAR task, that of medical
systematic reviews. In this context, we show that there is no need for further
pre-training if a domain-specific BERT backbone is used within the active
learning pipeline. This finding provides practical implications for using the
studied active learning pipeline within domain-specific TAR tasks.
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08105" title="Abstract">arXiv:2401.08105</a> [<a href="/pdf/2401.08105" title="Download PDF">pdf</a>, <a href="/format/2401.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Briley%2C+A">Austin Briley</a>, 
<a href="/search/cs?searchtype=author&query=Afghah%2C+F">Fatemeh Afghah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures, NETROBOTICS conference submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Early wildfire detection in remote and forest areas is crucial for minimizing
devastation and preserving ecosystems. Autonomous drones offer agile access to
remote, challenging terrains, equipped with advanced imaging technology that
delivers both high-temporal and detailed spatial resolution, making them
valuable assets in the early detection and monitoring of wildfires. However,
the limited computation and battery resources of Unmanned Aerial Vehicles
(UAVs) pose significant challenges in implementing robust and efficient image
classification models. Current works in this domain often operate offline,
emphasizing the need for solutions that can perform inference in real time,
given the constraints of UAVs. To address these challenges, this paper aims to
develop a real-time image classification and fire segmentation model. It
presents a comprehensive investigation into hardware acceleration using the
Jetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance
deep-learning inference library, on fire classification accuracy and speed. The
study includes implementations of Quantization Aware Training (QAT), Automatic
Mixed Precision (AMP), and post-training mechanisms, comparing them against the
latest baselines for fire segmentation and classification. All experiments
utilize the FLAME dataset - an image dataset collected by low-altitude drones
during a prescribed forest fire. This work contributes to the ongoing efforts
to enable real-time, on-board wildfire detection capabilities for UAVs,
addressing speed and the computational and energy constraints of these crucial
monitoring systems. The results show a 13% increase in classification speed
compared to similar models without hardware optimization. Comparatively, loss
and accuracy are within 1.225% of the original values.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08107" title="Abstract">arXiv:2401.08107</a> [<a href="/pdf/2401.08107" title="Download PDF">pdf</a>, <a href="/format/2401.08107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Shape-Texture Statistics for Completely Blind Image Quality  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peilin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hanwei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+K">Keyan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leida Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Opinion-Unaware Blind Image Quality Assessment (OU-BIQA) models aim to
predict image quality without training on reference images and subjective
quality scores. Thereinto, image statistical comparison is a classic paradigm,
while the performance is limited by the representation ability of visual
descriptors. Deep features as visual descriptors have advanced IQA in recent
research, but they are discovered to be highly texture-biased and lack of
shape-bias. On this basis, we find out that image shape and texture cues
respond differently towards distortions, and the absence of either one results
in an incomplete image representation. Therefore, to formulate a well-round
statistical description for images, we utilize the shapebiased and
texture-biased deep features produced by Deep Neural Networks (DNNs)
simultaneously. More specifically, we design a Shape-Texture Adaptive Fusion
(STAF) module to merge shape and texture information, based on which we
formulate qualityrelevant image statistics. The perceptual quality is
quantified by the variant Mahalanobis Distance between the inner and outer
Shape-Texture Statistics (DSTS), wherein the inner and outer statistics
respectively describe the quality fingerprints of the distorted image and
natural images. The proposed DSTS delicately utilizes shape-texture statistical
relations between different data scales in the deep domain, and achieves
state-of-the-art (SOTA) quality prediction performance on images with
artificial and authentic distortions.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08111" title="Abstract">arXiv:2401.08111</a> [<a href="/pdf/2401.08111" title="Download PDF">pdf</a>, <a href="/format/2401.08111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mobile Contactless Palmprint Recognition: Use of Multiscale, Multimodel  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grosz%2C+S+A">Steven A. Grosz</a>, 
<a href="/search/cs?searchtype=author&query=Godbole%2C+A">Akash Godbole</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A+K">Anil K. Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contactless palmprints are comprised of both global and local discriminative
features. Most prior work focuses on extracting global features or local
features alone for palmprint matching, whereas this research introduces a novel
framework that combines global and local features for enhanced palmprint
matching accuracy. Leveraging recent advancements in deep learning, this study
integrates a vision transformer (ViT) and a convolutional neural network (CNN)
to extract complementary local and global features. Next, a mobile-based,
end-to-end palmprint recognition system is developed, referred to as Palm-ID.
On top of the ViT and CNN features, Palm-ID incorporates a palmprint
enhancement module and efficient dimensionality reduction (for faster
matching). Palm-ID balances the trade-off between accuracy and latency,
requiring just 18ms to extract a template of size 516 bytes, which can be
efficiently searched against a 10,000 palmprint gallery in 0.33ms on an AMD
EPYC 7543 32-Core CPU utilizing 128-threads. Cross-database matching protocols
and evaluations on large-scale operational datasets demonstrate the robustness
of the proposed method, achieving a TAR of 98.06% at FAR=0.01% on a newly
collected, time-separated dataset. To show a practical deployment of the
end-to-end system, the entire recognition pipeline is embedded within a mobile
device for enhanced user privacy and security.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08115" title="Abstract">arXiv:2401.08115</a> [<a href="/pdf/2401.08115" title="Download PDF">pdf</a>, <a href="/format/2401.08115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> No-Clean-Reference Image Super-Resolution: Application to Electron  Microscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khateri%2C+M">Mohammad Khateri</a>, 
<a href="/search/cs?searchtype=author&query=Ghahremani%2C+M">Morteza Ghahremani</a>, 
<a href="/search/cs?searchtype=author&query=Sierra%2C+A">Alejandra Sierra</a>, 
<a href="/search/cs?searchtype=author&query=Tohka%2C+J">Jussi Tohka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 12 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The inability to acquire clean high-resolution (HR) electron microscopy (EM)
images over a large brain tissue volume hampers many neuroscience studies. To
address this challenge, we propose a deep-learning-based image super-resolution
(SR) approach to computationally reconstruct clean HR 3D-EM with a large field
of view (FoV) from noisy low-resolution (LR) acquisition. Our contributions are
I) Investigating training with no-clean references for $\ell_2$ and $\ell_1$
loss functions; II) Introducing a novel network architecture, named EMSR, for
enhancing the resolution of LR EM images while reducing inherent noise; and,
III) Comparing different training strategies including using acquired LR and HR
image pairs, i.e., real pairs with no-clean references contaminated with real
corruptions, the pairs of synthetic LR and acquired HR, as well as acquired LR
and denoised HR pairs. Experiments with nine brain datasets showed that
training with real pairs can produce high-quality super-resolved results,
demonstrating the feasibility of training with non-clean references for both
loss functions. Additionally, comparable results were observed, both visually
and numerically, when employing denoised and noisy references for training.
Moreover, utilizing the network trained with synthetically generated LR images
from HR counterparts proved effective in yielding satisfactory SR results, even
in certain cases, outperforming training with real pairs. The proposed SR
network was compared quantitatively and qualitatively with several established
SR techniques, showcasing either the superiority or competitiveness of the
proposed method in mitigating noise while recovering fine details.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08117" title="Abstract">arXiv:2401.08117</a> [<a href="/pdf/2401.08117" title="Download PDF">pdf</a>, <a href="/format/2401.08117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E2HQV: High-Quality Video Generation from Event Camera via  Theory-Inspired Model-Aided Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+Q">Qiang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yiran Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y+Y">Yuk Ying Chung</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongliang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The bio-inspired event cameras or dynamic vision sensors are capable of
asynchronously capturing per-pixel brightness changes (called event-streams) in
high temporal resolution and high dynamic range. However, the non-structural
spatial-temporal event-streams make it challenging for providing intuitive
visualization with rich semantic information for human vision. It calls for
events-to-video (E2V) solutions which take event-streams as input and generate
high quality video frames for intuitive visualization. However, current
solutions are predominantly data-driven without considering the prior knowledge
of the underlying statistics relating event-streams and video frames. It highly
relies on the non-linearity and generalization capability of the deep neural
networks, thus, is struggling on reconstructing detailed textures when the
scenes are complex. In this work, we propose \textbf{E2HQV}, a novel E2V
paradigm designed to produce high-quality video frames from events. This
approach leverages a model-aided deep learning framework, underpinned by a
theory-inspired E2V model, which is meticulously derived from the fundamental
imaging principles of event cameras. To deal with the issue of state-reset in
the recurrent components of E2HQV, we also design a temporal shift embedding
module to further improve the quality of the video frames. Comprehensive
evaluations on the real world event camera datasets validate our approach, with
E2HQV, notably outperforming state-of-the-art approaches, e.g., surpassing the
second best by over 40\% for some evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08119" title="Abstract">arXiv:2401.08119</a> [<a href="/pdf/2401.08119" title="Download PDF">pdf</a>, <a href="/format/2401.08119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic  Spatio-Temporal Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lequan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Andi Han</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic forecasting, a crucial application of spatio-temporal graph (STG)
learning, has traditionally relied on deterministic models for accurate point
estimations. Yet, these models fall short of identifying latent risks of
unexpected volatility in future observations. To address this gap,
probabilistic methods, especially variants of diffusion models, have emerged as
uncertainty-aware solutions. However, existing diffusion methods typically
focus on generating separate future time series for individual sensors in the
traffic network, resulting in insufficient involvement of spatial network
characteristics in the probabilistic learning process. To better leverage
spatial dependencies and systematic patterns inherent in traffic data, we
propose SpecSTG, a novel spectral diffusion framework. Our method generates the
Fourier representation of future time series, transforming the learning process
into the spectral domain enriched with spatial information. Additionally, our
approach incorporates a fast spectral graph convolution designed for Fourier
input, alleviating the computational burden associated with existing models.
Numerical experiments show that SpecSTG achieves outstanding performance with
traffic flow and traffic speed datasets compared to state-of-the-art baselines.
The source code for SpecSTG is available at
https://anonymous.4open.science/r/SpecSTG.
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08120" title="Abstract">arXiv:2401.08120</a> [<a href="/pdf/2401.08120" title="Download PDF">pdf</a>, <a href="/ps/2401.08120" title="Download PostScript">ps</a>, <a href="/format/2401.08120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operation Scheme Optimizations to Achieve Ultra-high Endurance (1010) in  Flash Memory with Robust Reliabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Z">Zhaohui Sun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+X">Xinyi Guo</a>, 
<a href="/search/eess?searchtype=author&query=Mei%2C+J">Junyao Mei</a>, 
<a href="/search/eess?searchtype=author&query=Qi%2C+Y">Yueran Qi</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Junyu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jixuan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhan%2C+X">Xuepeng Zhan</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiezhi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Flash memory has been widely adopted as stand-alone memory and embedded
memory due to its robust reliability. However, the limited endurance obstacles
its further applications in storage class memory (SCM) and to proceed
endurance-required computing-in-memory (CIM) tasks. In this work, the
optimization strategies have been studied to tackle this concern. It is shown
that by adopting the channel hot electrons injection (CHEI) and hot hole
injection (HHI) to implement program/erase (PE) cycling together with a
balanced memory window (MW) at the high-Vth (HV) mode, impressively, the
endurance can be greatly extended to 1010 PE cycles, which is a record-high
value in flash memory. Moreover, by using the proposed electric-field-assisted
relaxation (EAR) scheme, the degradation of flash cells can be well suppressed
with better subthreshold swings (SS) and lower leakage currents (sub-10pA after
1010 PE cycles). Our results shed light on the optimization strategy of flash
memory to serve as SCM and implementendurance-required CIM tasks.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08121" title="Abstract">arXiv:2401.08121</a> [<a href="/pdf/2401.08121" title="Download PDF">pdf</a>, <a href="/format/2401.08121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CycLight: learning traffic signal cooperation with a cycle-level  strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+G">Gengyue Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xianyue Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yu Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">This study introduces CycLight, a novel cycle-level deep reinforcement
learning (RL) approach for network-level adaptive traffic signal control
(NATSC) systems. Unlike most traditional RL-based traffic controllers that
focus on step-by-step decision making, CycLight adopts a cycle-level strategy,
optimizing cycle length and splits simultaneously using Parameterized Deep
Q-Networks (PDQN) algorithm. This cycle-level approach effectively reduces the
computational burden associated with frequent data communication, meanwhile
enhancing the practicality and safety of real-world applications. A
decentralized framework is formulated for multi-agent cooperation, while
attention mechanism is integrated to accurately assess the impact of the
surroundings on the current intersection. CycLight is tested in a large
synthetic traffic grid using the microscopic traffic simulation tool, SUMO.
Experimental results not only demonstrate the superiority of CycLight over
other state-of-the-art approaches but also showcase its robustness against
information transmission delays.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08123" title="Abstract">arXiv:2401.08123</a> [<a href="/pdf/2401.08123" title="Download PDF">pdf</a>, <a href="/format/2401.08123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil is in the Details: Boosting Guided Depth Super-Resolution via  Rethinking Cross-Modal Alignment and Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinni Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zengsheng Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chunle Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruixun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L">Lei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chongyi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Guided depth super-resolution (GDSR) involves restoring missing depth details
using the high-resolution RGB image of the same scene. Previous approaches have
struggled with the heterogeneity and complementarity of the multi-modal inputs,
and neglected the issues of modal misalignment, geometrical misalignment, and
feature selection. In this study, we rethink some essential components in GDSR
networks and propose a simple yet effective Dynamic Dual Alignment and
Aggregation network (D2A2). D2A2 mainly consists of 1) a dynamic dual alignment
module that adapts to alleviate the modal misalignment via a learnable domain
alignment block and geometrically align cross-modal features by learning the
offset; and 2) a mask-to-pixel feature aggregate module that uses the gated
mechanism and pixel attention to filter out irrelevant texture noise from RGB
features and combine the useful features with depth features. By combining the
strengths of RGB and depth features while minimizing disturbance introduced by
the RGB image, our method with simple reuse and redesign of basic components
achieves state-of-the-art performance on multiple benchmark datasets. The code
is available at https://github.com/JiangXinni/D2A2.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08124" title="Abstract">arXiv:2401.08124</a> [<a href="/pdf/2401.08124" title="Download PDF">pdf</a>, <a href="/format/2401.08124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale Epidemic Simulation Framework for Realistic Social Contact  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitson%2C+J">Joy Kitson</a>, 
<a href="/search/cs?searchtype=author&query=Costello%2C+I">Ian Costello</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiangzhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez%2C+D">Diego Jim&#xe9;nez</a>, 
<a href="/search/cs?searchtype=author&query=Hoops%2C+S">Stefan Hoops</a>, 
<a href="/search/cs?searchtype=author&query=Mortveit%2C+H">Henning Mortveit</a>, 
<a href="/search/cs?searchtype=author&query=Meneses%2C+E">Esteban Meneses</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J">Jae-Seung Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Marathe%2C+M+V">Madhav V. Marathe</a>, 
<a href="/search/cs?searchtype=author&query=Bhatele%2C+A">Abhinav Bhatele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages (including references), 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Global pandemics can wreak havoc and lead to significant social, economic,
and personal losses. Preventing the spread of infectious diseases requires
implementing interventions at different levels of government, and evaluating
the potential impact and efficacy of those preemptive measures. Agent-based
modeling can be used for detailed studies of epidemic diffusion and possible
interventions. We present Loimos, a highly parallel simulation of epidemic
diffusion written on top of Charm++, an asynchronous task-based parallel
runtime. Loimos uses a hybrid of time-stepping and discrete-event simulation to
model disease spread. We demonstrate that our implementation of Loimos is able
to scale to large core counts on an HPC system. In particular, Loimos is able
to simulate a US-scale synthetic interaction network in an average of 1.497
seconds per simulation day when executed on 16 nodes on Rivanna at the
University of Virginia, processing around 428 billion interactions
(person-person edges) in under five minutes for an average of 1.4 billion
traversed edges per second (TEPS).
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08126" title="Abstract">arXiv:2401.08126</a> [<a href="/pdf/2401.08126" title="Download PDF">pdf</a>, <a href="/format/2401.08126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Octopus: A Fair Packet Delivery Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Junzhi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+D">Devdeep Ray</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+K">KK Yap</a>, 
<a href="/search/cs?searchtype=author&query=Dukkipati%2C+N">Nandita Dukkipati</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The packet delivery fairness is critical in many applications in the cloud,
such as exchange systems, consensus protocols, and online gaming applications.
However, due to nonidentical and dynamic packet forwarding paths, as well as
many in-network queuing delays, supporting packet delivery fairness is
challenging in a shared compute environment. In this paper, we present Octopus,
the first general fair packet delivery service to achieve packet arrival time
variations smaller than tens of nanoseconds, with the existence of latency
variations in the network. The key ideas of Octopus to support such good
fairness come from repurposing hardware traffic shaping capabilities in modern
NICs, and deploying agents at local SmartNICs to minimize latency variations
from packet forwarding. Evaluation results show that Octopus has less than 40
ns unfairness for up to 99.97\% multicast packets.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08127" title="Abstract">arXiv:2401.08127</a> [<a href="/pdf/2401.08127" title="Download PDF">pdf</a>, <a href="/ps/2401.08127" title="Download PostScript">ps</a>, <a href="/format/2401.08127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framework and Classification of Indicator of Compromise for  physics-based attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+V">Vincent Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-print is submitted to 2024 IEEE World Forum on Public Safety Technology, and is under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">Quantum communications are based on the law of physics for information
security and the implications for this form of future information security
enabled by quantum science has to be studied. Physics-based vulnerabilities may
exist due to the inherent physics properties and behavior of quantum
technologies such as Quantum Key Distribution (QKD), thus resulting in new
threats that may emerge with attackers exploiting the physics-based
vulnerabilities. There were many studies and experiments done to demonstrate
the threat of physics-based attacks on quantum links. However, there is a lack
of a framework that provides a common language to communicate about the threats
and type of adversaries being dealt with for physics-based attacks. This paper
is a review of physics-based attacks that were being investigated and attempt
to initialize a framework based on the attack objectives and methodologies,
referencing the concept from the well-established MITRE ATT&amp;CK, therefore
pioneering the classification of Indicator of Compromises (IoCs) for
physics-based attacks. This paper will then pave the way for future work in the
development of a forensic tool for the different classification of IoCs, with
the methods of evidence collections and possible points of extractions for
analysis being further investigated.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08131" title="Abstract">arXiv:2401.08131</a> [<a href="/pdf/2401.08131" title="Download PDF">pdf</a>, <a href="/format/2401.08131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game Rewards Vulnerabilities: Software Vulnerability Detection with  Zero-Sum Game and Prototype Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+X">Xin-Cheng Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Recent years have witnessed a growing focus on automated software
vulnerability detection. Notably, deep learning (DL)-based methods, which
employ source code for the implicit acquisition of vulnerability patterns, have
demonstrated superior performance compared to other approaches. However, the
DL-based approaches are still hard to capture the vulnerability-related
information from the whole code snippet, since the vulnerable parts usually
account for only a small proportion. As evidenced by our experiments, the
approaches tend to excessively emphasize semantic information, potentially
leading to limited vulnerability detection performance in practical scenarios.
First, they cannot well distinguish between the code snippets before (i.e.,
vulnerable code) and after (i.e., non-vulnerable code) developers' fixes due to
the minimal code changes. Besides, substituting user-defined identifiers with
placeholders (e.g., "VAR1" and "FUN1") in obvious performance degradation at up
to 14.53% with respect to the F1 score. To mitigate these issues, we propose to
leverage the vulnerable and corresponding fixed code snippets, in which the
minimal changes can provide hints about semantic-agnostic features for
vulnerability detection. In this paper, we propose a software vulneRability
dEteCtion framework with zerO-sum game and prototype learNing, named RECON. In
RECON, we propose a zero-sum game construction module. Distinguishing the
vulnerable code from the corresponding fixed code is regarded as one player
(i.e. Calibrator), while the conventional vulnerability detection is another
player (i.e. Detector) in the zero-sum game. The goal is to capture the
semantic-agnostic features of the first player for enhancing the second
player's performance for vulnerability detection. Experiments on the public
benchmark dataset show that RECON outperforms the state-of-the-art baseline by
6.29% in F1 score.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08132" title="Abstract">arXiv:2401.08132</a> [<a href="/pdf/2401.08132" title="Download PDF">pdf</a>, <a href="/format/2401.08132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Oriented Semantic Mapping for Reliable UAVs Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canh%2C+T+N">Thanh Nguyen Canh</a>, 
<a href="/search/cs?searchtype=author&query=Elibol%2C+A">Armagan Elibol</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+N+Y">Nak Young Chong</a>, 
<a href="/search/cs?searchtype=author&query=HoangVan%2C+X">Xiem HoangVan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the 12th International Conference on Control, Automation and Information Sciences (ICCAIS 2023), Hanoi, Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">To autonomously navigate in real-world environments, special in search and
rescue operations, Unmanned Aerial Vehicles (UAVs) necessitate comprehensive
maps to ensure safety. However, the prevalent metric map often lacks semantic
information crucial for holistic scene comprehension. In this paper, we
proposed a system to construct a probabilistic metric map enriched with object
information extracted from the environment from RGB-D images. Our approach
combines a state-of-the-art YOLOv8-based object detection framework at the
front end and a 2D SLAM method - CartoGrapher at the back end. To effectively
track and position semantic object classes extracted from the front-end
interface, we employ the innovative BoT-SORT methodology. A novel association
method is introduced to extract the position of objects and then project it
with the metric map. Unlike previous research, our approach takes into reliable
navigating in the environment with various hollow bottom objects. The output of
our system is a probabilistic map, which significantly enhances the map's
representation by incorporating object-specific attributes, encompassing class
distinctions, accurate positioning, and object heights. A number of experiments
have been conducted to evaluate our proposed approach. The results show that
the robot can effectively produce augmented semantic maps containing several
objects (notably chairs and desks). Furthermore, our system is evaluated within
an embedded computer - Jetson Xavier AGX unit to demonstrate the use case in
real-world applications.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08134" title="Abstract">arXiv:2401.08134</a> [<a href="/pdf/2401.08134" title="Download PDF">pdf</a>, <a href="/format/2401.08134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S3M: Semantic Segmentation Sparse Mapping for UAVs with RGB-D Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canh%2C+T+N">Thanh Nguyen Canh</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+V">Van-Truong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=HoangVan%2C+X">Xiem HoangVan</a>, 
<a href="/search/cs?searchtype=author&query=Elibol%2C+A">Armagan Elibol</a>, 
<a href="/search/cs?searchtype=author&query=Chong%2C+N+Y">Nak Young Chong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In The 2024 IEEE/SICE International Symposium on System Integration (SII2024), Ha Long, Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs) hold immense potential for critical
applications, such as search and rescue operations, where accurate perception
of indoor environments is paramount. However, the concurrent amalgamation of
localization, 3D reconstruction, and semantic segmentation presents a notable
hurdle, especially in the context of UAVs equipped with constrained power and
computational resources. This paper presents a novel approach to address
challenges in semantic information extraction and utilization within UAV
operations. Our system integrates state-of-the-art visual SLAM to estimate a
comprehensive 6-DoF pose and advanced object segmentation methods at the back
end. To improve the computational and storage efficiency of the framework, we
adopt a streamlined voxel-based 3D map representation - OctoMap to build a
working system. Furthermore, the fusion algorithm is incorporated to obtain the
semantic information of each frame from the front-end SLAM task, and the
corresponding point. By leveraging semantic information, our framework enhances
the UAV's ability to perceive and navigate through indoor spaces, addressing
challenges in pose estimation accuracy and uncertainty reduction. Through
Gazebo simulations, we validate the efficacy of our proposed system and
successfully embed our approach into a Jetson Xavier AGX unit for real-world
applications.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08135" title="Abstract">arXiv:2401.08135</a> [<a href="/pdf/2401.08135" title="Download PDF">pdf</a>, <a href="/format/2401.08135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-Based Malicious Vehicle Detection for Security Threats  and Attacks in Vehicle Ad-hoc Network (VANET) Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canh%2C+T+N">Thanh Nguyen Canh</a>, 
<a href="/search/cs?searchtype=author&query=HoangVan%2C+X">Xiem HoangVan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In the 2023 RIVF International Conference on Computing and Communication Technologies, Hanoi, Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">With the rapid growth of Vehicle Ad-hoc Network (VANET) as a promising
technology for efficient and reliable communication among vehicles and
infrastructure, the security and integrity of VANET communications has become a
critical concern. One of the significant threats to VANET is the presence of
blackhole attacks, where malicious nodes disrupt the network's functionality
and compromise data confidentiality, integrity, and availability. In this
paper, we propose a machine learning-based approach for blackhole detection in
VANET. To achieve this task, we first create a comprehensive dataset comprising
normal and malicious traffic flows. Afterward, we study and define a promising
set of features to discriminate the blackhole attacks. Finally, we evaluate
various machine learning algorithms, including Gradient Boosting, Random
Forest, Support Vector Machines, k-Nearest Neighbors, Gaussian Naive Bayes, and
Logistic Regression. Experimental results demonstrate the effectiveness of
these algorithms in distinguishing between normal and malicious nodes. Our
findings also highlight the potential of machine learning based approach in
enhancing the security of VANET by detecting and mitigating blackhole attacks.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08136" title="Abstract">arXiv:2401.08136</a> [<a href="/pdf/2401.08136" title="Download PDF">pdf</a>, <a href="/format/2401.08136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias-Compensated State of Charge and State of Health Joint Estimation  for Lithium Iron Phosphate Batteries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yi%2C+B">Baozhao Yi</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+X">Xinhao Du</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaogang Wu</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Q">Qiuhao Hu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Weiran Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+X">Xiaosong Hu</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Ziyou Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages and 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Accurate estimation of the state of charge (SOC) and state of health (SOH) is
crucial for the safe and reliable operation of batteries. However, the
measurement bias of voltage can highly deteriorate the estimation accuracy. One
such example is the lithium iron phosphate (LFP) battery, which is highly prone
to suffer from this issue owing to its flat open-circuit voltage curve. This
work proposes a bias-compensated framework that reliably estimates the SOC and
SOH of LFP batteries under the influence of voltage measurement bias. To
validate the proposed approach, four LFP batteries are tested at various
ambient temperatures and SOH conditions, with two different values of voltage
measurement bias added. The results show that the bias-compensated algorithm
achieves test errors that are less than 1.5% and 2% for SOC and SOH estimation,
respectively. Additionally, the proposed approach outperforms the traditional
estimation method that ignores the effects of voltage measurement bias.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08138" title="Abstract">arXiv:2401.08138</a> [<a href="/pdf/2401.08138" title="Download PDF">pdf</a>, <a href="/format/2401.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs for Test Input Generation for Semantic Caches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasool%2C+Z">Zafaryab Rasool</a>, 
<a href="/search/cs?searchtype=author&query=Barnett%2C+S">Scott Barnett</a>, 
<a href="/search/cs?searchtype=author&query=Willie%2C+D">David Willie</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+S">Stefanus Kurniawan</a>, 
<a href="/search/cs?searchtype=author&query=Balugo%2C+S">Sherwin Balugo</a>, 
<a href="/search/cs?searchtype=author&query=Thudumu%2C+S">Srikanth Thudumu</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrazek%2C+M">Mohamed Abdelrazek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in International Conference on AI Engineering Software Engineering (CAIN 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) enable state-of-the-art semantic capabilities to
be added to software systems such as semantic search of unstructured documents
and text generation. However, these models are computationally expensive. At
scale, the cost of serving thousands of users increases massively affecting
also user experience. To address this problem, semantic caches are used to
check for answers to similar queries (that may have been phrased differently)
without hitting the LLM service. Due to the nature of these semantic cache
techniques that rely on query embeddings, there is a high chance of errors
impacting user confidence in the system. Adopting semantic cache techniques
usually requires testing the effectiveness of a semantic cache (accurate cache
hits and misses) which requires a labelled test set of similar queries and
responses which is often unavailable. In this paper, we present VaryGen, an
approach for using LLMs for test input generation that produces similar
questions from unstructured text documents. Our novel approach uses the
reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise
subtle variations to queries, and 3) evaluate the synthesised test dataset. We
evaluated our approach in the domain of a student question and answer system by
qualitatively analysing 100 generated queries and result pairs, and conducting
an empirical case study with an open source semantic cache. Our results show
that query pairs satisfy human expectations of similarity and our generated
data demonstrates failure cases of a semantic cache. Additionally, we also
evaluate our approach on Qasper dataset. This work is an important first step
into test input generation for semantic applications and presents
considerations for practitioners when calibrating a semantic cache.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08139" title="Abstract">arXiv:2401.08139</a> [<a href="/pdf/2401.08139" title="Download PDF">pdf</a>, <a href="/format/2401.08139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferring Core Knowledge via Learngenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+F">Fu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The pre-training paradigm fine-tunes the models trained on large-scale
datasets to downstream tasks with enhanced performance. It transfers all
knowledge to downstream tasks without discriminating which part is necessary or
unnecessary, which may lead to negative transfer. In comparison, knowledge
transfer in nature is much more efficient. When passing genetic information to
descendants, ancestors encode only the essential knowledge into genes, which
act as the medium. Inspired by that, we adopt a recent concept called
``learngene'' and refine its structures by mimicking the structures of natural
genes. We propose the Genetic Transfer Learning (GTL) -- a framework to copy
the evolutionary process of organisms into neural networks. GTL trains a
population of networks, selects superior learngenes by tournaments, performs
learngene mutations, and passes the learngenes to next generations. Finally, we
successfully extract the learngenes of VGG11 and ResNet12. We show that the
learngenes bring the descendant networks instincts and strong learning ability:
with 20% parameters, the learngenes bring 12% and 16% improvements of accuracy
on CIFAR-FS and miniImageNet. Besides, the learngenes have the scalability and
adaptability on the downstream structure of networks and datasets. Overall, we
offer a novel insight that transferring core knowledge via learngenes may be
sufficient and efficient for neural networks.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08140" title="Abstract">arXiv:2401.08140</a> [<a href="/pdf/2401.08140" title="Download PDF">pdf</a>, <a href="/format/2401.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nakayama%2C+K">Kiyohiro Nakayama</a>, 
<a href="/search/cs?searchtype=author&query=Uy%2C+M+A">Mikaela Angelina Uy</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+Y">Yang You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/cs?searchtype=author&query=Guibas%2C+L">Leonidas Guibas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural radiance fields (NeRFs) have gained popularity across various
applications. However, they face challenges in the sparse view setting, lacking
sufficient constraints from volume rendering. Reconstructing and understanding
a 3D scene from sparse and unconstrained cameras is a long-standing problem in
classical computer vision with diverse applications. While recent works have
explored NeRFs in sparse, unconstrained view scenarios, their focus has been
primarily on enhancing reconstruction and novel view synthesis. Our approach
takes a broader perspective by posing the question: "from where has each point
been seen?" -- which gates how well we can understand and reconstruct it. In
other words, we aim to determine the origin or provenance of each 3D point and
its associated information under sparse, unconstrained views. We introduce
ProvNeRF, a model that enriches a traditional NeRF representation by
incorporating per-point provenance, modeling likely source locations for each
point. We achieve this by extending implicit maximum likelihood estimation
(IMLE) for stochastic processes. Notably, our method is compatible with any
pre-trained NeRF model and the associated training camera poses. We demonstrate
that modeling per-point provenance offers several advantages, including
uncertainty estimation, criteria-based view selection, and improved novel view
synthesis, compared to state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08141" title="Abstract">arXiv:2401.08141</a> [<a href="/pdf/2401.08141" title="Download PDF">pdf</a>, <a href="/format/2401.08141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IoTWarden: A Deep Reinforcement Learning Based Real-time Defense System  to Mitigate Trigger-action IoT Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+M">Md Morshed Alam</a> (1), 
<a href="/search/cs?searchtype=author&query=Jahan%2C+I">Israt Jahan</a> (2), 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weichao Wang</a> (1) ((1) Department of Software and Information Systems, University of North Carolina at Charlotte, Charlotte, USA, (2) Department of Computer Science, University of Memphis, Memphis, USA)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 IEEE Wireless Communications and Networking Conference (WCNC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In trigger-action IoT platforms, IoT devices report event conditions to IoT
hubs notifying their cyber states and let the hubs invoke actions in other IoT
devices based on functional dependencies defined as rules in a rule engine.
These functional dependencies create a chain of interactions that help automate
network tasks. Adversaries exploit this chain to report fake event conditions
to IoT hubs and perform remote injection attacks upon a smart environment to
indirectly control targeted IoT devices. Existing defense efforts usually
depend on static analysis over IoT apps to develop rule-based anomaly detection
mechanisms. We also see ML-based defense mechanisms in the literature that
harness physical event fingerprints to determine anomalies in an IoT network.
However, these methods often demonstrate long response time and lack of
adaptability when facing complicated attacks. In this paper, we propose to
build a deep reinforcement learning based real-time defense system for
injection attacks. We define the reward functions for defenders and implement a
deep Q-network based approach to identify the optimal defense policy. Our
experiments show that the proposed mechanism can effectively and accurately
identify and defend against injection attacks with reasonable computation
overhead.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08144" title="Abstract">arXiv:2401.08144</a> [<a href="/pdf/2401.08144" title="Download PDF">pdf</a>, <a href="/format/2401.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Stackelberg Equilibrium Seeking for Networked Multi-Leader  Multi-Follower Games with A Clustered Information Structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yue Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+P">Peng Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The Stackelberg game depicts a leader-follower relationship wherein decisions
are made sequentially, and the Stackelberg equilibrium represents an expected
optimal solution when the leader can anticipate the rational response of the
follower. Motivated by control of network systems with two levels of
decision-making hierarchy, such as the management of energy networks and power
coordination at cellular networks, a networked multi-leaders and
multi-followers Stackelberg game is proposed. Due to the constraint of limited
information interaction among players, a clustered information structure is
assumed that each leader can only communicate with a portion of overall
followers, namely its subordinated followers, and also only with its local
neighboring leaders. In this case, the leaders cannot fully anticipate the
collective rational response of all followers with its local information. To
address Stackelberg equilibrium seeking under this partial information
structure, we propose a distributed seeking algorithm based on implicit
gradient estimation and network consensus mechanisms. We rigorously prove the
convergence of the algorithm for both diminishing and constant step sizes under
strict and strong monotonicity conditions, respectively. Furthermore, the model
and the algorithm can also incorporate linear equality and inequality
constraints into the followers' optimization problems, with the approach of the
interior point barrier function. Finally, we present numerical simulations in
applications to corroborate our claims on the proposed framework.
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08147" title="Abstract">arXiv:2401.08147</a> [<a href="/pdf/2401.08147" title="Download PDF">pdf</a>, <a href="/ps/2401.08147" title="Download PostScript">ps</a>, <a href="/format/2401.08147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning on Dynamic Graphs: A Survey on Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fard%2C+S+H">Sanaz Hasanzadeh Fard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Dynamic graph learning has gained significant attention as it offers a
powerful means to model intricate interactions among entities across various
real-world and scientific domains. Notably, graphs serve as effective
representations for diverse networks such as transportation, brain, social, and
internet networks. Furthermore, the rapid advancements in machine learning have
expanded the scope of dynamic graph applications beyond the aforementioned
domains. In this paper, we present a review of lesser-explored applications of
dynamic graph learning. This study revealed the potential of machine learning
on dynamic graphs in addressing challenges across diverse domains, including
those with limited levels of association with the field.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08149" title="Abstract">arXiv:2401.08149</a> [<a href="/pdf/2401.08149" title="Download PDF">pdf</a>, <a href="/ps/2401.08149" title="Download PostScript">ps</a>, <a href="/format/2401.08149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation for Holographic Communications in Hybrid Near-Far  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shaohua Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Shuhao Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+B">Boya Di</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">To realize holographic communications, a potential technology for spectrum
efficiency improvement in the future sixth-generation (6G) network, antenna
arrays inlaid with numerous antenna elements will be deployed. However, the
increase in antenna aperture size makes some users lie in the Fresnel region,
leading to the hybrid near-field and far-field communication mode, where the
conventional far-field channel estimation methods no longer work well. To
tackle the above challenge, this paper considers channel estimation in a
hybrid-field multipath environment, where each user and each scatterer can be
in either the far-field or the near-field region. First, a joint angular-polar
domain channel transform is designed to capture the hybrid-field channel's
near-field and far-field features. We then analyze the power diffusion effect
in the hybrid-field channel, which indicates that the power corresponding to
one near-field (far-field) path component of the multipath channel may spread
to far-field (near-field) paths and causes estimation error. We design a novel
power-diffusion-based orthogonal matching pursuit channel estimation algorithm
(PD-OMP). It can eliminate the prior knowledge requirement of path numbers in
the far field and near field, which is a must in other OMP-based channel
estimation algorithms. Simulation results show that PD-OMP outperforms current
hybrid-field channel estimation methods.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08151" title="Abstract">arXiv:2401.08151</a> [<a href="/pdf/2401.08151" title="Download PDF">pdf</a>, <a href="/ps/2401.08151" title="Download PostScript">ps</a>, <a href="/format/2401.08151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agile Meets Quantum: A Novel Genetic Algorithm Model for Predicting the  Success of Quantum Software Development Project
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Arif Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Akbar%2C+M+A">Muhammad Azeem Akbar</a>, 
<a href="/search/cs?searchtype=author&query=Lahtinen%2C+V">Valtteri Lahtinen</a>, 
<a href="/search/cs?searchtype=author&query=Paavola%2C+M">Marko Paavola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Context: Quantum software systems represent a new realm in software
engineering, utilizing quantum bits (Qubits) and quantum gates (Qgates) to
solve the complex problems more efficiently than classical counterparts . Agile
software development approaches are considered to address many inherent
challenges in quantum software development, but their effective integration
remains unexplored Objective: This study investigates key causes of challenges
that could hinders the adoption of traditional agile approaches in quantum
software projects and develop an Agile Quantum Software Project Success
Prediction Model (AQSSPM). Methodology: Firstly, w e identified 19 causes of
challenging factors discussed in our previous study, which are potentially
impacting agile quantum project success. Secondly, a survey was conducted to
collect expert opinions on these causes and applied Genetic Algorithm (GA) with
Na i ve Bayes Classifier (NBC) and Logistic Regression (LR) to develop the
AQSSPM Results: Utilizing GA with NBC, project success probability improved
from 53.17% to 99.68%, with cost reductions from 0.463% to 0.403%. Similarly,
GA with LR increased success rates from 55.52% to 98.99%, and costs decreased
from 0.496% to 0.409% after 100 iterati ons. Both methods result showed a
strong positive correlation (rs=0.955) in causes ranking, with no significant
difference between them (t=1.195, p=0.240&gt;0.05). Conclusion: The AQSSPM
highlights critical focus areas for efficiently and successfully implementing
agile quantum projects considering the cost factor of a particular project
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08153" title="Abstract">arXiv:2401.08153</a> [<a href="/pdf/2401.08153" title="Download PDF">pdf</a>, <a href="/format/2401.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Stable Koopman Embeddings for Identification and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fan%2C+F">Fletcher Fan</a>, 
<a href="/search/eess?searchtype=author&query=Yi%2C+B">Bowen Yi</a>, 
<a href="/search/eess?searchtype=author&query=Rye%2C+D">David Rye</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+G">Guodong Shi</a>, 
<a href="/search/eess?searchtype=author&query=Manchester%2C+I+R">Ian R. Manchester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper introduces new model parameterizations for learning dynamical
systems from data via the Koopman operator, and studies their properties.
Whereas most existing works on Koopman learning do not take into account the
stability or stabilizability of the model -- two fundamental pieces of prior
knowledge about a given system to be identified -- in this paper, we propose
new classes of Koopman models that have built-in guarantees of these
properties. These models are guaranteed to be stable or stabilizable via a
novel {\em direct parameterization approach} that leads to {\em unconstrained}
optimization problems with respect to their parameter sets. To explore the
representational flexibility of these model sets, we establish novel
theoretical connections between the stability of discrete-time Koopman
embedding and contraction-based forms of nonlinear stability and
stabilizability. The proposed approach is illustrated in applications to stable
nonlinear system identification and imitation learning via stabilizable models.
Simulation results empirically show that the learning approaches based on the
proposed models outperform prior methods lacking stability guarantees.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08154" title="Abstract">arXiv:2401.08154</a> [<a href="/pdf/2401.08154" title="Download PDF">pdf</a>, <a href="/ps/2401.08154" title="Download PostScript">ps</a>, <a href="/format/2401.08154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Image Compression with ROI-Weighted Distortion and Bit  Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yongqi Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ronggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">This one page paper describes our method for the track of image compression.
To achieve better perceptual quality, we use the adversarial loss to generate
realistic textures, use region of interest (ROI) mask to guide the bit
allocation for different regions. Our Team name is TLIC.
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08156" title="Abstract">arXiv:2401.08156</a> [<a href="/pdf/2401.08156" title="Download PDF">pdf</a>, <a href="/format/2401.08156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GMLake: Efficient and Transparent GPU Memory Defragmentation for  Large-scale DNN Training with Virtual Memory Stitching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Cong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiale Xu</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jingwen Leng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Minyi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shouren Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junping Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASPLOS24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Large-scale deep neural networks (DNNs), such as large language models
(LLMs), have revolutionized the artificial intelligence (AI) field and become
increasingly popular. However, training or fine-tuning such models requires
substantial computational power and resources, where the memory capacity of a
single acceleration device like a GPU is one of the most important bottlenecks.
Owing to the prohibitively large overhead (e.g., $10 \times$) of GPUs' native
memory allocator, DNN frameworks like PyTorch and TensorFlow adopt a caching
allocator that maintains a memory pool with a splitting mechanism for fast
memory (de)allocation. Unfortunately, the caching allocator's efficiency
degrades quickly for popular memory reduction techniques such as recomputation,
offloading, distributed training, and low-rank adaptation. The primary reason
is that those memory reduction techniques introduce frequent and irregular
memory (de)allocation requests, leading to severe fragmentation problems for
the splitting-based caching allocator. To mitigate this fragmentation problem,
we propose a novel memory allocation framework based on low-level GPU virtual
memory management called GPU memory lake (GMLake). GMLake employs a novel
virtual memory stitching (VMS) mechanism, which can fuse or combine
non-contiguous memory blocks with a virtual memory address mapping. GMLake can
reduce an average of 9.2 GB (up to 25 GB) GPU memory usage and 15% (up to 33% )
fragmentation among eight LLM models on GPU A100 with 80 GB memory. GMLake is
completely transparent to the DNN models and memory reduction techniques and
ensures the seamless execution of resource-intensive deep-learning tasks. We
have open-sourced GMLake at
https://github.com/intelligent-machine-learning/glake/tree/main/GMLake.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08161" title="Abstract">arXiv:2401.08161</a> [<a href="/pdf/2401.08161" title="Download PDF">pdf</a>, <a href="/format/2401.08161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Structure of an Inversive Pseudorandom Number Generator over Ring  $\mathbb{Z}_{p^{e}}$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoxiong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Generating random and pseudorandom numbers with a deterministic system is a
long-standing challenge in theoretical research and engineering applications.
Several pseudorandom number generators based on the inversive congruential
method have been designed as attractive alternatives to those based on the
classical linear congruential method. This paper discloses the least period of
sequences generated by iterating an inversive pseudorandom number generator
over the ring $\mathbb{Z}_e$ by transforming it into a two-order linear
congruential recurrence relation. Depending on whether the sequence is periodic
or ultimately periodic, all states in the domain can be attributed to two types
of objects: some cycles of different lengths and one unilateral connected
digraph whose structure remains unchanged concerning parameter $e$. The graph
structure of the generator over the ring $\mathbb{Z}_e$ is precisely disclosed
with rigorous theoretical analysis and verified experimentally. The adopted
analysis methodology can be extended to study the graph structure of other
nonlinear maps.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08164" title="Abstract">arXiv:2401.08164</a> [<a href="/pdf/2401.08164" title="Download PDF">pdf</a>, <a href="/format/2401.08164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEG-based Cognitive Load Estimation of Acoustic Parameters for Data  Sonification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+G">Gulshan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Madan%2C+S">Surbhi Madan</a>, 
<a href="/search/cs?searchtype=author&query=Bilalpur%2C+M">Maneesh Bilalpur</a>, 
<a href="/search/cs?searchtype=author&query=Dhall%2C+A">Abhinav Dhall</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+R">Ramanathan Subramanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Sonification is a data visualization technique which expresses data
attributes via psychoacoustic parameters, which are non-speech audio signals
used to convey information. This paper investigates the binary estimation of
cognitive load induced by psychoacoustic parameters conveying the focus level
of an astronomical image via Electroencephalogram (EEG) embeddings. Employing
machine learning and deep learning methodologies, we demonstrate that EEG
signals are reliable for (a) binary estimation of cognitive load, (b) isolating
easy vs difficult visual-to-auditory perceptual mappings, and (c) capturing
perceptual similarities among psychoacoustic parameters. Our key findings
reveal that (1) EEG embeddings can reliably measure cognitive load, achieving a
peak F1-score of 0.98; (2) Extreme focus levels are easier to detect via
auditory mappings than intermediate ones, and (3) psychoacoustic parameters
inducing comparable cognitive load levels tend to generate similar EEG
encodings.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08165" title="Abstract">arXiv:2401.08165</a> [<a href="/pdf/2401.08165" title="Download PDF">pdf</a>, <a href="/format/2401.08165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Far Field Codebook Design for IOS-Aided Multi-User Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shupei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yutong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+B">Boya Di</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Recently, the rapid development of metasurface facilitates the growth of
extremely large-scale antenna arrays, making the ultra-massive MIMO possible.
In this paper, we study the codebook design and beam training for an
intelligent omni-surface (IOS) aided multi-user system, where the IOS is a
novel metasurface enabling simultaneous signal reflection and refraction. To
deal with the near field expansion caused by the large-dimension of IOS, we
design a near-far field codebook to serve users both in the near and far fields
without prior knowledge of user distribution. Moreover, to fully exploit the
dual functionality of the IOS, the coupling between the reflective and
refractive signals is analyzed theoretically and utilized in the codebook
design, thereby reducing the training overhead. On this basis, the multi-user
beam training is adopted where each codeword covers multiple areas to enable
all users to be trained simultaneously. Simulation results verify our
theoretical analysis on the reflective-refractive coupling. Compared to the
state-of-the-art schemes, the proposed scheme can improve the sum rate and
throughput.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08171" title="Abstract">arXiv:2401.08171</a> [<a href="/pdf/2401.08171" title="Download PDF">pdf</a>, <a href="/format/2401.08171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Linear Array Pushbroom Image Restoration: A Degradation Pipeline  and Jitter-Aware Restoration Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zida Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziran Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoying Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Menghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yueting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Huajun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhihai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiqi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Linear Array Pushbroom (LAP) imaging technology is widely used in the realm
of remote sensing. However, images acquired through LAP always suffer from
distortion and blur because of camera jitter. Traditional methods for restoring
LAP images, such as algorithms estimating the point spread function (PSF),
exhibit limited performance. To tackle this issue, we propose a Jitter-Aware
Restoration Network (JARNet), to remove the distortion and blur in two stages.
In the first stage, we formulate an Optical Flow Correction (OFC) block to
refine the optical flow of the degraded LAP images, resulting in pre-corrected
images where most of the distortions are alleviated. In the second stage, for
further enhancement of the pre-corrected images, we integrate two jitter-aware
techniques within the Spatial and Frequency Residual (SFRes) block: 1)
introducing Coordinate Attention (CoA) to the SFRes block in order to capture
the jitter state in orthogonal direction; 2) manipulating image features in
both spatial and frequency domains to leverage local and global priors.
Additionally, we develop a data synthesis pipeline, which applies Continue
Dynamic Shooting Model (CDSM) to simulate realistic degradation in LAP images.
Both the proposed JARNet and LAP image synthesis pipeline establish a
foundation for addressing this intricate challenge. Extensive experiments
demonstrate that the proposed two-stage method outperforms state-of-the-art
image restoration models. Code is available at
https://github.com/JHW2000/JARNet.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08174" title="Abstract">arXiv:2401.08174</a> [<a href="/pdf/2401.08174" title="Download PDF">pdf</a>, <a href="/format/2401.08174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Completely Occluded and Dense Object Instance Segmentation Using Box  Prompt-Based Segmentation Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Junfeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunkai Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sihan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+F">Fengshui Jing</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+M">Min Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Completely occluded and dense object instance segmentation (IS) is an
important and challenging task. Although current amodal IS methods can predict
invisible regions of occluded objects, they are difficult to directly predict
completely occluded objects. For dense object IS, existing box-based methods
are overly dependent on the performance of bounding box detection. In this
paper, we propose CFNet, a coarse-to-fine IS framework for completely occluded
and dense objects, which is based on box prompt-based segmentation foundation
models (BSMs). Specifically, CFNet first detects oriented bounding boxes (OBBs)
to distinguish instances and provide coarse localization information. Then, it
predicts OBB prompt-related masks for fine segmentation. To predict completely
occluded object instances, CFNet performs IS on occluders and utilizes prior
geometric properties, which overcomes the difficulty of directly predicting
completely occluded object instances. Furthermore, based on BSMs, CFNet reduces
the dependence on bounding box detection performance, improving dense object IS
performance. Moreover, we propose a novel OBB prompt encoder for BSMs. To make
CFNet more lightweight, we perform knowledge distillation on it and introduce a
Gaussian smoothing method for teacher targets. Experimental results demonstrate
that CFNet achieves the best performance on both industrial and publicly
available datasets.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08178" title="Abstract">arXiv:2401.08178</a> [<a href="/pdf/2401.08178" title="Download PDF">pdf</a>, <a href="/format/2401.08178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key-point Guided Deformable Image Manipulation Using Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Seok-Hwan Oh</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+G">Guil Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Myeong-Gee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sang-Yun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Young-Min Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyeon-Jik Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+H">Hyuk-Sool Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Hyeon-Min Bae</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is released at <a href="https://github.com/joseph9337/Key-point-Guided-Deformable-Image-Manipulation-Using-Diffusion-Mode">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we introduce a Key-point-guided Diffusion probabilistic Model
(KDM) that gains precise control over images by manipulating the object's
key-point. We propose a two-stage generative model incorporating an optical
flow map as an intermediate output. By doing so, a dense pixel-wise
understanding of the semantic relation between the image and sparse key point
is configured, leading to more realistic image generation. Additionally, the
integration of optical flow helps regulate the inter-frame variance of
sequential images, demonstrating an authentic sequential image generation. The
KDM is evaluated with diverse key-point conditioned image synthesis tasks,
including facial image generation, human pose synthesis, and echocardiography
video prediction, demonstrating the KDM is proving consistency enhanced and
photo-realistic images compared with state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08179" title="Abstract">arXiv:2401.08179</a> [<a href="/pdf/2401.08179" title="Download PDF">pdf</a>, <a href="/ps/2401.08179" title="Download PostScript">ps</a>, <a href="/format/2401.08179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeMM: A Decoupled Matrix Multiplication Engine Supporting Relaxed  Structured Sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peltekis%2C+C">Christodoulos Peltekis</a>, 
<a href="/search/cs?searchtype=author&query=Titopoulos%2C+V">Vasileios Titopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nicopoulos%2C+C">Chrysostomos Nicopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrakopoulos%2C+G">Giorgos Dimitrakopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted on the IEEE Computer Architecture Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Deep Learning (DL) has achieved unprecedented success in various application
domains. Meanwhile, model pruning has emerged as a viable solution to reduce
the footprint of DL models in mobile applications, without compromising their
accuracy. To enable the matrix engines built for dense DL models to also handle
their pruned counterparts, pruned DL models follow a fine-grained structured
sparsity pattern of 1:4, or 2:4, whereby in each group of four contiguous
values, at least one, or two, respectively, must be non-zero. Structured
sparsity has recently also moved to coarser (relaxed) cases of N:128, or N:256,
for small values of N, targeting a wider range of sparsity (10%-90%) for the DL
models. In this work, we design an accelerator that operates, by construction,
on wide blocks with relaxed structured sparsity. In contrast to the
conventional systolic array archetype, the new engine decouples the memory part
of the systolic array from the multiply-add units. The memory block comprises 1
write and N read ports, with the number of read ports being equal to the number
of non-zero elements per row. The multiply-add units connect directly to each
read port and complete the multiplication in a row-wise product-first order.
More importantly, simple reconfiguration facilitates more dense patterns. The
experimental evaluation demonstrates substantial latency improvements over
current state-of-the-art systolic array engines built for fine-grained and
relaxed structured sparsity.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08181" title="Abstract">arXiv:2401.08181</a> [<a href="/pdf/2401.08181" title="Download PDF">pdf</a>, <a href="/format/2401.08181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiveScaler: Live control of the harmony of an electronic music track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rixte%2C+A">Alice Rixte</a> (LaBRI, UB)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in French language
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journ{\'e}es d'Informatique Musicale (JIM), Association
  Francophone d'Informatique Musicale (AFIM), May 2023, Saint-Denis (93),
  France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In Electronic Dance Music (EDM), many artists use DJing techniques in order
to perform their own productions live. As a consequence, they do not have
access during the performance to the internal structure of their tracks, and
specifically to their equivalent of a partition: MIDI files. On the other hand,
if an artist attempts to remix or interpret their own production live, the
number of tracks that they can simultaneously control is limited without
suitable software. This article introduces LiveScaler, a software that allows
live control of the harmony and pitch of electronic music. A set of pitch
transformations, termed affine transformations, is presented. These
transformations are applied to all MIDI streams of a prepared track. A MaxMSP
implementation, in conjunction with Ableton Live, is proposed. Special
attention is given to control issues, mapping, and practical live
experimentation in the context of EDM.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08185" title="Abstract">arXiv:2401.08185</a> [<a href="/pdf/2401.08185" title="Download PDF">pdf</a>, <a href="/ps/2401.08185" title="Download PostScript">ps</a>, <a href="/format/2401.08185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPAFNet:Dual Path Attention Fusion Network for Single Image Deraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+B">Bingcai Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Rainy weather will have a significant impact on the regular operation of the
imaging system. Based on this premise, image rain removal has always been a
popular branch of low-level visual tasks, especially methods using deep neural
networks. However, most neural networks are but-branched, such as only using
convolutional neural networks or Transformers, which is unfavourable for the
multidimensional fusion of image features. In order to solve this problem, this
paper proposes a dual-branch attention fusion network. Firstly, a two-branch
network structure is proposed. Secondly, an attention fusion module is proposed
to selectively fuse the features extracted by the two branches rather than
simply adding them. Finally, complete ablation experiments and sufficient
comparison experiments prove the rationality and effectiveness of the proposed
method.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08189" title="Abstract">arXiv:2401.08189</a> [<a href="/pdf/2401.08189" title="Download PDF">pdf</a>, <a href="/format/2401.08189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRewrite: Prompt Rewriting with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+W">Weize Kong</a>, 
<a href="/search/cs?searchtype=author&query=Hombaiah%2C+S+A">Spurthi Amba Hombaiah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+Q">Qiaozhu Mei</a>, 
<a href="/search/cs?searchtype=author&query=Bendersky%2C+M">Michael Bendersky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Prompt engineering is critical for the development of LLM-based applications.
However, it is usually done manually in a "trial and error" fashion. This
manual procedure can be time consuming, ineffective, and the generated prompts
are, in a lot of cases, sub-optimal. Even for the prompts which seemingly work
well, there is always a lingering question: can the prompts be made better with
further modifications?
<br />To address these questions, in this paper, we investigate prompt engineering
automation. We consider a specific use case scenario in which developers/users
have drafted initial prompts, but lack the time/expertise to optimize them. We
propose PRewrite, an automated tool to rewrite these drafts and to generate
highly effective new prompts. PRewrite is based on the Reinforcement Learning
(RL) framework which allows for end-to-end optimization and our design allows
the RL search to happen in a large action space. The automated tool leverages
manually crafted prompts as starting points which makes the rewriting procedure
more guided and efficient. The generated prompts are human readable, and
self-explanatory, unlike some of those in previous works. We conducted
extensive experiments on diverse datasets and found that the prompts generated
with this new method not only outperform professionally crafted prompts, but
also prompts generated with other previously proposed methods.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08190" title="Abstract">arXiv:2401.08190</a> [<a href="/pdf/2401.08190" title="Download PDF">pdf</a>, <a href="/format/2401.08190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Minpeng Liao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+K">Kai Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have seen considerable advancements in natural
language understanding tasks, yet there remains a gap to bridge before
attaining true artificial general intelligence, especially concerning
shortcomings in mathematical reasoning capabilities. We postulate that the
inherent nature of LLM training, which focuses on predicting probabilities of
next token, presents challenges in effectively modeling mathematical reasoning
that demands exact calculations, both from data-driven and theoretical
standpoints. In this paper, we address this challenge by enriching the data
landscape and introducing a novel math dataset, enhanced with a capability to
utilize a Python code interpreter. This dataset is derived from GSM8K and MATH
and has been further refined through a combination of GPT-4 annotations, human
review, and self-training processes, where the errors in the original GSM8K
training set have been fixed. Additionally, we propose a tentative, easily
replicable protocol for the fine-tuning of math-specific LLMs, which has led to
a significant improvement in the performance of a 7B-parameter LLM on the GSM8K
and MATH datasets. We are committed to advancing the field of mathematical
reasoning in LLMs and, to that end, we have made the model checkpoints and will
make the dataset publicly available. We hope this will facilitate further
research and development within the community.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08191" title="Abstract">arXiv:2401.08191</a> [<a href="/pdf/2401.08191" title="Download PDF">pdf</a>, <a href="/ps/2401.08191" title="Download PostScript">ps</a>, <a href="/format/2401.08191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfiguration of a parallel kinematic manipulator with 2T2R motions  for avoiding singularities through minimizing actuator forces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valero%2C+F">Francisco Valero</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Rodriguez%2C+M">Miguel Diaz-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Valles%2C+M">Marina Valles</a>, 
<a href="/search/cs?searchtype=author&query=Besa%2C+A">Antonio Besa</a>, 
<a href="/search/cs?searchtype=author&query=Bernabeu%2C+E">Enrique Bernabeu</a>, 
<a href="/search/cs?searchtype=author&query=Valera%2C+A">Angel Valera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper aims to develop an approach for the reconfiguration of a parallel
kinematic manipulator (PKM) with four degrees of freedom (DoF) designed to
tackle tasks of diagnosis and rehabilitation in an injured knee. The original
layout of the 4-DoF manipulator presents Type-II singular configurations within
its workspace. Thus, we proposed to reconfigure the manipulator to avoid such
singularities (owing to the Forward Jacobian of the PKM) during typical
rehabilitation trajectories. We achieve the reconfiguration of the PKM through
a minimization problem where the design variables correspond to the anchoring
points of the robot limbs on fixed and mobile platforms. The objective function
relies on the minimization of the forces exerted by the actuators for a
specific trajectory. The minimization problem considers constraint equations to
avoid Type-II singularities, which guarantee the feasibility of the active
generalized coordinates for a particular path. To evaluate the proposed
conceptual strategy, we build a prototype where reconfiguration occurs by
moving the position of the anchoring points to holes bored in the fixed and
mobile platforms. Simulations and experiments of several study cases enable
testing the strategy performance. The results show that the reconfiguration
strategy allows obtaining trajectories having minimum actuation forces without
Type-II singularities.
</p>
</div>
</dd>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08192" title="Abstract">arXiv:2401.08192</a> [<a href="/pdf/2401.08192" title="Download PDF">pdf</a>, <a href="/ps/2401.08192" title="Download PostScript">ps</a>, <a href="/format/2401.08192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mechatronic Design, Experimental Setup and Control Architecture Design  of a Novel 4 DoF Parallel Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valles%2C+M">Marina Valles</a>, 
<a href="/search/cs?searchtype=author&query=Araujo-Gomez%2C+P">Pedro Araujo-Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Mata%2C+V">Vicente Mata</a>, 
<a href="/search/cs?searchtype=author&query=Valera%2C+A">Angel Valera</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Rodriguez%2C+M">Miguel Diaz-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Page%2C+A">Alvaro Page</a>, 
<a href="/search/cs?searchtype=author&query=Farhat%2C+N+M">Nidal M. Farhat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Although parallel manipulators (PMs) started with the introduction of
architectures with 6 Degrees of Freedom (DoF), a vast number of applications
require less than 6 DoF. Consequently, scholars have proposed architectures
with 3 DoF and 4 DoF, but relatively few 4 DoF PMs have become prototypes,
especially of the two rotation (2R) and two translation (2T) motion types. In
this paper, we explain the mechatronics design, prototype and control
architecture design of a 4 DoF PM with 2R2T motions. We chose to design a 4 DoF
manipulator based on the motion needed to complete the tasks of lower limb
rehabilitation.
<br />To the author's best knowledge, PMs between 3 and 6 DoF for rehabilitation of
lower limbs have not been proposed to date. The developed architecture enhances
the three minimum DoF required by adding a 4 DoF which allows combinations of
normal or tangential efforts in the joints, or torque acting on the knee. We
put forward the inverse and forward displacement equations, describe the
prototype, perform the experimental setup, and develop the hardware and control
architecture. The tracking accuracy experiments from the proposed controller
show that the manipulator can accomplish the required application.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08194" title="Abstract">arXiv:2401.08194</a> [<a href="/pdf/2401.08194" title="Download PDF">pdf</a>, <a href="/format/2401.08194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Optimized Image Compression with the Frequency-Oriented  Transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuefeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kai Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, accepted by MVAP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">Image compression constitutes a significant challenge amidst the era of
information explosion. Recent studies employing deep learning methods have
demonstrated the superior performance of learning-based image compression
methods over traditional codecs. However, an inherent challenge associated with
these methods lies in their lack of interpretability. Following an analysis of
the varying degrees of compression degradation across different frequency
bands, we propose the end-to-end optimized image compression model facilitated
by the frequency-oriented transform. The proposed end-to-end image compression
model consists of four components: spatial sampling, frequency-oriented
transform, entropy estimation, and frequency-aware fusion. The
frequency-oriented transform separates the original image signal into distinct
frequency bands, aligning with the human-interpretable concept. Leveraging the
non-overlapping hypothesis, the model enables scalable coding through the
selective transmission of arbitrary frequency components. Extensive experiments
are conducted to demonstrate that our model outperforms all traditional codecs
including next-generation standard H.266/VVC on MS-SSIM metric. Moreover,
visual analysis tasks (i.e., object detection and semantic segmentation) are
conducted to verify the proposed compression method could preserve semantic
fidelity besides signal-level precision.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08195" title="Abstract">arXiv:2401.08195</a> [<a href="/pdf/2401.08195" title="Download PDF">pdf</a>, <a href="/ps/2401.08195" title="Download PostScript">ps</a>, <a href="/format/2401.08195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three classes of propagation rules for GRS and EGRS codes and their  applications to EAQECCs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+R">Ruhao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shixin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, we study the Hermitian hulls of (extended) generalized
Reed-Solomon (GRS and EGRS) codes over finite fields. For a given class of
(extended) GRS codes, by increasing the length, increasing the dimensions and
increasing both the length and the dimensions, we obtain three new classes of
(extended) GRS codes with Hermitian hulls of arbitrary dimensions. Furthermore,
we obtain several new classes of $q^2$-ary maximum distance separable (MDS)
codes with Hermitian hulls of arbitrary dimensions. And the dimension of these
MDS codes can be taken from $1$ to $\frac{n}{2}$. By propagation rules, the
parameters of the obtained code can be more flexible. As an application, a lot
of new (MDS) entanglement-assisted quantum error correction codes (EAQECCs) can
be constructed from previous known (extended) GRS codes. We derive three new
propagation rules on (MDS) EAQECCs constructed from (extended) GRS codes.
Finally, we present several new classes of (MDS) EAQECCs with flexible
parameters. Notably, the distance parameters of our codes can range from $2$ to
$\frac{n+2}{2}$.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08196" title="Abstract">arXiv:2401.08196</a> [<a href="/pdf/2401.08196" title="Download PDF">pdf</a>, <a href="/format/2401.08196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Cryptographic Mechanisms for the Selective Disclosure of Verifiable  Credentials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flamini%2C+A">Andrea Flamini</a>, 
<a href="/search/cs?searchtype=author&query=Sciarretta%2C+G">Giada Sciarretta</a>, 
<a href="/search/cs?searchtype=author&query=Scuro%2C+M">Mario Scuro</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+A">Amir Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Tomasi%2C+A">Alessandro Tomasi</a>, 
<a href="/search/cs?searchtype=author&query=Ranise%2C+S">Silvio Ranise</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 6 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Verifiable credentials are a digital analogue of physical credentials. Their
authenticity and integrity are protected by means of cryptographic techniques,
and they can be presented to verifiers to reveal attributes or even predicates
about the attributes included in the credential. One way to preserve privacy
during presentation consists in selectively disclosing the attributes in a
credential. In this paper we present the most widespread cryptographic
mechanisms used to enable selective disclosure of attributes identifying two
categories: the ones based on hiding commitments - e.g., mdl ISO/IEC 18013-5 -
and the ones based on non-interactive zero-knowledge proofs - e.g., BBS
signatures. We also include a description of the cryptographic primitives used
to design such cryptographic mechanisms. We describe the design of the
cryptographic mechanisms and compare them by performing an analysis on their
standard maturity in terms of standardization, cryptographic agility and
quantum safety, then we compare the features that they support with main focus
on the unlinkability of presentations, the ability to create predicate proofs
and support for threshold credential issuance. Finally we perform an
experimental evaluation based on the Rust open source implementations that we
have considered most relevant. In particular we evaluate the size of
credentials and presentations built using different cryptographic mechanisms
and the time needed to generate and verify them. We also highlight some
trade-offs that must be considered in the instantiation of the cryptographic
mechanisms.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08197" title="Abstract">arXiv:2401.08197</a> [<a href="/pdf/2401.08197" title="Download PDF">pdf</a>, <a href="/format/2401.08197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Completion with Hypergraphs:Sharp Thresholds and Efficient  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhongtian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiaosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT); Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers the problem of completing a rating matrix based on
sub-sampled matrix entries as well as observed social graphs and hypergraphs.
We show that there exists a \emph{sharp threshold} on the sample probability
for the task of exactly completing the rating matrix -- the task is achievable
when the sample probability is above the threshold, and is impossible otherwise
-- demonstrating a phase transition phenomenon. The threshold can be expressed
as a function of the ``quality'' of hypergraphs, enabling us to \emph{quantify}
the amount of reduction in sample probability due to the exploitation of
hypergraphs. This also highlights the usefulness of hypergraphs in the matrix
completion problem. En route to discovering the sharp threshold, we develop a
computationally efficient matrix completion algorithm that effectively exploits
the observed graphs and hypergraphs. Theoretical analyses show that our
algorithm succeeds with high probability as long as the sample probability
exceeds the aforementioned threshold, and this theoretical result is further
validated by synthetic experiments. Moreover, our experiments on a real social
network dataset (with both graphs and hypergraphs) show that our algorithm
outperforms other state-of-the-art matrix completion algorithms.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08202" title="Abstract">arXiv:2401.08202</a> [<a href="/pdf/2401.08202" title="Download PDF">pdf</a>, <a href="/format/2401.08202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IsamasRed: A Public Dataset Tracking Reddit Discussions on Israel-Hamas  Conflict
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zihao He</a>, 
<a href="/search/cs?searchtype=author&query=Burghardt%2C+K">Keith Burghardt</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Digital Libraries (cs.DL)

</div>
<p class="mathjax">The conflict between Israel and Palestinians significantly escalated after
the October 7, 2023 Hamas attack, capturing global attention. To understand the
public discourse on this conflict, we present a meticulously compiled
dataset--IsamasRed--comprising nearly 400,000 conversations and over 8 million
comments from Reddit, spanning from August 2023 to November 2023. We introduce
an innovative keyword extraction framework leveraging a large language model to
effectively identify pertinent keywords, ensuring a comprehensive data
collection. Our initial analysis on the dataset, examining topics, controversy,
emotional and moral language trends over time, highlights the emotionally
charged and complex nature of the discourse. This dataset aims to enrich the
understanding of online discussions, shedding light on the complex interplay
between ideology, sentiment, and community engagement in digital spaces.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08206" title="Abstract">arXiv:2401.08206</a> [<a href="/pdf/2401.08206" title="Download PDF">pdf</a>, <a href="/format/2401.08206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Multi-Modal Knowledge Retrieval with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xinwei Long</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jiali Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+F">Fandong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhiyuan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaiyan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Knowledge retrieval with multi-modal queries plays a crucial role in
supporting knowledge-intensive multi-modal applications. However, existing
methods face challenges in terms of their effectiveness and training
efficiency, especially when it comes to training and integrating multiple
retrievers to handle multi-modal queries. In this paper, we propose an
innovative end-to-end generative framework for multi-modal knowledge retrieval.
Our framework takes advantage of the fact that large language models (LLMs) can
effectively serve as virtual knowledge bases, even when trained with limited
data. We retrieve knowledge via a two-step process: 1) generating knowledge
clues related to the queries, and 2) obtaining the relevant document by
searching databases using the knowledge clue. In particular, we first introduce
an object-aware prefix-tuning technique to guide multi-grained visual learning.
Then, we align multi-grained visual features into the textual feature space of
the LLM, employing the LLM to capture cross-modal interactions. Subsequently,
we construct instruction data with a unified format for model training.
Finally, we propose the knowledge-guided generation strategy to impose prior
constraints in the decoding steps, thereby promoting the generation of
distinctive knowledge clues. Through experiments conducted on three benchmarks,
we demonstrate significant improvements ranging from 3.0% to 14.6% across all
evaluation metrics when compared to strong baselines.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08209" title="Abstract">arXiv:2401.08209</a> [<a href="/pdf/2401.08209" title="Download PDF">pdf</a>, <a href="/format/2401.08209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transcending the Limit of Local Window: Advanced Super-Resolution  Transformer with Adaptive Token Dictionary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Leheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaorui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuhang Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single Image Super-Resolution is a classic computer vision problem that
involves estimating high-resolution (HR) images from low-resolution (LR) ones.
Although deep neural networks (DNNs), especially Transformers for
super-resolution, have seen significant advancements in recent years,
challenges still remain, particularly in limited receptive field caused by
window-based self-attention. To address these issues, we introduce a group of
auxiliary Adapeive Token Dictionary to SR Transformer and establish an ATD-SR
method. The introduced token dictionary could learn prior information from
training data and adapt the learned prior to specific testing image through an
adaptive refinement step. The refinement strategy could not only provide global
information to all input tokens but also group image tokens into categories.
Based on category partitions, we further propose a category-based
self-attention mechanism designed to leverage distant but similar tokens for
enhancing input features. The experimental results show that our method
achieves the best performance on various single image super-resolution
benchmarks.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08210" title="Abstract">arXiv:2401.08210</a> [<a href="/pdf/2401.08210" title="Download PDF">pdf</a>, <a href="/format/2401.08210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ModelNet-O: A Large-Scale Synthetic Dataset for Occlusion-Aware Point  Cloud Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Z">Zhongbin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengyuan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://github.com/fanglaosi/PointMLS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, 3D point cloud classification has made significant progress with
the help of many datasets. However, these datasets do not reflect the
incomplete nature of real-world point clouds caused by occlusion, which limits
the practical application of current methods. To bridge this gap, we propose
ModelNet-O, a large-scale synthetic dataset of 123,041 samples that emulate
real-world point clouds with self-occlusion caused by scanning from monocular
cameras. ModelNet-O is 10 times larger than existing datasets and offers more
challenging cases to evaluate the robustness of existing methods. Our
observation on ModelNet-O reveals that well-designed sparse structures can
preserve structural information of point clouds under occlusion, motivating us
to propose a robust point cloud processing method that leverages a critical
point sampling (CPS) strategy in a multi-level manner. We term our method
PointMLS. Through extensive experiments, we demonstrate that our PointMLS
achieves state-of-the-art results on ModelNet-O and competitive results on
regular datasets, and it is robust and effective. More experiments also
demonstrate the robustness and effectiveness of PointMLS.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08212" title="Abstract">arXiv:2401.08212</a> [<a href="/pdf/2401.08212" title="Download PDF">pdf</a>, <a href="/format/2401.08212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human vs. LMMs: Exploring the Discrepancy in Emoji Interpretation and  Usage in Digital Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hanjia Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+W">Weihong Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiebo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Leveraging Large Multimodal Models (LMMs) to simulate human behaviors when
processing multimodal information, especially in the context of social media,
has garnered immense interest due to its broad potential and far-reaching
implications. Emojis, as one of the most unique aspects of digital
communication, are pivotal in enriching and often clarifying the emotional and
tonal dimensions. Yet, there is a notable gap in understanding how these
advanced models, such as GPT-4V, interpret and employ emojis in the nuanced
context of online interaction. This study intends to bridge this gap by
examining the behavior of GPT-4V in replicating human-like use of emojis. The
findings reveal a discernible discrepancy between human and GPT-4V behaviors,
likely due to the subjective nature of human interpretation and the limitations
of GPT-4V's English-centric training, suggesting cultural biases and inadequate
representation of non-English cultures.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08216" title="Abstract">arXiv:2401.08216</a> [<a href="/pdf/2401.08216" title="Download PDF">pdf</a>, <a href="/format/2401.08216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient and Certified Recovery from Poisoning Attacks in  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiyuan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziyao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C+W">Chee Wei Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kwok-Yan Lam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated learning (FL) is vulnerable to poisoning attacks, where malicious
clients manipulate their updates to affect the global model. Although various
methods exist for detecting those clients in FL, identifying malicious clients
requires sufficient model updates, and hence by the time malicious clients are
detected, FL models have been already poisoned. Thus, a method is needed to
recover an accurate global model after malicious clients are identified.
Current recovery methods rely on (i) all historical information from
participating FL clients and (ii) the initial model unaffected by the malicious
clients, leading to a high demand for storage and computational resources. In
this paper, we show that highly effective recovery can still be achieved based
on (i) selective historical information rather than all historical information
and (ii) a historical model that has not been significantly affected by
malicious clients rather than the initial model. In this scenario, while
maintaining comparable recovery performance, we can accelerate the recovery
speed and decrease memory consumption. Following this concept, we introduce
Crab, an efficient and certified recovery method, which relies on selective
information storage and adaptive model rollback. Theoretically, we demonstrate
that the difference between the global model recovered by Crab and the one
recovered by train-from-scratch can be bounded under certain assumptions. Our
empirical evaluation, conducted across three datasets over multiple machine
learning models, and a variety of untargeted and targeted poisoning attacks
reveals that Crab is both accurate and efficient, and consistently outperforms
previous approaches in terms of both recovery speed and memory consumption.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08217" title="Abstract">arXiv:2401.08217</a> [<a href="/pdf/2401.08217" title="Download PDF">pdf</a>, <a href="/format/2401.08217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Guided Multi-View Hypergraph Learning for Human-Centric Explainable  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Qing Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Longfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenqing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">As personalized recommendation systems become vital in the age of information
overload, traditional methods relying solely on historical user interactions
often fail to fully capture the multifaceted nature of human interests. To
enable more human-centric modeling of user preferences, this work proposes a
novel explainable recommendation framework, i.e., LLMHG, synergizing the
reasoning capabilities of large language models (LLMs) and the structural
advantages of hypergraph neural networks. By effectively profiling and
interpreting the nuances of individual user interests, our framework pioneers
enhancements to recommendation systems with increased explainability. We
validate that explicitly accounting for the intricacies of human preferences
allows our human-centric and explainable LLMHG approach to consistently
outperform conventional models across diverse real-world datasets. The proposed
plug-and-play enhancement framework delivers immediate gains in recommendation
performance while offering a pathway to apply advanced LLMs for better
capturing the complexity of human interests across machine learning
applications.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08219" title="Abstract">arXiv:2401.08219</a> [<a href="/pdf/2401.08219" title="Download PDF">pdf</a>, <a href="/ps/2401.08219" title="Download PostScript">ps</a>, <a href="/format/2401.08219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monoidal Extended Stone Duality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Birkmann%2C+F">Fabian Birkmann</a>, 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>, 
<a href="/search/cs?searchtype=author&query=Milius%2C+S">Stefan Milius</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Extensions of Stone-type dualities have a long history in algebraic logic and
have also been instrumental for proving results in algebraic language theory.
We show how to extend abstract categorical dualities via monoidal adjunctions,
subsuming various incarnations of classical extended Stone and Priestley
duality as a special case. Guided by these categorical foundations, we
investigate residuation algebras, which are algebraic models of language
derivatives, and show the subcategory of derivation algebras to be dually
equivalent to the category of profinite ordered monoids, restricting to a
duality between boolean residuation algebras and profinite monoids. We further
extend this duality to capture relational morphisms of profinite ordered
monoids, which dualize to natural morphisms of residuation algebras.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08221" title="Abstract">arXiv:2401.08221</a> [<a href="/pdf/2401.08221" title="Download PDF">pdf</a>, <a href="/format/2401.08221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Relationship in Indefinite Data: Baseline Model and New  Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keqing Du</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> If you are interested in the two new datasets, pls contact us by email
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Integrating deep learning and causal discovery has encouraged us to spot that
learning causal structures and representations in dialogue and video is full of
challenges. We defined These data forms as "Indefinite Data", characterized by
multi-structure data and multi-value representations. Unlike existing adaptable
data forms, Indefinite Data still faces gaps in datasets and methods. To
address the dataset gap, we release two high-quality datasets - Causalogue and
Causaction, containing text dialogue samples and video action samples with
causal annotations respectively. Moreover, the method gap arises from the
coexistence of multi-structure data and multi-value representations, breaking
the assumptions of all current methods and rendering them infeasible on
Indefinite Data. To this end, we propose a probabilistic framework as a
baseline, incorporating three designed highlights for this gap: 1) establishing
Causation Condition of representations using the independence of noise terms
under non-fixed causal structures, 2) treating causal strength as a latent
variable and measuring the reconstruction loss in the correlation space, and 3)
estimating the effects of latent confounders. These highpoints make the
probabilistic model capable of overcoming challenges brought by the coexistence
of multi-structure data and multi-value representations and pave the way for
the extension of latent confounders. Comprehensive experiments have evaluated
baseline results of causal structures, causal representations, and confounding
disentanglement.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08225" title="Abstract">arXiv:2401.08225</a> [<a href="/pdf/2401.08225" title="Download PDF">pdf</a>, <a href="/format/2401.08225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Mathematically Robust Operations for Certified Neural  Networks Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geyer%2C+F">Fabien Geyer</a>, 
<a href="/search/cs?searchtype=author&query=Freitag%2C+J">Johannes Freitag</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+T">Tobias Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Uhrig%2C+S">Sascha Uhrig</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 6th Workshop on Accelerated Machine Learning (AccML) at HiPEAC
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">In recent years, machine learning (ML) and neural networks (NNs) have gained
widespread use and attention across various domains, particularly in
transportation for achieving autonomy, including the emergence of flying taxis
for urban air mobility (UAM). However, concerns about certification have come
up, compelling the development of standardized processes encompassing the
entire ML and NN pipeline. This paper delves into the inference stage and the
requisite hardware, highlighting the challenges associated with IEEE 754
floating-point arithmetic and proposing alternative number representations. By
evaluating diverse summation and dot product algorithms, we aim to mitigate
issues related to non-associativity. Additionally, our exploration of
fixed-point arithmetic reveals its advantages over floating-point methods,
demonstrating significant hardware efficiencies. Employing an empirical
approach, we ascertain the optimal bit-width necessary to attain an acceptable
level of accuracy, considering the inherent complexity of bit-width
optimization.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08227" title="Abstract">arXiv:2401.08227</a> [<a href="/pdf/2401.08227" title="Download PDF">pdf</a>, <a href="/format/2401.08227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Core-periphery Detection Based on Masked Bayesian Non-negative Matrix  Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhonghao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+R">Ru Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jiaye Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Ka-Chun Wong</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chengbin Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures. IEEE Transactions on Computational Social Systems(TCSS), 2024, early access
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Computational Social Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Core-periphery structure is an essential mesoscale feature in complex
networks. Previous researches mostly focus on discriminative approaches while
in this work, we propose a generative model called masked Bayesian non-negative
matrix factorization. We build the model using two pair affiliation matrices to
indicate core-periphery pair associations and using a mask matrix to highlight
connections to core nodes. We propose an approach to infer the model
parameters, and prove the convergence of variables with our approach. Besides
the abilities as traditional approaches, it is able to identify core scores
with overlapping core-periphery pairs. We verify the effectiveness of our
method using randomly generated networks and real-world networks. Experimental
results demonstrate that the proposed method outperforms traditional
approaches.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08228" title="Abstract">arXiv:2401.08228</a> [<a href="/pdf/2401.08228" title="Download PDF">pdf</a>, <a href="/format/2401.08228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCRPL: A Pretrain, Prompt &amp; Fine-tune Paradigm for Non-overlapping  Many-to-one Cross-domain Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yongqiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Min Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Cross-domain Recommendation (CR) is the task that tends to improve the
recommendations in the sparse target domain by leveraging the information from
other rich domains. Existing methods of cross-domain recommendation mainly
focus on overlapping scenarios by assuming users are totally or partially
overlapped, which are taken as bridges to connect different domains. However,
this assumption does not always hold since it is illegal to leak users'
identity information to other domains. Conducting Non-overlapping MCR (NMCR) is
challenging since 1) The absence of overlapping information prevents us from
directly aligning different domains, and this situation may get worse in the
MCR scenario. 2) The distribution between source and target domains makes it
difficult for us to learn common information across domains. To overcome the
above challenges, we focus on NMCR, and devise MCRPL as our solution. To
address Challenge 1, we first learn shared domain-agnostic and domain-dependent
prompts, and pre-train them in the pre-training stage. To address Challenge 2,
we further update the domain-dependent prompts with other parameters kept fixed
to transfer the domain knowledge to the target domain. We conduct experiments
on five real-world domains, and the results show the advance of our MCRPL
method compared with several recent SOTA baselines.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08229" title="Abstract">arXiv:2401.08229</a> [<a href="/pdf/2401.08229" title="Download PDF">pdf</a>, <a href="/ps/2401.08229" title="Download PostScript">ps</a>, <a href="/format/2401.08229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental Analysis of Type II Singularities and Assembly Change  Points in a 3UPS+RPU Parallel Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pulloquinga%2C+J+L">Jose L. Pulloquinga</a>, 
<a href="/search/cs?searchtype=author&query=Mata%2C+V">Vicente Mata</a>, 
<a href="/search/cs?searchtype=author&query=Valera%2C+A">Angel Valera</a>, 
<a href="/search/cs?searchtype=author&query=Zamora-Ortiz%2C+P">Pau Zamora-Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Diaz-Rodriguez%2C+M">Miguel Diaz-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Zambrano%2C+I">Ivan Zambrano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Parallel robots (PRs) have singular configurations where the robot gains at
least one degree of freedom and loses control. Theoretically, such singularity
occurs when the Forward Jacobian-matrix determinant becomes zero (Type II).
However, actual PRs could lose control owing to Type II singularities for
determinant values near zero, but not zero, because manufacturing tolerances
introduce errors that are complex to model due to their low repeatability.
<br />Thus, using an actual 3UPS+RPU PR, this paper presents three contributions:
i) a proximity detection index for Type II singularities based on the angle
between two Output Twist Screws. The index can identify which kinematic chains
contribute to the singularity. ii) an experimental benchmark to study Type II
singularities. iii) PR configurations where the proposed index is zero and the
Forward Jacobian determinant is not. In this last configuration, the findings
show that the actual robot is unable to handle external actions applied to the
PR.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08232" title="Abstract">arXiv:2401.08232</a> [<a href="/pdf/2401.08232" title="Download PDF">pdf</a>, <a href="/format/2401.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-scale 2D Temporal Map Diffusion Models for Natural Language Video  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chongzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+Z">Zhiyang Teng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xizhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lewei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Aixin Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Natural Language Video Localization (NLVL), grounding phrases from natural
language descriptions to corresponding video segments, is a complex yet
critical task in video understanding. Despite ongoing advancements, many
existing solutions lack the capability to globally capture temporal dynamics of
the video data. In this study, we present a novel approach to NLVL that aims to
address this issue. Our method involves the direct generation of a global 2D
temporal map via a conditional denoising diffusion process, based on the input
video and language query. The main challenges are the inherent sparsity and
discontinuity of a 2D temporal map in devising the diffusion decoder. To
address these challenges, we introduce a multi-scale technique and develop an
innovative diffusion decoder. Our approach effectively encapsulates the
interaction between the query and video data across various time scales.
Experiments on the Charades and DiDeMo datasets underscore the potency of our
design.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08233" title="Abstract">arXiv:2401.08233</a> [<a href="/pdf/2401.08233" title="Download PDF">pdf</a>, <a href="/ps/2401.08233" title="Download PostScript">ps</a>, <a href="/format/2401.08233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Wind Speed and Wind Power Forecasting Using Shape-Wise Feature  Engineering: A Novel Approach for Improved Accuracy and Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Christian%2C+M+M">Mulomba Mukendi Christian</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+S">Yun Seon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+H">Hyebong Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaeyoung Lee</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+S">SongHee You</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Advanced Culture Technology Vol.11 No.4
  393-405 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Accurate prediction of wind speed and power is vital for enhancing the
efficiency of wind energy systems. Numerous solutions have been implemented to
date, demonstrating their potential to improve forecasting. Among these, deep
learning is perceived as a revolutionary approach in the field. However,
despite their effectiveness, the noise present in the collected data remains a
significant challenge. This noise has the potential to diminish the performance
of these algorithms, leading to inaccurate predictions. In response to this,
this study explores a novel feature engineering approach. This approach
involves altering the data input shape in both Convolutional Neural
Network-Long Short-Term Memory (CNN-LSTM) and Autoregressive models for various
forecasting horizons. The results reveal substantial enhancements in model
resilience against noise resulting from step increases in data. The approach
could achieve an impressive 83% accuracy in predicting unseen data up to the
24th steps. Furthermore, this method consistently provides high accuracy for
short, mid, and long-term forecasts, outperforming the performance of
individual models. These findings pave the way for further research on noise
reduction strategies at different forecasting horizons through shape-wise
feature engineering.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08236" title="Abstract">arXiv:2401.08236</a> [<a href="/pdf/2401.08236" title="Download PDF">pdf</a>, <a href="/ps/2401.08236" title="Download PostScript">ps</a>, <a href="/format/2401.08236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Node Embedding Distances Through $n$-order Proximity  Neighbourhoods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shakespeare%2C+D">Dougal Shakespeare</a>, 
<a href="/search/cs?searchtype=author&query=Roth%2C+C">Camille Roth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">In the field of node representation learning the task of interpreting latent
dimensions has become a prominent, well-studied research topic. The
contribution of this work focuses on appraising the interpretability of another
rarely-exploited feature of node embeddings increasingly utilised in
recommendation and consumption diversity studies: inter-node embedded
distances. Introducing a new method to measure how understandable the distances
between nodes are, our work assesses how well the proximity weights derived
from a network before embedding relate to the node closeness measurements after
embedding. Testing several classical node embedding models, our findings reach
a conclusion familiar to practitioners albeit rarely cited in literature - the
matrix factorisation model SVD is the most interpretable through 1, 2 and even
higher-order proximities.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08238" title="Abstract">arXiv:2401.08238</a> [<a href="/pdf/2401.08238" title="Download PDF">pdf</a>, <a href="/ps/2401.08238" title="Download PostScript">ps</a>, <a href="/format/2401.08238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-free Dynamic Movement Primitives Applied to Kinesthetic Guidance  in Robotic Co-manipulation Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Braglia%2C+G">Giovanni Braglia</a>, 
<a href="/search/cs?searchtype=author&query=Tebaldi%2C+D">Davide Tebaldi</a>, 
<a href="/search/cs?searchtype=author&query=Biagiotti%2C+L">Luigi Biagiotti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">When there is a need to define and adapt a robotic task based on a reference
motion, Dynamic Movement Primitives (DMP) is a standard and efficient method
for encoding it. The nominal trajectory is typically obtained through a
Programming by Demonstration (PbD) approach, where the robot is taught a
specific task through kinesthetic guidance. Subsequently, the motion is
reproduced by the manipulator in terms of both geometric path and timing law.
The basic approach for modifying the duration of the execution involves
adjusting a time constant characterizing the model. On the contrary, the goal
of this paper is to achieve complete decoupling between the geometric
information of the task, encoded into the DMP, and the phase law governing the
execution, allowing them to be chosen independently. This enables the
optimization of the task duration to satisfy constraints such as velocity or
acceleration or even to define a phase law dependent on external inputs, such
as the force applied by a user in a co-manipulation task. As an example, this
mechanism will be exploited to define a rehabilitation activity where the cobot
assists humans in performing various pre-planned exercises.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08241" title="Abstract">arXiv:2401.08241</a> [<a href="/pdf/2401.08241" title="Download PDF">pdf</a>, <a href="/ps/2401.08241" title="Download PostScript">ps</a>, <a href="/format/2401.08241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt/Exchange decisions or generic choices: Does framing influence how  people integrate qualitatively different risks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Romy M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Blunk%2C+A">Alexander Blunk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In complex systems, decision makers often have to consider qualitatively
different risks when choosing between options. Do their strategies of
integrating these risks depend on the framing of problem contents? In the
present study, participants were either instructed that they were choosing
between two ways of solving a complex problem, or between two generic options.
The former was framed as a modular plant scenario that required choices between
modifying parameter settings in a current module (Adapt) and replacing the
module by another one (Exchange). The risk was higher for Adapt to harm the
product and for Exchange to harm the plant. These risks were presented as
probabilities, and participants were either told that the consequences of both
risks were equally severe (content-same group), or that harming the plant was
much worse (content-different group). A third group made decisions based on the
same probabilities, but received a generic task framing (no-content group). We
expected framing to affect risk integration, leading the content-same group to
make different choices than the no-content group. Contrary to this hypothesis,
these two groups were strikingly similar in their decision outcomes and
strategies, but clearly differed from the content-different group. These
findings question whether ecological validity can be enhanced merely by framing
a task in terms of real-world problem contents.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08242" title="Abstract">arXiv:2401.08242</a> [<a href="/pdf/2401.08242" title="Download PDF">pdf</a>, <a href="/format/2401.08242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polygonal Sequence-driven Triangulation Validator: An Incremental  Approach to 2D Triangulation Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sawai%2C+S">Sora Sawai</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+K">Kazuaki Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+K">Katsuhisa Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Oishi%2C+S">Shin&#x27;ichi Oishi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Two-dimensional Delaunay triangulation is a fundamental aspect of
computational geometry. This paper presents a novel algorithm that is
specifically designed to ensure the correctness of 2D Delaunay triangulation,
namely the Polygonal Sequence-driven Triangulation Validator (PSTV). Our
research highlights the paramount importance of proper triangulation and the
often overlooked, yet profound, impact of rounding errors in numerical
computations on the precision of triangulation. The primary objective of the
PSTV algorithm is to identify these computational errors and ensure the
accuracy of the triangulation output. In addition to validating the correctness
of triangulation, this study underscores the significance of the Delaunay
property for the quality of finite element methods. Effective strategies are
proposed to verify this property for a triangulation and correct it when
necessary. While acknowledging the difficulty of rectifying complex
triangulation errors such as overlapping triangles, these strategies provide
valuable insights on identifying the locations of these errors and remedying
them. The unique feature of the PSTV algorithm lies in its adoption of
floating-point filters in place of interval arithmetic, striking an effective
balance between computational efficiency and precision. This research sets a
vital precedent for error reduction and precision enhancement in computational
geometry.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08245" title="Abstract">arXiv:2401.08245</a> [<a href="/pdf/2401.08245" title="Download PDF">pdf</a>, <a href="/format/2401.08245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing $k$ in $k$NN Graphs with Graph Learning Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamaru%2C+A">Asuka Tamaru</a>, 
<a href="/search/cs?searchtype=author&query=Hara%2C+J">Junya Hara</a>, 
<a href="/search/cs?searchtype=author&query=Higashi%2C+H">Hiroshi Higashi</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+Y">Yuichi Tanaka</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+A">Antonio Ortega</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose a method, based on graph signal processing, to
optimize the choice of $k$ in $k$-nearest neighbor graphs ($k$NNGs). $k$NN is
one of the most popular approaches and is widely used in machine learning and
signal processing. The parameter $k$ represents the number of neighbors that
are connected to the target node; however, its appropriate selection is still a
challenging problem. Therefore, most $k$NNGs use ad hoc selection methods for
$k$. In the proposed method, we assume that a different $k$ can be chosen for
each node. We formulate a discrete optimization problem to seek the best $k$
with a constraint on the sum of distances of the connected nodes. The optimal
$k$ values are efficiently obtained without solving a complex optimization.
Furthermore, we reveal that the proposed method is closely related to existing
graph learning methods. In experiments on real datasets, we demonstrate that
the $k$NNGs obtained with our method are sparse and can determine an
appropriate variable number of edges per node. We validate the effectiveness of
the proposed method for point cloud denoising, comparing our denoising
performance with achievable graph construction methods that can be scaled to
typical point cloud sizes (e.g., thousands of nodes).
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08249" title="Abstract">arXiv:2401.08249</a> [<a href="/pdf/2401.08249" title="Download PDF">pdf</a>, <a href="/format/2401.08249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph-based Algorithms for Linear Computation Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberger%2C+H">Hans Rosenberger</a>, 
<a href="/search/cs?searchtype=author&query=Bereyhi%2C+A">Ali Bereyhi</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R+R">Ralf R. M&#xfc;ller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 2024 International Zurich Seminar on Information and Communication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We revisit existing linear computation coding (LCC) algorithms, and introduce
a new framework that measures the computational cost of computing
multidimensional linear functions, not only in terms of the number of
additions, but also with respect to their suitability for parallel processing.
Utilizing directed acyclic graphs, which correspond to signal flow graphs in
hardware, we propose a novel LCC algorithm that controls the trade-off between
the total number of operations and their parallel executability. Numerical
evaluations show that the proposed algorithm, constrained to a fully parallel
structure, outperforms existing schemes.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08251" title="Abstract">arXiv:2401.08251</a> [<a href="/pdf/2401.08251" title="Download PDF">pdf</a>, <a href="/ps/2401.08251" title="Download PostScript">ps</a>, <a href="/format/2401.08251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A techno-economic model for avoiding conflicts of interest between  owners of offshore wind farms and maintenance suppliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marug%C3%A1n%2C+A+P">Alberto Pliego Marug&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A1rquez%2C+F+P+G">Fausto Pedro Garc&#xed;a M&#xe1;rquez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+M+P">Jes&#xfa;s Mar&#xed;a Pinar P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Renewable and Sustainable Energy Reviews (ELSEVIER) 10 July 2022. DOI: <a href="https://doi.org/10.1016/j.rser.2022.112753">this https URL</a> Cite as: Marug\'an, A. P., M\'arquez, F. P. G., &amp; P\'erez, J. M. P. (2022). A techno-economic model for avoiding conflicts of interest between owners of offshore wind farms and maintenance suppliers. Renewable and Sustainable Energy Reviews, 168, 112753
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; General Economics (econ.GN); Systems and Control (eess.SY)

</div>
<p class="mathjax">Currently, wind energy is one of the most important sources of renewable
energy. Offshore locations for wind turbines are increasingly exploited because
of their numerous advantages. However, offshore wind farms require high
investment in maintenance service. Due to its complexity and special
requirements, maintenance service is usually outsourced by wind farm owners. In
this paper, we propose a novel approach to determine, quantify, and reduce the
possible conflicts of interest between owners and maintenance suppliers. We
created a complete techno-economic model to address this problem from an
impartial point of view. An iterative process was developed to obtain
statistical results that can help stakeholders negotiate the terms of the
contract, in which the availability of the wind farm is the reference parameter
by which to determine penalisations and incentives. Moreover, a multi-objective
programming problem was addressed that maximises the profits of both parties
without losing the alignment of their interests. The main scientific
contribution of this paper is the maintenance analysis of offshore wind farms
from two perspectives: that of the owner and the maintenance supplier. This
analysis evaluates the conflicts of interest of both parties. In addition, we
demonstrate that proper adjustment of some parameters, such as penalisation,
incentives, and resources, and adequate control of availability can help reduce
this conflict of interests.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08255" title="Abstract">arXiv:2401.08255</a> [<a href="/pdf/2401.08255" title="Download PDF">pdf</a>, <a href="/format/2401.08255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Adversarial Attack for Multilingual Text Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roth%2C+T">Tom Roth</a>, 
<a href="/search/cs?searchtype=author&query=Unanue%2C+I+J">Inigo Jauregi Unanue</a>, 
<a href="/search/cs?searchtype=author&query=Abuadbba%2C+A">Alsharif Abuadbba</a>, 
<a href="/search/cs?searchtype=author&query=Piccardi%2C+M">Massimo Piccardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24 Workshop on Artificial Intelligence for Cyber Security (AICS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Current adversarial attack algorithms, where an adversary changes a text to
fool a victim model, have been repeatedly shown to be effective against text
classifiers. These attacks, however, generally assume that the victim model is
monolingual and cannot be used to target multilingual victim models, a
significant limitation given the increased use of these models. For this
reason, in this work we propose an approach to fine-tune a multilingual
paraphrase model with an adversarial objective so that it becomes able to
generate effective adversarial examples against multilingual classifiers. The
training objective incorporates a set of pre-trained models to ensure text
quality and language consistency of the generated text. In addition, all the
models are suitably connected to the generator by vocabulary-mapping matrices,
allowing for full end-to-end differentiability of the overall training
pipeline. The experimental validation over two multilingual datasets and five
languages has shown the effectiveness of the proposed approach compared to
existing baselines, particularly in terms of query efficiency. We also provide
a detailed analysis of the generated attacks and discuss limitations and
opportunities for future research.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08256" title="Abstract">arXiv:2401.08256</a> [<a href="/pdf/2401.08256" title="Download PDF">pdf</a>, <a href="/format/2401.08256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multitask Learning in Minimally Invasive Surgical Vision: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabi%2C+O">Oluwatosin Alabi</a>, 
<a href="/search/cs?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Miaojing Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Minimally invasive surgery (MIS) has revolutionized many procedures and led
to reduced recovery time and risk of patient injury. However, MIS poses
additional complexity and burden on surgical teams. Data-driven surgical vision
algorithms are thought to be key building blocks in the development of future
MIS systems with improved autonomy. Recent advancements in machine learning and
computer vision have led to successful applications in analyzing videos
obtained from MIS with the promise of alleviating challenges in MIS videos.
Surgical scene and action understanding encompasses multiple related tasks
that, when solved individually, can be memory-intensive, inefficient, and fail
to capture task relationships. Multitask learning (MTL), a learning paradigm
that leverages information from multiple related tasks to improve performance
and aid generalization, is wellsuited for fine-grained and high-level
understanding of MIS data. This review provides an overview of the current
state-of-the-art MTL systems that leverage videos obtained from MIS. Beyond
listing published approaches, we discuss the benefits and limitations of these
MTL systems. Moreover, this manuscript presents an analysis of the literature
for various application fields of MTL in MIS, including those with large
models, highlighting notable trends, new directions of research, and
developments.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08258" title="Abstract">arXiv:2401.08258</a> [<a href="/pdf/2401.08258" title="Download PDF">pdf</a>, <a href="/format/2401.08258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time, Simultaneity, and Causality in Wireless Networks with Sensing and  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Wireless systems beyond 5G evolve towards embracing both sensing and
communication, resulting in increased convergence of the digital and the
physical world. The existence of fused digital-physical realms raises critical
questions regarding temporal ordering, causality, and the synchronization of
events. This paper addresses the temporal challenges arising from the fact that
the wireless infrastructure becomes an entity with multisensory perception.
With the growing reliance on real-time interactions and applications such as
digital twins, extended reality, and the metaverse, the need for accurate
timestamping and temporal forensics becomes crucial. The paper introduces a
model that incorporates Temporal Windows of Integration (TWI) to emulate human
multisensory perception and discusses the implications for setting timing
constraints in real-time applications and enabling temporal forensics. The
analysis explores trade-offs, probabilities, and bounds for simultaneity and
causality violation in the context of wireless systems evolving towards
perceptive networks. This work underscores the significance of timestamping in
the evolving wireless landscape, provide insights into system-level
implications, and points out new research avenues for systems that combine
sensing and communications.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08260" title="Abstract">arXiv:2401.08260</a> [<a href="/pdf/2401.08260" title="Download PDF">pdf</a>, <a href="/format/2401.08260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Kernel Summation in High Dimensions via Slicing and Fourier  Transforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hertrich%2C+J">Johannes Hertrich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Kernel-based methods are heavily used in machine learning. However, they
suffer from $O(N^2)$ complexity in the number $N$ of considered data points. In
this paper, we propose an approximation procedure, which reduces this
complexity to $O(N)$. Our approach is based on two ideas. First, we prove that
any radial kernel with analytic basis function can be represented as sliced
version of some one-dimensional kernel and derive an analytic formula for the
one-dimensional counterpart. It turns out that the relation between one- and
$d$-dimensional kernels is given by a generalized Riemann-Liouville fractional
integral. Hence, we can reduce the $d$-dimensional kernel summation to a
one-dimensional setting. Second, for solving these one-dimensional problems
efficiently, we apply fast Fourier summations on non-equispaced data, a sorting
algorithm or a combination of both. Due to its practical importance we pay
special attention to the Gaussian kernel, where we show a dimension-independent
error bound and represent its one-dimensional counterpart via a closed-form
Fourier transform. We provide a run time comparison and error estimate of our
fast kernel summations.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08261" title="Abstract">arXiv:2401.08261</a> [<a href="/pdf/2401.08261" title="Download PDF">pdf</a>, <a href="/format/2401.08261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistically Robust Watermarking of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pautov%2C+M">Mikhail Pautov</a>, 
<a href="/search/cs?searchtype=author&query=Bogdanov%2C+N">Nikita Bogdanov</a>, 
<a href="/search/cs?searchtype=author&query=Pyatkin%2C+S">Stanislav Pyatkin</a>, 
<a href="/search/cs?searchtype=author&query=Rogov%2C+O">Oleg Rogov</a>, 
<a href="/search/cs?searchtype=author&query=Oseledets%2C+I">Ivan Oseledets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As deep learning (DL) models are widely and effectively used in Machine
Learning as a Service (MLaaS) platforms, there is a rapidly growing interest in
DL watermarking techniques that can be used to confirm the ownership of a
particular model. Unfortunately, these methods usually produce watermarks
susceptible to model stealing attacks. In our research, we introduce a novel
trigger set-based watermarking approach that demonstrates resilience against
functionality stealing attacks, particularly those involving extraction and
distillation. Our approach does not require additional model training and can
be applied to any model architecture. The key idea of our method is to compute
the trigger set, which is transferable between the source model and the set of
proxy models with a high probability. In our experimental study, we show that
if the probability of the set being transferable is reasonably high, it can be
effectively used for ownership verification of the stolen model. We evaluate
our method on multiple benchmarks and show that our approach outperforms
current state-of-the-art watermarking techniques in all considered experimental
setups.
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08263" title="Abstract">arXiv:2401.08263</a> [<a href="/pdf/2401.08263" title="Download PDF">pdf</a>, <a href="/format/2401.08263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Technique Sequential Information Consistency For Dynamic Visual  Place Recognition In Changing Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcanjo%2C+B">Bruno Arcanjo</a>, 
<a href="/search/cs?searchtype=author&query=Ferrarini%2C+B">Bruno Ferrarini</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>, 
<a href="/search/cs?searchtype=author&query=McDonald-Maier%2C+K+D">Klaus D. McDonald-Maier</a>, 
<a href="/search/cs?searchtype=author&query=Ehsan%2C+S">Shoaib Ehsan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.14247">arXiv:2303.14247</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visual place recognition (VPR) is an essential component of robot navigation
and localization systems that allows them to identify a place using only image
data. VPR is challenging due to the significant changes in a place's appearance
driven by different daily illumination, seasonal weather variations and diverse
viewpoints. Currently, no single VPR technique excels in every environmental
condition, each exhibiting unique benefits and shortcomings, and therefore
combining multiple techniques can achieve more reliable VPR performance.
Present multi-method approaches either rely on online ground-truth information,
which is often not available, or on brute-force technique combination,
potentially lowering performance with high variance technique sets. Addressing
these shortcomings, we propose a VPR system dubbed Multi-Sequential Information
Consistency (MuSIC) which leverages sequential information to select the most
cohesive technique on an online per-frame basis. For each technique in a set,
MuSIC computes their respective sequential consistencies by analysing the
frame-to-frame continuity of their top match candidates, which are then
directly compared to select the optimal technique for the current query image.
The use of sequential information to select between VPR methods results in an
overall VPR performance increase across different benchmark datasets, while
avoiding the need for extra ground-truth of the runtime environment.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08264" title="Abstract">arXiv:2401.08264</a> [<a href="/pdf/2401.08264" title="Download PDF">pdf</a>, <a href="/ps/2401.08264" title="Download PostScript">ps</a>, <a href="/format/2401.08264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Transpiler for C/C++ to Safer Rust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tripuramallu%2C+D">Dhiren Tripuramallu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Swapnil Singh</a>, 
<a href="/search/cs?searchtype=author&query=Deshmukh%2C+S">Shrirang Deshmukh</a>, 
<a href="/search/cs?searchtype=author&query=Pinisetty%2C+S">Srinivas Pinisetty</a>, 
<a href="/search/cs?searchtype=author&query=Shivaji%2C+S+A">Shinde Arjun Shivaji</a>, 
<a href="/search/cs?searchtype=author&query=Balusamy%2C+R">Raja Balusamy</a>, 
<a href="/search/cs?searchtype=author&query=Bandeppa%2C+A">Ajaganna Bandeppa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">Rust is a multi-paradigm programming language developed by Mozilla that
focuses on performance and safety. Rust code is arguably known best for its
speed and memory safety, a property essential while developing embedded
systems. Thus, it becomes one of the alternatives when developing operating
systems for embedded devices. How to convert an existing C++ code base to Rust
is also gaining greater attention. In this work, we focus on the process of
transpiling C++ code to a Rust codebase in a robust and safe manner. The manual
transpilation process is carried out to understand the different constructs of
the Rust language and how they correspond to C++ constructs. Based on the
learning from the manual transpilation, a transpilation table is created to aid
in future transpilation efforts and to develop an automated transpiler. We also
studied the existing automated transpilers and identified the problems and
inefficiencies they involved. The results of the transpilation process were
closely monitored and evaluated, showing improved memory safety without
compromising performance and reliability of the resulting codebase. The study
concludes with a comprehensive analysis of the findings, an evaluation of the
implications for future research, and recommendations for the same in this
area.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08267" title="Abstract">arXiv:2401.08267</a> [<a href="/pdf/2401.08267" title="Download PDF">pdf</a>, <a href="/format/2401.08267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ranking Heterogeneous Search Result Pages using the Interactive  Probability Ranking Principle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzopardi%2C+K+P+L">Kanaad Pathak. Leif Azzopardi</a>, 
<a href="/search/cs?searchtype=author&query=Halvey%2C+M">Martin Halvey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented as a full paper at ECIR 2024 in Glasgow, UK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The Probability Ranking Principle (PRP) ranks search results based on their
expected utility derived solely from document contents, often overlooking the
nuances of presentation and user interaction. However, with the evolution of
Search Engine Result Pages (SERPs), now comprising a variety of result cards,
the manner in which these results are presented is pivotal in influencing user
engagement and satisfaction. This shift prompts the question: How does the PRP
and its user-centric counterpart, the Interactive Probability Ranking Principle
(iPRP), compare in the context of these heterogeneous SERPs? Our study draws a
comparison between the PRP and the iPRP, revealing significant differences in
their output. The iPRP, accounting for item-specific costs and interaction
probabilities to determine the ``Expected Perceived Utility" (EPU), yields
different result orderings compared to the PRP. We evaluate the effect of the
EPU on the ordering of results by observing changes in the ranking within a
heterogeneous SERP compared to the traditional ``ten blue links''. We find that
changing the presentation affects the ranking of items according to the (iPRP)
by up to 48\% (with respect to DCG, TBG and RBO) in ad-hoc search tasks on the
TREC WaPo Collection. This work suggests that the iPRP should be employed when
ranking heterogeneous SERPs to provide a user-centric ranking that adapts the
ordering based on the presentation and user engagement.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08272" title="Abstract">arXiv:2401.08272</a> [<a href="/pdf/2401.08272" title="Download PDF">pdf</a>, <a href="/format/2401.08272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Siamese Content-based Search Engine for a More Transparent Skin and  Breast Cancer Diagnosis through Histological Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tabatabaei%2C+Z">Zahra Tabatabaei</a>, 
<a href="/search/cs?searchtype=author&query=Colomer%2C+A">Adri&#xe1;n Colomer</a>, 
<a href="/search/cs?searchtype=author&query=Moll%2C+J+O">JAvier Oliver Moll</a>, 
<a href="/search/cs?searchtype=author&query=Naranjo%2C+V">Valery Naranjo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Computer Aid Diagnosis (CAD) has developed digital pathology with Deep
Learning (DL)-based tools to assist pathologists in decision-making.
Content-Based Histopathological Image Retrieval (CBHIR) is a novel tool to seek
highly correlated patches in terms of similarity in histopathological features.
In this work, we proposed two CBHIR approaches on breast (Breast-twins) and
skin cancer (Skin-twins) data sets for robust and accurate patch-level
retrieval, integrating a custom-built Siamese network as a feature extractor.
The proposed Siamese network is able to generalize for unseen images by
focusing on the similar histopathological features of the input pairs. The
proposed CBHIR approaches are evaluated on the Breast (public) and Skin
(private) data sets with top K accuracy. Finding the optimum amount of K is
challenging, but also, as much as K increases, the dissimilarity between the
query and the returned images increases which might mislead the pathologists.
To the best of the author's belief, this paper is tackling this issue for the
first time on histopathological images by evaluating the top first retrieved
images. The Breast-twins model achieves 70% of the F1score at the top first,
which exceeds the other state-of-the-art methods at a higher amount of K such
as 5 and 400. Skin-twins overpasses the recently proposed Convolutional Auto
Encoder (CAE) by 67%, increasing the precision. Besides, the Skin-twins model
tackles the challenges of Spitzoid Tumors of Uncertain Malignant Potential
(STUMP) to assist pathologists with retrieving top K images and their
corresponding labels. So, this approach can offer a more explainable CAD tool
to pathologists in terms of transparency, trustworthiness, or reliability among
other characteristics.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08273" title="Abstract">arXiv:2401.08273</a> [<a href="/pdf/2401.08273" title="Download PDF">pdf</a>, <a href="/format/2401.08273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Null-Shot Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taveekitworachai%2C+P">Pittawat Taveekitworachai</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+F">Febri Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Thawonmas%2C+R">Ruck Thawonmas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents null-shot prompting. Null-shot prompting exploits
hallucination in large language models (LLMs) by instructing LLMs to utilize
information from the "Examples" section that never exists within the provided
context to perform a task. While reducing hallucination is crucial and
non-negligible for daily and critical uses of LLMs, we propose that in the
current landscape in which these LLMs still hallucinate, it is possible, in
fact, to exploit hallucination to increase performance in performing tasks
compared to standard zero-shot prompting. Experiments with six LLMs show
improvements in performance across the majority of eight datasets, including
reading comprehension, arithmetic reasoning, and closed-book question
answering. The observed inconsistency in increased relative performance across
LLMs also potentially indicates a different degree of inherent hallucination in
each model. These differences show that it is possible to utilize null-shot
prompting as a way to detect degrees of hallucination in LLMs using existing
benchmarking datasets. We also perform ablation studies, including
experimenting with a modified version of null-shot prompting that incorporates
ideas from zero-shot chain-of-thought prompting, which shows different trends
of results.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08275" title="Abstract">arXiv:2401.08275</a> [<a href="/pdf/2401.08275" title="Download PDF">pdf</a>, <a href="/format/2401.08275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Spoof Noise by De-spoofing Diffusion and its Application in  Face Anti-spoofing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiangyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCB2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Face anti-spoofing is crucial for ensuring the security and reliability of
face recognition systems. Several existing face anti-spoofing methods utilize
GAN-like networks to detect presentation attacks by estimating the noise
pattern of a spoof image and recovering the corresponding genuine image. But
GAN's limited face appearance space results in the denoised faces cannot cover
the full data distribution of genuine faces, thereby undermining the
generalization performance of such methods. In this work, we present a
pioneering attempt to employ diffusion models to denoise a spoof image and
restore the genuine image. The difference between these two images is
considered as the spoof noise, which can serve as a discriminative cue for face
anti-spoofing. We evaluate our proposed method on several intra-testing and
inter-testing protocols, where the experimental results showcase the
effectiveness of our method in achieving competitive performance in terms of
both accuracy and generalization.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08276" title="Abstract">arXiv:2401.08276</a> [<a href="/pdf/2401.08276" title="Download PDF">pdf</a>, <a href="/format/2401.08276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AesBench: An Expert Benchmark for Multimodal Large Language Models on  Image Aesthetics Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yipo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Q">Quan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+X">Xiangfei Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhichao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pengfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuzhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leida Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">With collective endeavors, multimodal large language models (MLLMs) are
undergoing a flourishing development. However, their performances on image
aesthetics perception remain indeterminate, which is highly desired in
real-world applications. An obvious obstacle lies in the absence of a specific
benchmark to evaluate the effectiveness of MLLMs on aesthetic perception. This
blind groping may impede the further development of more advanced MLLMs with
aesthetic perception capacity. To address this dilemma, we propose AesBench, an
expert benchmark aiming to comprehensively evaluate the aesthetic perception
capacities of MLLMs through elaborate design across dual facets. (1) We
construct an Expert-labeled Aesthetics Perception Database (EAPD), which
features diversified image contents and high-quality annotations provided by
professional aesthetic experts. (2) We propose a set of integrative criteria to
measure the aesthetic perception abilities of MLLMs from four perspectives,
including Perception (AesP), Empathy (AesE), Assessment (AesA) and
Interpretation (AesI). Extensive experimental results underscore that the
current MLLMs only possess rudimentary aesthetic perception ability, and there
is still a significant gap between MLLMs and humans. We hope this work can
inspire the community to engage in deeper explorations on the aesthetic
potentials of MLLMs. Source data will be available at
https://github.com/yipoh/AesBench.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08281" title="Abstract">arXiv:2401.08281</a> [<a href="/pdf/2401.08281" title="Download PDF">pdf</a>, <a href="/format/2401.08281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Faiss library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Douze%2C+M">Matthijs Douze</a>, 
<a href="/search/cs?searchtype=author&query=Guzhva%2C+A">Alexandr Guzhva</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chengqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+J">Jeff Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Szilvasy%2C+G">Gergely Szilvasy</a>, 
<a href="/search/cs?searchtype=author&query=Mazar%C3%A9%2C+P">Pierre-Emmanuel Mazar&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Lomeli%2C+M">Maria Lomeli</a>, 
<a href="/search/cs?searchtype=author&query=Hosseini%2C+L">Lucas Hosseini</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%A9gou%2C+H">Herv&#xe9; J&#xe9;gou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Software Engineering (cs.SE)

</div>
<p class="mathjax">Vector databases manage large collections of embedding vectors. As AI
applications are growing rapidly, so are the number of embeddings that need to
be stored and indexed. The Faiss library is dedicated to vector similarity
search, a core functionality of vector databases. Faiss is a toolkit of
indexing methods and related primitives used to search, cluster, compress and
transform vectors. This paper first describes the tradeoff space of vector
search, then the design principles of Faiss in terms of structure, approach to
optimization and interfacing. We benchmark key features of the library and
discuss a few selected applications to highlight its broad applicability.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08282" title="Abstract">arXiv:2401.08282</a> [<a href="/pdf/2401.08282" title="Download PDF">pdf</a>, <a href="/format/2401.08282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear stiffness allows passive dynamic hopping for one-legged robots  with an upright trunk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ossadnik%2C+D">Dennis Ossadnik</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+E">Elisabeth Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2021 IEEE International Conference on Robotics and Automation
  (ICRA 2021), May 31 - June 4, 2021, Xi'an, China, pp. 3047 - 3053
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Template models are frequently used to simplify the control dynamics for
robot hopping or running. Passive limit cycles can emerge for such systems and
be exploited for energy-efficient control. A grand challenge in locomotion is
trunk stabilization when the hip is offset from the center of mass (CoM). The
swing phase plays a major role in this process due to the moment of inertia of
the leg; however, many template models ignore the leg mass. In this work, the
authors consider a robot hopper model (RHM) with a rigid trunk and leg plus a
hip that is displaced from the CoM. It has been previously shown that no
passive limit cycle exists for such a model given a linear hip spring. In this
work, we show that passive limit cycles can be found when a nonlinear hip
spring is used instead. To the authors' knowledge, this is the first time that
a passive limit cycle has been found for this type of system.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08287" title="Abstract">arXiv:2401.08287</a> [<a href="/pdf/2401.08287" title="Download PDF">pdf</a>, <a href="/format/2401.08287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RichWasm: Bringing Safe, Fine-Grained, Shared-Memory Interoperability  Down to WebAssembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paraskevopoulou%2C+Z">Zoe Paraskevopoulou</a>, 
<a href="/search/cs?searchtype=author&query=Fitzgibbons%2C+M">Michael Fitzgibbons</a>, 
<a href="/search/cs?searchtype=author&query=Thalakottur%2C+M">Michelle Thalakottur</a>, 
<a href="/search/cs?searchtype=author&query=Mushtak%2C+N">Noble Mushtak</a>, 
<a href="/search/cs?searchtype=author&query=Mazur%2C+J+S">Jose Sulaiman Mazur</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A">Amal Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Safe, shared-memory interoperability between languages with different type
systems and memory-safety guarantees is an intricate problem as crossing
language boundaries may result in memory-safety violations. In this paper, we
present RichWasm, a novel richly typed intermediate language designed to serve
as a compilation target for typed high-level languages with different
memory-safety guarantees. RichWasm is based on WebAssembly and enables safe
shared-memory interoperability by incorporating a variety of type features that
support fine-grained memory ownership and sharing. RichWasm is rich enough to
serve as a typed compilation target for both typed garbage-collected languages
and languages with an ownership-based type system and manually managed memory.
We demonstrate this by providing compilers from core ML and L3, a type-safe
language with strong updates, to RichWasm. RichWasm is compiled to regular
Wasm, allowing for use in existing environments. We formalize RichWasm in Coq
and prove type safety.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08292" title="Abstract">arXiv:2401.08292</a> [<a href="/pdf/2401.08292" title="Download PDF">pdf</a>, <a href="/format/2401.08292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ULT-model: Towards a one-legged unified locomotion template model for  forward hopping with an upright trunk
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ossadnik%2C+D">Dennis Ossadnik</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+E">Elisabeth Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2021 IEEE International Conference on Robotics and Automation
  (ICRA 2021), May 31 - June 4, 2021, Xi'an, China, pp. 3040-3046
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">While many advancements have been made in the development of template models
for describing upright-trunk locomotion, the majority of the effort has been
focused on the stance phase. In this paper, we develop a new compact dynamic
model as a first step toward a fully unified locomotion template model
(ULT-model) of an upright-trunk forward hopping system, which will also require
a unified control law in the next step. We demonstrate that all locomotion
subfunctions are enabled by adding just a point foot mass and a parallel leg
actuator to the well-known trunk SLIP model and that a stable limit cycle can
be achieved. This brings us closer toward the ultimate goal of enabling
closed-loop dynamics for anchor matching and thus achieving simple, efficient,
robust and stable upright-trunk gait control, as observed in biological
systems.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08294" title="Abstract">arXiv:2401.08294</a> [<a href="/pdf/2401.08294" title="Download PDF">pdf</a>, <a href="/format/2401.08294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferflow: an Efficient and Highly Configurable Inference Engine for  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huayang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report of Inferflow
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present Inferflow, an efficient and highly configurable inference engine
for large language models (LLMs). With Inferflow, users can serve most of the
common transformer models by simply modifying some lines in corresponding
configuration files, without writing a single line of source code. Compared
with most existing inference engines, Inferflow has some key features. First,
by implementing a modular framework of atomic build-blocks and technologies,
Inferflow is compositionally generalizable to new models. Second, 3.5-bit
quantization is introduced in Inferflow as a tradeoff between 3-bit and 4-bit
quantization. Third, hybrid model partitioning for multi-GPU inference is
introduced in Inferflow to better balance inference speed and throughput than
the existing partition-by-layer and partition-by-tensor strategies.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08295" title="Abstract">arXiv:2401.08295</a> [<a href="/pdf/2401.08295" title="Download PDF">pdf</a>, <a href="/format/2401.08295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAPT: A Dual Attention Framework for Parameter-Efficient Continual  Learning of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Weixiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yulin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuanyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+W">Wanxiang Che</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The continual learning (CL) ability is vital for deploying large language
models (LLMs) in the dynamic world. Based on parameter-efficient tuning (PET),
existing methods devise the learning module and the selection module to handle
the challenges of catastrophic forgetting (CF) and knowledge transfer (KT) in
CL. The learning module allocates separate PET blocks for each continually
emerged task and the selection module function to choose the correct one for
the input at testing time. However, there are limitations in their deigns of
both modules and they ignore the potential of aligning the two module to
address CF and KT simultaneously. To this end, we propose a novel Dual
Attention Framework , to align the PET learning and selection via the Dual
Attentive Learning\&amp;Selection module. Extensive Experiments on two CL
benchmarks demonstrate the superiority of DAPT to resist CF and facilitate KT
at the same time. Moreover, DAPT exhibits the superiority when we scale it to
different model sizes (from 770M to 11B) and unseen tasks.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08297" title="Abstract">arXiv:2401.08297</a> [<a href="/pdf/2401.08297" title="Download PDF">pdf</a>, <a href="/format/2401.08297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The extension of zbMATH Open by arXiv preprints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beckenbach%2C+I">Isabel Beckenbach</a>, 
<a href="/search/cs?searchtype=author&query=Hulek%2C+K">Klaus Hulek</a>, 
<a href="/search/cs?searchtype=author&query=Teschke%2C+O">Olaf Teschke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; History and Overview (math.HO)

</div>
<p class="mathjax">zbMATH Open has started a new feature -- relevant preprints posted at arXiv
will also be displayed in the database. In this article we introduce this new
feature and the underlying editorial policy. We also describe some of the
technical issues involved and discuss the challenges this presents for future
developments.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08298" title="Abstract">arXiv:2401.08298</a> [<a href="/pdf/2401.08298" title="Download PDF">pdf</a>, <a href="/ps/2401.08298" title="Download PostScript">ps</a>, <a href="/format/2401.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating online elasticity estimation of soft objects using standard  robot grippers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patni%2C+S+P">Shubhan P. Patni</a>, 
<a href="/search/cs?searchtype=author&query=Stoudek%2C+P">Pavel Stoudek</a>, 
<a href="/search/cs?searchtype=author&query=Chlup%2C+H">Hynek Chlup</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+M">Matej Hoffmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Standard robot grippers are not designed for elasticity estimation. In this
work, a professional biaxial compression device was used as a control setup to
study the accuracy with which material properties can be estimated by two
standard parallel jaw grippers and a force/torque sensor mounted at the robot
wrist. Using three sets of deformable objects, different parameters were varied
to observe their effect on measuring material characteristics: (1) repeated
compression cycles, (2) compression speed, and (3) the surface area of the
gripper jaws. Gripper effort versus position curves were obtained and
transformed into stress/strain curves. The modulus of elasticity was estimated
at different strain points. Viscoelasticity was assessed using the energy
absorbed in a compression/decompression cycle, the Kelvin-Voigt, and
Hunt-Crossley models. Our results can be summarized as follows: (1) better
results were obtained with slower compression speeds, while additional
compression cycles or surface area did not improve estimation; (2) the robot
grippers, even after calibration, were found to have a limited capability of
delivering accurate estimates of absolute values of Young's modulus and
viscoelasticity; (3) relative ordering of material characteristics was largely
consistent across different grippers; (4) despite the nonlinear characteristics
of deformable objects, fitting linear stress/strain approximations led to more
stable results than local estimates of Young's modulus; (5) to assess
viscoelasticity, the Hunt-Crossley model worked best. Finally, we show that a
two-dimensional space representing elasticity and viscoelasticity estimates is
advantageous for the discrimination of deformable objects. A single-grasp,
online, classification and sorting of such objects is thus possible. An
additional contribution is the dataset and data processing codes that we make
publicly available.
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08309" title="Abstract">arXiv:2401.08309</a> [<a href="/pdf/2401.08309" title="Download PDF">pdf</a>, <a href="/format/2401.08309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anchor function: a type of benchmark functions for studying language  models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhongwang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Junjie Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhangchen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaolong Li</a>, 
<a href="/search/cs?searchtype=author&query=E%2C+W">Weinan E</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z+J">Zhi-Qin John Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding transformer-based language models is becoming increasingly
crucial, particularly as they play pivotal roles in advancing towards
artificial general intelligence. However, language model research faces
significant challenges, especially for academic research groups with
constrained resources. These challenges include complex data structures,
unknown target functions, high computational costs and memory requirements, and
a lack of interpretability in the inference process, etc. Drawing a parallel to
the use of simple models in scientific research, we propose the concept of an
anchor function. This is a type of benchmark function designed for studying
language models in learning tasks that follow an "anchor-key" pattern. By
utilizing the concept of an anchor function, we can construct a series of
functions to simulate various language tasks. The anchor function plays a role
analogous to that of mice in diabetes research, particularly suitable for
academic research. We demonstrate the utility of the anchor function with an
example, revealing two basic operations by attention structures in language
models: shifting tokens and broadcasting one token from one position to many
positions. These operations are also commonly observed in large language
models. The anchor function framework, therefore, opens up a series of valuable
and accessible research questions for further exploration, especially for
theoretical study.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08315" title="Abstract">arXiv:2401.08315</a> [<a href="/pdf/2401.08315" title="Download PDF">pdf</a>, <a href="/format/2401.08315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of LLM Agents in Recruitment: A Novel Framework for Resume  Screening
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chengguang Gan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mori%2C+T">Tatsunori Mori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review, 14 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The automation of resume screening is a crucial aspect of the recruitment
process in organizations. Automated resume screening systems often encompass a
range of natural language processing (NLP) tasks. The advent of Large Language
Models (LLMs) has notably enhanced the efficacy of these systems, showcasing
their robust generalization abilities across diverse language-related tasks.
Accompanying these developments are various agents based on LLMs, which
facilitate their application in practical scenarios. This paper introduces a
novel LLM-based agent framework for resume screening, aimed at enhancing
efficiency and time management in recruitment processes. Our framework is
distinct in its ability to efficiently summarize and grade each resume from a
large dataset. Moreover, it utilizes LLM agents for decision-making,
determining which candidates receive job offers, or which ones to bring in for
interviews. To evaluate our framework, we constructed a dataset from actual
resumes and conducted simulate a resume screening process. Subsequently, the
outcomes of the simulation experiment were compared and subjected to detailed
analysis. The results demonstrate that our automated resume screening framework
is 11 times faster than traditional manual methods. Furthermore, by fine-tuning
the LLMs, we observed a significant improvement in the F1 score, reaching
87.73\%, during the resume sentence classification phase. In the resume
summarization and grading phase, our fine-tuned model surpassed the baseline
performance of the GPT-3.5 model. Analysis of the decision-making efficacy of
the LLM agents in the final offer stage further underscores the potential of
LLM agents in transforming resume screening processes.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08318" title="Abstract">arXiv:2401.08318</a> [<a href="/pdf/2401.08318" title="Download PDF">pdf</a>, <a href="/format/2401.08318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenDPD: An Open-Source End-to-End Learning &amp; Benchmarking Framework for  Wideband Power Amplifier Modeling and Digital Pre-Distortion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yizhuo Wu</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+G+D">Gagan Deep Singh</a>, 
<a href="/search/cs?searchtype=author&query=Beikmirza%2C+M">Mohammadreza Beikmirza</a>, 
<a href="/search/cs?searchtype=author&query=de+Vreede%2C+L">Leo de Vreede</a>, 
<a href="/search/cs?searchtype=author&query=Alavi%2C+M">Morteza Alavi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at the 2024 IEEE International Symposium on Circuits and Systems (ISCAS), Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">With the rise in communication capacity, deep neural networks (DNN) for
digital pre-distortion (DPD) to correct non-linearity in wideband power
amplifiers (PAs) have become prominent. Yet, there is a void in open-source and
measurement-setup-independent platforms for fast DPD exploration and objective
DPD model comparison. This paper presents an open-source framework, OpenDPD,
crafted in PyTorch, with an associated dataset for PA modeling and DPD
learning. We introduce a Dense Gated Recurrent Unit (DGRU)-DPD, trained via a
novel end-to-end learning architecture, outperforming previous DPD models on a
digital PA DPA in the new digital transmitter (DTX) architecture with
unconventional transfer characteristics compared to analog PAs. Measurements
show our DGRU-DPD achieves an ACPR of -44.69/-44.47 dBc and an EVM of -35.22 dB
for 200 MHz OFDM signals. OpenDPD code, datasets, and documentation are
publicly available at https://github.com/lab-emi/OpenDPD.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08326" title="Abstract">arXiv:2401.08326</a> [<a href="/pdf/2401.08326" title="Download PDF">pdf</a>, <a href="/format/2401.08326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large  Language Models in Tool Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixian Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Tool learning has generated widespread interest as a vital means of
interaction between Large Language Models (LLMs) and the physical world.
Current research predominantly emphasizes LLMs' capacity to utilize tools in
well-structured environments while overlooking their stability when confronted
with the inevitable noise of the real world. To bridge this gap, we introduce
RoTBench, a multi-level benchmark for evaluating the robustness of LLMs in tool
learning. Specifically, we establish five external environments, each featuring
varying levels of noise (i.e., Clean, Slight, Medium, Heavy, and Union),
providing an in-depth analysis of the model's resilience across three critical
phases: tool selection, parameter identification, and content filling.
Experiments involving six widely-used models underscore the urgent necessity
for enhancing the robustness of LLMs in tool learning. For instance, the
performance of GPT-4 even drops significantly from 80.00 to 58.10 when there is
no substantial change in manual accuracy. More surprisingly, the noise
correction capability inherent in the GPT family paradoxically impedes its
adaptability in the face of mild noise. In light of these findings, we propose
RoTTuning, a strategy that enriches the diversity of training environments to
bolster the robustness of LLMs in tool learning. The code and data are
available at https://github.com/Junjie-Ye/RoTBench.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08327" title="Abstract">arXiv:2401.08327</a> [<a href="/pdf/2401.08327" title="Download PDF">pdf</a>, <a href="/format/2401.08327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn What You Need in Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+K">Kexin Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Personalized federated learning aims to address data heterogeneity across
local clients in federated learning. However, current methods blindly
incorporate either full model parameters or predefined partial parameters in
personalized federated learning. They fail to customize the collaboration
manner according to each local client's data characteristics, causing
unpleasant aggregation results. To address this essential issue, we propose
$\textit{Learn2pFed}$, a novel algorithm-unrolling-based personalized federated
learning framework, enabling each client to adaptively select which part of its
local model parameters should participate in collaborative training. The key
novelty of the proposed $\textit{Learn2pFed}$ is to optimize each local model
parameter's degree of participant in collaboration as learnable parameters via
algorithm unrolling methods. This approach brings two benefits: 1)
mathmatically determining the participation degree of local model parameters in
the federated collaboration, and 2) obtaining more stable and improved
solutions. Extensive experiments on various tasks, including regression,
forecasting, and image classification, demonstrate that $\textit{Learn2pFed}$
significantly outperforms previous personalized federated learning methods.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08328" title="Abstract">arXiv:2401.08328</a> [<a href="/pdf/2401.08328" title="Download PDF">pdf</a>, <a href="/format/2401.08328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal  Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tomar%2C+D">Devavrat Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Vray%2C+G">Guillaume Vray</a>, 
<a href="/search/cs?searchtype=author&query=Thiran%2C+J">Jean-Philippe Thiran</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgtabar%2C+B">Behzad Bozorgtabar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In an era where test-time adaptation methods increasingly rely on the nuanced
manipulation of batch normalization (BN) parameters, one critical assumption
often goes overlooked: that of independently and identically distributed
(i.i.d.) test batches with respect to unknown labels. This assumption
culminates in biased estimates of BN statistics and jeopardizes system
stability under non-i.i.d. conditions. This paper pioneers a departure from the
i.i.d. paradigm by introducing a groundbreaking strategy termed "Un-Mixing
Test-Time Normalization Statistics" (UnMix-TNS). UnMix-TNS re-calibrates the
instance-wise statistics used to normalize each instance in a batch by mixing
it with multiple unmixed statistics components, thus inherently simulating the
i.i.d. environment. The key lies in our innovative online unmixing procedure,
which persistently refines these statistics components by drawing upon the
closest instances from an incoming test batch. Remarkably generic in its
design, UnMix-TNS seamlessly integrates with an array of state-of-the-art
test-time adaptation methods and pre-trained architectures equipped with BN
layers. Empirical evaluations corroborate the robustness of UnMix-TNS under
varied scenarios ranging from single to continual and mixed domain shifts.
UnMix-TNS stands out when handling test data streams with temporal correlation,
including those with corrupted real-world non-i.i.d. streams, sustaining its
efficacy even with minimal batch sizes and individual samples. Our results set
a new standard for test-time adaptation, demonstrating significant improvements
in both stability and performance across multiple benchmarks.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08329" title="Abstract">arXiv:2401.08329</a> [<a href="/pdf/2401.08329" title="Download PDF">pdf</a>, <a href="/format/2401.08329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding User Experience in Large Language Model Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiayin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Weizhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+P">Peijie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jian-Yun Nie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages + 3 page references + 2 page Appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the rapidly evolving landscape of large language models (LLMs), most
research has primarily viewed them as independent individuals, focusing on
assessing their capabilities through standardized benchmarks and enhancing
their general intelligence. This perspective, however, tends to overlook the
vital role of LLMs as user-centric services in human-AI collaboration. This gap
in research becomes increasingly critical as LLMs become more integrated into
people's everyday and professional interactions. This study addresses the
important need to understand user satisfaction with LLMs by exploring four key
aspects: comprehending user intents, scrutinizing user experiences, addressing
major user concerns about current LLM services, and charting future research
paths to bolster human-AI collaborations. Our study develops a taxonomy of 7
user intents in LLM interactions, grounded in analysis of real-world user
interaction logs and human verification. Subsequently, we conduct a user survey
to gauge their satisfaction with LLM services, encompassing usage frequency,
experiences across intents, and predominant concerns. This survey, compiling
411 anonymous responses, uncovers 11 first-hand insights into the current state
of user engagement with LLMs. Based on this empirical analysis, we pinpoint 6
future research directions prioritizing the user perspective in LLM
developments. This user-centered approach is essential for crafting LLMs that
are not just technologically advanced but also resonate with the intricate
realities of human interactions and real-world applications.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08330" title="Abstract">arXiv:2401.08330</a> [<a href="/pdf/2401.08330" title="Download PDF">pdf</a>, <a href="/format/2401.08330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Gradient Ascent for Continuous DR-submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qixin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zongqi Wan</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zengde Deng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zaiyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoming Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 74 pages, 6 figures and 9 tables. An extended version of Stochastic Continuous Submodular Maximization: Boosting via Non-oblivious Function (ICML 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
<p class="mathjax">Projected Gradient Ascent (PGA) is the most commonly used optimization scheme
in machine learning and operations research areas. Nevertheless, numerous
studies and examples have shown that the PGA methods may fail to achieve the
tight approximation ratio for continuous DR-submodular maximization problems.
To address this challenge, we present a boosting technique in this paper, which
can efficiently improve the approximation guarantee of the standard PGA to
\emph{optimal} with only small modifications on the objective function. The
fundamental idea of our boosting technique is to exploit non-oblivious search
to derive a novel auxiliary function $F$, whose stationary points are excellent
approximations to the global maximum of the original DR-submodular objective
$f$. Specifically, when $f$ is monotone and $\gamma$-weakly DR-submodular, we
propose an auxiliary function $F$ whose stationary points can provide a better
$(1-e^{-\gamma})$-approximation than the
$(\gamma^2/(1+\gamma^2))$-approximation guaranteed by the stationary points of
$f$ itself. Similarly, for the non-monotone case, we devise another auxiliary
function $F$ whose stationary points can achieve an optimal
$\frac{1-\min_{\boldsymbol{x}\in\mathcal{C}}\|\boldsymbol{x}\|_{\infty}}{4}$-approximation
guarantee where $\mathcal{C}$ is a convex constraint set. In contrast, the
stationary points of the original non-monotone DR-submodular function can be
arbitrarily bad~\citep{chen2023continuous}. Furthermore, we demonstrate the
scalability of our boosting technique on four problems. In all of these four
problems, our resulting variants of boosting PGA algorithm beat the previous
standard PGA in several aspects such as approximation ratio and efficiency.
Finally, we corroborate our theoretical findings with numerical experiments,
which demonstrate the effectiveness of our boosting PGA methods.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08332" title="Abstract">arXiv:2401.08332</a> [<a href="/pdf/2401.08332" title="Download PDF">pdf</a>, <a href="/format/2401.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Denoise Distillation: Simple Stochastic Noises Induce  Efficient Knowledge Transfer for Dense Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoge Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaohao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yunkang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Weiming Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Knowledge distillation is the process of transferring knowledge from a more
powerful large model (teacher) to a simpler counterpart (student). Numerous
current approaches involve the student imitating the knowledge of the teacher
directly. However, redundancy still exists in the learned representations
through these prevalent methods, which tend to learn each spatial location's
features indiscriminately. To derive a more compact representation (concept
feature) from the teacher, inspired by human cognition, we suggest an
innovative method, termed Generative Denoise Distillation (GDD), where
stochastic noises are added to the concept feature of the student to embed them
into the generated instance feature from a shallow network. Then, the generated
instance feature is aligned with the knowledge of the instance from the
teacher. We extensively experiment with object detection, instance
segmentation, and semantic segmentation to demonstrate the versatility and
effectiveness of our method. Notably, GDD achieves new state-of-the-art
performance in the tasks mentioned above. We have achieved substantial
improvements in semantic segmentation by enhancing PspNet and DeepLabV3, both
of which are based on ResNet-18, resulting in mIoU scores of 74.67 and 77.69,
respectively, surpassing their previous scores of 69.85 and 73.20 on the
Cityscapes dataset of 20 categories. The source code of GDD is available at
https://github.com/ZhgLiu/GDD.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08333" title="Abstract">arXiv:2401.08333</a> [<a href="/pdf/2401.08333" title="Download PDF">pdf</a>, <a href="/format/2401.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> dabih -- encrypted data storage and sharing platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huttner%2C+M">Michael Huttner</a>, 
<a href="/search/cs?searchtype=author&query=Simeth%2C+J">Jakob Simeth</a>, 
<a href="/search/cs?searchtype=author&query=Liguori%2C+R">Renato Liguori</a>, 
<a href="/search/cs?searchtype=author&query=Ferrazzi%2C+F">Fulvia Ferrazzi</a>, 
<a href="/search/cs?searchtype=author&query=Spang%2C+R">Rainer Spang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages including 4 figures and 5 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE); Genomics (q-bio.GN)

</div>
<p class="mathjax">Background: The secure management of sensitive clinical data, particularly
human genomics data, has become a critical requirement in modern biomedical
research. Although the necessary software and algorithms are readily available,
their use by non-IT experts poses significant challenges.
<br />Methods: We developed dabih, an open-source web application specifically
designed to facilitate user-friendly encrypted data management. dabih enables
web-based uploading, storing, sharing, and downloading of sensitive data in any
format. Its approach to data security involves a two-stage envelope encryption
process. We combine symmetric-key encryption for data and public-key encryption
as key encapsulation mechanism. The private key necessary for decrypting the
data remains exclusively on the owner's device. Thus, accessing data is
impossible without explicit permission from the keyholder.
<br />Results: dabih is available open-source on GitHub
https://github.com/spang-lab/dabih, as ready to use containers on docker hub
and includes a command line interface and a graphical bulk upload tool as
pre-built binaries. Documentation is available as part of the web application.
<br />Conclusions: dabih enables everyone to use strong cryptography for their
data, while being just as simple to use as other, non-encrypted, data storage
solutions. All the cryptography occurs seamlessly in the background as users
interact with a secure web portal, simply by dragging and dropping files.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08341" title="Abstract">arXiv:2401.08341</a> [<a href="/pdf/2401.08341" title="Download PDF">pdf</a>, <a href="/format/2401.08341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direct-Conflict Resolution in Intent-Driven Autonomous Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cinmere%2C+I">Idris Cinmere</a>, 
<a href="/search/cs?searchtype=author&query=Mehmood%2C+K">Kashif Mehmood</a>, 
<a href="/search/cs?searchtype=author&query=Kralevska%2C+K">Katina Kralevska</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoodi%2C+T">Toktam Mahmoodi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at 28th European Wireless Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">As network systems evolve, there is an escalating demand for automated tools
to facilitate efficient management and configuration. This paper explores
conflict resolution in Intent-Based Network (IBN) management, an innovative
approach that holds promise for effective network administration, especially
within radio access domain. Nevertheless, when multiple intents are in
operation concurrently, conflicts may emerge, presenting a significant issue
that remains under-addressed in the current literature. In response to this
challenge, our research expands the range of conflict resolution strategies
beyond the established Nash Bargaining Solution (NBS), to incorporate the
Weighted Nash Bargaining Solution (WNBS), the Kalai-Smorodinsky Bargaining
Solution (KSBS), and the Shannon Entropy Bargaining Solution (SEBS). These
methods are employed with the objective to identify optimal parameter values,
aiming to ensure fairness in conflict resolution. Through simulations, it is
demonstrated that distinct antenna tilt values are yielded as the respective
solutions for each method. Ultimately, based on Jain Fairness Index, the KSBS
is identified as the most equitable method under the given conditions.
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08345" title="Abstract">arXiv:2401.08345</a> [<a href="/pdf/2401.08345" title="Download PDF">pdf</a>, <a href="/format/2401.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-view Distillation based on Multi-modal Fusion for Few-shot Action  Recognition(CLIP-$\mathrm{M^2}$DF)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">YiKang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Han Qi</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">WenPing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Li Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, few-shot action recognition has attracted increasing
attention. It generally adopts the paradigm of meta-learning. In this field,
overcoming the overlapping distribution of classes and outliers is still a
challenging problem based on limited samples. We believe the combination of
Multi-modal and Multi-view can improve this issue depending on information
complementarity. Therefore, we propose a method of Multi-view Distillation
based on Multi-modal Fusion. Firstly, a Probability Prompt Selector for the
query is constructed to generate probability prompt embedding based on the
comparison score between the prompt embeddings of the support and the visual
embedding of the query. Secondly, we establish a Multi-view. In each view, we
fuse the prompt embedding as consistent information with visual and the global
or local temporal context to overcome the overlapping distribution of classes
and outliers. Thirdly, we perform the distance fusion for the Multi-view and
the mutual distillation of matching ability from one to another, enabling the
model to be more robust to the distribution bias. Our code is available at the
URL: \url{https://github.com/cofly2014/MDMF}.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08348" title="Abstract">arXiv:2401.08348</a> [<a href="/pdf/2401.08348" title="Download PDF">pdf</a>, <a href="/format/2401.08348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> We don&#x27;t need no labels: Estimating post-deployment model performance  under covariate shift without ground truth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bia%C5%82ek%2C+J">Jakub Bia&#x142;ek</a>, 
<a href="/search/cs?searchtype=author&query=Kuberski%2C+W">Wojtek Kuberski</a>, 
<a href="/search/cs?searchtype=author&query=Perrakis%2C+N">Nikolaos Perrakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The performance of machine learning models often degrades after deployment
due to data distribution shifts. In many use cases, it is impossible to
calculate the post-deployment performance because labels are unavailable or
significantly delayed. Proxy methods for evaluating model performance
stability, like drift detection techniques, do not properly quantify data
distribution shift impact. As a solution, we propose a robust and accurate
performance estimation method for evaluating ML classification models on
unlabeled data that accurately quantifies the impact of covariate shift on
model performance. We call it multi-calibrated confidence-based performance
estimation (M-CBPE). It is model and data-type agnostic and works for any
performance metric. It does not require access to the monitored model - it uses
the model predictions and probability estimates. M-CBPE does not need user
input on the nature of the covariate shift as it fully learns from the data. We
evaluate it with over 600 dataset-model pairs from US census data and compare
it with multiple benchmarks using several evaluation metrics. Results show that
M-CBPE is the best method to estimate the performance of classification models
in any evaluation context.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08350" title="Abstract">arXiv:2401.08350</a> [<a href="/pdf/2401.08350" title="Download PDF">pdf</a>, <a href="/format/2401.08350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Salute the Classic: Revisiting Challenges of Machine Translation in the  Age of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jianhui Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fanghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D+F">Derek F. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The evolution of Neural Machine Translation (NMT) has been significantly
influenced by six core challenges (Koehn and Knowles, 2017), which have acted
as benchmarks for progress in this field. This study revisits these challenges,
offering insights into their ongoing relevance in the context of advanced Large
Language Models (LLMs): domain mismatch, amount of parallel data, rare word
prediction, translation of long sentences, attention model as word alignment,
and sub-optimal beam search. Our empirical findings indicate that LLMs
effectively lessen the reliance on parallel data for major languages in the
pretraining phase. Additionally, the LLM-based translation system significantly
enhances the translation of long sentences that contain approximately 80 words
and shows the capability to translate documents of up to 512 words. However,
despite these significant improvements, the challenges of domain mismatch and
prediction of rare words persist. While the challenges of word alignment and
beam search, specifically associated with NMT, may not apply to LLMs, we
identify three new challenges for LLMs in translation tasks: inference
efficiency, translation of low-resource languages in the pretraining phase, and
human-aligned evaluation. The datasets and models are released at
https://github.com/pangjh3/LLM4MT.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08351" title="Abstract">arXiv:2401.08351</a> [<a href="/pdf/2401.08351" title="Download PDF">pdf</a>, <a href="/format/2401.08351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Federated Learning of Probabilistic Models: A PAC-Bayesian  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boroujeni%2C+M+G">Mahrokh Ghoddousi Boroujeni</a>, 
<a href="/search/cs?searchtype=author&query=Krause%2C+A">Andreas Krause</a>, 
<a href="/search/cs?searchtype=author&query=Trecate%2C+G+F">Giancarlo Ferrari Trecate</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Federated learning aims to infer a shared model from private and
decentralized data stored locally by multiple clients. Personalized federated
learning (PFL) goes one step further by adapting the global model to each
client, enhancing the model's fit for different clients. A significant level of
personalization is required for highly heterogeneous clients, but can be
challenging to achieve especially when they have small datasets. To address
this problem, we propose a PFL algorithm named PAC-PFL for learning
probabilistic models within a PAC-Bayesian framework that utilizes differential
privacy to handle data-dependent priors. Our algorithm collaboratively learns a
shared hyper-posterior and regards each client's posterior inference as the
personalization step. By establishing and minimizing a generalization bound on
the average true risk of clients, PAC-PFL effectively combats over-fitting.
PACPFL achieves accurate and well-calibrated predictions, supported by
experiments on a dataset of photovoltaic panel power generation, FEMNIST
dataset (Caldas et al., 2019), and Dirichlet-partitioned EMNIST dataset (Cohen
et al., 2017).
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08352" title="Abstract">arXiv:2401.08352</a> [<a href="/pdf/2401.08352" title="Download PDF">pdf</a>, <a href="/format/2401.08352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated solver selection for simulation of multiphysics processes in  porous media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zabegaev%2C+Y">Yury Zabegaev</a>, 
<a href="/search/math?searchtype=author&query=Keilegavlen%2C+E">Eirik Keilegavlen</a>, 
<a href="/search/math?searchtype=author&query=Iversen%2C+E">Einar Iversen</a>, 
<a href="/search/math?searchtype=author&query=Berre%2C+I">Inga Berre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Porous media processes involve various physical phenomena such as mechanical
deformation, transport, and fluid flow. Accurate simulations must capture the
strong couplings between these phenomena. Choosing an efficient solver for the
multiphysics problem usually entails the decoupling into subproblems related to
separate physical phenomena. Then, the suitable solvers for each subproblem and
the iteration scheme must be chosen. The wide range of options for the solver
components makes finding the optimum difficult and time-consuming; moreover,
solvers come with numerical parameters that need to be optimized. As a further
complication, the solver performance may depend on the physical regime of the
simulation model, which may vary with time. Switching a solver with respect to
the dominant process can be beneficial, but the threshold of when to switch
solver is unclear and complicated to analyze. We address this challenge by
developing a machine learning framework that automatically searches for the
optimal solver for a given multiphysics simulation setup, based on statistical
data from previously solved problems. For a series of problems, exemplified by
successive time steps in a time-dependent simulation, the framework updates and
improves its decision model online during the simulation. We show how it
outperforms preselected state-of-the-art solvers for test problem setups. The
examples are based on simulations of poromechanics and simulations of flow and
transport. For the quasi-static linear Biot model, we demonstrate automated
tuning of numerical solver parameters by showing how the L-parameter of the
so-called Fixed-Stress preconditioner can be optimized. Motivated by a test
example where the main heat transfer mechanism changes between convection and
diffusion, we discuss how the solver selector can dynamically switch solvers
when the dominant physical phenomenon changes with time.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08357" title="Abstract">arXiv:2401.08357</a> [<a href="/pdf/2401.08357" title="Download PDF">pdf</a>, <a href="/format/2401.08357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMF: Small-Area-Aware Multi-focus Image Fusion for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xilai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaosong Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Haishu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing multi-focus image fusion (MFIF) methods often fail to preserve the
uncertain transition region and detect small focus areas within large defocused
regions accurately. To address this issue, this study proposes a new
small-area-aware MFIF algorithm for enhancing object detection capability.
First, we enhance the pixel attributes within the small focus and boundary
regions, which are subsequently combined with visual saliency detection to
obtain the pre-fusion results used to discriminate the distribution of focused
pixels. To accurately ensure pixel focus, we consider the source image as a
combination of focused, defocused, and uncertain regions and propose a
three-region segmentation strategy. Finally, we design an effective pixel
selection rule to generate segmentation decision maps and obtain the final
fusion results. Experiments demonstrated that the proposed method can
accurately detect small and smooth focus areas while improving object detection
performance, outperforming existing methods in both subjective and objective
evaluations. The source code is available at https://github.com/ixilai/SAMF.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08358" title="Abstract">arXiv:2401.08358</a> [<a href="/pdf/2401.08358" title="Download PDF">pdf</a>, <a href="/format/2401.08358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Detection and Hallucination Mitigation: An Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Junliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tianyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jenkin%2C+M">Michael Jenkin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Steve Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs), including ChatGPT, Bard, and Llama, have
achieved remarkable successes over the last two years in a range of different
applications. In spite of these successes, there exist concerns that limit the
wide application of LLMs. A key problem is the problem of hallucination.
Hallucination refers to the fact that in addition to correct responses, LLMs
can also generate seemingly correct but factually incorrect responses. This
report aims to present a comprehensive review of the current literature on both
hallucination detection and hallucination mitigation. We hope that this report
can serve as a good reference for both engineers and researchers who are
interested in LLMs and applying them to real world tasks.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08360" title="Abstract">arXiv:2401.08360</a> [<a href="/pdf/2401.08360" title="Download PDF">pdf</a>, <a href="/format/2401.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaSem: Adaptive Goal-Oriented Semantic Communications for End-to-End  Camera Relocalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qi Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tung%2C+T">Tze-Yang Tung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in IEEE INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Recently, deep autoencoders have gained traction as a powerful method for
implementing goal-oriented semantic communications systems. The idea is to
train a mapping from the source domain directly to channel symbols, and vice
versa. However, prior studies often focused on rate-distortion tradeoff and
transmission delay, at the cost of increasing end-to-end complexity and thus
latency. Moreover, the datasets used are often not reflective of real-world
environments, and the results were not validated against real-world baseline
systems, leading to an unfair comparison. In this paper, we study the problem
of remote camera pose estimation and propose AdaSem, an adaptive semantic
communications approach that optimizes the tradeoff between inference accuracy
and end-to-end latency. We develop an adaptive semantic codec model, which
encodes the source data into a dynamic number of symbols, based on the latent
space distribution and the channel state feedback. We utilize a lightweight
model for both transmitter and receiver to ensure comparable complexity to the
baseline implemented in a real-world system. Extensive experiments on
real-environment data show the effectiveness of our approach. When compared to
a real implementation of a client-server camera relocalization service, AdaSem
outperforms the baseline by reducing the end-to-end delay and estimation error
by over 75% and 63%, respectively.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08361" title="Abstract">arXiv:2401.08361</a> [<a href="/pdf/2401.08361" title="Download PDF">pdf</a>, <a href="/ps/2401.08361" title="Download PostScript">ps</a>, <a href="/format/2401.08361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adjoint Monte Carlo Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Caflisch%2C+R">Russel Caflisch</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yunan Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">This survey explores the development of adjoint Monte Carlo methods for
solving optimization problems governed by kinetic equations, a common challenge
in areas such as plasma control and device design. These optimization problems
are particularly demanding due to the high dimensionality of the phase space
and the randomness in evaluating the objective functional, a consequence of
using a forward Monte Carlo solver. To overcome these difficulties, a range of
``adjoint Monte Carlo methods'' have been devised. These methods skillfully
combine Monte Carlo gradient estimators with PDE-constrained optimization,
introducing innovative solutions tailored for kinetic applications. In this
review, we begin by examining three primary strategies for Monte Carlo gradient
estimation: the score function approach, the reparameterization trick, and the
coupling method. We also delve into the adjoint-state method, an essential
element in PDE-constrained optimization. Focusing on applications in the
radiative transfer equation and the nonlinear Boltzmann equation, we provide a
comprehensive guide on how to integrate Monte Carlo gradient techniques within
both the optimize-then-discretize and the discretize-then-optimize frameworks
from PDE-constrained optimization. This approach leads to the formulation of
effective adjoint Monte Carlo methods, enabling efficient gradient estimation
in complex, high-dimensional optimization problems.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08363" title="Abstract">arXiv:2401.08363</a> [<a href="/pdf/2401.08363" title="Download PDF">pdf</a>, <a href="/format/2401.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Bias in Machine Learning Models for Phishing Webpage  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+A">Aditya Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Balachandran%2C+V">Vivek Balachandran</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+D+M">Dinil Mon Divakaran</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+T">Tamal Das</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The widespread accessibility of the Internet has led to a surge in online
fraudulent activities, underscoring the necessity of shielding users' sensitive
information from cybercriminals. Phishing, a well-known cyberattack, revolves
around the creation of phishing webpages and the dissemination of corresponding
URLs, aiming to deceive users into sharing their sensitive information, often
for identity theft or financial gain. Various techniques are available for
preemptively categorizing zero-day phishing URLs by distilling unique
attributes and constructing predictive models. However, these existing
techniques encounter unresolved issues. This proposal delves into persistent
challenges within phishing detection solutions, particularly concentrated on
the preliminary phase of assembling comprehensive datasets, and proposes a
potential solution in the form of a tool engineered to alleviate bias in ML
models. Such a tool can generate phishing webpages for any given set of
legitimate URLs, infusing randomly selected content and visual-based phishing
features. Furthermore, we contend that the tool holds the potential to assess
the efficacy of existing phishing detection solutions, especially those trained
on confined datasets.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08364" title="Abstract">arXiv:2401.08364</a> [<a href="/pdf/2401.08364" title="Download PDF">pdf</a>, <a href="/format/2401.08364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weighted Spectral Filters for Kernel Interpolation on Spheres: Estimates  of Prediction Accuracy for Noisy Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaotong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shao-Bo Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Spherical radial-basis-based kernel interpolation abounds in image sciences
including geophysical image reconstruction, climate trends description and
image rendering due to its excellent spatial localization property and perfect
approximation performance. However, in dealing with noisy data, kernel
interpolation frequently behaves not so well due to the large condition number
of the kernel matrix and instability of the interpolation process. In this
paper, we introduce a weighted spectral filter approach to reduce the condition
number of the kernel matrix and then stabilize kernel interpolation. The main
building blocks of the proposed method are the well developed spherical
positive quadrature rules and high-pass spectral filters. Using a recently
developed integral operator approach for spherical data analysis, we
theoretically demonstrate that the proposed weighted spectral filter approach
succeeds in breaking through the bottleneck of kernel interpolation, especially
in fitting noisy data. We provide optimal approximation rates of the new method
to show that our approach does not compromise the predicting accuracy.
Furthermore, we conduct both toy simulations and two real-world data
experiments with synthetically added noise in geophysical image reconstruction
and climate image processing to verify our theoretical assertions and show the
feasibility of the weighted spectral filter approach.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08366" title="Abstract">arXiv:2401.08366</a> [<a href="/pdf/2401.08366" title="Download PDF">pdf</a>, <a href="/ps/2401.08366" title="Download PostScript">ps</a>, <a href="/format/2401.08366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the formalization of the notion of an algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Middelburg%2C+C+A">C. A. Middelburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Data Structures and Algorithms (cs.DS); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">The starting point of this paper is a collection of properties of an
algorithm that have been distilled from the informal descriptions of what an
algorithm is that are given in standard works from the mathematical and
computer science literature. Based on that, the notion of a proto-algorithm is
introduced. The thought is that algorithms are equivalence classes of
proto-algorithms under some equivalence relation. Three equivalence relations
are defined. Two of them give bounds between which an appropriate equivalence
relation must lie. The third lies in between these two and is likely an
appropriate equivalence relation. A sound method is presented to prove, using
an imperative process algebra based on ACP, that this equivalence relation
holds between two proto-algorithms.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08367" title="Abstract">arXiv:2401.08367</a> [<a href="/pdf/2401.08367" title="Download PDF">pdf</a>, <a href="/ps/2401.08367" title="Download PostScript">ps</a>, <a href="/format/2401.08367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphology and Syntax of the Tamil Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarveswaran%2C+K">Kengatharaiyer Sarveswaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper provides an overview of the morphology and syntax of the Tamil
language, focusing on its contemporary usage. The paper also highlights the
complexity and richness of Tamil in terms of its morphological and syntactic
features, which will be useful for linguists analysing the language and
conducting comparative studies. In addition, the paper will be useful for those
developing computational resources for the Tamil language. It is proven as a
rule-based morphological analyser cum generator and a computational grammar for
Tamil have already been developed based on this paper. To enhance accessibility
for a broader audience, the analysis is conducted without relying on any
specific grammatical formalism.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08374" title="Abstract">arXiv:2401.08374</a> [<a href="/pdf/2401.08374" title="Download PDF">pdf</a>, <a href="/format/2401.08374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-lingual neural fuzzy matching for exploiting target-language  monolingual corpora in computer-aided translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Espl%C3%A0-Gomis%2C+M">Miquel Espl&#xe0;-Gomis</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Cartagena%2C+V+M">V&#xed;ctor M. S&#xe1;nchez-Cartagena</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Ortiz%2C+J+A">Juan Antonio P&#xe9;rez-Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez-Mart%C3%ADnez%2C+F">Felipe S&#xe1;nchez-Mart&#xed;nez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 2022 Conference on Empirical Methods in
  Natural Language Processing (pp. 7532-7543)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Computer-aided translation (CAT) tools based on translation memories (MT)
play a prominent role in the translation workflow of professional translators.
However, the reduced availability of in-domain TMs, as compared to in-domain
monolingual corpora, limits its adoption for a number of translation tasks. In
this paper, we introduce a novel neural approach aimed at overcoming this
limitation by exploiting not only TMs, but also in-domain target-language (TL)
monolingual corpora, and still enabling a similar functionality to that offered
by conventional TM-based CAT tools. Our approach relies on cross-lingual
sentence embeddings to retrieve translation proposals from TL monolingual
corpora, and on a neural model to estimate their post-editing effort. The paper
presents an automatic evaluation of these techniques on four language pairs
that shows that our approach can successfully exploit monolingual texts in a
TM-based CAT environment, increasing the amount of useful translation
proposals, and that our neural model for estimating the post-editing effort
enables the combination of translation proposals obtained from monolingual
corpora and from TMs in the usual way. A human evaluation performed on a single
language pair confirms the results of the automatic evaluation and seems to
indicate that the translation proposals retrieved with our approach are more
useful than what the automatic evaluation shows.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08376" title="Abstract">arXiv:2401.08376</a> [<a href="/pdf/2401.08376" title="Download PDF">pdf</a>, <a href="/format/2401.08376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wei Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yucheng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanlin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haofen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenqiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Transactions on Software Engineering and Methodology 2024 (TOSEM'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Commit messages are natural language descriptions of code changes, which are
important for software evolution such as code understanding and maintenance.
However, previous methods are trained on the entire dataset without considering
the fact that a portion of commit messages adhere to good practice (i.e.,
good-practice commits), while the rest do not. On the basis of our empirical
study, we discover that training on good-practice commits significantly
contributes to the commit message generation. Motivated by this finding, we
propose a novel knowledge-aware denoising learning method called KADEL.
Considering that good-practice commits constitute only a small proportion of
the dataset, we align the remaining training samples with these good-practice
commits. To achieve this, we propose a model that learns the commit knowledge
by training on good-practice commits. This knowledge model enables
supplementing more information for training samples that do not conform to good
practice. However, since the supplementary information may contain noise or
prediction errors, we propose a dynamic denoising training method. This method
composes a distribution-aware confidence function and a dynamic distribution
list, which enhances the effectiveness of the training process. Experimental
results on the whole MCMD dataset demonstrate that our method overall achieves
state-of-the-art performance compared with previous methods. Our source code
and data are available at https://github.com/DeepSoftwareAnalytics/KADEL
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08377" title="Abstract">arXiv:2401.08377</a> [<a href="/pdf/2401.08377" title="Download PDF">pdf</a>, <a href="/format/2401.08377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pareto Curves for Compositionally Model Checking String Diagrams of MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+K">Kazuki Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Vegt%2C+M">Marck van der Vegt</a>, 
<a href="/search/cs?searchtype=author&query=Hasuo%2C+I">Ichiro Hasuo</a>, 
<a href="/search/cs?searchtype=author&query=Rot%2C+J">Jurriaan Rot</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version (includes the Appendix) of the paper accepted at TACAS-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Computing schedulers that optimize reachability probabilities in MDPs is a
standard verification task. To address scalability concerns, we focus on MDPs
that are compositionally described in a high-level description formalism. In
particular, this paper considers string diagrams, which specify an algebraic,
sequential composition of subMDPs. Towards their compositional verification,
the key challenge is to locally optimize schedulers on subMDPs without
considering their context in the string diagram. This paper proposes to
consider the schedulers in a subMDP which form a Pareto curve on a combination
of local objectives. While considering all such schedulers is intractable, it
gives rise to a highly efficient sound approximation algorithm. The prototype
on top of the model checker Storm demonstrates the scalability of this
approach.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08381" title="Abstract">arXiv:2401.08381</a> [<a href="/pdf/2401.08381" title="Download PDF">pdf</a>, <a href="/format/2401.08381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Imitation of Human Actions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spisak%2C+J">Josua Spisak</a>, 
<a href="/search/cs?searchtype=author&query=Kerzel%2C+M">Matthias Kerzel</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation can allow us to quickly gain an understanding of a new task.
Through a demonstration, we can gain direct knowledge about which actions need
to be performed and which goals they have. In this paper, we introduce a new
approach to imitation learning that tackles the challenges of a robot imitating
a human, such as the change in perspective and body schema. Our approach can
use a single human demonstration to abstract information about the demonstrated
task, and use that information to generalise and replicate it. We facilitate
this ability by a new integration of two state-of-the-art methods: a diffusion
action segmentation model to abstract temporal information from the
demonstration and an open vocabulary object detector for spatial information.
Furthermore, we refine the abstracted information and use symbolic reasoning to
create an action plan utilising inverse kinematics, to allow the robot to
imitate the demonstrated action.
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08383" title="Abstract">arXiv:2401.08383</a> [<a href="/pdf/2401.08383" title="Download PDF">pdf</a>, <a href="/format/2401.08383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Inter-Layer Expert Affinity for Accelerating  Mixture-of-Experts Model Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jinghan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Anthony%2C+Q">Quentin Anthony</a>, 
<a href="/search/cs?searchtype=author&query=Shafi%2C+A">Aamir Shafi</a>, 
<a href="/search/cs?searchtype=author&query=Subramoni%2C+H">Hari Subramoni</a>, 
<a href="/search/cs?searchtype=author&query=K.%2C+D">Dhabaleswar K.</a> (DK)
<a href="/search/cs?searchtype=author&query=Panda">Panda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">In large language models like the Generative Pre-trained Transformer, the
Mixture of Experts paradigm has emerged as a powerful technique for enhancing
model expressiveness and accuracy. However, deploying GPT MoE models for
parallel inference on distributed systems presents significant challenges,
primarily due to the extensive Alltoall communication required for expert
routing and aggregation. This communication bottleneck exacerbates the already
complex computational landscape, hindering the efficient utilization of
high-performance computing resources. In this paper, we propose a lightweight
optimization technique called ExFlow, to largely accelerate the inference of
these MoE models. We take a new perspective on alleviating the communication
overhead by exploiting the inter-layer expert affinity. Unlike previous
methods, our solution can be directly applied to pre-trained MoE models without
any fine-tuning or accuracy degradation. By proposing a context-coherent expert
parallelism on distributed systems, our design only uses one Alltoall
communication to deliver the same functionality while previous methods all
require two Alltoalls. By carefully examining the conditional probability in
tokens' routing across multiple layers, we proved that pre-trained GPT MoE
models implicitly exhibit a strong inter-layer expert affinity. We then design
an efficient integer programming model to capture such features and show that
by properly placing the experts on corresponding GPUs, we can reduce up to 67%
cross-GPU routing latency. Our solution beats the cutting-edge MoE
implementations with experts from 8 to 64, with up to 2.2x improvement in
inference throughput. We further provide a detailed study of how the model
implicitly acquires this expert affinity at the very early training stage and
how this affinity evolves and stabilizes during training.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08385" title="Abstract">arXiv:2401.08385</a> [<a href="/pdf/2401.08385" title="Download PDF">pdf</a>, <a href="/ps/2401.08385" title="Download PostScript">ps</a>, <a href="/format/2401.08385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient VCGen-based Modular Verification of Relational Properties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blatter%2C+L">Lionel Blatter</a>, 
<a href="/search/cs?searchtype=author&query=Kosmatov%2C+N">Nikolai Kosmatov</a>, 
<a href="/search/cs?searchtype=author&query=Prevosto%2C+V">Virgile Prevosto</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+P+L">Pascale Le Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2202.10349">arXiv:2202.10349</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Deductive verification typically relies on function contracts that specify
the behavior of each function for a single function call. Relational properties
link several function calls together within a single specification. They can
express more advanced properties of a given function, such as non-interference,
continuity, or monotonicity, or relate calls to different functions, possibly
run in parallel, for instance, to show the equivalence of two implementations.
However, relational properties cannot be expressed and verified directly in the
traditional setting of modular deductive verification. Recent work proposed a
new technique for relational property verification that relies on a
verification condition generator to produce logical formulas that must be
verified to ensure a given relational property. This paper presents an overview
of this approach and proposes important enhancements. We integrate an optimized
verification condition generator and extend the underlying theory to show how
relational properties can be proved in a modular way, where one relational
property can be used to prove another one, like in modular verification of
function contracts. Our results have been fully formalized and proved sound in
the Coq proof assistant.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08386" title="Abstract">arXiv:2401.08386</a> [<a href="/pdf/2401.08386" title="Download PDF">pdf</a>, <a href="/format/2401.08386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Group Causal Inference in Multivariate Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmad%2C+W">Wasim Ahmad</a>, 
<a href="/search/cs?searchtype=author&query=Shadaydeh%2C+M">Maha Shadaydeh</a>, 
<a href="/search/cs?searchtype=author&query=Denzler%2C+J">Joachim Denzler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI24 (AI4TS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Causal inference in a nonlinear system of multivariate timeseries is
instrumental in disentangling the intricate web of relationships among
variables, enabling us to make more accurate predictions and gain deeper
insights into real-world complex systems. Causality methods typically identify
the causal structure of a multivariate system by considering the cause-effect
relationship of each pair of variables while ignoring the collective effect of
a group of variables or interactions involving more than two-time series
variables. In this work, we test model invariance by group-level interventions
on the trained deep networks to infer causal direction in groups of variables,
such as climate and ecosystem, brain networks, etc. Extensive testing with
synthetic and real-world time series data shows a significant improvement of
our method over other applied group causality methods and provides us insights
into real-world time series. The code for our method can be found
at:https://github.com/wasimahmadpk/gCause.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08392" title="Abstract">arXiv:2401.08392</a> [<a href="/pdf/2401.08392" title="Download PDF">pdf</a>, <a href="/format/2401.08392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guikun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The field of AI agents is advancing at an unprecedented rate due to the
capabilities of large language models (LLMs). However, LLM-driven visual agents
mainly focus on solving tasks for the image modality, which limits their
ability to understand the dynamic nature of the real world, making it still far
from real-life applications, e.g., guiding students in laboratory experiments
and identifying their mistakes. Considering the video modality better reflects
the ever-changing and perceptually intensive nature of real-world scenarios, we
devise DoraemonGPT, a comprehensive and conceptually elegant system driven by
LLMs to handle dynamic video tasks. Given a video with a question/task,
DoraemonGPT begins by converting the input video with massive content into a
symbolic memory that stores \textit{task-related} attributes. This structured
representation allows for spatial-temporal querying and reasoning by sub-task
tools, resulting in concise and relevant intermediate results. Recognizing that
LLMs have limited internal knowledge when it comes to specialized domains
(e.g., analyzing the scientific principles underlying experiments), we
incorporate plug-and-play tools to assess external knowledge and address tasks
across different domains. Moreover, we introduce a novel LLM-driven planner
based on Monte Carlo Tree Search to efficiently explore the large planning
space for scheduling various tools. The planner iteratively finds feasible
solutions by backpropagating the result's reward, and multiple solutions can be
summarized into an improved final answer. We extensively evaluate DoraemonGPT
in dynamic scenes and provide in-the-wild showcases demonstrating its ability
to handle more complex questions than previous studies.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08396" title="Abstract">arXiv:2401.08396</a> [<a href="/pdf/2401.08396" title="Download PDF">pdf</a>, <a href="/ps/2401.08396" title="Download PostScript">ps</a>, <a href="/format/2401.08396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qiao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiliang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Ziyang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+M">Justin M. Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Robert Chen</a>, 
<a href="/search/cs?searchtype=author&query=Summers%2C+R+M">Ronald M. Summers</a>, 
<a href="/search/cs?searchtype=author&query=Rousseau%2C+J+F">Justin F. Rousseau</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+P">Peiyun Ni</a>, 
<a href="/search/cs?searchtype=author&query=Landsman%2C+M+J">Marc J Landsman</a>, 
<a href="/search/cs?searchtype=author&query=Baxter%2C+S+L">Sally L. Baxter</a>, 
<a href="/search/cs?searchtype=author&query=Al%27Aref%2C+S+J">Subhi J. Al&#x27;Aref</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+M+F">Michael F. Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhiyong Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent studies indicate that Generative Pre-trained Transformer 4 with Vision
(GPT-4V) outperforms human physicians in medical challenge tasks. However,
these evaluations primarily focused on the accuracy of multi-choice questions
alone. Our study extends the current scope by conducting a comprehensive
analysis of GPT-4V's rationales of image comprehension, recall of medical
knowledge, and step-by-step multimodal reasoning when solving New England
Journal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test
the knowledge and diagnostic capabilities of medical professionals. Evaluation
results confirmed that GPT-4V outperforms human physicians regarding
multi-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in
cases where physicians incorrectly answer, with over 80% accuracy. However, we
discovered that GPT-4V frequently presents flawed rationales in cases where it
makes the correct final choices (27.3%), most prominent in image comprehension
(21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, our
findings emphasize the necessity for further in-depth evaluations of its
rationales before integrating such models into clinical workflows.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08397" title="Abstract">arXiv:2401.08397</a> [<a href="/pdf/2401.08397" title="Download PDF">pdf</a>, <a href="/format/2401.08397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Micro Architectural Events Aware Real-Time Embedded System Fault  Injector
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Magliano%2C+E">Enrico Magliano</a>, 
<a href="/search/cs?searchtype=author&query=Carpegna%2C+A">Alessio Carpegna</a>, 
<a href="/search/cs?searchtype=author&query=Savino%2C+A">Alessadro Savino</a>, 
<a href="/search/cs?searchtype=author&query=Di+Carlo%2C+S">Stefano Di Carlo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In contemporary times, the increasing complexity of the system poses
significant challenges to the reliability, trustworthiness, and security of the
SACRES. Key issues include the susceptibility to phenomena such as
instantaneous voltage spikes, electromagnetic interference, neutron strikes,
and out-of-range temperatures. These factors can induce switch state changes in
transistors, resulting in bit-flipping, soft errors, and transient corruption
of stored data in memory. The occurrence of soft errors, in turn, may lead to
system faults that can propel the system into a hazardous state. Particularly
in critical sectors like automotive, avionics, or aerospace, such malfunctions
can have real-world implications, potentially causing harm to individuals.
<br />This paper introduces a novel fault injector designed to facilitate the
monitoring, aggregation, and examination of micro-architectural events. This is
achieved by harnessing the microprocessor's PMU and the debugging interface,
specifically focusing on ensuring the repeatability of fault injections. The
fault injection methodology targets bit-flipping within the memory system,
affecting CPU registers and RAM. The outcomes of these fault injections enable
a thorough analysis of the impact of soft errors and establish a robust
correlation between the identified faults and the essential timing
predictability demanded by SACRES.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08398" title="Abstract">arXiv:2401.08398</a> [<a href="/pdf/2401.08398" title="Download PDF">pdf</a>, <a href="/format/2401.08398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High-Quality Mesh Blendshape Generation from Face Videos via Neural  Inverse Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ming%2C+X">Xin Ming</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+J">Jingwang Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Libo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Readily editable mesh blendshapes have been widely used in animation
pipelines, while recent advancements in neural geometry and appearance
representations have enabled high-quality inverse rendering. Building upon
these observations, we introduce a novel technique that reconstructs mesh-based
blendshape rigs from single or sparse multi-view videos, leveraging
state-of-the-art neural inverse rendering. We begin by constructing a
deformation representation that parameterizes vertex displacements into
differential coordinates with tetrahedral connections, allowing for
high-quality vertex deformation on high-resolution meshes. By constructing a
set of semantic regulations in this representation, we achieve joint
optimization of blendshapes and expression coefficients. Furthermore, to enable
a user-friendly multi-view setup with unsynchronized cameras, we propose a
neural regressor to model time-varying motion parameters. This approach
implicitly considers the time difference across multiple cameras, enhancing the
accuracy of motion modeling. Experiments demonstrate that, with the flexible
input of single or sparse multi-view videos, we reconstruct personalized
high-fidelity blendshapes. These blendshapes are both geometrically and
semantically accurate, and they are compatible with industrial animation
pipelines. Code and data will be released.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08399" title="Abstract">arXiv:2401.08399</a> [<a href="/pdf/2401.08399" title="Download PDF">pdf</a>, <a href="/format/2401.08399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TACO: Benchmarking Generalizable Bimanual Tool-ACtion-Object  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haolin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+X">Xu Si</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Ling Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zipeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+L">Li Yi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Humans commonly work with multiple objects in daily life and can intuitively
transfer manipulation skills to novel objects by understanding object
functional regularities. However, existing technical approaches for analyzing
and synthesizing hand-object manipulation are mostly limited to handling a
single hand and object due to the lack of data support. To address this, we
construct TACO, an extensive bimanual hand-object-interaction dataset spanning
a large variety of tool-action-object compositions for daily human activities.
TACO contains 2.5K motion sequences paired with third-person and egocentric
views, precise hand-object 3D meshes, and action labels. To rapidly expand the
data scale, we present a fully-automatic data acquisition pipeline combining
multi-view sensing with an optical motion capture system. With the vast
research fields provided by TACO, we benchmark three generalizable
hand-object-interaction tasks: compositional action recognition, generalizable
hand-object motion forecasting, and cooperative grasp synthesis. Extensive
experiments reveal new insights, challenges, and opportunities for advancing
the studies of generalizable hand-object motion analysis and synthesis. Our
data and code are available at https://taco2024.github.io.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08402" title="Abstract">arXiv:2401.08402</a> [<a href="/pdf/2401.08402" title="Download PDF">pdf</a>, <a href="/format/2401.08402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform Recovery Guarantees for Quantized Corrupted Sensing Using  Structured or Generative Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junren Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhaoqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Meng Ding</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+M+K">Michael K. Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 69 pages, 11 figures (In Review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies quantized corrupted sensing where the measurements are
contaminated by unknown corruption and then quantized by a dithered uniform
quantizer. We establish uniform guarantees for Lasso that ensure the accurate
recovery of all signals and corruptions using a single draw of the sub-Gaussian
sensing matrix and uniform dither. For signal and corruption with structured
priors (e.g., sparsity, low-rankness), our uniform error rate for constrained
Lasso typically coincides with the non-uniform one [Sun, Cui and Liu, 2022] up
to logarithmic factors. By contrast, our uniform error rate for unconstrained
Lasso exhibits worse dependence on the structured parameters due to
regularization parameters larger than the ones for non-uniform recovery. For
signal and corruption living in the ranges of some Lipschitz continuous
generative models (referred to as generative priors), we achieve uniform
recovery via constrained Lasso with a measurement number proportional to the
latent dimensions of the generative models. Our treatments to the two kinds of
priors are (nearly) unified and share the common key ingredients of (global)
quantized product embedding (QPE) property, which states that the dithered
uniform quantization (universally) preserves inner product. As a by-product,
our QPE result refines the one in [Xu and Jacques, 2020] under sub-Gaussian
random matrix, and in this specific instance we are able to sharpen the uniform
error decaying rate (for the projected-back projection estimator with signals
in some convex symmetric set) presented therein from $O(m^{-1/16})$ to
$O(m^{-1/8})$.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08405" title="Abstract">arXiv:2401.08405</a> [<a href="/pdf/2401.08405" title="Download PDF">pdf</a>, <a href="/ps/2401.08405" title="Download PostScript">ps</a>, <a href="/format/2401.08405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interrogating AI: Characterizing Emergent Playful Interactions with  ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikghalb%2C+M+R">Mohammad Ronagh Nikghalb</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jinghui Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In an era of AI's growing capabilities and influences, recent advancements
are reshaping HCI and CSCW's view of AI as mere tools. Playful interactions
with AI systems naturally emerged as a way for users to make sense of the
ever-changing technology. However, these emergent and playful interactions are
underexamined. We target this gap by investigating playful interactions
exhibited by users of a recently trending powerful AI technology, ChatGPT.
Through a thematic analysis of 372 user-generated posts on the ChatGPT
subreddit, we found that a substantial portion of user discourse revolves
around playful interactions. The analysis further allowed us to construct a
preliminary taxonomy to describe these interactions, categorizing them into six
types: reflecting, jesting, imitating, challenging, tricking, and contriving;
each included sub-categories. Overall, this study contributes to the field of
HCI and CSCW by illuminating the multifaceted nature of playful interactions
with AI, underlining their significance in shaping the human-AI relationship.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08406" title="Abstract">arXiv:2401.08406</a> [<a href="/pdf/2401.08406" title="Download PDF">pdf</a>, <a href="/format/2401.08406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on  Agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Shirgaonkar%2C+A">Anup Shirgaonkar</a>, 
<a href="/search/cs?searchtype=author&query=de+Luis+Balaguer%2C+A">Angels de Luis Balaguer</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+B">Bruno Silva</a>, 
<a href="/search/cs?searchtype=author&query=Holstein%2C+D">Daniel Holstein</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Marsman%2C+J">Jennifer Marsman</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+L+O">Leonardo O. Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Rouzbahman%2C+M">Mahsa Rouzbahman</a>, 
<a href="/search/cs?searchtype=author&query=Sharp%2C+M">Morris Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Mecklenburg%2C+N">Nick Mecklenburg</a>, 
<a href="/search/cs?searchtype=author&query=Padilha%2C+R">Rafael Padilha</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Ranveer Chandra</a>, 
<a href="/search/cs?searchtype=author&query=de+Freitas+Cunha%2C+R+L">Renato Luiz de Freitas Cunha</a>, 
<a href="/search/cs?searchtype=author&query=de+M.+Estev%C3%A3o+Filho%2C+R">Roberto de M. Estev&#xe3;o Filho</a>, 
<a href="/search/cs?searchtype=author&query=Tsang%2C+R">Ryan Tsang</a>, 
<a href="/search/cs?searchtype=author&query=Malvar%2C+S">Sara Malvar</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Swati Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Hendry%2C+T">Todd Hendry</a>, 
<a href="/search/cs?searchtype=author&query=Aski%2C+V">Vijay Aski</a>, 
<a href="/search/cs?searchtype=author&query=Vijayendran%2C+V">Vijetha Vijayendran</a>, 
<a href="/search/cs?searchtype=author&query=Benara%2C+V">Vinamra Benara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">There are two common ways in which developers are incorporating proprietary
and domain-specific data when building applications of Large Language Models
(LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the
prompt with the external data, while fine-Tuning incorporates the additional
knowledge into the model itself. However, the pros and cons of both approaches
are not well understood. In this paper, we propose a pipeline for fine-tuning
and RAG, and present the tradeoffs of both for multiple popular LLMs, including
Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages,
including extracting information from PDFs, generating questions and answers,
using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We
propose metrics to assess the performance of different stages of the RAG and
fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset.
Agriculture as an industry has not seen much penetration of AI, and we study a
potentially disruptive application - what if we could provide location-specific
insights to a farmer? Our results show the effectiveness of our dataset
generation pipeline in capturing geographic-specific knowledge, and the
quantitative and qualitative benefits of RAG and fine-tuning. We see an
accuracy increase of over 6 p.p. when fine-tuning the model and this is
cumulative with RAG, which increases accuracy by 5 p.p. further. In one
particular experiment, we also demonstrate that the fine-tuned model leverages
information from across geographies to answer specific questions, increasing
answer similarity from 47% to 72%. Overall, the results point to how systems
built using LLMs can be adapted to respond and incorporate knowledge across a
dimension that is critical for a specific industry, paving the way for further
applications of LLMs in other industrial domains.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08407" title="Abstract">arXiv:2401.08407</a> [<a href="/pdf/2401.08407" title="Download PDF">pdf</a>, <a href="/format/2401.08407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Domain Few-Shot Segmentation via Iterative Support-Query  Correspondence Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yun Xing</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gongjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Pei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Aoran Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Yap-Peng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Kot%2C+A+C">Alex C. Kot</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cross-Domain Few-Shot Segmentation (CD-FSS) poses the challenge of segmenting
novel categories from a distinct domain using only limited exemplars. In this
paper, we undertake a comprehensive study of CD-FSS and uncover two crucial
insights: (i) the necessity of a fine-tuning stage to effectively transfer the
learned meta-knowledge across domains, and (ii) the overfitting risk during the
na\"ive fine-tuning due to the scarcity of novel category examples. With these
insights, we propose a novel cross-domain fine-tuning strategy that addresses
the challenging CD-FSS tasks. We first design Bi-directional Few-shot
Prediction (BFP), which establishes support-query correspondence in a
bi-directional manner, crafting augmented supervision to reduce the overfitting
risk. Then we further extend BFP into Iterative Few-shot Adaptor (IFA), which
is a recursive framework to capture the support-query correspondence
iteratively, targeting maximal exploitation of supervisory signals from the
sparse novel category samples. Extensive empirical evaluations show that our
method significantly outperforms the state-of-the-arts (+7.8\%), which verifies
that IFA tackles the cross-domain challenges and mitigates the overfitting
simultaneously. Code will be made available.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08411" title="Abstract">arXiv:2401.08411</a> [<a href="/pdf/2401.08411" title="Download PDF">pdf</a>, <a href="/format/2401.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Counterfactuals to Improve Causal Inferences from Visualizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borland%2C+D">David Borland</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+Z">Arran Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gotz%2C+D">David Gotz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Computer Graphics and Applications, 44(1), Jan/Feb, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Traditional approaches to data visualization have often focused on comparing
different subsets of data, and this is reflected in the many techniques
developed and evaluated over the years for visual comparison. Similarly, common
workflows for exploratory visualization are built upon the idea of users
interactively applying various filter and grouping mechanisms in search of new
insights. This paradigm has proven effective at helping users identify
correlations between variables that can inform thinking and decision-making.
However, recent studies show that consumers of visualizations often draw causal
conclusions even when not supported by the data. Motivated by these
observations, this article highlights recent advances from a growing community
of researchers exploring methods that aim to directly support visual causal
inference. However, many of these approaches have their own limitations which
limit their use in many real-world scenarios. This article therefore also
outlines a set of key open challenges and corresponding priorities for new
research to advance the state of the art in visual causal inference.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08415" title="Abstract">arXiv:2401.08415</a> [<a href="/pdf/2401.08415" title="Download PDF">pdf</a>, <a href="/format/2401.08415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Coarse to Fine: Efficient Training for Audio Spectrogram  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Erol%2C+M+H">Mehmet Hamza Erol</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J+S">Joon Son Chung</a>, 
<a href="/search/cs?searchtype=author&query=Senocak%2C+A">Arda Senocak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Transformers have become central to recent advances in audio classification.
However, training an audio spectrogram transformer, e.g. AST, from scratch can
be resource and time-intensive. Furthermore, the complexity of transformers
heavily depends on the input audio spectrogram size. In this work, we aim to
optimize AST training by linking to the resolution in the time-axis. We
introduce multi-phase training of audio spectrogram transformers by connecting
the seminal idea of coarse-to-fine with transformer models. To achieve this, we
propose a set of methods for temporal compression. By employing one of these
methods, the transformer model learns from lower-resolution (coarse) data in
the initial phases, and then is fine-tuned with high-resolution data later in a
curriculum learning strategy. Experimental results demonstrate that the
proposed training mechanism for AST leads to improved (or on-par) performance
with faster convergence, i.e. requiring fewer computational resources and less
time. This approach is also generalizable to other AST-based methods regardless
of their learning paradigms.
</p>
</div>
</dd>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08417" title="Abstract">arXiv:2401.08417</a> [<a href="/pdf/2401.08417" title="Download PDF">pdf</a>, <a href="/format/2401.08417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Preference Optimization: Pushing the Boundaries of LLM  Performance in Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haoran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sharaf%2C+A">Amr Sharaf</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunmo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weiting Tan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lingfeng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Murray%2C+K">Kenton Murray</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+J">Young Jin Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Moderate-sized large language models (LLMs) -- those with 7B or 13B
parameters -- exhibit promising machine translation (MT) performance. However,
even the top-performing 13B LLM-based translation models, like ALMA, does not
match the performance of state-of-the-art conventional encoder-decoder
translation models or larger-scale LLMs such as GPT-4. In this study, we bridge
this performance gap. We first assess the shortcomings of supervised
fine-tuning for LLMs in the MT task, emphasizing the quality issues present in
the reference data, despite being human-generated. Then, in contrast to SFT
which mimics reference translations, we introduce Contrastive Preference
Optimization (CPO), a novel approach that trains models to avoid generating
adequate but not perfect translations. Applying CPO to ALMA models with only
22K parallel sentences and 12M parameters yields significant improvements. The
resulting model, called ALMA-R, can match or exceed the performance of the WMT
competition winners and GPT-4 on WMT'21, WMT'22 and WMT'23 test datasets.
</p>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08420" title="Abstract">arXiv:2401.08420</a> [<a href="/pdf/2401.08420" title="Download PDF">pdf</a>, <a href="/format/2401.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ask the experts: sourcing high-quality datasets for nutritional  counselling through Human-AI collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balloccu%2C+S">Simone Balloccu</a>, 
<a href="/search/cs?searchtype=author&query=Reiter%2C+E">Ehud Reiter</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vivek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Recupero%2C+D+R">Diego Reforgiato Recupero</a>, 
<a href="/search/cs?searchtype=author&query=Riboni%2C+D">Daniele Riboni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs), with their flexible generation abilities, can
be powerful data sources in domains with few or no available corpora. However,
problems like hallucinations and biases limit such applications. In this case
study, we pick nutrition counselling, a domain lacking any public resource, and
show that high-quality datasets can be gathered by combining LLMs,
crowd-workers and nutrition experts. We first crowd-source and cluster a novel
dataset of diet-related issues, then work with experts to prompt ChatGPT into
producing related supportive text. Finally, we let the experts evaluate the
safety of the generated text. We release HAI-coaching, the first
expert-annotated nutrition counselling dataset containing ~2.4K dietary
struggles from crowd workers, and ~97K related supportive texts generated by
ChatGPT. Extensive analysis shows that ChatGPT while producing highly fluent
and human-like text, also manifests harmful behaviours, especially in sensitive
topics like mental health, making it unsuitable for unsupervised use.
</p>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08422" title="Abstract">arXiv:2401.08422</a> [<a href="/pdf/2401.08422" title="Download PDF">pdf</a>, <a href="/format/2401.08422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Limited Supervised Foot Ulcer Segmentation Using Cross-Domain  Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuo%2C+S">Shang-Jui Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Po-Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chia-Ching Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jeng-Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+M">Ming-Ching Chang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Diabetic foot ulcers pose health risks, including higher morbidity,
mortality, and amputation rates. Monitoring wound areas is crucial for proper
care, but manual segmentation is subjective due to complex wound features and
background variation. Expert annotations are costly and time-intensive, thus
hampering large dataset creation. Existing segmentation models relying on
extensive annotations are impractical in real-world scenarios with limited
annotated data. In this paper, we propose a cross-domain augmentation method
named TransMix that combines Augmented Global Pre-training AGP and Localized
CutMix Fine-tuning LCF to enrich wound segmentation data for model learning.
TransMix can effectively improve the foot ulcer segmentation model training by
leveraging other dermatology datasets not on ulcer skins or wounds. AGP
effectively increases the overall image variability, while LCF increases the
diversity of wound regions. Experimental results show that TransMix increases
the variability of wound regions and substantially improves the Dice score for
models trained with only 40 annotated images under various proportions.
</p>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08423" title="Abstract">arXiv:2401.08423</a> [<a href="/pdf/2401.08423" title="Download PDF">pdf</a>, <a href="/format/2401.08423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Splines and Their Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lai%2C+M">Ming-Jun Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has 28 pages and 18 figures and is submitted for a conference proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper begins by reviewing numerous theoretical advancements in the field
of multivariate splines, primarily contributed by Professor Larry L. Schumaker.
These foundational results have paved the way for a wide range of applications
and computational techniques. The paper then proceeds to highlight various
practical applications of multivariate splines. These include scattered data
fitting and interpolation, the construction of smooth curves and surfaces, and
the numerical solutions of various partial differential equations, encompassing
both linear and nonlinear PDEs. Beyond these conventional and well-established
uses, the paper introduces a novel application of multivariate splines in
function value denoising. This innovative approach facilitates the creation of
LKB splines, which are instrumental in approximating high-dimensional functions
and effectively circumventing the curse of dimensionality.
</p>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08424" title="Abstract">arXiv:2401.08424</a> [<a href="/pdf/2401.08424" title="Download PDF">pdf</a>, <a href="/ps/2401.08424" title="Download PostScript">ps</a>, <a href="/format/2401.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal assessment of best possible self as a self-regulatory  activity for the classroom
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sayis%2C+B">Batuhan Sayis</a>, 
<a href="/search/cs?searchtype=author&query=Beardsley%2C+M">Marc Beardsley</a>, 
<a href="/search/cs?searchtype=author&query=Portero-Tresserra%2C+M">Marta Portero-Tresserra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at 11th International Conference on Affective Computing and Intelligent Interaction (ACII'2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Best possible self (BPS) is a positive psychological intervention shown to
enhance well-being which involves writing a description of an ideal future
scenario. This paper presents a comparison of psychophysiological effects of a
BPS activity that has been adapted for classroom settings and a time-matched
control activity (NA). Thirty-three undergraduate students participated in the
study that assessed state anxiety (State-Trait Anxiety Inventory, STAI), affect
(Affective Slider, AS), and cardiac vagal activity (heart-rate variability,
HRV) as an indicator of self-regulatory resource usage, at three time periods
(PRE, DURING, POST). Results show that BPS led to a significantly greater
increase in positive valence (DURING) and overall higher levels of cardiac
vagal activity (HRV) compared to NA. These findings suggest that BPS has
promising characteristics as a self-regulatory technique aimed at fostering
positive affect and positively impacting self-regulatory resources. As BPS does
not require expert knowledge nor specialized technology to administer, it may
be a suitable activity for educators to use when teaching and having students
practice self-regulation. This study presents evidence collected in a
replicable multimodal approach of the self-regulatory effects of a brief BPS
activity on undergraduate students.
</p>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08425" title="Abstract">arXiv:2401.08425</a> [<a href="/pdf/2401.08425" title="Download PDF">pdf</a>, <a href="/format/2401.08425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-DIADS-Bib: a full and few-shot pixel-precise dataset for document  layout analysis of ancient manuscripts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zottin%2C+S">Silvia Zottin</a>, 
<a href="/search/cs?searchtype=author&query=De+Nardin%2C+A">Axel De Nardin</a>, 
<a href="/search/cs?searchtype=author&query=Colombi%2C+E">Emanuela Colombi</a>, 
<a href="/search/cs?searchtype=author&query=Piciarelli%2C+C">Claudio Piciarelli</a>, 
<a href="/search/cs?searchtype=author&query=Pavan%2C+F">Filippo Pavan</a>, 
<a href="/search/cs?searchtype=author&query=Foresti%2C+G+L">Gian Luca Foresti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neural Comput &amp; Applic (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Document Layout Analysis, which is the task of identifying different semantic
regions inside of a document page, is a subject of great interest for both
computer scientists and humanities scholars as it represents a fundamental step
towards further analysis tasks for the former and a powerful tool to improve
and facilitate the study of the documents for the latter. However, many of the
works currently present in the literature, especially when it comes to the
available datasets, fail to meet the needs of both worlds and, in particular,
tend to lean towards the needs and common practices of the computer science
side, leading to resources that are not representative of the humanities real
needs. For this reason, the present paper introduces U-DIADS-Bib, a novel,
pixel-precise, non-overlapping and noiseless document layout analysis dataset
developed in close collaboration between specialists in the fields of computer
vision and humanities. Furthermore, we propose a novel, computer-aided,
segmentation pipeline in order to alleviate the burden represented by the
time-consuming process of manual annotation, necessary for the generation of
the ground truth segmentation maps. Finally, we present a standardized few-shot
version of the dataset (U-DIADS-BibFS), with the aim of encouraging the
development of models and solutions able to address this task with as few
samples as possible, which would allow for more effective use in a real-world
scenario, where collecting a large number of segmentations is not always
feasible.
</p>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08426" title="Abstract">arXiv:2401.08426</a> [<a href="/pdf/2401.08426" title="Download PDF">pdf</a>, <a href="/format/2401.08426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Three ways that non-differentiability affects neural network training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S+K">Siddharth Krishna Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper investigates how non-differentiability affects three different
aspects of the neural network training process. We first analyze fully
connected neural networks with ReLU activations, for which we show that the
continuously differentiable neural networks converge faster than
non-differentiable neural networks. Next, we analyze the problem of $L_{1}$
regularization and show that the solutions produced by deep learning solvers
are incorrect and counter-intuitive even for the $L_{1}$ penalized linear
model. Finally, we analyze the Edge of Stability problem, where we show that
all convex, non-smooth, Lipschitz continuous functions display unstable
convergence, and provide an example of a result derived using twice
differentiable functions which fails in the once differentiable setting. More
generally, our results suggest that accounting for the non-linearity of neural
networks in the training process is essential for us to develop better
algorithms, and to get a better understanding of the training process in
general.
</p>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08429" title="Abstract">arXiv:2401.08429</a> [<a href="/pdf/2401.08429" title="Download PDF">pdf</a>, <a href="/ps/2401.08429" title="Download PostScript">ps</a>, <a href="/format/2401.08429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation with Large Language Models: Prompt Engineering for  Persian, English, and Russian Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourkamali%2C+N">Nooshin Pourkamali</a>, 
<a href="/search/cs?searchtype=author&query=Sharifi%2C+S+E">Shler Ebrahim Sharifi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 46 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative large language models (LLMs) have demonstrated exceptional
proficiency in various natural language processing (NLP) tasks, including
machine translation, question answering, text summarization, and natural
language understanding.
<br />To further enhance the performance of LLMs in machine translation, we
conducted an investigation into two popular prompting methods and their
combination, focusing on cross-language combinations of Persian, English, and
Russian. We employed n-shot feeding and tailored prompting frameworks. Our
findings indicate that multilingual LLMs like PaLM exhibit human-like machine
translation outputs, enabling superior fine-tuning of desired translation
nuances in accordance with style guidelines and linguistic considerations.
These models also excel in processing and applying prompts. However, the choice
of language model, machine translation task, and the specific source and target
languages necessitate certain considerations when adopting prompting frameworks
and utilizing n-shot in-context learning.
<br />Furthermore, we identified errors and limitations inherent in popular LLMs as
machine translation tools and categorized them based on various linguistic
metrics. This typology of errors provides valuable insights for utilizing LLMs
effectively and offers methods for designing prompts for in-context learning.
Our report aims to contribute to the advancement of machine translation with
LLMs by improving both the accuracy and reliability of evaluation metrics.
</p>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08430" title="Abstract">arXiv:2401.08430</a> [<a href="/pdf/2401.08430" title="Download PDF">pdf</a>, <a href="/format/2401.08430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Capacitance Matching (DCM)-based Current Response Algorithm  for Signal Line RC Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhoujie Wu</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+C">Cai Luo</a>, 
<a href="/search/eess?searchtype=author&query=Guan%2C+Z">Zhong Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper proposes a dynamic capacitance matching (DCM)-based RC current
response algorithm for calculating the current waveform of a signal line
without performing SPICE simulation. Specifically, unlike previous method such
as CCS model, driver linear representation, waveform functional fitting or
equivalent load capacitance, our algorithm does not rely on fixed reduced model
of both standard cell driver and RC load. Instead, our algorithm approaches the
current waveform dynamically by computing current responses of the target
driver for various load scenarios. Besides, we creatively use symbolic
expression to combine the y-parameter of RC network with the pre-characterized
driver library in order to perform capacitance matching by considering
over/under-shoot effect. Our algorithm is experimentally verified on 40nm CMOS
technology and has been partially adopted by latest commercial tool for other
nodes. Experimental results show that our algorithm has excellent resolution
and promising efficiency compared with traditional methods and SPICE golden
result, especially for application in computing delay, power and signal line
electromigration.
</p>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08433" title="Abstract">arXiv:2401.08433</a> [<a href="/pdf/2401.08433" title="Download PDF">pdf</a>, <a href="/format/2401.08433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Multiple-Trolley Collection System with Nonholonomic Robots:  Design, Control, and Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Peijia Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bingyi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+A">Anjun Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lingxiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhirui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xuheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The intricate and multi-stage task in dynamic public spaces like luggage
trolley collection in airports presents both a promising opportunity and an
ongoing challenge for automated service robots. Previous research has primarily
focused on handling a single trolley or individual functional components,
creating a gap in providing cost-effective and efficient solutions for
practical scenarios. In this paper, we propose a mobile manipulation robot
incorporated with an autonomy framework for the collection and transportation
of multiple trolleys that can significantly enhance operational efficiency. We
address the key challenges in the trolley collection problem through the novel
design of the mechanical system and the vision-based control strategy. We
design a lightweight manipulator and docking mechanism, optimized for the
sequential stacking and transportation of multiple trolleys. Additionally,
based on the Control Lyapunov Function and Control Barrier Function, we propose
a novel vision-based control with the online Quadratic Programming which
significantly improves the accuracy and efficiency of the collection process.
The practical application of our system is demonstrated in real world
scenarios, where it successfully executes multiple-trolley collection tasks.
</p>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08434" title="Abstract">arXiv:2401.08434</a> [<a href="/pdf/2401.08434" title="Download PDF">pdf</a>, <a href="/format/2401.08434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed IRSs Always Benefit Every Mobile Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yashvanth%2C+L">L. Yashvanth</a>, 
<a href="/search/cs?searchtype=author&query=Murthy%2C+C+R">Chandra R. Murthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We investigate the impact of multiple distributed intelligent reflecting
surfaces (IRSs), which are deployed and optimized by a mobile operator (MO), on
the performance of user equipments (UEs) served by other co-existing
out-of-band (OOB) MOs that do not control the IRSs. We show that, under
round-robin scheduling, in mmWave frequencies, the ergodic sum spectral
efficiency (SE) of an OOB MO is monotonic in the total number of IRS elements
with a pre-log factor that depends on the channel properties of the OOB UE. We
further show that the maximum achievable SE of OOB MO scales log-linearly in
IRS elements. Then, by specifying the minimum number of IRSs as a function of
the channel parameters, we design a distributed IRS system in which an OOB MO
almost surely obtains the maximum SE. Finally, we prove that the outage
probability at an OOB UE decreases exponentially in the number of IRSs, even
though they are randomly configured from the UE's viewpoint. We numerically
verify our theory and conclude that distributed IRSs always help every MO, but
the MO controlling the IRSs benefits the most.
</p>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08438" title="Abstract">arXiv:2401.08438</a> [<a href="/pdf/2401.08438" title="Download PDF">pdf</a>, <a href="/format/2401.08438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yaojia Lv</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haojie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruiji Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+B">Bing Qin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cognitive dynamics are pivotal to advance human understanding of the world.
Recent advancements in large language models (LLMs) reveal their potential for
cognitive simulation. However, these LLM-based cognitive studies primarily
focus on static modeling, overlooking the dynamic nature of cognition. To
bridge this gap, we propose the concept of the cognitive dynamics of LLMs and
present a corresponding task with the inspiration of longitudinal studies.
Towards the task, we develop CogBench, a novel benchmark to assess the
cognitive dynamics of LLMs and validate it through participant surveys. We also
design two evaluation metrics for CogBench, including Authenticity and
Rationality. Recognizing the inherent static nature of LLMs, we introduce
CogGPT for the task, which features an innovative iterative cognitive mechanism
aimed at enhancing lifelong cognitive dynamics. Empirical results demonstrate
the superiority of CogGPT over existing methods, particularly in its ability to
facilitate role-specific cognitive dynamics under continuous information flows.
</p>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08443" title="Abstract">arXiv:2401.08443</a> [<a href="/pdf/2401.08443" title="Download PDF">pdf</a>, <a href="/format/2401.08443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Centralized vs. Decoupled Dual-Arm Planning Taking into Account Path  Quality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wittmann%2C+J">Jonas Wittmann</a>, 
<a href="/search/cs?searchtype=author&query=Ochsenfarth%2C+F">Franziska Ochsenfarth</a>, 
<a href="/search/cs?searchtype=author&query=Sonneville%2C+V">Valentin Sonneville</a>, 
<a href="/search/cs?searchtype=author&query=Rixen%2C+D">Daniel Rixen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The aim of coordinated planning is to avoid robot-to-robot collisions in a
multi-robot system, and there are two standard solution approaches: centralized
planning and decoupled planning. Our first contribution is a decoupled planning
approach that ensures C2-continuous control commands with zero velocities at
the start and goal. We benchmark our decoupled approach with a centralized
approach. Contrary to literature, we show that for a standard motion planning
pipeline, such as the one used by MoveIt!, centralized planning is superior to
decoupled planning in dual-arm manipulation: It has a lower computation time
and a higher robustness. Our second contribution is an optimization that
minimizes the rotational motion of an end-effector while considering obstacle
avoidance. We derive the analytic gradients of this optimization problem,
making the algorithm suitable for online motion planning. Our optimization
extends an existing path quality improvement method. Integrating it into our
decoupled approach overcomes its shortcomings and provides a motion planning
pipeline that is robust at up to 99.9% with a planning time of less than 1s and
that computes high-quality paths.
</p>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08444" title="Abstract">arXiv:2401.08444</a> [<a href="/pdf/2401.08444" title="Download PDF">pdf</a>, <a href="/format/2401.08444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revealing the Hidden Impact of Top-N Metrics on Optimization in  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wegmeth%2C+L">Lukas Wegmeth</a>, 
<a href="/search/cs?searchtype=author&query=Vente%2C+T">Tobias Vente</a>, 
<a href="/search/cs?searchtype=author&query=Purucker%2C+L">Lennart Purucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Full Paper Track for ECIR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The hyperparameters of recommender systems for top-n predictions are
typically optimized to enhance the predictive performance of algorithms.
Thereby, the optimization algorithm, e.g., grid search or random search,
searches for the best hyperparameter configuration according to an
optimization-target metric, like nDCG or Precision. In contrast, the optimized
algorithm, internally optimizes a different loss function during training, like
squared error or cross-entropy. To tackle this discrepancy, recent work focused
on generating loss functions better suited for recommender systems. Yet, when
evaluating an algorithm using a top-n metric during optimization, another
discrepancy between the optimization-target metric and the training loss has so
far been ignored. During optimization, the top-n items are selected for
computing a top-n metric; ignoring that the top-n items are selected from the
recommendations of a model trained with an entirely different loss function.
Item recommendations suitable for optimization-target metrics could be outside
the top-n recommended items; hiddenly impacting the optimization performance.
Therefore, we were motivated to analyze whether the top-n items are optimal for
optimization-target top-n metrics. In pursuit of an answer, we exhaustively
evaluate the predictive performance of 250 selection strategies besides
selecting the top-n. We extensively evaluate each selection strategy over
twelve implicit feedback and eight explicit feedback data sets with eleven
recommender systems algorithms. Our results show that there exist selection
strategies other than top-n that increase predictive performance for various
algorithms and recommendation domains. However, the performance of the top ~43%
of selection strategies is not significantly different. We discuss the impact
of our findings on optimization and re-ranking in recommender systems and
feasible solutions.
</p>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08445" title="Abstract">arXiv:2401.08445</a> [<a href="/pdf/2401.08445" title="Download PDF">pdf</a>, <a href="/format/2401.08445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Reasoning over Relational Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jurka%2C+J">Jan Jurka</a>, 
<a href="/search/cs?searchtype=author&query=Milius%2C+S">Stefan Milius</a>, 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Many important computational structures involve an intricate interplay
between algebraic features (given by operations on the underlying set) and
relational features (taking account of notions such as order or distance). This
paper investigates algebras over relational structures axiomatized by an
infinitary Horn theory, which subsume, for example, partial algebras, various
incarnations of ordered algebras, quantitative algebras introduced by Mardare,
Panangaden, and Plotkin, and their recent extension to generalized metric
spaces and lifted algebraic signatures by Mio, Sarkis, and Vignudelli. To this
end, we develop the notion of clustered equation, which is inspired by Mardare
et al.'s basic conditional equations in the theory of quantitative algebras, at
the level of generality of arbitrary relational structures, and we prove it to
be equivalent to an abstract categorical form of equation earlier introduced by
Milius and Urbat. Our main results are a family of Birkhoff-type variety
theorems (classifying the expressive power of clustered equations) and an
exactness theorem (classifying abstract equations by a congruence property).
</p>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08447" title="Abstract">arXiv:2401.08447</a> [<a href="/pdf/2401.08447" title="Download PDF">pdf</a>, <a href="/format/2401.08447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monitoring the development of CFD applications on unstable HPC platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dosimont%2C+D">Damien Dosimont</a>, 
<a href="/search/cs?searchtype=author&query=Houzeaux%2C+G">Guillaume Houzeaux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ParCFD2023 34th International Conference on Parallel Computational Fluid Dynamics, May 29-31 2023, Cuenca, Ecuador
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We tackle the challenging tasks of monitoring on unstable HPC platforms the
performance of CFD applications all along their development. We have designed
and implemented a monitoring framework, integrated at the end of a CI-CD
pipeline. Measures retrieved during the automatic execution of production
simulations are analyzed within a visual analytics interface we developed,
providing advanced visualizations and interaction. We have validated this
approach by monitoring the CFD code Alya over two years, detecting and
resolving issues related to the platform, and highlighting performance
improvement.
</p>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08449" title="Abstract">arXiv:2401.08449</a> [<a href="/pdf/2401.08449" title="Download PDF">pdf</a>, <a href="/format/2401.08449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIPRerank: An Extremely Simple Method for Improving Ad-hoc Video Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Aozhu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fangming Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xirong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Ad-hoc Video Search (AVS) enables users to search for unlabeled video content
using on-the-fly textual queries. Current deep learning-based models for AVS
are trained to optimize holistic similarity between short videos and their
associated descriptions. However, due to the diversity of ad-hoc queries, even
for a short video, its truly relevant part w.r.t. a given query can be of
shorter duration. In such a scenario, the holistic similarity becomes
suboptimal. To remedy the issue, we propose in this paper CLIPRerank, a
fine-grained re-scoring method. We compute cross-modal similarities between
query and video frames using a pre-trained CLIP model, with multi-frame scores
aggregated by max pooling. The fine-grained score is weightedly added to the
initial score for search result reranking. As such, CLIPRerank is agnostic to
the underlying video retrieval models and extremely simple, making it a handy
plug-in for boosting AVS. Experiments on the challenging TRECVID AVS benchmarks
(from 2016 to 2021) justify the effectiveness of the proposed strategy.
CLIPRerank consistently improves the TRECVID top performers and multiple
existing models including SEA, W2VV++, Dual Encoding, Dual Task, LAFF,
CLIP2Video, TS2-Net and X-CLIP. Our method also works when substituting BLIP-2
for CLIP.
</p>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08453" title="Abstract">arXiv:2401.08453</a> [<a href="/pdf/2401.08453" title="Download PDF">pdf</a>, <a href="/format/2401.08453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-existence of Terrestrial and Non-Terrestrial Networks in S-band
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Okati%2C+N">Niloofar Okati</a>, 
<a href="/search/eess?searchtype=author&query=Barreto%2C+A+N">Andre Noll Barreto</a>, 
<a href="/search/eess?searchtype=author&query=Garcia%2C+L+U">Luis Uzeda Garcia</a>, 
<a href="/search/eess?searchtype=author&query=Wigard%2C+J">Jeroen Wigard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Co-existence of terrestrial and non-terrestrial networks (NTN) is foreseen as
an important component to fulfill the global coverage promised for
sixth-generation (6G) of cellular networks. Due to ever rising spectrum demand,
using dedicated frequency bands for terrestrial network (TN) and NTN may not be
feasible. As a result, certain S-band frequency bands allocated by radio
regulations to NTN networks are overlapping with those already utilized by
cellular TN, leading to significant performance degradation due to the
potential co-channel interference. Early simulation-based studies on different
co-existence scenarios failed to offer a comprehensive and insightful
understanding of these networks' overall performance. Besides, the complexity
of a brute force performance evaluation increases exponentially with the number
of nodes and their possible combinations in the network. In this paper, we
utilize stochastic geometry to analytically derive the performance of TN-NTN
integrated networks in terms of the probability of coverage and average
achievable data rate for two co-existence scenarios. From the numerical
results, it can be observed that, depending on the network parameters, TN and
NTN users' distributions, and traffic load, one co-existence case may
outperform the other, resulting in optimal performance of the integrated
network. The analytical results presented herein pave the way for designing
state-of-the-art methods for spectrum sharing between TN and NTN and optimizing
the integrated network performance.
</p>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08455" title="Abstract">arXiv:2401.08455</a> [<a href="/pdf/2401.08455" title="Download PDF">pdf</a>, <a href="/ps/2401.08455" title="Download PostScript">ps</a>, <a href="/format/2401.08455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Submodule approach to creative telescoping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Hoeij%2C+M">Mark van Hoeij</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">This paper proposes ideas to speed up the process of creative telescoping,
particularly when the telescoper is reducible. One can interpret telescoping as
computing an annihilator $L \in D$ for an element $m$ in a $D$-module $M$. The
main idea is to look for submodules of $M$. If $N$ is a non-trivial submodule
of $M$, constructing the minimal operator $R$ of the image of $m$ in $M/N$
gives a right-factor of $L$ in $D$. Then $L = L' R$ where the left-factor $L'$
is the telescoper of $R(m) \in N$. To expedite computing $L'$, compute the
action of $D$ on a natural basis of $N$, then obtain $L'$ with a cyclic vector
computation.
<br />The next main idea is that when $N$ has automorphisms, use them to construct
submodules. An automorphism with distinct eigenvalues can be used to decompose
$N$ as a direct sum $N_1 \oplus \cdots \oplus N_k$. Then $L'$ is the LCLM
(Least Common Left Multiple) of $L_1, \ldots, L_k$ where $L_i$ is the
telescoper of the projection of $R(m)$ on $N_i$. An LCLM can greatly increase
the degrees of coefficients, so $L'$ and $L$ can be much larger expressions
than the factors $L_1,\ldots,L_k$ and $R$. Examples show that computing each
factor $L_i$ and $R$ seperately can save a lot of CPU time compared to
computing $L$ in expanded form with standard creative telescoping.
</p>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08458" title="Abstract">arXiv:2401.08458</a> [<a href="/pdf/2401.08458" title="Download PDF">pdf</a>, <a href="/format/2401.08458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy Issues and Solutions in Federated Learning for  Digital Healthcare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+H">Hyejun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+T">Tai-Myoung Chung</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Future Data and Security Engineering
  (2022) 316-331
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of Federated Learning has enabled the creation of a
high-performing model as if it had been trained on a considerable amount of
data. A multitude of participants and a server cooperatively train a model
without the need for data disclosure or collection. The healthcare industry,
where security and privacy are paramount, can substantially benefit from this
new learning paradigm, as data collection is no longer feasible due to
stringent data policies. Nonetheless, unaddressed challenges and insufficient
attack mitigation are hampering its adoption. Attack surfaces differ from
traditional centralized learning in that the server and clients communicate
between each round of training. In this paper, we thus present vulnerabilities,
attacks, and defenses based on the widened attack surfaces, as well as suggest
promising new research directions toward a more robust FL.
</p>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08460" title="Abstract">arXiv:2401.08460</a> [<a href="/pdf/2401.08460" title="Download PDF">pdf</a>, <a href="/format/2401.08460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Conversational Question Answering over  Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Conversational question answering (ConvQA) over law knowledge bases (KBs)
involves answering multi-turn natural language questions about law and hope to
find answers in the law knowledge base. Despite many methods have been
proposed. Existing law knowledge base ConvQA model assume that the input
question is clear and can perfectly reflect user's intention. However, in real
world, the input questions are noisy and inexplict. This makes the model hard
to find the correct answer in the law knowledge bases. In this paper, we try to
use reinforcement learning to solve this problem. The reinforcement learning
agent can automatically learn how to find the answer based on the input
question and the conversation history, even when the input question is
inexplicit. We test the proposed method on several real world datasets and the
results show the effectivenss of the proposed model.
</p>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08461" title="Abstract">arXiv:2401.08461</a> [<a href="/pdf/2401.08461" title="Download PDF">pdf</a>, <a href="/format/2401.08461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralised Emergence of Robust and Adaptive Linguistic Conventions in  Populations of Autonomous Agents Grounded in Continuous Worlds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ekila%2C+J+B">J&#xe9;r&#xf4;me Botoko Ekila</a>, 
<a href="/search/cs?searchtype=author&query=Nevens%2C+J">Jens Nevens</a>, 
<a href="/search/cs?searchtype=author&query=Verheyen%2C+L">Lara Verheyen</a>, 
<a href="/search/cs?searchtype=author&query=Beuls%2C+K">Katrien Beuls</a>, 
<a href="/search/cs?searchtype=author&query=Van+Eecke%2C+P">Paul Van Eecke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">This paper introduces a methodology through which a population of autonomous
agents can establish a linguistic convention that enables them to refer to
arbitrary entities that they observe in their environment. The linguistic
convention emerges in a decentralised manner through local communicative
interactions between pairs of agents drawn from the population. The convention
consists of symbolic labels (word forms) associated to concept representations
(word meanings) that are grounded in a continuous feature space. The concept
representations of each agent are individually constructed yet compatible on a
communicative level. Through a range of experiments, we show (i) that the
methodology enables a population to converge on a communicatively effective,
coherent and human-interpretable linguistic convention, (ii) that it is
naturally robust against sensor defects in individual agents, (iii) that it can
effectively deal with noisy observations, uncalibrated sensors and
heteromorphic populations, (iv) that the method is adequate for continual
learning, and (v) that the convention self-adapts to changes in the environment
and communicative needs of the agents.
</p>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08464" title="Abstract">arXiv:2401.08464</a> [<a href="/pdf/2401.08464" title="Download PDF">pdf</a>, <a href="/format/2401.08464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Evolving Domain Generalization through Dynamic Latent  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+B">Binghui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongqiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiwen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bo Han</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+W">Wei Meng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">James Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted By AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Domain generalization is a critical challenge for machine learning systems.
Prior domain generalization methods focus on extracting domain-invariant
features across several stationary domains to enable generalization to new
domains. However, in non-stationary tasks where new domains evolve in an
underlying continuous structure, such as time, merely extracting the invariant
features is insufficient for generalization to the evolving new domains.
Nevertheless, it is non-trivial to learn both evolving and invariant features
within a single model due to their conflicts. To bridge this gap, we build
causal models to characterize the distribution shifts concerning the two
patterns, and propose to learn both dynamic and invariant features via a new
framework called Mutual Information-Based Sequential Autoencoders (MISTS).
MISTS adopts information theoretic constraints onto sequential autoencoders to
disentangle the dynamic and invariant features, and leverage a domain adaptive
classifier to make predictions based on both evolving and invariant
information. Our experimental results on both synthetic and real-world datasets
demonstrate that MISTS succeeds in capturing both evolving and invariant
information, and present promising results in evolving domain generalization
tasks.
</p>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08465" title="Abstract">arXiv:2401.08465</a> [<a href="/pdf/2401.08465" title="Download PDF">pdf</a>, <a href="/format/2401.08465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Mobility Analysis of UE-Side Beamforming for Multi-Panel User  Equipment with Hand Blockage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+S+B">Subhyal Bin Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Nadaf%2C+S">Salman Nadaf</a>, 
<a href="/search/cs?searchtype=author&query=Karabulut%2C+U">Umur Karabulut</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+P">Philipp Schulz</a>, 
<a href="/search/cs?searchtype=author&query=Prado%2C+A">Anna Prado</a>, 
<a href="/search/cs?searchtype=author&query=Fettweis%2C+G+P">Gerhard P. Fettweis</a>, 
<a href="/search/cs?searchtype=author&query=Kellerer%2C+W">Wolfgang Kellerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures. Accepted for presentation at the 2024 IEEE Wireless Communications and Networking Conference (IEEE WCNC 2024), to be held in Dubai, United Arab Emirates
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The hand blockage effect of the human hand around the user equipment (UE) is
too considerable to be ignored in frequency range 2 (FR2). This adds another
layer of complexity to the link budget design in FR2 for 5G networks, which
already suffer from high path and diffraction loss. More recently, multipanel
UEs (MPUEs) have been proposed as a way to address this problem, whereby
multiple distinct antenna panels are integrated into the UE body as a way to
leverage gains from antenna directivity. MPUEs also enhance the Rx-beamforming
gain because it is now subject to each individual antenna panel. In this paper,
the mobility performance of hand blockage induced by three practical hand grips
is analyzed in a system-level simulation, where in each grip both the UE
orientation and the hand positioning around the UE is different. It is seen
that each hand grip has a significant impact on mobility performance of the
network, where in the worst case mobility failures increase by 43% compared to
the non-hand blockage case. Moreover, a detailed analysis of the tradeoff
between the mobility key performance indicators and the panel and Rx beam
switching frequency is also studied. Results have shown that both the panel and
Rx beam switches can be reduced considerably without compromising on the
mobility performance. This is beneficial because it helps in reducing UE power
consumption.
</p>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08470" title="Abstract">arXiv:2401.08470</a> [<a href="/pdf/2401.08470" title="Download PDF">pdf</a>, <a href="/ps/2401.08470" title="Download PostScript">ps</a>, <a href="/format/2401.08470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypergeometric Solutions of Linear Difference Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barkatou%2C+M">Moulay Barkatou</a>, 
<a href="/search/cs?searchtype=author&query=van+Hoeij%2C+M">Mark van Hoeij</a>, 
<a href="/search/cs?searchtype=author&query=Middeke%2C+J">Johannes Middeke</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
<p class="mathjax">We extend Petkov\v{s}ek's algorithm for computing hypergeometric solutions of
scalar difference equations to the case of difference systems $\tau(Y) = M Y$,
with $M \in {\rm GL}_n(C(x))$, where $\tau$ is the shift operator.
Hypergeometric solutions are solutions of the form $\gamma P$ where $P \in
C(x)^n$ and $\gamma$ is a hypergeometric term over $C(x)$, i.e.
${\tau(\gamma)}/{\gamma} \in C(x)$. Our contributions concern efficient
computation of a set of candidates for ${\tau(\gamma)}/{\gamma}$ which we write
as $\lambda = c\frac{A}{B}$ with monic $A, B \in C[x]$, $c \in C^*$. Factors of
the denominators of $M^{-1}$ and $M$ give candidates for $A$ and $B$, while
another algorithm is needed for $c$. We use the super-reduction algorithm to
compute candidates for $c$, as well as other ingredients to reduce the list of
candidates for $A/B$. To further reduce the number of candidates $A/B$, we
bound the so-called type of $A/B$ by bounding local types. Our algorithm has
been implemented in Maple and experiments show that our implementation can
handle systems of high dimension, which is useful for factoring operators.
</p>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08472" title="Abstract">arXiv:2401.08472</a> [<a href="/pdf/2401.08472" title="Download PDF">pdf</a>, <a href="/format/2401.08472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instilling Multi-round Thinking to Text-guided Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Lidong Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhedong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we study the text-guided image generation task. Our focus lies
in the modification of a reference image, given user text feedback, to imbue it
with specific desired properties. Despite recent strides in this field, a
persistent challenge remains that single-round optimization often overlooks
crucial details, particularly in the realm of fine-grained changes like shoes
or sleeves. This misalignment accumulation significantly hampers multi-round
customization during interaction. In an attempt to address this challenge, we
introduce a new self-supervised regularization into the existing framework,
i.e., multi-round regularization. It builds upon the observation that the
modification order does not affect the final result. As the name suggests, the
multi-round regularization encourages the model to maintain consistency across
different modification orders. Specifically, our proposed approach addresses
the issue where an initial failure to capture fine-grained details leads to
substantial discrepancies after multiple rounds, as opposed to traditional
one-round learning. Both qualitative and quantitative experiments show the
proposed method achieves high-fidelity generation quality over the text-guided
generation task, especially the local modification. Furthermore, we extend the
evaluation to semantic alignment with text by applying our method to
text-guided retrieval datasets, such as FahisonIQ, where it demonstrates
competitive performance.
</p>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08474" title="Abstract">arXiv:2401.08474</a> [<a href="/pdf/2401.08474" title="Download PDF">pdf</a>, <a href="/format/2401.08474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TUMTraf Event: Calibration and Fusion Resulting in a Dataset for  Roadside Event-Based and RGB Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cre%C3%9F%2C+C">Christian Cre&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+W">Walter Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Purschke%2C+N">Nils Purschke</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+B+N">Bach Ngoc Doan</a>, 
<a href="/search/cs?searchtype=author&query=Lakshminarasimhan%2C+V">Venkatnarayanan Lakshminarasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Strand%2C+L">Leah Strand</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A+C">Alois C. Knoll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 8 figures, 4 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Event-based cameras are predestined for Intelligent Transportation Systems
(ITS). They provide very high temporal resolution and dynamic range, which can
eliminate motion blur and make objects easier to recognize at night. However,
event-based images lack color and texture compared to images from a
conventional rgb camera. Considering that, data fusion between event-based and
conventional cameras can combine the strengths of both modalities. For this
purpose, extrinsic calibration is necessary. To the best of our knowledge, no
targetless calibration between event-based and rgb cameras can handle multiple
moving objects, nor data fusion optimized for the domain of roadside ITS
exists, nor synchronized event-based and rgb camera datasets in the field of
ITS are known. To fill these research gaps, based on our previous work, we
extend our targetless calibration approach with clustering methods to handle
multiple moving objects. Furthermore, we develop an early fusion, simple late
fusion, and a novel spatiotemporal late fusion method. Lastly, we publish the
TUMTraf Event Dataset, which contains more than 4k synchronized event-based and
rgb images with 21.9k labeled 2D boxes. During our extensive experiments, we
verified the effectiveness of our calibration method with multiple moving
objects. Furthermore, compared to a single rgb camera, we increased the
detection performance of up to +16% mAP in the day and up to +12% mAP in the
challenging night with our presented event-based sensor fusion methods. The
TUMTraf Event Dataset is available at
https://innovation-mobility.com/tumtraf-dataset.
</p>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08476" title="Abstract">arXiv:2401.08476</a> [<a href="/pdf/2401.08476" title="Download PDF">pdf</a>, <a href="/format/2401.08476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incentivizing Secure Software Development: The Role of Liability  (Waiver) and Audit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bicz%C3%B3k%2C+G">Gergely Bicz&#xf3;k</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mingyan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 6 figures, submitted to the 23rd Workshop on the Economics of Information Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Misaligned incentives in secure software development have long been the focus
of research in the economics of security. Product liability, a powerful legal
framework in other industries, has been largely ineffective for software
products until recent times. However, the rapid regulatory responses to recent
global cyberattacks by both the United States and the European Union, together
with the (relative) success of the General Data Protection Regulation in
defining both duty and standard of care for software vendors, may just enable
regulators to use liability to re-align incentives for the benefit of the
digital society. Specifically, the recently proposed United States National
Cybersecurity Strategy shifts responsibility for cyber incidents back to
software vendors. In doing so, the strategy also puts forward the concept of
the liability waiver: if a software company voluntarily undergoes and passes an
IT security audit, its liability is waived.
<br />In this paper, we analyze this audit scenario from the aspect of the software
vendor. We propose a mechanism where a software vendor should first undergo a
repeated auditing process in each stage of which the vendor decides whether to
quit early or stay with additional security investment. We show that the
optimal strategy for an opt-in vendor is to never quit; and exert cumulative
investments in either "one-and-done" or "incremental" manner. We relate the
audit mechanism to a liability waiver insurance policy and revealed its effect
on reshaping the vendor's risk perception. We also discuss influence of audit
quality on the vendor's incentives and pinpoint that a desirable audit rule
should be highly accurate and less strict.
</p>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08478" title="Abstract">arXiv:2401.08478</a> [<a href="/pdf/2401.08478" title="Download PDF">pdf</a>, <a href="/format/2401.08478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Continual Offline Reinforcement Learning with Decision  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaixin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Continuous offline reinforcement learning (CORL) combines continuous and
offline reinforcement learning, enabling agents to learn multiple tasks from
static datasets without forgetting prior tasks. However, CORL faces challenges
in balancing stability and plasticity. Existing methods, employing Actor-Critic
structures and experience replay (ER), suffer from distribution shifts, low
efficiency, and weak knowledge-sharing. We aim to investigate whether Decision
Transformer (DT), another offline RL paradigm, can serve as a more suitable
offline continuous learner to address these issues. We first compare AC-based
offline algorithms with DT in the CORL framework. DT offers advantages in
learning efficiency, distribution shift mitigation, and zero-shot
generalization but exacerbates the forgetting problem during supervised
parameter updates. We introduce multi-head DT (MH-DT) and low-rank adaptation
DT (LoRA-DT) to mitigate DT's forgetting problem. MH-DT stores task-specific
knowledge using multiple heads, facilitating knowledge sharing with common
components. It employs distillation and selective rehearsal to enhance current
task learning when a replay buffer is available. In buffer-unavailable
scenarios, LoRA-DT merges less influential weights and fine-tunes DT's decisive
MLP layer to adapt to the current task. Extensive experiments on MoJuCo and
Meta-World benchmarks demonstrate that our methods outperform SOTA CORL
baselines and showcase enhanced learning capabilities and superior memory
efficiency.
</p>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08484" title="Abstract">arXiv:2401.08484</a> [<a href="/pdf/2401.08484" title="Download PDF">pdf</a>, <a href="/ps/2401.08484" title="Download PostScript">ps</a>, <a href="/format/2401.08484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Dynamic Layout Optimization for Floating Offshore Wind Farm  Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jard%2C+T">Timoth&#xe9; Jard</a>, 
<a href="/search/eess?searchtype=author&query=Snaiki%2C+R">Reda Snaiki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Downstream wind turbines operating behind upstream turbines face significant
performance challenges due to reduced wind speeds and increased turbulence.
This leads to decreased wind energy production and higher dynamic loads on
downwind turbines. Consequently, real-time monitoring and control have become
crucial for improving wind farm performance. One promising solution involves
optimizing wind farm layouts in real-time, taking advantage of the added
flexibility offered by floating offshore wind turbines (FOWTs). This study
explores a dynamic layout optimization strategy to minimize wake effects in
wind farms while meeting power requirements. Two scenarios are considered:
power maximization and power set-point tracking. The methodology involves a
centralized wind farm controller optimizing the layout, followed by wind
turbine controllers to meet the prescribed targets. Each FOWT employs model
predictive control to adjust aerodynamic thrust force. The control strategy
integrates a dynamic wind farm model that considers floating platform motion
and wake transport in changing wind conditions. In a case study with a 1x3 wind
farm layout of 5 MW FOWTs, the results show a 25% increase in stable energy
production compared to a static layout in one hour for the first scenario. In
the second scenario, desired power production was swiftly and consistently
achieved.
</p>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08491" title="Abstract">arXiv:2401.08491</a> [<a href="/pdf/2401.08491" title="Download PDF">pdf</a>, <a href="/format/2401.08491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Perplexity for Controlled Generation: An Application in  Detoxifying Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klein%2C+T">Tassilo Klein</a>, 
<a href="/search/cs?searchtype=author&query=Nabi%2C+M">Moin Nabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The generation of undesirable and factually incorrect content of large
language models poses a significant challenge and remains largely an unsolved
issue. This paper studies the integration of a contrastive learning objective
for fine-tuning LLMs for implicit knowledge editing and controlled text
generation. Optimizing the training objective entails aligning text
perplexities in a contrastive fashion. To facilitate training the model in a
self-supervised fashion, we leverage an off-the-shelf LLM for training data
generation. We showcase applicability in the domain of detoxification. Herein,
the proposed approach leads to a significant decrease in the generation of
toxic content while preserving general utility for downstream tasks such as
commonsense reasoning and reading comprehension. The proposed approach is
conceptually simple but empirically powerful.
</p>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08495" title="Abstract">arXiv:2401.08495</a> [<a href="/pdf/2401.08495" title="Download PDF">pdf</a>, <a href="/format/2401.08495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Group Status on the Variability of Group Representations  in LLM-generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M+H+J">Messi H.J. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Montgomery%2C+J+M">Jacob M. Montgomery</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+C+K">Calvin K. Lai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the Socially Responsible Language Modelling Research (SoLaR) Workshop at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have become pervasive in everyday life, yet
their inner workings remain opaque. While scholarly efforts have demonstrated
LLMs' propensity to reproduce biases in their training data, they have
primarily focused on the association of social groups with stereotypic
attributes. In this paper, we extend this line of inquiry to investigate a bias
akin to the social-psychological phenomenon where socially dominant groups are
perceived to be less homogeneous than socially subordinate groups as it is
reproduced by LLMs. We had ChatGPT, a state-of-the-art LLM, generate a
diversity of texts about intersectional group identities and compared text
homogeneity. We consistently find that LLMs portray African, Asian, and
Hispanic Americans as more homogeneous than White Americans. They also portray
women as more homogeneous than men, but these differences are small. Finally,
we find that the effect of gender differs across racial/ethnic groups such that
the effect of gender is consistent within African and Hispanic Americans but
not within Asian and White Americans. We speculate possible sources of this
bias in LLMs and posit that the bias has the potential to amplify biases in
future LLM training and to reinforce stereotypes.
</p>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08497" title="Abstract">arXiv:2401.08497</a> [<a href="/pdf/2401.08497" title="Download PDF">pdf</a>, <a href="/format/2401.08497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Battery-Swapping Multi-Agent System for Sustained Operation of Large  Planetary Fleets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holand%2C+E">Ethan Holand</a>, 
<a href="/search/cs?searchtype=author&query=Homer%2C+J">Jarrod Homer</a>, 
<a href="/search/cs?searchtype=author&query=Storrer%2C+A">Alex Storrer</a>, 
<a href="/search/cs?searchtype=author&query=Khandeker%2C+M">Musheeera Khandeker</a>, 
<a href="/search/cs?searchtype=author&query=Muhlon%2C+E+F">Ethan F. Muhlon</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+M">Maulik Patel</a>, 
<a href="/search/cs?searchtype=author&query=Vainqueur%2C+B">Ben-oni Vainqueur</a>, 
<a href="/search/cs?searchtype=author&query=Antaki%2C+D">David Antaki</a>, 
<a href="/search/cs?searchtype=author&query=Cooke%2C+N">Naomi Cooke</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+C">Chloe Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Shafai%2C+B">Bahram Shafai</a>, 
<a href="/search/cs?searchtype=author&query=Hanson%2C+N">Nathaniel Hanson</a>, 
<a href="/search/cs?searchtype=author&query=Pad%C4%B1r%2C+T">Ta&#x15f;k&#x131;n Pad&#x131;r</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures. To be published in IEEE Aerospace Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We propose a novel, heterogeneous multi-agent architecture that miniaturizes
rovers by outsourcing power generation to a central hub. By delegating power
generation and distribution functions to this hub, the size, weight, power, and
cost (SWAP-C) per rover are reduced, enabling efficient fleet scaling. As these
rovers conduct mission tasks around the terrain, the hub charges an array of
replacement battery modules. When a rover requires charging, it returns to the
hub to initiate an autonomous docking sequence and exits with a fully charged
battery. This confers an advantage over direct charging methods, such as
wireless or wired charging, by replenishing a rover in minutes as opposed to
hours, increasing net rover uptime.
<br />This work shares an open-source platform developed to demonstrate battery
swapping on unknown field terrain. We detail our design methodologies utilized
for increasing system reliability, with a focus on optimization, robust
mechanical design, and verification. Optimization of the system is discussed,
including the design of passive guide rails through simulation-based
optimization methods which increase the valid docking configuration space by
258%. The full system was evaluated during integrated testing, where an average
servicing time of 98 seconds was achieved on surfaces with a gradient up to
10{\deg}. We conclude by briefly proposing flight considerations for advancing
the system toward a space-ready design. In sum, this prototype represents a
proof of concept for autonomous docking and battery transfer on field terrain,
advancing its Technology Readiness Level (TRL) from 1 to 3.
</p>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08500" title="Abstract">arXiv:2401.08500</a> [<a href="/pdf/2401.08500" title="Download PDF">pdf</a>, <a href="/format/2401.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Code Generation with AlphaCodium: From Prompt Engineering to Flow  Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ridnik%2C+T">Tal Ridnik</a>, 
<a href="/search/cs?searchtype=author&query=Kredo%2C+D">Dedy Kredo</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+I">Itamar Friedman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
<p class="mathjax">Code generation problems differ from common natural language problems - they
require matching the exact syntax of the target language, identifying happy
paths and edge cases, paying attention to numerous small details in the problem
spec, and addressing other code-specific issues and requirements. Hence, many
of the optimizations and tricks that have been successful in natural language
generation may not be effective for code tasks. In this work, we propose a new
approach to code generation by LLMs, which we call AlphaCodium - a test-based,
multi-stage, code-oriented iterative flow, that improves the performances of
LLMs on code problems. We tested AlphaCodium on a challenging code generation
dataset called CodeContests, which includes competitive programming problems
from platforms such as Codeforces. The proposed flow consistently and
significantly improves results. On the validation set, for example, GPT-4
accuracy (pass@5) increased from 19% with a single well-designed direct prompt
to 44% with the AlphaCodium flow. Many of the principles and best practices
acquired in this work, we believe, are broadly applicable to general code
generation tasks. Full implementation is available at:
https://github.com/Codium-ai/AlphaCodium
</p>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08501" title="Abstract">arXiv:2401.08501</a> [<a href="/pdf/2401.08501" title="Download PDF">pdf</a>, <a href="/format/2401.08501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ValUES: A Framework for Systematic Validation of Uncertainty Estimation  in Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahl%2C+K">Kim-Celine Kahl</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCth%2C+C+T">Carsten T. L&#xfc;th</a>, 
<a href="/search/cs?searchtype=author&query=Zenk%2C+M">Maximilian Zenk</a>, 
<a href="/search/cs?searchtype=author&query=Maier-Hein%2C+K">Klaus Maier-Hein</a>, 
<a href="/search/cs?searchtype=author&query=Jaeger%2C+P+F">Paul F. Jaeger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Uncertainty estimation is an essential and heavily-studied component for the
reliable application of semantic segmentation methods. While various studies
exist claiming methodological advances on the one hand, and successful
application on the other hand, the field is currently hampered by a gap between
theory and practice leaving fundamental questions unanswered: Can data-related
and model-related uncertainty really be separated in practice? Which components
of an uncertainty method are essential for real-world performance? Which
uncertainty method works well for which application? In this work, we link this
research gap to a lack of systematic and comprehensive evaluation of
uncertainty methods. Specifically, we identify three key pitfalls in current
literature and present an evaluation framework that bridges the research gap by
providing 1) a controlled environment for studying data ambiguities as well as
distribution shifts, 2) systematic ablations of relevant method components, and
3) test-beds for the five predominant uncertainty applications: OoD-detection,
active learning, failure detection, calibration, and ambiguity modeling.
Empirical results on simulated as well as real-world data demonstrate how the
proposed framework is able to answer the predominant questions in the field
revealing for instance that 1) separation of uncertainty types works on
simulated data but does not necessarily translate to real-world data, 2)
aggregation of scores is a crucial but currently neglected component of
uncertainty methods, 3) While ensembles are performing most robustly across the
different downstream tasks and settings, test-time augmentation often
constitutes a light-weight alternative. Code is at:
https://github.com/IML-DKFZ/values
</p>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08503" title="Abstract">arXiv:2401.08503</a> [<a href="/pdf/2401.08503" title="Download PDF">pdf</a>, <a href="/format/2401.08503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhenhui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tianyun Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yi Ren</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiaqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weichuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Ziyue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinzheng He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+R">Rongjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiang Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zejun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhou Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024 (Spotlight). Project page: <a href="https://real3dportrait.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One-shot 3D talking portrait generation aims to reconstruct a 3D avatar from
an unseen image, and then animate it with a reference video or audio to
generate a talking portrait video. The existing methods fail to simultaneously
achieve the goals of accurate 3D avatar reconstruction and stable talking face
animation. Besides, while the existing works mainly focus on synthesizing the
head part, it is also vital to generate natural torso and background segments
to obtain a realistic talking portrait video. To address these limitations, we
present Real3D-Potrait, a framework that (1) improves the one-shot 3D
reconstruction power with a large image-to-plane model that distills 3D prior
knowledge from a 3D face generative model; (2) facilitates accurate
motion-conditioned animation with an efficient motion adapter; (3) synthesizes
realistic video with natural torso movement and switchable background using a
head-torso-background super-resolution model; and (4) supports one-shot
audio-driven talking face generation with a generalizable audio-to-motion
model. Extensive experiments show that Real3D-Portrait generalizes well to
unseen identities and generates more realistic talking portrait videos compared
to previous methods.
</p>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08505" title="Abstract">arXiv:2401.08505</a> [<a href="/pdf/2401.08505" title="Download PDF">pdf</a>, <a href="/format/2401.08505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Orthogonality to Train Low-Rank Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coquelin%2C+D">Daniel Coquelin</a>, 
<a href="/search/cs?searchtype=author&query=Fl%C3%BCgel%2C+K">Katharina Fl&#xfc;gel</a>, 
<a href="/search/cs?searchtype=author&query=Weiel%2C+M">Marie Weiel</a>, 
<a href="/search/cs?searchtype=author&query=Kiefer%2C+N">Nicholas Kiefer</a>, 
<a href="/search/cs?searchtype=author&query=Debus%2C+C">Charlotte Debus</a>, 
<a href="/search/cs?searchtype=author&query=Streit%2C+A">Achim Streit</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tz%2C+M">Markus G&#xf6;tz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study explores the learning dynamics of neural networks by analyzing the
singular value decomposition (SVD) of their weights throughout training. Our
investigation reveals that an orthogonal basis within each multidimensional
weight's SVD representation stabilizes during training. Building upon this, we
introduce Orthogonality-Informed Adaptive Low-Rank (OIALR) training, a novel
training method exploiting the intrinsic orthogonality of neural networks.
OIALR seamlessly integrates into existing training workflows with minimal
accuracy loss, as demonstrated by benchmarking on various datasets and
well-established network architectures. With appropriate hyperparameter tuning,
OIALR can surpass conventional training setups, including those of
state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08506" title="Abstract">arXiv:2401.08506</a> [<a href="/pdf/2401.08506" title="Download PDF">pdf</a>, <a href="/ps/2401.08506" title="Download PostScript">ps</a>, <a href="/format/2401.08506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Content-Aware Tweet Location Inference using Quadtree Spatial  Partitioning and Jaccard-Cosine Word Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajao%2C+O">Oluwaseun Ajao</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+D">Deepayan Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Zargari%2C+S">Shahrzad Zargari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, 5 tables, International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2018)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In ASONAM 2018 (pp. 1116-1123). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Inferring locations from user texts on social media platforms is a
non-trivial and challenging problem relating to public safety. We propose a
novel non-uniform grid-based approach for location inference from Twitter
messages using Quadtree spatial partitions. The proposed algorithm uses natural
language processing (NLP) for semantic understanding and incorporates Cosine
similarity and Jaccard similarity measures for feature vector extraction and
dimensionality reduction. We chose Twitter as our experimental social media
platform due to its popularity and effectiveness for the dissemination of news
and stories about recent events happening around the world. Our approach is the
first of its kind to make location inference from tweets using Quadtree spatial
partitions and NLP, in hybrid word-vector representations. The proposed
algorithm achieved significant classification accuracy and outperformed
state-of-the-art grid-based content-only location inference methods by up to
24% in correctly predicting tweet locations within a 161km radius and by 300km
in median error distance on benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08508" title="Abstract">arXiv:2401.08508</a> [<a href="/pdf/2401.08508" title="Download PDF">pdf</a>, <a href="/format/2401.08508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EmoLLMs: A Series of Emotional Large Language Models and Annotation  Tools for Comprehensive Affective Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zeping Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Sentiment analysis and emotion detection are important research topics in
natural language processing (NLP) and benefit many downstream tasks. With the
widespread application of LLMs, researchers have started exploring the
application of LLMs based on instruction-tuning in the field of sentiment
analysis. However, these models only focus on single aspects of affective
classification tasks (e.g. sentimental polarity or categorical emotions), and
overlook the regression tasks (e.g. sentiment strength or emotion intensity),
which leads to poor performance in downstream tasks. The main reason is the
lack of comprehensive affective instruction tuning datasets and evaluation
benchmarks, which cover various affective classification and regression tasks.
Moreover, although emotional information is useful for downstream tasks,
existing downstream datasets lack high-quality and comprehensive affective
annotations. In this paper, we propose EmoLLMs, the first series of
open-sourced instruction-following LLMs for comprehensive affective analysis
based on fine-tuning various LLMs with instruction data, the first multi-task
affective analysis instruction dataset (AAID) with 234K data samples based on
various classification and regression tasks to support LLM instruction tuning,
and a comprehensive affective evaluation benchmark (AEB) with 14 tasks from
various sources and domains to test the generalization ability of LLMs. We
propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various
affective instruction tasks. We compare our model with a variety of LLMs on
AEB, where our models outperform all other open-sourced LLMs, and surpass
ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve
the ChatGPT-level and GPT-4-level generalization capabilities on affective
analysis tasks, and demonstrates our models can be used as affective annotation
tools.
</p>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08511" title="Abstract">arXiv:2401.08511</a> [<a href="/pdf/2401.08511" title="Download PDF">pdf</a>, <a href="/format/2401.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Gaps between Pre-train and Downstream Settings in Bias Evaluation  and Debiasing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+M">Masahiro Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Bollegala%2C+D">Danushka Bollegala</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The output tendencies of Pre-trained Language Models (PLM) vary markedly
before and after Fine-Tuning (FT) due to the updates to the model parameters.
These divergences in output tendencies result in a gap in the social biases of
PLMs. For example, there exits a low correlation between intrinsic bias scores
of a PLM and its extrinsic bias scores under FT-based debiasing methods.
Additionally, applying FT-based debiasing methods to a PLM leads to a decline
in performance in downstream tasks. On the other hand, PLMs trained on large
datasets can learn without parameter updates via In-Context Learning (ICL)
using prompts. ICL induces smaller changes to PLMs compared to FT-based
debiasing methods. Therefore, we hypothesize that the gap observed in
pre-trained and FT models does not hold true for debiasing methods that use
ICL. In this study, we demonstrate that ICL-based debiasing methods show a
higher correlation between intrinsic and extrinsic bias scores compared to
FT-based methods. Moreover, the performance degradation due to debiasing is
also lower in the ICL case compared to that in the FT case.
</p>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08513" title="Abstract">arXiv:2401.08513</a> [<a href="/pdf/2401.08513" title="Download PDF">pdf</a>, <a href="/format/2401.08513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X Hacking: The Threat of Misguided AutoML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Rahul Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Redyuk%2C+S">Sergey Redyuk</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sumantrak Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Sipka%2C+A">Andrea Sipka</a>, 
<a href="/search/cs?searchtype=author&query=Vollmer%2C+S">Sebastian Vollmer</a>, 
<a href="/search/cs?searchtype=author&query=Selby%2C+D">David Selby</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, plus supplementary materials
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Explainable AI (XAI) and interpretable machine learning methods help to build
trust in model predictions and derived insights, yet also present a perverse
incentive for analysts to manipulate XAI metrics to support pre-specified
conclusions. This paper introduces the concept of X-hacking, a form of
p-hacking applied to XAI metrics such as Shap values. We show how an automated
machine learning pipeline can be used to search for 'defensible' models that
produce a desired explanation while maintaining superior predictive performance
to a common baseline. We formulate the trade-off between explanation and
accuracy as a multi-objective optimization problem and illustrate the
feasibility and severity of X-hacking empirically on familiar real-world
datasets. Finally, we suggest possible methods for detection and prevention,
and discuss ethical implications for the credibility and reproducibility of XAI
research.
</p>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08514" title="Abstract">arXiv:2401.08514</a> [<a href="/pdf/2401.08514" title="Download PDF">pdf</a>, <a href="/format/2401.08514" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN  Expressiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bohang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+J">Jingchu Gai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiheng Du</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qiwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 73 pages, 9 figures, 9 tables; Extended from ICLR 2024 (Oral Presentation). This version polishes all proofs for better readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">Designing expressive Graph Neural Networks (GNNs) is a fundamental topic in
the graph learning community. So far, GNN expressiveness has been primarily
assessed via the Weisfeiler-Lehman (WL) hierarchy. However, such an
expressivity measure has notable limitations: it is inherently coarse,
qualitative, and may not well reflect practical requirements (e.g., the ability
to encode substructures). In this paper, we introduce a unified framework for
quantitatively studying the expressiveness of GNN architectures, addressing all
the above limitations. Specifically, we identify a fundamental expressivity
measure termed homomorphism expressivity, which quantifies the ability of GNN
models to count graphs under homomorphism. Homomorphism expressivity offers a
complete and practical assessment tool: the completeness enables direct
expressivity comparisons between GNN models, while the practicality allows for
understanding concrete GNN abilities such as subgraph counting. By examining
four classes of prominent GNNs as case studies, we derive simple, unified, and
elegant descriptions of their homomorphism expressivity for both invariant and
equivariant settings. Our results provide novel insights into a series of
previous work, unify the landscape of different subareas in the community, and
settle several open questions. Empirically, extensive experiments on both
synthetic and real-world tasks verify our theory, showing that the practical
performance of GNN models aligns well with the proposed metric.
</p>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08517" title="Abstract">arXiv:2401.08517</a> [<a href="/pdf/2401.08517" title="Download PDF">pdf</a>, <a href="/ps/2401.08517" title="Download PostScript">ps</a>, <a href="/format/2401.08517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting Student Decisions on Learning Recommendations: An LLM-Based  Chatbot with Knowledge Graph Contextualization for Conversational  Explainability and Mentoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Abdulsalam%2C+M+H">Mohamad Hussam Abdulsalam</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Christian Weber</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Student commitment towards a learning recommendation is not separable from
their understanding of the reasons it was recommended to them; and their
ability to modify it based on that understanding. Among explainability
approaches, chatbots offer the potential to engage the student in a
conversation, similar to a discussion with a peer or a mentor. The capabilities
of chatbots, however, are still not sufficient to replace a human mentor,
despite the advancements of generative AI (GenAI) and large language models
(LLM). Therefore, we propose an approach to utilize chatbots as mediators of
the conversation and sources of limited and controlled generation of
explanations, to harvest the potential of LLMs while reducing their potential
risks at the same time. The proposed LLM-based chatbot supports students in
understanding learning-paths recommendations. We use a knowledge graph (KG) as
a human-curated source of information, to regulate the LLM's output through
defining its prompt's context. A group chat approach is developed to connect
students with human mentors, either on demand or in cases that exceed the
chatbot's pre-defined tasks. We evaluate the chatbot with a user study, to
provide a proof-of-concept and highlight the potential requirements and
limitations of utilizing chatbots in conversational explainability.
</p>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08518" title="Abstract">arXiv:2401.08518</a> [<a href="/pdf/2401.08518" title="Download PDF">pdf</a>, <a href="/format/2401.08518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPSURF: Combining Patches and Point Convolutions for Detailed Surface  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Erler%2C+P">Philipp Erler</a>, 
<a href="/search/cs?searchtype=author&query=Fuentes%2C+L">Lizeth Fuentes</a>, 
<a href="/search/cs?searchtype=author&query=Hermosilla%2C+P">Pedro Hermosilla</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+P">Paul Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Wimmer%2C+R+P+M">Renato Pajarola Michael Wimmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Computer Graphics Forum (Jan 2024): <a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.15000">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computer Graphics Forum e15000, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">3D surface reconstruction from point clouds is a key step in areas such as
content creation, archaeology, digital cultural heritage, and engineering.
Current approaches either try to optimize a non-data-driven surface
representation to fit the points, or learn a data-driven prior over the
distribution of commonly occurring surfaces and how they correlate with
potentially noisy point clouds. Data-driven methods enable robust handling of
noise and typically either focus on a global or a local prior, which trade-off
between robustness to noise on the global end and surface detail preservation
on the local end. We propose PPSurf as a method that combines a global prior
based on point convolutions and a local prior based on processing local point
cloud patches. We show that this approach is robust to noise while recovering
surface details more accurately than the current state-of-the-art.
<br />Our source code, pre-trained model and dataset are available at:
https://github.com/cg-tuwien/ppsurf
</p>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08519" title="Abstract">arXiv:2401.08519</a> [<a href="/pdf/2401.08519" title="Download PDF">pdf</a>, <a href="/format/2401.08519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Graphs to Hypergraphs: Hypergraph Projection and its Remediation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We study the implications of the modeling choice to use a graph, instead of a
hypergraph, to represent real-world interconnected systems whose constituent
relationships are of higher order by nature. Such a modeling choice typically
involves an underlying projection process that maps the original hypergraph
onto a graph, and is common in graph-based analysis. While hypergraph
projection can potentially lead to loss of higher-order relations, there exists
very limited studies on the consequences of doing so, as well as its
remediation. This work fills this gap by doing two things: (1) we develop
analysis based on graph and set theory, showing two ubiquitous patterns of
hyperedges that are root to structural information loss in all hypergraph
projections; we also quantify the combinatorial impossibility of recovering the
lost higher-order structures if no extra help is provided; (2) we still seek to
recover the lost higher-order structures in hypergraph projection, and in light
of (1)'s findings we propose to relax the problem into a learning-based
setting. Under this setting, we develop a learning-based hypergraph
reconstruction method based on an important statistic of hyperedge
distributions that we find. Our reconstruction method is evaluated on 8
real-world datasets under different settings, and exhibits consistently good
performance. We also demonstrate benefits of the reconstructed hypergraphs via
use cases of protein rankings and link predictions.
</p>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08520" title="Abstract">arXiv:2401.08520</a> [<a href="/pdf/2401.08520" title="Download PDF">pdf</a>, <a href="/format/2401.08520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SecPLF: Secure Protocols for Loanable Funds against Oracle Manipulation  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Sanidhay Arora</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingjiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yebo Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiahua Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The evolving landscape of Decentralized Finance (DeFi) has raised critical
security concerns, especially pertaining to Protocols for Loanable Funds (PLFs)
and their dependency on price oracles, which are susceptible to manipulation.
The emergence of flash loans has further amplified these risks, enabling
increasingly complex oracle manipulation attacks that can lead to significant
financial losses. Responding to this threat, we first dissect the attack
mechanism by formalizing the standard operational and adversary models for
PLFs. Based on our analysis, we propose SecPLF, a robust and practical solution
designed to counteract oracle manipulation attacks efficiently. SecPLF operates
by tracking a price state for each crypto-asset, including the recent price and
the timestamp of its last update. By imposing price constraints on the price
oracle usage, SecPLF ensures a PLF only engages a price oracle if the last
recorded price falls within a defined threshold, thereby negating the
profitability of potential attacks. Our evaluation based on historical market
data confirms SecPLF's efficacy in providing high-confidence prevention against
arbitrage attacks that arise due to minor price differences. SecPLF delivers
proactive protection against oracle manipulation attacks, offering ease of
implementation, oracle-agnostic property, and resource and cost efficiency.
</p>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08522" title="Abstract">arXiv:2401.08522</a> [<a href="/pdf/2401.08522" title="Download PDF">pdf</a>, <a href="/format/2401.08522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Quality Assessment Based on Swin TransformerV2 and Coarse to Fine  Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zihao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+F">Fengbin Guan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yiting Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The objective of non-reference video quality assessment is to evaluate the
quality of distorted video without access to reference high-definition
references. In this study, we introduce an enhanced spatial perception module,
pre-trained on multiple image quality assessment datasets, and a lightweight
temporal fusion module to address the no-reference visual quality assessment
(NR-VQA) task. This model implements Swin Transformer V2 as a local-level
spatial feature extractor and fuses these multi-stage representations through a
series of transformer layers. Furthermore, a temporal transformer is utilized
for spatiotemporal feature fusion across the video. To accommodate compressed
videos of varying bitrates, we incorporate a coarse-to-fine contrastive
strategy to enrich the model's capability to discriminate features from videos
of different bitrates. This is an expanded version of the one-page abstract.
</p>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08525" title="Abstract">arXiv:2401.08525</a> [<a href="/pdf/2401.08525" title="Download PDF">pdf</a>, <a href="/format/2401.08525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GATS: Gather-Attend-Scatter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zolna%2C+K">Konrad Zolna</a>, 
<a href="/search/cs?searchtype=author&query=Cabi%2C+S">Serkan Cabi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yutian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+E">Eric Lau</a>, 
<a href="/search/cs?searchtype=author&query=Fantacci%2C+C">Claudio Fantacci</a>, 
<a href="/search/cs?searchtype=author&query=Pasukonis%2C+J">Jurgis Pasukonis</a>, 
<a href="/search/cs?searchtype=author&query=Springenberg%2C+J+T">Jost Tobias Springenberg</a>, 
<a href="/search/cs?searchtype=author&query=Colmenarejo%2C+S+G">Sergio Gomez Colmenarejo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">As the AI community increasingly adopts large-scale models, it is crucial to
develop general and flexible tools to integrate them. We introduce
Gather-Attend-Scatter (GATS), a novel module that enables seamless combination
of pretrained foundation models, both trainable and frozen, into larger
multimodal networks. GATS empowers AI systems to process and generate
information across multiple modalities at different rates. In contrast to
traditional fine-tuning, GATS allows for the original component models to
remain frozen, avoiding the risk of them losing important knowledge acquired
during the pretraining phase. We demonstrate the utility and versatility of
GATS with a few experiments across games, robotics, and multimodal input-output
systems.
</p>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08527" title="Abstract">arXiv:2401.08527</a> [<a href="/pdf/2401.08527" title="Download PDF">pdf</a>, <a href="/format/2401.08527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MICA: Towards Explainable Skin Lesion Diagnosis via Multi-Level  Image-Concept Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bie%2C+Y">Yequan Bie</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Luyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Black-box deep learning approaches have showcased significant potential in
the realm of medical image analysis. However, the stringent trustworthiness
requirements intrinsic to the medical field have catalyzed research into the
utilization of Explainable Artificial Intelligence (XAI), with a particular
focus on concept-based methods. Existing concept-based methods predominantly
apply concept annotations from a single perspective (e.g., global level),
neglecting the nuanced semantic relationships between sub-regions and concepts
embedded within medical images. This leads to underutilization of the valuable
medical information and may cause models to fall short in harmoniously
balancing interpretability and performance when employing inherently
interpretable architectures such as Concept Bottlenecks. To mitigate these
shortcomings, we propose a multi-modal explainable disease diagnosis framework
that meticulously aligns medical images and clinical-related concepts
semantically at multiple strata, encompassing the image level, token level, and
concept level. Moreover, our method allows for model intervention and offers
both textual and visual explanations in terms of human-interpretable concepts.
Experimental results on three skin image datasets demonstrate that our method,
while preserving model interpretability, attains high performance and label
efficiency for concept detection and disease diagnosis.
</p>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08534" title="Abstract">arXiv:2401.08534</a> [<a href="/pdf/2401.08534" title="Download PDF">pdf</a>, <a href="/format/2401.08534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiConStruct: Causal Concept-based Explanations through Black-Box  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreira%2C+R">Ricardo Moreira</a>, 
<a href="/search/cs?searchtype=author&query=Bono%2C+J">Jacopo Bono</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+M">M&#xe1;rio Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Saleiro%2C+P">Pedro Saleiro</a>, 
<a href="/search/cs?searchtype=author&query=Figueiredo%2C+M+A+T">M&#xe1;rio A. T. Figueiredo</a>, 
<a href="/search/cs?searchtype=author&query=Bizarro%2C+P">Pedro Bizarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Conference on Causal Learning and Reasoning (CLeaR 2024, <a href="https://www.cclear.cc/2024">this https URL</a>). To be published at Proceedings of Machine Learning Research (PMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Model interpretability plays a central role in human-AI decision-making
systems. Ideally, explanations should be expressed using human-interpretable
semantic concepts. Moreover, the causal relations between these concepts should
be captured by the explainer to allow for reasoning about the explanations.
Lastly, explanation methods should be efficient and not compromise the
performance of the predictive task. Despite the rapid advances in AI
explainability in recent years, as far as we know to date, no method fulfills
these three properties. Indeed, mainstream methods for local concept
explainability do not produce causal explanations and incur a trade-off between
explainability and prediction performance. We present DiConStruct, an
explanation method that is both concept-based and causal, with the goal of
creating more interpretable local explanations in the form of structural causal
models and concept attributions. Our explainer works as a distillation model to
any black-box machine learning model by approximating its predictions while
producing the respective explanations. Because of this, DiConStruct generates
explanations efficiently while not impacting the black-box prediction task. We
validate our method on an image dataset and a tabular dataset, showing that
DiConStruct approximates the black-box models with higher fidelity than other
concept explainability baselines, while providing explanations that include the
causal relations between the concepts.
</p>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08536" title="Abstract">arXiv:2401.08536</a> [<a href="/pdf/2401.08536" title="Download PDF">pdf</a>, <a href="/format/2401.08536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Loop Robust Control of Biased Koopman Operator Model by Noisy Data  of Nonlinear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pal%2C+A">Anuj Pal</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+T">Tianyi He</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xiang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The Koopman operator approach for data-driven control design of a nonlinear
system is on the rise because of its capability to capture the behaviours of
global dynamics. However, the measurement noises of inputs and outputs will
bias the Koopman model identification and cause model mismatch from the actual
nonlinear dynamics. The current work evaluates the bounds of the noise-induced
model bias of the Koopman operator model and proposes a data-driven robust
dual-loop control framework (Koopman based robust control-KROC) for the biased
model. First, the model mismatch is found bounded under radial basis functions
(RBF) and the bounded noises, and the bound of model mismatch is assessed.
Second, the pitfalls of linear quadratic Gaussian (LQG) control based on the
biased Koopman model of Van Der Pol oscillator are shown. Motivated from the
pitfalls, the dual-loop control is proposed, which consist of an observer-based
state-feedback control based on the nominal Koopman model and an additional
robust loop to compensate model mismatch. A linear matrix inequality (LMI) is
derived, which can guarantee robust stability and performance under bounded
noises for the finite-dimensional Koopman operator model. Finally, the proposed
framework is implemented to a nonlinear Van Der Pol oscillator to demonstrate
enhanced control performance by the dual-loop robust control.
</p>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08537" title="Abstract">arXiv:2401.08537</a> [<a href="/pdf/2401.08537" title="Download PDF">pdf</a>, <a href="/ps/2401.08537" title="Download PostScript">ps</a>, <a href="/format/2401.08537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Entity Resolution between Restaurant Locations and  Transportation Destinations in Southeast Asia
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+E">Emily Gao</a>, 
<a href="/search/cs?searchtype=author&query=Widdows%2C+D">Dominic Widdows</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 6th International Conference on Geospatial Information Systems
  Theory, Applications, and Management. GISTAM 2020, Prague, Czech Republic,
  May 7-9, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As a tech company, Grab has expanded from transportation to food delivery,
aiming to serve Southeast Asia with hyperlocalized applications. Information
about places as transportation destinations can help to improve our knowledge
about places as restaurants, so long as the spatial entity resolution problem
between these datasets can be solved. In this project, we attempted to
recognize identical place entities from databases of Points-of-Interest (POI)
and GrabFood restaurants, using their spatial and textual attributes, i.e.,
latitude, longitude, place name, and street address.
<br />Distance metrics were calculated for these attributes and fed to tree-based
classifiers. POI-restaurant matching was conducted separately for Singapore,
Philippines, Indonesia, and Malaysia. Experimental estimates demonstrate that a
matching POI can be found for over 35% of restaurants in these countries. As
part of these estimates, test datasets were manually created, and RandomForest,
AdaBoost, Gradient Boosting, and XGBoost perform well, with most accuracy,
precision, and recall scores close to or higher than 90% for matched vs.
unmatched classification. To the authors' knowledge, there are no previous
published scientific papers devoted to matching of spatial entities for the
Southeast Asia region.
</p>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08539" title="Abstract">arXiv:2401.08539</a> [<a href="/pdf/2401.08539" title="Download PDF">pdf</a>, <a href="/format/2401.08539" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mapping low-resolution edges to high-resolution paths: the case of  traffic measurements in cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Legay%2C+B">Bastien Legay</a>, 
<a href="/search/cs?searchtype=author&query=Latapy%2C+M">Matthieu Latapy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We consider the following problem : we have a high-resolution street network
of a given city, and low-resolution measurements of traffic within this city.
We want to associate to each measurement the set of streets corresponding to
the observed traffic. To do so, we take benefit of specific properties of these
data to match measured links to links in the street network. We propose several
success criteria for the obtained matching. They show that the matching
algorithm generally performs very well, and they give complementary ways to
detect data discrepancies that makes any matching highly dubious.
</p>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08541" title="Abstract">arXiv:2401.08541</a> [<a href="/pdf/2401.08541" title="Download PDF">pdf</a>, <a href="/format/2401.08541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Pre-training of Large Autoregressive Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Nouby%2C+A">Alaaeldin El-Nouby</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+M">Michal Klein</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+S">Shuangfei Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Bautista%2C+M+A">Miguel Angel Bautista</a>, 
<a href="/search/cs?searchtype=author&query=Toshev%2C+A">Alexander Toshev</a>, 
<a href="/search/cs?searchtype=author&query=Shankar%2C+V">Vaishaal Shankar</a>, 
<a href="/search/cs?searchtype=author&query=Susskind%2C+J+M">Joshua M Susskind</a>, 
<a href="/search/cs?searchtype=author&query=Joulin%2C+A">Armand Joulin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/apple/ml-aim">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces AIM, a collection of vision models pre-trained with an
autoregressive objective. These models are inspired by their textual
counterparts, i.e., Large Language Models (LLMs), and exhibit similar scaling
properties. Specifically, we highlight two key findings: (1) the performance of
the visual features scale with both the model capacity and the quantity of
data, (2) the value of the objective function correlates with the performance
of the model on downstream tasks. We illustrate the practical implication of
these findings by pre-training a 7 billion parameter AIM on 2 billion images,
that achieves 84.0% on ImageNet-1k with a frozen trunk. Interestingly, even at
this scale, we observe no sign of saturation in performance, suggesting that
AIM potentially represents a new frontier for training large-scale vision
models. The pre-training of AIM is similar to the pre-training of LLMs, and
does not require any image-specific strategy to stabilize the training at
scale.
</p>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08544" title="Abstract">arXiv:2401.08544</a> [<a href="/pdf/2401.08544" title="Download PDF">pdf</a>, <a href="/ps/2401.08544" title="Download PostScript">ps</a>, <a href="/format/2401.08544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> N-Adaptive Ritz Method: A Neural Network Enriched Partition of Unity for  Boundary Value Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baek%2C+J">Jonghyuk Baek</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yanran Wang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+J+S">J. S. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 66 pages, 41 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Conventional finite element methods are known to be tedious in adaptive
refinements due to their conformal regularity requirements. Further, the
enrichment functions for adaptive refinements are often not readily available
in general applications. This work introduces a novel neural network-enriched
Partition of Unity (NN-PU) approach for solving boundary value problems via
artificial neural networks with a potential energy-based loss function
minimization. The flexibility and adaptivity of the NN function space are
utilized to capture complex solution patterns that the conventional Galerkin
methods fail to capture. The NN enrichment is constructed by combining
pre-trained feature-encoded NN blocks with an additional untrained NN block.
The pre-trained NN blocks learn specific local features during the offline
stage, enabling efficient enrichment of the approximation space during the
online stage through the Ritz-type energy minimization. The NN enrichment is
introduced under the Partition of Unity (PU) framework, ensuring convergence of
the proposed method. The proposed NN-PU approximation and feature-encoded
transfer learning forms an adaptive approximation framework, termed the
neural-refinement (n-refinement), for solving boundary value problems.
Demonstrated by solving various elasticity problems, the proposed method offers
accurate solutions while notably reducing the computational cost compared to
the conventional adaptive refinement in the mesh-based methods.
</p>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08552" title="Abstract">arXiv:2401.08552</a> [<a href="/pdf/2401.08552" title="Download PDF">pdf</a>, <a href="/format/2401.08552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Time Series via Contrastive and Locally Sparse Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingying Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zefan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongsheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lunting Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Q">Qingsong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Explaining multivariate time series is a compound challenge, as it requires
identifying important locations in the time series and matching complex
temporal patterns. Although previous saliency-based methods addressed the
challenges, their perturbation may not alleviate the distribution shift issue,
which is inevitable especially in heterogeneous samples. We present ContraLSP,
a locally sparse model that introduces counterfactual samples to build
uninformative perturbations but keeps distribution using contrastive learning.
Furthermore, we incorporate sample-specific sparse gates to generate more
binary-skewed and smooth masks, which easily integrate temporal trends and
select the salient features parsimoniously. Empirical studies on both synthetic
and real-world datasets show that ContraLSP outperforms state-of-the-art
models, demonstrating a substantial improvement in explanation quality for time
series data. The code is available for review:
https://anonymous.4open.science/r/ContraLSP-1146/
</p>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08553" title="Abstract">arXiv:2401.08553</a> [<a href="/pdf/2401.08553" title="Download PDF">pdf</a>, <a href="/format/2401.08553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FMB: a Functional Manipulation Benchmark for Generalizable Robotic  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Liam Tan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zipeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jeffrey Wu</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a real-world benchmark for studying robotic
learning in the context of functional manipulation: a robot needs to accomplish
complex long-horizon behaviors by composing individual manipulation skills in
functionally relevant ways. The core design principles of our Functional
Manipulation Benchmark (FMB) emphasize a harmonious balance between complexity
and accessibility. Tasks are deliberately scoped to be narrow, ensuring that
models and datasets of manageable scale can be utilized effectively to track
progress. Simultaneously, they are diverse enough to pose a significant
generalization challenge. Furthermore, the benchmark is designed to be easily
replicable, encompassing all essential hardware and software components. To
achieve this goal, FMB consists of a variety of 3D-printed objects designed for
easy and accurate replication by other researchers. The objects are
procedurally generated, providing a principled framework to study
generalization in a controlled fashion. We focus on fundamental manipulation
skills, including grasping, repositioning, and a range of assembly behaviors.
The FMB can be used to evaluate methods for acquiring individual skills, as
well as methods for combining and ordering such skills to solve complex,
multi-stage manipulation tasks. We also offer an imitation learning framework
that includes a suite of policies trained to solve the proposed tasks. This
enables researchers to utilize our tasks as a versatile toolkit for examining
various parts of the pipeline. For example, researchers could propose a better
design for a grasping controller and evaluate it in combination with our
baseline reorientation and assembly policies as part of a pipeline for solving
multi-stage tasks. Our dataset, object CAD files, code, and evaluation videos
can be found on our project website:
https://functional-manipulation-benchmark.github.io
</p>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08556" title="Abstract">arXiv:2401.08556</a> [<a href="/pdf/2401.08556" title="Download PDF">pdf</a>, <a href="/format/2401.08556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimentally implemented dynamic optogenetic optimization of ATPase  expression using knowledge-based and Gaussian-process-supported models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Espinel-R%C3%ADos%2C+S">Sebasti&#xe1;n Espinel-R&#xed;os</a>, 
<a href="/search/eess?searchtype=author&query=Behrendt%2C+G">Gerrich Behrendt</a>, 
<a href="/search/eess?searchtype=author&query=Bauer%2C+J">Jasmin Bauer</a>, 
<a href="/search/eess?searchtype=author&query=Morabito%2C+B">Bruno Morabito</a>, 
<a href="/search/eess?searchtype=author&query=Pohlodek%2C+J">Johannes Pohlodek</a>, 
<a href="/search/eess?searchtype=author&query=Sch%C3%BCtze%2C+A">Andrea Sch&#xfc;tze</a>, 
<a href="/search/eess?searchtype=author&query=Findeisen%2C+R">Rolf Findeisen</a>, 
<a href="/search/eess?searchtype=author&query=Bettenbrock%2C+K">Katja Bettenbrock</a>, 
<a href="/search/eess?searchtype=author&query=Klamt%2C+S">Steffen Klamt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures, journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Optogenetic modulation of adenosine triphosphatase (ATPase) expression
represents a novel approach to maximize the efficiency of bioprocesses by
leveraging the concept of enforced adenosine triphosphate (ATP) turnover. In
this study, we experimentally implement a model-based open-loop optimization
scheme for optogenetic modulation of the expression of the ATPase. Increasing
the intracellular concentration of ATPase, and thus the level of ATP turnover,
in bioprocesses with product synthesis coupled with ATP generation, can lead to
an increase in product formation and substrate uptake. Previous simulation
studies involved formulating optimal control problems using dynamic
constraint-based models to find optimal light inputs in fermentations with
optogenetically mediated ATPase expression. However, using these models poses
challenges due to resulting bilevel optimization problems and complex
parameterization. Here, we outline a simplified unsegregated and
quasi-unstructured kinetic modeling approach that reduces the number of dynamic
states and leads to single-level optimization problems. The proposed models can
be augmented with Gaussian processes to compensate for model uncertainties. We
show the use of optimal control constrained by knowledge-based and hybrid
models in the context of optogenetic ATPase expression in $\textit{Escherichia
coli}$ with lactate as the main fermentation product. To do so, we genetically
engineer $\textit{E. coli}$ to obtain optogenetic expression of ATPase using
the CcaS/CcaR system. This work represents the first experimental
implementation of model-based optimization to dynamically modulate ATPase
expression in bioprocesses.
</p>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08558" title="Abstract">arXiv:2401.08558</a> [<a href="/pdf/2401.08558" title="Download PDF">pdf</a>, <a href="/format/2401.08558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Mission-Level Path Planning for Exploration of Lunar Shadowed  Regions by a Solar-Powered Rover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamarre%2C+O">Olivier Lamarre</a>, 
<a href="/search/cs?searchtype=author&query=Malhotra%2C+S">Shantanu Malhotra</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+J">Jonathan Kelly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the IEEE Aerospace Conference (AERO'24), Big Sky, Montana, March 2-9, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Exploration of the lunar south pole with a solar-powered rover is challenging
due to the highly dynamic solar illumination conditions and the presence of
permanently shadowed regions (PSRs). In turn, careful planning in space and
time is essential. Mission-level path planning is a global, spatiotemporal
paradigm that addresses this challenge, taking into account rover resources and
mission requirements. However, existing approaches do not proactively account
for random disturbances, such as recurring faults, that may temporarily delay
rover traverse progress. In this paper, we formulate a chance-constrained
mission-level planning problem for the exploration of PSRs by a solar-powered
rover affected by random faults. The objective is to find a policy that visits
as many waypoints of scientific interest as possible while respecting an upper
bound on the probability of mission failure.
<br />Our approach assumes that faults occur randomly, but at a known, constant
average rate. Each fault is resolved within a fixed time, simulating the
recovery period of an autonomous system or the time required for a team of
human operators to intervene. Unlike solutions based upon dynamic programming
alone, our method breaks the chance-constrained optimization problem into
smaller offline and online subtasks to make the problem computationally
tractable. Specifically, our solution combines existing mission-level path
planning techniques with a stochastic reachability analysis component. We find
mission plans that remain within reach of safety throughout large state spaces.
To empirically validate our algorithm, we simulate mission scenarios using
orbital terrain and illumination maps of Cabeus Crater. Results from
simulations of multi-day, long-range drives in the LCROSS impact region are
also presented.
</p>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08559" title="Abstract">arXiv:2401.08559</a> [<a href="/pdf/2401.08559" title="Download PDF">pdf</a>, <a href="/format/2401.08559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Track Timeline Control for Text-Driven 3D Human Motion Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Petrovich%2C+M">Mathis Petrovich</a>, 
<a href="/search/cs?searchtype=author&query=Litany%2C+O">Or Litany</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>, 
<a href="/search/cs?searchtype=author&query=Varol%2C+G">G&#xfc;l Varol</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X+B">Xue Bin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Rempe%2C+D">Davis Rempe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://mathis.petrovich.fr/stmc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advances in generative modeling have led to promising progress on
synthesizing 3D human motion from text, with methods that can generate
character animations from short prompts and specified durations. However, using
a single text prompt as input lacks the fine-grained control needed by
animators, such as composing multiple actions and defining precise durations
for parts of the motion. To address this, we introduce the new problem of
timeline control for text-driven motion synthesis, which provides an intuitive,
yet fine-grained, input interface for users. Instead of a single prompt, users
can specify a multi-track timeline of multiple prompts organized in temporal
intervals that may overlap. This enables specifying the exact timings of each
action and composing multiple actions in sequence or at overlapping intervals.
To generate composite animations from a multi-track timeline, we propose a new
test-time denoising method. This method can be integrated with any pre-trained
motion diffusion model to synthesize realistic motions that accurately reflect
the timeline. At every step of denoising, our method processes each timeline
interval (text prompt) individually, subsequently aggregating the predictions
with consideration for the specific body parts engaged in each action.
Experimental comparisons and ablations validate that our method produces
realistic motions that respect the semantics and timing of given text prompts.
Our code and models are publicly available at https://mathis.petrovich.fr/stmc.
</p>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08561" title="Abstract">arXiv:2401.08561</a> [<a href="/pdf/2401.08561" title="Download PDF">pdf</a>, <a href="/format/2401.08561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PlayMyData: a curated dataset of multi-platform video games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%27Angelo%2C+A">Andrea D&#x27;Angelo</a>, 
<a href="/search/cs?searchtype=author&query=Di+Sipio%2C+C">Claudio Di Sipio</a>, 
<a href="/search/cs?searchtype=author&query=Politowsky%2C+C">Cristiano Politowsky</a>, 
<a href="/search/cs?searchtype=author&query=Rubei%2C+R">Riccardo Rubei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the The 21st Mining Software Repositories (MSR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Being predominant in digital entertainment for decades, video games have been
recognized as valuable software artifacts by the software engineering (SE)
community just recently. Such an acknowledgment has unveiled several research
opportunities, spanning from empirical studies to the application of AI
techniques for classification tasks. In this respect, several curated game
datasets have been disclosed for research purposes even though the collected
data are insufficient to support the application of advanced models or to
enable interdisciplinary studies. Moreover, the majority of those are limited
to PC games, thus excluding notorious gaming platforms, e.g., PlayStation,
Xbox, and Nintendo. In this paper, we propose PlayMyData, a curated dataset
composed of 99,864 multi-platform games gathered by IGDB website. By exploiting
a dedicated API, we collect relevant metadata for each game, e.g., description,
genre, rating, gameplay video URLs, and screenshots. Furthermore, we enrich
PlayMyData with the timing needed to complete each game by mining the HLTB
website. To the best of our knowledge, this is the most comprehensive dataset
in the domain that can be used to support different automated tasks in SE. More
importantly, PlayMyData can be used to foster cross-domain investigations built
on top of the provided multimedia data.
</p>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08564" title="Abstract">arXiv:2401.08564</a> [<a href="/pdf/2401.08564" title="Download PDF">pdf</a>, <a href="/format/2401.08564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADVENT: Attack/Anomaly Detection in VANETs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharlouei%2C+H">Hamideh Baharlouei</a>, 
<a href="/search/cs?searchtype=author&query=Makanju%2C+A">Adetokunbo Makanju</a>, 
<a href="/search/cs?searchtype=author&query=Zincir-Heywood%2C+N">Nur Zincir-Heywood</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the domain of Vehicular Ad hoc Networks (VANETs), where the imperative of
having a real-world malicious detector capable of detecting attacks in
real-time and unveiling their perpetrators is crucial, our study introduces a
system with this goal. This system is designed for real-time detection of
malicious behavior, addressing the critical need to first identify the onset of
attacks and subsequently the responsible actors. Prior work in this area have
never addressed both requirements, which we believe are necessary for real
world deployment, simultaneously. By seamlessly integrating statistical and
machine learning techniques, the proposed system prioritizes simplicity and
efficiency. It excels in swiftly detecting attack onsets with a remarkable
F1-score of 99.66%, subsequently identifying malicious vehicles with an average
F1-score of approximately 97.85%. Incorporating federated learning in both
stages enhances privacy and improves the efficiency of malicious node
detection, effectively reducing the false negative rate.
</p>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08565" title="Abstract">arXiv:2401.08565</a> [<a href="/pdf/2401.08565" title="Download PDF">pdf</a>, <a href="/format/2401.08565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning Language Models by Proxy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alisa Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaochuang Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yizhong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkov%2C+Y">Yulia Tsvetkov</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+Y">Yejin Choi</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+N+A">Noah A. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Despite the general capabilities of large pretrained language models, they
consistently benefit from further adaptation to better achieve desired
behaviors. However, tuning these models has become increasingly
resource-intensive, or impossible when model weights are private. We introduce
proxy-tuning, a lightweight decoding-time algorithm that operates on top of
black-box LMs to achieve the result of directly tuning the model, but by
accessing only its prediction over the output vocabulary. Our method instead
tunes a smaller LM, then applies the difference between the predictions of the
small tuned and untuned LMs to shift the original predictions of the base model
in the direction of tuning, while retaining the benefits of larger scale
pretraining. In experiments, when we apply proxy-tuning to Llama2-70B using
proxies of only 7B size, we can close 88% of the gap between Llama2-70B and its
truly-tuned chat version, when evaluated across knowledge, reasoning, and
safety benchmarks. Interestingly, when tested on TruthfulQA, proxy-tuned models
are actually more truthful than directly tuned models, possibly because
decoding-time guidance better retains the model's factual knowledge. We then
demonstrate the generality of proxy-tuning by applying it for domain adaptation
on code, and task-specific finetuning on question-answering and math problems.
Our work demonstrates the promise of using small tuned LMs to efficiently
customize large, potentially proprietary LMs through decoding-time guidance.
</p>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08567" title="Abstract">arXiv:2401.08567</a> [<a href="/pdf/2401.08567" title="Download PDF">pdf</a>, <a href="/format/2401.08567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+E">Elaine Sui</a>, 
<a href="/search/cs?searchtype=author&query=Yeung-Levy%2C+S">Serena Yeung-Levy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Building cross-modal applications is challenging due to limited paired
multi-modal data. Recent works have shown that leveraging a pre-trained
multi-modal contrastive representation space enables cross-modal tasks to be
learned from uni-modal data. This is based on the assumption that contrastive
optimization makes embeddings from different modalities interchangeable.
However, this assumption is under-explored due to the poorly understood
geometry of the multi-modal contrastive space, where a modality gap exists. In
our study, we provide a theoretical explanation of this space's geometry and
introduce a three-step method, $C^3$ (Connect, Collapse, Corrupt), to bridge
the modality gap, enhancing the interchangeability of embeddings. Our $C^3$
method significantly improves cross-modal learning from uni-modal data,
achieving state-of-the-art results on zero-shot image / audio / video
captioning and text-to-image generation.
</p>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08570" title="Abstract">arXiv:2401.08570</a> [<a href="/pdf/2401.08570" title="Download PDF">pdf</a>, <a href="/format/2401.08570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoHM: Robust Human Motion Reconstruction via Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+B+L">Bharat Lal Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanlu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Winkler%2C+A">Alexander Winkler</a>, 
<a href="/search/cs?searchtype=author&query=Kadlecek%2C+P">Petr Kadlecek</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Siyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Bogo%2C+F">Federica Bogo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> With the appendix included
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose RoHM, an approach for robust 3D human motion reconstruction from
monocular RGB(-D) videos in the presence of noise and occlusions. Most previous
approaches either train neural networks to directly regress motion in 3D or
learn data-driven motion priors and combine them with optimization at test
time. The former do not recover globally coherent motion and fail under
occlusions; the latter are time-consuming, prone to local minima, and require
manual tuning. To overcome these shortcomings, we exploit the iterative,
denoising nature of diffusion models. RoHM is a novel diffusion-based motion
model that, conditioned on noisy and occluded input data, reconstructs
complete, plausible motions in consistent global coordinates. Given the
complexity of the problem -- requiring one to address different tasks
(denoising and infilling) in different solution spaces (local and global
motion) -- we decompose it into two sub-tasks and learn two models, one for
global trajectory and one for local motion. To capture the correlations between
the two, we then introduce a novel conditioning module, combining it with an
iterative inference scheme. We apply RoHM to a variety of tasks -- from motion
reconstruction and denoising to spatial and temporal infilling. Extensive
experiments on three popular datasets show that our method outperforms
state-of-the-art approaches qualitatively and quantitatively, while being
faster at test time. The code will be available at
https://sanweiliti.github.io/ROHM/ROHM.html.
</p>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08572" title="Abstract">arXiv:2401.08572</a> [<a href="/pdf/2401.08572" title="Download PDF">pdf</a>, <a href="/format/2401.08572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The illusion of artificial inclusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agnew%2C+W">William Agnew</a>, 
<a href="/search/cs?searchtype=author&query=Bergman%2C+A+S">A. Stevie Bergman</a>, 
<a href="/search/cs?searchtype=author&query=Chien%2C+J">Jennifer Chien</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+M">Mark D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=El-Sayed%2C+S">Seliem El-Sayed</a>, 
<a href="/search/cs?searchtype=author&query=Pittman%2C+J">Jaylen Pittman</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+S">Shakir Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=McKee%2C+K+R">Kevin R. McKee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Human participants play a central role in the development of modern
artificial intelligence (AI) technology, in psychological science, and in user
research. Recent advances in generative AI have attracted growing interest to
the possibility of replacing human participants in these domains with AI
surrogates. We survey several such "substitution proposals" to better
understand the arguments for and against substituting human participants with
modern generative AI. Our scoping review indicates that the recent wave of
these proposals is motivated by goals such as reducing the costs of research
and development work and increasing the diversity of collected data. However,
these proposals ignore and ultimately conflict with foundational values of work
with human participants: representation, inclusion, and understanding. This
paper critically examines the principles and goals underlying human
participation to help chart out paths for future work that truly centers and
empowers participants.
</p>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08573" title="Abstract">arXiv:2401.08573</a> [<a href="/pdf/2401.08573" title="Download PDF">pdf</a>, <a href="/format/2401.08573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking the Robustness of Image Watermarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+B">Bang An</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mucong Ding</a>, 
<a href="/search/cs?searchtype=author&query=Rabbani%2C+T">Tahseen Rabbani</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Aakriti Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuancheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chenghao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Sicheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Abdirisak Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuxin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+T">Tom Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper investigates the weaknesses of image watermarking techniques. We
present WAVES (Watermark Analysis Via Enhanced Stress-testing), a novel
benchmark for assessing watermark robustness, overcoming the limitations of
current evaluation methods.WAVES integrates detection and identification tasks,
and establishes a standardized evaluation protocol comprised of a diverse range
of stress tests. The attacks in WAVES range from traditional image distortions
to advanced and novel variations of adversarial, diffusive, and embedding-based
attacks. We introduce a normalized score of attack potency which incorporates
several widely used image quality metrics and allows us to produce of an
ordered ranking of attacks. Our comprehensive evaluation over reveals
previously undetected vulnerabilities of several modern watermarking
algorithms. WAVES is envisioned as a toolkit for the future development of
robust watermarking systems.
</p>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08574" title="Abstract">arXiv:2401.08574</a> [<a href="/pdf/2401.08574" title="Download PDF">pdf</a>, <a href="/format/2401.08574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deductive Closure Training of Language Models for Coherence, Accuracy,  and Updatability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aky%C3%BCrek%2C+A+F">Afra Feyza Aky&#xfc;rek</a>, 
<a href="/search/cs?searchtype=author&query=Aky%C3%BCrek%2C+E">Ekin Aky&#xfc;rek</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+D">Derry Wijaya</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While language models (LMs) can sometimes generate factually correct text and
estimate truth values of individual claims, these generally do not reflect a
globally coherent, manipulable model of the world. As a consequence, current
LMs also generate incorrect or nonsensical content, and are difficult to edit
and bring up to date. We present a method called Deductive Closure Training
(DCT) that uses LMs themselves to identify implications of (and contradictions
within) the text that they generate, yielding an efficient self-supervised
procedure for improving LM factuality. Given a collection of seed documents,
DCT prompts LMs to generate additional text implied by these documents, reason
globally about the correctness of this generated text, and finally fine-tune on
text inferred to be correct. Given seed documents from a trusted source, DCT
provides a tool for supervised model updating; if seed documents are sampled
from the LM itself, DCT enables fully unsupervised fine-tuning for improved
coherence and accuracy. Across the CREAK, MQUaKE, and Reversal Curse datasets,
supervised DCT improves LM fact verification and text generation accuracy by
3-26%; on CREAK fully unsupervised DCT improves verification accuracy by 12%.
These results show that LMs' reasoning capabilities during inference can be
leveraged during training to improve their reliability.
</p>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08577" title="Abstract">arXiv:2401.08577</a> [<a href="/pdf/2401.08577" title="Download PDF">pdf</a>, <a href="/format/2401.08577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in  3D World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yining Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zishuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Peihao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://vis-www.cs.umass.edu/multiply">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Human beings possess the capability to multiply a melange of multisensory
cues while actively exploring and interacting with the 3D world. Current
multi-modal large language models, however, passively absorb sensory data as
inputs, lacking the capacity to actively interact with the objects in the 3D
environment and dynamically collect their multisensory information. To usher in
the study of this area, we propose MultiPLY, a multisensory embodied large
language model that could incorporate multisensory interactive data, including
visual, audio, tactile, and thermal information into large language models,
thereby establishing the correlation among words, actions, and percepts. To
this end, we first collect Multisensory Universe, a large-scale multisensory
interaction dataset comprising 500k data by deploying an LLM-powered embodied
agent to engage with the 3D environment. To perform instruction tuning with
pre-trained LLM on such generated data, we first encode the 3D scene as
abstracted object-centric representations and then introduce action tokens
denoting that the embodied agent takes certain actions within the environment,
as well as state tokens that represent the multisensory state observations of
the agent at each time step. In the inference time, MultiPLY could generate
action tokens, instructing the agent to take the action in the environment and
obtain the next multisensory state observation. The observation is then
appended back to the LLM via state tokens to generate subsequent text or action
tokens. We demonstrate that MultiPLY outperforms baselines by a large margin
through a diverse set of embodied tasks involving object retrieval, tool use,
multisensory captioning, and task decomposition.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 17 Jan 24</h3>
<dl>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17816" title="Abstract">arXiv:2311.17816</a> (cross-list from hep-lat) [<a href="/pdf/2311.17816" title="Download PDF">pdf</a>, <a href="/format/2311.17816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed point actions from convolutional neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Holland%2C+K">Kieran Holland</a>, 
<a href="/search/hep-lat?searchtype=author&query=Ipp%2C+A">Andreas Ipp</a>, 
<a href="/search/hep-lat?searchtype=author&query=M%C3%BCller%2C+D+I">David I. M&#xfc;ller</a>, 
<a href="/search/hep-lat?searchtype=author&query=Wenger%2C+U">Urs Wenger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures; Proceedings of the 40th International Symposium on Lattice Field Theory (Lattice 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Lattice gauge-equivariant convolutional neural networks (L-CNNs) can be used
to form arbitrarily shaped Wilson loops and can approximate any gauge-covariant
or gauge-invariant function on the lattice. Here we use L-CNNs to describe
fixed point (FP) actions which are based on renormalization group
transformations. FP actions are classically perfect, i.e., they have no lattice
artifacts on classical gauge-field configurations satisfying the equations of
motion, and therefore possess scale invariant instanton solutions. FP actions
are tree-level Symanzik-improved to all orders in the lattice spacing and can
produce physical predictions with very small lattice artifacts even on coarse
lattices. We find that L-CNNs are much more accurate at parametrizing the FP
action compared to older approaches. They may therefore provide a way to
circumvent critical slowing down and topological freezing towards the continuum
limit.
</p>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06481" title="Abstract">arXiv:2401.06481</a> (cross-list from hep-lat) [<a href="/pdf/2401.06481" title="Download PDF">pdf</a>, <a href="/format/2401.06481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning a fixed point action for SU(3) gauge theory with a  gauge equivariant convolutional neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-lat?searchtype=author&query=Holland%2C+K">Kieran Holland</a>, 
<a href="/search/hep-lat?searchtype=author&query=Ipp%2C+A">Andreas Ipp</a>, 
<a href="/search/hep-lat?searchtype=author&query=M%C3%BCller%2C+D+I">David I. M&#xfc;ller</a>, 
<a href="/search/hep-lat?searchtype=author&query=Wenger%2C+U">Urs Wenger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 15 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Lattice (hep-lat)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Fixed point lattice actions are designed to have continuum classical
properties unaffected by discretization effects and reduced lattice artifacts
at the quantum level. They provide a possible way to extract continuum physics
with coarser lattices, thereby allowing to circumvent problems with critical
slowing down and topological freezing toward the continuum limit. A crucial
ingredient for practical applications is to find an accurate and compact
parametrization of a fixed point action, since many of its properties are only
implicitly defined. Here we use machine learning methods to revisit the
question of how to parametrize fixed point actions. In particular, we obtain a
fixed point action for four-dimensional SU(3) gauge theory using convolutional
neural networks with exact gauge invariance. The large operator space allows us
to find superior parametrizations compared to previous studies, a necessary
first step for future Monte Carlo simulations.
</p>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06740" title="Abstract">arXiv:2401.06740</a> (cross-list from q-fin.CP) [<a href="/pdf/2401.06740" title="Download PDF">pdf</a>, <a href="/format/2401.06740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A deep implicit-explicit minimizing movement method for option pricing  in jump-diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Georgoulis%2C+E+H">Emmanuil H. Georgoulis</a>, 
<a href="/search/q-fin?searchtype=author&query=Papapantoleon%2C+A">Antonis Papapantoleon</a>, 
<a href="/search/q-fin?searchtype=author&query=Smaragdakis%2C+C">Costas Smaragdakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">We develop a novel deep learning approach for pricing European basket options
written on assets that follow jump-diffusion dynamics. The option pricing
problem is formulated as a partial integro-differential equation, which is
approximated via a new implicit-explicit minimizing movement time-stepping
approach, involving approximation by deep, residual-type Artificial Neural
Networks (ANNs) for each time step. The integral operator is discretized via
two different approaches: a) a sparse-grid Gauss--Hermite approximation
following localised coordinate axes arising from singular value decompositions,
and b) an ANN-based high-dimensional special-purpose quadrature rule.
Crucially, the proposed ANN is constructed to ensure the asymptotic behavior of
the solution for large values of the underlyings and also leads to consistent
outputs with respect to a priori known qualitative properties of the solution.
The performance and robustness with respect to the dimension of the methods are
assessed in a series of numerical experiments involving the Merton
jump-diffusion model.
</p>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06771" title="Abstract">arXiv:2401.06771</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.06771" title="Download PDF">pdf</a>, <a href="/ps/2401.06771" title="Download PostScript">ps</a>, <a href="/format/2401.06771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curiosity as a Self-Supervised Method to Improve Exploration in De novo  Drug Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chadi%2C+M">Mohamed-Amine Chadi</a>, 
<a href="/search/q-bio?searchtype=author&query=Mousannif%2C+H">Hajar Mousannif</a>, 
<a href="/search/q-bio?searchtype=author&query=Aamouche%2C+A">Ahmed Aamouche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biomolecules (q-bio.BM)

</div>
<p class="mathjax">In recent years, deep learning has demonstrated promising results in de novo
drug design. However, the proposed techniques still lack an efficient
exploration of the large chemical space. Most of these methods explore a small
fragment of the chemical space of known drugs, if the desired molecules were
not found, the process ends. In this work, we introduce a curiosity-driven
method to force the model to navigate many parts of the chemical space,
therefore, achieving higher desirability and diversity as well. At first, we
train a recurrent neural network-based general molecular generator (G), then we
fine-tune G to maximize curiosity and desirability. We define curiosity as the
Tanimoto similarity between two generated molecules, a first molecule generated
by G, and a second one generated by a copy of G (Gcopy). We only backpropagate
the loss through G while keeping Gcopy unchanged. We benchmarked our approach
against two desirable chemical properties related to drug-likeness and showed
that the discovered chemical space can be significantly expanded, thus,
discovering a higher number of desirable molecules with more diversity and
potentially easier to synthesize. All Code and data used in this paper are
available at https://github.com/amine179/Curiosity-RL-for-Drug-Design.
</p>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06777" title="Abstract">arXiv:2401.06777</a> (cross-list from eess.IV) [<a href="/pdf/2401.06777" title="Download PDF">pdf</a>, <a href="/format/2401.06777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Neuroimaging Attention-Based architecture for Cognitive  Decline Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vo%2C+J">Jamie Vo</a>, 
<a href="/search/eess?searchtype=author&query=Sharif%2C+N">Naeha Sharif</a>, 
<a href="/search/eess?searchtype=author&query=Hassan%2C+G+M">Ghulam Mubashar Hassan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The early detection of Alzheimer's Disease is imperative to ensure early
treatment and improve patient outcomes. There has consequently been extenstive
research into detecting AD and its intermediate phase, mild cognitive
impairment (MCI). However, there is very small literature in predicting the
conversion to AD and MCI from normal cognitive condition. Recently, multiple
studies have applied convolutional neural networks (CNN) which integrate
Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) to
classify MCI and AD. However, in these works, the fusion of MRI and PET
features are simply achieved through concatenation, resulting in a lack of
cross-modal interactions. In this paper, we propose a novel multimodal
neuroimaging attention-based CNN architecture, MNA-net, to predict whether
cognitively normal (CN) individuals will develop MCI or AD within a period of
10 years. To address the lack of interactions across neuroimaging modalities
seen in previous works, MNA-net utilises attention mechanisms to form shared
representations of the MRI and PET images. The proposed MNA-net is tested in
OASIS-3 dataset and is able to predict CN individuals who converted to MCI or
AD with an accuracy of 83%, true negative rate of 80%, and true positive rate
of 86%. The new state of the art results improved by 5% and 10% for accuracy
and true negative rate by the use of attention mechanism. These results
demonstrate the potential of the proposed model to predict cognitive impairment
and attention based mechanisms in the fusion of different neuroimaging
modalities to improve the prediction of cognitive decline.
</p>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06779" title="Abstract">arXiv:2401.06779</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.06779" title="Download PDF">pdf</a>, <a href="/format/2401.06779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VAE for Modified 1-Hot Generative Materials Modeling, A Step Towards  Inverse Material Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=El-Awady%2C+K">Khalid El-Awady</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We investigate the construction of generative models capable of encoding
physical constraints that can be hard to express explicitly. For the problem of
inverse material design, where one seeks to design a material with a prescribed
set of properties, a significant challenge is ensuring synthetic viability of a
proposed new material. We encode an implicit dataset relationships, namely that
certain materials can be decomposed into other ones in the dataset, and present
a VAE model capable of preserving this property in the latent space and
generating new samples with the same. This is particularly useful in sequential
inverse material design, an emergent research area that seeks to design a
material with specific properties by sequentially adding (or removing) elements
using policies trained through deep reinforcement learning.
</p>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06780" title="Abstract">arXiv:2401.06780</a> (cross-list from eess.IV) [<a href="/pdf/2401.06780" title="Download PDF">pdf</a>, <a href="/format/2401.06780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HA-HI: Synergising fMRI and DTI through Hierarchical Alignments and  Hierarchical Interactions for Mild Cognitive Impairment Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shen%2C+X">Xiongri Shen</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhenxi Song</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Linling Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+L+L+H">Lingyan Liang Honghai Liu</a>, 
<a href="/search/eess?searchtype=author&query=Deng%2C+D">Demao Deng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhiguo Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Early diagnosis of mild cognitive impairment (MCI) and subjective cognitive
decline (SCD) utilizing multi-modal magnetic resonance imaging (MRI) is a
pivotal area of research. While various regional and connectivity features from
functional MRI (fMRI) and diffusion tensor imaging (DTI) have been employed to
develop diagnosis models, most studies integrate these features without
adequately addressing their alignment and interactions. This limits the
potential to fully exploit the synergistic contributions of combined features
and modalities. To solve this gap, our study introduces a novel Hierarchical
Alignments and Hierarchical Interactions (HA-HI) method for MCI and SCD
classification, leveraging the combined strengths of fMRI and DTI. HA-HI
efficiently learns significant MCI- or SCD- related regional and connectivity
features by aligning various feature types and hierarchically maximizing their
interactions. Furthermore, to enhance the interpretability of our approach, we
have developed the Synergistic Activation Map (SAM) technique, revealing the
critical brain regions and connections that are indicative of MCI/SCD.
Comprehensive evaluations on the ADNI dataset and our self-collected data
demonstrate that HA-HI outperforms other existing methods in diagnosing MCI and
SCD, making it a potentially vital and interpretable tool for early detection.
The implementation of this method is publicly accessible at
https://github.com/ICI-BCI/Dual-MRI-HA-HI.git.
</p>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06788" title="Abstract">arXiv:2401.06788</a> (cross-list from eess.AS) [<a href="/pdf/2401.06788" title="Download PDF">pdf</a>, <a href="/format/2401.06788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in  CNVSRC 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+P">Pengcheng Guo</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+P">Pan Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">This paper delineates the visual speech recognition (VSR) system introduced
by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech
Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of
Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms
of data processing, we leverage the lip motion extractor from the baseline1 to
produce multi-scale video data. Besides, various augmentation techniques are
applied during training, encompassing speed perturbation, random rotation,
horizontal flipping, and color transformation. The VSR model adopts an
end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D
visual frontend, an E-Branchformer encoder, and a Transformer decoder.
Experiments show that our system achieves 34.76% CER for the Single-Speaker
Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion,
ranking first place in all three tracks we participate.
</p>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06794" title="Abstract">arXiv:2401.06794</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.06794" title="Download PDF">pdf</a>, <a href="/ps/2401.06794" title="Download PostScript">ps</a>, <a href="/format/2401.06794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying the hierarchical scales of scientists&#x27;mobility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Huang%2C+Y">Yurui Huang</a>, 
<a href="/search/physics?searchtype=author&query=Ma%2C+L">Langtian Ma</a>, 
<a href="/search/physics?searchtype=author&query=Tian%2C+C">Chaolin Tian</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+X">Xunyi Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Sinatra%2C+R">Roberta Sinatra</a>, 
<a href="/search/physics?searchtype=author&query=Ma%2C+Y">Yifang Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Digital Libraries (cs.DL)

</div>
<p class="mathjax">Human behaviors, including scientific activities, are shaped by the
hierarchical divisions of geography. As a result, researchers' mobility
patterns vary across regions, influencing several aspects of the scientific
community. These aspects encompass career trajectories, knowledge transfer,
international collaborations, talent circulation, innovation diffusion,
resource distribution, and policy development. However, our understanding of
the relationship between the hierarchical regional scale and scientific
movements is limited. This study aims to understand the subtle role of the
geographical scales on scientists' mobility patterns across cities, countries,
and continents. To this end, we analyzed 2.03 million scientists from 1960 to
2021, spanning institutions, cities, countries, and continents. We built a
model based on hierarchical regions with different administrative levels and
assessed the tendency for mobility from one region to another and the
attractiveness of each region. Our findings reveal distinct nested hierarchies
of regional scales and the dynamic of scientists' relocation patterns. This
study sheds light on the complex dynamics of scientists' mobility and offers
insights into how geographical scale and administrative divisions influence
career decisions.
</p>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06820" title="Abstract">arXiv:2401.06820</a> (cross-list from math.OC) [<a href="/pdf/2401.06820" title="Download PDF">pdf</a>, <a href="/format/2401.06820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QCQP-Net: Reliably Learning Feasible Alternating Current Optimal Power  Flow Solutions Under Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zeng%2C+S">Sihan Zeng</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+Y">Youngdae Kim</a>, 
<a href="/search/math?searchtype=author&query=Ren%2C+Y">Yuxuan Ren</a>, 
<a href="/search/math?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">At the heart of power system operations, alternating current optimal power
flow (ACOPF) studies the generation of electric power in the most economical
way under network-wide load requirement, and can be formulated as a highly
structured non-convex quadratically constrained quadratic program (QCQP).
Optimization-based solutions to ACOPF (such as ADMM or interior-point method),
as the classic approach, require large amount of computation and cannot meet
the need to repeatedly solve the problem as load requirement frequently
changes. On the other hand, learning-based methods that directly predict the
ACOPF solution given the load input incur little computational cost but often
generates infeasible solutions (i.e. violate the constraints of ACOPF). In this
work, we combine the best of both worlds -- we propose an innovated framework
for learning ACOPF, where the input load is mapped to the ACOPF solution
through a neural network in a computationally efficient and reliable manner.
Key to our innovation is a specific-purpose "activation function" defined
implicitly by a QCQP and a novel loss, which enforce constraint satisfaction.
We show through numerical simulations that our proposed method achieves
superior feasibility rate and generation cost in situations where the existing
learning-based approaches fail.
</p>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06822" title="Abstract">arXiv:2401.06822</a> (cross-list from math.OC) [<a href="/pdf/2401.06822" title="Download PDF">pdf</a>, <a href="/ps/2401.06822" title="Download PostScript">ps</a>, <a href="/format/2401.06822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy Mathematical Model For Optimizing Success Criteria Of Projects: A  Project Management Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sammany%2C+M">Mohammad Sammany</a>, 
<a href="/search/math?searchtype=author&query=Steef%2C+A">Ahmad Steef</a>, 
<a href="/search/math?searchtype=author&query=Agami%2C+N">Nedaa Agami</a>, 
<a href="/search/math?searchtype=author&query=Medhat%2C+T">T. Medhat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Multi-Objective Optimization, Project Management, Criteria Optimization, Fuzzy Mathematical Model. International Journal of Scientific Research in Computer Science and Engineering (2020)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">It is well known over the recent years that measuring the success of projects
under the umbrella of project management is inextricably linked with the
associated cost, time, and quality. Most of the previous researches in the
field assigned a separate mathematical model for each criterion, then numerical
methods or search techniques were applied to obtain the optimal trade-off
between the three criteria. However in this paper, the problem was addressed by
linear multi-objective optimization using only one fuzzy mathematical model.
The three criteria were merged in a single non-linear membership function to
find the optimal trade-off. Finally, the proposed model is tested and validated
using numerical examples.
</p>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06823" title="Abstract">arXiv:2401.06823</a> (cross-list from q-bio.GN) [<a href="/pdf/2401.06823" title="Download PDF">pdf</a>, <a href="/format/2401.06823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable deep learning in single-cell omics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wagle%2C+M+M">Manoj M Wagle</a>, 
<a href="/search/q-bio?searchtype=author&query=Long%2C+S">Siqu Long</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+C">Carissa Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Liu%2C+C">Chunlei Liu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yang%2C+P">Pengyi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent developments in single-cell omics technologies have enabled the
quantification of molecular profiles in individual cells at an unparalleled
resolution. Deep learning, a rapidly evolving sub-field of machine learning,
has instilled a significant interest in single-cell omics research due to its
remarkable success in analysing heterogeneous high-dimensional single-cell
omics data. Nevertheless, the inherent multi-layer nonlinear architecture of
deep learning models often makes them `black boxes' as the reasoning behind
predictions is often unknown and not transparent to the user. This has
stimulated an increasing body of research for addressing the lack of
interpretability in deep learning models, especially in single-cell omics data
analyses, where the identification and understanding of molecular regulators
are crucial for interpreting model predictions and directing downstream
experimental validations. In this work, we introduce the basics of single-cell
omics technologies and the concept of interpretable deep learning. This is
followed by a review of the recent interpretable deep learning models applied
to various single-cell omics research. Lastly, we highlight the current
limitations and discuss potential future directions. We anticipate this review
to bring together the single-cell and machine learning research communities to
foster future development and application of interpretable deep learning in
single-cell omics research.
</p>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06834" title="Abstract">arXiv:2401.06834</a> (cross-list from math.OC) [<a href="/pdf/2401.06834" title="Download PDF">pdf</a>, <a href="/format/2401.06834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Discrete Parameters Using the Adaptive Gradient Method  and Directed Evolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beinarovich%2C+A">Andrei Beinarovich</a>, 
<a href="/search/math?searchtype=author&query=Stepanov%2C+S">Sergey Stepanov</a>, 
<a href="/search/math?searchtype=author&query=Zaslavsky%2C+A">Alexander Zaslavsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The problem is considered of optimizing discrete parameters in the presence
of constraints. We use the stochastic sigmoid with temperature and put forward
the new adaptive gradient method CONGA. The search for an optimal solution is
carried out by a population of individuals. Each of them varies according to
gradients of the 'environment' and is characterized by two temperature
parameters with different annealing schedules. Unadapted individuals die, and
optimal ones interbreed, the result is directed evolutionary dynamics. The
proposed method is illustrated using the well-known combinatorial problem for
optimal packing of a backpack (0-1 KP).
</p>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06839" title="Abstract">arXiv:2401.06839</a> (cross-list from astro-ph.EP) [<a href="/pdf/2401.06839" title="Download PDF">pdf</a>, <a href="/format/2401.06839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Stellar Parameters from Iodine-Imprinted Keck/HIRES Spectra  with Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Gussman%2C+J">Jude Gussman</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rice%2C+M">Malena Rice</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, accepted to ApJL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Solar and Stellar Astrophysics (astro-ph.SR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The properties of exoplanet host stars are traditionally characterized
through a detailed forward-modeling analysis of high-resolution spectra.
However, many exoplanet radial velocity surveys employ iodine-cell-calibrated
spectrographs, such that the vast majority of spectra obtained include an
imprinted forest of iodine absorption lines. For surveys that use iodine cells,
iodine-free "template" spectra must be separately obtained for precise stellar
characterization. These template spectra often require extensive additional
observing time to obtain, and they are not always feasible to obtain for faint
stars. In this paper, we demonstrate that machine learning methods can be
applied to infer stellar parameters and chemical abundances from
iodine-imprinted spectra with high accuracy and precision. The methods
presented in this work are broadly applicable to any iodine-cell-calibrated
spectrograph. We make publicly available our spectroscopic pipeline, the Cannon
HIRES Iodine Pipeline (CHIP), which derives stellar parameters and 15 chemical
abundances from iodine-imprinted spectra of FGK stars and which has been set up
for ease of use with Keck/HIRES spectra. Our proof-of-concept offers an
efficient new avenue to rapidly estimate a large number of stellar parameters
even in the absence of an iodine-free template spectrum.
</p>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06859" title="Abstract">arXiv:2401.06859</a> (cross-list from eess.SP) [<a href="/pdf/2401.06859" title="Download PDF">pdf</a>, <a href="/ps/2401.06859" title="Download PostScript">ps</a>, <a href="/format/2401.06859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Power Optimization and AP Selection for Secure Cell-Free Massive  MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Atiya%2C+Y+S">Yasseen Sadoon Atiya</a>, 
<a href="/search/eess?searchtype=author&query=Mobini%2C+Z">Zahra Mobini</a>, 
<a href="/search/eess?searchtype=author&query=Ngo%2C+H+Q">Hien Quoc Ngo</a>, 
<a href="/search/eess?searchtype=author&query=Matthaiou%2C+M">Michail Matthaiou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper will appear at IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we investigate joint power control and access point (AP)
selection scheme in a cell-free massive multiple-input multiple-output
(CF-mMIMO) system under an active eavesdropping attack, where an eavesdropper
tries to overhear the signal sent to one of the legitimate users by
contaminating the uplink channel estimation. We formulate a joint optimization
problem to minimize the eavesdropping spectral efficiency (SE) while
guaranteeing a given SE requirement at legitimate users. The challenging
formulated problem is converted into a more tractable form and an efficient
low-complexity accelerated projected gradient (APG)-based approach is proposed
to solve it. Our findings reveal that the proposed joint optimization approach
significantly outperforms the heuristic approaches in terms of secrecy SE
(SSE). For instance, the $50\%$ likely SSE performance of the proposed approach
is $265\%$ higher than that of equal power allocation and random AP selection
scheme.
</p>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06864" title="Abstract">arXiv:2401.06864</a> (cross-list from stat.ML) [<a href="/pdf/2401.06864" title="Download PDF">pdf</a>, <a href="/format/2401.06864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning With DAGs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Balgi%2C+S">Sourabh Balgi</a>, 
<a href="/search/stat?searchtype=author&query=Daoud%2C+A">Adel Daoud</a>, 
<a href="/search/stat?searchtype=author&query=Pe%C3%B1a%2C+J+M">Jose M. Pe&#xf1;a</a>, 
<a href="/search/stat?searchtype=author&query=Wodtke%2C+G+T">Geoffrey T. Wodtke</a>, 
<a href="/search/stat?searchtype=author&query=Zhou%2C+J">Jesse Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Methodology (stat.ME)

</div>
<p class="mathjax">Social science theories often postulate causal relationships among a set of
variables or events. Although directed acyclic graphs (DAGs) are increasingly
used to represent these theories, their full potential has not yet been
realized in practice. As non-parametric causal models, DAGs require no
assumptions about the functional form of the hypothesized relationships.
Nevertheless, to simplify the task of empirical evaluation, researchers tend to
invoke such assumptions anyway, even though they are typically arbitrary and do
not reflect any theoretical content or prior knowledge. Moreover, functional
form assumptions can engender bias, whenever they fail to accurately capture
the complexity of the causal system under investigation. In this article, we
introduce causal-graphical normalizing flows (cGNFs), a novel approach to
causal inference that leverages deep neural networks to empirically evaluate
theories represented as DAGs. Unlike conventional approaches, cGNFs model the
full joint distribution of the data according to a DAG supplied by the analyst,
without relying on stringent assumptions about functional form. In this way,
the method allows for flexible, semi-parametric estimation of any causal
estimand that can be identified from the DAG, including total effects,
conditional effects, direct and indirect effects, and path-specific effects. We
illustrate the method with a reanalysis of Blau and Duncan's (1967) model of
status attainment and Zhou's (2019) model of conditional versus controlled
mobility. To facilitate adoption, we provide open-source software together with
a series of online tutorials for implementing cGNFs. The article concludes with
a discussion of current limitations and directions for future development.
</p>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06893" title="Abstract">arXiv:2401.06893</a> (cross-list from eess.IV) [<a href="/pdf/2401.06893" title="Download PDF">pdf</a>, <a href="/format/2401.06893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Gamma Augmentation for Ischemic Stroke Lesion Segmentation on MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Middleton%2C+J">Jon Middleton</a>, 
<a href="/search/eess?searchtype=author&query=Bauer%2C+M">Marko Bauer</a>, 
<a href="/search/eess?searchtype=author&query=Sheng%2C+K">Kaining Sheng</a>, 
<a href="/search/eess?searchtype=author&query=Johansen%2C+J">Jacob Johansen</a>, 
<a href="/search/eess?searchtype=author&query=Perslev%2C+M">Mathias Perslev</a>, 
<a href="/search/eess?searchtype=author&query=Ingala%2C+S">Silvia Ingala</a>, 
<a href="/search/eess?searchtype=author&query=Nielsen%2C+M">Mads Nielsen</a>, 
<a href="/search/eess?searchtype=author&query=Pai%2C+A">Akshay Pai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version for Northern Lights Deep Learning Conference 2024, 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The identification and localisation of pathological tissues in medical images
continues to command much attention among deep learning practitioners. When
trained on abundant datasets, deep neural networks can match or exceed human
performance. However, the scarcity of annotated data complicates the training
of these models. Data augmentation techniques can compensate for a lack of
training samples. However, many commonly used augmentation methods can fail to
provide meaningful samples during model fitting. We present local gamma
augmentation, a technique for introducing new instances of intensities in
pathological tissues. We leverage local gamma augmentation to compensate for a
bias in intensities corresponding to ischemic stroke lesions in human brain
MRIs. On three datasets, we show how local gamma augmentation can improve the
image-level sensitivity of a deep neural network tasked with ischemic lesion
segmentation on magnetic resonance images.
</p>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06962" title="Abstract">arXiv:2401.06962</a> (cross-list from math.LO) [<a href="/pdf/2401.06962" title="Download PDF">pdf</a>, <a href="/ps/2401.06962" title="Download PostScript">ps</a>, <a href="/format/2401.06962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowability as continuity: a topological account of informational  dependence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baltag%2C+A">Alexandru Baltag</a>, 
<a href="/search/math?searchtype=author&query=van+Benthem%2C+J">Johan van Benthem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 65 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We study knowable informational dependence between empirical questions,
modeled as continuous functional dependence between variables in a topological
setting. We also investigate epistemic independence in topological terms and
show that it is compatible with functional (but non-continuous) dependence. We
then proceed to study a stronger notion of knowability based on uniformly
continuous dependence. On the technical logical side, we determine the complete
logics of languages that combine general functional dependence, continuous
dependence, and uniformly continuous dependence.
</p>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06967" title="Abstract">arXiv:2401.06967</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.06967" title="Download PDF">pdf</a>, <a href="/ps/2401.06967" title="Download PostScript">ps</a>, <a href="/format/2401.06967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NHANES-GCP: Leveraging the Google Cloud Platform and BigQuery ML for  reproducible machine learning with data from the National Health and  Nutrition Examination Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Katz%2C+B+R">B. Ross Katz</a>, 
<a href="/search/q-bio?searchtype=author&query=Khan%2C+A">Abdul Khan</a>, 
<a href="/search/q-bio?searchtype=author&query=York-Winegar%2C+J">James York-Winegar</a>, 
<a href="/search/q-bio?searchtype=author&query=Titus%2C+A+J">Alexander J. Titus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">Summary: NHANES, the National Health and Nutrition Examination Survey, is a
program of studies led by the Centers for Disease Control and Prevention (CDC)
designed to assess the health and nutritional status of adults and children in
the United States (U.S.). NHANES data is frequently used by biostatisticians
and clinical scientists to study health trends across the U.S., but every
analysis requires extensive data management and cleaning before use and this
repetitive data engineering collectively costs valuable research time and
decreases the reproducibility of analyses. Here, we introduce NHANES-GCP, a
Cloud Development Kit for Terraform (CDKTF) Infrastructure-as-Code (IaC) and
Data Build Tool (dbt) resources built on the Google Cloud Platform (GCP) that
automates the data engineering and management aspects of working with NHANES
data. With current GCP pricing, NHANES-GCP costs less than $2 to run and less
than $15/yr of ongoing costs for hosting the NHANES data, all while providing
researchers with clean data tables that can readily be integrated for
large-scale analyses. We provide examples of leveraging BigQuery ML to carry
out the process of selecting data, integrating data, training machine learning
and statistical models, and generating results all from a single SQL-like
query. NHANES-GCP is designed to enhance the reproducibility of analyses and
create a well-engineered NHANES data resource for statistics, machine learning,
and fine-tuning Large Language Models (LLMs).
<br />Availability and implementation" NHANES-GCP is available at
https://github.com/In-Vivo-Group/NHANES-GCP
</p>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06987" title="Abstract">arXiv:2401.06987</a> (cross-list from q-bio.MN) [<a href="/pdf/2401.06987" title="Download PDF">pdf</a>, <a href="/format/2401.06987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cramer-Rao bound and absolute sensitivity in chemical reaction networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Loutchko%2C+D">Dimitri Loutchko</a>, 
<a href="/search/q-bio?searchtype=author&query=Sughiyama%2C+Y">Yuki Sughiyama</a>, 
<a href="/search/q-bio?searchtype=author&query=Kobayashi%2C+T+J">Tetsuya J. Kobayashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Molecular Networks (q-bio.MN)</span>; Information Theory (cs.IT); Biological Physics (physics.bio-ph); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Chemical reaction networks (CRN) comprise an important class of models to
understand biological functions such as cellular information processing, the
robustness and control of metabolic pathways, circadian rhythms, and many more.
However, any CRN describing a certain function does not act in isolation but is
a part of a much larger network and as such is constantly subject to external
changes. In [Shinar, Alon, and Feinberg. "Sensitivity and robustness in
chemical reaction networks." SIAM J App Math (2009): 977-998.], the responses
of CRN to changes in the linear conserved quantities, called sensitivities,
were studied in and the question of how to construct absolute, i.e.,
basis-independent, sensitivities was raised. In this article, by applying
information geometric methods, such a construction is provided. The idea is to
track how concentration changes in a particular chemical propagate to changes
of all the other chemicals within a steady state. This is encoded in the matrix
of absolute sensitivites. A linear algebraic characterization of the matrix of
absolute sensitivities for quasi-thermostatic CRN is derived via a Cramer-Rao
bound for CRN, which is based on the the analogy between quasi-thermostatic
steady states and the exponential family of probability distributions.
</p>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07010" title="Abstract">arXiv:2401.07010</a> (cross-list from physics.med-ph) [<a href="/pdf/2401.07010" title="Download PDF">pdf</a>, <a href="/ps/2401.07010" title="Download PostScript">ps</a>, <a href="/format/2401.07010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advances in Biomedical Devices_A comprehensive Exploration of  Cardiovascular and Ophthalmic Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=M%2C+S">Shankar M</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> -
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This review article discusses current technological advances in biomedical
devices,emphasizing cardiovascular and ophthalmic application
diagnostic,monitoring, and prosthetic instruments and systems. The scope
encompasses various aspects, including implantable retinal prosthetic devices,
portable device for carotid stiffness measurement, automatic identification
algorithms for arteries, cuffless evaluation of carotid pulse pressure,
wearable neural recording systems, and arterial compliance probes.
Additionally, the paper explores advancements in pulse wave velocity
measurement, real time heart rate estimation from wrist type signals, and the
clinical significance of non invasive pulse wave velocity measurement in
assessing arterial stiffness. The synthesis of these studies provides insights
into the evolving landscape of biomedical devices, their validation,
reproducibility, and potential clinical implications, emphasizing their role in
enhancing diagnostics and therapeutic interventions in cardiovascular and
ophthalmic domains.
</p>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07020" title="Abstract">arXiv:2401.07020</a> (cross-list from eess.IV) [<a href="/pdf/2401.07020" title="Download PDF">pdf</a>, <a href="/ps/2401.07020" title="Download PostScript">ps</a>, <a href="/format/2401.07020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Medical Imaging with Artificial Intelligence: A Review of  Machine Learning Approaches for the Detection, and Segmentation of COVID-19  Using Radiographic and Tomographic Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mobarakeh%2C+S+A+M">Sayed Amir Mousavi Mobarakeh</a>, 
<a href="/search/eess?searchtype=author&query=Kazemi%2C+K">Kamran Kazemi</a>, 
<a href="/search/eess?searchtype=author&query=Aarabi%2C+A">Ardalan Aarabi</a>, 
<a href="/search/eess?searchtype=author&query=Danyal%2C+H">Habibollah Danyal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Since 2019, the global dissemination of the Coronavirus and its novel strains
has resulted in a surge of new infections. The use of X-ray and computed
tomography (CT) imaging techniques is critical in diagnosing and managing
COVID-19. Incorporating artificial intelligence (AI) into the field of medical
imaging is a powerful combination that can provide valuable support to
healthcare professionals.This paper focuses on the methodological approach of
using machine learning (ML) to enhance medical imaging for COVID-19
diagnosis.For example, deep learning can accurately distinguish lesions from
other parts of the lung without human intervention in a matter of
minutes.Moreover, ML can enhance performance efficiency by assisting
radiologists in making more precise clinical decisions, such as detecting and
distinguishing Covid-19 from different respiratory infections and segmenting
infections in CT and X-ray images, even when the lesions have varying sizes and
shapes.This article critically assesses machine learning methodologies utilized
for the segmentation, classification, and detection of Covid-19 within CT and
X-ray images, which are commonly employed tools in clinical and hospital
settings to represent the lung in various aspects and extensive detail.There is
a widespread expectation that this technology will continue to hold a central
position within the healthcare sector, driving further progress in the
management of the pandemic.
</p>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07039" title="Abstract">arXiv:2401.07039</a> (cross-list from quant-ph) [<a href="/pdf/2401.07039" title="Download PDF">pdf</a>, <a href="/format/2401.07039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Generative Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+C">Chuangtao Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+Q">Qinglin Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments are welcome. 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces the Quantum Generative Diffusion Model (QGDM), a fully
quantum-mechanical model for generating quantum state ensembles, inspired by
Denoising Diffusion Probabilistic Models. QGDM features a diffusion process
that introduces timestep-dependent noise into quantum states, paired with a
denoising mechanism trained to reverse this contamination. This model
efficiently evolves a completely mixed state into a target quantum state
post-training. Our comparative analysis with Quantum Generative Adversarial
Networks demonstrates QGDM's superiority, with fidelity metrics exceeding 0.99
in numerical simulations involving up to 4 qubits. Additionally, we present a
Resource-Efficient version of QGDM (RE-QGDM), which minimizes the need for
auxiliary qubits while maintaining impressive generative capabilities for tasks
involving up to 8 qubits. These results showcase the proposed models' potential
for tackling challenging quantum generation problems.
</p>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07041" title="Abstract">arXiv:2401.07041</a> (cross-list from eess.IV) [<a href="/pdf/2401.07041" title="Download PDF">pdf</a>, <a href="/format/2401.07041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An automated framework for brain vessel centerline extraction from CTA  images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Sijie Liu</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Ruisheng Su</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+J">Jianghang Su</a>, 
<a href="/search/eess?searchtype=author&query=Xin%2C+J">Jingmin Xin</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jiayi Wu</a>, 
<a href="/search/eess?searchtype=author&query=van+Zwam%2C+W">Wim van Zwam</a>, 
<a href="/search/eess?searchtype=author&query=van+Doormaal%2C+P+J">Pieter Jan van Doormaal</a>, 
<a href="/search/eess?searchtype=author&query=van+der+Lugt%2C+A">Aad van der Lugt</a>, 
<a href="/search/eess?searchtype=author&query=Niessen%2C+W+J">Wiro J. Niessen</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>, 
<a href="/search/eess?searchtype=author&query=van+Walsum%2C+T">Theo van Walsum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate automated extraction of brain vessel centerlines from CTA images
plays an important role in diagnosis and therapy of cerebrovascular diseases,
such as stroke. However, this task remains challenging due to the complex
cerebrovascular structure, the varying imaging quality, and vessel pathology
effects. In this paper, we consider automatic lumen segmentation generation
without additional annotation effort by physicians and more effective use of
the generated lumen segmentation for improved centerline extraction
performance. We propose an automated framework for brain vessel centerline
extraction from CTA images. The framework consists of four major components:
(1) pre-processing approaches that register CTA images with a CT atlas and
divide these images into input patches, (2) lumen segmentation generation from
annotated vessel centerlines using graph cuts and robust kernel regression, (3)
a dual-branch topology-aware UNet (DTUNet) that can effectively utilize the
annotated vessel centerlines and the generated lumen segmentation through a
topology-aware loss (TAL) and its dual-branch design, and (4) post-processing
approaches that skeletonize the predicted lumen segmentation. Extensive
experiments on a multi-center dataset demonstrate that the proposed framework
outperforms state-of-the-art methods in terms of average symmetric centerline
distance (ASCD) and overlap (OV). Subgroup analyses further suggest that the
proposed framework holds promise in clinical applications for stroke treatment.
Code is publicly available at https://github.com/Liusj-gh/DTUNet.
</p>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07043" title="Abstract">arXiv:2401.07043</a> (cross-list from quant-ph) [<a href="/pdf/2401.07043" title="Download PDF">pdf</a>, <a href="/format/2401.07043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Advantage Actor-Critic for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hgog%2C+M">Mohamad Hgog</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ritz%2C+F">Fabian Ritz</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zorn%2C+M">Maximilian Zorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICAART 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Quantum computing offers efficient encapsulation of high-dimensional states.
In this work, we propose a novel quantum reinforcement learning approach that
combines the Advantage Actor-Critic algorithm with variational quantum circuits
by substituting parts of the classical components. This approach addresses
reinforcement learning's scalability concerns while maintaining high
performance. We empirically test multiple quantum Advantage Actor-Critic
configurations with the well known Cart Pole environment to evaluate our
approach in control tasks with continuous state spaces. Our results indicate
that the hybrid strategy of using either a quantum actor or quantum critic with
classical post-processing yields a substantial performance increase compared to
pure classical and pure quantum variants with similar parameter counts. They
further reveal the limits of current quantum approaches due to the hardware
constraints of noisy intermediate-scale quantum computers, suggesting further
research to scale hybrid approaches for larger and more complex control tasks.
</p>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07049" title="Abstract">arXiv:2401.07049</a> (cross-list from quant-ph) [<a href="/pdf/2401.07049" title="Download PDF">pdf</a>, <a href="/format/2401.07049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Denoising Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stenzel%2C+G">Gerhard Stenzel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zielinski%2C+S">Sebastian Zielinski</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ommer%2C+B">Bj&#xf6;rn Ommer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In recent years, machine learning models like DALL-E, Craiyon, and Stable
Diffusion have gained significant attention for their ability to generate
high-resolution images from concise descriptions. Concurrently, quantum
computing is showing promising advances, especially with quantum machine
learning which capitalizes on quantum mechanics to meet the increasing
computational requirements of traditional machine learning algorithms. This
paper explores the integration of quantum machine learning and variational
quantum circuits to augment the efficacy of diffusion-based image generation
models. Specifically, we address two challenges of classical diffusion models:
their low sampling speed and the extensive parameter requirements. We introduce
two quantum diffusion models and benchmark their capabilities against their
classical counterparts using MNIST digits, Fashion MNIST, and CIFAR-10. Our
models surpass the classical models with similar parameter counts in terms of
performance metrics FID, SSIM, and PSNR. Moreover, we introduce a consistency
model unitary single sampling architecture that combines the diffusion
procedure into a single step, enabling a fast one-step image generation.
</p>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07054" title="Abstract">arXiv:2401.07054</a> (cross-list from quant-ph) [<a href="/pdf/2401.07054" title="Download PDF">pdf</a>, <a href="/format/2401.07054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement Learning Environment for Directed Quantum Circuit  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Schubert%2C+T">Tom Schubert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zorn%2C+M">Maximilian Zorn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With recent advancements in quantum computing technology, optimizing quantum
circuits and ensuring reliable quantum state preparation have become
increasingly vital. Traditional methods often demand extensive expertise and
manual calculations, posing challenges as quantum circuits grow in qubit- and
gate-count. Therefore, harnessing machine learning techniques to handle the
growing variety of gate-to-qubit combinations is a promising approach. In this
work, we introduce a comprehensive reinforcement learning environment for
quantum circuit synthesis, where circuits are constructed utilizing gates from
the the Clifford+T gate set to prepare specific target states. Our experiments
focus on exploring the relationship between the depth of synthesized quantum
circuits and the circuit depths used for target initialization, as well as
qubit count. We organize the environment configurations into multiple
evaluation levels and include a range of well-known quantum states for
benchmarking purposes. We also lay baselines for evaluating the environment
using Proximal Policy Optimization. By applying the trained agents to benchmark
tests, we demonstrated their ability to reliably design minimal quantum
circuits for a selection of 2-qubit Bell states.
</p>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07060" title="Abstract">arXiv:2401.07060</a> (cross-list from cond-mat.soft) [<a href="/pdf/2401.07060" title="Download PDF">pdf</a>, <a href="/format/2401.07060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Biofilms as poroelastic materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Carpio%2C+A">Ana Carpio</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cebrian%2C+E">Elena Cebrian</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vidal%2C+P">Perfecto Vidal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Non-linear Mechanics 109, 1-8, 2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Biological Physics (physics.bio-ph); Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">Biofilms are bacterial aggregates encased in a self-produced polymeric matrix
which attach to moist surfaces and are extremely resistant to chemicals and
antibiotics. Recent experiments show that their structure is defined by the
interplay of elastic deformations and liquid transport within the biofilm, in
response to the cellular activity and the interaction with the surrounding
environment. We propose a poroelastic model for elastic deformation and liquid
transport in three dimensional biofilms spreading on agar surfaces. The motion
of the boundaries can be described by the combined use of Von Karman type
approximations for the agar/biofilm interface and thin film approximations for
the biofilm/air interface. Bacterial activity informs the macroscopic
continuous model through source terms and residual stresses, either
phenomenological or derived from microscopic models. We present a procedure to
estimate the structure of such residual stresses, based on a simple cellular
automata description of bacterial activity. Inspired by image processing, we
show that a filtering strategy effectively smooths out the rough tensors
provided by the stochastic cellular automata rules, allowing us to insert them
in the macroscopic model without numerical instability.
</p>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07070" title="Abstract">arXiv:2401.07070</a> (cross-list from econ.TH) [<a href="/pdf/2401.07070" title="Download PDF">pdf</a>, <a href="/format/2401.07070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Agent Based Model of the Real Economy with Monopolistic  Competition, Perfect Product Differentiation, Heterogeneous Agents,  Increasing Returns to Scale and Trade in Disequilibrium
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Supantha%2C+S">Subhamon Supantha</a>, 
<a href="/search/econ?searchtype=author&query=Sharma%2C+N+K">Naresh Kumar Sharma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We have used agent-based modeling as our numerical method to artificially
simulate a dynamic real economy where agents are rational maximizers of an
objective function of Cobb-Douglas type. The economy is characterised by
heterogeneous agents, acting out of local or imperfect information,
monopolistic competition, perfect product differentiation, allowance for
increasing returns to scale technology and trade in disequilibrium. An
algorithm for economic activity in each period is devised and a general purpose
open source agent-based model is developed which allows for counterfactual
inquiries, testing out treatments, analysing causality of various economic
processes, outcomes and studying emergent properties. 10,000 simulations, with
10 firms and 80 consumers are run with varying parameters and the results show
that from only a few initial conditions the economy reaches equilibrium while
in most of the other cases it remains in perpetual disequilibrium. It also
shows that from a few initial conditions the economy reaches a disaster where
all the consumer wealth falls to zero or only a single producer remains.
Furthermore, from some initial conditions, an ideal economy with high wage
rate, high consumer utility and no unemployment is also reached. It was also
observed that starting from an equal endowment of wealth in consumers and in
producers, inequality emerged in the economy. In majority of the cases most of
the firms(6-7) shut down because they were not profitable enough and only a few
firms remained. Our results highlight that all these varying outcomes are
possible for a decentralized market economy with rational optimizing agents.
</p>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07088" title="Abstract">arXiv:2401.07088</a> (cross-list from cond-mat.soft) [<a href="/pdf/2401.07088" title="Download PDF">pdf</a>, <a href="/format/2401.07088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Cellular Stochasticity in Solid--Fluid Mixture Biofilm  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Carpio%2C+A">Ana Carpio</a>, 
<a href="/search/cond-mat?searchtype=author&query=Cebrian%2C+E">Elena Cebrian</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Entropy 22(2), 188, 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Biological Physics (physics.bio-ph); Cell Behavior (q-bio.CB)

</div>
<p class="mathjax">The dynamics of cellular aggregates is driven by the interplay of
mechanochemical processes and cellular activity. Although deterministic models
may capture mechanical features, local chemical fluctuations trigger random
cell responses, which determine the overall evolution. Incorporating stochastic
cellular behavior in macroscopic models of biological media is a challenging
task. Herein, we propose hybrid models for bacterial biofilm growth, which
couple a two phase solid/fluid mixture description of mechanical and chemical
fields with a dynamic energy budget-based cellular automata treatment of
bacterial activity. Thin film and plate approximations for the relevant
interfaces allow us to obtain numerical solutions exhibiting behaviors observed
in experiments, such as accelerated spread due to water intake from the
environment, wrinkle formation, undulated contour development, and the
appearance of inhomogeneous distributions of differentiated bacteria performing
varied tasks.
</p>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07096" title="Abstract">arXiv:2401.07096</a> (cross-list from math.OC) [<a href="/pdf/2401.07096" title="Download PDF">pdf</a>, <a href="/ps/2401.07096" title="Download PostScript">ps</a>, <a href="/format/2401.07096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the ADMM Algorithm via High-Resolution Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+B">Bowen Li</a>, 
<a href="/search/math?searchtype=author&query=Shi%2C+B">Bin Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In the fields of statistics, machine learning, image science, and related
areas, there is an increasing demand for decentralized collection or storage of
large-scale datasets, as well as distributed solution methods. To tackle this
challenge, the alternating direction method of multipliers (ADMM) has emerged
as a widely used approach, particularly well-suited to distributed convex
optimization. However, the iterative behavior of ADMM has not been well
understood. In this paper, we employ dimensional analysis to derive a system of
high-resolution ordinary differential equations (ODEs) for ADMM. This system
captures an important characteristic of ADMM, called the $\lambda$-correction,
which causes the trajectory of ADMM to deviate from the constrained hyperplane.
To explore the convergence behavior of the system of high-resolution ODEs, we
utilize Lyapunov analysis and extend our findings to the discrete ADMM
algorithm. Through this analysis, we identify that the numerical error
resulting from the implicit scheme is a crucial factor that affects the
convergence rate and monotonicity in the discrete ADMM algorithm. In addition,
we further discover that if one component of the objective function is assumed
to be strongly convex, the iterative average of ADMM converges strongly with a
rate $O(1/N)$, where $N$ is the number of iterations.
</p>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07126" title="Abstract">arXiv:2401.07126</a> (cross-list from eess.IV) [<a href="/pdf/2401.07126" title="Download PDF">pdf</a>, <a href="/format/2401.07126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IVIM-Morph: Motion-compensated quantitative Intra-voxel Incoherent  Motion (IVIM) analysis for functional fetal lung maturity assessment from  diffusion-weighted MRI data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kertes%2C+N">Noga Kertes</a>, 
<a href="/search/eess?searchtype=author&query=Zaffrani-Reznikov%2C+Y">Yael Zaffrani-Reznikov</a>, 
<a href="/search/eess?searchtype=author&query=Afacan%2C+O">Onur Afacan</a>, 
<a href="/search/eess?searchtype=author&query=Kurugol%2C+S">Sila Kurugol</a>, 
<a href="/search/eess?searchtype=author&query=Warfield%2C+S+K">Simon K. Warfield</a>, 
<a href="/search/eess?searchtype=author&query=Freiman%2C+M">Moti Freiman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Quantitative analysis of pseudo-diffusion in diffusion-weighted magnetic
resonance imaging (DWI) data shows potential for assessing fetal lung
maturation and generating valuable imaging biomarkers. Yet, the clinical
utility of DWI data is hindered by unavoidable fetal motion during acquisition.
We present IVIM-morph, a self-supervised deep neural network model for
motion-corrected quantitative analysis of DWI data using the Intra-voxel
Incoherent Motion (IVIM) model. IVIM-morph combines two sub-networks, a
registration sub-network, and an IVIM model fitting sub-network, enabling
simultaneous estimation of IVIM model parameters and motion. To promote
physically plausible image registration, we introduce a biophysically informed
loss function that effectively balances registration and model-fitting quality.
We validated the efficacy of IVIM-morph by establishing a correlation between
the predicted IVIM model parameters of the lung and gestational age (GA) using
fetal DWI data of 39 subjects. IVIM-morph exhibited a notably improved
correlation with gestational age (GA) when performing in-vivo quantitative
analysis of fetal lung DWI data during the canalicular phase. IVIM-morph shows
potential in developing valuable biomarkers for non-invasive assessment of
fetal lung maturity with DWI data. Moreover, its adaptability opens the door to
potential applications in other clinical contexts where motion compensation is
essential for quantitative DWI analysis. The IVIM-morph code is readily
available at: https://github.com/TechnionComputationalMRILab/qDWI-Morph.
</p>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07174" title="Abstract">arXiv:2401.07174</a> (cross-list from math.ST) [<a href="/pdf/2401.07174" title="Download PDF">pdf</a>, <a href="/format/2401.07174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the (In)Compatibility between Group Fairness and Individual Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+S">Shizhou Xu</a>, 
<a href="/search/math?searchtype=author&query=Strohmer%2C+T">Thomas Strohmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study the compatibility between the optimal statistical parity solutions
and individual fairness. While individual fairness seeks to treat similar
individuals similarly, optimal statistical parity aims to provide similar
treatment to individuals who share relative similarity within their respective
sensitive groups. The two fairness perspectives, while both desirable from a
fairness perspective, often come into conflict in applications. Our goal in
this work is to analyze the existence of this conflict and its potential
solution. In particular, we establish sufficient (sharp) conditions for the
compatibility between the optimal (post-processing) statistical parity $L^2$
learning and the ($K$-Lipschitz or $(\epsilon,\delta)$) individual fairness
requirements. Furthermore, when there exists a conflict between the two, we
first relax the former to the Pareto frontier (or equivalently the optimal
trade-off) between $L^2$ error and statistical disparity, and then analyze the
compatibility between the frontier and the individual fairness requirements.
Our analysis identifies regions along the Pareto frontier that satisfy
individual fairness requirements. (Lastly, we provide individual fairness
guarantees for the composition of a trained model and the optimal
post-processing step so that one can determine the compatibility of the
post-processed model.) This provides practitioners with a valuable approach to
attain Pareto optimality for statistical parity while adhering to the
constraints of individual fairness.
</p>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07187" title="Abstract">arXiv:2401.07187</a> (cross-list from stat.ML) [<a href="/pdf/2401.07187" title="Download PDF">pdf</a>, <a href="/ps/2401.07187" title="Download PostScript">ps</a>, <a href="/format/2401.07187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Statistical Theory of Deep Learning: Approximation, Training  Dynamics, and Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Suh%2C+N">Namjoon Suh</a>, 
<a href="/search/stat?searchtype=author&query=Cheng%2C+G">Guang Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, no figures,Invited for review in Annual Review of Statistics and Its Application (In review)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this article, we review the literature on statistical theories of neural
networks from three perspectives. In the first part, results on excess risks
for neural networks are reviewed in the nonparametric framework of regression
or classification. These results rely on explicit constructions of neural
networks, leading to fast convergence rates of excess risks, in that tools from
the approximation theory are adopted. Through these constructions, the width
and depth of the networks can be expressed in terms of sample size, data
dimension, and function smoothness. Nonetheless, their underlying analysis only
applies to the global minimizer in the highly non-convex landscape of deep
neural networks. This motivates us to review the training dynamics of neural
networks in the second part. Specifically, we review papers that attempt to
answer ``how the neural network trained via gradient-based methods finds the
solution that can generalize well on unseen data.'' In particular, two
well-known paradigms are reviewed: the Neural Tangent Kernel (NTK) paradigm,
and Mean-Field (MF) paradigm. In the last part, we review the most recent
theoretical advancements in generative models including Generative Adversarial
Networks (GANs), diffusion models, and in-context learning (ICL) in the Large
Language Models (LLMs). The former two models are known to be the main pillars
of the modern generative AI era, while ICL is a strong capability of LLMs in
learning from a few examples in the context. Finally, we conclude the paper by
suggesting several promising directions for deep learning theory.
</p>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07206" title="Abstract">arXiv:2401.07206</a> (cross-list from stat.ML) [<a href="/pdf/2401.07206" title="Download PDF">pdf</a>, <a href="/format/2401.07206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Reduced-Dimensional Vector Autoregressive Modeling with  Oblique Projections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Mo%2C+Y">Yanfang Mo</a>, 
<a href="/search/stat?searchtype=author&query=Qin%2C+S+J">S. Joe Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we propose a probabilistic reduced-dimensional vector
autoregressive (PredVAR) model to extract low-dimensional dynamics from
high-dimensional noisy data. The model utilizes an oblique projection to
partition the measurement space into a subspace that accommodates the
reduced-dimensional dynamics and a complementary static subspace. An optimal
oblique decomposition is derived for the best predictability regarding
prediction error covariance. Building on this, we develop an iterative PredVAR
algorithm using maximum likelihood and the expectation-maximization (EM)
framework. This algorithm alternately updates the estimates of the latent
dynamics and optimal oblique projection, yielding dynamic latent variables with
rank-ordered predictability and an explicit latent VAR model that is consistent
with the outer projection model. The superior performance and efficiency of the
proposed approach are demonstrated using data sets from a synthesized Lorenz
system and an industrial process from Eastman Chemical.
</p>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07232" title="Abstract">arXiv:2401.07232</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2401.07232" title="Download PDF">pdf</a>, <a href="/format/2401.07232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polariton lattices as binarized neuromorphic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Sedov%2C+E">Evgeny Sedov</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kavokin%2C+A">Alexey Kavokin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">We introduce a novel neuromorphic network architecture based on a lattice of
exciton-polariton condensates, intricately interconnected and energized through
non-resonant optical pumping. The network employs a binary framework, where
each neuron, facilitated by the spatial coherence of pairwise coupled
condensates, performs binary operations. This coherence, emerging from the
ballistic propagation of polaritons, ensures efficient, network-wide
communication. The binary neuron switching mechanism, driven by the nonlinear
repulsion through the excitonic component of polaritons, offers computational
efficiency and scalability advantages over continuous weight neural networks.
Our network enables parallel processing, enhancing computational speed compared
to sequential or pulse-coded binary systems. The system's performance was
evaluated using the MNIST dataset for handwritten digit recognition, showcasing
the potential to outperform existing polaritonic neuromorphic systems, as
demonstrated by its impressive predicted classification accuracy of up to
97.5%.
</p>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07298" title="Abstract">arXiv:2401.07298</a> (cross-list from stat.ML) [<a href="/pdf/2401.07298" title="Download PDF">pdf</a>, <a href="/format/2401.07298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Frameworks for Generalized Low-Rank Matrix Bandit Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kang%2C+Y">Yue Kang</a>, 
<a href="/search/stat?searchtype=author&query=Hsieh%2C+C">Cho-Jui Hsieh</a>, 
<a href="/search/stat?searchtype=author&query=Lee%2C+T+C+M">Thomas C. M. Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision of the paper accepted by NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the stochastic contextual low-rank matrix bandit problem, the expected
reward of an action is given by the inner product between the action's feature
matrix and some fixed, but initially unknown $d_1$ by $d_2$ matrix $\Theta^*$
with rank $r \ll \{d_1, d_2\}$, and an agent sequentially takes actions based
on past experience to maximize the cumulative reward. In this paper, we study
the generalized low-rank matrix bandit problem, which has been recently
proposed in \cite{lu2021low} under the Generalized Linear Model (GLM)
framework. To overcome the computational infeasibility and theoretical restrain
of existing algorithms on this problem, we first propose the G-ESTT framework
that modifies the idea from \cite{jun2019bilinear} by using Stein's method on
the subspace estimation and then leverage the estimated subspaces via a
regularization idea. Furthermore, we remarkably improve the efficiency of
G-ESTT by using a novel exclusion idea on the estimated subspace instead, and
propose the G-ESTS framework. We also show that G-ESTT can achieve the
$\tilde{O}(\sqrt{(d_1+d_2)MrT})$ bound of regret while G-ESTS can achineve the
$\tilde{O}(\sqrt{(d_1+d_2)^{3/2}Mr^{3/2}T})$ bound of regret under mild
assumption up to logarithm terms, where $M$ is some problem dependent value.
Under a reasonable assumption that $M = O((d_1+d_2)^2)$ in our problem setting,
the regret of G-ESTT is consistent with the current best regret of
$\tilde{O}((d_1+d_2)^{3/2} \sqrt{rT}/D_{rr})$~\citep{lu2021low} ($D_{rr}$ will
be defined later). For completeness, we conduct experiments to illustrate that
our proposed algorithms, especially G-ESTS, are also computationally tractable
and consistently outperform other state-of-the-art (generalized) linear matrix
bandit methods based on a suite of simulations.
</p>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07305" title="Abstract">arXiv:2401.07305</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.07305" title="Download PDF">pdf</a>, <a href="/format/2401.07305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Service Slowdown using Observational Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kuang%2C+X">Xu Kuang</a>, 
<a href="/search/physics?searchtype=author&query=Mendelson%2C+G">Gal Mendelson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Systems and Control (eess.SY); Probability (math.PR)

</div>
<p class="mathjax">Being able to detect service slowdowns is crucial to many operational
problems. We study how to use observational congestion data to detect service
slowdown in a multi-server system, and in particular, the statistical
implications of running adaptive congestion control mechanisms in such
settings. We show that a commonly used summary statistic that relies on the
marginal congestion measured at individual servers can be highly inaccurate the
presence of adaptive congestion control. We propose a new statistic based on
potential routing actions, and show it provides a much more robust signal for
server slowdown in these settings. Unlike the marginal statistic, potential
action aims to detect changes in the {routing actions}, and is able to uncover
slowdowns even when they do not reflect in marginal congestion. Our work
highlights the complexity in performing observational statistical analysis for
service systems in the presence of adaptive congestion control. Our results
also suggest that practitioners may want to combine multiple, orthogonal
statistics to achieve reliable slowdown detection.
</p>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07326" title="Abstract">arXiv:2401.07326</a> (cross-list from eess.IV) [<a href="/pdf/2401.07326" title="Download PDF">pdf</a>, <a href="/format/2401.07326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Traditional Approaches: Multi-Task Network for Breast Ultrasound  Diagnosis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chung%2C+D+T">Dat T. Chung</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+M">Minh-Anh Dang</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+M">Mai-Anh Vu</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+M+T">Minh T. Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+T">Thanh-Huy Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Dinh%2C+V+Q">Vinh Q. Dinh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Breast Ultrasound plays a vital role in cancer diagnosis as a non-invasive
approach with cost-effective. In recent years, with the development of deep
learning, many CNN-based approaches have been widely researched in both tumor
localization and cancer classification tasks. Even though previous single
models achieved great performance in both tasks, these methods have some
limitations in inference time, GPU requirement, and separate fine-tuning for
each model. In this study, we aim to redesign and build end-to-end multi-task
architecture to conduct both segmentation and classification. With our proposed
approach, we achieved outstanding performance and time efficiency, with 79.8%
and 86.4% in DeepLabV3+ architecture in the segmentation task.
</p>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07336" title="Abstract">arXiv:2401.07336</a> (cross-list from eess.AS) [<a href="/pdf/2401.07336" title="Download PDF">pdf</a>, <a href="/ps/2401.07336" title="Download PostScript">ps</a>, <a href="/format/2401.07336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Construction and Evaluation of Mandarin Multimodal Emotional Speech  Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ting%2C+Z">Zhu Ting</a>, 
<a href="/search/eess?searchtype=author&query=Liangqi%2C+L">Li Liangqi</a>, 
<a href="/search/eess?searchtype=author&query=Shufei%2C+D">Duan Shufei</a>, 
<a href="/search/eess?searchtype=author&query=Xueying%2C+Z">Zhang Xueying</a>, 
<a href="/search/eess?searchtype=author&query=Zhongzhe%2C+X">Xiao Zhongzhe</a>, 
<a href="/search/eess?searchtype=author&query=Hairng%2C+J">Jia Hairng</a>, 
<a href="/search/eess?searchtype=author&query=Huizhi%2C+L">Liang Huizhi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">A multi-modal emotional speech Mandarin database including articulatory
kinematics, acoustics, glottal and facial micro-expressions is designed and
established, which is described in detail from the aspects of corpus design,
subject selection, recording details and data processing. Where signals are
labeled with discrete emotion labels (neutral, happy, pleasant, indifferent,
angry, sad, grief) and dimensional emotion labels (pleasure, arousal,
dominance). In this paper, the validity of dimension annotation is verified by
statistical analysis of dimension annotation data. The SCL-90 scale data of
annotators are verified and combined with PAD annotation data for analysis, so
as to explore the internal relationship between the outlier phenomenon in
annotation and the psychological state of annotators. In order to verify the
speech quality and emotion discrimination of the database, this paper uses 3
basic models of SVM, CNN and DNN to calculate the recognition rate of these
seven emotions. The results show that the average recognition rate of seven
emotions is about 82% when using acoustic data alone. When using glottal data
alone, the average recognition rate is about 72%. Using kinematics data alone,
the average recognition rate also reaches 55.7%. Therefore, the database is of
high quality and can be used as an important source for speech analysis
research, especially for the task of multimodal emotional speech analysis.
</p>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07337" title="Abstract">arXiv:2401.07337</a> (cross-list from econ.TH) [<a href="/pdf/2401.07337" title="Download PDF">pdf</a>, <a href="/format/2401.07337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Individual and Collective Welfare in Risk Sharing with Many States
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Echenique%2C+F">Federico Echenique</a>, 
<a href="/search/econ?searchtype=author&query=Pourbabaee%2C+F">Farzad Pourbabaee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We provide a quantitative assessment of welfare in the classical model of
risk-sharing and exchange under uncertainty. We prove three kinds of results.
First, that in an equilibrium allocation, the scope for improving individual
welfare by a given margin (an $\ve$-improvement) vanishes as the number of
states increases. Second, that the scope for a change in aggregate resources
that may be distributed to enhance individual welfare by a given margin also
vanishes. Equivalently: in an inefficient allocation, for a given level of
resource sub-optimality (as measured by the coefficient of resource
under-utilization), the possibilities for enhancing welfare by perturbing
aggregate resources decrease exponentially to zero with the number of states.
Finally, we consider efficient risk-sharing in standard models of uncertainty
aversion with multiple priors, and show that, in an inefficient allocation,
certain sets of priors shrink with the size of the state space.
</p>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07342" title="Abstract">arXiv:2401.07342</a> (cross-list from eess.AS) [<a href="/pdf/2401.07342" title="Download PDF">pdf</a>, <a href="/format/2401.07342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Who Said What? An Automated Approach to Analyzing Speech in Preschool  Classrooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+A">Anchen Sun</a>, 
<a href="/search/eess?searchtype=author&query=Londono%2C+J+J">Juan J Londono</a>, 
<a href="/search/eess?searchtype=author&query=Elbaum%2C+B">Batya Elbaum</a>, 
<a href="/search/eess?searchtype=author&query=Estrada%2C+L">Luis Estrada</a>, 
<a href="/search/eess?searchtype=author&query=Lazo%2C+R+J">Roberto Jose Lazo</a>, 
<a href="/search/eess?searchtype=author&query=Vitale%2C+L">Laura Vitale</a>, 
<a href="/search/eess?searchtype=author&query=Villasanti%2C+H+G">Hugo Gonzalez Villasanti</a>, 
<a href="/search/eess?searchtype=author&query=Fusaroli%2C+R">Riccardo Fusaroli</a>, 
<a href="/search/eess?searchtype=author&query=Perry%2C+L+K">Lynn K Perry</a>, 
<a href="/search/eess?searchtype=author&query=Messinger%2C+D+S">Daniel S Messinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Young children spend substantial portions of their waking hours in noisy
preschool classrooms. In these environments, children's vocal interactions with
teachers are critical contributors to their language outcomes, but manually
transcribing these interactions is prohibitive. Using audio from child- and
teacher-worn recorders, we propose an automated framework that uses open source
software both to classify speakers (ALICE) and to transcribe their utterances
(Whisper). We compare results from our framework to those from a human expert
for 110 minutes of classroom recordings, including 85 minutes from child-word
microphones (n=4 children) and 25 minutes from teacher-worn microphones (n=2
teachers). The overall proportion of agreement, that is, the proportion of
correctly classified teacher and child utterances, was .76, with an
error-corrected kappa of .50 and a weighted F1 of .76. The word error rate for
both teacher and child transcriptions was .15, meaning that 15% of words would
need to be deleted, added, or changed to equate the Whisper and expert
transcriptions. Moreover, speech features such as the mean length of utterances
in words, the proportion of teacher and child utterances that were questions,
and the proportion of utterances that were responded to within 2.5 seconds were
similar when calculated separately from expert and automated transcriptions.
The results suggest substantial progress in analyzing classroom speech that may
support children's language development. Future research using natural language
processing is underway to improve speaker classification and to analyze results
from the application of the automated it framework to a larger dataset
containing classroom recordings from 13 children and 4 teachers observed on 17
occasions over one year.
</p>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07379" title="Abstract">arXiv:2401.07379</a> (cross-list from q-bio.QM) [<a href="/pdf/2401.07379" title="Download PDF">pdf</a>, <a href="/format/2401.07379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inference of dynamical gene regulatory networks from single-cell data  with physics informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mircea%2C+M">Maria Mircea</a>, 
<a href="/search/q-bio?searchtype=author&query=Garlaschelli%2C+D">Diego Garlaschelli</a>, 
<a href="/search/q-bio?searchtype=author&query=Semrau%2C+S">Stefan Semrau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">One of the main goals of developmental biology is to reveal the gene
regulatory networks (GRNs) underlying the robust differentiation of multipotent
progenitors into precisely specified cell types. Most existing methods to infer
GRNs from experimental data have limited predictive power as the inferred GRNs
merely reflect gene expression similarity or correlation. Here, we demonstrate,
how physics-informed neural networks (PINNs) can be used to infer the
parameters of predictive, dynamical GRNs that provide mechanistic understanding
of biological processes. Specifically we study GRNs that exhibit bifurcation
behavior and can therefore model cell differentiation. We show that PINNs
outperform regular feed-forward neural networks on the parameter inference task
and analyze two relevant experimental scenarios: 1. a system with cell
communication for which gene expression trajectories are available and 2.
snapshot measurements of a cell population in which cell communication is
absent. Our analysis will inform the design of future experiments to be
analyzed with PINNs and provides a starting point to explore this powerful
class of neural network models further.
</p>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07381" title="Abstract">arXiv:2401.07381</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.07381" title="Download PDF">pdf</a>, <a href="/ps/2401.07381" title="Download PostScript">ps</a>, <a href="/format/2401.07381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagrammatic Rules for Triad Census
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Borriello%2C+E">Enrico Borriello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In network theory, a triad census is a method designed to categorize and
enumerate the various types of subgraphs with three nodes and their connecting
edges within a network. Triads serve as fundamental building blocks for
comprehending the structure and dynamics of networks, and the triad census
offers a systematic approach to their classification. Typically, triad counts
are obtained numerically, but lesser-known methods have been developed to
precisely evaluate them without the need for sampling. In our study, we build
upon Moody's matrix approach, presenting general diagrammatic rules that
systematically and intuitively generate closed formulas for the occurrence
numbers of triads in a network.
</p>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07383" title="Abstract">arXiv:2401.07383</a> (cross-list from physics.chem-ph) [<a href="/pdf/2401.07383" title="Download PDF">pdf</a>, <a href="/format/2401.07383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recent mathematical advances in coupled cluster theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Faulstich%2C+F+M">Fabian M. Faulstich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Mathematical Physics (math-ph); Algebraic Geometry (math.AG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">This article presents an in-depth educational overview of the latest
mathematical developments in coupled cluster (CC) theory, beginning with
Schneider's seminal work from 2009 that introduced the first local analysis of
CC theory. We offer a tutorial review of second quantization and the CC ansatz,
laying the groundwork for understanding the mathematical basis of the theory.
This is followed by a detailed exploration of the most recent mathematical
advancements in CC theory.Our review starts with an in-depth look at the local
analysis pioneered by Schneider which has since been applied to analyze various
CC methods. We then move on to discuss the graph-based framework for CC methods
developed by Csirik and Laestadius. This framework provides a comprehensive
platform for comparing different CC methods, including multireference
approaches. Next, we delve into the latest numerical analysis results analyzing
the single reference CC method developed by Hassan, Maday, and Wang. This very
general approach is based on the invertibility of the CC function's Fr\'echet
derivative. We conclude the article with a discussion on the recent
incorporation of algebraic geometry into CC theory, highlighting how this novel
and fundamentally different mathematical perspective has furthered our
understanding and provides exciting pathways to new computational approaches.
</p>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07425" title="Abstract">arXiv:2401.07425</a> (cross-list from math.OC) [<a href="/pdf/2401.07425" title="Download PDF">pdf</a>, <a href="/ps/2401.07425" title="Download PostScript">ps</a>, <a href="/format/2401.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZEH-oriented Linear Programming for the Sizing Problem of Photovoltaic  Panels and Batteries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carnerero%2C+A+D">A. Daniel Carnerero</a>, 
<a href="/search/math?searchtype=author&query=Tanaka%2C+T">Taichi Tanaka</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+M">Mengmou Li</a>, 
<a href="/search/math?searchtype=author&query=Hatanaka%2C+T">Takeshi Hatanaka</a>, 
<a href="/search/math?searchtype=author&query=Wasa%2C+Y">Yasuaki Wasa</a>, 
<a href="/search/math?searchtype=author&query=Hirata%2C+K">Kenji Hirata</a>, 
<a href="/search/math?searchtype=author&query=Ushifusa%2C+Y">Yoshiaki Ushifusa</a>, 
<a href="/search/math?searchtype=author&query=Ida%2C+T">Takanori Ida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 13 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we explore the concept of net-Zero Energy Houses (ZEH) -
houses designed to have an annual net energy consumption around zero. To
achieve this, we present a constrained optimization problem whose objective is
finding the optimal sizing of photovoltaic panels and a battery system to be
integrated at home. The original optimization problem is nonlinear with
nonconvex constraints. Nevertheless, by applying a series of transformations,
it is possible to find an equivalent Linear Programming (LP) problem which is
computationally tractable. The attainment of ZEH can be tackled by introducing
a single constraint in the optimization problem. Additionally, we propose a
sharing economy approach to the investment problem, a strategy that carries the
potential to reduce the cost of the investment and facilitate the attainment of
ZEH in a more efficient manner. Finally, we apply the proposed frameworks to a
neighborhood in Japan as a case study, demonstrating the potential for
long-term ZEH attainment. The results show the importance of choosing an
appropriate incentive to motivate residents towards achieving ZEH.
</p>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07435" title="Abstract">arXiv:2401.07435</a> (cross-list from math.GT) [<a href="/pdf/2401.07435" title="Download PDF">pdf</a>, <a href="/format/2401.07435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manifolds from Partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Knill%2C+O">Oliver Knill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">If f maps a discrete d-manifold G onto a (k+1)-partite complex P then
H(G,f,P),the set of simplices x in G such that f(x) contains at least one facet
in P defines a (d-k)-manifold.
</p>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07455" title="Abstract">arXiv:2401.07455</a> (cross-list from math.OC) [<a href="/pdf/2401.07455" title="Download PDF">pdf</a>, <a href="/format/2401.07455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability analysis of a departure time choice problem with atomic  vehicle models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Satsukawa%2C+K">Koki Satsukawa</a>, 
<a href="/search/math?searchtype=author&query=Wada%2C+K">Kentaro Wada</a>, 
<a href="/search/math?searchtype=author&query=Iryo%2C+T">Takamasa Iryo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 11figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Dynamical Systems (math.DS)

</div>
<p class="mathjax">In this study, we analyse the global stability of the equilibrium in a
departure time choice problem using a game-theoretic approach that deals with
atomic users. We first formulate the departure time choice problem as a
strategic game in which atomic users select departure times to minimise their
trip cost; we call this game the 'departure time choice game'. The concept of
the epsilon-Nash equilibrium is introduced to ensure the existence of
pure-strategy equilibrium corresponding to the departure time choice
equilibrium in conventional fluid models. Then, we prove that the departure
time choice game is a weakly acyclic game. By analysing the convergent better
responses, we clarify the mechanisms of global convergence to equilibrium. This
means that the epsilon-Nash equilibrium is achieved by sequential better
responses of users, which are departure time changes to improve their own
utility, in an appropriate order. Specifically, the following behavioural rules
are important to ensure global convergence: (i) the adjustment of the departure
time of the first user departing from the origin to the corresponding
equilibrium departure time and (ii) the fixation of users to their equilibrium
departure times in order (starting with the earliest). Using convergence
mechanisms, we construct evolutionary dynamics under which global stability is
guaranteed. We also investigate the stable and unstable dynamics studied in the
literature based on convergence mechanisms, and gain insight into the factors
influencing the different stability results. Finally, numerical experiments are
conducted to demonstrate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07463" title="Abstract">arXiv:2401.07463</a> (cross-list from math.ST) [<a href="/pdf/2401.07463" title="Download PDF">pdf</a>, <a href="/format/2401.07463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency of semi-supervised learning, stochastic tug-of-war games,  and the p-Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Calder%2C+J">Jeff Calder</a>, 
<a href="/search/math?searchtype=author&query=Drenska%2C+N">Nadejda Drenska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP); Numerical Analysis (math.NA); Probability (math.PR)

</div>
<p class="mathjax">In this paper we give a broad overview of the intersection of partial
differential equations (PDEs) and graph-based semi-supervised learning. The
overview is focused on a large body of recent work on PDE continuum limits of
graph-based learning, which have been used to prove well-posedness of
semi-supervised learning algorithms in the large data limit. We highlight some
interesting research directions revolving around consistency of graph-based
semi-supervised learning, and present some new results on the consistency of
p-Laplacian semi-supervised learning using the stochastic tug-of-war game
interpretation of the p-Laplacian. We also present the results of some
numerical experiments that illustrate our results and suggest directions for
future work.
</p>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07464" title="Abstract">arXiv:2401.07464</a> (cross-list from quant-ph) [<a href="/pdf/2401.07464" title="Download PDF">pdf</a>, <a href="/format/2401.07464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Privacy Aggregation of Teacher Ensembles (QPATE) for  Privacy-preserving Quantum Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Watkins%2C+W">William Watkins</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Heehwan Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bae%2C+S">Sangyoon Bae</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tseng%2C+H">Huan-Hsin Tseng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cha%2C+J">Jiook Cha</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+S+Y">Samuel Yen-Chi Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The utility of machine learning has rapidly expanded in the last two decades
and presents an ethical challenge. Papernot et. al. developed a technique,
known as Private Aggregation of Teacher Ensembles (PATE) to enable federated
learning in which multiple teacher models are trained on disjoint datasets.
This study is the first to apply PATE to an ensemble of quantum neural networks
(QNN) to pave a new way of ensuring privacy in quantum machine learning (QML)
models.
</p>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07484" title="Abstract">arXiv:2401.07484</a> (cross-list from math.CO) [<a href="/pdf/2401.07484" title="Download PDF">pdf</a>, <a href="/format/2401.07484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Growing Trees and Amoebas&#x27; Replications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gurvich%2C+V">Vladimir Gurvich</a>, 
<a href="/search/math?searchtype=author&query=Krnc%2C+M">Matja&#x17e; Krnc</a>, 
<a href="/search/math?searchtype=author&query=Vyalyi%2C+M">Mikhail Vyalyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">An amoeba is a tree with a number assigned to each vertex. We describe a
natural process of growing trees from a given amoeba and discuss conditions for
such a process to be finite.
</p>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07489" title="Abstract">arXiv:2401.07489</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2401.07489" title="Download PDF">pdf</a>, <a href="/format/2401.07489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Principle of Minimum Pressure Gradient: An Alternative Basis for  Physics-Informed Learning of Incompressible Fluid Mechanics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Alhussein%2C+H">Hussam Alhussein</a>, 
<a href="/search/physics?searchtype=author&query=Daqaq%2C+M">Mohammed Daqaq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent advances in the application of physics-informed learning into the
field of fluid mechanics have been predominantly grounded in the Newtonian
framework, primarly leveraging Navier-Stokes Equation or one of its various
derivative to train a neural network. Here, we propose an alternative approach
based on variational methods. The proposed approach uses the principle of
minimum pressure gradient combined with the continuity constraint to train a
neural network and predict the flow field in incompressible fluids. We describe
the underlying principles of the proposed approach, then use a demonstrative
example to illustrate its implementation and show that it reduces the
computational time per training epoch when compared to the conventional
approach.
</p>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07506" title="Abstract">arXiv:2401.07506</a> (cross-list from eess.AS) [<a href="/pdf/2401.07506" title="Download PDF">pdf</a>, <a href="/format/2401.07506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeMaScore : a new evaluation metric for automatic speech recognition  tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sasindran%2C+Z">Zitha Sasindran</a>, 
<a href="/search/eess?searchtype=author&query=Yelchuri%2C+H">Harsha Yelchuri</a>, 
<a href="/search/eess?searchtype=author&query=Prabhakar%2C+T+V">T. V. Prabhakar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In this study, we present SeMaScore, generated using a segment-wise mapping
and scoring algorithm that serves as an evaluation metric for automatic speech
recognition tasks. SeMaScore leverages both the error rate and a more robust
similarity score. We show that our algorithm's score generation improves upon
the state-of-the-art BERTscore. Our experimental results show that SeMaScore
corresponds well with expert human assessments, signal-to-noise ratio levels,
and other natural language metrics. We outperform BERTscore by 41x in metric
computation speed. Overall, we demonstrate that SeMaScore serves as a more
dependable evaluation metric, particularly in real-world situations involving
atypical speech patterns.
</p>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07528" title="Abstract">arXiv:2401.07528</a> (cross-list from astro-ph.EP) [<a href="/pdf/2401.07528" title="Download PDF">pdf</a>, <a href="/ps/2401.07528" title="Download PostScript">ps</a>, <a href="/format/2401.07528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic characterization of boulders on planetary surfaces from  high-resolution satellite images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Prieur%2C+N+C">Nils C. Prieur</a>, 
<a href="/search/astro-ph?searchtype=author&query=Amaro%2C+B">Brian Amaro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Gonzalez%2C+E">Emiliano Gonzalez</a>, 
<a href="/search/astro-ph?searchtype=author&query=Kerner%2C+H">Hannah Kerner</a>, 
<a href="/search/astro-ph?searchtype=author&query=Medvedev%2C+S">Sergei Medvedev</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rubanenko%2C+L">Lior Rubanenko</a>, 
<a href="/search/astro-ph?searchtype=author&query=Werner%2C+S+C">Stephanie C. Werner</a>, 
<a href="/search/astro-ph?searchtype=author&query=Xiao8%2C+Z">Zhiyong Xiao8</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zastrozhnov%2C+D">Dmitry Zastrozhnov</a>, 
<a href="/search/astro-ph?searchtype=author&query=Lap%C3%B4tre%2C+M+G+A">Mathieu G. A. Lap&#xf4;tre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Boulders form from a variety of geological processes, which their size,
shape, and orientation may help us better understand. Furthermore, they
represent potential hazards to spacecraft landing that need to be
characterized. However, mapping individual boulders across vast areas is
extremely labor-intensive, often limiting the extent over which they are
characterized and the statistical robustness of obtained boulder morphometrics.
To automate boulder characterization, we use an instance segmentation neural
network, Mask R-CNN, to detect and outline boulders in high-resolution
satellite images. Our neural network, BoulderNet, was trained from a dataset of
&gt; 33,000 boulders in &gt; 750 image tiles from Earth, the Moon, and Mars.
BoulderNet not only correctly detects the majority of boulders in images, but
it identifies the outline of boulders with high fidelity, achieving average
precision and recall values of 72% and 64% relative to manually digitized
boulders from the test dataset, when only detections with
intersection-over-union ratios &gt; 50% are considered valid. These values are
similar to those obtained by human mappers. On Earth, equivalent boulder
diameters, aspect ratios, and orientations extracted from predictions were
benchmarked against ground measurements and yield values within 15%, 0.20, and
20 degrees of their ground-truth values, respectively. BoulderNet achieves
better boulder detection and characterization performance relative to existing
methods, providing a versatile open-source tool to characterize entire boulder
fields on planetary surfaces.
</p>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07538" title="Abstract">arXiv:2401.07538</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2401.07538" title="Download PDF">pdf</a>, <a href="/format/2401.07538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence of Scaling Regimes in the Hopfield Dynamics of Whole Brain  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Gosti%2C+G">Giorgio Gosti</a>, 
<a href="/search/cond-mat?searchtype=author&query=Succi%2C+S">Sauro Succi</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ruocco%2C+G">Giancarlo Ruocco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">It is shown that a Hopfield recurrent neural network, informed by
experimentally derived brain topology, recovers the scaling picture recently
introduced by Deco et al., according to which the process of information
transfer within the human brain shows spatially correlated patterns
qualitatively similar to those displayed by turbulent flows. Although both
models employ a coupling strength which decays exponentially with the euclidean
distance between the nodes, their mathematical nature is widely different, Hopf
oscillators versus Hopfield neural network. Hence, their convergence suggests a
remarkable robustness of the aforementioned scaling picture. Furthermore, the
present analysis shows that the Hopfield model brain remains functional by
removing links above about five decay lengths, corresponding to about one sixth
of the size of the global brain. This suggests that, in terms of connectivity
decay length, the Hopfield brain functions in a sort of intermediate "turbulent
liquid"-like state, whose essential connections are the intermediate ones
between the connectivity decay length and the global brain size. This
"turbulent-like liquid" appears to be more spiky than actual turbulent fluids,
with a scaling exponent around $2/5$ instead of $2/3$.
</p>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07562" title="Abstract">arXiv:2401.07562</a> (cross-list from stat.ME) [<a href="/pdf/2401.07562" title="Download PDF">pdf</a>, <a href="/format/2401.07562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Richardson Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Oates%2C+C+J">Chris. J. Oates</a>, 
<a href="/search/stat?searchtype=author&query=Karvonen%2C+T">Toni Karvonen</a>, 
<a href="/search/stat?searchtype=author&query=Teckentrup%2C+A+L">Aretha L. Teckentrup</a>, 
<a href="/search/stat?searchtype=author&query=Strocchi%2C+M">Marina Strocchi</a>, 
<a href="/search/stat?searchtype=author&query=Niederer%2C+S+A">Steven A. Niederer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA); Computation (stat.CO)

</div>
<p class="mathjax">For over a century, extrapolation methods have provided a powerful tool to
improve the convergence order of a numerical method. However, these tools are
not well-suited to modern computer codes, where multiple continua are
discretised and convergence orders are not easily analysed. To address this
challenge we present a probabilistic perspective on Richardson extrapolation, a
point of view that unifies classical extrapolation methods with modern
multi-fidelity modelling, and handles uncertain convergence orders by allowing
these to be statistically estimated. The approach is developed using Gaussian
processes, leading to Gauss-Richardson Extrapolation (GRE). Conditions are
established under which extrapolation using the conditional mean achieves a
polynomial (or even an exponential) speed-up compared to the original numerical
method. Further, the probabilistic formulation unlocks the possibility of
experimental design, casting the selection of fidelities as a continuous
optimisation problem which can then be (approximately) solved. A case-study
involving a computational cardiac model demonstrates that practical gains in
accuracy can be achieved using the GRE method.
</p>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07583" title="Abstract">arXiv:2401.07583</a> (cross-list from quant-ph) [<a href="/pdf/2401.07583" title="Download PDF">pdf</a>, <a href="/format/2401.07583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Quantum Codes from Algebraic Extensions of Generalized Bicycle  Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Koukoulekidis%2C+N">Nikolaos Koukoulekidis</a>, 
<a href="/search/quant-ph?searchtype=author&query=%C5%A0imkovic%2C+F">Fedor &#x160;imkovic IV</a>, 
<a href="/search/quant-ph?searchtype=author&query=Leib%2C+M">Martin Leib</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pereira%2C+F+R+F">Francisco Revson Fernandes Pereira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Quantum error correction is rapidly seeing first experimental
implementations, but there is a significant gap between asymptotically optimal
error-correcting codes and codes that are experimentally feasible. Quantum LDPC
codes range from the surface code, which has a vanishing encoding rate, to very
promising codes with constant encoding rate and linear distance. In this work,
motivated by current small-scale experimental quantum processing units, we
devise small quantum codes that are inspired by a subset of quantum LDPC codes,
known as generalized bicycle (GB) codes. We introduce a code construction based
on algebraic manipulation of the parity-check matrix of GB codes, rather than
manipulation of Tanner graphs. Our construction leads to families of quantum
LDPC codes of small size, and we demonstrate numerically that their performance
scales comparably to the performance of surface codes for similar sizes under a
phenomenological noise model. The advantage of our code family is that they
encode many logical qubits in one code, at the expense of non-local
connectivity. We then explore three variants of the code construction focusing
on reducing the long-range connectivity by bringing it closer to the current
experimental capabilities of short-range connectivity devices.
</p>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07604" title="Abstract">arXiv:2401.07604</a> (cross-list from physics.ao-ph) [<a href="/pdf/2401.07604" title="Download PDF">pdf</a>, <a href="/format/2401.07604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Assimilation using ERA5, ASOS, and the U-STN model for Weather  Forecasting over the UK
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Wang%2C+W">Wenqi Wang</a>, 
<a href="/search/physics?searchtype=author&query=Bieker%2C+J">Jacob Bieker</a>, 
<a href="/search/physics?searchtype=author&query=Arcucci%2C+R">Rossella Arcucci</a>, 
<a href="/search/physics?searchtype=author&query=Quilodr%C3%A1n-Casas%2C+C">C&#xe9;sar Quilodr&#xe1;n-Casas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the Tackling Climate Change with Machine Learning Workshop@NeurIPS 2023, 8 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, the convergence of data-driven machine learning models with
Data Assimilation (DA) offers a promising avenue for enhancing weather
forecasting. This study delves into this emerging trend, presenting our
methodologies and outcomes. We harnessed the UK's local ERA5 850 hPa
temperature data and refined the U-STN12 global weather forecasting model,
tailoring its predictions to the UK's climate nuances. From the ASOS network,
we sourced T2m data, representing ground observations across the UK. We
employed the advanced kriging method with a polynomial drift term for
consistent spatial resolution. Furthermore, Gaussian noise was superimposed on
the ERA5 T850 data, setting the stage for ensuing multi-time step synthetic
observations. Probing into the assimilation impacts, the ASOS T2m data was
integrated with the ERA5 T850 dataset. Our insights reveal that while global
forecast models can adapt to specific regions, incorporating atmospheric data
in DA significantly bolsters model accuracy. Conversely, the direct
assimilation of surface temperature data tends to mitigate this enhancement,
tempering the model's predictive prowess.
</p>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07627" title="Abstract">arXiv:2401.07627</a> (cross-list from stat.ML) [<a href="/pdf/2401.07627" title="Download PDF">pdf</a>, <a href="/ps/2401.07627" title="Download PostScript">ps</a>, <a href="/format/2401.07627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-sensitive Feature Selection for Support Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Ben%C3%ADtez-Pe%C3%B1a%2C+S">Sandra Ben&#xed;tez-Pe&#xf1;a</a>, 
<a href="/search/stat?searchtype=author&query=Blanquero%2C+R">Rafael Blanquero</a>, 
<a href="/search/stat?searchtype=author&query=Carrizosa%2C+E">Emilio Carrizosa</a>, 
<a href="/search/stat?searchtype=author&query=Ram%C3%ADrez-Cobo%2C+P">Pepa Ram&#xed;rez-Cobo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> S. Ben\'itez-Pe\~na, R. Blanquero, E. Carrizosa, P.
  Ram\'irez-Cobo. Cost-sensitive Feature Selection for Support Vector Machines,
  Computers &amp; Operations Research, Volume 106, 2019, Pages 169-178
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Feature Selection is a crucial procedure in Data Science tasks such as
Classification, since it identifies the relevant variables, making thus the
classification procedures more interpretable, cheaper in terms of measurement
and more effective by reducing noise and data overfit. The relevance of
features in a classification procedure is linked to the fact that
misclassifications costs are frequently asymmetric, since false positive and
false negative cases may have very different consequences. However,
off-the-shelf Feature Selection procedures seldom take into account such
cost-sensitivity of errors.
<br />In this paper we propose a mathematical-optimization-based Feature Selection
procedure embedded in one of the most popular classification procedures,
namely, Support Vector Machines, accommodating asymmetric misclassification
costs. The key idea is to replace the traditional margin maximization by
minimizing the number of features selected, but imposing upper bounds on the
false positive and negative rates. The problem is written as an integer linear
problem plus a quadratic convex problem for Support Vector Machines with both
linear and radial kernels.
<br />The reported numerical experience demonstrates the usefulness of the proposed
Feature Selection procedure. Indeed, our results on benchmark data sets show
that a substantial decrease of the number of features is obtained, whilst the
desired trade-off between false positive and false negative rates is achieved.
</p>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07643" title="Abstract">arXiv:2401.07643</a> (cross-list from eess.SP) [<a href="/pdf/2401.07643" title="Download PDF">pdf</a>, <a href="/format/2401.07643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning-based xApp for Dynamic Resource Allocation in O-RAN  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qazzaz%2C+M+M+H">Mohammed M. H. Qazzaz</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Ku%C5%82acz%2C+%C5%81">&#x141;ukasz Ku&#x142;acz</a> (3 and 4), 
<a href="/search/eess?searchtype=author&query=Kliks%2C+A">Adrian Kliks</a> (3 and 4), 
<a href="/search/eess?searchtype=author&query=Zaidi%2C+S+A">Syed A. Zaidi</a> (1), 
<a href="/search/eess?searchtype=author&query=Dryjanski%2C+M">Marcin Dryjanski</a> (4), 
<a href="/search/eess?searchtype=author&query=McLernon%2C+D">Des McLernon</a> (1) ((1) School of Electronic and Electrical Engineering, University of Leeds, Leeds, UK, (2) College of Electronics Engineering, Ninevah University, Mosul, Iraq, (3) Institute of Radiocommunications, Poznan University of Technology, Poznan, Poland,(4) Rimedo Labs, Poznan, Poland)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, 2024 IEEE International Conference on Machine Learning for Communication and Networking (ICMLCN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The disaggregated, distributed and virtualised implementation of radio access
networks allows for dynamic resource allocation. These attributes can be
realised by virtue of the Open Radio Access Networks (O-RAN) architecture. In
this article, we tackle the issue of dynamic resource allocation using a
data-driven approach by employing Machine Learning (ML). We present an
xApp-based implementation for the proposed ML algorithm. The core aim of this
work is to optimise resource allocation and fulfil Service Level Specifications
(SLS). This is accomplished by dynamically adjusting the allocation of Physical
Resource Blocks (PRBs) based on traffic demand and Quality of Service (QoS)
requirements. The proposed ML model effectively selects the best allocation
policy for each base station and enhances the performance of scheduler
functionality in O-RAN - Distributed Unit (O-DU). We show that an xApp
implementing the Random Forest Classifier can yield high (85\%) performance
accuracy for optimal policy selection. This can be attained using the O-RAN
instance state input parameters over a short training duration.
</p>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07646" title="Abstract">arXiv:2401.07646</a> (cross-list from nlin.AO) [<a href="/pdf/2401.07646" title="Download PDF">pdf</a>, <a href="/ps/2401.07646" title="Download PostScript">ps</a>, <a href="/format/2401.07646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multifractal-spectral features enhance classification of anomalous  diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Seckler%2C+H">Henrik Seckler</a>, 
<a href="/search/nlin?searchtype=author&query=Metzler%2C+R">Ralf Metzler</a>, 
<a href="/search/nlin?searchtype=author&query=Kelty-Stephen%2C+D+G">Damian G. Kelty-Stephen</a>, 
<a href="/search/nlin?searchtype=author&query=Mangalam%2C+M">Madhur Mangalam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Anomalous diffusion processes pose a unique challenge in classification and
characterization. Previously (Mangalam et al., 2023, Physical Review Research
5, 023144), we established a framework for understanding anomalous diffusion
using multifractal formalism. The present study delves into the potential of
multifractal spectral features for effectively distinguishing anomalous
diffusion trajectories from five widely used models: fractional Brownian
motion, scaled Brownian motion, continuous time random walk, annealed transient
time motion, and L\'evy walk. To accomplish this, we generate extensive
datasets comprising $10^6$ trajectories from these five anomalous diffusion
models and extract multiple multifractal spectra from each trajectory. Our
investigation entails a thorough analysis of neural network performance,
encompassing features derived from varying numbers of spectra. Furthermore, we
explore the integration of multifractal spectra into traditional feature
datasets, enabling us to assess their impact comprehensively. To ensure a
statistically meaningful comparison, we categorize features into concept groups
and train neural networks using features from each designated group. Notably,
several feature groups demonstrate similar levels of accuracy, with the highest
performance observed in groups utilizing moving-window characteristics and
$p$-variation features. Multifractal spectral features, particularly those
derived from three spectra involving different timescales and cutoffs, closely
follow, highlighting their robust discriminatory potential. Remarkably, a
neural network exclusively trained on features from a single multifractal
spectrum exhibits commendable performance, surpassing other feature groups. Our
findings underscore the diverse and potent efficacy of multifractal spectral
features in enhancing classification of anomalous diffusion.
</p>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07681" title="Abstract">arXiv:2401.07681</a> (cross-list from eess.AS) [<a href="/pdf/2401.07681" title="Download PDF">pdf</a>, <a href="/format/2401.07681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of target signals and delays on spatially selective active noise  control for open-fitting hearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+T">Tong Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Doclo%2C+S">Simon Doclo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024 (c) 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Spatially selective active noise control (ANC) hearables are designed to
reduce unwanted noise from certain directions while preserving desired sounds
from other directions. In previous studies, the target signal has been defined
either as the delayed desired component in one of the reference microphone
signals or as the desired component in the error microphone signal without any
delay. In this paper, we systematically investigate the influence of delays in
different target signals on the ANC performance and provide an intuitive
explanation for how the system obtains the desired signal. Simulations were
conducted on a pair of open-fitting hearables for localized speech and noise
sources in an anechoic environment. The performance was assessed in terms of
noise reduction, signal quality and control effort. Results indicate that
optimal performance is achieved without delays when the target signal is
defined at the error microphone, whereas causality necessitates delays when the
target signal is defined at the reference microphone. The optimal delay is
found to be the acoustic delay between this reference microphone and the error
microphone from the desired source.
</p>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07694" title="Abstract">arXiv:2401.07694</a> (cross-list from math.OC) [<a href="/pdf/2401.07694" title="Download PDF">pdf</a>, <a href="/format/2401.07694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic optimization with arbitrary recurrent data sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Powell%2C+W+G">William G. Powell</a>, 
<a href="/search/math?searchtype=author&query=Lyu%2C+H">Hanbaek Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 3 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">For obtaining optimal first-order convergence guarantee for stochastic
optimization, it is necessary to use a recurrent data sampling algorithm that
samples every data point with sufficient frequency. Most commonly used data
sampling algorithms (e.g., i.i.d., MCMC, random reshuffling) are indeed
recurrent under mild assumptions. In this work, we show that for a particular
class of stochastic optimization algorithms, we do not need any other property
(e.g., independence, exponential mixing, and reshuffling) than recurrence in
data sampling algorithms to guarantee the optimal rate of first-order
convergence. Namely, using regularized versions of Minimization by Incremental
Surrogate Optimization (MISO), we show that for non-convex and possibly
non-smooth objective functions, the expected optimality gap converges at an
optimal rate $O(n^{-1/2})$ under general recurrent sampling schemes.
Furthermore, the implied constant depends explicitly on the `speed of
recurrence', measured by the expected amount of time to visit a given data
point either averaged (`target time') or supremized (`hitting time') over the
current location. We demonstrate theoretically and empirically that convergence
can be accelerated by selecting sampling algorithms that cover the data set
most effectively. We discuss applications of our general framework to
decentralized optimization and distributed non-negative matrix factorization.
</p>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07706" title="Abstract">arXiv:2401.07706</a> (cross-list from math.OC) [<a href="/pdf/2401.07706" title="Download PDF">pdf</a>, <a href="/format/2401.07706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Converse Lyapunov Results for Switched Systems with Lower and Upper  Bounds on Switching Intervals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Della+Rossa%2C+M">Matteo Della Rossa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The topic of this manuscript is the stability analysis of continuous-time
switched nonlinear systems with constraints on the admissible switching
signals. Our particular focus lies in considering signals characterized by
upper and lower bounds on the length of the switching intervals. We adapt and
extend the existing theory of multiple Lyapunov functions, providing converse
results and thus a complete characterization of uniform stability for this
class of systems. We specify our results in the context of switched linear
systems, providing the equivalence of exponential stability and the existence
of multiple Lyapunov norms. By restricting the class of candidate Lyapunov
functions to the set of quadratic functions, we are able to provide
semidefinite-optimization-based numerical schemes to check the proposed
conditions. We provide numerical examples to illustrate our approach and
highlight its advantages over existing methods.
</p>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07733" title="Abstract">arXiv:2401.07733</a> (cross-list from stat.ML) [<a href="/pdf/2401.07733" title="Download PDF">pdf</a>, <a href="/format/2401.07733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Approach To Gaussian Process Surrogate Evaluation With  Coverage Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Jaber%2C+E">Edgar Jaber</a> (EDF R&amp;D PRISME, CB, LISN), 
<a href="/search/stat?searchtype=author&query=Blot%2C+V">Vincent Blot</a> (The State of the Art AI company, LISN), 
<a href="/search/stat?searchtype=author&query=Brunel%2C+N">Nicolas Brunel</a> (The State of the Art AI company, ENSIIE), 
<a href="/search/stat?searchtype=author&query=Chabridon%2C+V">Vincent Chabridon</a> (EDF R&amp;D PRISME, SINCLAIR AI Lab), 
<a href="/search/stat?searchtype=author&query=Remy%2C+E">Emmanuel Remy</a> (EDF R&amp;D PRISME), 
<a href="/search/stat?searchtype=author&query=Iooss%2C+B">Bertrand Iooss</a> (EDF R&amp;D PRISME, IMT, SINCLAIR AI Lab, GdR MASCOT-NUM), 
<a href="/search/stat?searchtype=author&query=Lucor%2C+D">Didier Lucor</a> (LISN), 
<a href="/search/stat?searchtype=author&query=Mougeot%2C+M">Mathilde Mougeot</a> (CB, ENSIIE), 
<a href="/search/stat?searchtype=author&query=Leite%2C+A">Alessandro Leite</a> (LISN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Gaussian processes (GPs) are a Bayesian machine learning approach widely used
to construct surrogate models for the uncertainty quantification of computer
simulation codes in industrial applications. It provides both a mean predictor
and an estimate of the posterior prediction variance, the latter being used to
produce Bayesian credibility intervals. Interpreting these intervals relies on
the Gaussianity of the simulation model as well as the well-specification of
the priors which are not always appropriate. We propose to address this issue
with the help of conformal prediction. In the present work, a method for
building adaptive cross-conformal prediction intervals is proposed by weighting
the non-conformity score with the posterior standard deviation of the GP. The
resulting conformal prediction intervals exhibit a level of adaptivity akin to
Bayesian credibility sets and display a significant correlation with the
surrogate model local approximation error, while being free from the underlying
model assumptions and having frequentist coverage guarantees. These estimators
can thus be used for evaluating the quality of a GP surrogate model and can
assist a decision-maker in the choice of the best prior for the specific
application of the GP. The performance of the method is illustrated through a
panel of numerical examples based on various reference databases. Moreover, the
potential applicability of the method is demonstrated in the context of
surrogate modeling of an expensive-to-evaluate simulator of the clogging
phenomenon in steam generators of nuclear reactors.
</p>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07751" title="Abstract">arXiv:2401.07751</a> (cross-list from eess.IV) [<a href="/pdf/2401.07751" title="Download PDF">pdf</a>, <a href="/ps/2401.07751" title="Download PostScript">ps</a>, <a href="/format/2401.07751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepThalamus: A novel deep learning method for automatic segmentation of  brain thalamic nuclei from multimodal ultra-high resolution MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ruiz-Perez%2C+M">Marina Ruiz-Perez</a>, 
<a href="/search/eess?searchtype=author&query=Morell-Ortega%2C+S">Sergio Morell-Ortega</a>, 
<a href="/search/eess?searchtype=author&query=Gadea%2C+M">Marien Gadea</a>, 
<a href="/search/eess?searchtype=author&query=Vivo-Hernando%2C+R">Roberto Vivo-Hernando</a>, 
<a href="/search/eess?searchtype=author&query=Rubio%2C+G">Gregorio Rubio</a>, 
<a href="/search/eess?searchtype=author&query=Aparici%2C+F">Fernando Aparici</a>, 
<a href="/search/eess?searchtype=author&query=de+la+Iglesia-Vaya%2C+M">Mariam de la Iglesia-Vaya</a>, 
<a href="/search/eess?searchtype=author&query=Tourdias%2C+T">Thomas Tourdias</a>, 
<a href="/search/eess?searchtype=author&query=Coup%C3%A9%2C+P">Pierrick Coup&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Manj%C3%B3n%2C+J+V">Jos&#xe9; V. Manj&#xf3;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The implication of the thalamus in multiple neurological pathologies makes it
a structure of interest for volumetric analysis. In the present work, we have
designed and implemented a multimodal volumetric deep neural network for the
segmentation of thalamic nuclei at ultra-high resolution (0.125 mm3). Current
tools either operate at standard resolution (1 mm3) or use monomodal data. To
achieve the proposed objective, first, a database of semiautomatically
segmented thalamic nuclei was created using ultra-high resolution T1, T2 and
White Matter nulled (WMn) images. Then, a novel Deep learning based strategy
was designed to obtain the automatic segmentations and trained to improve its
robustness and accuaracy using a semisupervised approach. The proposed method
was compared with a related state-of-the-art method showing competitive results
both in terms of segmentation quality and efficiency. To make the proposed
method fully available to the scientific community, a full pipeline able to
work with monomodal standard resolution T1 images is also proposed.
</p>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07774" title="Abstract">arXiv:2401.07774</a> (cross-list from quant-ph) [<a href="/pdf/2401.07774" title="Download PDF">pdf</a>, <a href="/format/2401.07774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predominant Aspects on Security for Quantum Machine Learning: Literature  Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Franco%2C+N">Nicola Franco</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sakhnenko%2C+A">Alona Sakhnenko</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stolpmann%2C+L">Leon Stolpmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Thuerck%2C+D">Daniel Thuerck</a>, 
<a href="/search/quant-ph?searchtype=author&query=Petsch%2C+F">Fabian Petsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=R%C3%BCll%2C+A">Annika R&#xfc;ll</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lorenz%2C+J+M">Jeanette Miriam Lorenz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Quantum Machine Learning (QML) has emerged as a promising intersection of
quantum computing and classical machine learning, anticipated to drive
breakthroughs in computational tasks. This paper discusses the question which
security concerns and strengths are connected to QML by means of a systematic
literature review. We categorize and review the security of QML models, their
vulnerabilities inherent to quantum architectures, and the mitigation
strategies proposed. The survey reveals that while QML possesses unique
strengths, it also introduces novel attack vectors not seen in classical
systems. Techniques like adversarial training, quantum noise exploitation, and
quantum differential privacy have shown potential in enhancing QML robustness.
Our review discuss the need for continued and rigorous research to ensure the
secure deployment of QML in real-world applications. This work serves as a
foundational reference for researchers and practitioners aiming to navigate the
security aspects of QML.
</p>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07776" title="Abstract">arXiv:2401.07776</a> (cross-list from math.CO) [<a href="/pdf/2401.07776" title="Download PDF">pdf</a>, <a href="/ps/2401.07776" title="Download PostScript">ps</a>, <a href="/format/2401.07776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the clique number of tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aubian%2C+G">Guillaume Aubian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The clique number of a tournament is the maximum clique number of a graph
formed by keeping backwards arcs in an ordering of its vertices. We study the
time complexity of computing the clique number of a tournament and prove that,
for any integer $k \geq 3$, deciding whether a tournament has clique number at
most $k$ is NP-complete. This answers an interrogation of Nguyen, Scott and
Seymour. To do so, we make use of a construction which we then modify to
provide a counterexample to a conjecture of Aboulker, Aubian, Charbit and
Lopes.
</p>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07782" title="Abstract">arXiv:2401.07782</a> (cross-list from eess.IV) [<a href="/pdf/2401.07782" title="Download PDF">pdf</a>, <a href="/format/2401.07782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Masked Autoencoders for Sensor-Agnostic Image Retrieval in  Remote Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hackstein%2C+J">Jakob Hackstein</a>, 
<a href="/search/eess?searchtype=author&query=Sumbul%2C+G">Gencer Sumbul</a>, 
<a href="/search/eess?searchtype=author&query=Clasen%2C+K+N">Kai Norman Clasen</a>, 
<a href="/search/eess?searchtype=author&query=Demir%2C+B">Beg&#xfc;m Demir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Our code is available at <a href="https://github.com/jakhac/CSMAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Self-supervised learning through masked autoencoders (MAEs) has recently
attracted great attention for remote sensing (RS) image representation
learning, and thus embodies a significant potential for content-based image
retrieval (CBIR) from ever-growing RS image archives. However, the existing
studies on MAEs in RS assume that the considered RS images are acquired by a
single image sensor, and thus are only suitable for uni-modal CBIR problems.
The effectiveness of MAEs for cross-sensor CBIR, which aims to search
semantically similar images across different image modalities, has not been
explored yet. In this paper, we take the first step to explore the
effectiveness of MAEs for sensor-agnostic CBIR in RS. To this end, we present a
systematic overview on the possible adaptations of the vanilla MAE to exploit
masked image modeling on multi-sensor RS image archives (denoted as
cross-sensor masked autoencoders [CSMAEs]). Based on different adjustments
applied to the vanilla MAE, we introduce different CSMAE models. We also
provide an extensive experimental analysis of these CSMAE models. We finally
derive a guideline to exploit masked image modeling for uni-modal and
cross-modal CBIR problems in RS. The code of this work is publicly available at
https://github.com/jakhac/CSMAE.
</p>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07809" title="Abstract">arXiv:2401.07809</a> (cross-list from math.OC) [<a href="/pdf/2401.07809" title="Download PDF">pdf</a>, <a href="/format/2401.07809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Data Splitting in Distributed Optimization for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Medyakov%2C+D">Daniil Medyakov</a>, 
<a href="/search/math?searchtype=author&query=Molodtsov%2C+G">Gleb Molodtsov</a>, 
<a href="/search/math?searchtype=author&query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="/search/math?searchtype=author&query=Gasnikov%2C+A">Alexander Gasnikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 2 figures, Doklady Rossijskoj akademii nauk: <a href="https://journals.rcsi.science/2686-9543/article/view/247131">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The distributed optimization problem has become increasingly relevant
recently. It has a lot of advantages such as processing a large amount of data
in less time compared to non-distributed methods. However, most distributed
approaches suffer from a significant bottleneck - the cost of communications.
Therefore, a large amount of research has recently been directed at solving
this problem. One such approach uses local data similarity. In particular,
there exists an algorithm provably optimally exploiting the similarity
property. But this result, as well as results from other works solve the
communication bottleneck by focusing only on the fact that communication is
significantly more expensive than local computing and does not take into
account the various capacities of network devices and the different
relationship between communication time and local computing expenses. We
consider this setup and the objective of this study is to achieve an optimal
ratio of distributed data between the server and local machines for any costs
of communications and local computations. The running times of the network are
compared between uniform and optimal distributions. The superior theoretical
performance of our solutions is experimentally validated.
</p>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07849" title="Abstract">arXiv:2401.07849</a> (cross-list from eess.AS) [<a href="/pdf/2401.07849" title="Download PDF">pdf</a>, <a href="/format/2401.07849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparison of Frequency-Fusion Mechanisms for Binaural  Direction-of-Arrival Estimation for Multiple Speakers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fejgin%2C+D">Daniel Fejgin</a>, 
<a href="/search/eess?searchtype=author&query=Hadad%2C+E">Elior Hadad</a>, 
<a href="/search/eess?searchtype=author&query=Gannot%2C+S">Sharon Gannot</a>, 
<a href="/search/eess?searchtype=author&query=Koldovsk%C3%BD%2C+Z">Zbyn&#x11b;k Koldovsk&#xfd;</a>, 
<a href="/search/eess?searchtype=author&query=Doclo%2C+S">Simon Doclo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">To estimate the direction of arrival (DOA) of multiple speakers with methods
that use prototype transfer functions, frequency-dependent spatial spectra
(SPS) are usually constructed. To make the DOA estimation robust, SPS from
different frequencies can be combined. According to how the SPS are combined,
frequency fusion mechanisms are categorized into narrowband, broadband, or
speaker-grouped, where the latter mechanism requires a speaker-wise grouping of
frequencies. For a binaural hearing aid setup, in this paper we propose an
interaural time difference (ITD)-based speaker-grouped frequency fusion
mechanism. By exploiting the DOA dependence of ITDs, frequencies can be grouped
according to a common ITD and be used for DOA estimation of the respective
speaker. We apply the proposed ITD-based speaker-grouped frequency fusion
mechanism for different DOA estimation methods, namely the multiple signal
classification, steered response power and a recently published method based on
relative transfer function (RTF) vectors. In our experiments, we compare DOA
estimation with different fusion mechanisms. For all considered DOA estimation
methods, the proposed ITD-based speaker-grouped frequency fusion mechanism
results in a higher DOA estimation accuracy compared with the narrowband and
broadband fusion mechanisms.
</p>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07856" title="Abstract">arXiv:2401.07856</a> (cross-list from physics.optics) [<a href="/pdf/2401.07856" title="Download PDF">pdf</a>, <a href="/ps/2401.07856" title="Download PostScript">ps</a>, <a href="/format/2401.07856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information hiding cameras: optical concealment of object information  into ordinary images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bai%2C+B">Bijie Bai</a>, 
<a href="/search/physics?searchtype=author&query=Lee%2C+R">Ryan Lee</a>, 
<a href="/search/physics?searchtype=author&query=Li%2C+Y">Yuhang Li</a>, 
<a href="/search/physics?searchtype=author&query=Gan%2C+T">Tianyi Gan</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+Y">Yuntian Wang</a>, 
<a href="/search/physics?searchtype=author&query=Jarrahi%2C+M">Mona Jarrahi</a>, 
<a href="/search/physics?searchtype=author&query=Ozcan%2C+A">Aydogan Ozcan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 Pages, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Computer Vision and Pattern Recognition (cs.CV); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Data protection methods like cryptography, despite being effective,
inadvertently signal the presence of secret communication, thereby drawing
undue attention. Here, we introduce an optical information hiding camera
integrated with an electronic decoder, optimized jointly through deep learning.
This information hiding-decoding system employs a diffractive optical processor
as its front-end, which transforms and hides input images in the form of
ordinary-looking patterns that deceive/mislead human observers. This
information hiding transformation is valid for infinitely many combinations of
secret messages, all of which are transformed into ordinary-looking output
patterns, achieved all-optically through passive light-matter interactions
within the optical processor. By processing these ordinary-looking output
images, a jointly-trained electronic decoder neural network accurately
reconstructs the original information hidden within the deceptive output
pattern. We numerically demonstrated our approach by designing an information
hiding diffractive camera along with a jointly-optimized convolutional decoder
neural network. The efficacy of this system was demonstrated under various
lighting conditions and noise levels, showing its robustness. We further
extended this information hiding camera to multi-spectral operation, allowing
the concealment and decoding of multiple images at different wavelengths, all
performed simultaneously in a single feed-forward operation. The feasibility of
our framework was also demonstrated experimentally using THz radiation. This
optical encoder-electronic decoder-based co-design provides a novel information
hiding camera interface that is both high-speed and energy-efficient, offering
an intriguing solution for visual information security.
</p>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07912" title="Abstract">arXiv:2401.07912</a> (cross-list from quant-ph) [<a href="/pdf/2401.07912" title="Download PDF">pdf</a>, <a href="/format/2401.07912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lower Bounds for Unitary Property Testing with Proofs and Advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Weggemans%2C+J">Jordi Weggemans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">In unitary property testing a quantum algorithm, also known as a tester, is
given query access to a black-box unitary and has to decide whether it
satisfies some property. We propose a new technique for proving lower bounds on
the quantum query complexity of unitary property testing and related problems,
which utilises the connection between unitary property testing and unitary
channel discrimination. The main advantage of this technique is that all
obtained lower bounds hold for any $\mathsf{C}$-tester with $\mathsf{C}
\subseteq \mathsf{QMA}(\text{poly(n)} / \mathsf{qpoly}$, showing that even
having access to both (unentangled) quantum proofs and advice does not help for
many unitary problems. We apply our technique to prove lower bounds for
problems like quantum phase estimation, the entanglement entropy problem,
quantum Gibbs sampling and more, removing all logarithmic factors in the lower
bounds obtained by the sample-to-query lifting theorem of Wang and Zhang
(2023). As a direct corollary, we show that there exists a quantum oracle
relative to which $\mathsf{QMA}(\text{poly(n)} / \mathsf{qpoly} \not\supset
\mathsf{SBQP}$.
</p>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07937" title="Abstract">arXiv:2401.07937</a> (cross-list from q-bio.GN) [<a href="/pdf/2401.07937" title="Download PDF">pdf</a>, <a href="/format/2401.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrate Any Omics: Towards genome-wide data integration for patient  stratification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+S">Shihao Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Zeng%2C+A+G+X">Andy G.X. Zeng</a>, 
<a href="/search/q-bio?searchtype=author&query=Haibe-Kains%2C+B">Benjamin Haibe-Kains</a>, 
<a href="/search/q-bio?searchtype=author&query=Goldenberg%2C+A">Anna Goldenberg</a>, 
<a href="/search/q-bio?searchtype=author&query=Dick%2C+J+E">John E Dick</a>, 
<a href="/search/q-bio?searchtype=author&query=Wang%2C+B">Bo Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Genomics (q-bio.GN)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">High-throughput omics profiling advancements have greatly enhanced cancer
patient stratification. However, incomplete data in multi-omics integration
presents a significant challenge, as traditional methods like sample exclusion
or imputation often compromise biological diversity and dependencies.
Furthermore, the critical task of accurately classifying new patients with
partial omics data into existing subtypes is commonly overlooked. To address
these issues, we introduce IntegrAO (Integrate Any Omics), an unsupervised
framework for integrating incomplete multi-omics data and classifying new
samples. IntegrAO first combines partially overlapping patient graphs from
diverse omics sources and utilizes graph neural networks to produce unified
patient embeddings. Our systematic evaluation across five cancer cohorts
involving six omics modalities demonstrates IntegrAO's robustness to missing
data and its accuracy in classifying new samples with partial profiles. An
acute myeloid leukemia case study further validates its capability to uncover
biological and clinical heterogeneity in incomplete datasets. IntegrAO's
ability to handle heterogeneous and incomplete data makes it an essential tool
for precision oncology, offering a holistic approach to patient
characterization.
</p>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07957" title="Abstract">arXiv:2401.07957</a> (cross-list from eess.IV) [<a href="/pdf/2401.07957" title="Download PDF">pdf</a>, <a href="/ps/2401.07957" title="Download PostScript">ps</a>, <a href="/format/2401.07957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Perceptual Quality: Evaluating the Impact of Severe Lossy  Compression on Audio and Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jacobellis%2C+D">Dan Jacobellis</a>, 
<a href="/search/eess?searchtype=author&query=Cummings%2C+D">Daniel Cummings</a>, 
<a href="/search/eess?searchtype=author&query=Yadwadkar%2C+N+J">Neeraja J. Yadwadkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages; abridged version published in IEEE Data Compression Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the field of neural data compression, the prevailing focus has been on
optimizing algorithms for either classical distortion metrics, such as PSNR or
SSIM, or human perceptual quality. With increasing amounts of data consumed by
machines rather than humans, a new paradigm of machine-oriented
compression$\unicode{x2013}$which prioritizes the retention of features salient
for machine perception over traditional human-centric
criteria$\unicode{x2013}$has emerged, creating several new challenges to the
development, evaluation, and deployment of systems utilizing lossy compression.
In particular, it is unclear how different approaches to lossy compression will
affect the performance of downstream machine perception tasks. To address this
under-explored area, we evaluate various perception
models$\unicode{x2013}$including image classification, image segmentation,
speech recognition, and music source separation$\unicode{x2013}$under severe
lossy compression. We utilize several popular codecs spanning conventional,
neural, and generative compression architectures. Our results indicate three
key findings: (1) using generative compression, it is feasible to leverage
highly compressed data while incurring a negligible impact on machine
perceptual quality; (2) machine perceptual quality correlates strongly with
deep similarity metrics, indicating a crucial role of these metrics in the
development of machine-oriented codecs; and (3) using lossy compressed
datasets, (e.g. ImageNet) for pre-training can lead to counter-intuitive
scenarios where lossy compression increases machine perceptual quality rather
than degrading it. To encourage engagement on this growing area of research,
our code and experiments are available at:
https://github.com/danjacobellis/MPQ.
</p>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07961" title="Abstract">arXiv:2401.07961</a> (cross-list from math.OC) [<a href="/pdf/2401.07961" title="Download PDF">pdf</a>, <a href="/format/2401.07961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solution of the Probabilistic Lambert Problem: Connections with Optimal  Mass Transport, Schr&#xf6;dinger Bridge and Reaction-Diffusion PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Teter%2C+A+M+H">Alexis M.H. Teter</a>, 
<a href="/search/math?searchtype=author&query=Nodozi%2C+I">Iman Nodozi</a>, 
<a href="/search/math?searchtype=author&query=Halder%2C+A">Abhishek Halder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Mathematical Physics (math-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Lambert's problem concerns with transferring a spacecraft from a given
initial to a given terminal position within prescribed flight time via velocity
control subject to a gravitational force field. We consider a probabilistic
variant of the Lambert problem where the knowledge of the endpoint constraints
in position vectors are replaced by the knowledge of their respective joint
probability density functions. We show that the Lambert problem with endpoint
joint probability density constraints is a generalized optimal mass transport
(OMT) problem, thereby connecting this classical astrodynamics problem with a
burgeoning area of research in modern stochastic control and stochastic machine
learning. This newfound connection allows us to rigorously establish the
existence and uniqueness of solution for the probabilistic Lambert problem. The
same connection also helps to numerically solve the probabilistic Lambert
problem via diffusion regularization, i.e., by leveraging further connection of
the OMT with the Schr\"odinger bridge problem (SBP). This also shows that the
probabilistic Lambert problem with additive dynamic process noise is in fact a
generalized SBP, and can be solved numerically using the so-called
Schr\"odinger factors, as we do in this work. We explain how the resulting
analysis leads to solving a boundary-coupled system of reaction-diffusion PDEs
where the nonlinear gravitational potential appears as the reaction rate. We
propose novel algorithms for the same, and present illustrative numerical
results. Our analysis and the algorithmic framework are nonparametric, i.e., we
make neither statistical (e.g., Gaussian, first few moments, mixture or
exponential family, finite dimensionality of the sufficient statistic) nor
dynamical (e.g., Taylor series) approximations.
</p>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07969" title="Abstract">arXiv:2401.07969</a> (cross-list from nlin.CG) [<a href="/pdf/2401.07969" title="Download PDF">pdf</a>, <a href="/format/2401.07969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulated Autopoiesis in Liquid Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Battle%2C+S">Steve Battle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cellular Automata and Lattice Gases (nlin.CG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a novel form of Liquid Automata, using this to simulate
autopoiesis, whereby living machines self-organise in the physical realm. This
simulation is based on an earlier Cellular Automaton described by Francisco
Varela. The basis of Liquid Automata is a particle simulation with additional
rules about how particles are transformed on collision with other particles.
Unlike cellular automata, there is no fixed grid or time-step, only particles
moving about and colliding with each other in a continuous space/time.
</p>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07971" title="Abstract">arXiv:2401.07971</a> (cross-list from stat.CO) [<a href="/pdf/2401.07971" title="Download PDF">pdf</a>, <a href="/format/2401.07971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tractable Optimal Experimental Design using Transport Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Koval%2C+K">Karina Koval</a>, 
<a href="/search/stat?searchtype=author&query=Herzog%2C+R">Roland Herzog</a>, 
<a href="/search/stat?searchtype=author&query=Scheichl%2C+R">Robert Scheichl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA); Optimization and Control (math.OC)

</div>
<p class="mathjax">We present a flexible method for computing Bayesian optimal experimental
designs (BOEDs) for inverse problems with intractable posteriors. The approach
is applicable to a wide range of BOED problems and can accommodate various
optimality criteria, prior distributions and noise models. The key to our
approach is the construction of a transport-map-based surrogate to the joint
probability law of the design, observational and inference random variables.
This order-preserving transport map is constructed using tensor trains and can
be used to efficiently sample from (and evaluate approximate densities of)
conditional distributions that are used to define many commonly-used optimality
criteria. The algorithm is also extended to sequential data acquisition
problems, where experiments can be performed in sequence and used to update the
state of knowledge about the unknown parameters. The sequential BOED problem is
made computationally feasible by preconditioning the approximation of the joint
density at the current stage using transport maps constructed at previous
stages. The flexibility of our approach in finding optimal designs is
illustrated with some numerical examples inspired by disease modeling and the
reconstruction of subsurface structures in aquifers.
</p>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07974" title="Abstract">arXiv:2401.07974</a> (cross-list from quant-ph) [<a href="/pdf/2401.07974" title="Download PDF">pdf</a>, <a href="/format/2401.07974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Space-Time Cost of Purifying Quantum Computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhandry%2C+M">Mark Zhandry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ITCS'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">General quantum computation consists of unitary operations and also
measurements. It is well known that intermediate quantum measurements can be
deferred to the end of the computation, resulting in an equivalent purely
unitary computation. While time efficient, this transformation blows up the
space to linear in the running time, which could be super-polynomial for
low-space algorithms. Fefferman and Remscrim (STOC'21) and Girish, Raz and Zhan
(ICALP'21) show different transformations which are space efficient, but blow
up the running time by a factor that is exponential in the space. This leaves
the case of algorithms with small-but-super-logarithmic space as incurring a
large blowup in either time or space complexity. We show that such a blowup is
likely inherent, demonstrating that any "black-box" transformation which
removes intermediate measurements must significantly blow up either space or
time.
</p>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07988" title="Abstract">arXiv:2401.07988</a> (cross-list from eess.SP) [<a href="/pdf/2401.07988" title="Download PDF">pdf</a>, <a href="/format/2401.07988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Metasurface-Based Receivers with $1$-bit ADCs for Multi-User Uplink  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gavriilidis%2C+P">Panagiotis Gavriilidis</a>, 
<a href="/search/eess?searchtype=author&query=Atzeni%2C+I">Italo Atzeni</a>, 
<a href="/search/eess?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, to be presented in IEEE ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Emerging Technologies (cs.ET); Information Theory (cs.IT)

</div>
<p class="mathjax">The massive Multiple-Input Multiple-Output (mMIMO) concept has been recently
moving forward to extreme scales to address the envisioned requirements of next
generation networks. However, the extension of conventional architectures will
result in significant cost and power consumption. To this end,
metasurface-based transceivers, consisting of microstrips of metamaterials,
have recently emerged as an efficient enabler of extreme mMIMO systems. In this
paper, we consider metasurface-based receivers with a $1$-bit Analog-to-Digital
Converter (ADC) per microstrip and develop an analytical framework for the
optimization of the analog and digital combining matrices. Our numerical
results, including comparisons with fully digital, infinite-resolution MIMO,
provide useful insights into the role of various system parameters.
</p>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07990" title="Abstract">arXiv:2401.07990</a> (cross-list from eess.IV) [<a href="/pdf/2401.07990" title="Download PDF">pdf</a>, <a href="/format/2401.07990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does self-supervised pretraining improve robustness against noisy  labels across various medical image classification datasets?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khanal%2C+B">Bidur Khanal</a>, 
<a href="/search/eess?searchtype=author&query=Bhattarai%2C+B">Binod Bhattarai</a>, 
<a href="/search/eess?searchtype=author&query=Khanal%2C+B">Bishesh Khanal</a>, 
<a href="/search/eess?searchtype=author&query=Linte%2C+C">Cristian Linte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Noisy labels can significantly impact medical image classification,
particularly in deep learning, by corrupting learned features. Self-supervised
pretraining, which doesn't rely on labeled data, can enhance robustness against
noisy labels. However, this robustness varies based on factors like the number
of classes, dataset complexity, and training size. In medical images, subtle
inter-class differences and modality-specific characteristics add complexity.
Previous research hasn't comprehensively explored the interplay between
self-supervised learning and robustness against noisy labels in medical image
classification, considering all these factors. In this study, we address three
key questions: i) How does label noise impact various medical image
classification datasets? ii) Which types of medical image datasets are more
challenging to learn and more affected by label noise? iii) How do different
self-supervised pretraining methods enhance robustness across various medical
image datasets? Our results show that DermNet, among five datasets (Fetal
plane, DermNet, COVID-DU-Ex, MURA, NCT-CRC-HE-100K), is the most challenging
but exhibits greater robustness against noisy labels. Additionally, contrastive
learning stands out among the eight self-supervised methods as the most
effective approach to enhance robustness against noisy labels.
</p>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08032" title="Abstract">arXiv:2401.08032</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.08032" title="Download PDF">pdf</a>, <a href="/format/2401.08032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-based out-of-distribution (OOD) materials property prediction:  a benchmark study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Omee%2C+S+S">Sadman Sadeed Omee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fu%2C+N">Nihang Fu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Dong%2C+R">Rongzhi Dong</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hu%2C+M">Ming Hu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hu%2C+J">Jianjun Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In real-world material research, machine learning (ML) models are usually
expected to predict and discover novel exceptional materials that deviate from
the known materials. It is thus a pressing question to provide an objective
evaluation of ML model performances in property prediction of
out-of-distribution (OOD) materials that are different from the training set
distribution. Traditional performance evaluation of materials property
prediction models through random splitting of the dataset frequently results in
artificially high performance assessments due to the inherent redundancy of
typical material datasets. Here we present a comprehensive benchmark study of
structure-based graph neural networks (GNNs) for extrapolative OOD materials
property prediction. We formulate five different categories of OOD ML problems
for three benchmark datasets from the MatBench study. Our extensive experiments
show that current state-of-the-art GNN algorithms significantly underperform
for the OOD property prediction tasks on average compared to their baselines in
the MatBench study, demonstrating a crucial generalization gap in realistic
material prediction tasks. We further examine the latent physical spaces of
these GNN models and identify the sources of CGCNN, ALIGNN, and DeeperGATGNN's
significantly more robust OOD performance than those of the current best models
in the MatBench study (coGN and coNGN), and provide insights to improve their
performance.
</p>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08041" title="Abstract">arXiv:2401.08041</a> (cross-list from math.OC) [<a href="/pdf/2401.08041" title="Download PDF">pdf</a>, <a href="/ps/2401.08041" title="Download PostScript">ps</a>, <a href="/format/2401.08041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Stage Distributionally Robust Edge Node Placement Under Endogenous  Demand Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cheng%2C+J">Jiaming Cheng</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+D+T+A">Duong Thuy Anh Nguyen</a>, 
<a href="/search/math?searchtype=author&query=Nguyen%2C+D+T">Duong Tung Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Edge computing (EC) promises to deliver low-latency and ubiquitous
computation to numerous devices at the network edge. This paper aims to jointly
optimize edge node (EN) placement and resource allocation for an EC platform,
considering demand uncertainty. Diverging from existing approaches treating
uncertainties as exogenous, we propose a novel two-stage decision-dependent
distributionally robust optimization (DRO) framework to effectively capture the
interdependence between EN placement decisions and uncertain demands. The first
stage involves making EN placement decisions, while the second stage optimizes
resource allocation after uncertainty revelation. We present an exact
mixed-integer linear program reformulation for solving the underlying
``min-max-min" two-stage model. We further introduce a valid inequality method
to enhance computational efficiency, especially for large-scale networks.
Extensive numerical experiments demonstrate the benefits of considering
endogenous uncertainties and the advantages of the proposed model and approach.
</p>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08064" title="Abstract">arXiv:2401.08064</a> (cross-list from econ.GN) [<a href="/pdf/2401.08064" title="Download PDF">pdf</a>, <a href="/ps/2401.08064" title="Download PostScript">ps</a>, <a href="/format/2401.08064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new model of trust based on neural information processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Allen%2C+S+E">Scott E. Allen</a>, 
<a href="/search/econ?searchtype=author&query=Kizilcec%2C+R+F">Ren&#xe9; F. Kizilcec</a>, 
<a href="/search/econ?searchtype=author&query=Redish%2C+A+D">A. David Redish</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Human-Computer Interaction (cs.HC); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">More than 30 years of research has firmly established the vital role of trust
in human organizations and relationships, but the underlying mechanisms by
which people build, lose, and rebuild trust remains incompletely understood. We
propose a mechanistic model of trust that is grounded in the modern
neuroscience of decision making. Since trust requires anticipating the future
actions of others, any mechanistic model must be built upon up-to-date theories
on how the brain learns, represents, and processes information about the future
within its decision-making systems. Contemporary neuroscience has revealed that
decision making arises from multiple parallel systems that perform distinct,
complementary information processing. Each system represents information in
different forms, and therefore learns via different mechanisms. When an act of
trust is reciprocated or violated, this provides new information that can be
used to anticipate future actions. The taxonomy of neural information
representations that is the basis for the system boundaries between neural
decision-making systems provides a taxonomy for categorizing different forms of
trust and generating mechanistic predictions about how these forms of trust are
learned and manifested in human behavior. Three key predictions arising from
our model are (1) strategic risk-taking can reveal how to best proceed in a
relationship, (2) human organizations and environments can be intentionally
designed to encourage trust among their members, and (3) violations of trust
need not always degrade trust, but can also provide opportunities to build
trust.
</p>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08150" title="Abstract">arXiv:2401.08150</a> (cross-list from stat.ML) [<a href="/pdf/2401.08150" title="Download PDF">pdf</a>, <a href="/format/2401.08150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Sliced Inverse Regression: Minimax Optimality and  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Xia%2C+X">Xintao Xia</a>, 
<a href="/search/stat?searchtype=author&query=Zhang%2C+L">Linjun Zhang</a>, 
<a href="/search/stat?searchtype=author&query=Cai%2C+Z">Zhanrui Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">Privacy preservation has become a critical concern in high-dimensional data
analysis due to the growing prevalence of data-driven applications. Proposed by
Li (1991), sliced inverse regression has emerged as a widely utilized
statistical technique for reducing covariate dimensionality while maintaining
sufficient statistical information. In this paper, we propose optimally
differentially private algorithms specifically designed to address privacy
concerns in the context of sufficient dimension reduction. We proceed to
establish lower bounds for differentially private sliced inverse regression in
both the low and high-dimensional settings. Moreover, we develop differentially
private algorithms that achieve the minimax lower bounds up to logarithmic
factors. Through a combination of simulations and real data analysis, we
illustrate the efficacy of these differentially private algorithms in
safeguarding privacy while preserving vital information within the reduced
dimension space. As a natural extension, we can readily offer analogous lower
and upper bounds for differentially private sparse principal component
analysis, a topic that may also be of potential interest to the statistical and
machine learning community.
</p>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08166" title="Abstract">arXiv:2401.08166</a> (cross-list from eess.AS) [<a href="/pdf/2401.08166" title="Download PDF">pdf</a>, <a href="/format/2401.08166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ED-TTS: Multi-Scale Emotion Modeling using Cross-Domain Emotion  Diarization for Emotional Speech Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tang%2C+H">Haobin Tang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xulong Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+N">Ning Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Existing emotional speech synthesis methods often utilize an utterance-level
style embedding extracted from reference audio, neglecting the inherent
multi-scale property of speech prosody. We introduce ED-TTS, a multi-scale
emotional speech synthesis model that leverages Speech Emotion Diarization
(SED) and Speech Emotion Recognition (SER) to model emotions at different
levels. Specifically, our proposed approach integrates the utterance-level
emotion embedding extracted by SER with fine-grained frame-level emotion
embedding obtained from SED. These embeddings are used to condition the reverse
process of the denoising diffusion probabilistic model (DDPM). Additionally, we
employ cross-domain SED to accurately predict soft labels, addressing the
challenge of a scarcity of fine-grained emotion-annotated datasets for
supervising emotional TTS training.
</p>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08167" title="Abstract">arXiv:2401.08167</a> (cross-list from math.ST) [<a href="/pdf/2401.08167" title="Download PDF">pdf</a>, <a href="/format/2401.08167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental limits of community detection from multi-view data:  multi-layer, dynamic and partially labeled block models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xiaodong Yang</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+B">Buyu Lin</a>, 
<a href="/search/math?searchtype=author&query=Sen%2C+S">Subhabrata Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 75 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Information Theory (cs.IT); Social and Information Networks (cs.SI); Probability (math.PR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Multi-view data arises frequently in modern network analysis e.g. relations
of multiple types among individuals in social network analysis, longitudinal
measurements of interactions among observational units, annotated networks with
noisy partial labeling of vertices etc. We study community detection in these
disparate settings via a unified theoretical framework, and investigate the
fundamental thresholds for community recovery. We characterize the mutual
information between the data and the latent parameters, provided the degrees
are sufficiently large. Based on this general result, (i) we derive a sharp
threshold for community detection in an inhomogeneous multilayer block model
\citep{chen2022global}, (ii) characterize a sharp threshold for weak recovery
in a dynamic stochastic block model \citep{matias2017statistical}, and (iii)
identify the limiting mutual information in an unbalanced partially labeled
block model. Our first two results are derived modulo coordinate-wise convexity
assumptions on specific functions -- we provide extensive numerical evidence
for their correctness. Finally, we introduce iterative algorithms based on
Approximate Message Passing for community detection in these problems.
</p>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08169" title="Abstract">arXiv:2401.08169</a> (cross-list from stat.ML) [<a href="/pdf/2401.08169" title="Download PDF">pdf</a>, <a href="/format/2401.08169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Test for Attention Map in Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shiraishi%2C+T">Tomohiro Shiraishi</a>, 
<a href="/search/stat?searchtype=author&query=Miwa%2C+D">Daiki Miwa</a>, 
<a href="/search/stat?searchtype=author&query=Katsuoka%2C+T">Teruyuki Katsuoka</a>, 
<a href="/search/stat?searchtype=author&query=Duy%2C+V+N+L">Vo Nguyen Le Duy</a>, 
<a href="/search/stat?searchtype=author&query=Taji%2C+K">Koichi Taji</a>, 
<a href="/search/stat?searchtype=author&query=Takeuchi%2C+I">Ichiro Takeuchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42pages, 17figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The Vision Transformer (ViT) demonstrates exceptional performance in various
computer vision tasks. Attention is crucial for ViT to capture complex
wide-ranging relationships among image patches, allowing the model to weigh the
importance of image patches and aiding our understanding of the decision-making
process. However, when utilizing the attention of ViT as evidence in
high-stakes decision-making tasks such as medical diagnostics, a challenge
arises due to the potential of attention mechanisms erroneously focusing on
irrelevant regions. In this study, we propose a statistical test for ViT's
attentions, enabling us to use the attentions as reliable quantitative evidence
indicators for ViT's decision-making with a rigorously controlled error rate.
Using the framework called selective inference, we quantify the statistical
significance of attentions in the form of p-values, which enables the
theoretically grounded quantification of the false positive detection
probability of attentions. We demonstrate the validity and the effectiveness of
the proposed method through numerical experiments and applications to brain
image diagnoses.
</p>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08180" title="Abstract">arXiv:2401.08180</a> (cross-list from physics.optics) [<a href="/pdf/2401.08180" title="Download PDF">pdf</a>, <a href="/format/2401.08180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-free and efficient silicon photonic neural networks via  hardware-aware training and pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xu%2C+T">Tengji Xu</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+W">Weipeng Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+Z">Zeyu Luo</a>, 
<a href="/search/physics?searchtype=author&query=Xiao%2C+Q">Qiarong Xiao</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+B">Benshan Wang</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+M">Mingcheng Luo</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+X">Xingyuan Xu</a>, 
<a href="/search/physics?searchtype=author&query=Shastri%2C+B+J">Bhavin J. Shastri</a>, 
<a href="/search/physics?searchtype=author&query=Prucnal%2C+P+R">Paul R. Prucnal</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+C">Chaoran Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET); Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Silicon photonic neural networks (PNNs) utilizing wavelength-multiplexing
approaches, such as those based on micro-ring resonators (MRRs), offer superior
performance due to their weight assignment, exceptional energy efficiency, and
high computing density achieved through small device footprints. However, MRRs
are highly sensitive to ambient disturbance, with even slight resonance drifts
of tens of picometers potentially compromising MRRs-based PNNs. Current
solutions often rely on complex control methods, resulting in high hardware
complexity impractical for large-scale PNNs. Here, we propose a novel
hardware-aware training and pruning approach. The core idea is to train the
parameters of a physical neural network towards its noise-robust and
energy-efficient region. This innovation enables control-free and
energy-efficient photonic computing. Experimentally, this method improves
computing precision by 4 bits without requiring intricate MRR control or
power-consuming temperature stabilization circuits. It notably increases the
accuracy of experimental handwritten digit classification from 67.0%, initially
impacted by the thermal variances, to 95.0%, a figure comparable to the
theoretical value and achieved without a thermoelectric controller.
Additionally, this approach reduces the energy required to tune the MRRs
ten-fold. Furthermore, our numerical verification indicates that this method is
broadly applicable across various NN sizes and machine-learning tasks. Its
effectiveness is particularly marked in larger NNs, where it boosts accuracy
from 10.9% to 98.0% and slashes power consumption by 160 times. This
advancement represents a significant step towards the practical,
energy-efficient, and noise-resilient implementation of large-scale integrated
PNNs.
</p>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08183" title="Abstract">arXiv:2401.08183</a> (cross-list from eess.SP) [<a href="/pdf/2401.08183" title="Download PDF">pdf</a>, <a href="/ps/2401.08183" title="Download PostScript">ps</a>, <a href="/format/2401.08183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Over-the-Air Federated Learning with Phase Noise: Analysis and  Countermeasures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dahl%2C+M">Martin Dahl</a>, 
<a href="/search/eess?searchtype=author&query=Larsson%2C+E+G">Erik G. Larsson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in CISS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Wirelessly connected devices can collaborately train a machine learning model
using federated learning, where the aggregation of model updates occurs using
over-the-air computation. Carrier frequency offset caused by imprecise clocks
in devices will cause the phase of the over-the-air channel to drift randomly,
such that late symbols in a coherence block are transmitted with lower quality
than early symbols. To mitigate the effect of degrading symbol quality, we
propose a scheme where one of the permutations Roll, Flip and Sort are applied
on gradients before transmission. Through simulations we show that the
permutations can both improve and degrade learning performance. Furthermore, we
derive the expectation and variance of the gradient estimate, which is shown to
grow exponentially with the number of symbols in a coherence block.
</p>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08186" title="Abstract">arXiv:2401.08186</a> (cross-list from eess.SP) [<a href="/pdf/2401.08186" title="Download PDF">pdf</a>, <a href="/format/2401.08186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Index Modulation for Integrated Sensing and Communications: A Signal  Processing Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elbir%2C+A+M">Ahmet M. Elbir</a>, 
<a href="/search/eess?searchtype=author&query=Celik%2C+A">Abdulkadir Celik</a>, 
<a href="/search/eess?searchtype=author&query=Eltawil%2C+A+M">Ahmed M. Eltawil</a>, 
<a href="/search/eess?searchtype=author&query=Amin%2C+M+G">Moeness G. Amin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11pages5figures, submitted to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">A joint design of both sensing and communication can lead to substantial
enhancement for both subsystems in terms of size, cost as well as spectrum and
hardware efficiency. In the last decade, integrated sensing and communications
(ISAC) has emerged as a means to efficiently utilize the spectrum on a single
and shared hardware platform. Recent studies focused on developing
multi-function approaches to share the spectrum between radar sensing and
communications. Index modulation (IM) is one particular approach to incorporate
information-bearing communication symbols into the emitted radar waveforms.
While IM has been well investigated in communications-only systems, the
implementation adoption of IM concept in ISAC has recently attracted
researchers to achieve improved energy/spectral efficiency while maintaining
satisfactory radar sensing performance. This article focuses on recent studies
on IM-ISAC, and presents in detail the analytical background and relevance of
the major IM-ISAC applications.
</p>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08224" title="Abstract">arXiv:2401.08224</a> (cross-list from stat.ME) [<a href="/pdf/2401.08224" title="Download PDF">pdf</a>, <a href="/format/2401.08224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Estimation of CATE in Adaptive Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Li%2C+J">Jiachun Li</a>, 
<a href="/search/stat?searchtype=author&query=Simchi-Levi%2C+D">David Simchi-Levi</a>, 
<a href="/search/stat?searchtype=author&query=Shi%2C+K">Kaining Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adaptive experiment is widely adopted to estimate conditional average
treatment effect (CATE) in clinical trials and many other scenarios. While the
primary goal in experiment is to maximize estimation accuracy, due to the
imperative of social welfare, it's also crucial to provide treatment with
superior outcomes to patients, which is measured by regret in contextual bandit
framework. These two objectives often lead to contrast optimal allocation
mechanism. Furthermore, privacy concerns arise in clinical scenarios containing
sensitive data like patients health records. Therefore, it's essential for the
treatment allocation mechanism to incorporate robust privacy protection
measures. In this paper, we investigate the tradeoff between loss of social
welfare and statistical power in contextual bandit experiment. We propose a
matched upper and lower bound for the multi-objective optimization problem, and
then adopt the concept of Pareto optimality to mathematically characterize the
optimality condition. Furthermore, we propose differentially private algorithms
which still matches the lower bound, showing that privacy is "almost free".
Additionally, we derive the asymptotic normality of the estimator, which is
essential in statistical inference and hypothesis testing.
</p>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08237" title="Abstract">arXiv:2401.08237</a> (cross-list from eess.SP) [<a href="/pdf/2401.08237" title="Download PDF">pdf</a>, <a href="/format/2401.08237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Far- versus Near-Field RIS Modeling and Beam Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Delbari%2C+M">Mohamadreza Delbari</a>, 
<a href="/search/eess?searchtype=author&query=Alexandropoulos%2C+G+C">George C. Alexandropoulos</a>, 
<a href="/search/eess?searchtype=author&query=Schober%2C+R">Robert Schober</a>, 
<a href="/search/eess?searchtype=author&query=Jamali%2C+V">Vahid Jamali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this chapter, we investigate the mathematical foundation of the modeling
and design of reconfigurable intelligent surfaces (RIS) in both the far- and
near-field regimes. More specifically, we first present RIS-assisted wireless
channel models for the far- and near-field regimes, discussing relevant
phenomena, such as line-of-sight (LOS) and non-LOS links, rich and poor
scattering, channel correlation, and array manifold. Subsequently, we introduce
two general approaches for the RIS reflective beam design, namely
optimization-based and analytical, which offer different degrees of design
flexibility and computational complexity. Furthermore, we provide a
comprehensive set of simulation results for the performance evaluation of the
studied RIS beam designs and the investigation of the impact of the system
parameters.
</p>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08268" title="Abstract">arXiv:2401.08268</a> (cross-list from eess.AS) [<a href="/pdf/2401.08268" title="Download PDF">pdf</a>, <a href="/format/2401.08268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable Proxy Model for Multiabel Audio Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mariotte%2C+T">Th&#xe9;o Mariotte</a>, 
<a href="/search/eess?searchtype=author&query=Almud%C3%A9var%2C+A">Antonio Almud&#xe9;var</a>, 
<a href="/search/eess?searchtype=author&query=Tahon%2C+M">Marie Tahon</a>, 
<a href="/search/eess?searchtype=author&query=Ortega%2C+A">Alsonfo Ortega</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Audio signal segmentation is a key task for automatic audio indexing. It
consists of detecting the boundaries of class-homogeneous segments in the
signal. In many applications, explainable AI is a vital process for
transparency of decision-making with machine learning. In this paper, we
propose an explainable multilabel segmentation model that solves speech
activity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD)
simultaneously. This proxy uses the non-negative matrix factorization (NMF) to
map the embedding used for the segmentation to the frequency domain.
Experiments conducted on two datasets show similar performances as the
pre-trained black box model while showing strong explainability features.
Specifically, the frequency bins used for the decision can be easily identified
at both the segment level (local explanations) and global level (class
prototypes).
</p>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08301" title="Abstract">arXiv:2401.08301</a> (cross-list from eess.SP) [<a href="/pdf/2401.08301" title="Download PDF">pdf</a>, <a href="/ps/2401.08301" title="Download PostScript">ps</a>, <a href="/format/2401.08301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sum Throughput Maximization in Multi-BD Symbiotic Radio NOMA Network  Assisted by Active-STAR-RIS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yeganeh%2C+R+S">Rahman Saadat Yeganeh</a>, 
<a href="/search/eess?searchtype=author&query=Omidi%2C+M+J">Mohammad Javad Omidi</a>, 
<a href="/search/eess?searchtype=author&query=Zeinali%2C+F">Farshad Zeinali</a>, 
<a href="/search/eess?searchtype=author&query=Robatmili%2C+M">Mohammad Robatmili</a>, 
<a href="/search/eess?searchtype=author&query=Ghavami%2C+M">Mohammad Ghavami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article will be submitted to the Transactions journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we employ active simultaneously transmitting and reflecting
reconfigurable intelligent surface (ASRIS) to aid in establishing and enhancing
communication within a commensal symbiotic radio (CSR) network. Unlike
traditional RIS, ASRIS not only ensures coverage in an omni directional manner
but also amplifies received signals, consequently elevating overall network
performance. in the first phase, base station (BS) with active massive MIMO
antennas, send ambient signal to SBDs. In the first phase, the BS transmits
ambient signals to the symbiotic backscatter devices (SBDs), and after
harvesting the energy and modulating their information onto the signal carrier,
the SBDs send Backscatter signals back to the BS. In this scheme, we employ the
Backscatter Relay system to facilitate the transmission of information from the
SBDs to the symbiotic User Equipments (SUEs) with the assistance of the BS. In
the second phase, the BS transmits information signals to the SUEs after
eliminating interference using the Successive Interference Cancellation (SIC)
method. ASRIS is employed to establish communication among SUEs lacking a line
of sight (LoS) and to amplify power signals for SUEs with a LoS connection to
the BS. It is worth noting that we use NOMA for multiple access in all network.
<br />The main goal of this paper is to maximize the sum throughput between all
users. To achieve this, we formulate an optimization problem with variables
including active beamforming coefficients at the BS and ASRIS, as well as the
phase adjustments of ASRIS and scheduling parameters between the first and
second phases. To model this optimization problem, we employ three deep
reinforcement learning (DRL) methods, namely PPO, TD3, and A3C. Finally, the
mentioned methods are simulated and compared with each other.
</p>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08302" title="Abstract">arXiv:2401.08302</a> (cross-list from q-fin.TR) [<a href="/pdf/2401.08302" title="Download PDF">pdf</a>, <a href="/ps/2401.08302" title="Download PostScript">ps</a>, <a href="/format/2401.08302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do backrun auctions protect traders?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Macpherson%2C+A+W">Andrew W. Macpherson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: MEV, queue discipline, sandwich, CFMM, arbitrage, blockchain, Ethereum
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study a new "laminated" queueing model for orders on batched trading
venues such as decentralised exchanges. The model aims to capture and
generalise transaction queueing infrastructure that has arisen to organise MEV
activity on public blockchains such as Ethereum, providing convenient channels
for sophisticated agents to extract value by acting on end-user order flow by
performing arbitrage and related HFT activities. In our model, market orders
are interspersed with orders created by arbitrageurs that under idealised
conditions reset the marginal price to a global equilibrium between each trade,
improving predictability of execution for liquidity traders.
<br />If an arbitrageur has a chance to land multiple opportunities in a row, he
may attempt to manipulate the execution price of the intervening market order
by a probabilistic blind sandwiching strategy. To study how bad this
manipulation can get, we introduce and bound a price manipulation coefficient
that measures the deviation from global equilibrium of local pricing quoted by
a rational arbitrageur. We exhibit cases in which this coefficient is well
approximated by a "zeta value' with interpretable and empirically measurable
parameters.
</p>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08307" title="Abstract">arXiv:2401.08307</a> (cross-list from quant-ph) [<a href="/pdf/2401.08307" title="Download PDF">pdf</a>, <a href="/format/2401.08307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Quantum Natural Policy Gradients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sequeira%2C+A">Andr&#xe9; Sequeira</a>, 
<a href="/search/quant-ph?searchtype=author&query=Santos%2C+L+P">Luis Paulo Santos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Barbosa%2C+L+S">Luis Soares Barbosa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research delves into the role of the quantum Fisher Information Matrix
(FIM) in enhancing the performance of Parameterized Quantum Circuit (PQC)-based
reinforcement learning agents. While previous studies have highlighted the
effectiveness of PQC-based policies preconditioned with the quantum FIM in
contextual bandits, its impact in broader reinforcement learning contexts, such
as Markov Decision Processes, is less clear. Through a detailed analysis of
L\"owner inequalities between quantum and classical FIMs, this study uncovers
the nuanced distinctions and implications of using each type of FIM. Our
results indicate that a PQC-based agent using the quantum FIM without
additional insights typically incurs a larger approximation error and does not
guarantee improved performance compared to the classical FIM. Empirical
evaluations in classic control benchmarks suggest even though quantum FIM
preconditioning outperforms standard gradient ascent, in general it is not
superior to classical FIM preconditioning.
</p>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08355" title="Abstract">arXiv:2401.08355</a> (cross-list from quant-ph) [<a href="/pdf/2401.08355" title="Download PDF">pdf</a>, <a href="/format/2401.08355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multidimensional Quantum Walks, Recursion, and Quantum Divide &amp; Conquer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jeffery%2C+S">Stacey Jeffery</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pass%2C+G">Galina Pass</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We introduce an object called a subspace graph that formalizes the technique
of multidimensional quantum walks. Composing subspace graphs allows one to
seamlessly combine quantum and classical reasoning, keeping a classical
structure in mind, while abstracting quantum parts into subgraphs with simple
boundaries as need. As an example, we show how to combine a switching network
with arbitrary quantum subroutines, to compute a composed function. As another
application, we give a time-efficient implementation of quantum Divide &amp;
Conquer when the sub-problems are combined via a symmetric Boolean formula. We
use this to quadratically speed up Savitch's algorithm for directed
$st$-connectivity.
</p>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08375" title="Abstract">arXiv:2401.08375</a> (cross-list from stat.ML) [<a href="/pdf/2401.08375" title="Download PDF">pdf</a>, <a href="/format/2401.08375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse PCA with False Discovery Rate Controlled Variable Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Machkour%2C+J">Jasin Machkour</a>, 
<a href="/search/stat?searchtype=author&query=Breloy%2C+A">Arnaud Breloy</a>, 
<a href="/search/stat?searchtype=author&query=Muma%2C+M">Michael Muma</a>, 
<a href="/search/stat?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>, 
<a href="/search/stat?searchtype=author&query=Pascal%2C+F">Fr&#xe9;d&#xe9;ric Pascal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), scheduled for 14-19 April 2024 in Seoul, Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sparse principal component analysis (PCA) aims at mapping large dimensional
data to a linear subspace of lower dimension. By imposing loading vectors to be
sparse, it performs the double duty of dimension reduction and variable
selection. Sparse PCA algorithms are usually expressed as a trade-off between
explained variance and sparsity of the loading vectors (i.e., number of
selected variables). As a high explained variance is not necessarily synonymous
with relevant information, these methods are prone to select irrelevant
variables. To overcome this issue, we propose an alternative formulation of
sparse PCA driven by the false discovery rate (FDR). We then leverage the
Terminating-Random Experiments (T-Rex) selector to automatically determine an
FDR-controlled support of the loading vectors. A major advantage of the
resulting T-Rex PCA is that no sparsity parameter tuning is required. Numerical
experiments and a stock market data example demonstrate a significant
performance improvement.
</p>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08404" title="Abstract">arXiv:2401.08404</a> (cross-list from eess.IV) [<a href="/pdf/2401.08404" title="Download PDF">pdf</a>, <a href="/ps/2401.08404" title="Download PostScript">ps</a>, <a href="/format/2401.08404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training and Comparison of nnU-Net and DeepMedic Methods for  Autosegmentation of Pediatric Brain Tumors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vossough%2C+A">Arastoo Vossough</a>, 
<a href="/search/eess?searchtype=author&query=Khalili%2C+N">Nastaran Khalili</a>, 
<a href="/search/eess?searchtype=author&query=Familiar%2C+A+M">Ariana M. Familiar</a>, 
<a href="/search/eess?searchtype=author&query=Gandhi%2C+D">Deep Gandhi</a>, 
<a href="/search/eess?searchtype=author&query=Viswanathan%2C+K">Karthik Viswanathan</a>, 
<a href="/search/eess?searchtype=author&query=Tu%2C+W">Wenxin Tu</a>, 
<a href="/search/eess?searchtype=author&query=Haldar%2C+D">Debanjan Haldar</a>, 
<a href="/search/eess?searchtype=author&query=Bagheri%2C+S">Sina Bagheri</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+H">Hannah Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Haldar%2C+S">Shuvanjan Haldar</a>, 
<a href="/search/eess?searchtype=author&query=Storm%2C+P+B">Phillip B. Storm</a>, 
<a href="/search/eess?searchtype=author&query=Resnick%2C+A">Adam Resnick</a>, 
<a href="/search/eess?searchtype=author&query=Ware%2C+J+B">Jeffrey B. Ware</a>, 
<a href="/search/eess?searchtype=author&query=Nabavizadeh%2C+A">Ali Nabavizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Kazerooni%2C+A+F">Anahita Fathi Kazerooni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Brain tumors are the most common solid tumors and the leading cause of
cancer-related death among children. Tumor segmentation is essential in
surgical and treatment planning, and response assessment and monitoring.
However, manual segmentation is time-consuming and has high inter-operator
variability, underscoring the need for more efficient methods. We compared two
deep learning-based 3D segmentation models, DeepMedic and nnU-Net, after
training with pediatric-specific multi-institutional brain tumor data using
based on multi-parametric MRI scans.Multi-parametric preoperative MRI scans of
339 pediatric patients (n=293 internal and n=46 external cohorts) with a
variety of tumor subtypes, were preprocessed and manually segmented into four
tumor subregions, i.e., enhancing tumor (ET), non-enhancing tumor (NET), cystic
components (CC), and peritumoral edema (ED). After training, performance of the
two models on internal and external test sets was evaluated using Dice scores,
sensitivity, and Hausdorff distance with reference to ground truth manual
segmentations. Dice score for nnU-Net internal test sets was (mean +/- SD
(median)) 0.9+/-0.07 (0.94) for WT, 0.77+/-0.29 for ET, 0.66+/-0.32 for NET,
0.71+/-0.33 for CC, and 0.71+/-0.40 for ED, respectively. For DeepMedic the
Dice scores were 0.82+/-0.16 for WT, 0.66+/-0.32 for ET, 0.48+/-0.27, for NET,
0.48+/-0.36 for CC, and 0.19+/-0.33 for ED, respectively. Dice scores were
significantly higher for nnU-Net (p&lt;=0.01). External validation of the trained
nnU-Net model on the multi-institutional BraTS-PEDs 2023 dataset revealed high
generalization capability in segmentation of whole tumor and tumor core with
Dice scores of 0.87+/-0.13 (0.91) and 0.83+/-0.18 (0.89), respectively.
Pediatric-specific data trained nnU-Net model is superior to DeepMedic for
whole tumor and subregion segmentation of pediatric brain tumors.
</p>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08409" title="Abstract">arXiv:2401.08409</a> (cross-list from eess.IV) [<a href="/pdf/2401.08409" title="Download PDF">pdf</a>, <a href="/format/2401.08409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster ISNet for Background Bias Mitigation on Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bassi%2C+P+R+A+S">Pedro R. A. S. Bassi</a>, 
<a href="/search/eess?searchtype=author&query=Decherchi%2C+S">Sergio Decherchi</a>, 
<a href="/search/eess?searchtype=author&query=Cavalli%2C+A">Andrea Cavalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Image background features can constitute background bias (spurious
correlations) and impact deep classifiers decisions, causing shortcut learning
(Clever Hans effect) and reducing the generalization skill on real-world data.
The concept of optimizing Layer-wise Relevance Propagation (LRP) heatmaps, to
improve classifier behavior, was recently introduced by a neural network
architecture named ISNet. It minimizes background relevance in LRP maps, to
mitigate the influence of image background features on deep classifiers
decisions, hindering shortcut learning and improving generalization. For each
training image, the original ISNet produces one heatmap per possible class in
the classification task, hence, its training time scales linearly with the
number of classes. Here, we introduce reformulated architectures that allow the
training time to become independent from this number, rendering the
optimization process much faster. We challenged the enhanced models utilizing
the MNIST dataset with synthetic background bias, and COVID-19 detection in
chest X-rays, an application that is prone to shortcut learning due to
background bias. The trained models minimized background attention and hindered
shortcut learning, while retaining high accuracy. Considering external
(out-of-distribution) test datasets, they consistently proved more accurate
than multiple state-of-the-art deep neural network architectures, including a
dedicated image semantic segmenter followed by a classifier. The architectures
presented here represent a potentially massive improvement in training speed
over the original ISNet, thus introducing LRP optimization into a gamut of
applications that could not be feasibly handled by the original model.
</p>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08414" title="Abstract">arXiv:2401.08414</a> (cross-list from physics.comp-ph) [<a href="/pdf/2401.08414" title="Download PDF">pdf</a>, <a href="/format/2401.08414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Dynamical System Modeling through Interpretable Machine  Learning Augmentations: A Case Study in Cathodic Electrophoretic Deposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Jacobsen%2C+C">Christian Jacobsen</a>, 
<a href="/search/physics?searchtype=author&query=Dong%2C+J">Jiayuan Dong</a>, 
<a href="/search/physics?searchtype=author&query=Khalloufi%2C+M">Mehdi Khalloufi</a>, 
<a href="/search/physics?searchtype=author&query=Huan%2C+X">Xun Huan</a>, 
<a href="/search/physics?searchtype=author&query=Duraisamy%2C+K">Karthik Duraisamy</a>, 
<a href="/search/physics?searchtype=author&query=Akram%2C+M">Maryam Akram</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+W">Wanjiao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce a comprehensive data-driven framework aimed at enhancing the
modeling of physical systems, employing inference techniques and machine
learning enhancements. As a demonstrative application, we pursue the modeling
of cathodic electrophoretic deposition (EPD), commonly known as e-coating. Our
approach illustrates a systematic procedure for enhancing physical models by
identifying their limitations through inference on experimental data and
introducing adaptable model enhancements to address these shortcomings. We
begin by tackling the issue of model parameter identifiability, which reveals
aspects of the model that require improvement. To address generalizability , we
introduce modifications which also enhance identifiability. However, these
modifications do not fully capture essential experimental behaviors. To
overcome this limitation, we incorporate interpretable yet flexible
augmentations into the baseline model. These augmentations are parameterized by
simple fully-connected neural networks (FNNs), and we leverage machine learning
tools, particularly Neural Ordinary Differential Equations (Neural ODEs), to
learn these augmentations. Our simulations demonstrate that the machine
learning-augmented model more accurately captures observed behaviors and
improves predictive accuracy. Nevertheless, we contend that while the model
updates offer superior performance and capture the relevant physics, we can
reduce off-line computational costs by eliminating certain dynamics without
compromising accuracy or interpretability in downstream predictions of
quantities of interest, particularly film thickness predictions. The entire
process outlined here provides a structured approach to leverage data-driven
methods. Firstly, it helps us comprehend the root causes of model inaccuracies,
and secondly, it offers a principled method for enhancing model performance.
</p>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08442" title="Abstract">arXiv:2401.08442</a> (cross-list from econ.EM) [<a href="/pdf/2401.08442" title="Download PDF">pdf</a>, <a href="/format/2401.08442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the impact of forced and voluntary behavioral changes on  economic-epidemiological co-dynamics: A comparative case study between  Belgium and Sweden during the 2020 COVID-19 pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Alleman%2C+T+W">Tijs W. Alleman</a>, 
<a href="/search/econ?searchtype=author&query=Baetens%2C+J+M">Jan M. Baetens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">During the COVID-19 pandemic, governments faced the challenge of managing
population behavior to prevent their healthcare systems from collapsing. Sweden
adopted a strategy centered on voluntary sanitary recommendations while Belgium
resorted to mandatory measures. Their consequences on pandemic progression and
associated economic impacts remain insufficiently understood. This study
leverages the divergent policies of Belgium and Sweden during the COVID-19
pandemic to relax the unrealistic -- but persistently used -- assumption that
social contacts are not influenced by an epidemic's dynamics. We develop an
epidemiological-economic co-simulation model where pandemic-induced behavioral
changes are a superposition of voluntary actions driven by fear, prosocial
behavior or social pressure, and compulsory compliance with government
directives. Our findings emphasize the importance of early responses, which
reduce the stringency of measures necessary to safeguard healthcare systems and
minimize ensuing economic damage. Voluntary behavioral changes lead to a
pattern of recurring epidemics, which should be regarded as the natural
long-term course of pandemics. Governments should carefully consider prolonging
lockdown longer than necessary because this leads to higher economic damage and
a potentially higher second surge when measures are released. Our model can aid
policymakers in the selection of an appropriate long-term strategy that
minimizes economic damage.
</p>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08468" title="Abstract">arXiv:2401.08468</a> (cross-list from math.ST) [<a href="/pdf/2401.08468" title="Download PDF">pdf</a>, <a href="/format/2401.08468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep or toss? A nonparametric score to evaluate solutions for noisy ICA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kumar%2C+S">Syamantak Kumar</a>, 
<a href="/search/math?searchtype=author&query=Sarkar%2C+P">Purnamrita Sarkar</a>, 
<a href="/search/math?searchtype=author&query=Bickel%2C+P">Peter Bickel</a>, 
<a href="/search/math?searchtype=author&query=Bean%2C+D">Derek Bean</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we propose a non-parametric score to evaluate the quality of
the solution to an iterative algorithm for Independent Component Analysis (ICA)
with arbitrary Gaussian noise. The novelty of this score stems from the fact
that it just assumes a finite second moment of the data and uses the
characteristic function to evaluate the quality of the estimated mixing matrix
without any knowledge of the parameters of the noise distribution. We also
provide a new characteristic function-based contrast function for ICA and
propose a fixed point iteration to optimize the corresponding objective
function. Finally, we propose a theoretical framework to obtain sufficient
conditions for the local and global optima of a family of contrast functions
for ICA. This framework uses quasi-orthogonalization inherently, and our
results extend the classical analysis of cumulant-based objective functions to
noisy ICA. We demonstrate the efficacy of our algorithms via experimental
results on simulated datasets.
</p>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08469" title="Abstract">arXiv:2401.08469</a> (cross-list from eess.IV) [<a href="/pdf/2401.08469" title="Download PDF">pdf</a>, <a href="/format/2401.08469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explanations of Classifiers Enhance Medical Image Segmentation via  End-to-end Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiamin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xuhong Li</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yanwu Xu</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Medical image segmentation aims to identify and locate abnormal structures in
medical images, such as chest radiographs, using deep neural networks. These
networks require a large number of annotated images with fine-grained masks for
the regions of interest, making pre-training strategies based on classification
datasets essential for sample efficiency. Based on a large-scale medical image
classification dataset, our work collects explanations from well-trained
classifiers to generate pseudo labels of segmentation tasks. Specifically, we
offer a case study on chest radiographs and train image classifiers on the
CheXpert dataset to identify 14 pathological observations in radiology. We then
use Integrated Gradients (IG) method to distill and boost the explanations
obtained from the classifiers, generating massive diagnosis-oriented
localization labels (DoLL). These DoLL-annotated images are used for
pre-training the model before fine-tuning it for downstream segmentation tasks,
including COVID-19 infectious areas, lungs, heart, and clavicles. Our method
outperforms other baselines, showcasing significant advantages in model
performance and training efficiency across various segmentation settings.
</p>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08550" title="Abstract">arXiv:2401.08550</a> (cross-list from quant-ph) [<a href="/pdf/2401.08550" title="Download PDF">pdf</a>, <a href="/format/2401.08550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expanding Hardware-Efficiently Manipulable Hilbert Space via Hamiltonian  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Leng%2C+J">Jiaqi Leng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+J">Joseph Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Peng%2C+Y">Yuxiang Peng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wu%2C+X">Xiaodi Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 68 pages, 10 figures, an accompanying GitHub repository is at <a href="https://github.com/jiaqileng/hamiltonian-embedding">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Many promising quantum applications depend on the efficient quantum
simulation of an exponentially large sparse Hamiltonian, a task known as sparse
Hamiltonian simulation, which is fundamentally important in quantum
computation. Although several theoretically appealing quantum algorithms have
been proposed for this task, they typically require a black-box query model of
the sparse Hamiltonian, rendering them impractical for near-term implementation
on quantum devices.
<br />In this paper, we propose a technique named Hamiltonian embedding. This
technique simulates a desired sparse Hamiltonian by embedding it into the
evolution of a larger and more structured quantum system, allowing for more
efficient simulation through hardware-efficient operations. We conduct a
systematic study of this new technique and demonstrate significant savings in
computational resources for implementing prominent quantum applications. As a
result, we can now experimentally realize quantum walks on complicated graphs
(e.g., binary trees, glued-tree graphs), quantum spatial search, and the
simulation of real-space Schr\"odinger equations on current trapped-ion and
neutral-atom platforms. Given the fundamental role of Hamiltonian evolution in
the design of quantum algorithms, our technique markedly expands the horizon of
implementable quantum advantages in the NISQ era.
</p>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08562" title="Abstract">arXiv:2401.08562</a> (cross-list from math.OC) [<a href="/pdf/2401.08562" title="Download PDF">pdf</a>, <a href="/format/2401.08562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Registration of algebraic varieties using Riemannian optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goyens%2C+F">Florentin Goyens</a>, 
<a href="/search/math?searchtype=author&query=Cartis%2C+C">Coralia Cartis</a>, 
<a href="/search/math?searchtype=author&query=Chr%C3%A9tien%2C+S">St&#xe9;phane Chr&#xe9;tien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We consider the point cloud registration problem, the task of finding a
transformation between two point clouds that represent the same object but are
expressed in different coordinate systems. Our approach is not based on a
point-to-point correspondence, matching every point in the source point cloud
to a point in the target point cloud. Instead, we assume and leverage a
low-dimensional nonlinear geometric structure of the data. Firstly, we
approximate each point cloud by an algebraic variety (a set defined by finitely
many polynomial equations). This is done by solving an optimization problem on
the Grassmann manifold, using a connection between algebraic varieties and
polynomial bases. Secondly, we solve an optimization problem on the orthogonal
group to find the transformation (rotation $+$ translation) which makes the two
algebraic varieties overlap. We use second-order Riemannian optimization
methods for the solution of both steps. Numerical experiments on real and
synthetic data are provided, with encouraging results. Our approach is
particularly useful when the two point clouds describe different parts of an
objects (which may not even be overlapping), on the condition that the surface
of the object may be well approximated by a set of polynomial equations. The
first procedure -- the approximation -- is of independent interest, as it can
be used for denoising data that belongs to an algebraic variety. We provide
statistical guarantees for the estimation error of the denoising using Stein's
unbiased estimator.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 17 Jan 24</h3>
<dl>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1211.5656" title="Abstract">arXiv:1211.5656</a> (replaced) [<a href="/e-print/1211.5656" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Groupoids and Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Otto%2C+M">Martin Otto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Explicit completion of H in HxI (Section 2) is unstable (incompatible with restrictions), hence does not support inductive construction towards Prop. 2.17 based on Lem 2.16 as claimed. For corresponding technical result, now see arxiv:<a href="/abs/1806.08664">1806.08664</a>; for discussion of main applications first announced here, now see arxiv:<a href="/abs/1709.00031">1709.00031</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1809.04564" title="Abstract">arXiv:1809.04564</a> (replaced) [<a href="/pdf/1809.04564" title="Download PDF">pdf</a>, <a href="/format/1809.04564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Generalization of Stochastic Gradient Descent with Momentum
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani-Kebrya%2C+A">Ali Ramezani-Kebrya</a>, 
<a href="/search/cs?searchtype=author&query=Antonakopoulos%2C+K">Kimon Antonakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Cevher%2C+V">Volkan Cevher</a>, 
<a href="/search/cs?searchtype=author&query=Khisti%2C+A">Ashish Khisti</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Ben Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 14 figures. To appear in the Journal of Machine Learning Research (JMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1902.01453" title="Abstract">arXiv:1902.01453</a> (replaced) [<a href="/pdf/1902.01453" title="Download PDF">pdf</a>, <a href="/format/1902.01453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PVNet: A LRCN Architecture for Spatio-Temporal Photovoltaic  PowerForecasting from Numerical Weather Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mathe%2C+J">Johan Mathe</a>, 
<a href="/search/cs?searchtype=author&query=Miolane%2C+N">Nina Miolane</a>, 
<a href="/search/cs?searchtype=author&query=Sebastien%2C+N">Nicolas Sebastien</a>, 
<a href="/search/cs?searchtype=author&query=Lequeux%2C+J">Jeremie Lequeux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1905.09610" title="Abstract">arXiv:1905.09610</a> (replaced) [<a href="/pdf/1905.09610" title="Download PDF">pdf</a>, <a href="/ps/1905.09610" title="Download PostScript">ps</a>, <a href="/format/1905.09610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypothetical answers to continuous queries over data streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruz-Filipe%2C+L">Lu&#xed;s Cruz-Filipe</a>, 
<a href="/search/cs?searchtype=author&query=Gaspar%2C+G">Gra&#xe7;a Gaspar</a>, 
<a href="/search/cs?searchtype=author&query=Nunes%2C+I">Isabel Nunes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1911.03629" title="Abstract">arXiv:1911.03629</a> (replaced) [<a href="/pdf/1911.03629" title="Download PDF">pdf</a>, <a href="/format/1911.03629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tit-for-Tat Dynamics and Market Volatility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Nonlinearity
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.12410" title="Abstract">arXiv:2002.12410</a> (replaced) [<a href="/pdf/2002.12410" title="Download PDF">pdf</a>, <a href="/format/2002.12410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Biased Compression for Distributed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1th%2C+S">Samuel Horv&#xe1;th</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>, 
<a href="/search/cs?searchtype=author&query=Safaryan%2C+M">Mher Safaryan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 9 figures, 5 tables, 22 theorems and lemmas, 7 new compression operators, 1 algorithm
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research 2023:
  https://www.jmlr.org/papers/v24/21-1548.html
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.08863" title="Abstract">arXiv:2006.08863</a> (replaced) [<a href="/pdf/2006.08863" title="Download PDF">pdf</a>, <a href="/format/2006.08863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching Queues, Flexibility and Incentives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro%2C+F">Francisco Castro</a>, 
<a href="/search/cs?searchtype=author&query=Frazier%2C+P">Peter Frazier</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hongyao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Nazerzadeh%2C+H">Hamid Nazerzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chiwei Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.11830" title="Abstract">arXiv:2007.11830</a> (replaced) [<a href="/e-print/2007.11830" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Groebner basis structure of ideal interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yihe Gong</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xue Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> "Computing Groebner bases of ideal interpolation"(<a href="/abs/2111.07340">arXiv:2111.07340</a>) is the new version of this one
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.05825" title="Abstract">arXiv:2008.05825</a> (replaced) [<a href="/pdf/2008.05825" title="Download PDF">pdf</a>, <a href="/format/2008.05825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying supervised learning and VAEs -- coverage, systematics and  goodness-of-fit in normalizing-flow based neural network models for  astro-particle reconstructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gl%C3%BCsenkamp%2C+T">Thorsten Gl&#xfc;senkamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Astrophysical Phenomena (astro-ph.HE); Instrumentation and Methods for Astrophysics (astro-ph.IM); High Energy Physics - Experiment (hep-ex); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.04614" title="Abstract">arXiv:2009.04614</a> (replaced) [<a href="/pdf/2009.04614" title="Download PDF">pdf</a>, <a href="/format/2009.04614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Kernel Learning via Generative Random Fourier Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fanghui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.09876" title="Abstract">arXiv:2009.09876</a> (replaced) [<a href="/pdf/2009.09876" title="Download PDF">pdf</a>, <a href="/format/2009.09876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAC Address Anonymization for Crowd Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Determe%2C+J">Jean-Fran&#xe7;ois Determe</a>, 
<a href="/search/cs?searchtype=author&query=Azzagnuni%2C+S">Sophia Azzagnuni</a>, 
<a href="/search/cs?searchtype=author&query=Horlin%2C+F">Fran&#xe7;ois Horlin</a>, 
<a href="/search/cs?searchtype=author&query=De+Doncker%2C+P">Philippe De Doncker</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Algorithms 15, no. 5: 135 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.12190" title="Abstract">arXiv:2010.12190</a> (replaced) [<a href="/pdf/2010.12190" title="Download PDF">pdf</a>, <a href="/ps/2010.12190" title="Download PostScript">ps</a>, <a href="/format/2010.12190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Neural Networks via Orthogonal Diversity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Q">Qinghua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jia Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+F">Feipeng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaolin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.00650" title="Abstract">arXiv:2012.00650</a> (replaced) [<a href="/pdf/2012.00650" title="Download PDF">pdf</a>, <a href="/format/2012.00650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition, Compression, and Synthesis (DCS)-based Video Coding: A  Neural Exploration via Resolution-Adaptive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Ming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+D">Dandan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengqing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhan Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.00009" title="Abstract">arXiv:2101.00009</a> (replaced) [<a href="/pdf/2101.00009" title="Download PDF">pdf</a>, <a href="/format/2101.00009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Estimation of Riesz Representers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Chernozhukov%2C+V">Victor Chernozhukov</a>, 
<a href="/search/econ?searchtype=author&query=Newey%2C+W">Whitney Newey</a>, 
<a href="/search/econ?searchtype=author&query=Singh%2C+R">Rahul Singh</a>, 
<a href="/search/econ?searchtype=author&query=Syrgkanis%2C+V">Vasilis Syrgkanis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Econometrics (econ.EM)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.04645" title="Abstract">arXiv:2101.04645</a> (replaced) [<a href="/pdf/2101.04645" title="Download PDF">pdf</a>, <a href="/format/2101.04645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double-Adversarial Activation Anomaly Detection: Adversarial  Autoencoders are Anomaly Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schulze%2C+J+-">J.-P. Schulze</a>, 
<a href="/search/cs?searchtype=author&query=Sperl%2C+P">P. Sperl</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttinger%2C+K">K. B&#xf6;ttinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNN 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.01223" title="Abstract">arXiv:2102.01223</a> (replaced) [<a href="/pdf/2102.01223" title="Download PDF">pdf</a>, <a href="/format/2102.01223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inducing Meaningful Units from Character Sequences with Dynamic Capacity  Slot Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behjati%2C+M">Melika Behjati</a>, 
<a href="/search/cs?searchtype=author&query=Henderson%2C+J">James Henderson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to TMLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.01861" title="Abstract">arXiv:2103.01861</a> (replaced) [<a href="/pdf/2103.01861" title="Download PDF">pdf</a>, <a href="/format/2103.01861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Follow Your Nose -- Which Code Smells are Worth Chasing?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amit%2C+I">Idan Amit</a>, 
<a href="/search/cs?searchtype=author&query=Ezra%2C+N+B">Nili Ben Ezra</a>, 
<a href="/search/cs?searchtype=author&query=Feitelson%2C+D+G">Dror G. Feitelson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.14249" title="Abstract">arXiv:2103.14249</a> (replaced) [<a href="/pdf/2103.14249" title="Download PDF">pdf</a>, <a href="/format/2103.14249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marine Snow Removal Benchmarking Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaneko%2C+R">Reina Kaneko</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+Y">Yuya Sato</a>, 
<a href="/search/cs?searchtype=author&query=Ueda%2C+T">Takumi Ueda</a>, 
<a href="/search/cs?searchtype=author&query=Higashi%2C+H">Hiroshi Higashi</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+Y">Yuichi Tanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> APSIPA ASC 2023, Taipei, Taiwan, Nov. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.00032" title="Abstract">arXiv:2104.00032</a> (replaced) [<a href="/pdf/2104.00032" title="Download PDF">pdf</a>, <a href="/format/2104.00032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Dynamic Alignment Networks for Interpretable  Classifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hle%2C+M">Moritz B&#xf6;hle</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at CVRP 2021 (oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.03652" title="Abstract">arXiv:2104.03652</a> (replaced) [<a href="/pdf/2104.03652" title="Download PDF">pdf</a>, <a href="/format/2104.03652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interval constraint programming for globally solving catalog-based  categorical optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vanaret%2C+C">Charlie Vanaret</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Journal of Global Optimization on Dec 26, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Combinatorics (math.CO); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.15003" title="Abstract">arXiv:2104.15003</a> (replaced) [<a href="/pdf/2104.15003" title="Download PDF">pdf</a>, <a href="/format/2104.15003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Bounds for Concurrent Bounded Queues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aksenov%2C+V">Vitaly Aksenov</a>, 
<a href="/search/cs?searchtype=author&query=Koval%2C+N">Nikita Koval</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+P">Petr Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Paramonov%2C+A">Anton Paramonov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.00815" title="Abstract">arXiv:2105.00815</a> (replaced) [<a href="/pdf/2105.00815" title="Download PDF">pdf</a>, <a href="/format/2105.00815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning for Weakly Supervised Relation Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master Research Thesis of the Australian National University, 60 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.13722" title="Abstract">arXiv:2106.13722</a> (replaced) [<a href="/pdf/2106.13722" title="Download PDF">pdf</a>, <a href="/format/2106.13722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Curiously Effective Backtracking Strategy for Connection Tableaux
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%A4rber%2C+M">Michael F&#xe4;rber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AReCCa 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.15493" title="Abstract">arXiv:2106.15493</a> (replaced) [<a href="/pdf/2106.15493" title="Download PDF">pdf</a>, <a href="/ps/2106.15493" title="Download PostScript">ps</a>, <a href="/format/2106.15493" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Orthogonal Procrustes Problem under Arbitrary Adversaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Shuyang Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The first draft was posted in 2021; this version of manuscript has gone through a significant revision. The proof has been completely re-written and shortened to make it more readable
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.00116" title="Abstract">arXiv:2107.00116</a> (replaced) [<a href="/pdf/2107.00116" title="Download PDF">pdf</a>, <a href="/format/2107.00116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Benefits of Inducing Local Lipschitzness for Robust Generative  Adversarial Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Memarian%2C+F">Farzan Memarian</a>, 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+A">Abolfazl Hashemi</a>, 
<a href="/search/cs?searchtype=author&query=Niekum%2C+S">Scott Niekum</a>, 
<a href="/search/cs?searchtype=author&query=Topcu%2C+U">Ufuk Topcu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.04194" title="Abstract">arXiv:2109.04194</a> (replaced) [<a href="/pdf/2109.04194" title="Download PDF">pdf</a>, <a href="/format/2109.04194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Time Domain Based Upper-Limb Prosthesis Control using Incremental  Learning Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pancholi%2C+S">Sidharth Pancholi</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A+M+J+D">Amit M. Joshi Deepak Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Duerstock%2C+B+S">Bradly S. Duerstock</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 Pages, 8 Figures, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.10399" title="Abstract">arXiv:2109.10399</a> (replaced) [<a href="/pdf/2109.10399" title="Download PDF">pdf</a>, <a href="/format/2109.10399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and  Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Mouatadid%2C+S">Soukayna Mouatadid</a>, 
<a href="/search/physics?searchtype=author&query=Orenstein%2C+P">Paulo Orenstein</a>, 
<a href="/search/physics?searchtype=author&query=Flaspohler%2C+G">Genevieve Flaspohler</a>, 
<a href="/search/physics?searchtype=author&query=Oprescu%2C+M">Miruna Oprescu</a>, 
<a href="/search/physics?searchtype=author&query=Cohen%2C+J">Judah Cohen</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+F">Franklyn Wang</a>, 
<a href="/search/physics?searchtype=author&query=Knight%2C+S">Sean Knight</a>, 
<a href="/search/physics?searchtype=author&query=Geogdzhayeva%2C+M">Maria Geogdzhayeva</a>, 
<a href="/search/physics?searchtype=author&query=Levang%2C+S">Sam Levang</a>, 
<a href="/search/physics?searchtype=author&query=Fraenkel%2C+E">Ernest Fraenkel</a>, 
<a href="/search/physics?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.13004" title="Abstract">arXiv:2109.13004</a> (replaced) [<a href="/pdf/2109.13004" title="Download PDF">pdf</a>, <a href="/format/2109.13004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising for Interpretability: Convolutional Dynamic Alignment  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=B%C3%B6hle%2C+M">Moritz B&#xf6;hle</a>, 
<a href="/search/stat?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>, 
<a href="/search/stat?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of "Convolutional Dynamic Alignment Networks for Interpretable Classifications" (B\"ohle et al., CVPR 2021). arXiv admin note: substantial text overlap with <a href="/abs/2104.00032">arXiv:2104.00032</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Published in IEEE Transactions on Pattern Analysis and Machine
  Intelligence (Volume 45, Issue: 6, 01 June 2023, Page(s): 7625 - 7638)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.09155" title="Abstract">arXiv:2110.09155</a> (replaced) [<a href="/pdf/2110.09155" title="Download PDF">pdf</a>, <a href="/format/2110.09155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Dynamic Mode Decomposition Extension for the Forecasting of Parametric  Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Andreuzzi%2C+F">Francesco Andreuzzi</a>, 
<a href="/search/math?searchtype=author&query=Demo%2C+N">Nicola Demo</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM Journal on Applied Dynamical Systems (2023), Vol. 22, Iss. 3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.10083" title="Abstract">arXiv:2110.10083</a> (replaced) [<a href="/pdf/2110.10083" title="Download PDF">pdf</a>, <a href="/format/2110.10083" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Active Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazzaglia%2C+P">Pietro Mazzaglia</a>, 
<a href="/search/cs?searchtype=author&query=Verbelen%2C+T">Tim Verbelen</a>, 
<a href="/search/cs?searchtype=author&query=Dhoedt%2C+B">Bart Dhoedt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.15169" title="Abstract">arXiv:2110.15169</a> (replaced) [<a href="/pdf/2110.15169" title="Download PDF">pdf</a>, <a href="/format/2110.15169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimotion Visual Odometry (MVO)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Judd%2C+K+M">Kevin M. Judd</a>, 
<a href="/search/cs?searchtype=author&query=Gammell%2C+J+D">Jonathan D. Gammell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for the International Journal of Robotics Research (IJRR), Manuscript #IJR-21-4311. 25 pages, 15 figures, 11 tables. Videos available at <a href="https://www.youtube.com/watch?v=mNj3s1nf-6A">this https URL</a> and <a href="https://www.youtube.com/playlist?list=PLbaQBz4TuPcxMIXKh5Q80s0N9ISezFcpi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.07024" title="Abstract">arXiv:2111.07024</a> (replaced) [<a href="/pdf/2111.07024" title="Download PDF">pdf</a>, <a href="/format/2111.07024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Window Queries on Line Segments using the Trapezoidal Search DAG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brankovic%2C+M">Milutin Brankovic</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+M+P">Martin P. Seybold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added proceedings reference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. of Computing and Combinatorics (COCOON 2022). Lecture Notes
  in Computer Science, vol 13595
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.07340" title="Abstract">arXiv:2111.07340</a> (replaced) [<a href="/pdf/2111.07340" title="Download PDF">pdf</a>, <a href="/ps/2111.07340" title="Download PostScript">ps</a>, <a href="/format/2111.07340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Groebner bases of ideal interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+X">Xue Jiang</a>, 
<a href="/search/math?searchtype=author&query=Gong%2C+Y">Yihe Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2007.11830">arXiv:2007.11830</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.11802" title="Abstract">arXiv:2111.11802</a> (replaced) [<a href="/pdf/2111.11802" title="Download PDF">pdf</a>, <a href="/format/2111.11802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pruning Self-attentions into Convolutional Layers in Single Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyu He</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zizheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+B">Bohan Zhuang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.13322" title="Abstract">arXiv:2111.13322</a> (replaced) [<a href="/pdf/2111.13322" title="Download PDF">pdf</a>, <a href="/format/2111.13322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random-reshuffled SARAH does not need a full gradient computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="/search/cs?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 algorithms, 5 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.14185" title="Abstract">arXiv:2111.14185</a> (replaced) [<a href="/pdf/2111.14185" title="Download PDF">pdf</a>, <a href="/format/2111.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MALIGN: Explainable Static Raw-byte Based Malware Family Classification  using Sequence Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Shoumik Saha</a>, 
<a href="/search/cs?searchtype=author&query=Afroz%2C+S">Sadia Afroz</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Atif Rahman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.08487" title="Abstract">arXiv:2112.08487</a> (replaced) [<a href="/pdf/2112.08487" title="Download PDF">pdf</a>, <a href="/format/2112.08487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differential Privacy in Aggregated Mobility Networks: Balancing Privacy  and Utility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haydari%2C+A">Ammar Haydari</a>, 
<a href="/search/cs?searchtype=author&query=Chuah%2C+C">Chen-Nee Chuah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Michael Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Macfarlane%2C+J">Jane Macfarlane</a>, 
<a href="/search/cs?searchtype=author&query=Peisert%2C+S">Sean Peisert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.03820" title="Abstract">arXiv:2201.03820</a> (replaced) [<a href="/pdf/2201.03820" title="Download PDF">pdf</a>, <a href="/format/2201.03820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eternal Vertex Cover on Bipartite and Co-Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Misra%2C+N">Neeldhara Misra</a>, 
<a href="/search/cs?searchtype=author&query=Nanoti%2C+S">Saraswati Nanoti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 15 figures. Updated to remove a previously incorrect claim about the complexity of the problem on split graphs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00789" title="Abstract">arXiv:2202.00789</a> (replaced) [<a href="/pdf/2202.00789" title="Download PDF">pdf</a>, <a href="/format/2202.00789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Team Belief DAG: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B+H">Brian Hu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Farina%2C+G">Gabriele Farina</a>, 
<a href="/search/cs?searchtype=author&query=Sandholm%2C+T">Tuomas Sandholm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.01229" title="Abstract">arXiv:2202.01229</a> (replaced) [<a href="/pdf/2202.01229" title="Download PDF">pdf</a>, <a href="/ps/2202.01229" title="Download PostScript">ps</a>, <a href="/format/2202.01229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Behaviour Estimation in Parametric Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Maddux%2C+A+M">Anna M. Maddux</a>, 
<a href="/search/math?searchtype=author&query=Pagan%2C+N">Nicol&#xf2; Pagan</a>, 
<a href="/search/math?searchtype=author&query=Belgioioso%2C+G">Giuseppe Belgioioso</a>, 
<a href="/search/math?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IFAC, Volume 56, Issue 2, 2023, Pages 9330-9335,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.02423" title="Abstract">arXiv:2202.02423</a> (replaced) [<a href="/pdf/2202.02423" title="Download PDF">pdf</a>, <a href="/format/2202.02423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Information Theoretic Generalization Bounds for Distributed and  Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnes%2C+L+P">L. P. Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Dytso%2C+A">Alex Dytso</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. V. Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version of the paper adds an assumption that was missing from Theorem 4 for loss functions of type (i). Thanks to Peyman Gholami for spotting this bug
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.08246" title="Abstract">arXiv:2202.08246</a> (replaced) [<a href="/pdf/2202.08246" title="Download PDF">pdf</a>, <a href="/ps/2202.08246" title="Download PostScript">ps</a>, <a href="/format/2202.08246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Galois connecting call-by-value and call-by-name
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+D">Dylan McDermott</a>, 
<a href="/search/cs?searchtype=author&query=Mycroft%2C+A">Alan Mycroft</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> FSCD 2022 special issue of Logical Methods in Computer Science; minor changes incorporating reviewers' comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.11634" title="Abstract">arXiv:2202.11634</a> (replaced) [<a href="/pdf/2202.11634" title="Download PDF">pdf</a>, <a href="/format/2202.11634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice path matroids and quotients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Benedetti%2C+C">Carolina Benedetti</a>, 
<a href="/search/math?searchtype=author&query=Knauer%2C+K">Kolja Knauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.12883" title="Abstract">arXiv:2202.12883</a> (replaced) [<a href="/pdf/2202.12883" title="Download PDF">pdf</a>, <a href="/format/2202.12883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Detection of Political Speech Deepfakes across Transcripts, Audio,  and Video
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Groh%2C+M">Matthew Groh</a>, 
<a href="/search/cs?searchtype=author&query=Sankaranarayanan%2C+A">Aruna Sankaranarayanan</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Nikhil Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+Y">Dong Young Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lippman%2C+A">Andrew Lippman</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+R">Rosalind Picard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04049" title="Abstract">arXiv:2203.04049</a> (replaced) [<a href="/pdf/2203.04049" title="Download PDF">pdf</a>, <a href="/format/2203.04049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Attention Transformer Network for Multi-Label Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shikai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhongchao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+Y">Yong Rui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.04962" title="Abstract">arXiv:2203.04962</a> (replaced) [<a href="/pdf/2203.04962" title="Download PDF">pdf</a>, <a href="/format/2203.04962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the Degradation Distribution for Blind Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+Z">Zhengxiong Luo</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yan Huang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shang Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVRP2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.10364" title="Abstract">arXiv:2203.10364</a> (replaced) [<a href="/pdf/2203.10364" title="Download PDF">pdf</a>, <a href="/format/2203.10364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Practical Nearest Sub-Trajectory Queries under the Fr&#xe9;chet Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gudmundsson%2C+J">Joachim Gudmundsson</a>, 
<a href="/search/cs?searchtype=author&query=Pfeifer%2C+J">John Pfeifer</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+M+P">Martin P. Seybold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added journal reference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ACM Transactions on Spatial Algorithms and Systems, Volume 9,
  Issue 2 Article 14 (June 2023), 24 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.02791" title="Abstract">arXiv:2204.02791</a> (replaced) [<a href="/pdf/2204.02791" title="Download PDF">pdf</a>, <a href="/format/2204.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Motion-Compensated Network for Unsupervised Video Object  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+L">Lin Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.05104" title="Abstract">arXiv:2204.05104</a> (replaced) [<a href="/pdf/2204.05104" title="Download PDF">pdf</a>, <a href="/format/2204.05104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Graph Neural Network for Multi-Source Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jin Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+F">Feng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yangzhou Du</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhongchao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jianping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Rui%2C+Y">Yong Rui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07636" title="Abstract">arXiv:2204.07636</a> (replaced) [<a href="/pdf/2204.07636" title="Download PDF">pdf</a>, <a href="/format/2204.07636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lagrangian Motion Magnification with Double Sparse Optical Flow  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flotho%2C+P">Philipp Flotho</a>, 
<a href="/search/cs?searchtype=author&query=Heiss%2C+C">Cosmas Heiss</a>, 
<a href="/search/cs?searchtype=author&query=Steidl%2C+G">Gabriele Steidl</a>, 
<a href="/search/cs?searchtype=author&query=Strauss%2C+D+J">Daniel J. Strauss</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.07703" title="Abstract">arXiv:2204.07703</a> (replaced) [<a href="/pdf/2204.07703" title="Download PDF">pdf</a>, <a href="/format/2204.07703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Min Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Menglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Lujia Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by GLB 2022 @TheWebConf 2022;Data and codes are available at <a href="https://github.com/huawei-noah/benchmark/tree/main/TeleGraph">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.00932" title="Abstract">arXiv:2205.00932</a> (replaced) [<a href="/pdf/2205.00932" title="Download PDF">pdf</a>, <a href="/format/2205.00932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding CNNs from excitations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ying%2C+Z">Zijian Ying</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qianmu Li</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zhichao Lian</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Jun Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03990" title="Abstract">arXiv:2205.03990</a> (replaced) [<a href="/pdf/2205.03990" title="Download PDF">pdf</a>, <a href="/format/2205.03990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-resolution partial differential equations preserved learning  framework for spatiotemporal dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin-Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Min Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+L">Lu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jian-Xun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 27 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Commun Phys 7, 31 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05455" title="Abstract">arXiv:2205.05455</a> (replaced) [<a href="/pdf/2205.05455" title="Download PDF">pdf</a>, <a href="/ps/2205.05455" title="Download PostScript">ps</a>, <a href="/format/2205.05455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Final Iteration Convergence Bound of Q-Learning: Switching System  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Donghwna Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2102.08583">arXiv:2102.08583</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.09378" title="Abstract">arXiv:2205.09378</a> (replaced) [<a href="/pdf/2205.09378" title="Download PDF">pdf</a>, <a href="/ps/2205.09378" title="Download PostScript">ps</a>, <a href="/format/2205.09378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Relay Selection and Power Control that aims to Maximize Sum-Rate  in Multi-Hop Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dayarathna%2C+S">Shalanika Dayarathna</a>, 
<a href="/search/cs?searchtype=author&query=Senanayake%2C+R">Rajitha Senanayake</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+J">Jamie Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Version, Presented in 2023 IEEE 17th International Conference on Industrial and Information Systems (ICIIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.12787" title="Abstract">arXiv:2205.12787</a> (replaced) [<a href="/pdf/2205.12787" title="Download PDF">pdf</a>, <a href="/format/2205.12787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impartial Games: A Challenge for Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13114" title="Abstract">arXiv:2205.13114</a> (replaced) [<a href="/pdf/2205.13114" title="Download PDF">pdf</a>, <a href="/format/2205.13114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Pandora&#x27;s Box
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atsidakou%2C+A">Alexia Atsidakou</a>, 
<a href="/search/cs?searchtype=author&query=Caramanis%2C+C">Constantine Caramanis</a>, 
<a href="/search/cs?searchtype=author&query=Gergatsouli%2C+E">Evangelia Gergatsouli</a>, 
<a href="/search/cs?searchtype=author&query=Papadigenopoulos%2C+O">Orestis Papadigenopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tzamos%2C+C">Christos Tzamos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.14855" title="Abstract">arXiv:2205.14855</a> (replaced) [<a href="/pdf/2205.14855" title="Download PDF">pdf</a>, <a href="/ps/2205.14855" title="Download PostScript">ps</a>, <a href="/format/2205.14855" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leave-one-out Singular Subspace Perturbation Analysis for Spectral  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+A+Y">Anderson Y. Zhang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+H+H">Harrison H. Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00285" title="Abstract">arXiv:2206.00285</a> (replaced) [<a href="/pdf/2206.00285" title="Download PDF">pdf</a>, <a href="/format/2206.00285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Gradient Methods with Preconditioned Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sadiev%2C+A">Abdurakhmon Sadiev</a>, 
<a href="/search/math?searchtype=author&query=Beznosikov%2C+A">Aleksandr Beznosikov</a>, 
<a href="/search/math?searchtype=author&query=Almansoori%2C+A+J">Abdulla Jasem Almansoori</a>, 
<a href="/search/math?searchtype=author&query=Kamzolov%2C+D">Dmitry Kamzolov</a>, 
<a href="/search/math?searchtype=author&query=Tappenden%2C+R">Rachael Tappenden</a>, 
<a href="/search/math?searchtype=author&query=Tak%C3%A1%C4%8D%2C+M">Martin Tak&#xe1;&#x10d;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 2 new algorithms, 20 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02217" title="Abstract">arXiv:2206.02217</a> (replaced) [<a href="/pdf/2206.02217" title="Download PDF">pdf</a>, <a href="/format/2206.02217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Mesh Motion Techniques with Application to Fluid-Structure  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haubner%2C+J">Johannes Haubner</a>, 
<a href="/search/math?searchtype=author&query=Hellan%2C+O">Ottar Hellan</a>, 
<a href="/search/math?searchtype=author&query=Zeinhofer%2C+M">Marius Zeinhofer</a>, 
<a href="/search/math?searchtype=author&query=Kuchta%2C+M">Miroslav Kuchta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.04990" title="Abstract">arXiv:2206.04990</a> (replaced) [<a href="/pdf/2206.04990" title="Download PDF">pdf</a>, <a href="/format/2206.04990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantum Circuit Design with a Standard Cell Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dobbs%2C+E+E">Evan E. Dobbs</a>, 
<a href="/search/quant-ph?searchtype=author&query=Friedman%2C+J+S">Joseph S. Friedman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Paler%2C+A">Alexandru Paler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.08756" title="Abstract">arXiv:2206.08756</a> (replaced) [<a href="/pdf/2206.08756" title="Download PDF">pdf</a>, <a href="/format/2206.08756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor-on-Tensor Regression: Riemannian Optimization,  Over-parameterization, Statistical-computational Gap, and Their Interplay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Luo%2C+Y">Yuetian Luo</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+A+R">Anru R. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09507" title="Abstract">arXiv:2206.09507</a> (replaced) [<a href="/pdf/2206.09507" title="Download PDF">pdf</a>, <a href="/format/2206.09507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Efficient Separation Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Della+Libera%2C+L">Luca Della Libera</a>, 
<a href="/search/eess?searchtype=author&query=Subakan%2C+C">Cem Subakan</a>, 
<a href="/search/eess?searchtype=author&query=Ravanelli%2C+M">Mirco Ravanelli</a>, 
<a href="/search/eess?searchtype=author&query=Cornell%2C+S">Samuele Cornell</a>, 
<a href="/search/eess?searchtype=author&query=Lepoutre%2C+F">Fr&#xe9;d&#xe9;ric Lepoutre</a>, 
<a href="/search/eess?searchtype=author&query=Grondin%2C+F">Fran&#xe7;ois Grondin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11030" title="Abstract">arXiv:2206.11030</a> (replaced) [<a href="/pdf/2206.11030" title="Download PDF">pdf</a>, <a href="/ps/2206.11030" title="Download PostScript">ps</a>, <a href="/format/2206.11030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KeyCLD: Learning Constrained Lagrangian Dynamics in Keypoint Coordinates  from Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daems%2C+R">Rembert Daems</a>, 
<a href="/search/cs?searchtype=author&query=Taets%2C+J">Jeroen Taets</a>, 
<a href="/search/cs?searchtype=author&query=wyffels%2C+F">Francis wyffels</a>, 
<a href="/search/cs?searchtype=author&query=Crevecoeur%2C+G">Guillaume Crevecoeur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11705" title="Abstract">arXiv:2206.11705</a> (replaced) [<a href="/pdf/2206.11705" title="Download PDF">pdf</a>, <a href="/format/2206.11705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Tie Strength in Temporal Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oettershagen%2C+L">Lutz Oettershagen</a>, 
<a href="/search/cs?searchtype=author&query=Konstantinidis%2C+A+L">Athanasios L. Konstantinidis</a>, 
<a href="/search/cs?searchtype=author&query=Italiano%2C+G+F">Giuseppe F. Italiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13288" title="Abstract">arXiv:2206.13288</a> (replaced) [<a href="/pdf/2206.13288" title="Download PDF">pdf</a>, <a href="/format/2206.13288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Salient Neurons in Deep NLP Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durrani%2C+N">Nadir Durrani</a>, 
<a href="/search/cs?searchtype=author&query=Dalvi%2C+F">Fahim Dalvi</a>, 
<a href="/search/cs?searchtype=author&query=Sajjad%2C+H">Hassan Sajjad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08195" title="Abstract">arXiv:2207.08195</a> (replaced) [<a href="/pdf/2207.08195" title="Download PDF">pdf</a>, <a href="/format/2207.08195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPIRAL: A superlinearly convergent incremental proximal algorithm for  nonconvex finite sum minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Behmandpoor%2C+P">Pourya Behmandpoor</a>, 
<a href="/search/math?searchtype=author&query=Latafat%2C+P">Puya Latafat</a>, 
<a href="/search/math?searchtype=author&query=Themelis%2C+A">Andreas Themelis</a>, 
<a href="/search/math?searchtype=author&query=Moonen%2C+M">Marc Moonen</a>, 
<a href="/search/math?searchtype=author&query=Patrinos%2C+P">Panagiotis Patrinos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.10199" title="Abstract">arXiv:2207.10199</a> (replaced) [<a href="/pdf/2207.10199" title="Download PDF">pdf</a>, <a href="/format/2207.10199" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provably tuning the ElasticNet across instances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balcan%2C+M">Maria-Florina Balcan</a>, 
<a href="/search/cs?searchtype=author&query=Khodak%2C+M">Mikhail Khodak</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+D">Dravyansh Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11230" title="Abstract">arXiv:2207.11230</a> (replaced) [<a href="/pdf/2207.11230" title="Download PDF">pdf</a>, <a href="/format/2207.11230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> You Actually Look Twice At it (YALTAi): using an object detection  approach instead of region segmentation within the Kraken engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cl%C3%A9rice%2C+T">Thibault Cl&#xe9;rice</a> (ENC, CJM, HiSoMA, UJML, ALMAnaCH)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal of Data Mining and Digital Humanities, 2023, Historical Documents and automatic text recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.11429" title="Abstract">arXiv:2207.11429</a> (replaced) [<a href="/pdf/2207.11429" title="Download PDF">pdf</a>, <a href="/format/2207.11429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving degeneracies in Google search via quantum stochastic walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Benjamin%2C+C">Colin Benjamin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dudhe%2C+N">Naini Dudhe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 23 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Statistical Mechanics: Theory and Experiment (2024)
  013402
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Social and Information Networks (cs.SI); Systems and Control (eess.SY); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14314" title="Abstract">arXiv:2207.14314</a> (replaced) [<a href="/pdf/2207.14314" title="Download PDF">pdf</a>, <a href="/format/2207.14314" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supplementing Recurrent Neural Network Wave Functions with Symmetry and  Annealing to Improve Accuracy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Hibat-Allah%2C+M">Mohamed Hibat-Allah</a>, 
<a href="/search/cond-mat?searchtype=author&query=Melko%2C+R+G">Roger G. Melko</a>, 
<a href="/search/cond-mat?searchtype=author&query=Carrasquilla%2C+J">Juan Carrasquilla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures, 1 table. Corrected typos. Originally published in Machine Learning and the Physical Sciences Workshop (NeurIPS 2021), see: <a href="https://ml4physicalsciences.github.io/2021/files/NeurIPS_ML4PS_2021_92.pdf.">this https URL</a> Our reproducibility code can be found at <a href="https://github.com/mhibatallah/RNNWavefunctions">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning and the Physical Sciences, NeurIPS 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01215" title="Abstract">arXiv:2208.01215</a> (replaced) [<a href="/pdf/2208.01215" title="Download PDF">pdf</a>, <a href="/format/2208.01215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAPA: Intermediate-level Variational Native-pulse Ansatz for Variational  Quantum Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liang%2C+Z">Zhiding Liang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cheng%2C+J">Jinglei Cheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ren%2C+H">Hang Ren</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hua%2C+F">Fei Hua</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+Z">Zhixin Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ding%2C+Y">Yongshan Ding</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F">Fred Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/quant-ph?searchtype=author&query=Qian%2C+X">Xuehai Qian</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10100" title="Abstract">arXiv:2208.10100</a> (replaced) [<a href="/pdf/2208.10100" title="Download PDF">pdf</a>, <a href="/format/2208.10100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lirot.ai: A Novel Platform for Crowd-Sourcing Retinal Image  Segmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fhima%2C+J">Jonathan Fhima</a>, 
<a href="/search/cs?searchtype=author&query=Van+Eijgen%2C+J">Jan Van Eijgen</a>, 
<a href="/search/cs?searchtype=author&query=Freiman%2C+M">Moti Freiman</a>, 
<a href="/search/cs?searchtype=author&query=Stalmans%2C+I">Ingeborg Stalmans</a>, 
<a href="/search/cs?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10962" title="Abstract">arXiv:2208.10962</a> (replaced) [<a href="/e-print/2208.10962" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction of good reaction coordinates and future evolution of MD  trajectories using Regularized Sparse Autoencoders: A novel deep learning  approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gupta%2C+A">Abhijit Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Disagreement with my PhD supervisor about open-sourcing the publication and affiliation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14739" title="Abstract">arXiv:2208.14739</a> (replaced) [<a href="/pdf/2208.14739" title="Download PDF">pdf</a>, <a href="/ps/2208.14739" title="Download PostScript">ps</a>, <a href="/format/2208.14739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complete and tractable machine-independent characterizations of  second-order polytime
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hainry%2C+E">Emmanuel Hainry</a>, 
<a href="/search/cs?searchtype=author&query=Kapron%2C+B+M">Bruce M. Kapron</a>, 
<a href="/search/cs?searchtype=author&query=Marion%2C+J">Jean-Yves Marion</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9choux%2C+R">Romain P&#xe9;choux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00554" title="Abstract">arXiv:2209.00554</a> (replaced) [<a href="/pdf/2209.00554" title="Download PDF">pdf</a>, <a href="/ps/2209.00554" title="Download PostScript">ps</a>, <a href="/format/2209.00554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operational Interpretation of the Sandwiched R&#xe9;nyi Divergence of Order  1/2 to 1 as Strong Converse Exponents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+K">Ke Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yao%2C+Y">Yongsheng Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V2: minor changes. V3: more discussions and clarifications added, small errors and incompleteness in proof fixed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02505" title="Abstract">arXiv:2209.02505</a> (replaced) [<a href="/pdf/2209.02505" title="Download PDF">pdf</a>, <a href="/format/2209.02505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Realizations of Series Elastic Actuation: Effects of Plant and  Controller Dynamics on Haptic Rendering Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kenanoglu%2C+C+U">Celal Umut Kenanoglu</a>, 
<a href="/search/cs?searchtype=author&query=Patoglu%2C+V">Volkan Patoglu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02935" title="Abstract">arXiv:2209.02935</a> (replaced) [<a href="/pdf/2209.02935" title="Download PDF">pdf</a>, <a href="/format/2209.02935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalised clustering accuracy: An asymmetric external cluster validity  measure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gagolewski%2C+M">Marek Gagolewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07003" title="Abstract">arXiv:2209.07003</a> (replaced) [<a href="/pdf/2209.07003" title="Download PDF">pdf</a>, <a href="/format/2209.07003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-aided UAV navigation and dynamic obstacle avoidance using  gradient-based B-spline trajectory optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07225" title="Abstract">arXiv:2209.07225</a> (replaced) [<a href="/pdf/2209.07225" title="Download PDF">pdf</a>, <a href="/format/2209.07225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via  Mixing Recurrent Soft Decision Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zichuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuanyang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chunlin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08258" title="Abstract">arXiv:2209.08258</a> (replaced) [<a href="/pdf/2209.08258" title="Download PDF">pdf</a>, <a href="/format/2209.08258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A real-time dynamic obstacle tracking and mapping system for UAV  navigation and collision avoidance with an RGB-D camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Robotics and Automation
  (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11326" title="Abstract">arXiv:2209.11326</a> (replaced) [<a href="/pdf/2209.11326" title="Download PDF">pdf</a>, <a href="/format/2209.11326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Faithful Model Explanation in NLP: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Q">Qing Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Apidianaki%2C+M">Marianna Apidianaki</a>, 
<a href="/search/cs?searchtype=author&query=Callison-Burch%2C+C">Chris Callison-Burch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added acknowledgements; Accepted to the Computational Linguistics Journal (June 2024 issue)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14408" title="Abstract">arXiv:2209.14408</a> (replaced) [<a href="/pdf/2209.14408" title="Download PDF">pdf</a>, <a href="/format/2209.14408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RALACs: Action Recognition in Autonomous Vehicles using Interaction  Encoding and Optical Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Eddy Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+A">Alex Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Budhwani%2C+A">Alikasim Budhwani</a>, 
<a href="/search/cs?searchtype=author&query=Leather%2C+O">Owen Leather</a>, 
<a href="/search/cs?searchtype=author&query=Dempster%2C+R">Rowan Dempster</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quanquan Li</a>, 
<a href="/search/cs?searchtype=author&query=Al-Sharman%2C+M">Mohammad Al-Sharman</a>, 
<a href="/search/cs?searchtype=author&query=Rayside%2C+D">Derek Rayside</a>, 
<a href="/search/cs?searchtype=author&query=Melek%2C+W">William Melek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02289" title="Abstract">arXiv:2210.02289</a> (replaced) [<a href="/pdf/2210.02289" title="Download PDF">pdf</a>, <a href="/format/2210.02289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage and Rate of Joint Communication and Parameter Estimation in  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Olson%2C+N+R">Nicholas R. Olson</a>, 
<a href="/search/cs?searchtype=author&query=Andrews%2C+J+G">Jeffrey G. Andrews</a>, 
<a href="/search/cs?searchtype=author&query=Heath%2C+R+W">Robert W. Heath Jr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 87 pages, 5 figures. Published in IEEE Transactions on Information Theory
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Information Theory, vol. 70, no. 1, pp.
  206-243, Jan. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07018" title="Abstract">arXiv:2210.07018</a> (replaced) [<a href="/pdf/2210.07018" title="Download PDF">pdf</a>, <a href="/ps/2210.07018" title="Download PostScript">ps</a>, <a href="/format/2210.07018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online matching with delays and stochastic arrival times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%2C+M">Mathieu Mari</a>, 
<a href="/search/cs?searchtype=author&query=Paw%C5%82owski%2C+M">Micha&#x142; Paw&#x142;owski</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Runtian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sankowski%2C+P">Piotr Sankowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 7 figures, accepted at AAMAS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07893" title="Abstract">arXiv:2210.07893</a> (replaced) [<a href="/pdf/2210.07893" title="Download PDF">pdf</a>, <a href="/format/2210.07893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerically Stable Sparse Gaussian Processes via Minimum Separation  using Cover Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/stat?searchtype=author&query=Burt%2C+D+R">David R. Burt</a>, 
<a href="/search/stat?searchtype=author&query=Artemev%2C+A">Artem Artemev</a>, 
<a href="/search/stat?searchtype=author&query=Flaxman%2C+S">Seth Flaxman</a>, 
<a href="/search/stat?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/stat?searchtype=author&query=Rasmussen%2C+C+E">Carl Edward Rasmussen</a>, 
<a href="/search/stat?searchtype=author&query=Ge%2C+H">Hong Ge</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Machine Learning Research, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08604" title="Abstract">arXiv:2210.08604</a> (replaced) [<a href="/pdf/2210.08604" title="Download PDF">pdf</a>, <a href="/format/2210.08604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations  On-the-Fly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fung%2C+Y+R">Yi R. Fung</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Tuhin Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Rambow%2C+O">Owen Rambow</a>, 
<a href="/search/cs?searchtype=author&query=Muresan%2C+S">Smaranda Muresan</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10026" title="Abstract">arXiv:2210.10026</a> (replaced) [<a href="/pdf/2210.10026" title="Download PDF">pdf</a>, <a href="/format/2210.10026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Misinformation: Impacts of Human Biases on Detection of  Deepfakes on Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lovato%2C+J">Juniper Lovato</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A9bert-Dufresne%2C+L">Laurent H&#xe9;bert-Dufresne</a>, 
<a href="/search/cs?searchtype=author&query=St-Onge%2C+J">Jonathan St-Onge</a>, 
<a href="/search/cs?searchtype=author&query=Harp%2C+R">Randall Harp</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+G+S">Gabriela Salazar Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Rogers%2C+S+P">Sean P. Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Onaolapo%2C+J">Jeremiah Onaolapo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Supplementary appendix available upon request for the time being
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10537" title="Abstract">arXiv:2210.10537</a> (replaced) [<a href="/e-print/2210.10537" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online LiDAR-Camera Extrinsic Parameters Self-checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+P">Pengjin Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Guohang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikang Li</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There are some errors in the methodology section of the paper, which is currently being revised
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.16584" title="Abstract">arXiv:2210.16584</a> (replaced) [<a href="/pdf/2210.16584" title="Download PDF">pdf</a>, <a href="/format/2210.16584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable CNN-Multilevel Attention Transformer for Rapid Recognition  of Pneumonia from Chest X-Ray Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+S">Shengchao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+S">Sufen Ren</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Guanjun Wang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+M">Mengxing Huang</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+C">Chenyang Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the IEEE Journal of Biomedical and Health Informatic, doi: 10.1109/JBHI.2023.3247949
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01291" title="Abstract">arXiv:2211.01291</a> (replaced) [<a href="/pdf/2211.01291" title="Download PDF">pdf</a>, <a href="/format/2211.01291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: A Stratified Approach to Blockchain Decentralization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karakostas%2C+D">Dimitris Karakostas</a>, 
<a href="/search/cs?searchtype=author&query=Kiayias%2C+A">Aggelos Kiayias</a>, 
<a href="/search/cs?searchtype=author&query=Ovezik%2C+C">Christina Ovezik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02658" title="Abstract">arXiv:2211.02658</a> (replaced) [<a href="/pdf/2211.02658" title="Download PDF">pdf</a>, <a href="/format/2211.02658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dealing with Drift of Adaptation Spaces in Learning-based Self-Adaptive  Systems using Lifelong Self-Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheibi%2C+O">Omid Gheibi</a>, 
<a href="/search/cs?searchtype=author&query=Weyns%2C+D">Danny Weyns</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02951" title="Abstract">arXiv:2211.02951</a> (replaced) [<a href="/pdf/2211.02951" title="Download PDF">pdf</a>, <a href="/format/2211.02951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Map matching queries on realistic input graphs under the Fr&#xe9;chet  distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gudmundsson%2C+J">Joachim Gudmundsson</a>, 
<a href="/search/cs?searchtype=author&query=Seybold%2C+M+P">Martin P. Seybold</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+S">Sampson Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated proceedings reference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms
  (January 2023), p.1464-1492
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.04369" title="Abstract">arXiv:2211.04369</a> (replaced) [<a href="/pdf/2211.04369" title="Download PDF">pdf</a>, <a href="/format/2211.04369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Time Series Analysis via Processing using Non-Volatile  Memories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+I">Ivan Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Giannoula%2C+C">Christina Giannoula</a>, 
<a href="/search/cs?searchtype=author&query=Manglik%2C+A">Aditya Manglik</a>, 
<a href="/search/cs?searchtype=author&query=Quislant%2C+R">Ricardo Quislant</a>, 
<a href="/search/cs?searchtype=author&query=Ghiasi%2C+N+M">Nika Mansouri Ghiasi</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Gutierrez%2C+E">Eladio Gutierrez</a>, 
<a href="/search/cs?searchtype=author&query=Plata%2C+O">Oscar Plata</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06598" title="Abstract">arXiv:2211.06598</a> (replaced) [<a href="/pdf/2211.06598" title="Download PDF">pdf</a>, <a href="/format/2211.06598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Resource Utilization of Non-terrestrial Networks Using  Temporal Graph-based Deterministic Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Keyi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingchao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08291" title="Abstract">arXiv:2211.08291</a> (replaced) [<a href="/pdf/2211.08291" title="Download PDF">pdf</a>, <a href="/format/2211.08291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking and Defending Deep-Learning-Based Off-Device Wireless  Positioning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+P">Pengzhi Huang</a>, 
<a href="/search/eess?searchtype=author&query=G%C3%B6n%C3%BClta%C5%9F%2C+E">Emre G&#xf6;n&#xfc;lta&#x15f;</a>, 
<a href="/search/eess?searchtype=author&query=Arnold%2C+M">Maximilian Arnold</a>, 
<a href="/search/eess?searchtype=author&query=Srinath%2C+K+P">K. Pavan Srinath</a>, 
<a href="/search/eess?searchtype=author&query=Hoydis%2C+J">Jakob Hoydis</a>, 
<a href="/search/eess?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08770" title="Abstract">arXiv:2211.08770</a> (replaced) [<a href="/pdf/2211.08770" title="Download PDF">pdf</a>, <a href="/format/2211.08770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On some orthogonalization schemes in Tensor Train format
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coulaud%2C+O">Olivier Coulaud</a> (CONCACE), 
<a href="/search/cs?searchtype=author&query=Giraud%2C+L">Luc Giraud</a> (CONCACE), 
<a href="/search/cs?searchtype=author&query=Iannacito%2C+M">Martina Iannacito</a> (KU-ESAT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10526" title="Abstract">arXiv:2211.10526</a> (replaced) [<a href="/pdf/2211.10526" title="Download PDF">pdf</a>, <a href="/format/2211.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Castling-ViT: Compressing Self-Attention via Switching Towards  Linear-Angular Attention at Vision Transformer Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haoran You</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xiaoliang Dai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peizhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingyan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023 Camera Ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10747" title="Abstract">arXiv:2211.10747</a> (replaced) [<a href="/pdf/2211.10747" title="Download PDF">pdf</a>, <a href="/format/2211.10747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring validation metrics for offline model-based optimisation with  diffusion models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Beckham%2C+C">Christopher Beckham</a>, 
<a href="/search/stat?searchtype=author&query=Piche%2C+A">Alexandre Piche</a>, 
<a href="/search/stat?searchtype=author&query=Vazquez%2C+D">David Vazquez</a>, 
<a href="/search/stat?searchtype=author&query=Pal%2C+C">Christopher Pal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11691" title="Abstract">arXiv:2211.11691</a> (replaced) [<a href="/pdf/2211.11691" title="Download PDF">pdf</a>, <a href="/format/2211.11691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Signature Algorithm for Multi-dimensional Path-Dependent Options
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Bayraktar%2C+E">Erhan Bayraktar</a>, 
<a href="/search/q-fin?searchtype=author&query=Feng%2C+Q">Qi Feng</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+Z">Zhaoyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM Journal on Financial Mathematics. 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Machine Learning (cs.LG); Mathematical Finance (q-fin.MF)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13709" title="Abstract">arXiv:2211.13709</a> (replaced) [<a href="/pdf/2211.13709" title="Download PDF">pdf</a>, <a href="/format/2211.13709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undesirable Biases in NLP: Addressing Challenges of Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Wal%2C+O">Oskar van der Wal</a>, 
<a href="/search/cs?searchtype=author&query=Bachmann%2C+D">Dominik Bachmann</a>, 
<a href="/search/cs?searchtype=author&query=Leidinger%2C+A">Alina Leidinger</a>, 
<a href="/search/cs?searchtype=author&query=van+Maanen%2C+L">Leendert van Maanen</a>, 
<a href="/search/cs?searchtype=author&query=Zuidema%2C+W">Willem Zuidema</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+K">Katrin Schulz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Artificial Intelligence Research, 79, 1-40 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16297" title="Abstract">arXiv:2211.16297</a> (replaced) [<a href="/pdf/2211.16297" title="Download PDF">pdf</a>, <a href="/format/2211.16297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part II: The  multidimensional case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ching%2C+E+J">Eric J. Ching</a>, 
<a href="/search/math?searchtype=author&query=Johnson%2C+R+F">Ryan F. Johnson</a>, 
<a href="/search/math?searchtype=author&query=Kercher%2C+A+D">Andrew D. Kercher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16587" title="Abstract">arXiv:2211.16587</a> (replaced) [<a href="/pdf/2211.16587" title="Download PDF">pdf</a>, <a href="/format/2211.16587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rigorous Assessment of Model Inference Accuracy using Language  Cardinality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clun%2C+D">Donato Clun</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Donghwan Shin</a>, 
<a href="/search/cs?searchtype=author&query=Filieri%2C+A">Antonio Filieri</a>, 
<a href="/search/cs?searchtype=author&query=Bianculli%2C+D">Domenico Bianculli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the ACM Transactions on Software Engineering and Methodology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03597" title="Abstract">arXiv:2212.03597</a> (replaced) [<a href="/pdf/2212.03597" title="Download PDF">pdf</a>, <a href="/format/2212.03597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and  Training Efficiency via Efficient Data Sampling and Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Conglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+C">Connor Holmes</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Cheng Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in AAAI 2024 Main Technical Track. Equal contribution by the first 3 authors. Code has been released as a part of <a href="https://github.com/microsoft/DeepSpeed.">this https URL</a> Part of this paper is from our previous arxiv report (<a href="/abs/2211.11586">arXiv:2211.11586</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03822" title="Abstract">arXiv:2212.03822</a> (replaced) [<a href="/pdf/2212.03822" title="Download PDF">pdf</a>, <a href="/format/2212.03822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic weakly over-penalised symmetric interior penalty method for  the Stokes equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ishizaka%2C+H">Hiroki Ishizaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 11 figures, 19 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.06244" title="Abstract">arXiv:2212.06244</a> (replaced) [<a href="/pdf/2212.06244" title="Download PDF">pdf</a>, <a href="/format/2212.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PathFusion: Path-consistent Lidar-Camera Deep Feature Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lemeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yunyang Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthi%2C+R">Raghuraman Krishnamoorthi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08949" title="Abstract">arXiv:2212.08949</a> (replaced) [<a href="/pdf/2212.08949" title="Download PDF">pdf</a>, <a href="/format/2212.08949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Managing Temporal Resolution in Continuous Value Estimation: A  Fundamental Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kirschner%2C+J">Johannes Kirschner</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zanini%2C+F">Francesco Zanini</a>, 
<a href="/search/cs?searchtype=author&query=Ayoub%2C+A">Alex Ayoub</a>, 
<a href="/search/cs?searchtype=author&query=Dehghan%2C+M">Masood Dehghan</a>, 
<a href="/search/cs?searchtype=author&query=Schuurmans%2C+D">Dale Schuurmans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11542" title="Abstract">arXiv:2212.11542</a> (replaced) [<a href="/pdf/2212.11542" title="Download PDF">pdf</a>, <a href="/format/2212.11542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask Focal Loss: A unifying framework for dense crowd counting with  canonical object detection networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xiaopin Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weixiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Yuanlong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript is accepted by Multimedia Tools and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12024" title="Abstract">arXiv:2212.12024</a> (replaced) [<a href="/pdf/2212.12024" title="Download PDF">pdf</a>, <a href="/format/2212.12024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Playing Safe, Ten Years Later
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Colcombet%2C+T">Thomas Colcombet</a>, 
<a href="/search/cs?searchtype=author&query=Fijalkow%2C+N">Nathana&#xeb;l Fijalkow</a>, 
<a href="/search/cs?searchtype=author&query=Horn%2C+F">Florian Horn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13239" title="Abstract">arXiv:2212.13239</a> (replaced) [<a href="/pdf/2212.13239" title="Download PDF">pdf</a>, <a href="/ps/2212.13239" title="Download PostScript">ps</a>, <a href="/format/2212.13239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Mean Field Ensemble Kalman Filter: Near-Gaussian Setting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carrillo%2C+J+A">J. A. Carrillo</a>, 
<a href="/search/math?searchtype=author&query=Hoffmann%2C+F">F. Hoffmann</a>, 
<a href="/search/math?searchtype=author&query=Stuart%2C+A+M">A. M. Stuart</a>, 
<a href="/search/math?searchtype=author&query=Vaes%2C+U">U. Vaes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14566" title="Abstract">arXiv:2212.14566</a> (replaced) [<a href="/pdf/2212.14566" title="Download PDF">pdf</a>, <a href="/format/2212.14566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pontryagin Optimal Control via Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gu%2C+C">Chengyang Gu</a>, 
<a href="/search/eess?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yize Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00761" title="Abstract">arXiv:2301.00761</a> (replaced) [<a href="/pdf/2301.00761" title="Download PDF">pdf</a>, <a href="/format/2301.00761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The non-intrusive reduced basis two-grid method applied to sensitivity  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Grosjean%2C+E">Elise Grosjean</a>, 
<a href="/search/math?searchtype=author&query=Simeon%2C+B">Bernd Simeon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 3 figures. arXiv admin note: text overlap with <a href="/abs/2211.08897">arXiv:2211.08897</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03250" title="Abstract">arXiv:2301.03250</a> (replaced) [<a href="/pdf/2301.03250" title="Download PDF">pdf</a>, <a href="/format/2301.03250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the resilience of cellular networks: how can national roaming help?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weedage%2C+L">Lotte Weedage</a>, 
<a href="/search/cs?searchtype=author&query=Rangel%2C+S">Syllas Rangel</a>, 
<a href="/search/cs?searchtype=author&query=Stegehuis%2C+C">Clara Stegehuis</a>, 
<a href="/search/cs?searchtype=author&query=Bayhan%2C+S">Suzan Bayhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Network and Service Management, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05246" title="Abstract">arXiv:2301.05246</a> (replaced) [<a href="/pdf/2301.05246" title="Download PDF">pdf</a>, <a href="/format/2301.05246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Class-Incremental Learning For Real-World Food Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raghavan%2C+S">Siddeshwar Raghavan</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jiangpeng He</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fengqing Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06230" title="Abstract">arXiv:2301.06230</a> (replaced) [<a href="/pdf/2301.06230" title="Download PDF">pdf</a>, <a href="/format/2301.06230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swarm-SLAM : Sparse Decentralized Collaborative Simultaneous  Localization and Mapping Framework for Multi-Robot Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lajoie%2C+P">Pierre-Yves Lajoie</a>, 
<a href="/search/cs?searchtype=author&query=Beltrame%2C+G">Giovanni Beltrame</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/MISTLab/Swarm-SLAM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08422" title="Abstract">arXiv:2301.08422</a> (replaced) [<a href="/pdf/2301.08422" title="Download PDF">pdf</a>, <a href="/format/2301.08422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A vision-based autonomous UAV inspection framework for unknown tunnel  construction sites with dynamic obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Baihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiaoyang Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Xiu%2C+Y">Yumeng Xiu</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+C">Christopher Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters, Volume: 8, Issue: 8, June
  2023. Page(s): 4983 - 4990
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09217" title="Abstract">arXiv:2301.09217</a> (replaced) [<a href="/pdf/2301.09217" title="Download PDF">pdf</a>, <a href="/format/2301.09217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplicative Auction Algorithm for Approximate Maximum Weight  Bipartite Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D+W">Da Wei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in IPCO 2023. The newest version of the paper improves the runtime by a log(1/eps) factor. The first version claimed result that the dynamic data structure supported arbitrary edge deletion has been corrected to one-sided vertex deletion and other side vertex insertion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09734" title="Abstract">arXiv:2301.09734</a> (replaced) [<a href="/pdf/2301.09734" title="Download PDF">pdf</a>, <a href="/format/2301.09734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Learning in Multi-Class Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Griffin%2C+C">Christopher Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Karn%2C+T">Trevor Karn</a>, 
<a href="/search/cs?searchtype=author&query=Apple%2C+B">Benjamin Apple</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 18 figures. This is a revision of v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10260" title="Abstract">arXiv:2301.10260</a> (replaced) [<a href="/pdf/2301.10260" title="Download PDF">pdf</a>, <a href="/format/2301.10260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Interferometric Imaging for the SPIDER Instrument
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Mars%2C+M">Matthijs Mars</a>, 
<a href="/search/astro-ph?searchtype=author&query=Betcke%2C+M+M">Marta M. Betcke</a>, 
<a href="/search/astro-ph?searchtype=author&query=McEwen%2C+J+D">Jason D. McEwen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> RAS Techniques and Instruments, Volume 2, Issue 1, January 2023,
  Pages 760-778
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11578" title="Abstract">arXiv:2301.11578</a> (replaced) [<a href="/pdf/2301.11578" title="Download PDF">pdf</a>, <a href="/format/2301.11578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Unlearn: Instance-wise Unlearning for Pre-trained  Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cha%2C+S">Sungmin Cha</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sungjun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Dasol Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Honglak Lee</a>, 
<a href="/search/cs?searchtype=author&query=Moon%2C+T">Taesup Moon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Moontae Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12453" title="Abstract">arXiv:2301.12453</a> (replaced) [<a href="/pdf/2301.12453" title="Download PDF">pdf</a>, <a href="/format/2301.12453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APPT: Boosting Automated Patch Correctness Prediction via Fine-tuning  Pre-trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weisong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tieke He</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+X">Xiaodong Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Transactions on Software Engineering 2024 (TSE'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12755" title="Abstract">arXiv:2301.12755</a> (replaced) [<a href="/pdf/2301.12755" title="Download PDF">pdf</a>, <a href="/format/2301.12755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Node Selection in Private Personalized Decentralized Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zec%2C+E+L">Edvin Listo Zec</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96stman%2C+J">Johan &#xd6;stman</a>, 
<a href="/search/cs?searchtype=author&query=Mogren%2C+O">Olof Mogren</a>, 
<a href="/search/cs?searchtype=author&query=Gillblad%2C+D">Daniel Gillblad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12759" title="Abstract">arXiv:2301.12759</a> (replaced) [<a href="/pdf/2301.12759" title="Download PDF">pdf</a>, <a href="/format/2301.12759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning passive policies with virtual energy tanks in robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zanella%2C+R">Riccardo Zanella</a>, 
<a href="/search/cs?searchtype=author&query=Palli%2C+G">Gianluca Palli</a>, 
<a href="/search/cs?searchtype=author&query=Stramigioli%2C+S">Stefano Stramigioli</a>, 
<a href="/search/cs?searchtype=author&query=Califano%2C+F">Federico Califano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01212" title="Abstract">arXiv:2302.01212</a> (replaced) [<a href="/pdf/2302.01212" title="Download PDF">pdf</a>, <a href="/format/2302.01212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explicit two-sided unique-neighbor expanders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hsieh%2C+J">Jun-Ting Hsieh</a>, 
<a href="/search/math?searchtype=author&query=McKenzie%2C+T">Theo McKenzie</a>, 
<a href="/search/math?searchtype=author&query=Mohanty%2C+S">Sidhanth Mohanty</a>, 
<a href="/search/math?searchtype=author&query=Paredes%2C+P">Pedro Paredes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> New version contains stronger result, and many new technical ingredients. 45 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01463" title="Abstract">arXiv:2302.01463</a> (replaced) [<a href="/pdf/2302.01463" title="Download PDF">pdf</a>, <a href="/format/2302.01463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Descent with Linearly Correlated Noise: Theory and Applications  to Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koloskova%2C+A">Anastasia Koloskova</a>, 
<a href="/search/cs?searchtype=author&query=McKenna%2C+R">Ryan McKenna</a>, 
<a href="/search/cs?searchtype=author&query=Charles%2C+Z">Zachary Charles</a>, 
<a href="/search/cs?searchtype=author&query=Rush%2C+K">Keith Rush</a>, 
<a href="/search/cs?searchtype=author&query=McMahan%2C+B">Brendan McMahan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02152" title="Abstract">arXiv:2302.02152</a> (replaced) [<a href="/pdf/2302.02152" title="Download PDF">pdf</a>, <a href="/ps/2302.02152" title="Download PostScript">ps</a>, <a href="/format/2302.02152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extremal digraphs for open neighbourhood location-domination and  identifying codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Foucaud%2C+F">Florent Foucaud</a>, 
<a href="/search/math?searchtype=author&query=Ghareghani%2C+N">Narges Ghareghani</a>, 
<a href="/search/math?searchtype=author&query=Sharifani%2C+P">Pouyeh Sharifani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Applied Mathematics 347:62-74, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04511" title="Abstract">arXiv:2302.04511</a> (replaced) [<a href="/pdf/2302.04511" title="Download PDF">pdf</a>, <a href="/format/2302.04511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ShabaniMirzaei%2C+T">Taha ShabaniMirzaei</a>, 
<a href="/search/cs?searchtype=author&query=Chamani%2C+H">Houmaan Chamani</a>, 
<a href="/search/cs?searchtype=author&query=Abaskohi%2C+A">Amirhossein Abaskohi</a>, 
<a href="/search/cs?searchtype=author&query=Zadeh%2C+Z+S+H">Zhivar Sourati Hassan Zadeh</a>, 
<a href="/search/cs?searchtype=author&query=Bahrak%2C+B">Behnam Bahrak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Soc. Netw. Anal. Min. 13, 148 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04925" title="Abstract">arXiv:2302.04925</a> (replaced) [<a href="/pdf/2302.04925" title="Download PDF">pdf</a>, <a href="/ps/2302.04925" title="Download PostScript">ps</a>, <a href="/format/2302.04925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information Theoretic Lower Bounds for Information Theoretic Upper  Bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Livni%2C+R">Roi Livni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09633" title="Abstract">arXiv:2302.09633</a> (replaced) [<a href="/pdf/2302.09633" title="Download PDF">pdf</a>, <a href="/ps/2302.09633" title="Download PostScript">ps</a>, <a href="/format/2302.09633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Optimal Tradeoffs between EFX and Nash Welfare
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldman%2C+M">Michal Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Mauras%2C+S">Simon Mauras</a>, 
<a href="/search/cs?searchtype=author&query=Ponitka%2C+T">Tomasz Ponitka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12024" title="Abstract">arXiv:2302.12024</a> (replaced) [<a href="/pdf/2302.12024" title="Download PDF">pdf</a>, <a href="/format/2302.12024" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Study of Coupling and Autoregressive Flows through Robust  Statistical Tests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Coccaro%2C+A">Andrea Coccaro</a>, 
<a href="/search/stat?searchtype=author&query=Letizia%2C+M">Marco Letizia</a>, 
<a href="/search/stat?searchtype=author&query=Reyes-Gonzalez%2C+H">Humberto Reyes-Gonzalez</a>, 
<a href="/search/stat?searchtype=author&query=Torre%2C+R">Riccardo Torre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2: Title changed; Substantially improved statistical approach, including uncertainties; Highly multimodal/Truncated gaussian benchmarks removed; 23 Pages, 2 Figures, 3 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); High Energy Physics - Phenomenology (hep-ph)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12473" title="Abstract">arXiv:2302.12473</a> (replaced) [<a href="/pdf/2302.12473" title="Download PDF">pdf</a>, <a href="/ps/2302.12473" title="Download PostScript">ps</a>, <a href="/format/2302.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubalgebraBases in Macaulay2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burr%2C+M">Michael Burr</a>, 
<a href="/search/math?searchtype=author&query=Clarke%2C+O">Oliver Clarke</a>, 
<a href="/search/math?searchtype=author&query=Duff%2C+T">Timothy Duff</a>, 
<a href="/search/math?searchtype=author&query=Leaman%2C+J">Jackson Leaman</a>, 
<a href="/search/math?searchtype=author&query=Nichols%2C+N">Nathan Nichols</a>, 
<a href="/search/math?searchtype=author&query=Walker%2C+E">Elise Walker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version. 11 pages w/ refs. Ancillary file "accompanyingCode.m2" available on arXiv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13600" title="Abstract">arXiv:2302.13600</a> (replaced) [<a href="/pdf/2302.13600" title="Download PDF">pdf</a>, <a href="/ps/2302.13600" title="Download PostScript">ps</a>, <a href="/format/2302.13600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-place fast polynomial modular remainder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jean-Guillaume Dumas</a> (CASC), 
<a href="/search/cs?searchtype=author&query=Grenet%2C+B">Bruno Grenet</a> (CASC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02561" title="Abstract">arXiv:2303.02561</a> (replaced) [<a href="/e-print/2303.02561" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMEL: Curvature-Augmented Manifold Embedding and Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The original results reported in the original manuscript cannot be reproduced by a valid code from the first author. The first author stated that the original code was lost during a computer crash and cannot be retrieved. The corresponding author decided to withdraw the manuscript for further evaluation before resubmission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03374" title="Abstract">arXiv:2303.03374</a> (replaced) [<a href="/pdf/2303.03374" title="Download PDF">pdf</a>, <a href="/format/2303.03374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in  Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadrtdinov%2C+I">Ildus Sadrtdinov</a>, 
<a href="/search/cs?searchtype=author&query=Pozdeev%2C+D">Dmitrii Pozdeev</a>, 
<a href="/search/cs?searchtype=author&query=Vetrov%2C+D">Dmitry Vetrov</a>, 
<a href="/search/cs?searchtype=author&query=Lobacheva%2C+E">Ekaterina Lobacheva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in NeurIPS 2023. First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06268" title="Abstract">arXiv:2303.06268</a> (replaced) [<a href="/pdf/2303.06268" title="Download PDF">pdf</a>, <a href="/format/2303.06268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust your neighbours: Penalty-based constraints for model calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murugesan%2C+B">Balamurali Murugesan</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+S+A">Sukesh Adiga V</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lombaert%2C+H">Herv&#xe9; Lombaert</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=Dolz%2C+J">Jose Dolz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06524" title="Abstract">arXiv:2303.06524</a> (replaced) [<a href="/pdf/2303.06524" title="Download PDF">pdf</a>, <a href="/ps/2303.06524" title="Download PostScript">ps</a>, <a href="/format/2303.06524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Record-Breaking Condorcet Domains on 10 and 11 Alternatives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07995" title="Abstract">arXiv:2303.07995</a> (replaced) [<a href="/pdf/2303.07995" title="Download PDF">pdf</a>, <a href="/format/2303.07995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing a 3D Gestural Interface to Support User Interaction with  Time-Oriented Data as Immersive 3D Radar Chart
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reski%2C+N">Nico Reski</a>, 
<a href="/search/cs?searchtype=author&query=Alissandrakis%2C+A">Aris Alissandrakis</a>, 
<a href="/search/cs?searchtype=author&query=Kerren%2C+A">Andreas Kerren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 6 figures, 2 tables; this version corrects Figure 6 (boxplot of PU in the UES-SF scores) and related discussion in Section 6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11593" title="Abstract">arXiv:2303.11593</a> (replaced) [<a href="/pdf/2303.11593" title="Download PDF">pdf</a>, <a href="/ps/2303.11593" title="Download PostScript">ps</a>, <a href="/format/2303.11593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Difficulty in chirality recognition for Transformer architectures  learning chemical structures from string
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshikai%2C+Y">Yasuhiro Yoshikai</a>, 
<a href="/search/cs?searchtype=author&query=Mizuno%2C+T">Tadahaya Mizuno</a>, 
<a href="/search/cs?searchtype=author&query=Nemoto%2C+S">Shumpei Nemoto</a>, 
<a href="/search/cs?searchtype=author&query=Kusuhara%2C+H">Hiroyuki Kusuhara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Chemical Physics (physics.chem-ph); Biomolecules (q-bio.BM)

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13310" title="Abstract">arXiv:2303.13310</a> (replaced) [<a href="/pdf/2303.13310" title="Download PDF">pdf</a>, <a href="/format/2303.13310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwissBERT: The Multilingual Language Model for Switzerland
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Gra%C3%ABn%2C+J">Johannes Gra&#xeb;n</a>, 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SwissText 2023 [v3: Changed template because the proceedings moved to a different publisher. Same content.]
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13506" title="Abstract">arXiv:2303.13506</a> (replaced) [<a href="/pdf/2303.13506" title="Download PDF">pdf</a>, <a href="/format/2303.13506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quantization Model of Neural Scaling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michaud%2C+E+J">Eric J. Michaud</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Girit%2C+U">Uzay Girit</a>, 
<a href="/search/cs?searchtype=author&query=Tegmark%2C+M">Max Tegmark</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 18 figures, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14226" title="Abstract">arXiv:2303.14226</a> (replaced) [<a href="/pdf/2303.14226" title="Download PDF">pdf</a>, <a href="/format/2303.14226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Combinations: A Causal Inference Framework for Combinatorial  Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Agarwal%2C+A">Abhineet Agarwal</a>, 
<a href="/search/stat?searchtype=author&query=Agarwal%2C+A">Anish Agarwal</a>, 
<a href="/search/stat?searchtype=author&query=Vijaykumar%2C+S">Suhas Vijaykumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Econometrics (econ.EM); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14822" title="Abstract">arXiv:2303.14822</a> (replaced) [<a href="/pdf/2303.14822" title="Download PDF">pdf</a>, <a href="/format/2303.14822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGTBench: Benchmarking Machine-Generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xinlei He</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xinyue Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zeyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14994" title="Abstract">arXiv:2303.14994</a> (replaced) [<a href="/pdf/2303.14994" title="Download PDF">pdf</a>, <a href="/format/2303.14994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of DNA sequences through local distribution of nucleotides in  strategic neighborhoods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+P">Probir Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+P">Pratyay Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Basuli%2C+K">Krishnendu Basuli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17503" title="Abstract">arXiv:2303.17503</a> (replaced) [<a href="/pdf/2303.17503" title="Download PDF">pdf</a>, <a href="/format/2303.17503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pgx: Hardware-Accelerated Parallel Game Simulators for Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koyamada%2C+S">Sotetsu Koyamada</a>, 
<a href="/search/cs?searchtype=author&query=Okano%2C+S">Shinri Okano</a>, 
<a href="/search/cs?searchtype=author&query=Nishimori%2C+S">Soichiro Nishimori</a>, 
<a href="/search/cs?searchtype=author&query=Murata%2C+Y">Yu Murata</a>, 
<a href="/search/cs?searchtype=author&query=Habara%2C+K">Keigo Habara</a>, 
<a href="/search/cs?searchtype=author&query=Kita%2C+H">Haruka Kita</a>, 
<a href="/search/cs?searchtype=author&query=Ishii%2C+S">Shin Ishii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17510" title="Abstract">arXiv:2303.17510</a> (replaced) [<a href="/pdf/2303.17510" title="Download PDF">pdf</a>, <a href="/format/2303.17510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Dealiasing of Complex Convolutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Murasko%2C+N">Noel Murasko</a>, 
<a href="/search/math?searchtype=author&query=Bowman%2C+J+C">John C. Bowman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 17 figures, to appear in the SIAM Journal on Scientific Computing. Code can be found at <a href="https://github.com/dealias/fftwpp">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02538" title="Abstract">arXiv:2304.02538</a> (replaced) [<a href="/pdf/2304.02538" title="Download PDF">pdf</a>, <a href="/format/2304.02538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability and Latency Analysis for Wireless Communication Systems with  a Secret-Key Budget
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Besser%2C+K">Karl-Ludwig Besser</a>, 
<a href="/search/cs?searchtype=author&query=Schaefer%2C+R+F">Rafael F. Schaefer</a>, 
<a href="/search/cs?searchtype=author&query=Poor%2C+H+V">H. Vincent Poor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03930" title="Abstract">arXiv:2304.03930</a> (replaced) [<a href="/pdf/2304.03930" title="Download PDF">pdf</a>, <a href="/format/2304.03930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Photometric Correction for Infrared Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jincheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Brink%2C+K">Kevin Brink</a>, 
<a href="/search/cs?searchtype=author&query=Willis%2C+A+R">Andrew R Willis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04162" title="Abstract">arXiv:2304.04162</a> (replaced) [<a href="/pdf/2304.04162" title="Download PDF">pdf</a>, <a href="/format/2304.04162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Two-Level Incentive Mechanisms for Hierarchical Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+S">Shunfeng Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+K">Kang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yuwen Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kunlun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+F">Feng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04558" title="Abstract">arXiv:2304.04558</a> (replaced) [<a href="/pdf/2304.04558" title="Download PDF">pdf</a>, <a href="/ps/2304.04558" title="Download PostScript">ps</a>, <a href="/format/2304.04558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShakingBot: Dynamic Manipulation for Bagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+N">Ningquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhizhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruhan He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lianqing Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manipulating bag through robots to bagging
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04939" title="Abstract">arXiv:2304.04939</a> (replaced) [<a href="/pdf/2304.04939" title="Download PDF">pdf</a>, <a href="/format/2304.04939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal dual-port grid-forming control: bridging the gap between  grid-forming and grid-following control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Suboti%C4%87%2C+I">Irina Suboti&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Gro%C3%9F%2C+a+D">and Dominic Gro&#xdf;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04951" title="Abstract">arXiv:2304.04951</a> (replaced) [<a href="/pdf/2304.04951" title="Download PDF">pdf</a>, <a href="/format/2304.04951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing the Tracy-Widom Distribution for Arbitrary $&#x3b2;&gt;0$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Trogdon%2C+T">Thomas Trogdon</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yiting Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGMA 20 (2024), 005, 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04978" title="Abstract">arXiv:2304.04978</a> (replaced) [<a href="/pdf/2304.04978" title="Download PDF">pdf</a>, <a href="/format/2304.04978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StageInteractor: Query-based Object Detector with Cross-stage  Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teng%2C+Y">Yao Teng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Sheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Limin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05492" title="Abstract">arXiv:2304.05492</a> (replaced) [<a href="/pdf/2304.05492" title="Download PDF">pdf</a>, <a href="/format/2304.05492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards More Robust and Accurate Sequential Recommendation with  Cascade-guided Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Juntao Tan</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongjun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to present at SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06294" title="Abstract">arXiv:2304.06294</a> (replaced) [<a href="/pdf/2304.06294" title="Download PDF">pdf</a>, <a href="/format/2304.06294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When do homomorphism counts help in query algorithms?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="/search/cs?searchtype=author&query=Dalmau%2C+V">V&#xed;ctor Dalmau</a>, 
<a href="/search/cs?searchtype=author&query=Kolaitis%2C+P+G">Phokion G. Kolaitis</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wei-Lin Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06340" title="Abstract">arXiv:2304.06340</a> (replaced) [<a href="/pdf/2304.06340" title="Download PDF">pdf</a>, <a href="/format/2304.06340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing weak distance between the 2-sphere and its nonsmooth  approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Koga%2C+K">Kazuki Koga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06646" title="Abstract">arXiv:2304.06646</a> (replaced) [<a href="/pdf/2304.06646" title="Download PDF">pdf</a>, <a href="/ps/2304.06646" title="Download PostScript">ps</a>, <a href="/format/2304.06646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising Modal Formulas with Examples
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cate%2C+B+t">Balder ten Cate</a>, 
<a href="/search/cs?searchtype=author&query=Koudijs%2C+R">Raoul Koudijs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Expanded version of material from Raoul Koudijs's MSc thesis (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07735" title="Abstract">arXiv:2304.07735</a> (replaced) [<a href="/pdf/2304.07735" title="Download PDF">pdf</a>, <a href="/format/2304.07735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation Equivariance of Transformers and Its Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hengyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Liyao Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hangyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+D">Dixi Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P">Pengzhi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baochun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07967" title="Abstract">arXiv:2304.07967</a> (replaced) [<a href="/pdf/2304.07967" title="Download PDF">pdf</a>, <a href="/format/2304.07967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 360$^\circ$ High-Resolution Depth Estimation via Uncertainty-aware  Structural Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zidong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+H">Hao Ai</a>, 
<a href="/search/cs?searchtype=author&query=Vasilakos%2C+A+V">Athanasios V. Vasilakos</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09221" title="Abstract">arXiv:2304.09221</a> (replaced) [<a href="/pdf/2304.09221" title="Download PDF">pdf</a>, <a href="/ps/2304.09221" title="Download PostScript">ps</a>, <a href="/format/2304.09221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of stochastic gradient descent under a local Lojasiewicz  condition for deep neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+J">Jing An</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jianfeng Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2 fixed several mistakes. Some parts have been rewritten
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10050" title="Abstract">arXiv:2304.10050</a> (replaced) [<a href="/pdf/2304.10050" title="Download PDF">pdf</a>, <a href="/format/2304.10050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Radiance Fields: Past, Present, and Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mittal%2C+A">Ansh Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 413 pages, 9 figures, 277 citations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10681" title="Abstract">arXiv:2304.10681</a> (replaced) [<a href="/pdf/2304.10681" title="Download PDF">pdf</a>, <a href="/ps/2304.10681" title="Download PostScript">ps</a>, <a href="/format/2304.10681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simplicity bubble problem and zemblanity in digitally intermediated  societies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abrah%C3%A3o%2C+F+S">Felipe S. Abrah&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Cavassane%2C+R+P">Ricardo P. Cavassane</a>, 
<a href="/search/cs?searchtype=author&query=Winter%2C+M">Michael Winter</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+M+V">Mariana Vitti Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=D%27Ottaviano%2C+I+M+L">Itala M. L. D&#x27;Ottaviano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10765" title="Abstract">arXiv:2304.10765</a> (replaced) [<a href="/pdf/2304.10765" title="Download PDF">pdf</a>, <a href="/format/2304.10765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BPJDet: Extended Object Representation for Generic Body-Part Joint  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Huayi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+J">Jiaxin Si</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yue Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended journal version of <a href="/abs/2212.07652">arXiv:2212.07652</a>. Accepted by TPAMI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10771" title="Abstract">arXiv:2304.10771</a> (replaced) [<a href="/pdf/2304.10771" title="Download PDF">pdf</a>, <a href="/format/2304.10771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Revisit of the Normalized Eight-Point Algorithm and A Self-Supervised  Deep Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+B">Bin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yuchao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+Y">Yongduek Seo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+M">Mingyi He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Visual Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10801" title="Abstract">arXiv:2304.10801</a> (replaced) [<a href="/pdf/2304.10801" title="Download PDF">pdf</a>, <a href="/format/2304.10801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Protection Against Graph-Based False Data Injection Attacks on Power  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morgenstern%2C+G">Gal Morgenstern</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jip Kim</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+J">James Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Zussman%2C+G">Gil Zussman</a>, 
<a href="/search/eess?searchtype=author&query=Routtenberg%2C+T">Tirza Routtenberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11842" title="Abstract">arXiv:2304.11842</a> (replaced) [<a href="/pdf/2304.11842" title="Download PDF">pdf</a>, <a href="/format/2304.11842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gen-NeRF: Efficient and Generalizable Neural Radiance Fields via  Algorithm-Hardware Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yonggan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhifan Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiayi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shunyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haoran You</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingyan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISCA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12467" title="Abstract">arXiv:2304.12467</a> (replaced) [<a href="/pdf/2304.12467" title="Download PDF">pdf</a>, <a href="/format/2304.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instant-3D: Instant Neural Radiance Field Training Towards On-Device  AR/VR 3D Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenbo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Boyang">Boyang</a> (Tony)Yu, 
<a href="/search/cs?searchtype=author&query=Yang">Yang</a> (Katie)
<a href="/search/cs?searchtype=author&query=Zhao">Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+C">Cheng Wan</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haoran You</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Huihong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yingyan">Yingyan</a> (Celine)Lin
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISCA'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14096" title="Abstract">arXiv:2304.14096</a> (replaced) [<a href="/pdf/2304.14096" title="Download PDF">pdf</a>, <a href="/format/2304.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable quantum circuits for $n$-qubit unitary matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sarkar%2C+R+S">Rohit Sarma Sarkar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adhikari%2C+B">Bibhas Adhikari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in IEEE QCE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00935" title="Abstract">arXiv:2305.00935</a> (replaced) [<a href="/pdf/2305.00935" title="Download PDF">pdf</a>, <a href="/ps/2305.00935" title="Download PostScript">ps</a>, <a href="/format/2305.00935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embeddability of graphs and Weihrauch degrees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cipriani%2C+V">Vittorio Cipriani</a>, 
<a href="/search/math?searchtype=author&query=Pauly%2C+A">Arno Pauly</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02209" title="Abstract">arXiv:2305.02209</a> (replaced) [<a href="/pdf/2305.02209" title="Download PDF">pdf</a>, <a href="/format/2305.02209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Online Ridesharing: The Effect of Assignment Optimality on  System Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fiedler%2C+D">David Fiedler</a>, 
<a href="/search/math?searchtype=author&query=%C4%8Certick%C3%BD%2C+M">Michal &#x10c;ertick&#xfd;</a>, 
<a href="/search/math?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>, 
<a href="/search/math?searchtype=author&query=P%C4%9Bchou%C4%8Dek%2C+M">Michal P&#x11b;chou&#x10d;ek</a>, 
<a href="/search/math?searchtype=author&query=%C4%8C%C3%A1p%2C+M">Michal &#x10c;&#xe1;p</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Manuscript version. Currently published online in the Journal of Intelligent Transportation Systems: <a href="https://www.tandfonline.com/doi/abs/10.1080/15472450.2022.2121651">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> (2022) Large-scale online ridesharing: the effect of assignment
  optimality on system performance, Journal of Intelligent Transportation
  Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02957" title="Abstract">arXiv:2305.02957</a> (replaced) [<a href="/pdf/2305.02957" title="Download PDF">pdf</a>, <a href="/format/2305.02957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Monoidal View on Fixpoint Checks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldan%2C+P">Paolo Baldan</a>, 
<a href="/search/cs?searchtype=author&query=Eggert%2C+R">Richard Eggert</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%B6nig%2C+B">Barbara K&#xf6;nig</a>, 
<a href="/search/cs?searchtype=author&query=Matt%2C+T">Timo Matt</a>, 
<a href="/search/cs?searchtype=author&query=Padoan%2C+T">Tommaso Padoan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04323" title="Abstract">arXiv:2305.04323</a> (replaced) [<a href="/pdf/2305.04323" title="Download PDF">pdf</a>, <a href="/format/2305.04323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Muller to Parity and Rabin Automata: Optimal Transformations  Preserving (History-)Determinism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Casares%2C+A">Antonio Casares</a>, 
<a href="/search/cs?searchtype=author&query=Colcombet%2C+T">Thomas Colcombet</a>, 
<a href="/search/cs?searchtype=author&query=Fijalkow%2C+N">Nathana&#xeb;l Fijalkow</a>, 
<a href="/search/cs?searchtype=author&query=Lehtinen%2C+K">Karoliina Lehtinen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of an ICALP 2021 paper. It also includes content from an ICALP 2022 paper. Version 2: Added content in Section 6.2 (Theorem 6.27)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06435" title="Abstract">arXiv:2305.06435</a> (replaced) [<a href="/pdf/2305.06435" title="Download PDF">pdf</a>, <a href="/format/2305.06435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase transitions in the mini-batch size for sparse and dense two-layer  neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Marino%2C+R">Raffaele Marino</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ricci-Tersenghi%2C+F">Federico Ricci-Tersenghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine Learning: Science and Technology (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06548" title="Abstract">arXiv:2305.06548</a> (replaced) [<a href="/pdf/2305.06548" title="Download PDF">pdf</a>, <a href="/ps/2305.06548" title="Download PostScript">ps</a>, <a href="/format/2305.06548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Layered Modal Type Theories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J+Z+S">Jason Z. S. Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pientka%2C+B">Brigitte Pientka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06671" title="Abstract">arXiv:2305.06671</a> (replaced) [<a href="/pdf/2305.06671" title="Download PDF">pdf</a>, <a href="/format/2305.06671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WeditGAN: Few-Shot Image Generation via Latent Space Relocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuxuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Li Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liqing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024, see Appendix for update notes of this version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06863" title="Abstract">arXiv:2305.06863</a> (replaced) [<a href="/pdf/2305.06863" title="Download PDF">pdf</a>, <a href="/format/2305.06863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Finite Volume Method for High-Dimensional Partial Differential  Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cen%2C+J">Jianhuan Cen</a>, 
<a href="/search/math?searchtype=author&query=Zou%2C+Q">Qingsong Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07195" title="Abstract">arXiv:2305.07195</a> (replaced) [<a href="/pdf/2305.07195" title="Download PDF">pdf</a>, <a href="/format/2305.07195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Modeling of In Vivo and In Vitro Effects of Nondepolarizing  Neuromuscular Blocking Drugs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hoshino%2C+H">Hikaru Hoshino</a>, 
<a href="/search/eess?searchtype=author&query=Furutani%2C+E">Eiko Furutani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07515" title="Abstract">arXiv:2305.07515</a> (replaced) [<a href="/pdf/2305.07515" title="Download PDF">pdf</a>, <a href="/format/2305.07515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Shape Optimization Pipeline for Marine Propellers by means of Reduced  Order Modeling Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ivagnes%2C+A">Anna Ivagnes</a>, 
<a href="/search/math?searchtype=author&query=Demo%2C+N">Nicola Demo</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal for Numerical Methods in Engineering (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07522" title="Abstract">arXiv:2305.07522</a> (replaced) [<a href="/pdf/2305.07522" title="Download PDF">pdf</a>, <a href="/format/2305.07522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPADE: Sparse Pillar-based 3D Object Detection Accelerator for  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seongmin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungmin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+M">Minyong Yoon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Janghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+W">Jun Won Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+N+S">Nam Sung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Mingu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jungwook Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09373" title="Abstract">arXiv:2305.09373</a> (replaced) [<a href="/pdf/2305.09373" title="Download PDF">pdf</a>, <a href="/format/2305.09373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-task convolutional neural network for image aesthetic assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soydaner%2C+D">Derya Soydaner</a>, 
<a href="/search/cs?searchtype=author&query=Wagemans%2C+J">Johan Wagemans</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, vol. 12, pp. 4716-4729, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10005" title="Abstract">arXiv:2305.10005</a> (replaced) [<a href="/pdf/2305.10005" title="Download PDF">pdf</a>, <a href="/format/2305.10005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DinoSR: Self-Distillation and Online Clustering for Self-supervised  Speech Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A+H">Alexander H. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Heng-Jui Chang</a>, 
<a href="/search/cs?searchtype=author&query=Auli%2C+M">Michael Auli</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">Wei-Ning Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Glass%2C+J+R">James R. Glass</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10818" title="Abstract">arXiv:2305.10818</a> (replaced) [<a href="/pdf/2305.10818" title="Download PDF">pdf</a>, <a href="/format/2305.10818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Language Models Generation Can Be Halted Early
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaina%2C+S+M+L+C">Sofia Maria Lo Cicero Vaina</a>, 
<a href="/search/cs?searchtype=author&query=Balagansky%2C+N">Nikita Balagansky</a>, 
<a href="/search/cs?searchtype=author&query=Gavrilov%2C+D">Daniil Gavrilov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11417" title="Abstract">arXiv:2305.11417</a> (replaced) [<a href="/pdf/2305.11417" title="Download PDF">pdf</a>, <a href="/ps/2305.11417" title="Download PostScript">ps</a>, <a href="/format/2305.11417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complexity of Deep Neural Networks from the Perspective of Functional  Equivalence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guohao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11554" title="Abstract">arXiv:2305.11554</a> (replaced) [<a href="/pdf/2305.11554" title="Download PDF">pdf</a>, <a href="/format/2305.11554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via  Tool Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shibo Hao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiting Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (oral). Code: <a href="https://github.com/Ber666/ToolkenGPT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12825" title="Abstract">arXiv:2305.12825</a> (replaced) [<a href="/pdf/2305.12825" title="Download PDF">pdf</a>, <a href="/format/2305.12825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-based Detection of Adversarial Attacks in Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maag%2C+K">Kira Maag</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+A">Asja Fischer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13887" title="Abstract">arXiv:2305.13887</a> (replaced) [<a href="/pdf/2305.13887" title="Download PDF">pdf</a>, <a href="/format/2305.13887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Vision and An Evolutionary Framework for 6G: Scenarios, Capabilities  and Enablers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R+Y">Ruyue Yu-Ngok Li</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to an IEEE Magazine
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14062" title="Abstract">arXiv:2305.14062</a> (replaced) [<a href="/pdf/2305.14062" title="Download PDF">pdf</a>, <a href="/format/2305.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amplitude-Independent Machine Learning for PPG through Visibility Graphs  and Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Miao%2C+Y">Yuyang Miao</a>, 
<a href="/search/eess?searchtype=author&query=Davies%2C+H+J">Harry J. Davies</a>, 
<a href="/search/eess?searchtype=author&query=Mandic%2C+D+P">Danilo P. Mandic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14252" title="Abstract">arXiv:2305.14252</a> (replaced) [<a href="/pdf/2305.14252" title="Download PDF">pdf</a>, <a href="/format/2305.14252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Kolmogorov complexity and quantum correlations in  deterministic-control quantum Turing machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lemus%2C+M">Mariano Lemus</a>, 
<a href="/search/quant-ph?searchtype=author&query=Faleiro%2C+R">Ricardo Faleiro</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mateus%2C+P">Paulo Mateus</a>, 
<a href="/search/quant-ph?searchtype=author&query=Paunkovi%C4%87%2C+N">Nikola Paunkovi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Souto%2C+A">Andr&#xe9; Souto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15313" title="Abstract">arXiv:2305.15313</a> (replaced) [<a href="/pdf/2305.15313" title="Download PDF">pdf</a>, <a href="/ps/2305.15313" title="Download PostScript">ps</a>, <a href="/format/2305.15313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Poisson Rejection Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Flamich%2C+G">Gergely Flamich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 2 figures. V2: Fixed a typo in Section 3 (was using $\tau$ instead of $t$ as a variable). Added missing Laplace-Laplace calculations in Appendix G.5. V3: Fixed Figure 2 and fixed an error in the proofs of Theorems 3.5 and 3.6 (now Theorems 3.6 and 3.7, respectively). Added a new bound (Thm 3.2) on the fractional moments of the index returned by GPRS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15944" title="Abstract">arXiv:2305.15944</a> (replaced) [<a href="/pdf/2305.15944" title="Download PDF">pdf</a>, <a href="/format/2305.15944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Turn Your Knowledge Graph Embeddings into Generative Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loconte%2C+L">Lorenzo Loconte</a>, 
<a href="/search/cs?searchtype=author&query=Di+Mauro%2C+N">Nicola Di Mauro</a>, 
<a href="/search/cs?searchtype=author&query=Peharz%2C+R">Robert Peharz</a>, 
<a href="/search/cs?searchtype=author&query=Vergari%2C+A">Antonio Vergari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16215" title="Abstract">arXiv:2305.16215</a> (replaced) [<a href="/pdf/2305.16215" title="Download PDF">pdf</a>, <a href="/format/2305.16215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopman Kernel Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bevanda%2C+P">Petar Bevanda</a>, 
<a href="/search/cs?searchtype=author&query=Beier%2C+M">Max Beier</a>, 
<a href="/search/cs?searchtype=author&query=Lederer%2C+A">Armin Lederer</a>, 
<a href="/search/cs?searchtype=author&query=Sosnowski%2C+S">Stefan Sosnowski</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCllermeier%2C+E">Eyke H&#xfc;llermeier</a>, 
<a href="/search/cs?searchtype=author&query=Hirche%2C+S">Sandra Hirche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16284" title="Abstract">arXiv:2305.16284</a> (replaced) [<a href="/pdf/2305.16284" title="Download PDF">pdf</a>, <a href="/format/2305.16284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khaled%2C+A">Ahmed Khaled</a>, 
<a href="/search/cs?searchtype=author&query=Mishchenko%2C+K">Konstantin Mishchenko</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 1 table, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16494" title="Abstract">arXiv:2305.16494</a> (replaced) [<a href="/pdf/2305.16494" title="Download PDF">pdf</a>, <a href="/format/2305.16494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Adversarial Sample Generation for Improved Stealthiness  and Controllability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haotian Xue</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Alexandre Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a conference paper in NeurIPS'2023. Code repo: <a href="https://github.com/xavihart/Diff-PGD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16501" title="Abstract">arXiv:2305.16501</a> (replaced) [<a href="/pdf/2305.16501" title="Download PDF">pdf</a>, <a href="/ps/2305.16501" title="Download PostScript">ps</a>, <a href="/format/2305.16501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strategic Classification under Unknown Personalized Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+H">Han Shao</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+A">Avrim Blum</a>, 
<a href="/search/cs?searchtype=author&query=Montasser%2C+O">Omar Montasser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16801" title="Abstract">arXiv:2305.16801</a> (replaced) [<a href="/pdf/2305.16801" title="Download PDF">pdf</a>, <a href="/format/2305.16801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Based Sign Language Video Summarization using Curvature and  Torsion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sartinas%2C+E+G">Evangelos G. Sartinas</a>, 
<a href="/search/cs?searchtype=author&query=Psarakis%2C+E+Z">Emmanouil Z. Psarakis</a>, 
<a href="/search/cs?searchtype=author&query=Kosmopoulos%2C+D+I">Dimitrios I. Kosmopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is under consideration at Pattern Recognition Letters for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17402" title="Abstract">arXiv:2305.17402</a> (replaced) [<a href="/pdf/2305.17402" title="Download PDF">pdf</a>, <a href="/format/2305.17402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning and Collusion in Multi-unit Auctions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%A2nzei%2C+S">Simina Br&#xe2;nzei</a>, 
<a href="/search/cs?searchtype=author&query=Derakhshan%2C+M">Mahsa Derakhshan</a>, 
<a href="/search/cs?searchtype=author&query=Golrezaei%2C+N">Negin Golrezaei</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yanjun Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 1 figure. In Proceedings of NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17547" title="Abstract">arXiv:2305.17547</a> (replaced) [<a href="/pdf/2305.17547" title="Download PDF">pdf</a>, <a href="/format/2305.17547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Translatotron 3: Speech to Speech Translation with Monolingual Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nachmani%2C+E">Eliya Nachmani</a>, 
<a href="/search/cs?searchtype=author&query=Levkovitch%2C+A">Alon Levkovitch</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yifan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Asawaroengchai%2C+C">Chulayuth Asawaroengchai</a>, 
<a href="/search/cs?searchtype=author&query=Zen%2C+H">Heiga Zen</a>, 
<a href="/search/cs?searchtype=author&query=Ramanovich%2C+M+T">Michelle Tadmor Ramanovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17727" title="Abstract">arXiv:2305.17727</a> (replaced) [<a href="/pdf/2305.17727" title="Download PDF">pdf</a>, <a href="/format/2305.17727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Structural Causal Model for Intuition Reasoning in  Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+B">Bingyu Liao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jing Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wenjing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Knowledge and Data Engineering early access
  (2024) 1-14
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17734" title="Abstract">arXiv:2305.17734</a> (replaced) [<a href="/pdf/2305.17734" title="Download PDF">pdf</a>, <a href="/ps/2305.17734" title="Download PostScript">ps</a>, <a href="/format/2305.17734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design, actuation, and functionalization of untethered soft magnetic  robots with life-like motions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+J">Jiaqi Miao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Siqi Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Magn. Magn. Mater. 586, 171160 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Soft Condensed Matter (cond-mat.soft)

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18342" title="Abstract">arXiv:2305.18342</a> (replaced) [<a href="/pdf/2305.18342" title="Download PDF">pdf</a>, <a href="/format/2305.18342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Task Synthesis for Visual Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C4%83durean%2C+V">Victor-Alexandru P&#x103;durean</a>, 
<a href="/search/cs?searchtype=author&query=Tzannetos%2C+G">Georgios Tzannetos</a>, 
<a href="/search/cs?searchtype=author&query=Singla%2C+A">Adish Singla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions on Machine Learning Research (TMLR) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18455" title="Abstract">arXiv:2305.18455</a> (replaced) [<a href="/pdf/2305.18455" title="Download PDF">pdf</a>, <a href="/format/2305.18455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-Instruct: A Universal Approach for Transferring Knowledge From  Pre-trained Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weijian Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Tianyang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shifeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiacheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihua Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19556" title="Abstract">arXiv:2305.19556</a> (replaced) [<a href="/pdf/2305.19556" title="Download PDF">pdf</a>, <a href="/format/2305.19556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Phonetic Context-Aware Lip-Sync For Talking Face Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+S+J">Se Jin Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19706" title="Abstract">arXiv:2305.19706</a> (replaced) [<a href="/pdf/2305.19706" title="Download PDF">pdf</a>, <a href="/format/2305.19706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necessary and Sufficient Conditions for Optimal Decision Trees using  Dynamic Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+der+Linden%2C+J+G+M">Jacobus G. M. van der Linden</a>, 
<a href="/search/cs?searchtype=author&query=de+Weerdt%2C+M+M">Mathijs M. de Weerdt</a>, 
<a href="/search/cs?searchtype=author&query=Demirovi%C4%87%2C+E">Emir Demirovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20004" title="Abstract">arXiv:2305.20004</a> (replaced) [<a href="/pdf/2305.20004" title="Download PDF">pdf</a>, <a href="/format/2305.20004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to solve Bayesian inverse problems: An amortized variational  inference approach using Gaussian and Flow guides
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karumuri%2C+S">Sharmila Karumuri</a>, 
<a href="/search/stat?searchtype=author&query=Bilionis%2C+I">Ilias Bilionis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.20089" title="Abstract">arXiv:2305.20089</a> (replaced) [<a href="/pdf/2305.20089" title="Download PDF">pdf</a>, <a href="/format/2305.20089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Explicit Contact for Implicit Reconstruction of Hand-held  Objects from Monocular Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Junxing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zerui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengcheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yebin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhenan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024.Code and model available at <a href="https://junxinghu.github.io/projects/hoi.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00196" title="Abstract">arXiv:2306.00196</a> (replaced) [<a href="/pdf/2306.00196" title="Download PDF">pdf</a>, <a href="/format/2306.00196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restless Bandits with Average Reward: Breaking the Uniform Global  Attractor Assumption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Yige Hong</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qiaomin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yudong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weina Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. 35 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00965" title="Abstract">arXiv:2306.00965</a> (replaced) [<a href="/pdf/2306.00965" title="Download PDF">pdf</a>, <a href="/format/2306.00965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BUOL: A Bottom-Up Framework with Occupancy-aware Lifting for Panoptic 3D  Scene Reconstruction From A Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chu%2C+T">Tao Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023, <a href="https://github.com/chtsy/buol">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01028" title="Abstract">arXiv:2306.01028</a> (replaced) [<a href="/pdf/2306.01028" title="Download PDF">pdf</a>, <a href="/format/2306.01028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ITR: Grammar-based graph compression supporting fast triple queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adler%2C+E">Enno Adler</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6ttcher%2C+S">Stefan B&#xf6;ttcher</a>, 
<a href="/search/cs?searchtype=author&query=Hartel%2C+R">Rita Hartel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01222" title="Abstract">arXiv:2306.01222</a> (replaced) [<a href="/pdf/2306.01222" title="Download PDF">pdf</a>, <a href="/format/2306.01222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Up Semi-supervised Learning with Unconstrained Unlabelled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Shuvendu Roy</a>, 
<a href="/search/cs?searchtype=author&query=Etemad%2C+A">Ali Etemad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03072" title="Abstract">arXiv:2306.03072</a> (replaced) [<a href="/pdf/2306.03072" title="Download PDF">pdf</a>, <a href="/format/2306.03072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore to Generalize in Zero-Shot RL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zisselman%2C+E">Ev Zisselman</a>, 
<a href="/search/cs?searchtype=author&query=Lavie%2C+I">Itai Lavie</a>, 
<a href="/search/cs?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>, 
<a href="/search/cs?searchtype=author&query=Tamar%2C+A">Aviv Tamar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03266" title="Abstract">arXiv:2306.03266</a> (replaced) [<a href="/pdf/2306.03266" title="Download PDF">pdf</a>, <a href="/format/2306.03266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending the Design Space of Graph Neural Networks by Rethinking  Folklore Weisfeiler-Lehman
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiarui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lecheng Kong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fuhai Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03988" title="Abstract">arXiv:2306.03988</a> (replaced) [<a href="/pdf/2306.03988" title="Download PDF">pdf</a>, <a href="/format/2306.03988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn the Force We Can: Enabling Sparse Motion Control in Multi-Object  Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davtyan%2C+A">Aram Davtyan</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+P">Paolo Favaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024. Project website: <a href="https://araachie.github.io/yoda">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04746" title="Abstract">arXiv:2306.04746</a> (replaced) [<a href="/pdf/2306.04746" title="Download PDF">pdf</a>, <a href="/format/2306.04746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Imperfect Surrogates for Downstream Inference: Design-based  Supervised Learning for Social Science Applications of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Egami%2C+N">Naoki Egami</a>, 
<a href="/search/stat?searchtype=author&query=Hinck%2C+M">Musashi Hinck</a>, 
<a href="/search/stat?searchtype=author&query=Stewart%2C+B+M">Brandon M. Stewart</a>, 
<a href="/search/stat?searchtype=author&query=Wei%2C+H">Hanying Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05009" title="Abstract">arXiv:2306.05009</a> (replaced) [<a href="/pdf/2306.05009" title="Download PDF">pdf</a>, <a href="/ps/2306.05009" title="Download PostScript">ps</a>, <a href="/format/2306.05009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical computation of the half Laplacian by means of a fast  convolution algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cuesta%2C+C+M">Carlota M. Cuesta</a>, 
<a href="/search/math?searchtype=author&query=de+la+Hoz%2C+F">Francisco de la Hoz</a>, 
<a href="/search/math?searchtype=author&query=Girona%2C+I">Ivan Girona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures, 3 Matlab listings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05323" title="Abstract">arXiv:2306.05323</a> (replaced) [<a href="/pdf/2306.05323" title="Download PDF">pdf</a>, <a href="/ps/2306.05323" title="Download PostScript">ps</a>, <a href="/format/2306.05323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Italian Biomedical Information Extraction with  Transformers-based Models: Methodological Insights and Multicenter Practical  Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crema%2C+C">Claudio Crema</a>, 
<a href="/search/cs?searchtype=author&query=Buonocore%2C+T+M">Tommaso Mario Buonocore</a>, 
<a href="/search/cs?searchtype=author&query=Fostinelli%2C+S">Silvia Fostinelli</a>, 
<a href="/search/cs?searchtype=author&query=Parimbelli%2C+E">Enea Parimbelli</a>, 
<a href="/search/cs?searchtype=author&query=Verde%2C+F">Federico Verde</a>, 
<a href="/search/cs?searchtype=author&query=Fundar%C3%B2%2C+C">Cira Fundar&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Manera%2C+M">Marina Manera</a>, 
<a href="/search/cs?searchtype=author&query=Ramusino%2C+M+C">Matteo Cotta Ramusino</a>, 
<a href="/search/cs?searchtype=author&query=Capelli%2C+M">Marco Capelli</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+A">Alfredo Costa</a>, 
<a href="/search/cs?searchtype=author&query=Binetti%2C+G">Giuliano Binetti</a>, 
<a href="/search/cs?searchtype=author&query=Bellazzi%2C+R">Riccardo Bellazzi</a>, 
<a href="/search/cs?searchtype=author&query=Redolfi%2C+A">Alberto Redolfi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures, 6 tables, Supplementary Notes included
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Biomedical Informatics, Volume 148, 2023, 104557, ISSN
  1532-0464
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06446" title="Abstract">arXiv:2306.06446</a> (replaced) [<a href="/pdf/2306.06446" title="Download PDF">pdf</a>, <a href="/format/2306.06446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient  Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+H">Haoran You</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+H">Huihong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yipin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yingyan Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1070">[1070]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08247" title="Abstract">arXiv:2306.08247</a> (replaced) [<a href="/pdf/2306.08247" title="Download PDF">pdf</a>, <a href="/format/2306.08247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion in Diffusion: Cyclic One-Way Diffusion for  Text-Vision-Conditioned Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Z">Zhihao Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Ye Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yu Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1071">[1071]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08411" title="Abstract">arXiv:2306.08411</a> (replaced) [<a href="/pdf/2306.08411" title="Download PDF">pdf</a>, <a href="/ps/2306.08411" title="Download PostScript">ps</a>, <a href="/format/2306.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The MacWilliams Identity for the Hermitian Rank Metric
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friedlander%2C+I">Izzy Friedlander</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages. arXiv admin note: substantial text overlap with <a href="/abs/2210.16153">arXiv:2210.16153</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1072">[1072]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09467" title="Abstract">arXiv:2306.09467</a> (replaced) [<a href="/pdf/2306.09467" title="Download PDF">pdf</a>, <a href="/format/2306.09467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AQuA: A Benchmarking Tool for Label Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+M">Mononito Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Sanil%2C+V">Vedant Sanil</a>, 
<a href="/search/cs?searchtype=author&query=Choudhry%2C+A">Arjun Choudhry</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+A">Arvind Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Udompanyawit%2C+C">Chalisa Udompanyawit</a>, 
<a href="/search/cs?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) Track on Datasets and Benchmarks. Source code can be found at www.github.com/autonlab/aqua/
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1073">[1073]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09526" title="Abstract">arXiv:2306.09526</a> (replaced) [<a href="/pdf/2306.09526" title="Download PDF">pdf</a>, <a href="/format/2306.09526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Residual Q-Learning: Offline and Online Policy Customization without  Value
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenran Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+H">Haruki Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Mercat%2C+J">Jean Mercat</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+W">Wei Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 37th Conference on Neural Information Processing Systems (NeurIPS 2023). The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1074">[1074]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09666" title="Abstract">arXiv:2306.09666</a> (replaced) [<a href="/pdf/2306.09666" title="Download PDF">pdf</a>, <a href="/format/2306.09666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Smooth Binary Mechanism for Efficient Private Continual Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Andersson%2C+J+D">Joel Daniel Andersson</a>, 
<a href="/search/cs?searchtype=author&query=Pagh%2C+R">Rasmus Pagh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1075">[1075]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10345" title="Abstract">arXiv:2306.10345</a> (replaced) [<a href="/pdf/2306.10345" title="Download PDF">pdf</a>, <a href="/format/2306.10345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do as I can, not as I get
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Shangfei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q+V+H">Quoc Viet Hung Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lei Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1076">[1076]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10506" title="Abstract">arXiv:2306.10506</a> (replaced) [<a href="/pdf/2306.10506" title="Download PDF">pdf</a>, <a href="/format/2306.10506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Conditional Mixing of MCMC Algorithms for Non-log-concave  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yusong Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1077">[1077]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10739" title="Abstract">arXiv:2306.10739</a> (replaced) [<a href="/pdf/2306.10739" title="Download PDF">pdf</a>, <a href="/format/2306.10739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COLE: A Column-based Learned Storage for Blockchain Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ce Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Cheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haibo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianliang Xu</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 22nd USENIX Conference on File and Storage Technologies (FAST'
  24), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1078">[1078]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10898" title="Abstract">arXiv:2306.10898</a> (replaced) [<a href="/pdf/2306.10898" title="Download PDF">pdf</a>, <a href="/format/2306.10898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> B-cos Alignment for Inherently Interpretable CNNs and Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%B6hle%2C+M">Moritz B&#xf6;hle</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Navdeeppal Singh</a>, 
<a href="/search/cs?searchtype=author&query=Fritz%2C+M">Mario Fritz</a>, 
<a href="/search/cs?searchtype=author&query=Schiele%2C+B">Bernt Schiele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of B-cos Networks: Alignment is All We Need for Interpretability (B\"ohle et al., CVPR 2022). Accepted for publication in IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: substantial text overlap with <a href="/abs/2205.10268">arXiv:2205.10268</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1079">[1079]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11238" title="Abstract">arXiv:2306.11238</a> (replaced) [<a href="/pdf/2306.11238" title="Download PDF">pdf</a>, <a href="/format/2306.11238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAMP-Net: Consistency-Aware Multi-Prior Network for Accelerated MRI  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Liping Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaobo Li</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Weitian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1080">[1080]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11589" title="Abstract">arXiv:2306.11589</a> (replaced) [<a href="/pdf/2306.11589" title="Download PDF">pdf</a>, <a href="/format/2306.11589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling from Gaussian Process Posteriors using Stochastic Gradient  Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+J+A">Jihao Andreas Lin</a>, 
<a href="/search/cs?searchtype=author&query=Antor%C3%A1n%2C+J">Javier Antor&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Padhy%2C+S">Shreyas Padhy</a>, 
<a href="/search/cs?searchtype=author&query=Janz%2C+D">David Janz</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Lobato%2C+J+M">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>, 
<a href="/search/cs?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1081">[1081]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11990" title="Abstract">arXiv:2306.11990</a> (replaced) [<a href="/pdf/2306.11990" title="Download PDF">pdf</a>, <a href="/ps/2306.11990" title="Download PostScript">ps</a>, <a href="/format/2306.11990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-constrained Attack against Convolution-based Human Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+C">Chengxu Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yonghao Dang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jianqin Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1082">[1082]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12048" title="Abstract">arXiv:2306.12048</a> (replaced) [<a href="/pdf/2306.12048" title="Download PDF">pdf</a>, <a href="/format/2306.12048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Unsupervised Video Object Segmentation via Contrastive Motion  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+L">Lin Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1083">[1083]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12974" title="Abstract">arXiv:2306.12974</a> (replaced) [<a href="/pdf/2306.12974" title="Download PDF">pdf</a>, <a href="/format/2306.12974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Bernstein Change Detector for High-Dimensional Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heyden%2C+M">Marco Heyden</a>, 
<a href="/search/cs?searchtype=author&query=Fouch%C3%A9%2C+E">Edouard Fouch&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Arzamasov%2C+V">Vadim Arzamasov</a>, 
<a href="/search/cs?searchtype=author&query=Fenn%2C+T">Tanja Fenn</a>, 
<a href="/search/cs?searchtype=author&query=Kalinke%2C+F">Florian Kalinke</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%B6hm%2C+K">Klemens B&#xf6;hm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1084">[1084]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13677" title="Abstract">arXiv:2306.13677</a> (replaced) [<a href="/pdf/2306.13677" title="Download PDF">pdf</a>, <a href="/ps/2306.13677" title="Download PostScript">ps</a>, <a href="/format/2306.13677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Net Metering for Energy Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alahmed%2C+A+S">Ahmed S. Alahmed</a>, 
<a href="/search/eess?searchtype=author&query=Tong%2C+L">Lang Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures, 2 tables. arXiv admin note: text overlap with <a href="/abs/2211.09360">arXiv:2211.09360</a>. Accepted for publication at the IEEE Transactions on Energy Markets, Policy and Regulation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computer Science and Game Theory (cs.GT); Theoretical Economics (econ.TH); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1085">[1085]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14153" title="Abstract">arXiv:2306.14153</a> (replaced) [<a href="/pdf/2306.14153" title="Download PDF">pdf</a>, <a href="/format/2306.14153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image  Generation using Limited Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingyuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Huimin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiansheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jian Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> extended from DDPM-PA (<a href="/abs/2211.03264">arXiv:2211.03264</a>), 33 pages, 34 figures. arXiv admin note: substantial text overlap with <a href="/abs/2211.03264">arXiv:2211.03264</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1086">[1086]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14448" title="Abstract">arXiv:2306.14448</a> (replaced) [<a href="/pdf/2306.14448" title="Download PDF">pdf</a>, <a href="/format/2306.14448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Progressive Energy-Based Cooperative Learning for Multi-Domain  Image-to-Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Weinan Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yaxuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lei He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingnian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jianwen Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1087">[1087]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14525" title="Abstract">arXiv:2306.14525</a> (replaced) [<a href="/pdf/2306.14525" title="Download PDF">pdf</a>, <a href="/format/2306.14525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ParameterNet: Parameters Are All You Need
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+E">Enhua Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://parameternet.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1088">[1088]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14685" title="Abstract">arXiv:2306.14685</a> (replaced) [<a href="/pdf/2306.14685" title="Download PDF">pdf</a>, <a href="/format/2306.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffSketcher: Text Guided Vector Sketch Synthesis through Latent  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Ximing Xing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Haitao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NIPS 2023. Project page: <a href="https://ximinng.github.io/DiffSketcher-project/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1089">[1089]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16834" title="Abstract">arXiv:2306.16834</a> (replaced) [<a href="/pdf/2306.16834" title="Download PDF">pdf</a>, <a href="/ps/2306.16834" title="Download PostScript">ps</a>, <a href="/format/2306.16834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligence of Astronomical Optical Telescope: Present Status and  Future Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Huang%2C+K">Kang Huang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hu%2C+T">Tianzhu Hu</a>, 
<a href="/search/astro-ph?searchtype=author&query=Cai%2C+J">Jingyi Cai</a>, 
<a href="/search/astro-ph?searchtype=author&query=Pang%2C+X">Xiushan Pang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hou%2C+Y">Yonghui Hou</a>, 
<a href="/search/astro-ph?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wang%2C+H">Huaiqing Wang</a>, 
<a href="/search/astro-ph?searchtype=author&query=Cui%2C+X">Xiangqun Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 10 figure, for questions or comments, please email tzhu@niaot.ac.cn
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Methods for Astrophysics (astro-ph.IM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1090">[1090]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16992" title="Abstract">arXiv:2306.16992</a> (replaced) [<a href="/pdf/2306.16992" title="Download PDF">pdf</a>, <a href="/format/2306.16992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Noise in Quantum Software Testing Using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muqeet%2C+A">Asmar Muqeet</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Arcaini%2C+P">Paolo Arcaini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1091">[1091]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17361" title="Abstract">arXiv:2306.17361</a> (replaced) [<a href="/pdf/2306.17361" title="Download PDF">pdf</a>, <a href="/format/2306.17361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive  Noise Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+K">Kevin Bello</a>, 
<a href="/search/cs?searchtype=author&query=Aragam%2C+B">Bryon Aragam</a>, 
<a href="/search/cs?searchtype=author&query=Ravikumar%2C+P">Pradeep Ravikumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 18 figures. Published at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP); Methodology (stat.ME); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1092">[1092]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00097" title="Abstract">arXiv:2307.00097</a> (replaced) [<a href="/pdf/2307.00097" title="Download PDF">pdf</a>, <a href="/format/2307.00097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting classes: Exploring the Power of Prompt Class Learning in  Weakly Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Murugesan%2C+B">Balamurali Murugesan</a>, 
<a href="/search/cs?searchtype=author&query=Hussain%2C+R">Rukhshanda Hussain</a>, 
<a href="/search/cs?searchtype=author&query=Bhattacharya%2C+R">Rajarshi Bhattacharya</a>, 
<a href="/search/cs?searchtype=author&query=Ayed%2C+I+B">Ismail Ben Ayed</a>, 
<a href="/search/cs?searchtype=author&query=Dolz%2C+J">Jose Dolz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1093">[1093]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00673" title="Abstract">arXiv:2307.00673</a> (replaced) [<a href="/pdf/2307.00673" title="Download PDF">pdf</a>, <a href="/format/2307.00673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ENN: A Neural Network with DCT Adaptive Activation Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinez-Gost%2C+M">Marc Martinez-Gost</a>, 
<a href="/search/eess?searchtype=author&query=P%C3%A9rez-Neira%2C+A">Ana P&#xe9;rez-Neira</a>, 
<a href="/search/eess?searchtype=author&query=Lagunas%2C+M+%C3%81">Miguel &#xc1;ngel Lagunas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in IEEE Journal of Selected Topics in Signal Processing (JSTSP) Special Series on AI in Signal &amp; Data Science - Toward Explainable, Reliable, and Sustainable Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item1094">[1094]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00859" title="Abstract">arXiv:2307.00859</a> (replaced) [<a href="/e-print/2307.00859" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CardiGraphormer: Unveiling the Power of Self-Supervised Learning in  Revolutionizing Drug Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhijit Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Disagreement with my PhD supervisor about open sourcing the publication and affiliation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM); Applications (stat.AP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1095">[1095]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02251" title="Abstract">arXiv:2307.02251</a> (replaced) [<a href="/pdf/2307.02251" title="Download PDF">pdf</a>, <a href="/format/2307.02251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RanPAC: Random Projections and Pre-trained Models for Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDonnell%2C+M+D">Mark D. McDonnell</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+D">Dong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Parveneh%2C+A">Amin Parveneh</a>, 
<a href="/search/cs?searchtype=author&query=Abbasnejad%2C+E">Ehsan Abbasnejad</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Hengel%2C+A">Anton van den Hengel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Annual Conference on Neural Information Processing Systems
  (NeurIPS 2023), Dec 2023, New Orleans, United States
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1096">[1096]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03393" title="Abstract">arXiv:2307.03393</a> (replaced) [<a href="/pdf/2307.03393" title="Download PDF">pdf</a>, <a href="/format/2307.03393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Potential of Large Language Models (LLMs) in Learning on  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhikai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Haitao Mao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wei Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hongzhi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaochi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenqi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be appear on SIGKDD Explorations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1097">[1097]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03394" title="Abstract">arXiv:2307.03394</a> (replaced) [<a href="/pdf/2307.03394" title="Download PDF">pdf</a>, <a href="/format/2307.03394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust SDRTV-to-HDRTV via Dual Inverse Degradation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+K">Kepeng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+L">Li Xu</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+G">Gang He</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wenxin Yu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yunsong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1098">[1098]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03590" title="Abstract">arXiv:2307.03590</a> (replaced) [<a href="/pdf/2307.03590" title="Download PDF">pdf</a>, <a href="/format/2307.03590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Optimization Landscape of Linear-Quadratic Regulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feng%2C+L">Lechen Feng</a>, 
<a href="/search/math?searchtype=author&query=Ni%2C+Y">Yuan-Hua Ni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1099">[1099]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04108" title="Abstract">arXiv:2307.04108</a> (replaced) [<a href="/pdf/2307.04108" title="Download PDF">pdf</a>, <a href="/format/2307.04108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Proportional Response Dynamics in Markets with Adversarial  Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolumbus%2C+Y">Yoav Kolumbus</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+M">Menahem Levy</a>, 
<a href="/search/cs?searchtype=author&query=Nisan%2C+N">Noam Nisan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Theoretical Economics (econ.TH); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item1100">[1100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04596" title="Abstract">arXiv:2307.04596</a> (replaced) [<a href="/pdf/2307.04596" title="Download PDF">pdf</a>, <a href="/format/2307.04596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distill-SODA: Distilling Self-Supervised Vision Transformer for  Source-Free Open-Set Domain Adaptation in Computational Pathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vray%2C+G">Guillaume Vray</a>, 
<a href="/search/cs?searchtype=author&query=Tomar%2C+D">Devavrat Tomar</a>, 
<a href="/search/cs?searchtype=author&query=Thiran%2C+J">Jean-Philippe Thiran</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgtabar%2C+B">Behzad Bozorgtabar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1101">[1101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05900" title="Abstract">arXiv:2307.05900</a> (replaced) [<a href="/pdf/2307.05900" title="Download PDF">pdf</a>, <a href="/ps/2307.05900" title="Download PostScript">ps</a>, <a href="/format/2307.05900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Compatible Transfer Operators in Nonsymmetric Algebraic Multigrid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Southworth%2C+B+S">Ben S. Southworth</a>, 
<a href="/search/math?searchtype=author&query=Manteuffel%2C+T+A">Thomas A. Manteuffel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1102">[1102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08927" title="Abstract">arXiv:2307.08927</a> (replaced) [<a href="/pdf/2307.08927" title="Download PDF">pdf</a>, <a href="/format/2307.08927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Stage Cable Routing through Hierarchical Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianlan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Charles Xu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xinyang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+G">Gilbert Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+K">Kuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+L">Liam Tan</a>, 
<a href="/search/cs?searchtype=author&query=Schaal%2C+S">Stefan Schaal</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> T-RO 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1103">[1103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10443" title="Abstract">arXiv:2307.10443</a> (replaced) [<a href="/pdf/2307.10443" title="Download PDF">pdf</a>, <a href="/ps/2307.10443" title="Download PostScript">ps</a>, <a href="/format/2307.10443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating a Heterogeneous Graph with Entity-aware Self-attention using  Relative Position Labels for Reading Comprehension Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foolad%2C+S">Shima Foolad</a>, 
<a href="/search/cs?searchtype=author&query=Kiani%2C+K">Kourosh Kiani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted for Multimedia Tools and Applications Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1104">[1104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11448" title="Abstract">arXiv:2307.11448</a> (replaced) [<a href="/pdf/2307.11448" title="Download PDF">pdf</a>, <a href="/ps/2307.11448" title="Download PostScript">ps</a>, <a href="/format/2307.11448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the convergence order of the Euler scheme for scalar SDEs with  H&#xf6;lder-type diffusion coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mickel%2C+A">Annalena Mickel</a>, 
<a href="/search/math?searchtype=author&query=Neuenkirch%2C+A">Andreas Neuenkirch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages; minor corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1105">[1105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12082" title="Abstract">arXiv:2307.12082</a> (replaced) [<a href="/pdf/2307.12082" title="Download PDF">pdf</a>, <a href="/format/2307.12082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Code Quality Measurement: Implications from Metric  Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Siyuan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mianmian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yekai Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuejiang He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bichao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted for presentation at IEEE QRS 2023. Unfortunately, due to authorship limits, Mianmian Zhang, Yekai Guo, and Yuejiang He could not be included as co-authors. However, we gratefully acknowledge their valuable contributions to this work and use this arXiv version to prove their contributions
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE 23rd International Conference on Software Quality,
  Reliability, and Security (QRS), Chiang Mai, Thailand, 2023, pp. 488-496
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1106">[1106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12130" title="Abstract">arXiv:2307.12130</a> (replaced) [<a href="/pdf/2307.12130" title="Download PDF">pdf</a>, <a href="/format/2307.12130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating temperatures with low-cost infrared cameras using deep neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oz%2C+N">Navot Oz</a>, 
<a href="/search/cs?searchtype=author&query=Sochen%2C+N">Nir Sochen</a>, 
<a href="/search/cs?searchtype=author&query=Mendelovich%2C+D">David Mendelovich</a>, 
<a href="/search/cs?searchtype=author&query=Klapp%2C+I">Iftach Klapp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1107">[1107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12542" title="Abstract">arXiv:2307.12542</a> (replaced) [<a href="/pdf/2307.12542" title="Download PDF">pdf</a>, <a href="/format/2307.12542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Client-Level Differential Privacy via Adaptive Intermediary in Federated  Medical Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meirui Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+A">Anjie Le</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Q">Qi Dou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1108">[1108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12712" title="Abstract">arXiv:2307.12712</a> (replaced) [<a href="/pdf/2307.12712" title="Download PDF">pdf</a>, <a href="/ps/2307.12712" title="Download PostScript">ps</a>, <a href="/format/2307.12712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-place accumulation of fast multiplication formulae
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumas%2C+J">Jean-Guillaume Dumas</a> (CASC), 
<a href="/search/cs?searchtype=author&query=Grenet%2C+B">Bruno Grenet</a> (CASC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>

</div>
</div>
</dd>
<dt><a name="item1109">[1109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13304" title="Abstract">arXiv:2307.13304</a> (replaced) [<a href="/pdf/2307.13304" title="Download PDF">pdf</a>, <a href="/format/2307.13304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuIP: 2-Bit Quantization of Large Language Models With Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chee%2C+J">Jerry Chee</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yaohui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Kuleshov%2C+V">Volodymyr Kuleshov</a>, 
<a href="/search/cs?searchtype=author&query=De+Sa%2C+C">Christopher De Sa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1110">[1110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13716" title="Abstract">arXiv:2307.13716</a> (replaced) [<a href="/pdf/2307.13716" title="Download PDF">pdf</a>, <a href="/format/2307.13716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on  Staged Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Leiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Cihao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+S">Sibo Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ziling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yuming Nie</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Z">Zhaoxiang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheewei Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1111">[1111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14288" title="Abstract">arXiv:2307.14288</a> (replaced) [<a href="/pdf/2307.14288" title="Download PDF">pdf</a>, <a href="/format/2307.14288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> US \&amp; MRI Image Fusion Based on Markerless Skin Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paccini%2C+M">Martina Paccini</a>, 
<a href="/search/cs?searchtype=author&query=Paschina%2C+G">Giacomo Paschina</a>, 
<a href="/search/cs?searchtype=author&query=De+Beni%2C+S">Stefano De Beni</a>, 
<a href="/search/cs?searchtype=author&query=Patan%C3%A8%2C+G">Giuseppe Patan&#xe8;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1112">[1112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15220" title="Abstract">arXiv:2307.15220</a> (replaced) [<a href="/pdf/2307.15220" title="Download PDF">pdf</a>, <a href="/format/2307.15220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Multi-modal Representations by Watching Hundreds of Surgical  Video Lectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+V">Vinkle Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lavanchy%2C+J+L">Joel L. Lavanchy</a>, 
<a href="/search/cs?searchtype=author&query=Mascagni%2C+P">Pietro Mascagni</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1113">[1113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15404" title="Abstract">arXiv:2307.15404</a> (replaced) [<a href="/pdf/2307.15404" title="Download PDF">pdf</a>, <a href="/ps/2307.15404" title="Download PostScript">ps</a>, <a href="/format/2307.15404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Information-based Preprocessing of PLC Data for Automatic Behavior  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sai%2C+B+K">Brandon K. Sai</a>, 
<a href="/search/eess?searchtype=author&query=Gram%2C+J">Jonas Gram</a>, 
<a href="/search/eess?searchtype=author&query=Bauernhansl%2C+T">Thomas Bauernhansl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information-based Preprocessing of PLC Data for Automatic Behavior
  Modeling, Procedia CIRP, Volume 120, 2023, Pages 565-571, ISSN 2212-8271
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Computational Engineering, Finance, and Science (cs.CE); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1114">[1114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.15483" title="Abstract">arXiv:2307.15483</a> (replaced) [<a href="/pdf/2307.15483" title="Download PDF">pdf</a>, <a href="/ps/2307.15483" title="Download PostScript">ps</a>, <a href="/format/2307.15483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact Phase Histograms for Guided Exploration of Periodicity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franke%2C+M">Max Franke</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+S">Steffen Koch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE VIS 2023 Short Paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of 2023 IEEE Visualization and Visual Analytics
  (VIS), pp. 191-195
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item1115">[1115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16075" title="Abstract">arXiv:2307.16075</a> (replaced) [<a href="/pdf/2307.16075" title="Download PDF">pdf</a>, <a href="/ps/2307.16075" title="Download PostScript">ps</a>, <a href="/format/2307.16075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Redesigning Large-Scale Multimodal Transit Networks with Shared  Autonomous Mobility Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ng%2C+M+T+M">Max T.M. Ng</a>, 
<a href="/search/eess?searchtype=author&query=Mahmassani%2C+H+S">Hani S. Mahmassani</a>, 
<a href="/search/eess?searchtype=author&query=Verbas%2C+%C3%96">&#xd6;mer Verbas</a>, 
<a href="/search/eess?searchtype=author&query=Cokyasar%2C+T">Taner Cokyasar</a>, 
<a href="/search/eess?searchtype=author&query=Engelhardt%2C+R">Roman Engelhardt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 18 figures, revision under review for the 25th International Symposium on Transportation and Traffic Theory (ISTTT25)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1116">[1116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16149" title="Abstract">arXiv:2307.16149</a> (replaced) [<a href="/pdf/2307.16149" title="Download PDF">pdf</a>, <a href="/format/2307.16149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel DDPM-based Ensemble Approach for Energy Theft Detection in Smart  Grids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+A">Asif Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Gope%2C+P">Prosanta Gope</a>, 
<a href="/search/cs?searchtype=author&query=Sikdar%2C+B">Biplab Sikdar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1117">[1117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16356" title="Abstract">arXiv:2307.16356</a> (replaced) [<a href="/pdf/2307.16356" title="Download PDF">pdf</a>, <a href="/format/2307.16356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interleaved Training for Massive MIMO Downlink via Exploring Spatial  Correlation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yindi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Minjie Ding</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages (double column), 8 figures. The paper has been accepted by IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1118">[1118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00334" title="Abstract">arXiv:2308.00334</a> (replaced) [<a href="/pdf/2308.00334" title="Download PDF">pdf</a>, <a href="/format/2308.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guarding Polyominoes under $k$-Hop Visibility
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Filtser%2C+O">Omrit Filtser</a>, 
<a href="/search/cs?searchtype=author&query=Krohn%2C+E">Erik Krohn</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+B+J">Bengt J. Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+C">Christian Rieck</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+C">Christiane Schmidt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures. Full version of an extended abstract that has been accepted to LATIN 2024. Some parts have been improved based on reviewer comments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1119">[1119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00695" title="Abstract">arXiv:2308.00695</a> (replaced) [<a href="/pdf/2308.00695" title="Download PDF">pdf</a>, <a href="/ps/2308.00695" title="Download PostScript">ps</a>, <a href="/format/2308.00695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing the Power of Sample Abundance: Theoretical Guarantees and  Algorithms for Accelerated One-Bit Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eamaz%2C+A">Arian Eamaz</a>, 
<a href="/search/cs?searchtype=author&query=Yeganegi%2C+F">Farhang Yeganegi</a>, 
<a href="/search/cs?searchtype=author&query=Needell%2C+D">Deanna Needell</a>, 
<a href="/search/cs?searchtype=author&query=Soltanalian%2C+M">Mojtaba Soltanalian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2301.03467">arXiv:2301.03467</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1120">[1120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03109" title="Abstract">arXiv:2308.03109</a> (replaced) [<a href="/pdf/2308.03109" title="Download PDF">pdf</a>, <a href="/format/2308.03109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lost in Translation: A Study of Bugs Introduced by Large Language Models  while Translating Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+R">Rangeet Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahimzada%2C+A+R">Ali Reza Ibrahimzada</a>, 
<a href="/search/cs?searchtype=author&query=Krishna%2C+R">Rahul Krishna</a>, 
<a href="/search/cs?searchtype=author&query=Sankar%2C+D">Divya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Wassi%2C+L+P">Lambert Pouguem Wassi</a>, 
<a href="/search/cs?searchtype=author&query=Merler%2C+M">Michele Merler</a>, 
<a href="/search/cs?searchtype=author&query=Sobolev%2C+B">Boris Sobolev</a>, 
<a href="/search/cs?searchtype=author&query=Pavuluri%2C+R">Raju Pavuluri</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Saurabh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Jabbarvand%2C+R">Reyhaneh Jabbarvand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1121">[1121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04748" title="Abstract">arXiv:2308.04748</a> (replaced) [<a href="/pdf/2308.04748" title="Download PDF">pdf</a>, <a href="/format/2308.04748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzz4All: Universal Fuzzing with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+C+S">Chunqiu Steven Xia</a>, 
<a href="/search/cs?searchtype=author&query=Paltenghi%2C+M">Matteo Paltenghi</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J+L">Jia Le Tian</a>, 
<a href="/search/cs?searchtype=author&query=Pradel%2C+M">Michael Pradel</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lingming Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1122">[1122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05141" title="Abstract">arXiv:2308.05141</a> (replaced) [<a href="/pdf/2308.05141" title="Download PDF">pdf</a>, <a href="/format/2308.05141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound propagation in realistic interactive 3D scenes with parameterized  sources using deep neural operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borrel-Jensen%2C+N">Nikolas Borrel-Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Goswami%2C+S">Somdatta Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Engsig-Karup%2C+A+P">Allan P. Engsig-Karup</a>, 
<a href="/search/cs?searchtype=author&query=Karniadakis%2C+G+E">George Em Karniadakis</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Cheol-Ho Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 10 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1123">[1123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05404" title="Abstract">arXiv:2308.05404</a> (replaced) [<a href="/pdf/2308.05404" title="Download PDF">pdf</a>, <a href="/format/2308.05404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Low-light Light Field Images with A Deep Compensation  Unfolding Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xianqiang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1124">[1124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05929" title="Abstract">arXiv:2308.05929</a> (replaced) [<a href="/pdf/2308.05929" title="Download PDF">pdf</a>, <a href="/format/2308.05929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatiotemporal Receding Horizon Control with Proactive Interaction  Towards Autonomous Driving in Dense Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zengqi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M+Y">Michael Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jun Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1125">[1125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06399" title="Abstract">arXiv:2308.06399</a> (replaced) [<a href="/pdf/2308.06399" title="Download PDF">pdf</a>, <a href="/format/2308.06399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via  Mixed-Effect Models and Hierarchical Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Valleggi%2C+L">Lorenzo Valleggi</a>, 
<a href="/search/stat?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>, 
<a href="/search/stat?searchtype=author&query=Stefanini%2C+F+M">Federico Mattia Stefanini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1126">[1126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06513" title="Abstract">arXiv:2308.06513</a> (replaced) [<a href="/pdf/2308.06513" title="Download PDF">pdf</a>, <a href="/format/2308.06513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Study of MEV Extraction Techniques on a First-Come-First-Served  Blockchain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96z%2C+B">Burak &#xd6;z</a>, 
<a href="/search/cs?searchtype=author&query=Rezabek%2C+F">Filip Rezabek</a>, 
<a href="/search/cs?searchtype=author&query=Gebele%2C+J">Jonas Gebele</a>, 
<a href="/search/cs?searchtype=author&query=Hoops%2C+F">Felix Hoops</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1127">[1127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06581" title="Abstract">arXiv:2308.06581</a> (replaced) [<a href="/pdf/2308.06581" title="Download PDF">pdf</a>, <a href="/ps/2308.06581" title="Download PostScript">ps</a>, <a href="/format/2308.06581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Cooperative Coevolution and Global Crossover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bull%2C+L">Larry Bull</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haixia Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item1128">[1128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07272" title="Abstract">arXiv:2308.07272</a> (replaced) [<a href="/pdf/2308.07272" title="Download PDF">pdf</a>, <a href="/format/2308.07272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt  Generation for Few-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengzhengxu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yichen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Duyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yu Lan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 Main Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1129">[1129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07281" title="Abstract">arXiv:2308.07281</a> (replaced) [<a href="/pdf/2308.07281" title="Download PDF">pdf</a>, <a href="/ps/2308.07281" title="Download PostScript">ps</a>, <a href="/format/2308.07281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ergodic Estimations for Toeplitz Sequences Generated by a Symbol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Barbarino%2C+G">Giovanni Barbarino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1130">[1130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07438" title="Abstract">arXiv:2308.07438</a> (replaced) [<a href="/pdf/2308.07438" title="Download PDF">pdf</a>, <a href="/ps/2308.07438" title="Download PostScript">ps</a>, <a href="/format/2308.07438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the abyss in Kleene&#x27;s computability theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Sanders%2C+S">Sam Sanders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages; to appear in 'Computability'; this paper is a significant extension ('journal version') of my CiE2023 proceedings paper <a href="/abs/2302.07066">arXiv:2302.07066</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1131">[1131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07476" title="Abstract">arXiv:2308.07476</a> (replaced) [<a href="/pdf/2308.07476" title="Download PDF">pdf</a>, <a href="/ps/2308.07476" title="Download PostScript">ps</a>, <a href="/format/2308.07476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dependent rounding with strong negative-correlation, and scheduling on  unrelated machines to minimize completion time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harris%2C+D+G">David G. Harris</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SODA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item1132">[1132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08821" title="Abstract">arXiv:2308.08821</a> (replaced) [<a href="/pdf/2308.08821" title="Download PDF">pdf</a>, <a href="/format/2308.08821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experimental quantum e-commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cao%2C+X">Xiao-Yu Cao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+B">Bing-Hong Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Y">Yang Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fu%2C+Y">Yao Fu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yin%2C+H">Hua-Lei Yin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+Z">Zeng-Bing Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Science Advances 10, eadk3258 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item1133">[1133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09460" title="Abstract">arXiv:2308.09460</a> (replaced) [<a href="/pdf/2308.09460" title="Download PDF">pdf</a>, <a href="/format/2308.09460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Klatzer%2C+T">Teresa Klatzer</a>, 
<a href="/search/stat?searchtype=author&query=Dobson%2C+P">Paul Dobson</a>, 
<a href="/search/stat?searchtype=author&query=Altmann%2C+Y">Yoann Altmann</a>, 
<a href="/search/stat?searchtype=author&query=Pereyra%2C+M">Marcelo Pereyra</a>, 
<a href="/search/stat?searchtype=author&query=Sanz-Serna%2C+J+M">Jes&#xfa;s Mar&#xed;a Sanz-Serna</a>, 
<a href="/search/stat?searchtype=author&query=Zygalakis%2C+K+C">Konstantinos C. Zygalakis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Computer Vision and Pattern Recognition (cs.CV); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1134">[1134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10526" title="Abstract">arXiv:2308.10526</a> (replaced) [<a href="/pdf/2308.10526" title="Download PDF">pdf</a>, <a href="/format/2308.10526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with  Action Understanding and Feedback in Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chongyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+L">Lingxiao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Siyi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuntao Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chengqi He</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuanchun Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IMWUT/Ubicomp'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1135">[1135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11272" title="Abstract">arXiv:2308.11272</a> (replaced) [<a href="/pdf/2308.11272" title="Download PDF">pdf</a>, <a href="/format/2308.11272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FoX: Formation-aware exploration in multi-agent reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yonghyeon Jo</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sunwoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J">Junghyuk Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seungyul Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages main, 5 pages appendix with reference. 10 figures, accepeted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1136">[1136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13205" title="Abstract">arXiv:2308.13205</a> (replaced) [<a href="/pdf/2308.13205" title="Download PDF">pdf</a>, <a href="/format/2308.13205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Control of a Bio-inspired Wheeled Bipedal Robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haizhou Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S">Siying Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuqing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1137">[1137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13363" title="Abstract">arXiv:2308.13363</a> (replaced) [<a href="/pdf/2308.13363" title="Download PDF">pdf</a>, <a href="/format/2308.13363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CS-Mixer: A Cross-Scale Vision MLP Model with Spatial-Channel Mixing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jonathan Cui</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+D+A">David A. Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Suman Saha</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+M+F">Md. Faisal Kabir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, developed under Penn State University's Multi-Campus Research Experience for Undergraduates Symposium, 2023. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1138">[1138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13758" title="Abstract">arXiv:2308.13758</a> (replaced) [<a href="/pdf/2308.13758" title="Download PDF">pdf</a>, <a href="/format/2308.13758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new unified arc-length method for damage mechanics problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saji%2C+R+P">Roshan Philip Saji</a>, 
<a href="/search/cs?searchtype=author&query=Pantidis%2C+P">Panos Pantidis</a>, 
<a href="/search/cs?searchtype=author&query=Mobasher%2C+M+E">Mostafa E. Mobasher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1139">[1139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13937" title="Abstract">arXiv:2308.13937</a> (replaced) [<a href="/pdf/2308.13937" title="Download PDF">pdf</a>, <a href="/format/2308.13937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparative Study on Reward Models for UI Adaptation with  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gaspar-Figueiredo%2C+D">Daniel Gaspar-Figueiredo</a>, 
<a href="/search/cs?searchtype=author&query=Abrah%C3%A3o%2C+S">Silvia Abrah&#xe3;o</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez-Diego%2C+M">Marta Fern&#xe1;ndez-Diego</a>, 
<a href="/search/cs?searchtype=author&query=Insfran%2C+E">Emilio Insfran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + 1 refs. 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1140">[1140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13983" title="Abstract">arXiv:2308.13983</a> (replaced) [<a href="/pdf/2308.13983" title="Download PDF">pdf</a>, <a href="/format/2308.13983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpolation of mountain weather forecasts by machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Iwase%2C+K">Kazuma Iwase</a>, 
<a href="/search/physics?searchtype=author&query=Takenawa%2C+T">Tomoyuki Takenawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1141">[1141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14002" title="Abstract">arXiv:2308.14002</a> (replaced) [<a href="/pdf/2308.14002" title="Download PDF">pdf</a>, <a href="/format/2308.14002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hands-on Quantum Programming Labs for EECS Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Sang%2C+J">Janche Sang</a>, 
<a href="/search/physics?searchtype=author&query=Yu%2C+C">Chansu Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 70 pages, 33 figures; program templates updated; typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics Education (physics.ed-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1142">[1142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14663" title="Abstract">arXiv:2308.14663</a> (replaced) [<a href="/pdf/2308.14663" title="Download PDF">pdf</a>, <a href="/format/2308.14663" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formal Modelling and Analysis of a Self-Adaptive Robotic System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A4%C3%9Fler%2C+J">Juliane P&#xe4;&#xdf;ler</a>, 
<a href="/search/cs?searchtype=author&query=ter+Beek%2C+M+H">Maurice H. ter Beek</a>, 
<a href="/search/cs?searchtype=author&query=Damiani%2C+F">Ferruccio Damiani</a>, 
<a href="/search/cs?searchtype=author&query=Tarifa%2C+S+L+T">S. Lizeth Tapia Tarifa</a>, 
<a href="/search/cs?searchtype=author&query=Johnsen%2C+E+B">Einar Broch Johnsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version includes an acknowledgement to the published version of the paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> iFM 2023, Lecture Notes in Computer Science, vol 14300, pp.
  343-363
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Robotics (cs.RO); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1143">[1143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16151" title="Abstract">arXiv:2308.16151</a> (replaced) [<a href="/pdf/2308.16151" title="Download PDF">pdf</a>, <a href="/ps/2308.16151" title="Download PostScript">ps</a>, <a href="/format/2308.16151" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic assessment of text-based responses in post-secondary  education: A systematic review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Rujun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Merzdorf%2C+H+E">Hillary E. Merzdorf</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+S">Saira Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Hipwell%2C+M+C">M. Cynthia Hipwell</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasa%2C+A">Arun Srinivasa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 4 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1144">[1144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16862" title="Abstract">arXiv:2308.16862</a> (replaced) [<a href="/pdf/2308.16862" title="Download PDF">pdf</a>, <a href="/format/2308.16862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraLogLog: A Practical and More Space-Efficient Alternative to  HyperLogLog for Approximate Distinct Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ertl%2C+O">Otmar Ertl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item1145">[1145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16900" title="Abstract">arXiv:2308.16900</a> (replaced) [<a href="/pdf/2308.16900" title="Download PDF">pdf</a>, <a href="/format/2308.16900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Taste: A Multimodal Wine Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bender%2C+T">Thoranna Bender</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%B8rensen%2C+S+M">Simon Moe S&#xf8;rensen</a>, 
<a href="/search/cs?searchtype=author&query=Kashani%2C+A">Alireza Kashani</a>, 
<a href="/search/cs?searchtype=author&query=Hjorleifsson%2C+K+E">K. Eldjarn Hjorleifsson</a>, 
<a href="/search/cs?searchtype=author&query=Hyldig%2C+G">Grethe Hyldig</a>, 
<a href="/search/cs?searchtype=author&query=Hauberg%2C+S">S&#xf8;ren Hauberg</a>, 
<a href="/search/cs?searchtype=author&query=Belongie%2C+S">Serge Belongie</a>, 
<a href="/search/cs?searchtype=author&query=Warburg%2C+F">Frederik Warburg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023. See project page: <a href="https://thoranna.github.io/learning_to_taste/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1146">[1146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01816" title="Abstract">arXiv:2309.01816</a> (replaced) [<a href="/pdf/2309.01816" title="Download PDF">pdf</a>, <a href="/format/2309.01816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Model Pruning and Personalization for Federated Learning over  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaonan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ratnarajah%2C+T">Tharmalingam Ratnarajah</a>, 
<a href="/search/cs?searchtype=author&query=Sellathurai%2C+M">Mathini Sellathurai</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.09042">arXiv:2305.09042</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1147">[1147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03744" title="Abstract">arXiv:2309.03744</a> (replaced) [<a href="/pdf/2309.03744" title="Download PDF">pdf</a>, <a href="/format/2309.03744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Label-efficient Contrastive Learning-based model for nuclei detection  and classification in 3D Cardiovascular Immunofluorescent Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moradinasab%2C+N">Nazanin Moradinasab</a>, 
<a href="/search/eess?searchtype=author&query=Deaton%2C+R+A">Rebecca A. Deaton</a>, 
<a href="/search/eess?searchtype=author&query=Shankman%2C+L+S">Laura S. Shankman</a>, 
<a href="/search/eess?searchtype=author&query=Owens%2C+G+K">Gary K. Owens</a>, 
<a href="/search/eess?searchtype=author&query=Brown%2C+D+E">Donald E. Brown</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, MICCAI Workshop Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1148">[1148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04041" title="Abstract">arXiv:2309.04041</a> (replaced) [<a href="/pdf/2309.04041" title="Download PDF">pdf</a>, <a href="/format/2309.04041" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation and Enhancement of Semantic Grounding in Large  Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiaying Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+J">Jinmeng Rao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kezhen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xiaoyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Baochen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Carl Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jie Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted to the AAAI'24 Workshop on Responsible Language Models (ReLM 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1149">[1149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04266" title="Abstract">arXiv:2309.04266</a> (replaced) [<a href="/pdf/2309.04266" title="Download PDF">pdf</a>, <a href="/format/2309.04266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locating Buggy Segments in Quantum Program Debugging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sato%2C+N">Naoto Sato</a>, 
<a href="/search/cs?searchtype=author&query=Katsube%2C+R">Ryota Katsube</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1150">[1150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05027" title="Abstract">arXiv:2309.05027</a> (replaced) [<a href="/pdf/2309.05027" title="Download PDF">pdf</a>, <a href="/format/2309.05027" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figure, 5 pages, accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1151">[1151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05527" title="Abstract">arXiv:2309.05527</a> (replaced) [<a href="/pdf/2309.05527" title="Download PDF">pdf</a>, <a href="/format/2309.05527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source  Reconstruction and Target Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiakang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiangchao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and simulated points are available at <a href="https://github.com/PJLab-ADG/3DTrans#resimad">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1152">[1152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06627" title="Abstract">arXiv:2309.06627</a> (replaced) [<a href="/pdf/2309.06627" title="Download PDF">pdf</a>, <a href="/format/2309.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sequentially Fair Mechanism for Multiple Sensitive Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+F">Fran&#xe7;ois Hu</a>, 
<a href="/search/stat?searchtype=author&query=Ratz%2C+P">Philipp Ratz</a>, 
<a href="/search/stat?searchtype=author&query=Charpentier%2C+A">Arthur Charpentier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1153">[1153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07156" title="Abstract">arXiv:2309.07156</a> (replaced) [<a href="/pdf/2309.07156" title="Download PDF">pdf</a>, <a href="/format/2309.07156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparency in Sleep Staging: Deep Learning Method for EEG Sleep Stage  Classification with Model Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S">Shivam Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Maiti%2C+S">Suvadeep Maiti</a>, 
<a href="/search/eess?searchtype=author&query=Mythirayee%2C+S">S. Mythirayee</a>, 
<a href="/search/eess?searchtype=author&query=Rajendran%2C+S">Srijithesh Rajendran</a>, 
<a href="/search/eess?searchtype=author&query=Bapi%2C+R+S">Raju Surampudi Bapi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, Under review at IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1154">[1154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07355" title="Abstract">arXiv:2309.07355</a> (replaced) [<a href="/pdf/2309.07355" title="Download PDF">pdf</a>, <a href="/format/2309.07355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-Time Adaptive Processing for radars in Connected and Automated  Vehicular Radar Platoons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Esmaeilbeig%2C+Z">Zahra Esmaeilbeig</a>, 
<a href="/search/eess?searchtype=author&query=Mishra%2C+K+V">Kumar Vijay Mishra</a>, 
<a href="/search/eess?searchtype=author&query=Soltanalian%2C+M">Mojtaba Soltanalian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1155">[1155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07360" title="Abstract">arXiv:2309.07360</a> (replaced) [<a href="/pdf/2309.07360" title="Download PDF">pdf</a>, <a href="/format/2309.07360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haptic search with the Smart Suction Cup on adversarial objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jungpyo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+D">Sebastian D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Huh%2C+T+M">Tae Myung Huh</a>, 
<a href="/search/cs?searchtype=author&query=Stuart%2C+H+S">Hannah S. Stuart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted final version to appear in the IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1156">[1156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08105" title="Abstract">arXiv:2309.08105</a> (replaced) [<a href="/pdf/2309.08105" title="Download PDF">pdf</a>, <a href="/format/2309.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Libriheavy: a 50,000 hours ASR corpus with punctuation casing and  context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1157">[1157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08230" title="Abstract">arXiv:2309.08230</a> (replaced) [<a href="/pdf/2309.08230" title="Download PDF">pdf</a>, <a href="/format/2309.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in  Machine Unlearning Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongsheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jiamin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Haonan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shuang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haojin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the Network and Distributed System Security Symposium (NDSS) 2024, San Diego, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1158">[1158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09552" title="Abstract">arXiv:2309.09552</a> (replaced) [<a href="/pdf/2309.09552" title="Download PDF">pdf</a>, <a href="/format/2309.09552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary  Keyword-Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinglu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengxin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xiaosong Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaofeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+M">Mengyao Piao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiawei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xinglin Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Miaomiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1159">[1159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09677" title="Abstract">arXiv:2309.09677</a> (replaced) [<a href="/pdf/2309.09677" title="Download PDF">pdf</a>, <a href="/format/2309.09677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single and Few-step Diffusion for Generative Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lay%2C+B">Bunlong Lay</a>, 
<a href="/search/eess?searchtype=author&query=Lemercier%2C+J">Jean-Marie Lemercier</a>, 
<a href="/search/eess?searchtype=author&query=Richter%2C+J">Julius Richter</a>, 
<a href="/search/eess?searchtype=author&query=Gerkmann%2C+T">Timo Gerkmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1160">[1160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11856" title="Abstract">arXiv:2309.11856</a> (replaced) [<a href="/pdf/2309.11856" title="Download PDF">pdf</a>, <a href="/format/2309.11856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Activation Compression of Graph Neural Networks using Block-wise  Quantization with Improved Variance Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Eliassen%2C+S">Sebastian Eliassen</a>, 
<a href="/search/stat?searchtype=author&query=Selvan%2C+R">Raghavendra Selvan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to be presented at the International Conference on Acoustics, Speech and Signal Processing (ICASSP-2024). Source code at <a href="https://github.com/saintslab/i-Exact">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1161">[1161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11864" title="Abstract">arXiv:2309.11864</a> (replaced) [<a href="/pdf/2309.11864" title="Download PDF">pdf</a>, <a href="/ps/2309.11864" title="Download PostScript">ps</a>, <a href="/format/2309.11864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Golub-Welsch version for simultaneous Gaussian quadrature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Van+Assche%2C+W">Walter Van Assche</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Classical Analysis and ODEs (math.CA)

</div>
</div>
</dd>
<dt><a name="item1162">[1162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12081" title="Abstract">arXiv:2309.12081</a> (replaced) [<a href="/pdf/2309.12081" title="Download PDF">pdf</a>, <a href="/format/2309.12081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Framework on Fully Distributed State Estimation and Cooperative  Stabilization of LTI Plants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Duan%2C+P">Peihu Duan</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+Y">Yuezu Lv</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+G">Guanghui Wen</a>, 
<a href="/search/eess?searchtype=author&query=Ogorza%C5%82ek%2C+M">Maciej Ogorza&#x142;ek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1163">[1163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12252" title="Abstract">arXiv:2309.12252</a> (replaced) [<a href="/pdf/2309.12252" title="Download PDF">pdf</a>, <a href="/format/2309.12252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelizing non-linear sequential models over the sequence length
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+Y+H">Yi Heng Lim</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Selfridge%2C+J">Joshua Selfridge</a>, 
<a href="/search/cs?searchtype=author&query=Kasim%2C+M+F">Muhammad Firmansyah Kasim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item1164">[1164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12330" title="Abstract">arXiv:2309.12330</a> (replaced) [<a href="/pdf/2309.12330" title="Download PDF">pdf</a>, <a href="/format/2309.12330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Token Economy Theory (DeTEcT)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sadykhov%2C+R">Rem Sadykhov</a>, 
<a href="/search/q-fin?searchtype=author&query=Goodell%2C+G">Geoffrey Goodell</a>, 
<a href="/search/q-fin?searchtype=author&query=de+Montigny%2C+D">Denis de Montigny</a>, 
<a href="/search/q-fin?searchtype=author&query=Schoernig%2C+M">Martin Schoernig</a>, 
<a href="/search/q-fin?searchtype=author&query=Treleaven%2C+P">Philip Treleaven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item1165">[1165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12563" title="Abstract">arXiv:2309.12563</a> (replaced) [<a href="/pdf/2309.12563" title="Download PDF">pdf</a>, <a href="/format/2309.12563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Passive Reflection Codebook Design for IRS-Integrated Access Point
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1166">[1166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12657" title="Abstract">arXiv:2309.12657</a> (replaced) [<a href="/pdf/2309.12657" title="Download PDF">pdf</a>, <a href="/format/2309.12657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Modality-Specific Features For Multi-Modal Manipulation  Detection And Grounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiazhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Changtao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+W">Wanyi Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Q">Qi Chu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+N">Nenghai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Camera-ready version and supplementary material
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1167">[1167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12678" title="Abstract">arXiv:2309.12678</a> (replaced) [<a href="/pdf/2309.12678" title="Download PDF">pdf</a>, <a href="/format/2309.12678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Cellini%2C+L">Lorenzo Cellini</a>, 
<a href="/search/quant-ph?searchtype=author&query=Macaluso%2C+A">Antonio Macaluso</a>, 
<a href="/search/quant-ph?searchtype=author&query=Lombardi%2C+M">Michele Lombardi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1168">[1168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12689" title="Abstract">arXiv:2309.12689</a> (replaced) [<a href="/pdf/2309.12689" title="Download PDF">pdf</a>, <a href="/format/2309.12689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AMPLIFY:Attention-based Mixup for Performance Improvement and Label  Smoothing in Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Leixin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yu Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1169">[1169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13915" title="Abstract">arXiv:2309.13915</a> (replaced) [<a href="/pdf/2309.13915" title="Download PDF">pdf</a>, <a href="/format/2309.13915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity of Neural Policy Mirror Descent for Policy  Optimization on Low-Dimensional Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minshuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1170">[1170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14324" title="Abstract">arXiv:2309.14324</a> (replaced) [<a href="/pdf/2309.14324" title="Download PDF">pdf</a>, <a href="/format/2309.14324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General-Purpose Text-Instruction-Guided Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kuan%2C+C">Chun-Yi Kuan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C+A">Chen An Li</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+T">Tsu-Yuan Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+T">Tse-Yang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Chung%2C+H">Ho-Lam Chung</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S">Shuo-yiin Chang</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1171">[1171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14507" title="Abstract">arXiv:2309.14507</a> (replaced) [<a href="/pdf/2309.14507" title="Download PDF">pdf</a>, <a href="/format/2309.14507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-Robust DSP-Assisted Neural Pitch Estimation with Very Low  Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Subramani%2C+K">Krishna Subramani</a>, 
<a href="/search/eess?searchtype=author&query=Valin%2C+J">Jean-Marc Valin</a>, 
<a href="/search/eess?searchtype=author&query=Buethe%2C+J">Jan Buethe</a>, 
<a href="/search/eess?searchtype=author&query=Smaragdis%2C+P">Paris Smaragdis</a>, 
<a href="/search/eess?searchtype=author&query=Goodwin%2C+M">Mike Goodwin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024, 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1172">[1172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14838" title="Abstract">arXiv:2309.14838</a> (replaced) [<a href="/pdf/2309.14838" title="Download PDF">pdf</a>, <a href="/format/2309.14838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emphasized Non-Target Speaker Knowledge in Knowledge Distillation for  Automatic Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Truong%2C+D">Duc-Tuan Truong</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ruijie Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+J+Q">Jia Qi Yip</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+A">Kong Aik Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E+S">Eng Siong Chng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1173">[1173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15492" title="Abstract">arXiv:2309.15492</a> (replaced) [<a href="/pdf/2309.15492" title="Download PDF">pdf</a>, <a href="/format/2309.15492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EDGAR: An Autonomous Driving Research Platform -- From Feature  Development to Real-World Application
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karle%2C+P">Phillip Karle</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+T">Tobias Betz</a>, 
<a href="/search/cs?searchtype=author&query=Bosk%2C+M">Marcin Bosk</a>, 
<a href="/search/cs?searchtype=author&query=Fent%2C+F">Felix Fent</a>, 
<a href="/search/cs?searchtype=author&query=Gehrke%2C+N">Nils Gehrke</a>, 
<a href="/search/cs?searchtype=author&query=Geisslinger%2C+M">Maximilian Geisslinger</a>, 
<a href="/search/cs?searchtype=author&query=Gressenbuch%2C+L">Luis Gressenbuch</a>, 
<a href="/search/cs?searchtype=author&query=Hafemann%2C+P">Philipp Hafemann</a>, 
<a href="/search/cs?searchtype=author&query=Huber%2C+S">Sebastian Huber</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%BCbner%2C+M">Maximilian H&#xfc;bner</a>, 
<a href="/search/cs?searchtype=author&query=Huch%2C+S">Sebastian Huch</a>, 
<a href="/search/cs?searchtype=author&query=Kaljavesi%2C+G">Gemb Kaljavesi</a>, 
<a href="/search/cs?searchtype=author&query=Kerbl%2C+T">Tobias Kerbl</a>, 
<a href="/search/cs?searchtype=author&query=Kulmer%2C+D">Dominik Kulmer</a>, 
<a href="/search/cs?searchtype=author&query=Mascetta%2C+T">Tobias Mascetta</a>, 
<a href="/search/cs?searchtype=author&query=Maierhofer%2C+S">Sebastian Maierhofer</a>, 
<a href="/search/cs?searchtype=author&query=Pfab%2C+F">Florian Pfab</a>, 
<a href="/search/cs?searchtype=author&query=Rezabek%2C+F">Filip Rezabek</a>, 
<a href="/search/cs?searchtype=author&query=Rivera%2C+E">Esteban Rivera</a>, 
<a href="/search/cs?searchtype=author&query=Sagmeister%2C+S">Simon Sagmeister</a>, 
<a href="/search/cs?searchtype=author&query=Seidlitz%2C+L">Leander Seidlitz</a>, 
<a href="/search/cs?searchtype=author&query=Sauerbeck%2C+F">Florian Sauerbeck</a>, 
<a href="/search/cs?searchtype=author&query=Tahiraj%2C+I">Ilir Tahiraj</a>, 
<a href="/search/cs?searchtype=author&query=Trauth%2C+R">Rainer Trauth</a>, 
<a href="/search/cs?searchtype=author&query=Uhlemann%2C+N">Nico Uhlemann</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCrsching%2C+G">Gerald W&#xfc;rsching</a>, 
<a href="/search/cs?searchtype=author&query=Zarrouki%2C+B">Baha Zarrouki</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>, 
<a href="/search/cs?searchtype=author&query=Betz%2C+J">Johannes Betz</a>, 
<a href="/search/cs?searchtype=author&query=Bengler%2C+K">Klaus Bengler</a>, 
<a href="/search/cs?searchtype=author&query=Carle%2C+G">Georg Carle</a>, 
<a href="/search/cs?searchtype=author&query=Diermeyer%2C+F">Frank Diermeyer</a>, 
<a href="/search/cs?searchtype=author&query=Ott%2C+J">J&#xf6;rg Ott</a>, 
<a href="/search/cs?searchtype=author&query=Lienkamp%2C+M">Markus Lienkamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1174">[1174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.15641" title="Abstract">arXiv:2309.15641</a> (replaced) [<a href="/pdf/2309.15641" title="Download PDF">pdf</a>, <a href="/format/2309.15641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Exact Subgraph Matching via GNN-based Path Dominance Embedding  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yutong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+X">Xiang Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingsong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item1175">[1175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16157" title="Abstract">arXiv:2309.16157</a> (replaced) [<a href="/pdf/2309.16157" title="Download PDF">pdf</a>, <a href="/format/2309.16157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling Methods for Inner Product Sketching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daliri%2C+M">Majid Daliri</a>, 
<a href="/search/cs?searchtype=author&query=Freire%2C+J">Juliana Freire</a>, 
<a href="/search/cs?searchtype=author&query=Musco%2C+C">Christopher Musco</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A">A&#xe9;cio Santos</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1176">[1176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16265" title="Abstract">arXiv:2309.16265</a> (replaced) [<a href="/pdf/2309.16265" title="Download PDF">pdf</a>, <a href="/format/2309.16265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic Proximity Alignment: Towards Human Perception-consistent Audio  Tagging by Aligning with Label Text Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yanzhen Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures. Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1177">[1177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16349" title="Abstract">arXiv:2309.16349</a> (replaced) [<a href="/pdf/2309.16349" title="Download PDF">pdf</a>, <a href="/format/2309.16349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Feedback is not Gold Standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosking%2C+T">Tom Hosking</a>, 
<a href="/search/cs?searchtype=author&query=Blunsom%2C+P">Phil Blunsom</a>, 
<a href="/search/cs?searchtype=author&query=Bartolo%2C+M">Max Bartolo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1178">[1178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16369" title="Abstract">arXiv:2309.16369</a> (replaced) [<a href="/pdf/2309.16369" title="Download PDF">pdf</a>, <a href="/format/2309.16369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing the Discussion of Minima Sharpness to the Audio Domain: a  Filter-Normalised Evaluation for Acoustic Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Milling%2C+M">Manuel Milling</a>, 
<a href="/search/cs?searchtype=author&query=Triantafyllopoulos%2C+A">Andreas Triantafyllopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tsangko%2C+I">Iosif Tsangko</a>, 
<a href="/search/cs?searchtype=author&query=Rampp%2C+S+D+N">Simon David Noel Rampp</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn Wolfgang Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1179">[1179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16540" title="Abstract">arXiv:2309.16540</a> (replaced) [<a href="/pdf/2309.16540" title="Download PDF">pdf</a>, <a href="/format/2309.16540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Pretraining for Fact Verification by Language Model  Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazaga%2C+A">Adri&#xe1;n Bazaga</a>, 
<a href="/search/cs?searchtype=author&query=Li%C3%B2%2C+P">Pietro Li&#xf2;</a>, 
<a href="/search/cs?searchtype=author&query=Micklem%2C+G">Gos Micklem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1180">[1180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16672" title="Abstract">arXiv:2309.16672</a> (replaced) [<a href="/pdf/2309.16672" title="Download PDF">pdf</a>, <a href="/format/2309.16672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Transform for Generalizable Instance-wise Invariance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+U">Utkarsh Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Esteves%2C+C">Carlos Esteves</a>, 
<a href="/search/cs?searchtype=author&query=Makadia%2C+A">Ameesh Makadia</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1181">[1181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17011" title="Abstract">arXiv:2309.17011</a> (replaced) [<a href="/pdf/2309.17011" title="Download PDF">pdf</a>, <a href="/format/2309.17011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Interaction Aware Automated Data Representation Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azim%2C+E">Ehtesamul Azim</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIAM Conference on Data Mining(SDM) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1182">[1182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17093" title="Abstract">arXiv:2309.17093</a> (replaced) [<a href="/pdf/2309.17093" title="Download PDF">pdf</a>, <a href="/format/2309.17093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-based Aleatoric Uncertainty Quantification for Cross-modal  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaosu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1183">[1183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17334" title="Abstract">arXiv:2309.17334</a> (replaced) [<a href="/pdf/2309.17334" title="Download PDF">pdf</a>, <a href="/format/2309.17334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Depth Branch Network for Efficient Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tian%2C+H">Huiyuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijian Li</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+M">Min Yao</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1184">[1184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00100" title="Abstract">arXiv:2310.00100</a> (replaced) [<a href="/pdf/2310.00100" title="Download PDF">pdf</a>, <a href="/format/2310.00100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Natural Language Processing Model for Radiology Reports --  The Summary is all you need!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lindo%2C+M">Mariana Lindo</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+A+S">Ana Sofia Santos</a>, 
<a href="/search/cs?searchtype=author&query=Ferreira%2C+A">Andr&#xe9; Ferreira</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianning Li</a>, 
<a href="/search/cs?searchtype=author&query=Luijten%2C+G">Gijs Luijten</a>, 
<a href="/search/cs?searchtype=author&query=Correia%2C+G">Gustavo Correia</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Moon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Schaarschmidt%2C+B+M">Benedikt Michael Schaarschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Deuschl%2C+C">Cornelius Deuschl</a>, 
<a href="/search/cs?searchtype=author&query=Haubold%2C+J">Johannes Haubold</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Egger%2C+J">Jan Egger</a>, 
<a href="/search/cs?searchtype=author&query=Alves%2C+V">Victor Alves</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1185">[1185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01556" title="Abstract">arXiv:2310.01556</a> (replaced) [<a href="/pdf/2310.01556" title="Download PDF">pdf</a>, <a href="/ps/2310.01556" title="Download PostScript">ps</a>, <a href="/format/2310.01556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Family of Strang-type exponential splittings in the presence of  unbounded and time dependent operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kropielnicka%2C+K">Karolina Kropielnicka</a>, 
<a href="/search/math?searchtype=author&query=del+Valle%2C+J+C">Juan Carlos del Valle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1186">[1186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.02901" title="Abstract">arXiv:2310.02901</a> (replaced) [<a href="/pdf/2310.02901" title="Download PDF">pdf</a>, <a href="/format/2310.02901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Vectorized Backpropagation Algorithms for Training Feedforward  Networks Composed of Quadratic Neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Noel%2C+M+M">Mathew Mithra Noel</a>, 
<a href="/search/cs?searchtype=author&query=Muthiah-Nakarajan%2C+V">Venkataraman Muthiah-Nakarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1187">[1187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03586" title="Abstract">arXiv:2310.03586</a> (replaced) [<a href="/pdf/2310.03586" title="Download PDF">pdf</a>, <a href="/format/2310.03586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Suspended Aerial Manipulation Avatar for Physical Interaction in  Unstructured Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+F">Fanyi Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zambella%2C+G">Grazia Zambella</a>, 
<a href="/search/cs?searchtype=author&query=Monteleone%2C+S">Simone Monteleone</a>, 
<a href="/search/cs?searchtype=author&query=Grioli%2C+G">Giorgio Grioli</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+M+G">Manuel G. Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Bicchi%2C+A">Antonio Bicchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Comments: contents revised and re-organized, figures updated, references added, typos corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1188">[1188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04585" title="Abstract">arXiv:2310.04585</a> (replaced) [<a href="/pdf/2310.04585" title="Download PDF">pdf</a>, <a href="/format/2310.04585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interventions Against Machine-Assisted Statistical Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Zhu%2C+J+Y">John Y. Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1189">[1189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05369" title="Abstract">arXiv:2310.05369</a> (replaced) [<a href="/pdf/2310.05369" title="Download PDF">pdf</a>, <a href="/format/2310.05369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdvSV: An Over-the-Air Adversarial Attack Dataset for Speaker  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Li Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiaqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jiahao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chengfang Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jie Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1190">[1190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05378" title="Abstract">arXiv:2310.05378</a> (replaced) [<a href="/pdf/2310.05378" title="Download PDF">pdf</a>, <a href="/ps/2310.05378" title="Download PostScript">ps</a>, <a href="/format/2310.05378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transcending the Attention Paradigm: Representation Learning from  Geospatial Social Media Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DiSanto%2C+N">Nick DiSanto</a>, 
<a href="/search/cs?searchtype=author&query=Corso%2C+A">Anthony Corso</a>, 
<a href="/search/cs?searchtype=author&query=Sanders%2C+B">Benjamin Sanders</a>, 
<a href="/search/cs?searchtype=author&query=Harding%2C+G">Gavin Harding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item1191">[1191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05557" title="Abstract">arXiv:2310.05557</a> (replaced) [<a href="/pdf/2310.05557" title="Download PDF">pdf</a>, <a href="/format/2310.05557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated Computational Fluid Dynamics Simulations of Microfluidic  Devices by Exploiting Higher Levels of Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takken%2C+M">Michel Takken</a>, 
<a href="/search/cs?searchtype=author&query=Wille%2C+R">Robert Wille</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures. Source code: <a href="https://github.com/cda-tum/mmft-hybrid-simulator">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item1192">[1192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05628" title="Abstract">arXiv:2310.05628</a> (replaced) [<a href="/pdf/2310.05628" title="Download PDF">pdf</a>, <a href="/format/2310.05628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Glitter or Gold? Deriving Structured Insights from Sustainability  Reports via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bronzini%2C+M">Marco Bronzini</a>, 
<a href="/search/cs?searchtype=author&query=Nicolini%2C+C">Carlo Nicolini</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>, 
<a href="/search/cs?searchtype=author&query=Staiano%2C+J">Jacopo Staiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1193">[1193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05782" title="Abstract">arXiv:2310.05782</a> (replaced) [<a href="/pdf/2310.05782" title="Download PDF">pdf</a>, <a href="/format/2310.05782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aligning Language Models with Human Preferences via a Bayesian Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1194">[1194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06079" title="Abstract">arXiv:2310.06079</a> (replaced) [<a href="/pdf/2310.06079" title="Download PDF">pdf</a>, <a href="/format/2310.06079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anomalous diffusion and price impact in the fluid-limit of an order book
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Diana%2C+D">Derick Diana</a>, 
<a href="/search/q-fin?searchtype=author&query=Gebbie%2C+T">Tim Gebbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 23 figures, 4 tables; added footnotes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Computational Engineering, Finance, and Science (cs.CE); Adaptation and Self-Organizing Systems (nlin.AO); Trading and Market Microstructure (q-fin.TR)

</div>
</div>
</dd>
<dt><a name="item1195">[1195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06114" title="Abstract">arXiv:2310.06114</a> (replaced) [<a href="/pdf/2310.06114" title="Download PDF">pdf</a>, <a href="/format/2310.06114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Interactive Real-World Simulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengjiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Ghasemipour%2C+K">Kamyar Ghasemipour</a>, 
<a href="/search/cs?searchtype=author&query=Tompson%2C+J">Jonathan Tompson</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L">Leslie Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Schuurmans%2C+D">Dale Schuurmans</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://universal-simulator.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1196">[1196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06872" title="Abstract">arXiv:2310.06872</a> (replaced) [<a href="/pdf/2310.06872" title="Download PDF">pdf</a>, <a href="/format/2310.06872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On sparse regression, Lp-regularization, and automated model discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCulloch%2C+J+A">Jeremy A. McCulloch</a>, 
<a href="/search/cs?searchtype=author&query=Pierre%2C+S+R+S">Skyler R. St. Pierre</a>, 
<a href="/search/cs?searchtype=author&query=Linka%2C+K">Kevin Linka</a>, 
<a href="/search/cs?searchtype=author&query=Kuhl%2C+E">Ellen Kuhl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 15 figures, 2 tables, 62 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1197">[1197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07127" title="Abstract">arXiv:2310.07127</a> (replaced) [<a href="/pdf/2310.07127" title="Download PDF">pdf</a>, <a href="/format/2310.07127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jingyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+R">Rahul Jain</a>, 
<a href="/search/cs?searchtype=author&query=Doh%2C+H">Hyungjun Doh</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+R">Ryo Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Ramani%2C+K">Karthik Ramani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1198">[1198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07557" title="Abstract">arXiv:2310.07557</a> (replaced) [<a href="/pdf/2310.07557" title="Download PDF">pdf</a>, <a href="/format/2310.07557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quality of Service-Constrained Online Routing in High Throughput  Satellites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=B%C3%A9langer%2C+O">Olivier B&#xe9;langer</a>, 
<a href="/search/cs?searchtype=author&query=Yahia%2C+O+B">Olfa Ben Yahia</a>, 
<a href="/search/cs?searchtype=author&query=Martel%2C+S">St&#xe9;phane Martel</a>, 
<a href="/search/cs?searchtype=author&query=Lesage-Landry%2C+A">Antoine Lesage-Landry</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for 2024 IEEE Aerospace Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1199">[1199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07625" title="Abstract">arXiv:2310.07625</a> (replaced) [<a href="/pdf/2310.07625" title="Download PDF">pdf</a>, <a href="/format/2310.07625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cybersecurity as a Crosscutting Concept Across an Undergrad Computer  Science Curriculum: An Experience Report
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+A">Azqa Nadeem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages; Accepted at SIGCSE TS '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1200">[1200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07932" title="Abstract">arXiv:2310.07932</a> (replaced) [<a href="/pdf/2310.07932" title="Download PDF">pdf</a>, <a href="/format/2310.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Matters to You? Towards Visual Representation Alignment for Robot  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Ran Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chenfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tomizuka%2C+M">Masayoshi Tomizuka</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+J">Jitendra Malik</a>, 
<a href="/search/cs?searchtype=author&query=Bajcsy%2C+A">Andrea Bajcsy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1201">[1201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07958" title="Abstract">arXiv:2310.07958</a> (replaced) [<a href="/pdf/2310.07958" title="Download PDF">pdf</a>, <a href="/format/2310.07958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Causal Deep Learning for Vulnerability Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Md Mahbubur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Ceka%2C+I">Ira Ceka</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengzhi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Saikat Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+B">Baishakhi Ray</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+W">Wei Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICSE 2024, Camera Ready Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item1202">[1202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07985" title="Abstract">arXiv:2310.07985</a> (replaced) [<a href="/pdf/2310.07985" title="Download PDF">pdf</a>, <a href="/format/2310.07985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qingfu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhenkun Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1203">[1203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08279" title="Abstract">arXiv:2310.08279</a> (replaced) [<a href="/pdf/2310.08279" title="Download PDF">pdf</a>, <a href="/format/2310.08279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Text-based Knowledge Graph Completion Benefit From Zero-Shot Large  Language Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+L">Li Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> new versionv
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1204">[1204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08352" title="Abstract">arXiv:2310.08352</a> (replaced) [<a href="/pdf/2310.08352" title="Download PDF">pdf</a>, <a href="/format/2310.08352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral deferred correction methods for second-order problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Akramov%2C+I">Ikrom Akramov</a>, 
<a href="/search/math?searchtype=author&query=G%C3%B6tschel%2C+S">Sebastian G&#xf6;tschel</a>, 
<a href="/search/math?searchtype=author&query=Minion%2C+M">Michael Minion</a>, 
<a href="/search/math?searchtype=author&query=Ruprecht%2C+D">Daniel Ruprecht</a>, 
<a href="/search/math?searchtype=author&query=Speck%2C+R">Robert Speck</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1205">[1205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08661" title="Abstract">arXiv:2310.08661</a> (replaced) [<a href="/pdf/2310.08661" title="Download PDF">pdf</a>, <a href="/format/2310.08661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting and Algorithmic Generalization with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouellette%2C+S">Simon Ouellette</a>, 
<a href="/search/cs?searchtype=author&query=Pfister%2C+R">Rolf Pfister</a>, 
<a href="/search/cs?searchtype=author&query=Jud%2C+H">Hansueli Jud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Applied AAAI 2024 reviewer comments. We clarified notation in the main algorithm pseudo-code (alg. 1). Removed superfluous experiments on Universal Transformers which did not yield interesting results and added confusion to the main insights of the paper. The paper is now more concise and straight to the point. Clarified our main contributions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1206">[1206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.09605" title="Abstract">arXiv:2310.09605</a> (replaced) [<a href="/pdf/2310.09605" title="Download PDF">pdf</a>, <a href="/format/2310.09605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penetrative AI: Making LLMs Comprehend the Physical World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huatao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Liying Han</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qirui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mo Li</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M">Mani Srivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in HotMobile 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1207">[1207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10213" title="Abstract">arXiv:2310.10213</a> (replaced) [<a href="/pdf/2310.10213" title="Download PDF">pdf</a>, <a href="/format/2310.10213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Multi-Connectivity in Beyond 5G Non-Terrestrial Networks:  Challenges and Possible Solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Majamaa%2C+M">Mikko Majamaa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item1208">[1208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10788" title="Abstract">arXiv:2310.10788</a> (replaced) [<a href="/pdf/2310.10788" title="Download PDF">pdf</a>, <a href="/format/2310.10788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Models of Speech Infer Universal Articulatory Kinematics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+C+J">Cheol Jun Cho</a>, 
<a href="/search/eess?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="/search/eess?searchtype=author&query=Black%2C+A+W">Alan W Black</a>, 
<a href="/search/eess?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala K. Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1209">[1209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10803" title="Abstract">arXiv:2310.10803</a> (replaced) [<a href="/pdf/2310.10803" title="Download PDF">pdf</a>, <a href="/format/2310.10803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic  Organization in HuBERT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+C+J">Cheol Jun Cho</a>, 
<a href="/search/cs?searchtype=author&query=Mohamed%2C+A">Abdelrahman Mohamed</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shang-Wen Li</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+A+W">Alan W Black</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G+K">Gopala K. Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1210">[1210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11217" title="Abstract">arXiv:2310.11217</a> (replaced) [<a href="/pdf/2310.11217" title="Download PDF">pdf</a>, <a href="/format/2310.11217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovative Methods for Non-Destructive Inspection of Handwritten  Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Breci%2C+E">Eleonora Breci</a> (1), 
<a href="/search/cs?searchtype=author&query=Guarnera%2C+L">Luca Guarnera</a> (1), 
<a href="/search/cs?searchtype=author&query=Battiato%2C+S">Sebastiano Battiato</a> (1) ((1) University of Catania)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1211">[1211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11454" title="Abstract">arXiv:2310.11454</a> (replaced) [<a href="/pdf/2310.11454" title="Download PDF">pdf</a>, <a href="/format/2310.11454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VeRA: Vector-based Random Matrix Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kopiczko%2C+D+J">Dawid J. Kopiczko</a>, 
<a href="/search/cs?searchtype=author&query=Blankevoort%2C+T">Tijmen Blankevoort</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024, website: <a href="https://dkopi.github.io/vera">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1212">[1212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11952" title="Abstract">arXiv:2310.11952</a> (replaced) [<a href="/pdf/2310.11952" title="Download PDF">pdf</a>, <a href="/format/2310.11952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recasting Continual Learning as Sequence Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Soochan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Jaehyeon Son</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Gunhee Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1213">[1213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12248" title="Abstract">arXiv:2310.12248</a> (replaced) [<a href="/pdf/2310.12248" title="Download PDF">pdf</a>, <a href="/format/2310.12248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A PAC Learning Algorithm for LTL and Omega-regular Objectives in MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Perez%2C+M">Mateo Perez</a>, 
<a href="/search/cs?searchtype=author&query=Somenzi%2C+F">Fabio Somenzi</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ashutosh Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item1214">[1214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12447" title="Abstract">arXiv:2310.12447</a> (replaced) [<a href="/pdf/2310.12447" title="Download PDF">pdf</a>, <a href="/format/2310.12447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constrained Reweighting of Distributions: an Optimal Transport Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Chakraborty%2C+A">Abhisek Chakraborty</a>, 
<a href="/search/stat?searchtype=author&query=Bhattacharya%2C+A">Anirban Bhattacharya</a>, 
<a href="/search/stat?searchtype=author&query=Pati%2C+D">Debdeep Pati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.10085">arXiv:2303.10085</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1215">[1215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12474" title="Abstract">arXiv:2310.12474</a> (replaced) [<a href="/pdf/2310.12474" title="Download PDF">pdf</a>, <a href="/format/2310.12474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing High-Resolution 3D Generation through Pixel-wise Gradient  Clipping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zijie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiachen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report. Project page <a href="https://fudan-zvg.github.io/PGC-3D">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1216">[1216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12545" title="Abstract">arXiv:2310.12545</a> (replaced) [<a href="/pdf/2310.12545" title="Download PDF">pdf</a>, <a href="/format/2310.12545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel Picard algorithm for general semilinear parabolic PDEs with  gradient-dependent nonlinearities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Neufeld%2C+A">Ariel Neufeld</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+S">Sizhou Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1217">[1217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12600" title="Abstract">arXiv:2310.12600</a> (replaced) [<a href="/pdf/2310.12600" title="Download PDF">pdf</a>, <a href="/format/2310.12600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FUSC: Fetal Ultrasound Semantic Clustering of Second Trimester Scans  Using Deep Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alasmawi%2C+H">Hussain Alasmawi</a>, 
<a href="/search/cs?searchtype=author&query=Bricker%2C+L">Leanne Bricker</a>, 
<a href="/search/cs?searchtype=author&query=Yaqub%2C+M">Mohammad Yaqub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1218">[1218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12701" title="Abstract">arXiv:2310.12701</a> (replaced) [<a href="/pdf/2310.12701" title="Download PDF">pdf</a>, <a href="/ps/2310.12701" title="Download PostScript">ps</a>, <a href="/format/2310.12701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity Games on Temporal Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Austin%2C+P">Pete Austin</a>, 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Sougata Bose</a>, 
<a href="/search/cs?searchtype=author&query=Totzke%2C+P">Patrick Totzke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item1219">[1219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12798" title="Abstract">arXiv:2310.12798</a> (replaced) [<a href="/pdf/2310.12798" title="Download PDF">pdf</a>, <a href="/format/2310.12798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and  Uni-Modal Adapter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sihang Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yanchen Luo</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yixin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EMNLP main conference. 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1220">[1220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12870" title="Abstract">arXiv:2310.12870</a> (replaced) [<a href="/pdf/2310.12870" title="Download PDF">pdf</a>, <a href="/ps/2310.12870" title="Download PostScript">ps</a>, <a href="/format/2310.12870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure preservation in high-order hybrid discretisations of  potential-driven advection-diffusion: linear and nonlinear approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lemaire%2C+S">Simon Lemaire</a>, 
<a href="/search/math?searchtype=author&query=Moatti%2C+J">Julien Moatti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1221">[1221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13349" title="Abstract">arXiv:2310.13349</a> (replaced) [<a href="/pdf/2310.13349" title="Download PDF">pdf</a>, <a href="/format/2310.13349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepFDR: A Deep Learning-based False Discovery Rate Control Method for  Neuroimaging Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kim%2C+T">Taehyo Kim</a>, 
<a href="/search/stat?searchtype=author&query=Shu%2C+H">Hai Shu</a>, 
<a href="/search/stat?searchtype=author&query=Jia%2C+Q">Qiran Jia</a>, 
<a href="/search/stat?searchtype=author&query=de+Leon%2C+M">Mony de Leon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1222">[1222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13991" title="Abstract">arXiv:2310.13991</a> (replaced) [<a href="/pdf/2310.13991" title="Download PDF">pdf</a>, <a href="/format/2310.13991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An $M$-ary Concentration Shift Keying with Common Detection Thresholds  For Multitransmitter Molecular Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shitiri%2C+E">Ethungshan Shitiri</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+H">Ho-Shin Cho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1223">[1223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14053" title="Abstract">arXiv:2310.14053</a> (replaced) [<a href="/pdf/2310.14053" title="Download PDF">pdf</a>, <a href="/format/2310.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Accuracy: Evaluating Self-Consistency of Code Large Language  Models with IdentityChain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Min%2C+M+J">Marcus J. Min</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yangruibo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Buratti%2C+L">Luca Buratti</a>, 
<a href="/search/cs?searchtype=author&query=Pujar%2C+S">Saurabh Pujar</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+G">Gail Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+S">Suman Jana</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+B">Baishakhi Ray</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1224">[1224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14076" title="Abstract">arXiv:2310.14076</a> (replaced) [<a href="/pdf/2310.14076" title="Download PDF">pdf</a>, <a href="/format/2310.14076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Relationship Between Relevance and Conflict in Online Social Link  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanbang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kleinberg%2C+J">Jon Kleinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1225">[1225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14345" title="Abstract">arXiv:2310.14345</a> (replaced) [<a href="/pdf/2310.14345" title="Download PDF">pdf</a>, <a href="/format/2310.14345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum-walk search in motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sahu%2C+H">Himanshu Sahu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sen%2C+K">Kallol Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A section on scaling of the algorithm is added. 21 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1226">[1226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14580" title="Abstract">arXiv:2310.14580</a> (replaced) [<a href="/pdf/2310.14580" title="Download PDF">pdf</a>, <a href="/format/2310.14580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Acoustic BPE for Speech Generation with Discrete Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+F">Feiyu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yiwei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+C">Chenpeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kai Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures; accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1227">[1227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14685" title="Abstract">arXiv:2310.14685</a> (replaced) [<a href="/pdf/2310.14685" title="Download PDF">pdf</a>, <a href="/format/2310.14685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Learning in Contextual Games under Unknown Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maddux%2C+A+M">Anna M. Maddux</a>, 
<a href="/search/cs?searchtype=author&query=Kamgarpour%2C+M">Maryam Kamgarpour</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1228">[1228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14753" title="Abstract">arXiv:2310.14753</a> (replaced) [<a href="/pdf/2310.14753" title="Download PDF">pdf</a>, <a href="/format/2310.14753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Tokenizer and Decoder in Masked Graph Modeling for Molecules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yaorui Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">An Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Enzhi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kawaguchi%2C+K">Kenji Kawaguchi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023. 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1229">[1229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15011" title="Abstract">arXiv:2310.15011</a> (replaced) [<a href="/pdf/2310.15011" title="Download PDF">pdf</a>, <a href="/ps/2310.15011" title="Download PostScript">ps</a>, <a href="/format/2310.15011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interference Management by Harnessing Multi-Domain Resources in  Spectrum-Sharing Aided Satellite-Ground Integrated Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+X">Xiaojin Ding</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Y">Yue Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yulong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hanzo%2C+L">Lajos Hanzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Transactions on Vehicular Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1230">[1230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16221" title="Abstract">arXiv:2310.16221</a> (replaced) [<a href="/pdf/2310.16221" title="Download PDF">pdf</a>, <a href="/format/2310.16221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Randomized Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=Schuchardt%2C+J">Jan Schuchardt</a>, 
<a href="/search/cs?searchtype=author&query=Bojchevski%2C+A">Aleksandar Bojchevski</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1231">[1231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.16652" title="Abstract">arXiv:2310.16652</a> (replaced) [<a href="/pdf/2310.16652" title="Download PDF">pdf</a>, <a href="/format/2310.16652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Robust is Federated Learning to Communication Error? A Comparison  Study Between Uplink and Downlink Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Linping Qu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shenghui Song</a>, 
<a href="/search/cs?searchtype=author&query=Tsui%2C+C">Chi-Ying Tsui</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yuyi Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1232">[1232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17072" title="Abstract">arXiv:2310.17072</a> (replaced) [<a href="/pdf/2310.17072" title="Download PDF">pdf</a>, <a href="/format/2310.17072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMMP++: Isometric Motion Manifold Primitives with Parametric Curve  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yonghyeon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1233">[1233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18341" title="Abstract">arXiv:2310.18341</a> (replaced) [<a href="/pdf/2310.18341" title="Download PDF">pdf</a>, <a href="/ps/2310.18341" title="Download PostScript">ps</a>, <a href="/format/2310.18341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CXR-LLAVA: a multimodal large language model for interpreting chest  X-ray images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seowoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Youn%2C+J">Jiwon Youn</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Mansu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S+H">Soon Ho Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1234">[1234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19224" title="Abstract">arXiv:2310.19224</a> (replaced) [<a href="/pdf/2310.19224" title="Download PDF">pdf</a>, <a href="/format/2310.19224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHAMMI: A benchmark for channel-adaptive models in microscopy imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zitong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+C">Chau Pham</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Doron%2C+M">Michael Doron</a>, 
<a href="/search/cs?searchtype=author&query=Moshkov%2C+N">Nikita Moshkov</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Caicedo%2C+J+C">Juan C. Caicedo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS Track on Datasets and Benchmarks, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1235">[1235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19273" title="Abstract">arXiv:2310.19273</a> (replaced) [<a href="/pdf/2310.19273" title="Download PDF">pdf</a>, <a href="/format/2310.19273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Memory Perturbation Equation: Understanding Model&#x27;s Sensitivity to  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nickl%2C+P">Peter Nickl</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tailor%2C+D">Dharmesh Tailor</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6llenhoff%2C+T">Thomas M&#xf6;llenhoff</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+E">Mohammad Emtiyaz Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37th Conference on Neural Information Processing Systems (NeurIPS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1236">[1236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19680" title="Abstract">arXiv:2310.19680</a> (replaced) [<a href="/pdf/2310.19680" title="Download PDF">pdf</a>, <a href="/format/2310.19680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Pre-trained Language Model into Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hwang%2C+S">Soon-Jae Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+C">Chang-Sung Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1237">[1237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19747" title="Abstract">arXiv:2310.19747</a> (replaced) [<a href="/pdf/2310.19747" title="Download PDF">pdf</a>, <a href="/ps/2310.19747" title="Download PostScript">ps</a>, <a href="/format/2310.19747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristics of price related fluctuations in Non-Fungible Token  (NFT) market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Szyd%C5%82o%2C+P">Pawe&#x142; Szyd&#x142;o</a>, 
<a href="/search/q-fin?searchtype=author&query=W%C4%85torek%2C+M">Marcin W&#x105;torek</a>, 
<a href="/search/q-fin?searchtype=author&query=Kwapie%C5%84%2C+J">Jaros&#x142;aw Kwapie&#x144;</a>, 
<a href="/search/q-fin?searchtype=author&query=Dro%C5%BCd%C5%BC%2C+S">Stanis&#x142;aw Dro&#x17c;d&#x17c;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Chaos 34, 013108 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Computational Engineering, Finance, and Science (cs.CE); Econometrics (econ.EM); Data Analysis, Statistics and Probability (physics.data-an); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1238">[1238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20501" title="Abstract">arXiv:2310.20501</a> (replaced) [<a href="/pdf/2310.20501" title="Download PDF">pdf</a>, <a href="/format/2310.20501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs may Dominate Information Access: Neural Retrievers are Biased  Towards LLM-Generated Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+S">Sunhao Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuqi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weihao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaolin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1239">[1239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.20598" title="Abstract">arXiv:2310.20598</a> (replaced) [<a href="/pdf/2310.20598" title="Download PDF">pdf</a>, <a href="/format/2310.20598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Conversion with Switching Costs: Robust and Learning-Augmented  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lechowicz%2C+A">Adam Lechowicz</a>, 
<a href="/search/cs?searchtype=author&query=Christianson%2C+N">Nicolas Christianson</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Bo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bashir%2C+N">Noman Bashir</a>, 
<a href="/search/cs?searchtype=author&query=Hajiesmaili%2C+M">Mohammad Hajiesmaili</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>, 
<a href="/search/cs?searchtype=author&query=Shenoy%2C+P">Prashant Shenoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGMETRICS / Performance '24. 47 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1240">[1240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01017" title="Abstract">arXiv:2311.01017</a> (replaced) [<a href="/pdf/2311.01017" title="Download PDF">pdf</a>, <a href="/format/2311.01017" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Unsupervised World Models for Autonomous Driving via Discrete  Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lunjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yuwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Casas%2C+S">Sergio Casas</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Urtasun%2C+R">Raquel Urtasun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1241">[1241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01352" title="Abstract">arXiv:2311.01352</a> (replaced) [<a href="/pdf/2311.01352" title="Download PDF">pdf</a>, <a href="/format/2311.01352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning based Image Compression for Microscopy Images: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Sollmann%2C+J">Jan Sollmann</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jianxu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> - Update github link; - correct the author name; - update the table (correct some errors during calculation); - update the implementation detail section and the discussion section
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1242">[1242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01644" title="Abstract">arXiv:2311.01644</a> (replaced) [<a href="/pdf/2311.01644" title="Download PDF">pdf</a>, <a href="/format/2311.01644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Should Under-parameterized Student Networks Copy or Average Teacher  Weights?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C5%9Eim%C5%9Fek%2C+B">Berfin &#x15e;im&#x15f;ek</a>, 
<a href="/search/cs?searchtype=author&query=Bendjeddou%2C+A">Amire Bendjeddou</a>, 
<a href="/search/cs?searchtype=author&query=Gerstner%2C+W">Wulfram Gerstner</a>, 
<a href="/search/cs?searchtype=author&query=Brea%2C+J">Johanni Brea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, presented at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1243">[1243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02332" title="Abstract">arXiv:2311.02332</a> (replaced) [<a href="/pdf/2311.02332" title="Download PDF">pdf</a>, <a href="/format/2311.02332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Machine Learning in Image-Based and Clinical Biomedicine:  Survey and Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Warner%2C+E">Elisa Warner</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonsang Lee</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+W">William Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Syeda-Mahmood%2C+T">Tanveer Syeda-Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C">Charles Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Gevaert%2C+O">Olivier Gevaert</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+A">Arvind Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1244">[1244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02700" title="Abstract">arXiv:2311.02700</a> (replaced) [<a href="/pdf/2311.02700" title="Download PDF">pdf</a>, <a href="/format/2311.02700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generative Multi-Resolution Pyramid and Normal-Conditioning 3D Cloth  Draping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laczk%C3%B3%2C+H">Hunor Laczk&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Madadi%2C+M">Meysam Madadi</a>, 
<a href="/search/cs?searchtype=author&query=Escalera%2C+S">Sergio Escalera</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+J">Jordi Gonzalez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WACV24, IEEE copyright
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1245">[1245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02791" title="Abstract">arXiv:2311.02791</a> (replaced) [<a href="/pdf/2311.02791" title="Download PDF">pdf</a>, <a href="/format/2311.02791" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MirrorCalib: Utilizing Human Pose Information for Mirror-based Virtual  Camera Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Longyun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+A">Andrew Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rong Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1246">[1246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02794" title="Abstract">arXiv:2311.02794</a> (replaced) [<a href="/pdf/2311.02794" title="Download PDF">pdf</a>, <a href="/format/2311.02794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Cellular Perturbations with the Sparse Additive Mechanism  Shift Variational Autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bereket%2C+M">Michael Bereket</a>, 
<a href="/search/stat?searchtype=author&query=Karaletsos%2C+T">Theofanis Karaletsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) (Post-NeurIPS fixes: cosmetic fixes, updated references, added simulation to appendix)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item1247">[1247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02850" title="Abstract">arXiv:2311.02850</a> (replaced) [<a href="/pdf/2311.02850" title="Download PDF">pdf</a>, <a href="/format/2311.02850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IR-STP: Enhancing Autonomous Driving with Interaction Reasoning in  Spatio-Temporal Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingbing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jie Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+L">Lu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures, accepted by IEEE-TITS at this January
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1248">[1248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03046" title="Abstract">arXiv:2311.03046</a> (replaced) [<a href="/pdf/2311.03046" title="Download PDF">pdf</a>, <a href="/format/2311.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Antenna Positioning and Beamforming Design for Fluid-Antenna Enabled  Multi-user Downlink Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+H">Haoran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhendong Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Nan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fangjiong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1249">[1249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03220" title="Abstract">arXiv:2311.03220</a> (replaced) [<a href="/pdf/2311.03220" title="Download PDF">pdf</a>, <a href="/format/2311.03220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic  Decision-Making with AI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shaoguang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item1250">[1250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03351" title="Abstract">arXiv:2311.03351</a> (replaced) [<a href="/pdf/2311.03351" title="Download PDF">pdf</a>, <a href="/format/2311.03351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uni-O4: Unifying Online and Offline Deep Reinforcement Learning with  Multi-Step On-Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+K">Kun Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhengmao He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kaizhe Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our website: <a href="https://lei-kun.github.io/uni-o4/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1251">[1251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03517" title="Abstract">arXiv:2311.03517</a> (replaced) [<a href="/pdf/2311.03517" title="Download PDF">pdf</a>, <a href="/format/2311.03517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoundCam: A Dataset for Finding Humans Using Room Acoustics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mason Wang</a>, 
<a href="/search/cs?searchtype=author&query=Clarke%2C+S">Samuel Clarke</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jui-Hsien Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+R">Ruohan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In NeurIPS 2023 Datasets and Benchmarks Track. Project page: <a href="https://masonlwang.com/soundcam/.">this https URL</a> Wang and Clarke contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1252">[1252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04071" title="Abstract">arXiv:2311.04071</a> (replaced) [<a href="/pdf/2311.04071" title="Download PDF">pdf</a>, <a href="/format/2311.04071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-Calibrated VAE with Test Time Free Lunch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yihong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Siya Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xingjian Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yujun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jing Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1253">[1253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04076" title="Abstract">arXiv:2311.04076</a> (replaced) [<a href="/pdf/2311.04076" title="Download PDF">pdf</a>, <a href="/format/2311.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do LLMs exhibit human-like response biases? A case study in survey  design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tjuatja%2C+L">Lindia Tjuatja</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+V">Valerie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S+T">Sherry Tongshuang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Talwalkar%2C+A">Ameet Talwalkar</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1254">[1254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04131" title="Abstract">arXiv:2311.04131</a> (replaced) [<a href="/pdf/2311.04131" title="Download PDF">pdf</a>, <a href="/format/2311.04131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Locating Cross-Task Sequence Continuation Circuits in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+M">Michael Lan</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1255">[1255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.04207" title="Abstract">arXiv:2311.04207</a> (replaced) [<a href="/pdf/2311.04207" title="Download PDF">pdf</a>, <a href="/format/2311.04207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Hashing via Householder Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwengber%2C+L+R">Lucas R. Schwengber</a>, 
<a href="/search/cs?searchtype=author&query=Resende%2C+L">Lucas Resende</a>, 
<a href="/search/cs?searchtype=author&query=Orenstein%2C+P">Paulo Orenstein</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+R+I">Roberto I. Oliveira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1256">[1256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05546" title="Abstract">arXiv:2311.05546</a> (replaced) [<a href="/pdf/2311.05546" title="Download PDF">pdf</a>, <a href="/format/2311.05546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Quantum Reinforcement Learning using Evolutionary  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Topp%2C+F">Felix Topp</a>, 
<a href="/search/quant-ph?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=N%C3%BC%C3%9Flein%2C+J">Jonas N&#xfc;&#xdf;lein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1257">[1257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05559" title="Abstract">arXiv:2311.05559</a> (replaced) [<a href="/pdf/2311.05559" title="Download PDF">pdf</a>, <a href="/format/2311.05559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangling Quantum and Classical Contributions in Hybrid Quantum  Machine Learning Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=K%C3%B6lle%2C+M">Michael K&#xf6;lle</a>, 
<a href="/search/quant-ph?searchtype=author&query=Maurer%2C+J">Jonas Maurer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Altmann%2C+P">Philipp Altmann</a>, 
<a href="/search/quant-ph?searchtype=author&query=S%C3%BCnkel%2C+L">Leo S&#xfc;nkel</a>, 
<a href="/search/quant-ph?searchtype=author&query=Stein%2C+J">Jonas Stein</a>, 
<a href="/search/quant-ph?searchtype=author&query=Linnhoff-Popien%2C+C">Claudia Linnhoff-Popien</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1258">[1258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05739" title="Abstract">arXiv:2311.05739</a> (replaced) [<a href="/pdf/2311.05739" title="Download PDF">pdf</a>, <a href="/format/2311.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Architecture for Network-Efficiency at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudvari%2C+A">Akrit Mudvari</a>, 
<a href="/search/cs?searchtype=author&query=Vainio%2C+A">Antero Vainio</a>, 
<a href="/search/cs?searchtype=author&query=Ofeidis%2C+I">Iason Ofeidis</a>, 
<a href="/search/cs?searchtype=author&query=Tarkoma%2C+S">Sasu Tarkoma</a>, 
<a href="/search/cs?searchtype=author&query=Tassiulas%2C+L">Leandros Tassiulas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1259">[1259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05920" title="Abstract">arXiv:2311.05920</a> (replaced) [<a href="/pdf/2311.05920" title="Download PDF">pdf</a>, <a href="/format/2311.05920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding How People with Binge Eating Disorder and Bulimia Interact  with Digital Food Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+R">Ryuhaerang Choi</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Subin Park</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sujin Han</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sung-Ju Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1260">[1260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06670" title="Abstract">arXiv:2311.06670</a> (replaced) [<a href="/pdf/2311.06670" title="Download PDF">pdf</a>, <a href="/ps/2311.06670" title="Download PostScript">ps</a>, <a href="/format/2311.06670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EPSAPG: A Pipeline Combining MMseqs2 and PSI-BLAST to Quickly Generate  Extensive Protein Sequence Alignment Profiles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arab%2C+I">Issar Arab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1261">[1261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.06748" title="Abstract">arXiv:2311.06748</a> (replaced) [<a href="/pdf/2311.06748" title="Download PDF">pdf</a>, <a href="/format/2311.06748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do Minimum-Norm Shallow Denoisers Look in Function Space?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zeno%2C+C">Chen Zeno</a>, 
<a href="/search/stat?searchtype=author&query=Ongie%2C+G">Greg Ongie</a>, 
<a href="/search/stat?searchtype=author&query=Blumenfeld%2C+Y">Yaniv Blumenfeld</a>, 
<a href="/search/stat?searchtype=author&query=Weinberger%2C+N">Nir Weinberger</a>, 
<a href="/search/stat?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Thirty-seventh Conference on Neural Information Processing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1262">[1262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07377" title="Abstract">arXiv:2311.07377</a> (replaced) [<a href="/pdf/2311.07377" title="Download PDF">pdf</a>, <a href="/format/2311.07377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Testing learning-enabled cyber-physical systems with Large-Language  Models: A Formal Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Mok%2C+A+K">Aloysius K. Mok</a>, 
<a href="/search/cs?searchtype=author&query=Piskac%2C+R">Ruzica Piskac</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+J">Yong Jae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamachari%2C+B">Bhaskar Krishnamachari</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dakai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Sokolsky%2C+O">Oleg Sokolsky</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insup Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1263">[1263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08724" title="Abstract">arXiv:2311.08724</a> (replaced) [<a href="/pdf/2311.08724" title="Download PDF">pdf</a>, <a href="/ps/2311.08724" title="Download PostScript">ps</a>, <a href="/format/2311.08724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Construction in Power Distribution Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1264">[1264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08747" title="Abstract">arXiv:2311.08747</a> (replaced) [<a href="/pdf/2311.08747" title="Download PDF">pdf</a>, <a href="/format/2311.08747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Dense Nested Attention Network Based on Transformer for  Infrared Small Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+C">Chun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jie Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+Y">Yaqian Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianhua Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zechen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Q">Qun Hao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1265">[1265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09394" title="Abstract">arXiv:2311.09394</a> (replaced) [<a href="/pdf/2311.09394" title="Download PDF">pdf</a>, <a href="/format/2311.09394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GWP-ASan: Sampling-Based Detection of Memory-Safety Bugs in Production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Serebryany%2C+K">Kostya Serebryany</a>, 
<a href="/search/cs?searchtype=author&query=Kennelly%2C+C">Chris Kennelly</a>, 
<a href="/search/cs?searchtype=author&query=Phillips%2C+M">Mitch Phillips</a>, 
<a href="/search/cs?searchtype=author&query=Denton%2C+M">Matt Denton</a>, 
<a href="/search/cs?searchtype=author&query=Elver%2C+M">Marco Elver</a>, 
<a href="/search/cs?searchtype=author&query=Potapenko%2C+A">Alexander Potapenko</a>, 
<a href="/search/cs?searchtype=author&query=Morehouse%2C+M">Matt Morehouse</a>, 
<a href="/search/cs?searchtype=author&query=Tsyrklevich%2C+V">Vlad Tsyrklevich</a>, 
<a href="/search/cs?searchtype=author&query=Holler%2C+C">Christian Holler</a>, 
<a href="/search/cs?searchtype=author&query=Lettner%2C+J">Julian Lettner</a>, 
<a href="/search/cs?searchtype=author&query=Kilzer%2C+D">David Kilzer</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+L">Lander Brandt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1266">[1266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09620" title="Abstract">arXiv:2311.09620</a> (replaced) [<a href="/pdf/2311.09620" title="Download PDF">pdf</a>, <a href="/format/2311.09620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAIA: Delving into Gradient-based Attribution Abnormality for  Out-of-distribution Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinggang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoyang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianzong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jiguang Wan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1267">[1267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09760" title="Abstract">arXiv:2311.09760</a> (replaced) [<a href="/pdf/2311.09760" title="Download PDF">pdf</a>, <a href="/format/2311.09760" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eventually Lattice-Linear Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A+T">Arya Tanmay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S+S">Sandeep S Kulkarni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2109.13216">arXiv:2109.13216</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1268">[1268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09812" title="Abstract">arXiv:2311.09812</a> (replaced) [<a href="/pdf/2311.09812" title="Download PDF">pdf</a>, <a href="/format/2311.09812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Propaganda Span Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasanain%2C+M">Maram Hasanain</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+F">Fatema Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+F">Firoj Alam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> propaganda, span detection, disinformation, misinformation, fake news, LLMs, GPT-4
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1269">[1269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10388" title="Abstract">arXiv:2311.10388</a> (replaced) [<a href="/pdf/2311.10388" title="Download PDF">pdf</a>, <a href="/format/2311.10388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Smart Contract Comment Generation via Large Language Models  and In-Context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yiheng Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1270">[1270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11101" title="Abstract">arXiv:2311.11101</a> (replaced) [<a href="/pdf/2311.11101" title="Download PDF">pdf</a>, <a href="/ps/2311.11101" title="Download PostScript">ps</a>, <a href="/format/2311.11101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\varepsilon$-fractional Core Stability in Hedonic Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fioravanti%2C+S">Simone Fioravanti</a>, 
<a href="/search/cs?searchtype=author&query=Flammini%2C+M">Michele Flammini</a>, 
<a href="/search/cs?searchtype=author&query=Kodric%2C+B">Bojana Kodric</a>, 
<a href="/search/cs?searchtype=author&query=Varricchio%2C+G">Giovanna Varricchio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as poster at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1271">[1271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11416" title="Abstract">arXiv:2311.11416</a> (replaced) [<a href="/pdf/2311.11416" title="Download PDF">pdf</a>, <a href="/format/2311.11416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Integrated Sensing and Communication: When Near Field Meets  Wideband
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1272">[1272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11798" title="Abstract">arXiv:2311.11798</a> (replaced) [<a href="/pdf/2311.11798" title="Download PDF">pdf</a>, <a href="/format/2311.11798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operator Learning for Continuous Spatial-Temporal Model with  Gradient-Based and Derivative-Free Optimization Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chuanqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jin-Long Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1273">[1273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12082" title="Abstract">arXiv:2311.12082</a> (replaced) [<a href="/pdf/2311.12082" title="Download PDF">pdf</a>, <a href="/format/2311.12082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiny-VBF: Resource-Efficient Vision Transformer based Lightweight  Beamformer for Ultrasound Single-Angle Plane Wave Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rahoof%2C+A">Abdul Rahoof</a>, 
<a href="/search/eess?searchtype=author&query=Chaturvedi%2C+V">Vivek Chaturvedi</a>, 
<a href="/search/eess?searchtype=author&query=Panicker%2C+M+R">Mahesh Raveendranatha Panicker</a>, 
<a href="/search/eess?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, DATE 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1274">[1274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12275" title="Abstract">arXiv:2311.12275</a> (replaced) [<a href="/pdf/2311.12275" title="Download PDF">pdf</a>, <a href="/format/2311.12275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling On-Device Large Language Model Personalization with  Self-Supervised Data Selection and Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Ruiyang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhenge Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Abbasi%2C+A">Ahmed Abbasi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+P">Peipei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jingtong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1275">[1275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12401" title="Abstract">arXiv:2311.12401</a> (replaced) [<a href="/pdf/2311.12401" title="Download PDF">pdf</a>, <a href="/format/2311.12401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CASR: Refining Action Segmentation via Marginalizing Frame-levle Causal  Relationships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1276">[1276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13158" title="Abstract">arXiv:2311.13158</a> (replaced) [<a href="/pdf/2311.13158" title="Download PDF">pdf</a>, <a href="/format/2311.13158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for  AI Accountability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Boming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+U">Sung Une Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1277">[1277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13326" title="Abstract">arXiv:2311.13326</a> (replaced) [<a href="/pdf/2311.13326" title="Download PDF">pdf</a>, <a href="/format/2311.13326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning and Imitation Learning for Model-free Control on  Financial Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+W">Woosung Koh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+I">Insu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuntae Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Gimin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 AI4TS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Portfolio Management (q-fin.PM)

</div>
</div>
</dd>
<dt><a name="item1278">[1278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13629" title="Abstract">arXiv:2311.13629</a> (replaced) [<a href="/pdf/2311.13629" title="Download PDF">pdf</a>, <a href="/format/2311.13629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion models meet image counter-forensics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tailanian%2C+M">Mat&#xed;as Tailanian</a>, 
<a href="/search/cs?searchtype=author&query=Gardella%2C+M">Marina Gardella</a>, 
<a href="/search/cs?searchtype=author&query=Pardo%2C+%C3%81">&#xc1;lvaro Pardo</a>, 
<a href="/search/cs?searchtype=author&query=Mus%C3%A9%2C+P">Pablo Mus&#xe9;</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Tailani\'an, M., Gardella, M., Pardo, A., &amp; Mus\'e, P. (2024).
  Diffusion models meet image counter-forensics. In Proceedings of the IEEE/CVF
  Winter Conference on Applications of Computer Vision (pp. 3925-3935)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1279">[1279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13708" title="Abstract">arXiv:2311.13708</a> (replaced) [<a href="/pdf/2311.13708" title="Download PDF">pdf</a>, <a href="/ps/2311.13708" title="Download PostScript">ps</a>, <a href="/format/2311.13708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fault Analysis in Substations Based on Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Hui Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1280">[1280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14084" title="Abstract">arXiv:2311.14084</a> (replaced) [<a href="/pdf/2311.14084" title="Download PDF">pdf</a>, <a href="/format/2311.14084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Generated Images Introduce Invisible Relevance Bias to Text-Image  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+D">Danyang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+L">Liang Pang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jingcheng Deng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1281">[1281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14295" title="Abstract">arXiv:2311.14295</a> (replaced) [<a href="/pdf/2311.14295" title="Download PDF">pdf</a>, <a href="/ps/2311.14295" title="Download PostScript">ps</a>, <a href="/format/2311.14295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Active RIS in NOMA Networks with Hardware Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xinwei Yue</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Meiqi Song</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+C">Chongjun Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tian Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Tianwei Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1282">[1282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14656" title="Abstract">arXiv:2311.14656</a> (replaced) [<a href="/pdf/2311.14656" title="Download PDF">pdf</a>, <a href="/format/2311.14656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Charting New Territories: Exploring the Geographic and Geospatial  Capabilities of Multimodal LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberts%2C+J">Jonathan Roberts</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%BCddecke%2C+T">Timo L&#xfc;ddecke</a>, 
<a href="/search/cs?searchtype=author&query=Sheikh%2C+R">Rehan Sheikh</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Albanie%2C+S">Samuel Albanie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> V3: Fixed typo in Fig.1; V2: Minor formatting changes and added missing subfigure captions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1283">[1283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15565" title="Abstract">arXiv:2311.15565</a> (replaced) [<a href="/pdf/2311.15565" title="Download PDF">pdf</a>, <a href="/ps/2311.15565" title="Download PostScript">ps</a>, <a href="/format/2311.15565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing  AI-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oketunji%2C+A+F">Abiodun Finbarrs Oketunji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1284">[1284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16167" title="Abstract">arXiv:2311.16167</a> (replaced) [<a href="/pdf/2311.16167" title="Download PDF">pdf</a>, <a href="/format/2311.16167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving Sampling Physics-informed Neural Networks induced by Moving Mesh  PDE
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Q">Qihong Yang</a>, 
<a href="/search/math?searchtype=author&query=Deng%2C+Y">Yangtao Deng</a>, 
<a href="/search/math?searchtype=author&query=He%2C+Q">Qiaolin He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1285">[1285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16522" title="Abstract">arXiv:2311.16522</a> (replaced) [<a href="/pdf/2311.16522" title="Download PDF">pdf</a>, <a href="/ps/2311.16522" title="Download PostScript">ps</a>, <a href="/format/2311.16522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Fault Characteristics Evaluation in Power Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pei%2C+H">Hao Pei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Si Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanfu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Che Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sizhe Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1286">[1286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16716" title="Abstract">arXiv:2311.16716</a> (replaced) [<a href="/pdf/2311.16716" title="Download PDF">pdf</a>, <a href="/format/2311.16716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPro: Graph Pre-training and Prompt Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Da Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kangyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1287">[1287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16720" title="Abstract">arXiv:2311.16720</a> (replaced) [<a href="/pdf/2311.16720" title="Download PDF">pdf</a>, <a href="/format/2311.16720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSRankLLM: A Two-Stage Adaptation of LLMs for Text Ranking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Longhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanzhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+D">Dingkun Long</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+P">Pengjun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meishan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1288">[1288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16989" title="Abstract">arXiv:2311.16989</a> (replaced) [<a href="/pdf/2311.16989" title="Download PDF">pdf</a>, <a href="/format/2311.16989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGPT&#x27;s One-year Anniversary: Are Open-Source Large Language Models  Catching up?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hailin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+F">Fangkai Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chengwei Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ravaut%2C+M">Mathieu Ravaut</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruochen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Joty%2C+S">Shafiq Joty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> version v4, included latest top-performing open-sourced LLMs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1289">[1289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18193" title="Abstract">arXiv:2311.18193</a> (replaced) [<a href="/pdf/2311.18193" title="Download PDF">pdf</a>, <a href="/format/2311.18193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persistent Test-time Adaptation in Episodic Testing Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Trung-Hieu Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+D+M">Duc Minh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+M+N">Minh N. Do</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1290">[1290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18424" title="Abstract">arXiv:2311.18424</a> (replaced) [<a href="/pdf/2311.18424" title="Download PDF">pdf</a>, <a href="/ps/2311.18424" title="Download PostScript">ps</a>, <a href="/format/2311.18424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Collaborative Data Practices: a Case Study on Artificial  Intelligence for Healthcare Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henkin%2C+R">Rafael Henkin</a>, 
<a href="/search/cs?searchtype=author&query=Remfry%2C+E">Elizabeth Remfry</a>, 
<a href="/search/cs?searchtype=author&query=Reynolds%2C+D+J">Duncan J. Reynolds</a>, 
<a href="/search/cs?searchtype=author&query=Clinch%2C+M">Megan Clinch</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+M+R">Michael R. Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1291">[1291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18744" title="Abstract">arXiv:2311.18744</a> (replaced) [<a href="/pdf/2311.18744" title="Download PDF">pdf</a>, <a href="/format/2311.18744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $\mathbb{Z}_2\times \mathbb{Z}_2$ Equivariant Quantum Neural Networks:  Benchmarking against Classical Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Dong%2C+Z">Zhongtian Dong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cara%2C+M+C">Mar&#xe7;al Comajoan Cara</a>, 
<a href="/search/quant-ph?searchtype=author&query=Dahale%2C+G+R">Gopal Ramesh Dahale</a>, 
<a href="/search/quant-ph?searchtype=author&query=Forestano%2C+R+T">Roy T. Forestano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gleyzer%2C+S">Sergei Gleyzer</a>, 
<a href="/search/quant-ph?searchtype=author&query=Justice%2C+D">Daniel Justice</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kong%2C+K">Kyoungchul Kong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Magorsch%2C+T">Tom Magorsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matchev%2C+K+T">Konstantin T. Matchev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Matcheva%2C+K">Katia Matcheva</a>, 
<a href="/search/quant-ph?searchtype=author&query=Unlu%2C+E+B">Eyup B. Unlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Phenomenology (hep-ph); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1292">[1292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18815" title="Abstract">arXiv:2311.18815</a> (replaced) [<a href="/pdf/2311.18815" title="Download PDF">pdf</a>, <a href="/format/2311.18815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMMA: Immunizing text-to-image Models against Malicious Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+A+Y">Amber Yijia Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+R+A">Raymond A. Yeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1293">[1293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01520" title="Abstract">arXiv:2312.01520</a> (replaced) [<a href="/pdf/2312.01520" title="Download PDF">pdf</a>, <a href="/format/2312.01520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy and the Kullback-Leibler Divergence for Bayesian Networks:  Computational Complexity and Efficient Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scutari%2C+M">Marco Scutari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Algorithms (2024), 17(1), 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1294">[1294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01680" title="Abstract">arXiv:2312.01680</a> (replaced) [<a href="/pdf/2312.01680" title="Download PDF">pdf</a>, <a href="/format/2312.01680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> With Great Humor Comes Great Developer Engagement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+D">Deepika Tiwari</a>, 
<a href="/search/cs?searchtype=author&query=Toady%2C+T">Tim Toady</a>, 
<a href="/search/cs?searchtype=author&query=Monperrus%2C+M">Martin Monperrus</a>, 
<a href="/search/cs?searchtype=author&query=Baudry%2C+B">Benoit Baudry</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of International Conference on Software Engineering,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1295">[1295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02102" title="Abstract">arXiv:2312.02102</a> (replaced) [<a href="/pdf/2312.02102" title="Download PDF">pdf</a>, <a href="/format/2312.02102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Data Injection Attacks on Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shalom%2C+O">Or Shalom</a>, 
<a href="/search/cs?searchtype=author&query=Leshem%2C+A">Amir Leshem</a>, 
<a href="/search/cs?searchtype=author&query=Bajwa%2C+W+U">Waheed U. Bajwa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work will be presented at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1296">[1296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02538" title="Abstract">arXiv:2312.02538</a> (replaced) [<a href="/pdf/2312.02538" title="Download PDF">pdf</a>, <a href="/format/2312.02538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Granularity-Aware Aspect Learning Model for Multi-Aspect Dense  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaojie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+K">Keping Bi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sihui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qishen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WSDM2024, update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1297">[1297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02683" title="Abstract">arXiv:2312.02683</a> (replaced) [<a href="/pdf/2312.02683" title="Download PDF">pdf</a>, <a href="/format/2312.02683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Speech Enhancement in Matched and Mismatched Conditions  Using a Heun-Based Sampler
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gonzalez%2C+P">Philippe Gonzalez</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+Z">Zheng-Hua Tan</a>, 
<a href="/search/eess?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a>, 
<a href="/search/eess?searchtype=author&query=Jensen%2C+J">Jesper Jensen</a>, 
<a href="/search/eess?searchtype=author&query=Alstr%C3%B8m%2C+T+S">Tommy Sonne Alstr&#xf8;m</a>, 
<a href="/search/eess?searchtype=author&query=May%2C+T">Tobias May</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1298">[1298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02708" title="Abstract">arXiv:2312.02708</a> (replaced) [<a href="/pdf/2312.02708" title="Download PDF">pdf</a>, <a href="/format/2312.02708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Adversarial Robustness for Group Equivariant Tasks: Graphs,  Point Clouds, Molecules, and More
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schuchardt%2C+J">Jan Schuchardt</a>, 
<a href="/search/cs?searchtype=author&query=Scholten%2C+Y">Yan Scholten</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCnnemann%2C+S">Stephan G&#xfc;nnemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1299">[1299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03006" title="Abstract">arXiv:2312.03006</a> (replaced) [<a href="/pdf/2312.03006" title="Download PDF">pdf</a>, <a href="/format/2312.03006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Weight Ranking for Multi-Criteria Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamel%2C+A+H">Andreas H Hamel</a>, 
<a href="/search/cs?searchtype=author&query=Kostner%2C+D">Daniel Kostner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1300">[1300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03365" title="Abstract">arXiv:2312.03365</a> (replaced) [<a href="/pdf/2312.03365" title="Download PDF">pdf</a>, <a href="/format/2312.03365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Demand response for residential building heating: Effective Monte Carlo  Tree Search control based on physics-informed neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Pavirani%2C+F">Fabio Pavirani</a>, 
<a href="/search/eess?searchtype=author&query=Gokhale%2C+G">Gargya Gokhale</a>, 
<a href="/search/eess?searchtype=author&query=Claessens%2C+B">Bert Claessens</a>, 
<a href="/search/eess?searchtype=author&query=Develder%2C+C">Chris Develder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1301">[1301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04234" title="Abstract">arXiv:2312.04234</a> (replaced) [<a href="/pdf/2312.04234" title="Download PDF">pdf</a>, <a href="/format/2312.04234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Convolutions Enrich the Self-Attention in Transformers!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongwhan Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wi%2C+H">Hyowon Wi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jayoung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+Y">Yehjin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kookjin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Trask%2C+N">Nathaniel Trask</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+N">Noseong Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1302">[1302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04350" title="Abstract">arXiv:2312.04350</a> (replaced) [<a href="/pdf/2312.04350" title="Download PDF">pdf</a>, <a href="/format/2312.04350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Leeb%2C+F">Felix Leeb</a>, 
<a href="/search/cs?searchtype=author&query=Gresele%2C+L">Luigi Gresele</a>, 
<a href="/search/cs?searchtype=author&query=Kamal%2C+O">Ojasv Kamal</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Z">Zhiheng Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Blin%2C+K">Kevin Blin</a>, 
<a href="/search/cs?searchtype=author&query=Adauto%2C+F+G">Fernando Gonzalez Adauto</a>, 
<a href="/search/cs?searchtype=author&query=Kleiman-Weiner%2C+M">Max Kleiman-Weiner</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023; updated with CLadder dataset v1.5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1303">[1303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04432" title="Abstract">arXiv:2312.04432</a> (replaced) [<a href="/pdf/2312.04432" title="Download PDF">pdf</a>, <a href="/format/2312.04432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning  Attacks in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fereidooni%2C+H">Hossein Fereidooni</a>, 
<a href="/search/cs?searchtype=author&query=Pegoraro%2C+A">Alessandro Pegoraro</a>, 
<a href="/search/cs?searchtype=author&query=Rieger%2C+P">Phillip Rieger</a>, 
<a href="/search/cs?searchtype=author&query=Dmitrienko%2C+A">Alexandra Dmitrienko</a>, 
<a href="/search/cs?searchtype=author&query=Sadeghi%2C+A">Ahmad-Reza Sadeghi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the Network and Distributed System Security (NDSS) Symposium 2024. 16 pages, 8 figures, 12 tables, 1 algorithm, 3 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1304">[1304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05096" title="Abstract">arXiv:2312.05096</a> (replaced) [<a href="/pdf/2312.05096" title="Download PDF">pdf</a>, <a href="/format/2312.05096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ScalO-RAN: Energy-aware Network Intelligence Scaling in Open RAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maxenti%2C+S">Stefano Maxenti</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=Capone%2C+A">Antonio Capone</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item1305">[1305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05379" title="Abstract">arXiv:2312.05379</a> (replaced) [<a href="/pdf/2312.05379" title="Download PDF">pdf</a>, <a href="/format/2312.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Parity Challenges in Reinforcement Learning through Curriculum  Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riis%2C+S">Soren Riis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1306">[1306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05910" title="Abstract">arXiv:2312.05910</a> (replaced) [<a href="/pdf/2312.05910" title="Download PDF">pdf</a>, <a href="/format/2312.05910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Kalman Filtering Meets Gaussian Process SSM for Non-Mean-Field  and Online Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Thi%C3%A9ry%2C+A+H">Alexandre Hoang Thi&#xe9;ry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Gaussian process, state-space model, ensemble Kalman filter, online learning, variational inference. (19 pages, 10 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1307">[1307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06008" title="Abstract">arXiv:2312.06008</a> (replaced) [<a href="/pdf/2312.06008" title="Download PDF">pdf</a>, <a href="/ps/2312.06008" title="Download PostScript">ps</a>, <a href="/format/2312.06008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guardians of Trust: Navigating Data Security in AIOps through Vendor  Partnerships
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Subhadip Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1308">[1308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06355" title="Abstract">arXiv:2312.06355</a> (replaced) [<a href="/pdf/2312.06355" title="Download PDF">pdf</a>, <a href="/ps/2312.06355" title="Download PostScript">ps</a>, <a href="/format/2312.06355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linguistic and Structural Basis of Engineering Design Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Siddharth%2C+L">L. Siddharth</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jianxi Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Digital Libraries (cs.DL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1309">[1309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06910" title="Abstract">arXiv:2312.06910</a> (replaced) [<a href="/pdf/2312.06910" title="Download PDF">pdf</a>, <a href="/format/2312.06910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong convergence of a class of adaptive numerical methods for SDEs  with jumps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kelly%2C+C">C&#xf3;nall Kelly</a>, 
<a href="/search/math?searchtype=author&query=Lord%2C+G">Gabriel Lord</a>, 
<a href="/search/math?searchtype=author&query=Sun%2C+F">Fandi Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1310">[1310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07327" title="Abstract">arXiv:2312.07327</a> (replaced) [<a href="/pdf/2312.07327" title="Download PDF">pdf</a>, <a href="/format/2312.07327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Confidence Multi-View Hashing for Multimedia Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhangmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Lingfang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Li-Rong Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by International Conference on Acoustics, Speech and Signal Processing 2024(ICASSP2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1311">[1311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07586" title="Abstract">arXiv:2312.07586</a> (replaced) [<a href="/pdf/2312.07586" title="Download PDF">pdf</a>, <a href="/format/2312.07586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characteristic Guidance: Non-linear Correction for Diffusion Model at  Large Guidance Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+C">Candi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yuan Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item1312">[1312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07899" title="Abstract">arXiv:2312.07899</a> (replaced) [<a href="/pdf/2312.07899" title="Download PDF">pdf</a>, <a href="/ps/2312.07899" title="Download PostScript">ps</a>, <a href="/format/2312.07899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphological Profiling for Drug Discovery in the Era of Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+Q">Qiaosi Tang</a>, 
<a href="/search/q-bio?searchtype=author&query=Ratnayake%2C+R">Ranjala Ratnayake</a>, 
<a href="/search/q-bio?searchtype=author&query=Seabra%2C+G">Gustavo Seabra</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+Z">Zhe Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Fang%2C+R">Ruogu Fang</a>, 
<a href="/search/q-bio?searchtype=author&query=Cui%2C+L">Lina Cui</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Y">Yousong Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Kahveci%2C+T">Tamer Kahveci</a>, 
<a href="/search/q-bio?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+C">Chenglong Li</a>, 
<a href="/search/q-bio?searchtype=author&query=Luesch%2C+H">Hendrik Luesch</a>, 
<a href="/search/q-bio?searchtype=author&query=Li%2C+Y">Yanjun Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 5 figure, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1313">[1313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08553" title="Abstract">arXiv:2312.08553</a> (replaced) [<a href="/pdf/2312.08553" title="Download PDF">pdf</a>, <a href="/format/2312.08553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USM-Lite: Quantization and Sparsity Aware Fine-tuning for Speech  Recognition with Universal Speech Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ding%2C+S">Shaojin Ding</a>, 
<a href="/search/eess?searchtype=author&query=Qiu%2C+D">David Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Rim%2C+D">David Rim</a>, 
<a href="/search/eess?searchtype=author&query=He%2C+Y">Yanzhang He</a>, 
<a href="/search/eess?searchtype=author&query=Rybakov%2C+O">Oleg Rybakov</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/eess?searchtype=author&query=Prabhavalkar%2C+R">Rohit Prabhavalkar</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/eess?searchtype=author&query=Sainath%2C+T+N">Tara N. Sainath</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+Z">Zhonglin Han</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jian Li</a>, 
<a href="/search/eess?searchtype=author&query=Yazdanbakhsh%2C+A">Amir Yazdanbakhsh</a>, 
<a href="/search/eess?searchtype=author&query=Agrawal%2C+S">Shivani Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024. Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1314">[1314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08723" title="Abstract">arXiv:2312.08723</a> (replaced) [<a href="/pdf/2312.08723" title="Download PDF">pdf</a>, <a href="/format/2312.08723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StemGen: A music generation model that listens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parker%2C+J+D">Julian D. Parker</a>, 
<a href="/search/cs?searchtype=author&query=Spijkervet%2C+J">Janne Spijkervet</a>, 
<a href="/search/cs?searchtype=author&query=Kosta%2C+K">Katerina Kosta</a>, 
<a href="/search/cs?searchtype=author&query=Yesiler%2C+F">Furkan Yesiler</a>, 
<a href="/search/cs?searchtype=author&query=Kuznetsov%2C+B">Boris Kuznetsov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Ju-Chiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Avent%2C+M">Matt Avent</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jitong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+D">Duc Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1315">[1315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09211" title="Abstract">arXiv:2312.09211</a> (replaced) [<a href="/pdf/2312.09211" title="Download PDF">pdf</a>, <a href="/format/2312.09211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Outlier Activations in Low-Precision Fine-Tuning of Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+A">Alireza Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Justin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Nejad%2C+M+G">Mahsa Ghazvini Nejad</a>, 
<a href="/search/cs?searchtype=author&query=Asgharian%2C+M">Masoud Asgharian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Nia%2C+V+P">Vahid Partovi Nia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1316">[1316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09302" title="Abstract">arXiv:2312.09302</a> (replaced) [<a href="/pdf/2312.09302" title="Download PDF">pdf</a>, <a href="/format/2312.09302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Grasping Sites in a Martian Lava Tube: Multi-Stage Perception  Trade Study for ReachBo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+J">Julia Di</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, IEEE Aerospace Conference, March 3-8, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1317">[1317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10048" title="Abstract">arXiv:2312.10048</a> (replaced) [<a href="/pdf/2312.10048" title="Download PDF">pdf</a>, <a href="/ps/2312.10048" title="Download PostScript">ps</a>, <a href="/format/2312.10048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Enhanced Aspect-Level Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+K">Kavita Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+R">Ritu Patel</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+S">Sunita Iyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1318">[1318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10201" title="Abstract">arXiv:2312.10201</a> (replaced) [<a href="/pdf/2312.10201" title="Download PDF">pdf</a>, <a href="/format/2312.10201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARAT: Contrastive Feature Reconstruction and Aggregation for  Multi-Modal Multi-Label Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Cheng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Lidan Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1319">[1319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10251" title="Abstract">arXiv:2312.10251</a> (replaced) [<a href="/pdf/2312.10251" title="Download PDF">pdf</a>, <a href="/format/2312.10251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing Surgical VQA with Scene Graph Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kattel%2C+M">Manasi Kattel</a>, 
<a href="/search/cs?searchtype=author&query=Lavanchy%2C+J+L">Joel L. Lavanchy</a>, 
<a href="/search/cs?searchtype=author&query=Navab%2C+N">Nassir Navab</a>, 
<a href="/search/cs?searchtype=author&query=Srivastav%2C+V">Vinkle Srivastav</a>, 
<a href="/search/cs?searchtype=author&query=Padoy%2C+N">Nicolas Padoy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by IPCAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1320">[1320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10282" title="Abstract">arXiv:2312.10282</a> (replaced) [<a href="/pdf/2312.10282" title="Download PDF">pdf</a>, <a href="/format/2312.10282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RetailKLIP : Finetuning OpenCLIP backbone using metric learning on a  single GPU for Zero-shot retail product image classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+M+M">Muktabh Mayank Srivastava</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1321">[1321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11013" title="Abstract">arXiv:2312.11013</a> (replaced) [<a href="/pdf/2312.11013" title="Download PDF">pdf</a>, <a href="/format/2312.11013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPT4J: Patch Presence Test for Java Binaries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhiyuan Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+X">Xin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xian Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1322">[1322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11084" title="Abstract">arXiv:2312.11084</a> (replaced) [<a href="/pdf/2312.11084" title="Download PDF">pdf</a>, <a href="/format/2312.11084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reinforcement Learning for Connected and Automated Vehicles  Control: Recent Advancements and Future Prospects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hua%2C+M">Min Hua</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xinda Qi</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+K">Kun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z+E">Zemin Eitan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Quan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Hongming Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item1323">[1323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11306" title="Abstract">arXiv:2312.11306</a> (replaced) [<a href="/pdf/2312.11306" title="Download PDF">pdf</a>, <a href="/ps/2312.11306" title="Download PostScript">ps</a>, <a href="/format/2312.11306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-machine cooperation: optimization of drug retrieval sequencing in  automated drug dispensing systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+M">Mengge Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+K">Kan Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+N">Ning Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1324">[1324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11658" title="Abstract">arXiv:2312.11658</a> (replaced) [<a href="/pdf/2312.11658" title="Download PDF">pdf</a>, <a href="/format/2312.11658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traces of Memorisation in Large Language Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Kaswan%2C+A">Ali Al-Kaswan</a>, 
<a href="/search/cs?searchtype=author&query=Izadi%2C+M">Maliheh Izadi</a>, 
<a href="/search/cs?searchtype=author&query=van+Deursen%2C+A">Arie van Deursen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICSE 2024 Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1325">[1325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11841" title="Abstract">arXiv:2312.11841</a> (replaced) [<a href="/pdf/2312.11841" title="Download PDF">pdf</a>, <a href="/format/2312.11841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixRT: Mixed Neural Representations For Real-Time NeRF Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chaojian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Bichen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+P">Peter Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Yingyan">Yingyan</a> (Celine)Lin
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 3DV'24. Project Page: <a href="https://licj15.github.io/MixRT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1326">[1326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12108" title="Abstract">arXiv:2312.12108</a> (replaced) [<a href="/pdf/2312.12108" title="Download PDF">pdf</a>, <a href="/format/2312.12108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Graph Error Detection with Contrastive Confidence Adaption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 38th AAAI Conference on Artificial Intelligence (AAAI 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1327">[1327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12340" title="Abstract">arXiv:2312.12340</a> (replaced) [<a href="/pdf/2312.12340" title="Download PDF">pdf</a>, <a href="/format/2312.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Geometric Fracture Assembly via Co-creation Space among  Assemblers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexi Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chao Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1328">[1328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13424" title="Abstract">arXiv:2312.13424</a> (replaced) [<a href="/pdf/2312.13424" title="Download PDF">pdf</a>, <a href="/ps/2312.13424" title="Download PostScript">ps</a>, <a href="/format/2312.13424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Model Wireless Federated Learning with Downlink Beamforming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+M">Min Dong</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+B">Ben Liang</a>, 
<a href="/search/cs?searchtype=author&query=Afana%2C+A">Ali Afana</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Y">Yahia Ahmed</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. Accepted by IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1329">[1329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13845" title="Abstract">arXiv:2312.13845</a> (replaced) [<a href="/pdf/2312.13845" title="Download PDF">pdf</a>, <a href="/format/2312.13845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Clustering using Restricted Boltzman Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Woubie%2C+A">Abraham Woubie</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+E">Enoch Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Emiru%2C+E+S">Eyael Solomon Emiru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1330">[1330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14033" title="Abstract">arXiv:2312.14033</a> (replaced) [<a href="/pdf/2312.14033" title="Download PDF">pdf</a>, <a href="/format/2312.14033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-Eval: Evaluating the Tool Utilization Capability of Large Language  Models Step by Step
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weihua Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kuikun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiangning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Miao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+J">Jingming Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Feng Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project: <a href="https://open-compass.github.io/T-Eval">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1331">[1331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14040" title="Abstract">arXiv:2312.14040</a> (replaced) [<a href="/pdf/2312.14040" title="Download PDF">pdf</a>, <a href="/format/2312.14040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing Specialization and Adaptation in a Transforming Scientific  Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautheron%2C+L">Lucas Gautheron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1332">[1332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14075" title="Abstract">arXiv:2312.14075</a> (replaced) [<a href="/pdf/2312.14075" title="Download PDF">pdf</a>, <a href="/format/2312.14075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Quantum Complexity Helps Classical Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaezi%2C+A">Arash Vaezi</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M+H">Seyed Mohammad Hussein Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Noghrehy%2C+N+B">Negin Bagheri Noghrehy</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+S+M">Seyed Mohsen Kazemi</a>, 
<a href="/search/cs?searchtype=author&query=Movaghar%2C+A">Ali Movaghar</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+M">Mohammad Ghodsi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1333">[1333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14090" title="Abstract">arXiv:2312.14090</a> (replaced) [<a href="/pdf/2312.14090" title="Download PDF">pdf</a>, <a href="/format/2312.14090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Artificial Intelligence Equipped Social Decentralized  Autonomous Organizations for Tackling Sextortion Cases Version 0.7
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alex%2C+N">Norta Alex</a>, 
<a href="/search/cs?searchtype=author&query=Sotiris%2C+M">Makrygiannis Sotiris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1334">[1334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14198" title="Abstract">arXiv:2312.14198</a> (replaced) [<a href="/pdf/2312.14198" title="Download PDF">pdf</a>, <a href="/format/2312.14198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZeroShape: Regression-based Zero-shot Shape Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Stojanov%2C+S">Stefan Stojanov</a>, 
<a href="/search/cs?searchtype=author&query=Thai%2C+A">Anh Thai</a>, 
<a href="/search/cs?searchtype=author&query=Jampani%2C+V">Varun Jampani</a>, 
<a href="/search/cs?searchtype=author&query=Rehg%2C+J+M">James M. Rehg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://zixuanh.com/projects/zeroshape.html">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1335">[1335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14430" title="Abstract">arXiv:2312.14430</a> (replaced) [<a href="/pdf/2312.14430" title="Download PDF">pdf</a>, <a href="/ps/2312.14430" title="Download PostScript">ps</a>, <a href="/format/2312.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Minato%2C+T">Takashi Minato</a>, 
<a href="/search/cs?searchtype=author&query=Nishizaki%2C+H">Hiromitsu Nishizaki</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Takayuki Nagai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1336">[1336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14466" title="Abstract">arXiv:2312.14466</a> (replaced) [<a href="/pdf/2312.14466" title="Download PDF">pdf</a>, <a href="/format/2312.14466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Assessing Compliant Robotic Grasping from First-Object  Perspective via Instrumented Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Knopke%2C+M">Maceon Knopke</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liguo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Corke%2C+P">Peter Corke</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fangyi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1337">[1337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14507" title="Abstract">arXiv:2312.14507</a> (replaced) [<a href="/pdf/2312.14507" title="Download PDF">pdf</a>, <a href="/format/2312.14507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Harmonic Parameter Estimation Using Differentiable DSP and  Spectral Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torres%2C+B">Bernardo Torres</a> (S2A, IDS), 
<a href="/search/cs?searchtype=author&query=Peeters%2C+G">Geoffroy Peeters</a> (S2A, IDS), 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Ga&#xeb;l Richard</a> (S2A, IDS)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE International Conference on Acoustics, Speech and Signal
  Processing, Apr 2024, Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1338">[1338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14698" title="Abstract">arXiv:2312.14698</a> (replaced) [<a href="/pdf/2312.14698" title="Download PDF">pdf</a>, <a href="/format/2312.14698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-changed normalizing flows for accurate SDE modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bekri%2C+N+E">Naoufal El Bekri</a>, 
<a href="/search/cs?searchtype=author&query=Drumetz%2C+L">Lucas Drumetz</a>, 
<a href="/search/cs?searchtype=author&query=Vermet%2C+F">Franck Vermet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1339">[1339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14856" title="Abstract">arXiv:2312.14856</a> (replaced) [<a href="/pdf/2312.14856" title="Download PDF">pdf</a>, <a href="/format/2312.14856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbulence: Systematically and Automatically Testing Instruction-Tuned  Large Language Models for Code
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honarvar%2C+S">Shahin Honarvar</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Wilk%2C+M">Mark van der Wilk</a>, 
<a href="/search/cs?searchtype=author&query=Donaldson%2C+A">Alastair Donaldson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Modified a typo in the conclusion section regarding the impact of temperature reduction on the diversity of errors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1340">[1340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14957" title="Abstract">arXiv:2312.14957</a> (replaced) [<a href="/pdf/2312.14957" title="Download PDF">pdf</a>, <a href="/format/2312.14957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Session-Based Recommendation by Exploiting Substitutable and  Complementary Relationships from Multi-behavior Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huizi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+C">Cong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hui Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages,11 figures, accepted by Data Mining and Knowledge Discovery(2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1341">[1341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14972" title="Abstract">arXiv:2312.14972</a> (replaced) [<a href="/pdf/2312.14972" title="Download PDF">pdf</a>, <a href="/format/2312.14972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Trade-off Analysis of Replacing Proprietary LLMs with Open Source SLMs  in Production
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Irugalbandara%2C+C">Chandra Irugalbandara</a>, 
<a href="/search/cs?searchtype=author&query=Mahendra%2C+A">Ashish Mahendra</a>, 
<a href="/search/cs?searchtype=author&query=Daynauth%2C+R">Roland Daynauth</a>, 
<a href="/search/cs?searchtype=author&query=Arachchige%2C+T+K">Tharuka Kasthuri Arachchige</a>, 
<a href="/search/cs?searchtype=author&query=Flautner%2C+K">Krisztian Flautner</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lingjia Tang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yiping Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mars%2C+J">Jason Mars</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated title
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1342">[1342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15551" title="Abstract">arXiv:2312.15551</a> (replaced) [<a href="/pdf/2312.15551" title="Download PDF">pdf</a>, <a href="/format/2312.15551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Public Representations for Private Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thaker%2C+P">Pratiksha Thaker</a>, 
<a href="/search/cs?searchtype=author&query=Setlur%2C+A">Amrith Setlur</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z+S">Zhiwei Steven Wu</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+V">Virginia Smith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1343">[1343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15667" title="Abstract">arXiv:2312.15667</a> (replaced) [<a href="/pdf/2312.15667" title="Download PDF">pdf</a>, <a href="/format/2312.15667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy  Gradient
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+X">Xingzhou Lou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Norman%2C+T+J">Timothy J. Norman</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yali Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1344">[1344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15965" title="Abstract">arXiv:2312.15965</a> (replaced) [<a href="/pdf/2312.15965" title="Download PDF">pdf</a>, <a href="/format/2312.15965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reinforcemen Learning with Decoupling Exploration and  Utilization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingpu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qirui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Helin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zirui Song</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+M">Miao Fang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Update some figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1345">[1345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16011" title="Abstract">arXiv:2312.16011</a> (replaced) [<a href="/pdf/2312.16011" title="Download PDF">pdf</a>, <a href="/format/2312.16011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assigning Stationary Distributions to Sparse Stochastic Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gillis%2C+N">Nicolas Gillis</a>, 
<a href="/search/math?searchtype=author&query=Van+Dooren%2C+P">Paul Van Dooren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, code available from <a href="https://gitlab.com/ngillis/TSDP.">this https URL</a> In this second version, we have added a discussion on the Metropolis-Hastings algorithm and added numerical comparisons. Changes are highlighted in blue color
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC); Probability (math.PR); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item1346">[1346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16018" title="Abstract">arXiv:2312.16018</a> (replaced) [<a href="/pdf/2312.16018" title="Download PDF">pdf</a>, <a href="/format/2312.16018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Sichun Luo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bowei He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haohan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yinya Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aojun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yuanzhang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+M">Mingjie Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Linqi Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1347">[1347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16465" title="Abstract">arXiv:2312.16465</a> (replaced) [<a href="/pdf/2312.16465" title="Download PDF">pdf</a>, <a href="/format/2312.16465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Contact Whole Body Force Control for Position-Controlled Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rouxel%2C+Q">Quentin Rouxel</a> (LARSEN), 
<a href="/search/cs?searchtype=author&query=Ivaldi%2C+S">Serena Ivaldi</a> (LARSEN), 
<a href="/search/cs?searchtype=author&query=Mouret%2C+J">Jean-Baptiste Mouret</a> (LARSEN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1348">[1348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16895" title="Abstract">arXiv:2312.16895</a> (replaced) [<a href="/pdf/2312.16895" title="Download PDF">pdf</a>, <a href="/format/2312.16895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RLPlanner: Reinforcement Learning based Floorplanning for Chiplets with  Fast Thermal Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yuanyuan Duan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xingchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiping Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hanming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Leilai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaolei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item1349">[1349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16904" title="Abstract">arXiv:2312.16904</a> (replaced) [<a href="/pdf/2312.16904" title="Download PDF">pdf</a>, <a href="/format/2312.16904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block Pruning for Enhanced Efficiency in Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cheng-En Wu</a>, 
<a href="/search/cs?searchtype=author&query=Davoodi%2C+A">Azadeh Davoodi</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y+H">Yu Hen Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1350">[1350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16918" title="Abstract">arXiv:2312.16918</a> (replaced) [<a href="/pdf/2312.16918" title="Download PDF">pdf</a>, <a href="/format/2312.16918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intelligent Surfaces Empowered Wireless Network: Recent Advances and The  Road to 6G
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Beixiong Zheng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+K">Kaiming Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+X">Xiaodan Shao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+W">Weidong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Di%2C+B">Boya Di</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Basar%2C+E">Ertugrul Basar</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lingyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhi-Quan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1351">[1351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17071" title="Abstract">arXiv:2312.17071</a> (replaced) [<a href="/pdf/2312.17071" title="Download PDF">pdf</a>, <a href="/format/2312.17071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCTNet: Single-Branch CNN with Transformer Semantic Information for  Real-Time Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhengze Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Dongyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Changqian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xiangxiang Chu</a>, 
<a href="/search/cs?searchtype=author&query=Sang%2C+N">Nong Sang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Changxin Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024; typos corrected; code and models have been released at <a href="https://github.com/xzz777/SCTNet">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1352">[1352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17267" title="Abstract">arXiv:2312.17267</a> (replaced) [<a href="/pdf/2312.17267" title="Download PDF">pdf</a>, <a href="/format/2312.17267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Low-resource Prompt-based Relation Representation with  Multi-view Decoupling Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chenghao Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaoye Qu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhenyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Wenfeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangyang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1353">[1353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.17482" title="Abstract">arXiv:2312.17482</a> (replaced) [<a href="/pdf/2312.17482" title="Download PDF">pdf</a>, <a href="/format/2312.17482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Portes%2C+J">Jacob Portes</a>, 
<a href="/search/cs?searchtype=author&query=Trott%2C+A">Alex Trott</a>, 
<a href="/search/cs?searchtype=author&query=Havens%2C+S">Sam Havens</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+D">Daniel King</a>, 
<a href="/search/cs?searchtype=author&query=Venigalla%2C+A">Abhinav Venigalla</a>, 
<a href="/search/cs?searchtype=author&query=Nadeem%2C+M">Moin Nadeem</a>, 
<a href="/search/cs?searchtype=author&query=Sardana%2C+N">Nikhil Sardana</a>, 
<a href="/search/cs?searchtype=author&query=Khudia%2C+D">Daya Khudia</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures in main text. 25 pages total
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1354">[1354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00165" title="Abstract">arXiv:2401.00165</a> (replaced) [<a href="/pdf/2401.00165" title="Download PDF">pdf</a>, <a href="/format/2401.00165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating the Impact of False Negatives in Dense Retrieval with  Contrastive Confidence Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yeqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+C">Cam-Tu Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1355">[1355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00241" title="Abstract">arXiv:2401.00241</a> (replaced) [<a href="/pdf/2401.00241" title="Download PDF">pdf</a>, <a href="/ps/2401.00241" title="Download PostScript">ps</a>, <a href="/format/2401.00241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image Super-resolution Reconstruction Network based on Enhanced Swin  Transformer via Alternating Aggregation of Local-Global Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuming Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingpin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changhui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Hanrong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+B">Binhui Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1356">[1356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00436" title="Abstract">arXiv:2401.00436</a> (replaced) [<a href="/pdf/2401.00436" title="Download PDF">pdf</a>, <a href="/format/2401.00436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-PCR: Diffusion-Based Correspondence Searching in Doubly Stochastic  Matrix Space for Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qianliang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haobo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yaqing Ding</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Lei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1357">[1357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00592" title="Abstract">arXiv:2401.00592</a> (replaced) [<a href="/pdf/2401.00592" title="Download PDF">pdf</a>, <a href="/format/2401.00592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majority voting is not good for heaven or hell, with mirrored  performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Afonkin%2C+V">Vadim Afonkin</a>, 
<a href="/search/physics?searchtype=author&query=Chebotarev%2C+P">Pavel Chebotarev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures. Submitted to a Springer journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Computer Science and Game Theory (cs.GT); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1358">[1358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00741" title="Abstract">arXiv:2401.00741</a> (replaced) [<a href="/pdf/2401.00741" title="Download PDF">pdf</a>, <a href="/format/2401.00741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of  Large Language Models in Real-world Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junjie Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Caishuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yilong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sixian Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1359">[1359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00744" title="Abstract">arXiv:2401.00744</a> (replaced) [<a href="/pdf/2401.00744" title="Download PDF">pdf</a>, <a href="/format/2401.00744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonizing Covariance and Expressiveness for Deep Hamiltonian  Regression in Crystalline Material Research: a Hybrid Cascaded Regression  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+S">Shi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Pan%2C+X">Xinyang Pan</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+X">Xudong Zhu</a>, 
<a href="/search/physics?searchtype=author&query=Gao%2C+T">Tianyu Gao</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+H">Haochong Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Wu%2C+F">Feng Wu</a>, 
<a href="/search/physics?searchtype=author&query=He%2C+L">Lixin He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1360">[1360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00773" title="Abstract">arXiv:2401.00773</a> (replaced) [<a href="/pdf/2401.00773" title="Download PDF">pdf</a>, <a href="/format/2401.00773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Dongwook Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Juyeon Park</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+C">Hee Cheol Chung</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seonghyun Jeong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1361">[1361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00813" title="Abstract">arXiv:2401.00813</a> (replaced) [<a href="/pdf/2401.00813" title="Download PDF">pdf</a>, <a href="/format/2401.00813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultraspherical/Gegenbauer polynomials to unify 2D/3D Ambisonic  directivity designs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zotter%2C+F">Franz Zotter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 56 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1362">[1362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00828" title="Abstract">arXiv:2401.00828</a> (replaced) [<a href="/pdf/2401.00828" title="Download PDF">pdf</a>, <a href="/format/2401.00828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Lattice Sampling of Quantum Field Theories via Neural  Operator-based Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%A1t%C3%A9%2C+B">B&#xe1;lint M&#xe1;t&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Fleuret%2C+F">Fran&#xe7;ois Fleuret</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; High Energy Physics - Lattice (hep-lat); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1363">[1363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00910" title="Abstract">arXiv:2401.00910</a> (replaced) [<a href="/pdf/2401.00910" title="Download PDF">pdf</a>, <a href="/format/2401.00910" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WoodScape Motion Segmentation for Autonomous Driving -- CVPR 2023 OmniCV  Workshop Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+S">Saravanabalagi Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Cibik%2C+N">Nathaniel Cibik</a>, 
<a href="/search/cs?searchtype=author&query=Sistu%2C+G">Ganesh Sistu</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+J">John McDonald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023 OmniCV Workshop Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1364">[1364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01326" title="Abstract">arXiv:2401.01326</a> (replaced) [<a href="/pdf/2401.01326" title="Download PDF">pdf</a>, <a href="/format/2401.01326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Autoregressive Text-to-Graph Framework for Joint Entity and Relation  Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zaratiana%2C+U">Urchade Zaratiana</a>, 
<a href="/search/cs?searchtype=author&query=Tomeh%2C+N">Nadi Tomeh</a>, 
<a href="/search/cs?searchtype=author&query=Holat%2C+P">Pierre Holat</a>, 
<a href="/search/cs?searchtype=author&query=Charnois%2C+T">Thierry Charnois</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 (camera ready version)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1365">[1365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01491" title="Abstract">arXiv:2401.01491</a> (replaced) [<a href="/e-print/2401.01491" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid Neural Network Model For Predicting The Nitrate Concentration  In The Recirculating Aquaculture System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiangyu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lia%2C+J">Jiaxin Lia</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingzhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+Y">Yingsha Qu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+K">Keming Qu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhengguo Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The content of this paper needs to be further filled and improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1366">[1366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01527" title="Abstract">arXiv:2401.01527</a> (replaced) [<a href="/pdf/2401.01527" title="Download PDF">pdf</a>, <a href="/format/2401.01527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisoning Attacks against Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Min Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junliang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+S">Shazia Sadiq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1367">[1367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01619" title="Abstract">arXiv:2401.01619</a> (replaced) [<a href="/pdf/2401.01619" title="Download PDF">pdf</a>, <a href="/ps/2401.01619" title="Download PostScript">ps</a>, <a href="/format/2401.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Several new classes of MDS symbol-pair codes derived from matrix-product  codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiujing Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shixin Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1368">[1368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01622" title="Abstract">arXiv:2401.01622</a> (replaced) [<a href="/pdf/2401.01622" title="Download PDF">pdf</a>, <a href="/format/2401.01622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Atomic Arbitrage in Decentralized Finance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heimbach%2C+L">Lioba Heimbach</a>, 
<a href="/search/cs?searchtype=author&query=Pahari%2C+V">Vabuk Pahari</a>, 
<a href="/search/cs?searchtype=author&query=Schertenleib%2C+E">Eric Schertenleib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; General Finance (q-fin.GN)

</div>
</div>
</dd>
<dt><a name="item1369">[1369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01699" title="Abstract">arXiv:2401.01699</a> (replaced) [<a href="/pdf/2401.01699" title="Download PDF">pdf</a>, <a href="/format/2401.01699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WordArt Designer API: User-Driven Artistic Typography Synthesis with  Large Language Models on ModelScope
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingdong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yusen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xianhui Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiaoyang Kang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zengke Jin</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Spotlight Paper at the Workshop on Machine Learning for Creativity and Design, 37th Conference on Neural Information Processing Systems (NeurIPS 2023). 5 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1370">[1370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01841" title="Abstract">arXiv:2401.01841</a> (replaced) [<a href="/pdf/2401.01841" title="Download PDF">pdf</a>, <a href="/format/2401.01841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov  Decision Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Baiting Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dubey%2C+A">Abhishek Dubey</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+A">Ayan Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the International Conference on Autonomous Agents and MultiAgent Systems (AAMAS), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1371">[1371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02099" title="Abstract">arXiv:2401.02099</a> (replaced) [<a href="/pdf/2401.02099" title="Download PDF">pdf</a>, <a href="/format/2401.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLAPP: Contrastive Language-Audio Pre-training in Passive Underwater  Vessel Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jingsheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+S">Suncheng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jiacheng Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuzhuo Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1372">[1372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02116" title="Abstract">arXiv:2401.02116</a> (replaced) [<a href="/pdf/2401.02116" title="Download PDF">pdf</a>, <a href="/format/2401.02116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Starling: An I/O-Efficient Disk-Resident Graph Index Framework for  High-Dimensional Vector Similarity Search on Data Segment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengzhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weizhi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xiaomeng Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Songlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhangyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+X">Xiangyu Ke</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yunjun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoliang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rentong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Charles Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by SIGMOD 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1373">[1373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02330" title="Abstract">arXiv:2401.02330</a> (replaced) [<a href="/pdf/2401.02330" title="Download PDF">pdf</a>, <a href="/format/2401.02330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ou%2C+Z">Zhicai Ou</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+X">Xiaofeng Mou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jian Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> technique report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1374">[1374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02333" title="Abstract">arXiv:2401.02333</a> (replaced) [<a href="/pdf/2401.02333" title="Download PDF">pdf</a>, <a href="/format/2401.02333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Extraction: Contextualising Tabular Data for Efficient  Summarisation by Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allu%2C+U">Uday Allu</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+B">Biddwan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+V">Vishesh Tripathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1375">[1375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02362" title="Abstract">arXiv:2401.02362</a> (replaced) [<a href="/pdf/2401.02362" title="Download PDF">pdf</a>, <a href="/ps/2401.02362" title="Download PostScript">ps</a>, <a href="/format/2401.02362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Historical Review of Fluid Antenna and Movable Antenna
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1376">[1376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02554" title="Abstract">arXiv:2401.02554</a> (replaced) [<a href="/pdf/2401.02554" title="Download PDF">pdf</a>, <a href="/format/2401.02554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on eigenvalues of zero divisor graphs associated with commutative  rings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rather%2C+B+A">Bilal Ahmad Rather</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 Figures, Submitted to journal "Journal of Applied Mathematics and Computing" on 10 Apr 2023, Comments and suggestions are welcome and can be sent at bilalahmadrr@gamil.com
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Rings and Algebras (math.RA); Spectral Theory (math.SP)

</div>
</div>
</dd>
<dt><a name="item1377">[1377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02727" title="Abstract">arXiv:2401.02727</a> (replaced) [<a href="/pdf/2401.02727" title="Download PDF">pdf</a>, <a href="/ps/2401.02727" title="Download PostScript">ps</a>, <a href="/format/2401.02727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing targeted transferability via feature space fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+H">Hui Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Biwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+A">Anjie Peng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures, accepted by 2024ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1378">[1378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02765" title="Abstract">arXiv:2401.02765</a> (replaced) [<a href="/pdf/2401.02765" title="Download PDF">pdf</a>, <a href="/ps/2401.02765" title="Download PostScript">ps</a>, <a href="/format/2401.02765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved upper bound for the domination number of a graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arumugam%2C+S">Subramanian Arumugam</a>, 
<a href="/search/math?searchtype=author&query=Hegde%2C+S+M">Suresh Manjanath Hegde</a>, 
<a href="/search/math?searchtype=author&query=Kulamarva%2C+S">Shashanka Kulamarva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1379">[1379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02810" title="Abstract">arXiv:2401.02810</a> (replaced) [<a href="/pdf/2401.02810" title="Download PDF">pdf</a>, <a href="/format/2401.02810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Networks for High-Frequency and Multi-Scale  Problems using Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mustajab%2C+A+H">Abdul Hannan Mustajab</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+H">Hao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Rizvi%2C+Z">Zarghaam Rizvi</a>, 
<a href="/search/cs?searchtype=author&query=Wuttke%2C+F">Frank Wuttke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1380">[1380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02941" title="Abstract">arXiv:2401.02941</a> (replaced) [<a href="/pdf/2401.02941" title="Download PDF">pdf</a>, <a href="/format/2401.02941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Federated Domain Adaptation for Segmentation of MRI Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nananukul%2C+N">Navapat Nananukul</a>, 
<a href="/search/cs?searchtype=author&query=Soltanian-zadeh%2C+H">Hamid Soltanian-zadeh</a>, 
<a href="/search/cs?searchtype=author&query=Rostami%2C+M">Mohammad Rostami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1381">[1381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02987" title="Abstract">arXiv:2401.02987</a> (replaced) [<a href="/pdf/2401.02987" title="Download PDF">pdf</a>, <a href="/format/2401.02987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Has Your Pretrained Model Improved? A Multi-head Posterior Based  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aboagye%2C+P">Prince Aboagye</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Saini%2C+U+S">Uday Singh Saini</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+M">Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shubham Jain</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1382">[1382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03105" title="Abstract">arXiv:2401.03105</a> (replaced) [<a href="/pdf/2401.03105" title="Download PDF">pdf</a>, <a href="/format/2401.03105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Visual Experts to Resolve the Information Loss in  Multimodal Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xin He</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Longhui Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lingxi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Q">Qi Tian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1383">[1383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03201" title="Abstract">arXiv:2401.03201</a> (replaced) [<a href="/pdf/2401.03201" title="Download PDF">pdf</a>, <a href="/format/2401.03201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DMIT: 3D Multi-modal Instruction Tuning for Scene Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeju Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Ruilong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruifei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangde Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1384">[1384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03218" title="Abstract">arXiv:2401.03218</a> (replaced) [<a href="/pdf/2401.03218" title="Download PDF">pdf</a>, <a href="/format/2401.03218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiniScope: Automated UI Exploration and Privacy Inconsistency Detection  of MiniApps via Two-phase Iterative Hybrid Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuekang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kailong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item1385">[1385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03642" title="Abstract">arXiv:2401.03642</a> (replaced) [<a href="/pdf/2401.03642" title="Download PDF">pdf</a>, <a href="/format/2401.03642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Content-Based Novelty Measure for Scholarly Publications: A Proof of  Concept
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haining Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the proceedings of iConference2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Digital Libraries (cs.DL)

</div>
</div>
</dd>
<dt><a name="item1386">[1386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03648" title="Abstract">arXiv:2401.03648</a> (replaced) [<a href="/pdf/2401.03648" title="Download PDF">pdf</a>, <a href="/format/2401.03648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducibility Analysis and Enhancements for Multi-Aspect Dense  Retriever with Aspect Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+K">Keping Bi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaojie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiafeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ecir2024 as a reproducibility paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1387">[1387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03659" title="Abstract">arXiv:2401.03659</a> (replaced) [<a href="/pdf/2401.03659" title="Download PDF">pdf</a>, <a href="/format/2401.03659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The root-exponential convergence of lightning plus polynomial  approximation on corner domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xiang%2C+S">Shuhuang Xiang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shunfeng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1388">[1388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03726" title="Abstract">arXiv:2401.03726</a> (replaced) [<a href="/pdf/2401.03726" title="Download PDF">pdf</a>, <a href="/format/2401.03726" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAV-enabled Integrated Sensing and Communication: Tracking Design and  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Yifan Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Q">Qingqing Wu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+W">Wen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Meng%2C+K">Kaitao Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures, 5 pages, submitted to IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item1389">[1389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03836" title="Abstract">arXiv:2401.03836</a> (replaced) [<a href="/pdf/2401.03836" title="Download PDF">pdf</a>, <a href="/format/2401.03836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WidthFormer: Toward Efficient Transformer-based BEV View Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenhongyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T">Tianwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lichao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Crowley%2C+E+J">Elliot J. Crowley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1390">[1390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03865" title="Abstract">arXiv:2401.03865</a> (replaced) [<a href="/pdf/2401.03865" title="Download PDF">pdf</a>, <a href="/format/2401.03865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incremental Learning of Stock Trends via Meta-Learning with Dynamic  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shiluo Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Y">Ye Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item1391">[1391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03883" title="Abstract">arXiv:2401.03883</a> (replaced) [<a href="/pdf/2401.03883" title="Download PDF">pdf</a>, <a href="/format/2401.03883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Differential Privacy on Recommendation Accuracy and  Popularity Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%BCllner%2C+P">Peter M&#xfc;llner</a>, 
<a href="/search/cs?searchtype=author&query=Lex%2C+E">Elisabeth Lex</a>, 
<a href="/search/cs?searchtype=author&query=Schedl%2C+M">Markus Schedl</a>, 
<a href="/search/cs?searchtype=author&query=Kowald%2C+D">Dominik Kowald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the IR4Good track at ECIR'24, 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item1392">[1392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03997" title="Abstract">arXiv:2401.03997</a> (replaced) [<a href="/pdf/2401.03997" title="Download PDF">pdf</a>, <a href="/format/2401.03997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Complexity Control for a Class of Uncertain MIMO Nonlinear Systems  under Generalized Time-Varying Output Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mehdifar%2C+F">Farhad Mehdifar</a>, 
<a href="/search/eess?searchtype=author&query=Lindemann%2C+L">Lars Lindemann</a>, 
<a href="/search/eess?searchtype=author&query=Bechlioulis%2C+C+P">Charalampos P. Bechlioulis</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1393">[1393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04076" title="Abstract">arXiv:2401.04076</a> (replaced) [<a href="/pdf/2401.04076" title="Download PDF">pdf</a>, <a href="/format/2401.04076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Security and Privacy Issues in Cloud Storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asiri%2C+N">Norah Asiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item1394">[1394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04124" title="Abstract">arXiv:2401.04124</a> (replaced) [<a href="/pdf/2401.04124" title="Download PDF">pdf</a>, <a href="/format/2401.04124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MobileAgent: enhancing mobile control via human-machine interaction and  SOP integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tinghe Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> agent, mobile control, SOP, human-machine interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1395">[1395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04374" title="Abstract">arXiv:2401.04374</a> (replaced) [<a href="/pdf/2401.04374" title="Download PDF">pdf</a>, <a href="/format/2401.04374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Explainable Artificial Intelligence (XAI): A Data Mining  Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Haoyi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuhong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaofei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiamin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinhao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zeyi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1396">[1396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04377" title="Abstract">arXiv:2401.04377</a> (replaced) [<a href="/pdf/2401.04377" title="Download PDF">pdf</a>, <a href="/format/2401.04377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Real-World Aerial Vision Guidance with Categorical 6D Pose  Tracker
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingtao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Danwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1397">[1397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04464" title="Abstract">arXiv:2401.04464</a> (replaced) [<a href="/pdf/2401.04464" title="Download PDF">pdf</a>, <a href="/format/2401.04464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhilEO Bench: Evaluating Geo-Spatial Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fibaek%2C+C">Casper Fibaek</a>, 
<a href="/search/cs?searchtype=author&query=Camilleri%2C+L">Luke Camilleri</a>, 
<a href="/search/cs?searchtype=author&query=Luyts%2C+A">Andreas Luyts</a>, 
<a href="/search/cs?searchtype=author&query=Dionelis%2C+N">Nikolaos Dionelis</a>, 
<a href="/search/cs?searchtype=author&query=Saux%2C+B+L">Bertrand Le Saux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures, Submitted to IGARSS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1398">[1398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04579" title="Abstract">arXiv:2401.04579</a> (replaced) [<a href="/pdf/2401.04579" title="Download PDF">pdf</a>, <a href="/ps/2401.04579" title="Download PostScript">ps</a>, <a href="/format/2401.04579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Network for Explainable Prediction of Non-Imaging Phenotypes  using Anatomical Multi-View Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Wei%2C+Y">Yuxiang Wei</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+Y">Yuqian Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Xue%2C+T">Tengfei Xue</a>, 
<a href="/search/q-bio?searchtype=author&query=Zekelman%2C+L">Leo Zekelman</a>, 
<a href="/search/q-bio?searchtype=author&query=Makris%2C+N">Nikos Makris</a>, 
<a href="/search/q-bio?searchtype=author&query=Rathi%2C+Y">Yogesh Rathi</a>, 
<a href="/search/q-bio?searchtype=author&query=Cai%2C+W">Weidong Cai</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/q-bio?searchtype=author&query=Donnell%2C+L+J+O">Lauren J. O&#x27; Donnell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 The Medical Image Computing and Computer Assisted Intervention Society workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1399">[1399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04658" title="Abstract">arXiv:2401.04658</a> (replaced) [<a href="/pdf/2401.04658" title="Download PDF">pdf</a>, <a href="/format/2401.04658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence  Lengths in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weigao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dong Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuyang Shen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report. Yiran Zhong is the corresponding author. The source code is available at <a href="https://github.com/OpenNLPLab/lightning-attention">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1400">[1400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04812" title="Abstract">arXiv:2401.04812</a> (replaced) [<a href="/pdf/2401.04812" title="Download PDF">pdf</a>, <a href="/format/2401.04812" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-and-Bound for Non-Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yaoguang Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhizhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicun Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at AAAI 2024. Code is available at <a href="https://github.com/aaucsd/MCIR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item1401">[1401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04846" title="Abstract">arXiv:2401.04846</a> (replaced) [<a href="/pdf/2401.04846" title="Download PDF">pdf</a>, <a href="/format/2401.04846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The inherent goodness of well educated intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Glinsky%2C+M+E">Michael E. Glinsky</a>, 
<a href="/search/econ?searchtype=author&query=Sievert%2C+S">Sharon Sievert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 16 equations, to be submitted to Nature
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1402">[1402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04925" title="Abstract">arXiv:2401.04925</a> (replaced) [<a href="/pdf/2401.04925" title="Download PDF">pdf</a>, <a href="/format/2401.04925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Reasoning Step Length on Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mingyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qinkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=shu%2C+D">Dong shu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wenyue Hua</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yanda Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yongfeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1403">[1403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05153" title="Abstract">arXiv:2401.05153</a> (replaced) [<a href="/pdf/2401.05153" title="Download PDF">pdf</a>, <a href="/format/2401.05153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CrossDiff: Exploring Self-Supervised Representation of Pansharpening via  Cross-Predictive Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yinghui Xing</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Litao Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shizhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanning Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1404">[1404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05329" title="Abstract">arXiv:2401.05329</a> (replaced) [<a href="/pdf/2401.05329" title="Download PDF">pdf</a>, <a href="/format/2401.05329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SmartMME: Implementation of Base Station Switching Off Strategy in ns-3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Argha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+B">Bhupendra Pal</a>, 
<a href="/search/cs?searchtype=author&query=Achari%2C+S">Seemant Achari</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Sandip Chakraborty</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item1405">[1405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05394" title="Abstract">arXiv:2401.05394</a> (replaced) [<a href="/pdf/2401.05394" title="Download PDF">pdf</a>, <a href="/format/2401.05394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Regularization with k-support Norm: An Important Complement to  Sparse Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Vazelhes%2C+W">William de Vazelhes</a>, 
<a href="/search/eess?searchtype=author&query=Mukhoty%2C+B">Bhaskar Mukhoty</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+X">Xiao-Tong Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+B">Bin Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. Code at <a href="https://github.com/wdevazelhes/IRKSN_AAAI2024">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1406">[1406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05438" title="Abstract">arXiv:2401.05438</a> (replaced) [<a href="/pdf/2401.05438" title="Download PDF">pdf</a>, <a href="/format/2401.05438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Designs for Combined 2D+3D Visual Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiayi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Hnatyshyn%2C+R">Rostyslav Hnatyshyn</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+E+A+D">Ebrar A. D. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Maciejewski%2C+R">Ross Maciejewski</a>, 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+T">Tobias Isenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1407">[1407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05533" title="Abstract">arXiv:2401.05533</a> (replaced) [<a href="/pdf/2401.05533" title="Download PDF">pdf</a>, <a href="/format/2401.05533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Smocking through Fabric-Thread Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Ningfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sorkine-Hornung%2C+O">Olga Sorkine-Hornung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
</div>
</dd>
<dt><a name="item1408">[1408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05561" title="Abstract">arXiv:2401.05561</a> (replaced) [<a href="/pdf/2401.05561" title="Download PDF">pdf</a>, <a href="/format/2401.05561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrustLLM: Trustworthiness in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chujie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+W">Wenhan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiner Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yijue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Kellis%2C+M">Manolis Kellis</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J">John Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+S">Suman Jana</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Willian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yanfang Ye</a>,  et al. (3 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is still under work and we welcome your contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1409">[1409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05577" title="Abstract">arXiv:2401.05577</a> (replaced) [<a href="/pdf/2401.05577" title="Download PDF">pdf</a>, <a href="/format/2401.05577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLP: Vision Language Planning for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chenbin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Nesti%2C+T">Tommaso Nesti</a>, 
<a href="/search/cs?searchtype=author&query=Mallik%2C+A">Abhirup Mallik</a>, 
<a href="/search/cs?searchtype=author&query=Allievi%2C+A+G">Alessandro G Allievi</a>, 
<a href="/search/cs?searchtype=author&query=Velipasalar%2C+S">Senem Velipasalar</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liu Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1410">[1410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05596" title="Abstract">arXiv:2401.05596</a> (replaced) [<a href="/pdf/2401.05596" title="Download PDF">pdf</a>, <a href="/ps/2401.05596" title="Download PostScript">ps</a>, <a href="/format/2401.05596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource  Unsupervised Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shilong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihua Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1411">[1411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05611" title="Abstract">arXiv:2401.05611</a> (replaced) [<a href="/pdf/2401.05611" title="Download PDF">pdf</a>, <a href="/format/2401.05611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the existence of funneled orientations for classes of rooted  phylogenetic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=D%C3%B6cker%2C+J">Janosch D&#xf6;cker</a>, 
<a href="/search/q-bio?searchtype=author&query=Linz%2C+S">Simone Linz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1412">[1412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05612" title="Abstract">arXiv:2401.05612</a> (replaced) [<a href="/pdf/2401.05612" title="Download PDF">pdf</a>, <a href="/format/2401.05612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing for Appropriate Reliance: The Roles of AI Uncertainty  Presentation, Initial User Decision, and User Demographics in AI-Assisted  Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiye Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CSCW2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item1413">[1413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05831" title="Abstract">arXiv:2401.05831</a> (replaced) [<a href="/pdf/2401.05831" title="Download PDF">pdf</a>, <a href="/format/2401.05831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silhouette Aggregation: From Micro to Macro
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vardakas%2C+G">Georgios Vardakas</a>, 
<a href="/search/cs?searchtype=author&query=Pavlopoulos%2C+J">John Pavlopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1414">[1414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05926" title="Abstract">arXiv:2401.05926</a> (replaced) [<a href="/pdf/2401.05926" title="Download PDF">pdf</a>, <a href="/format/2401.05926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Commit Message Generation: A Preliminary  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingshu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 31st IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item1415">[1415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05982" title="Abstract">arXiv:2401.05982</a> (replaced) [<a href="/pdf/2401.05982" title="Download PDF">pdf</a>, <a href="/ps/2401.05982" title="Download PostScript">ps</a>, <a href="/format/2401.05982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tree-based varying coefficient model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zakrisson%2C+H">Henning Zakrisson</a>, 
<a href="/search/stat?searchtype=author&query=Lindholm%2C+M">Mathias Lindholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1416">[1416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05984" title="Abstract">arXiv:2401.05984</a> (replaced) [<a href="/pdf/2401.05984" title="Download PDF">pdf</a>, <a href="/format/2401.05984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HybridOctree_Hex: Hybrid Octree-Based Adaptive All-Hexahedral Mesh  Generation with Jacobian Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hua Tong</a>, 
<a href="/search/cs?searchtype=author&query=Halilaj%2C+E">Eni Halilaj</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+J">Yongjie Jessica Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item1417">[1417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06071" title="Abstract">arXiv:2401.06071</a> (replaced) [<a href="/pdf/2401.06071" title="Download PDF">pdf</a>, <a href="/format/2401.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGO:Language Enhanced Multi-modal Grounding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hang Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junting Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+T">Van Tu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhida Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item1418">[1418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06228" title="Abstract">arXiv:2401.06228</a> (replaced) [<a href="/pdf/2401.06228" title="Download PDF">pdf</a>, <a href="/format/2401.06228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Combinatorics of Motzkin Polyominoes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Baril%2C+J">Jean-Luc Baril</a>, 
<a href="/search/math?searchtype=author&query=Kirgizov%2C+S">Sergey Kirgizov</a>, 
<a href="/search/math?searchtype=author&query=Ram%C3%ADrez%2C+J+L">Jos&#xe9; L. Ram&#xed;rez</a>, 
<a href="/search/math?searchtype=author&query=Villamizar%2C+D">Diego Villamizar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item1419">[1419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06255" title="Abstract">arXiv:2401.06255</a> (replaced) [<a href="/pdf/2401.06255" title="Download PDF">pdf</a>, <a href="/format/2401.06255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Predicting Online Vaccination Views using Bow-tie  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yueting Han</a>, 
<a href="/search/cs?searchtype=author&query=Bazzi%2C+M">Marya Bazzi</a>, 
<a href="/search/cs?searchtype=author&query=Turrini%2C+P">Paolo Turrini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The author's affiliation [4] originally lost the part "University of Warwick"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item1420">[1420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06312" title="Abstract">arXiv:2401.06312</a> (replaced) [<a href="/pdf/2401.06312" title="Download PDF">pdf</a>, <a href="/format/2401.06312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Super-Resolution Transformer with Masked Inter&amp;Intra-Frame  Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Leheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaorui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Keze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Leida Li</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S">Shuhang Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1421">[1421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06362" title="Abstract">arXiv:2401.06362</a> (replaced) [<a href="/pdf/2401.06362" title="Download PDF">pdf</a>, <a href="/format/2401.06362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention, Distillation, and Tabularization: Towards Practical Neural  Network-Based Prefetching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengmiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Neelesh Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V+K">Viktor K. Prasanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Operating Systems (cs.OS)

</div>
</div>
</dd>
<dt><a name="item1422">[1422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06400" title="Abstract">arXiv:2401.06400</a> (replaced) [<a href="/pdf/2401.06400" title="Download PDF">pdf</a>, <a href="/format/2401.06400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizing Visual Question Answering from Synthetic to Human-Written  Questions via a Chain of QA with a Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Yeongjae Cho</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Heejun Shin</a>, 
<a href="/search/cs?searchtype=author&query=Jo%2C+Y">Yohan Jo</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Dongmyung Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1423">[1423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06506" title="Abstract">arXiv:2401.06506</a> (replaced) [<a href="/pdf/2401.06506" title="Download PDF">pdf</a>, <a href="/format/2401.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Masking for Universal Deepfake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doloriel%2C+C+T">Chandler Timm Doloriel</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+N">Ngai-Man Cheung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ICASSP-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1424">[1424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06604" title="Abstract">arXiv:2401.06604</a> (replaced) [<a href="/pdf/2401.06604" title="Download PDF">pdf</a>, <a href="/format/2401.06604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Policy Gradient Subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jan Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Schumacher%2C+P">Pierre Schumacher</a>, 
<a href="/search/cs?searchtype=author&query=Guist%2C+S">Simon Guist</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Le Chen</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4ufle%2C+D">Daniel H&#xe4;ufle</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1425">[1425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06637" title="Abstract">arXiv:2401.06637</a> (replaced) [<a href="/pdf/2401.06637" title="Download PDF">pdf</a>, <a href="/format/2401.06637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Examples are Misaligned in Diffusion Model Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+P">Peter Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Durall%2C+R">Ricard Durall</a>, 
<a href="/search/cs?searchtype=author&query=Keuper%2C+J">Janis Keuper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1426">[1426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06722" title="Abstract">arXiv:2401.06722</a> (replaced) [<a href="/pdf/2401.06722" title="Download PDF">pdf</a>, <a href="/ps/2401.06722" title="Download PostScript">ps</a>, <a href="/format/2401.06722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NetMind: Adaptive RAN Baseband Function Placement by GCN Encoding and  Maze-solving DRL
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Assis%2C+K+D">Karcius Day Assis</a>, 
<a href="/search/cs?searchtype=author&query=Aijaz%2C+A">Adnan Aijaz</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Nejabati%2C+R">Reza Nejabati</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shuangyi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Simeonidou%2C+D">Dimitra Simeonidou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item748">Cross-lists</a></li>
<li><a href="#item855">Replacements</a></li>
</ul>
<small>[ total of 1426 entries:  <b>1-1426</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
