<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Mon 22 Jan 24  to  Tue 23 Jan 24, announced Wed, 24 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item307">Cross-lists</a></li>
<li><a href="#item348">Replacements</a></li>
</ul>
<small>[ total of 562 entries:  <b>1-562</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Wed, 24 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12220" title="Abstract">arXiv:2401.12220</a> [<a href="/pdf/2401.12220" title="Download PDF">pdf</a>, <a href="/format/2401.12220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Recognition of Learning Resource Category in a Digital Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Soumya Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+D+K">Debarshi Kumar Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+S">Samiran Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmick%2C+P+K">Plaban Kumar Bhowmick</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P+P">Partha Pratim Das</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 3 figures, Published in JCDL 21
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Digital libraries often face the challenge of processing a large volume of
diverse document types. The manual collection and tagging of metadata can be a
time-consuming and error-prone task. To address this, we aim to develop an
automatic metadata extractor for digital libraries. In this work, we introduce
the Heterogeneous Learning Resources (HLR) dataset designed for document image
classification. The approach involves decomposing individual learning resources
into constituent document images (sheets). These images are then processed
through an OCR tool to extract textual representation. State-of-the-art
classifiers are employed to classify both the document image and its textual
content. Subsequently, the labels of the constituent document images are
utilized to predict the label of the overall document.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12221" title="Abstract">arXiv:2401.12221</a> [<a href="/pdf/2401.12221" title="Download PDF">pdf</a>, <a href="/ps/2401.12221" title="Download PostScript">ps</a>, <a href="/format/2401.12221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Information Technology in Cyberwars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pogaku%2C+S">Santhosh Pogaku</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Different types of warfare have evolved between nations and states in the
modern era, each with its technological breakthroughs and use of cutting-edge
technologies. With the help of the latest innovations, technologies and ideas
emerging and contributing more to the It sector, making it more advanced and
resulting in different technologies used for cyber warfare, information
technology has a stronghold, power, and control over many other integrated
automated technologies. To identify the various technologies that are primarily
used in cyber warfare. This exploratory study used a systematic review
technique and a theme analysis approach to examine prior works in information
technology relevant to cyber warfare.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12223" title="Abstract">arXiv:2401.12223</a> [<a href="/pdf/2401.12223" title="Download PDF">pdf</a>, <a href="/ps/2401.12223" title="Download PostScript">ps</a>, <a href="/format/2401.12223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Global Impact of AI-Artificial Intelligence: Recent Advances and  Future Directions, A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pachegowda%2C+C">Chandregowda Pachegowda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial intelligence (AI) is an emerging technology that has the potential
to transform many aspects of society, including the economy, healthcare, and
transportation. This article synthesizes recent research literature on the
global impact of AI, exploring its potential benefits and risks. The article
highlights the implications of AI, including its impact on economic, ethical,
social, security &amp; privacy, and job displacement aspects. It discusses the
ethical concerns surrounding AI development, including issues of bias,
security, and privacy violations. To ensure the responsible development and
deployment of AI, collaboration between government, industry, and academia is
essential. The article concludes by emphasizing the importance of public
engagement and education to promote awareness and understanding of AI's impact
on society at large.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12224" title="Abstract">arXiv:2401.12224</a> [<a href="/pdf/2401.12224" title="Download PDF">pdf</a>, <a href="/format/2401.12224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4EDA: Emerging Progress in Large Language Models for Electronic  Design Automation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Ruizhe Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xingbo Du</a>, 
<a href="/search/cs?searchtype=author&query=Kai%2C+S">Shixiong Kai</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zhentao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Siyuan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+H">Hui-Ling Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Driven by Moore's Law, the complexity and scale of modern chip design are
increasing rapidly. Electronic Design Automation (EDA) has been widely applied
to address the challenges encountered in the full chip design process. However,
the evolution of very large-scale integrated circuits has made chip design
time-consuming and resource-intensive, requiring substantial prior expert
knowledge. Additionally, intermediate human control activities are crucial for
seeking optimal solutions. In system design stage, circuits are usually
represented with Hardware Description Language (HDL) as a textual format.
Recently, Large Language Models (LLMs) have demonstrated their capability in
context understanding, logic reasoning and answer generation. Since circuit can
be represented with HDL in a textual format, it is reasonable to question
whether LLMs can be leveraged in the EDA field to achieve fully automated chip
design and generate circuits with improved power, performance, and area (PPA).
In this paper, we present a systematic study on the application of LLMs in the
EDA field, categorizing it into the following cases: 1) assistant chatbot, 2)
HDL and script generation, and 3) HDL verification and analysis. Additionally,
we highlight the future research direction, focusing on applying LLMs in logic
synthesis, physical design, multi-modal feature extraction and alignment of
circuits. We collect relevant papers up-to-date in this field via the following
link: https://github.com/Thinklab-SJTU/Awesome-LLM4EDA.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12225" title="Abstract">arXiv:2401.12225</a> [<a href="/pdf/2401.12225" title="Download PDF">pdf</a>, <a href="/format/2401.12225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Data Curation via Object Detection and Filter Ensembles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tzu-Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+C">Changho Shin</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+S+J">Sui Jiet Tay</a>, 
<a href="/search/cs?searchtype=author&query=Adila%2C+D">Dyah Adila</a>, 
<a href="/search/cs?searchtype=author&query=Sala%2C+F">Frederic Sala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appeared in the Workshop of Towards the Next Generation of Computer Vision Datasets (TNGCV) on ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose an approach for curating multimodal data that we used for our
entry in the 2023 DataComp competition filtering track. Our technique combines
object detection and weak supervision-based ensembling. In the first of two
steps in our approach, we employ an out-of-the-box zero-shot object detection
model to extract granular information and produce a variety of filter designs.
In the second step, we employ weak supervision to ensemble filtering rules.
This approach results in a 4% performance improvement when compared to the
best-performing baseline, producing the top-ranking position in the small scale
track at the time of writing. Furthermore, in the medium scale track, we
achieve a noteworthy 4.2% improvement over the baseline by simply ensembling
existing baselines with weak supervision.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12226" title="Abstract">arXiv:2401.12226</a> [<a href="/pdf/2401.12226" title="Download PDF">pdf</a>, <a href="/format/2401.12226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order multiscale methods for advection-diffusion equation with  highly oscillatory boundary condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Astuto%2C+C">Clarissa Astuto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 13 figures, 3 tables. arXiv admin note: substantial text overlap with <a href="/abs/2307.14001">arXiv:2307.14001</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we propose high order numerical methods to solve a 2D
advection-diffusion equation, in the highly oscillatory regime. We use an
integrator strategy that allows the construction of arbitrary high-order
schemes which leads to an accurate approximation of the solution without any
time step-size restriction. This paper focuses on the time multiscale challenge
of the problem, that comes from the velocity, an epsilon-periodic function,
whose expression is explicitly known. epsilon-uniform third order in time
numerical approximations are obtained. For the space discretization, this
strategy is combined with high order finite difference schemes. Numerical
experiments show that the proposed methods achieve the expected order of
accuracy.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12228" title="Abstract">arXiv:2401.12228</a> [<a href="/pdf/2401.12228" title="Download PDF">pdf</a>, <a href="/format/2401.12228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topics evolution through multilayer networks; Analysing 2M tweets from  2022 Qatar FIFA World Cup
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Russo%2C+A">Andrea Russo</a>, 
<a href="/search/cs?searchtype=author&query=Miracula%2C+V">Vincenzo Miracula</a>, 
<a href="/search/cs?searchtype=author&query=Picone%2C+A">Antonio Picone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, 1 table, 3 link
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In this study, we conducted a comprehensive data collection on the 2022 Qatar
FIFA World Cup event and used a multilayer network approach to visualize the
main topics, while considering their context and meaning relationships. We
structured the data into layers that corresponded with the stages of the
tournament and utilized Gephi software to generate the multilayer networks. Our
visualizations displayed both the relationships between topics and words,
showing the word-context relationship, as well as the dynamics and changes over
time by layer of the most frequently discussed topics.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12230" title="Abstract">arXiv:2401.12230</a> [<a href="/pdf/2401.12230" title="Download PDF">pdf</a>, <a href="/format/2401.12230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing in the Era of Large Generative Models: From Cloud-Native to  AI-Native
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+S">Song Bian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lequn Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongjun He</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Y">Yulong Hui</a>, 
<a href="/search/cs?searchtype=author&query=Lentz%2C+M">Matthew Lentz</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Beibin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jialin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Rui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+K">Kexin Rong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianguo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yingjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongji Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanchen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qizhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+D">Danyang Zhuo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we investigate the intersection of large generative AI models
and cloud-native computing architectures. Recent large models such as ChatGPT,
while revolutionary in their capabilities, face challenges like escalating
costs and demand for high-end GPUs. Drawing analogies between
large-model-as-a-service (LMaaS) and cloud database-as-a-service (DBaaS), we
describe an AI-native computing paradigm that harnesses the power of both
cloud-native technologies (e.g., multi-tenancy and serverless computing) and
advanced machine learning runtime (e.g., batched LoRA inference). These joint
efforts aim to optimize costs-of-goods-sold (COGS) and improve resource
accessibility. The journey of merging these two domains is just at the
beginning and we hope to stimulate future research and development in this
area.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12231" title="Abstract">arXiv:2401.12231</a> [<a href="/pdf/2401.12231" title="Download PDF">pdf</a>, <a href="/format/2401.12231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentangled Condensation for Large-scale Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Z">Zhenbang Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shunyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tongya Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph condensation has emerged as an intriguing technique to provide Graph
Neural Networks for large-scale graphs with a more compact yet informative
small graph to save the expensive costs of large-scale graph learning. Despite
the promising results achieved, previous graph condensation methods often
employ an entangled condensation strategy that involves condensing nodes and
edges simultaneously, leading to substantial GPU memory demands. This entangled
strategy has considerably impeded the scalability of graph condensation,
impairing its capability to condense extremely large-scale graphs and produce
condensed graphs with high fidelity. Therefore, this paper presents
Disentangled Condensation for large-scale graphs, abbreviated as DisCo, to
provide scalable graph condensation for graphs of varying sizes. At the heart
of DisCo are two complementary components, namely node and edge condensation
modules, that realize the condensation of nodes and edges in a disentangled
manner. In the node condensation module, we focus on synthesizing condensed
nodes that exhibit a similar node feature distribution to original nodes using
a pre-trained node classification model while incorporating class centroid
alignment and anchor attachment regularizers. After node condensation, in the
edge condensation module, we preserve the topology structure by transferring
the link prediction model of the original graph to the condensed nodes,
generating the corresponding condensed edges. Based on the disentangled
strategy, the proposed DisCo can successfully scale up to the ogbn-papers100M
graph with over 100 million nodes and 1 billion edges with flexible reduction
rates. Extensive experiments on five common datasets further demonstrate that
the proposed DisCo yields results superior to state-of-the-art counterparts by
a significant margin. The source code is available at
https://github.com/BangHonor/DisCo.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12233" title="Abstract">arXiv:2401.12233</a> [<a href="/pdf/2401.12233" title="Download PDF">pdf</a>, <a href="/format/2401.12233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memorization in Self-Supervised Learning Improves Downstream  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kaleem%2C+M+A">Muhammad Ahmad Kaleem</a>, 
<a href="/search/cs?searchtype=author&query=Dziedzic%2C+A">Adam Dziedzic</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Papernot%2C+N">Nicolas Papernot</a>, 
<a href="/search/cs?searchtype=author&query=Boenisch%2C+F">Franziska Boenisch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Self-supervised learning (SSL) has recently received significant attention
due to its ability to train high-performance encoders purely on unlabeled
data-often scraped from the internet. This data can still be sensitive and
empirical evidence suggests that SSL encoders memorize private information of
their training data and can disclose them at inference time. Since existing
theoretical definitions of memorization from supervised learning rely on
labels, they do not transfer to SSL. To address this gap, we propose SSLMem, a
framework for defining memorization within SSL. Our definition compares the
difference in alignment of representations for data points and their augmented
views returned by both encoders that were trained on these data points and
encoders that were not. Through comprehensive empirical analysis on diverse
encoder architectures and datasets we highlight that even though SSL relies on
large datasets and strong augmentations-both known in supervised learning as
regularization techniques that reduce overfitting-still significant fractions
of training data points experience high memorization. Through our empirical
results, we show that this memorization is essential for encoders to achieve
higher generalization performance on different downstream tasks.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12234" title="Abstract">arXiv:2401.12234</a> [<a href="/pdf/2401.12234" title="Download PDF">pdf</a>, <a href="/format/2401.12234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Shanker%2C+S">Shreejith Shanker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 11 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 International Conference on Field-Programmable Technology
  (ICFPT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Recent years have seen an exponential rise in complex software-driven
functionality in vehicles, leading to a rising number of electronic control
units (ECUs), network capabilities, and interfaces. These expanded capabilities
also bring-in new planes of vulnerabilities making intrusion detection and
management a critical capability; however, this can often result in more ECUs
and network elements due to the high computational overheads. In this paper, we
present a consolidated ECU architecture incorporating an Intrusion Detection
System (IDS) for Automotive Controller Area Network (CAN) along with
traditional ECU functionality on an off-the-shelf hybrid FPGA device, with
near-zero overhead for the ECU functionality. We propose two quantised
multi-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of
attack vectors including Denial-of-Service, Fuzzing and Spoofing, which are
accelerated using off-the-shelf deep-learning processing unit (DPU) IP block
from Xilinx, operating fully transparently to the software on the ECU. The
proposed models achieve the state-of-the-art classification accuracy for all
the attacks, while we observed a 15x reduction in power consumption when
compared against the GPU-based implementation of the same models quantised
using Nvidia libraries. We also achieved a 2.3x speed up in per-message
processing latency (at 0.24 ms from the arrival of a CAN message) to meet the
strict end-to-end latency on critical CAN nodes and a 2.6x reduction in power
consumption for inference when compared to the state-of-the-art IDS models on
embedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the
literature.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12235" title="Abstract">arXiv:2401.12235</a> [<a href="/pdf/2401.12235" title="Download PDF">pdf</a>, <a href="/ps/2401.12235" title="Download PostScript">ps</a>, <a href="/format/2401.12235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot  Adaption via Contextual Meta Graph Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Bairong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zhenning Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuehan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yufeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Q">Qiaoyi Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Reinforcement learning is an emerging approaches to facilitate multi-stage
sequential decision-making problems. This paper studies a real-time multi-stage
stochastic power dispatch considering multivariate uncertainties. Current
researches suffer from low generalization and practicality, that is, the
learned dispatch policy can only handle a specific dispatch scenario, its
performance degrades significantly if actual samples and training samples are
inconsistent. To fill these gaps, a novel contextual meta graph reinforcement
learning (Meta-GRL) for a highly generalized multi-stage optimal dispatch
policy is proposed. Specifically, a more general contextual Markov decision
process (MDP) and scalable graph representation are introduced to achieve a
more generalized multi-stage stochastic power dispatch modeling. An upper
meta-learner is proposed to encode context for different dispatch scenarios and
learn how to achieve dispatch task identification while the lower policy
learner learns context-specified dispatch policy. After sufficient offline
learning, this approach can rapidly adapt to unseen and undefined scenarios
with only a few updations of the hypothesis judgments generated by the
meta-learner. Numerical comparisons with state-of-the-art policies and
traditional reinforcement learning verify the optimality, efficiency,
adaptability, and scalability of the proposed Meta-GRL.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12236" title="Abstract">arXiv:2401.12236</a> [<a href="/pdf/2401.12236" title="Download PDF">pdf</a>, <a href="/ps/2401.12236" title="Download PostScript">ps</a>, <a href="/format/2401.12236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Surprising Harmfulness of Benign Overfitting for Adversarial  Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yifan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent empirical and theoretical studies have established the generalization
capabilities of large machine learning models that are trained to
(approximately or exactly) fit noisy data. In this work, we prove a surprising
result that even if the ground truth itself is robust to adversarial examples,
and the benignly overfitted model is benign in terms of the ``standard''
out-of-sample risk objective, this benign overfitting process can be harmful
when out-of-sample data are subject to adversarial manipulation. More
specifically, our main results contain two parts: (i) the min-norm estimator in
overparameterized linear model always leads to adversarial vulnerability in the
``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result
between the standard risk and the ``adversarial'' risk of every ridge
regression estimator, implying that under suitable conditions these two items
cannot both be small at the same time by any single choice of the ridge
regularization parameter. Furthermore, under the lazy training regime, we
demonstrate parallel results on two-layer neural tangent kernel (NTK) model,
which align with empirical observations in deep neural networks. Our finding
provides theoretical insights into the puzzling phenomenon observed in
practice, where the true target function (e.g., human) is robust against
adverasrial attack, while beginly overfitted neural networks lead to models
that are not robust.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12240" title="Abstract">arXiv:2401.12240</a> [<a href="/pdf/2401.12240" title="Download PDF">pdf</a>, <a href="/format/2401.12240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantised Neural Network Accelerators for Low-Power IDS in Automotive  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+S">Shashwat Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Walsh%2C+A">Anneliese Walsh</a>, 
<a href="/search/cs?searchtype=author&query=Shreejith%2C+S">Shanker Shreejith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 pages, 1 figure, 2 tables. arXiv admin note: text overlap with <a href="/abs/2401.11030">arXiv:2401.11030</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 Design, Automation &amp; Test in Europe Conference &amp; Exhibition
  (DATE)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this paper, we explore low-power custom quantised Multi-Layer Perceptrons
(MLPs) as an Intrusion Detection System (IDS) for automotive controller area
network (CAN). We utilise the FINN framework from AMD/Xilinx to quantise, train
and generate hardware IP of our MLP to detect denial of service (DoS) and
fuzzying attacks on CAN network, using ZCU104 (XCZU7EV) FPGA as our target ECU
architecture with integrated IDS capabilities. Our approach achieves
significant improvements in latency (0.12 ms per-message processing latency)
and inference energy consumption (0.25 mJ per inference) while achieving
similar classification performance as state-of-the-art approaches in the
literature.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12241" title="Abstract">arXiv:2401.12241</a> [<a href="/pdf/2401.12241" title="Download PDF">pdf</a>, <a href="/ps/2401.12241" title="Download PostScript">ps</a>, <a href="/format/2401.12241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Power System Resource Expansion Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Datta%2C+S">Sohom Datta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis, Department of Electrical Engineering, Indian Institute of Technology Delhi, New Delhi, India, May 2011
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Power System Resource Planning is the recurrent process of studying and
determining what facilities and procedures should be provided to satisfy and
promote appropriate future demands for electricity. The electric power system
as planned should meet or balance societal goals. These include availability of
electricity to all potential users at lowest possible cost, minimum
environmental damage, high levels of safety and reliability, etc. Plans should
be technically and financially feasible. Plans also should achieve the
objectives the entity doing the planning, including minimizing risk. The
emergence of meta-heuristics has given robustness to the non-analytical
methods, because of the rationale behind them. Besides, evolutionary algorithms
have provided a higher degree of confidence in a stochastic convergence to
optimum and have supported this confidence with a mathematical background
explaining not only how they achieve convergence but also how to improve the
convergence rate. The present work of analyses and implementation can be
divided into: i) Transmission Constrained Generation Expansion Planning (TC
GEP), ii) Composite Generation Expansion and Transmission Network Expansion
Planning (GEP TNEP), iii) Transmission Network Expansion (TNEP) Planning using
AC model, iv) Composite Transmission Network Expansion Planning (TNEP) and
Reactive Power Expansion Planning (RPP) and v) Transmission Network Planning
using Interior-Point Method (IP TNEP).
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12242" title="Abstract">arXiv:2401.12242</a> [<a href="/pdf/2401.12242" title="Download PDF">pdf</a>, <a href="/format/2401.12242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Z">Zhen Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fengqing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zidi Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Ramasubramanian%2C+B">Bhaskar Ramasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are shown to benefit from chain-of-thought (COT)
prompting, particularly when tackling tasks that require systematic reasoning
processes. On the other hand, COT prompting also poses new vulnerabilities in
the form of backdoor attacks, wherein the model will output unintended
malicious content under specific backdoor-triggered conditions during
inference. Traditional methods for launching backdoor attacks involve either
contaminating the training dataset with backdoored instances or directly
manipulating the model parameters during deployment. However, these approaches
are not practical for commercial LLMs that typically operate via API access. In
this paper, we propose BadChain, the first backdoor attack against LLMs
employing COT prompting, which does not require access to the training dataset
or model parameters and imposes low computational overhead. BadChain leverages
the inherent reasoning capabilities of LLMs by inserting a backdoor reasoning
step into the sequence of reasoning steps of the model output, thereby altering
the final response when a backdoor trigger exists in the query prompt.
Empirically, we show the effectiveness of BadChain for two COT strategies
across four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmark
tasks encompassing arithmetic, commonsense, and symbolic reasoning. Moreover,
we show that LLMs endowed with stronger reasoning capabilities exhibit higher
susceptibility to BadChain, exemplified by a high average attack success rate
of 97.0% across the six benchmark tasks on GPT-4. Finally, we propose two
defenses based on shuffling and demonstrate their overall ineffectiveness
against BadChain. Therefore, BadChain remains a severe threat to LLMs,
underscoring the urgency for the development of robust and effective future
defenses.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12244" title="Abstract">arXiv:2401.12244</a> [<a href="/pdf/2401.12244" title="Download PDF">pdf</a>, <a href="/format/2401.12244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-scale Reinforcement Learning for Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tzeng%2C+E">Eric Tzeng</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Kislyuk%2C+D">Dmitry Kislyuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image diffusion models are a class of deep generative models that
have demonstrated an impressive capacity for high-quality image generation.
However, these models are susceptible to implicit biases that arise from
web-scale text-image training pairs and may inaccurately model aspects of
images we care about. This can result in suboptimal samples, model bias, and
images that do not align with human ethics and preferences. In this paper, we
present an effective scalable algorithm to improve diffusion models using
Reinforcement Learning (RL) across a diverse set of reward functions, such as
human preference, compositionality, and fairness over millions of images. We
illustrate how our approach substantially outperforms existing methods for
aligning diffusion models with human preferences. We further illustrate how
this substantially improves pretrained Stable Diffusion (SD) models, generating
samples that are preferred by humans 80.3% of the time over those from the base
SD model while simultaneously improving both the composition and diversity of
generated samples.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12246" title="Abstract">arXiv:2401.12246</a> [<a href="/pdf/2401.12246" title="Download PDF">pdf</a>, <a href="/format/2401.12246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Orion-14B: Open-source Multilingual Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Du Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yongqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yongqiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+H">Haihui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Leichao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dacheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhipeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kun Han</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Authors are alphabetically listed by last names, except the corresponding author who is listed last
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we introduce Orion-14B, a collection of multilingual large
language models with 14 billion parameters. We utilize a data scheduling
approach to train a foundational model on a diverse corpus of 2.5 trillion
tokens, sourced from texts in English, Chinese, Japanese, Korean, and other
languages. Additionally, we fine-tuned a series of models tailored for
conversational applications and other specific use cases. Our evaluation
results demonstrate that Orion-14B achieves state-of-the-art performance across
a broad spectrum of tasks. We make the Orion-14B model family and its
associated code publicly accessible https://github.com/OrionStarAI/Orion,
aiming to inspire future research and practical applications in the field.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12247" title="Abstract">arXiv:2401.12247</a> [<a href="/pdf/2401.12247" title="Download PDF">pdf</a>, <a href="/ps/2401.12247" title="Download PostScript">ps</a>, <a href="/format/2401.12247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring consumers response to text-based chatbots in e-commerce: The  moderating role of task complexity and chatbot disclosure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xusen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Ying Bao</a>, 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+W">Wankun Gong</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+J">Jian Mou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Internet Research (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Artificial intelligence based chatbots have brought unprecedented business
potential. This study aims to explore consumers trust and response to a
text-based chatbot in ecommerce, involving the moderating effects of task
complexity and chatbot identity disclosure. A survey method with 299 useable
responses was conducted in this research. This study adopted the ordinary least
squares regression to test the hypotheses. First, the consumers perception of
both the empathy and friendliness of the chatbot positively impacts their trust
in it. Second, task complexity negatively moderates the relationship between
friendliness and consumers trust. Third, disclosure of the text based chatbot
negatively moderates the relationship between empathy and consumers trust,
while it positively moderates the relationship between friendliness and
consumers trust. Fourth, consumers trust in the chatbot increases their
reliance on the chatbot and decreases their resistance to the chatbot in future
interactions. Adopting the stimulus organism response framework, this study
provides important insights on consumers perception and response to the
text-based chatbot. The findings of this research also make suggestions that
can increase consumers positive responses to text based chatbots. Extant
studies have investigated the effects of automated bots attributes on consumers
perceptions. However, the boundary conditions of these effects are largely
ignored. This research is one of the first attempts to provide a deep
understanding of consumers responses to a chatbot.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12249" title="Abstract">arXiv:2401.12249</a> [<a href="/pdf/2401.12249" title="Download PDF">pdf</a>, <a href="/ps/2401.12249" title="Download PostScript">ps</a>, <a href="/format/2401.12249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding users negative emotions and continuous usage intention in  short video platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xusen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+X">Xiaowei Su</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zarifis%2C+A">Alex Zarifis</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+J">Jian Mou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Electronic Commerce Research and Applications (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While short videos bring a lot of information and happiness to users, they
also occupy users time and short videos gradually change peoples living habits.
This paper studies the negative effects and negative emotions of users caused
by using short video platforms, as well as the users intention to continue
using the short video platform when they have negative emotions. Therefore,
this study uses flow theory and illusion of control theory to construct a
research hypothesis model and preliminarily confirms six influencing factors,
and uses sequential mixed research method to conduct quantitative and
qualitative research. The results show that users use of short video platforms
will have negative emotions and negative emotions will affect users intention
to continue to use short video platforms. This study expands the breadth and
depth of research on short videos and enriches the research of negative
emotions on the intention to continue using human computer interaction
software. Additionally, illusion of control theory is introduced into the field
of human computer interaction for the first time, which enriches the
application scenarios of control illusion theory.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12251" title="Abstract">arXiv:2401.12251</a> [<a href="/pdf/2401.12251" title="Download PDF">pdf</a>, <a href="/format/2401.12251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Representation for Asymmetric Kernels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gomez%2C+A+A">Alvaro Almeida Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Neto%2C+A+S">Antonio Silva Neto</a>, 
<a href="/search/cs?searchtype=author&query=zubelli%2C+J">Jorge zubelli</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Numerical Mathematics, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">We extend the diffusion-map formalism to data sets that are induced by
asymmetric kernels. Analytical convergence results of the resulting expansion
are proved, and an algorithm is proposed to perform the dimensional reduction.
In this work we study data sets in which its geometry structure is induced by
an asymmetric kernel. We use a priori coordinate system to represent this
geometry and, thus, be able to improve the computational complexity of reducing
the dimensionality of data sets. A coordinate system connected to the tensor
product of Fourier basis is used to represent the underlying geometric
structure obtained by the diffusion-map, thus reducing the dimensionality of
the data set and making use of the speedup provided by the two-dimensional Fast
Fourier Transform algorithm (2-D FFT). We compare our results with those
obtained by other eigenvalue expansions, and verify the efficiency of the
algorithms with synthetic data, as well as with real data from applications
including climate change studies.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12254" title="Abstract">arXiv:2401.12254</a> [<a href="/pdf/2401.12254" title="Download PDF">pdf</a>, <a href="/format/2401.12254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer learning-assisted inverse modeling in nanophotonics based on  mixture density networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Liang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+P">Prashant Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ferranti%2C+F">Francesco Ferranti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optics (physics.optics)

</div>
<p class="mathjax">The simulation of nanophotonic structures relies on electromagnetic solvers,
which play a crucial role in understanding their behavior. However, these
solvers often come with a significant computational cost, making their
application in design tasks, such as optimization, impractical. To address this
challenge, machine learning techniques have been explored for accurate and
efficient modeling and design of photonic devices. Deep neural networks, in
particular, have gained considerable attention in this field. They can be used
to create both forward and inverse models. An inverse modeling approach avoids
the need for coupling a forward model with an optimizer and directly performs
the prediction of the optimal design parameters values.
<br />In this paper, we propose an inverse modeling method for nanophotonic
structures, based on a mixture density network model enhanced by transfer
learning. Mixture density networks can predict multiple possible solutions at a
time including their respective importance as Gaussian distributions. However,
multiple challenges exist for mixture density network models. An important
challenge is that an upper bound on the number of possible simultaneous
solutions needs to be specified in advance. Also, another challenge is that the
model parameters must be jointly optimized, which can result computationally
expensive. Moreover, optimizing all parameters simultaneously can be
numerically unstable and can lead to degenerate predictions. The proposed
approach allows overcoming these limitations using transfer learning-based
techniques, while preserving a high accuracy in the prediction capability of
the design solutions given an optical response as an input. A dimensionality
reduction step is also explored. Numerical results validate the proposed
method.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12255" title="Abstract">arXiv:2401.12255</a> [<a href="/pdf/2401.12255" title="Download PDF">pdf</a>, <a href="/format/2401.12255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instructional Fingerprinting of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiashu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M+D">Mingyu Derek Ma</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+P+W">Pang Wei Koh</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Muhao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The exorbitant cost of training Large language models (LLMs) from scratch
makes it essential to fingerprint the models to protect intellectual property
via ownership authentication and to ensure downstream users and developers
comply with their license terms (e.g. restricting commercial use). In this
study, we present a pilot study on LLM fingerprinting as a form of very
lightweight instruction tuning. Model publisher specifies a confidential
private key and implants it as an instruction backdoor that causes the LLM to
generate specific text when the key is present. Results on 11 popularly-used
LLMs showed that this approach is lightweight and does not affect the normal
behavior of the model. It also prevents publisher overclaim, maintains
robustness against fingerprint guessing and parameter-efficient training, and
supports multi-stage fingerprinting akin to MIT License. Code is available in
https://cnut1648.github.io/Model-Fingerprint/.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12258" title="Abstract">arXiv:2401.12258</a> [<a href="/pdf/2401.12258" title="Download PDF">pdf</a>, <a href="/format/2401.12258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Dominance Hierarchies in Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rachum%2C+R">Ram Rachum</a>, 
<a href="/search/cs?searchtype=author&query=Nakar%2C+Y">Yonatan Nakar</a>, 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+B">Bill Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=Alon%2C+N">Nitay Alon</a>, 
<a href="/search/cs?searchtype=author&query=Mirsky%2C+R">Reuth Mirsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Modern Reinforcement Learning (RL) algorithms are able to outperform humans
in a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings
present additional challenges, and successful cooperation in mixed-motive
groups of agents depends on a delicate balancing act between individual and
group objectives. Social conventions and norms, often inspired by human
institutions, are used as tools for striking this balance.
<br />In this paper, we examine a fundamental, well-studied social convention that
underlies cooperation in both animal and human societies: Dominance
hierarchies.
<br />We adapt the ethological theory of dominance hierarchies to artificial
agents, borrowing the established terminology and definitions with as few
amendments as possible. We demonstrate that populations of RL agents, operating
without explicit programming or intrinsic rewards, can invent, learn, enforce,
and transmit a dominance hierarchy to new populations. The dominance
hierarchies that emerge have a similar structure to those studied in chickens,
mice, fish, and other species.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12259" title="Abstract">arXiv:2401.12259</a> [<a href="/pdf/2401.12259" title="Download PDF">pdf</a>, <a href="/ps/2401.12259" title="Download PostScript">ps</a>, <a href="/format/2401.12259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Agreement Technologies for Coordination in Smart Cities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Billhardt%2C+H">Holger Billhardt</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+A">Alberto Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Lujak%2C+M">Marin Lujak</a>, 
<a href="/search/cs?searchtype=author&query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Sciences, Volume 8, Issue 5 (2018)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Many challenges in today's society can be tackled by distributed open
systems. This is particularly true for domains that are commonly perceived
under the umbrella of smart cities, such as intelligent transportation, smart
energy grids, or participative governance. When designing computer applications
for these domains, it is necessary to account for the fact that the elements of
such systems, often called software agents, are usually made by different
designers and act on behalf of particular stakeholders. Furthermore, it is
unknown at design time when such agents will enter or leave the system, and
what interests new agents will represent. To instil coordination in such
systems is particularly demanding, as usually only part of them can be directly
controlled at runtime. Agreement technologies refer to a sandbox of tools and
mechanisms for the development of such open multiagent systems, which are based
on the notion of agreement. In this paper, we argue that agreement technologies
are a suitable means for achieving coordination in smart city domains, and back
our claim through examples of several real-world applications.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12261" title="Abstract">arXiv:2401.12261</a> [<a href="/pdf/2401.12261" title="Download PDF">pdf</a>, <a href="/format/2401.12261" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Quality Attributes of AI Vision Models in Open  Repositories Under Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zerui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As AI models rapidly evolve, they are frequently released to open
repositories, such as HuggingFace. It is essential to perform quality assurance
validation on these models before integrating them into the production
development lifecycle. In addition to evaluating efficiency in terms of
balanced accuracy and computing costs, adversarial attacks are potential
threats to the robustness and explainability of AI models. Meanwhile, XAI
applies algorithms that approximate inputs to outputs post-hoc to identify the
contributing features. Adversarial perturbations may also degrade the utility
of XAI explanations that require further investigation. In this paper, we
present an integrated process designed for downstream evaluation tasks,
including validating AI model accuracy, evaluating robustness with benchmark
perturbations, comparing explanation utility, and assessing overhead. We
demonstrate an evaluation scenario involving six computer vision models, which
include CNN-based, Transformer-based, and hybrid architectures, three types of
perturbations, and five XAI methods, resulting in ninety unique combinations.
The process reveals the explanation utility among the XAI methods in terms of
the identified key areas responding to the adversarial perturbation. The
process produces aggregated results that illustrate multiple attributes of each
AI model.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12262" title="Abstract">arXiv:2401.12262</a> [<a href="/pdf/2401.12262" title="Download PDF">pdf</a>, <a href="/format/2401.12262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine learning-based network intrusion detection for big and  imbalanced data using oversampling, stacking feature embedding and feature  extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talukder%2C+M+A">Md. Alamin Talukder</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md. Manowarul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Uddin%2C+M+A">Md Ashraf Uddin</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+K+F">Khondokar Fida Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Sharmin%2C+S">Selina Sharmin</a>, 
<a href="/search/cs?searchtype=author&query=Alyami%2C+S+A">Salem A. Alyami</a>, 
<a href="/search/cs?searchtype=author&query=Moni%2C+M+A">Mohammad Ali Moni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Journal of Big Data (Q1, IF: 8.1, SCIE) on Jan 19, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Cybersecurity has emerged as a critical global concern. Intrusion Detection
Systems (IDS) play a critical role in protecting interconnected networks by
detecting malicious actors and activities. Machine Learning (ML)-based behavior
analysis within the IDS has considerable potential for detecting dynamic cyber
threats, identifying abnormalities, and identifying malicious conduct within
the network. However, as the number of data grows, dimension reduction becomes
an increasingly difficult task when training ML models. Addressing this, our
paper introduces a novel ML-based network intrusion detection model that uses
Random Oversampling (RO) to address data imbalance and Stacking Feature
Embedding based on clustering results, as well as Principal Component Analysis
(PCA) for dimension reduction and is specifically designed for large and
imbalanced datasets. This model's performance is carefully evaluated using
three cutting-edge benchmark datasets: UNSW-NB15, CIC-IDS-2017, and
CIC-IDS-2018. On the UNSW-NB15 dataset, our trials show that the RF and ET
models achieve accuracy rates of 99.59% and 99.95%, respectively. Furthermore,
using the CIC-IDS2017 dataset, DT, RF, and ET models reach 99.99% accuracy,
while DT and RF models obtain 99.94% accuracy on CIC-IDS2018. These performance
results continuously outperform the state-of-art, indicating significant
progress in the field of network intrusion detection. This achievement
demonstrates the efficacy of the suggested methodology, which can be used
practically to accurately monitor and identify network traffic intrusions,
thereby blocking possible threats.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12263" title="Abstract">arXiv:2401.12263</a> [<a href="/pdf/2401.12263" title="Download PDF">pdf</a>, <a href="/ps/2401.12263" title="Download PostScript">ps</a>, <a href="/format/2401.12263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maintenance policy for a system with a weighted linear combination of  degradation processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shaomin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+I+T">Inma T. Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Probability (math.PR)

</div>
<p class="mathjax">This paper develops maintenance policies for a system under condition
monitoring. We assume that a number of defects may develop and the degradation
process of each defect follows a gamma process, respectively. The system is
inspected periodically and maintenance actions are performed on the defects
present in the system. The effectiveness of the maintenance is assumed
imperfect and it is modelled using a geometric process. By performing these
maintenance actions, different costs are incurred depending on the type and the
degradation levels of the defects. Furthermore, once a linear combination of
the degradation processes exceeds a pre-specified threshold, the system needs a
special maintenance and an extra cost is imposed. The system is renewed after
several preventive maintenance activities have been performed. The main concern
of this paper is to optimise the time between renewals and the number of
renewals. Numerical examples are given to illustrate the results derived in the
paper.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12265" title="Abstract">arXiv:2401.12265</a> [<a href="/pdf/2401.12265" title="Download PDF">pdf</a>, <a href="/ps/2401.12265" title="Download PostScript">ps</a>, <a href="/format/2401.12265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessment of the maintenance cost and analysis of availability measures  in a finite life cycle for a system subject to competing failures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caball%C3%A9%2C+N">Nuria Caball&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+I+T">Inma T. Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Probability (math.PR)

</div>
<p class="mathjax">This paper deals with the assessment of the performance of a system under a
finite planning horizon. The system is subject to two dependent causes of
failure: internal degradation and sudden shocks. We assume that internal
degradation follows a gamma process. When the deterioration level of the
degradation process exceeds a predetermined value, a degradation failure
occurs. Sudden shocks arrive at the system following a doubly stochastic
Poisson process (DSPP). A sudden shock provokes the total breakdown of the
system. A condition-based maintenance (CBM) with periodic inspection times is
developed. To evaluate the maintenance cost, recursive methods combining
numerical integration and Monte Carlo simulation are developed to evalute the
expected cost rate and its standard deviation. Also, recursive methods to
calculate some transient measures of the system are given. Numerical examples
are provided to illustrate the analytical results.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12266" title="Abstract">arXiv:2401.12266</a> [<a href="/pdf/2401.12266" title="Download PDF">pdf</a>, <a href="/ps/2401.12266" title="Download PostScript">ps</a>, <a href="/format/2401.12266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Exploratory Study of Multimodal Physiological Data in Jazz  Improvisation Using Basic Machine Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yawen Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Our study delves into the "Embodied Musicking Dataset," exploring the
intertwined relationships and correlations between physiological and
psychological dimensions during improvisational music performances. The primary
objective is to ascertain the presence of a definitive causal or correlational
relationship between these states and comprehend their manifestation in musical
compositions. This rich dataset provides a perspective on how musicians
coordinate their physicality with sonic events in real-time improvisational
scenarios, emphasizing the concept of "Embodied Musicking."
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12273" title="Abstract">arXiv:2401.12273</a> [<a href="/pdf/2401.12273" title="Download PDF">pdf</a>, <a href="/ps/2401.12273" title="Download PostScript">ps</a>, <a href="/format/2401.12273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Ethics of Interaction: Mitigating Security Threats in LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ashutosh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+S">Sagarika Singh</a>, 
<a href="/search/cs?searchtype=author&query=Murty%2C+S+V">Shiv Vignesh Murty</a>, 
<a href="/search/cs?searchtype=author&query=Ragupathy%2C+S">Swathy Ragupathy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper comprehensively explores the ethical challenges arising from
security threats to Language Learning Models (LLMs). These intricate digital
repositories are increasingly integrated into our daily lives, making them
prime targets for attacks that can compromise their training data and the
confidentiality of their data sources. The paper delves into the nuanced
ethical repercussions of such security threats on society and individual
privacy. We scrutinize five major threats: prompt injection, jailbreaking,
Personal Identifiable Information (PII) exposure, sexually explicit content,
and hate based content, going beyond mere identification to assess their
critical ethical consequences and the urgency they create for robust defensive
strategies. The escalating reliance on LLMs underscores the crucial need for
ensuring these systems operate within the bounds of ethical norms, particularly
as their misuse can lead to significant societal and individual harm. We
propose conceptualizing and developing an evaluative tool tailored for LLMs,
which would serve a dual purpose, guiding developers and designers in
preemptive fortification of backend systems and scrutinizing the ethical
dimensions of LLM chatbot responses during the testing phase. By comparing LLM
responses with those expected from humans in a moral context, we aim to discern
the degree to which AI behaviors align with the ethical values held by a
broader society. Ultimately, this paper not only underscores the ethical
troubles presented by LLMs, it also highlights a path toward cultivating trust
in these systems.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12275" title="Abstract">arXiv:2401.12275</a> [<a href="/pdf/2401.12275" title="Download PDF">pdf</a>, <a href="/format/2401.12275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+C">Chuanbo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hengbo Ma</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Dax%2C+V">Victoria Dax</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Social robot navigation can be helpful in various contexts of daily life but
requires safe human-robot interactions and efficient trajectory planning. While
modeling pairwise relations has been widely studied in multi-agent interacting
systems, the ability to capture larger-scale group-wise activities is limited.
In this paper, we propose a systematic relational reasoning approach with
explicit inference of the underlying dynamically evolving relational
structures, and we demonstrate its effectiveness for multi-agent trajectory
prediction and social robot navigation. In addition to the edges between pairs
of nodes (i.e., agents), we propose to infer hyperedges that adaptively connect
multiple nodes to enable group-wise reasoning in an unsupervised manner. Our
approach infers dynamically evolving relation graphs and hypergraphs to capture
the evolution of relations, which the trajectory predictor employs to generate
future states. Meanwhile, we propose to regularize the sharpness and sparsity
of the learned relations and the smoothness of the relation evolution, which
proves to enhance training stability and model performance. The proposed
approach is validated on synthetic crowd simulations and real-world benchmark
datasets. Experiments demonstrate that the approach infers reasonable relations
and achieves state-of-the-art prediction performance. In addition, we present a
deep reinforcement learning (DRL) framework for social robot navigation, which
incorporates relational reasoning and trajectory prediction systematically. In
a group-based crowd simulation, our method outperforms the strongest baseline
by a significant margin in terms of safety, efficiency, and social compliance
in dense, interactive scenarios.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12292" title="Abstract">arXiv:2401.12292</a> [<a href="/pdf/2401.12292" title="Download PDF">pdf</a>, <a href="/format/2401.12292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRATH: Gradual Self-Truthifying for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Truthfulness is paramount for large language models (LLMs) as they are
increasingly deployed in real-world applications. However, existing LLMs still
struggle with generating truthful answers and content, as evidenced by their
modest performance on benchmarks like TruthfulQA. To address this issue, we
propose GRAdual self-truTHifying (GRATH), a novel post-processing method to
enhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts to
generate corresponding answers and adaptively optimizes the model via direct
preference optimization (DPO). Note that during this process, GRATH learns
truthfulness in a self-supervised manner without requiring annotated answers.
In particular, GRATH first generates pairwise truthfulness training data by
prompting the LLM itself, with each pair containing a question and its correct
and incorrect answers. The model is then fine-tuned using DPO to learn from the
difference between answer pairs. Subsequently, GRATH iteratively refines the
truthfulness data and optimizes the model, leading to a gradual improvement in
model truthfulness. Empirically, we evaluate GRATH using different 7B-LLMs and
compare with LLMs with similar or even larger sizes on benchmark datasets. Our
results show that GRATH effectively improves LLMs' truthfulness without
compromising other core capabilities. Notably, GRATH achieves state-of-the-art
performance on TruthfulQA, with MC1 accuracy as 54.71% and MC2 accuracy as
69.10%, which even surpass those on larger-scale models, such as
Llama2-Chat-70B, by 23.62% and 24.18%, respectively.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12295" title="Abstract">arXiv:2401.12295</a> [<a href="/pdf/2401.12295" title="Download PDF">pdf</a>, <a href="/format/2401.12295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cheap Learning: Maximising Performance of Language Models for Social  Data Science Using Minimal Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castro-Gonzalez%2C+L">Leonardo Castro-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+Y">Yi-Ling Chung</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannak Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+J">John Francis</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+A+R">Angus R. Williams</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+P">Pica Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Bright%2C+J">Jonathan Bright</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 10 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The field of machine learning has recently made significant progress in
reducing the requirements for labelled training data when building new models.
These `cheaper' learning techniques hold significant potential for the social
sciences, where development of large labelled training datasets is often a
significant practical impediment to the use of machine learning for analytical
tasks. In this article we review three `cheap' techniques that have developed
in recent years: weak supervision, transfer learning and prompt engineering.
For the latter, we also review the particular case of zero-shot prompting of
large language models. For each technique we provide a guide of how it works
and demonstrate its application across six different realistic social science
applications (two different tasks paired with three different dataset makeups).
We show good performance for all techniques, and in particular we demonstrate
how prompting of large language models can achieve high accuracy at very low
cost. Our results are accompanied by a code repository to make it easy for
others to duplicate our work and use it in their own research. Overall, our
article is intended to stimulate further uptake of these techniques in the
social sciences.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12317" title="Abstract">arXiv:2401.12317</a> [<a href="/pdf/2401.12317" title="Download PDF">pdf</a>, <a href="/ps/2401.12317" title="Download PostScript">ps</a>, <a href="/format/2401.12317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Engineering for Robotics: Future Research Directions; Report  from the 2023 Workshop on Software Engineering for Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a> (Carnegie Mellon University), 
<a href="/search/cs?searchtype=author&query=Elbaum%2C+S">Sebastian Elbaum</a> (University of Virginia), 
<a href="/search/cs?searchtype=author&query=Anthony%2C+D">David Anthony</a> (Southwest Research Institute), 
<a href="/search/cs?searchtype=author&query=Celik%2C+Z+B">Z. Berkay Celik</a> (Purdue University), 
<a href="/search/cs?searchtype=author&query=Castillo-Effen%2C+M">Mauricio Castillo-Effen</a> (Lockheed Martin), 
<a href="/search/cs?searchtype=author&query=Correll%2C+N">Nikolaus Correll</a> (University of Colorado-Boulder), 
<a href="/search/cs?searchtype=author&query=Jamshidi%2C+P">Pooyan Jamshidi</a> (University of South Carolina), 
<a href="/search/cs?searchtype=author&query=Quigley%2C+M">Morgan Quigley</a> (Open Source Robotics Foundation), 
<a href="/search/cs?searchtype=author&query=Tabor%2C+T">Trenton Tabor</a> (Carnegie Mellon University), 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qi Zhu</a> (Northwestern University)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Robots are experiencing a revolution as they permeate many aspects of our
daily lives, from performing house maintenance to infrastructure inspection,
from efficiently warehousing goods to autonomous vehicles, and more. This
technical progress and its impact are astounding. This revolution, however, is
outstripping the capabilities of existing software development processes,
techniques, and tools, which largely have remained unchanged for decades. These
capabilities are ill-suited to handling the challenges unique to robotics
software such as dealing with a wide diversity of domains, heterogeneous
hardware, programmed and learned components, complex physical environments
captured and modeled with uncertainty, emergent behaviors that include human
interactions, and scalability demands that span across multiple dimensions.
<br />Looking ahead to the need to develop software for robots that are ever more
ubiquitous, autonomous, and reliant on complex adaptive components, hardware,
and data, motivated an NSF-sponsored community workshop on the subject of
Software Engineering for Robotics, held in Detroit, Michigan in October 2023.
The goal of the workshop was to bring together thought leaders across robotics
and software engineering to coalesce a community, and identify key problems in
the area of SE for robotics that that community should aim to solve over the
next 5 years. This report serves to summarize the motivation, activities, and
findings of that workshop, in particular by articulating the challenges unique
to robot software, and identifying a vision for fruitful near-term research
directions to tackle them.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12321" title="Abstract">arXiv:2401.12321</a> [<a href="/pdf/2401.12321" title="Download PDF">pdf</a>, <a href="/ps/2401.12321" title="Download PostScript">ps</a>, <a href="/format/2401.12321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The outcomes of generative AI are exactly the Nash equilibria of a  non-potential game
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djehiche%2C+B">Boualem Djehiche</a>, 
<a href="/search/cs?searchtype=author&query=Tembine%2C+H">Hamidou Tembine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. Accepted and to appear in: International Econometric Conference of Vietnam
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this article we show that the asymptotic outcomes of both shallow and deep
neural networks such as those used in BloombergGPT to generate economic time
series are exactly the Nash equilibria of a non-potential game. We then design
and analyze deep neural network algorithms that converge to these equilibria.
The methodology is extended to federated deep neural networks between clusters
of regional servers and on-device clients. Finally, the variational
inequalities behind large language models including encoder-decoder related
transformers are established.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12322" title="Abstract">arXiv:2401.12322</a> [<a href="/pdf/2401.12322" title="Download PDF">pdf</a>, <a href="/ps/2401.12322" title="Download PostScript">ps</a>, <a href="/format/2401.12322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Recommendations for Renting Bikes in Bike Sharing Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Billhardt%2C+H">Holger Billhardt</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+A">Alberto Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Sciences, Volume 11, Issue 20 (2021)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems
-- have become increasingly popular in big cities in recent years. On the one
hand, they provide a cheaper and environmentally friendlier means of
transportation than private cars, and on the other hand, they satisfy the
individual mobility demands of citizens better than traditional public
transport systems. One of their advantages in this regard is their
availability, e.g., the possibility of taking (or leaving) a vehicle almost
anywhere in a city. This availability obviously depends on different strategic
and operational management decisions and policies, such as the dimension of the
fleet or the (re)distribution of vehicles. Agglutination problems -- where, due
to usage patterns, available vehicles are concentrated in certain areas,
whereas no vehicles are available in others -- are quite common in such
systems, and need to be dealt with. Research has been dedicated to this
problem, specifying different techniques to reduce imbalanced situations. In
this paper, we present and compare strategies for recommending stations to
users who wish to rent or return bikes in station-based bike-sharing systems.
Our first contribution is a novel recommendation strategy based on queuing
theory that recommends stations based on their utility to the user in terms of
lower distance and higher probability of finding a bike or slot. Then, we go
one step further, defining a strategy that recommends stations by combining the
utility of a particular user with the utility of the global system, measured in
terms of the improvement in the distribution of bikes and slots with respect to
the expected future demand, with the aim of implicitly avoiding or alleviating
balancing problems. We present several experiments to evaluate our proposal
with real data from the bike sharing system BiciMAD in Madrid.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12324" title="Abstract">arXiv:2401.12324</a> [<a href="/pdf/2401.12324" title="Download PDF">pdf</a>, <a href="/ps/2401.12324" title="Download PostScript">ps</a>, <a href="/format/2401.12324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Billhardt%2C+H">Holger Billhardt</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+J">Jos&#xe9;-Antonio Santos</a>, 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+A">Alberto Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+M">Mar Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Ossowski%2C+S">Sascha Ossowski</a>, 
<a href="/search/cs?searchtype=author&query=Rodr%C3%ADguez%2C+J+A">Jos&#xe9; A. Rodr&#xed;guez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neurocomputing, Volume 438 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In recent years many novel applications have appeared that promote the
provision of services and activities in a collaborative manner. The key idea
behind such systems is to take advantage of idle or underused capacities of
existing resources, in order to provide improved services that assist people in
their daily tasks, with additional functionality, enhanced efficiency, and/or
reduced cost. Particularly in the domain of urban transportation, many
researchers have put forward novel ideas, which are then implemented and
evaluated through prototypes that usually draw upon AI methods and tools.
However, such proposals also bring up multiple non-technical issues that need
to be identified and addressed adequately if such systems are ever meant to be
applied to the real world. While, in practice, legal and ethical aspects
related to such AI-based systems are seldomly considered in the beginning of
the research and development process, we argue that they not only restrict
design decisions, but can also help guiding them. In this manuscript, we set
out from a prototype of a taxi coordination service that mediates between
individual (and autonomous) taxis and potential customers. After representing
key aspects of its operation in a semi-structured manner, we analyse its
viability from the viewpoint of current legal restrictions and constraints, so
as to identify additional non-functional requirements as well as options to
address them. Then, we go one step ahead, and actually modify the existing
prototype to incorporate the previously identified recommendations. Performing
experiments with this improved system helps us identify the most adequate
option among several legally admissible alternatives.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12326" title="Abstract">arXiv:2401.12326</a> [<a href="/pdf/2401.12326" title="Download PDF">pdf</a>, <a href="/format/2401.12326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tuning Large Language Models for Multigenerator, Multidomain, and  Multilingual Machine-Generated Text Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+F">Feng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Markchom%2C+T">Thanet Markchom</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Ziwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Subin Jung</a>, 
<a href="/search/cs?searchtype=author&query=Ojha%2C+V">Varun Ojha</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Huizhi Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">SemEval-2024 Task 8 introduces the challenge of identifying machine-generated
texts from diverse Large Language Models (LLMs) in various languages and
domains. The task comprises three subtasks: binary classification in
monolingual and multilingual (Subtask A), multi-class classification (Subtask
B), and mixed text detection (Subtask C). This paper focuses on Subtask A &amp; B.
Each subtask is supported by three datasets for training, development, and
testing. To tackle this task, two methods: 1) using traditional machine
learning (ML) with natural language preprocessing (NLP) for feature extraction,
and 2) fine-tuning LLMs for text classification. The results show that
transformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in
effectiveness, with majority voting being particularly effective in
multilingual contexts for identifying machine-generated texts.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12332" title="Abstract">arXiv:2401.12332</a> [<a href="/pdf/2401.12332" title="Download PDF">pdf</a>, <a href="/format/2401.12332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Precise Characterization of SGD Stability Using Loss Surface Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dexter%2C+G">Gregory Dexter</a>, 
<a href="/search/cs?searchtype=author&query=Ocejo%2C+B">Borja Ocejo</a>, 
<a href="/search/cs?searchtype=author&query=Keerthi%2C+S">Sathiya Keerthi</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Acharya%2C+A">Ayan Acharya</a>, 
<a href="/search/cs?searchtype=author&query=Khanna%2C+R">Rajiv Khanna</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Stochastic Gradient Descent (SGD) stands as a cornerstone optimization
algorithm with proven real-world empirical successes but relatively limited
theoretical understanding. Recent research has illuminated a key factor
contributing to its practical efficacy: the implicit regularization it
instigates. Several studies have investigated the linear stability property of
SGD in the vicinity of a stationary point as a predictive proxy for sharpness
and generalization error in overparameterized neural networks (Wu et al., 2022;
Jastrzebski et al., 2019; Cohen et al., 2021). In this paper, we delve deeper
into the relationship between linear stability and sharpness. More
specifically, we meticulously delineate the necessary and sufficient conditions
for linear stability, contingent on hyperparameters of SGD and the sharpness at
the optimum. Towards this end, we introduce a novel coherence measure of the
loss Hessian that encapsulates pertinent geometric properties of the loss
function that are relevant to the linear stability of SGD. It enables us to
provide a simplified sufficient condition for identifying linear instability at
an optimum. Notably, compared to previous works, our analysis relies on
significantly milder assumptions and is applicable for a broader class of loss
functions than known before, encompassing not only mean-squared error but also
cross-entropy loss.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12340" title="Abstract">arXiv:2401.12340</a> [<a href="/pdf/2401.12340" title="Download PDF">pdf</a>, <a href="/format/2401.12340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning and Cycle Consistency-based Transductive Transfer  Learning for Target Annotation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sami%2C+S+M">Shoaib Meraj Sami</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M+M">Md Mahedi Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Nasrabadi%2C+N+M">Nasser M. Nasrabadi</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+R">Raghuveer Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This Paper is Accepted in IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS. This Arxiv version is an older version than the reviewed version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Machine Learning (stat.ML)

</div>
<p class="mathjax">Annotating automatic target recognition (ATR) is a highly challenging task,
primarily due to the unavailability of labeled data in the target domain.
Hence, it is essential to construct an optimal target domain classifier by
utilizing the labeled information of the source domain images. The transductive
transfer learning (TTL) method that incorporates a CycleGAN-based unpaired
domain translation network has been previously proposed in the literature for
effective ATR annotation. Although this method demonstrates great potential for
ATR, it severely suffers from lower annotation performance, higher Fr\'echet
Inception Distance (FID) score, and the presence of visual artifacts in the
synthetic images. To address these issues, we propose a hybrid contrastive
learning base unpaired domain translation (H-CUT) network that achieves a
significantly lower FID score. It incorporates both attention and entropy to
emphasize the domain-specific region, a noisy feature mixup module to generate
high variational synthetic negative patches, and a modulated noise contrastive
estimation (MoNCE) loss to reweight all negative patches using optimal
transport for better performance. Our proposed contrastive learning and
cycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks
and two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and
identity losses. In C3TTL, two H-CUT networks have been employed through a
bijection mapping to feed the reconstructed source domain images into a
pretrained classifier to guide the optimal target domain classifier. Extensive
experimental analysis conducted on three ATR datasets demonstrates that the
proposed C3TTL method is effective in annotating civilian and military
vehicles, as well as ship targets.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12342" title="Abstract">arXiv:2401.12342</a> [<a href="/pdf/2401.12342" title="Download PDF">pdf</a>, <a href="/format/2401.12342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discretisations of mixed-dimensional Thermo-Hydro-Mechanical models  preserving energy estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Droniou%2C+J">Jerome Droniou</a>, 
<a href="/search/math?searchtype=author&query=Laaziri%2C+M">Mohamed Laaziri</a>, 
<a href="/search/math?searchtype=author&query=Masson%2C+R">Roland Masson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this study, we explore mixed-dimensional Thermo-Hydro-Mechanical (THM)
models in fractured porous media accounting for Coulomb frictional contact at
matrix fracture interfaces. The simulation of such models plays an important
role in many applications such as hydraulic stimulation in deep geothermal
systems and assessing induced seismic risks in CO2 storage. We first extend to
the mixed-dimensional framework the thermodynamically consistent THM models
derived in [16] based on first and second principles of thermodynamics. Two
formulations of the energy equation will be considered based either on energy
conservation or on the entropy balance, assuming a vanishing
thermo-poro-elastic dissipation. Our focus is on space time discretisations
preserving energy estimates for both types of formulations and for a general
single phase fluid thermodynamical model. This is achieved by a Finite Volume
discretisation of the non-isothermal flow based on coercive fluxes and a
tailored discretisation of the non-conservative convective terms. It is
combined with a mixed Finite Element formulation of the contact-mechanical
model with face-wise constant Lagrange multipliers accounting for the surface
tractions, which preserves the dissipative properties of the contact terms. The
discretisations of both THM formulations are investigated and compared in terms
of convergence, accuracy and robustness on 2D test cases. It includes a
Discrete Fracture Matrix model with a convection dominated thermal regime, and
either a weakly compressible liquid or a highly compressible gas
thermodynamical model.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12343" title="Abstract">arXiv:2401.12343</a> [<a href="/pdf/2401.12343" title="Download PDF">pdf</a>, <a href="/format/2401.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subgraph Extraction-based Feedback-guided Iterative Scheduling for HLS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hanchen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Leary%2C+C">Chris Leary</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaoqing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DATE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper proposes ISDC, a novel feedback-guided iterative system of
difference constraints (SDC) scheduling algorithm for high-level synthesis
(HLS). ISDC leverages subgraph extraction-based low-level feedback from
downstream tools like logic synthesizers to iteratively refine HLS scheduling.
Technical innovations include: (1) An enhanced SDC formulation that effectively
integrates low-level feedback into the linear-programming (LP) problem; (2) A
fanout and window-based subgraph extraction mechanism driving the feedback
cycle; (3) A no-human-in-loop ISDC flow compatible with a wide range of
downstream tools and process design kits (PDKs). Evaluation shows that ISDC
reduces register usage by 28.5% against an industrial-strength open-source HLS
tool.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12344" title="Abstract">arXiv:2401.12344</a> [<a href="/pdf/2401.12344" title="Download PDF">pdf</a>, <a href="/format/2401.12344" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for  Generalized and Robust Retinal Disease Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jannat%2C+F">Fatema-E Jannat</a>, 
<a href="/search/cs?searchtype=author&query=Gholami%2C+S">Sina Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+N">Minhaj Nur Alam</a>, 
<a href="/search/cs?searchtype=author&query=Tabkhi%2C+H">Hamed Tabkhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the revolutionary impact of AI and the development of locally trained
algorithms, achieving widespread generalized learning from multi-modal data in
medical AI remains a significant challenge. This gap hinders the practical
deployment of scalable medical AI solutions. Addressing this challenge, our
research contributes a self-supervised robust machine learning framework,
OCT-SelfNet, for detecting eye diseases using optical coherence tomography
(OCT) images. In this work, various data sets from various institutions are
combined enabling a more comprehensive range of representation. Our method
addresses the issue using a two-phase training approach that combines
self-supervised pretraining and supervised fine-tuning with a mask autoencoder
based on the SwinV2 backbone by providing a solution for real-world clinical
deployment. Extensive experiments on three datasets with different encoder
backbones, low data settings, unseen data settings, and the effect of
augmentation show that our method outperforms the baseline model, Resnet-50 by
consistently attaining AUC-ROC performance surpassing 77% across all tests,
whereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PR
metric, our proposed method exceeded 42%, showcasing a substantial increase of
at least 10% in performance compared to the baseline, which exceeded only 33%.
This contributes to our understanding of our approach's potential and
emphasizes its usefulness in clinical settings.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12346" title="Abstract">arXiv:2401.12346</a> [<a href="/pdf/2401.12346" title="Download PDF">pdf</a>, <a href="/format/2401.12346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fuzzy quantitative attack tree analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dang%2C+T+K+N">Thi Kim Nhung Dang</a>, 
<a href="/search/cs?searchtype=author&query=Lopuha%C3%A4-Zwakenberg%2C+M">Milan Lopuha&#xe4;-Zwakenberg</a>, 
<a href="/search/cs?searchtype=author&query=Stoelinga%2C+M">Mari&#xeb;lle Stoelinga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures, FASE2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Attack trees are important for security, as they help to identify weaknesses
and vulnerabilities in a system. Quantitative attack tree analysis supports a
number security metrics, which formulate important KPIs such as the shortest,
most likely and cheapest attacks.
<br />A key bottleneck in quantitative analysis is that the values are usually not
known exactly, due to insufficient data and/or lack of knowledge. Fuzzy logic
is a prominent framework to handle such uncertain values, with applications in
numerous domains. While several studies proposed fuzzy approaches to attack
tree analysis, none of them provided a firm definition of fuzzy metric values
or generic algorithms for computation of fuzzy metrics.
<br />In this work, we define a generic formulation for fuzzy metric values that
applies to most quantitative metrics. The resulting metric value is a fuzzy
number obtained by following Zadeh's extension principle, obtained when we
equip the basis attack steps, i.e., the leaves of the attack trees, with fuzzy
numbers. In addition, we prove a modular decomposition theorem that yields a
bottom-up algorithm to efficiently calculate the top fuzzy metric value.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12350" title="Abstract">arXiv:2401.12350</a> [<a href="/pdf/2401.12350" title="Download PDF">pdf</a>, <a href="/format/2401.12350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Up Quantization-Aware Neural Architecture Search for Efficient  Deep Learning on the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+H+R+T">Hiram Rayo Torres Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+S">Sebastian Vogel</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Waterlaat%2C+N">Nick van de Waterlaat</a>, 
<a href="/search/cs?searchtype=author&query=Jancura%2C+P">Pavol Jancura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Workshop on Compilers, Deployment, and Tooling for Edge AI (CODAI '23 ), September 21, 2023, Hamburg, Germany
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural Architecture Search (NAS) has become the de-facto approach for
designing accurate and efficient networks for edge devices. Since models are
typically quantized for edge deployment, recent work has investigated
quantization-aware NAS (QA-NAS) to search for highly accurate and efficient
quantized models. However, existing QA-NAS approaches, particularly few-bit
mixed-precision (FB-MP) methods, do not scale to larger tasks. Consequently,
QA-NAS has mostly been limited to low-scale tasks and tiny networks. In this
work, we present an approach to enable QA-NAS (INT8 and FB-MP) on large-scale
tasks by leveraging the block-wise formulation introduced by block-wise NAS. We
demonstrate strong results for the semantic segmentation task on the Cityscapes
dataset, finding FB-MP models 33% smaller and INT8 models 17.6% faster than
DeepLabV3 (INT8) without compromising task performance.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12351" title="Abstract">arXiv:2401.12351</a> [<a href="/pdf/2401.12351" title="Download PDF">pdf</a>, <a href="/format/2401.12351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of 6G Multiuser Massive MIMO-OFDM THz Wireless  Systems with Hybrid Beamforming under Intercarrier Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ullah%2C+M+S">Md Saheed Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Ashraf%2C+Z+B">Zulqarnain Bin Ashraf</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+S+C">Sudipta Chandra Sarker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">6G networks are expected to provide more diverse capabilities than their
predecessors and are likely to support applications beyond current mobile
applications, such as virtual and augmented reality (VR/AR), AI, and the
Internet of Things (IoT). In contrast to typical multiple-input multiple-output
(MIMO) systems, THz MIMO precoding cannot be conducted totally at baseband
using digital precoders due to the restricted number of signal mixers and
analog-to-digital converters that can be supported due to their cost and power
consumption. In this thesis, we analyzed the performance of multiuser massive
MIMO-OFDM THz wireless systems with hybrid beamforming. Carrier frequency
offset (CFO) is one of the most well-known disturbances for OFDM. For
practicality, we accounted for CFO, which results in Intercarrier Interference.
Incorporating the combined impact of molecular absorption, high sparsity, and
multi-path fading, we analyzed a three-dimensional wideband THz channel and the
carrier frequency offset in multi-carrier systems. With this model, we first
presented a two-stage wideband hybrid beamforming technique comprising
Riemannian manifolds optimization for analog beamforming and then a
zero-forcing (ZF) approach for digital beamforming. We adjusted the objective
function to reduce complexity, and instead of maximizing the bit rate, we
determined parameters by minimizing interference. Numerical results demonstrate
the significance of considering ICI for practical implementation for the THz
system. We demonstrated how our change in problem formulation minimizes latency
without compromising results. We also evaluated spectral efficiency by varying
the number of RF chains and antennas. The spectral efficiency grows as the
number of RF chains and antennas increases, but the spectral efficiency of
antennas declines when the number of users increases.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12356" title="Abstract">arXiv:2401.12356</a> [<a href="/pdf/2401.12356" title="Download PDF">pdf</a>, <a href="/format/2401.12356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Collaborations through Weight-Driven Coalition Dynamics in  Federated Learning Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanjri%2C+M+E">Mohammed El Hanjri</a>, 
<a href="/search/cs?searchtype=author&query=Reguieg%2C+H">Hamza Reguieg</a>, 
<a href="/search/cs?searchtype=author&query=Attiaoui%2C+A">Adil Attiaoui</a>, 
<a href="/search/cs?searchtype=author&query=Abouaomar%2C+A">Amine Abouaomar</a>, 
<a href="/search/cs?searchtype=author&query=Kobbane%2C+A">Abdellatif Kobbane</a>, 
<a href="/search/cs?searchtype=author&query=Kamili%2C+M+E">Mohamed El Kamili</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">In the era of the Internet of Things (IoT), decentralized paradigms for
machine learning are gaining prominence. In this paper, we introduce a
federated learning model that capitalizes on the Euclidean distance between
device model weights to assess their similarity and disparity. This is
foundational for our system, directing the formation of coalitions among
devices based on the closeness of their model weights. Furthermore, the concept
of a barycenter, representing the average of model weights, helps in the
aggregation of updates from multiple devices. We evaluate our approach using
homogeneous and heterogeneous data distribution, comparing it against
traditional federated learning averaging algorithm. Numerical results
demonstrate its potential in offering structured, outperformed and
communication-efficient model for IoT-based machine learning.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12358" title="Abstract">arXiv:2401.12358</a> [<a href="/pdf/2401.12358" title="Download PDF">pdf</a>, <a href="/format/2401.12358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Security Risk Assessment Method for Distributed Ledger Technology  (DLT) based Applications: Three Industry Case Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baninemeh%2C+E">Elena Baninemeh</a>, 
<a href="/search/cs?searchtype=author&query=Jansen%2C+S">Slinger Jansen</a>, 
<a href="/search/cs?searchtype=author&query=Labunets%2C+K">Katsiaryna Labunets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Distributed ledger technologies have gained significant attention and
adoption in recent years. Despite various security features distributed ledger
technology provides, they are vulnerable to different and new malicious
attacks, such as selfish mining and Sybil attacks. While such vulnerabilities
have been investigated, detecting and discovering appropriate countermeasures
still need to be reported. Cybersecurity knowledge is limited and fragmented in
this domain, while distributed ledger technology usage grows daily. Thus,
research focusing on overcoming potential attacks on distributed ledgers is
required. This study aims to raise awareness of the cybersecurity of
distributed ledger technology by designing a security risk assessment method
for distributed ledger technology applications. We have developed a database
with possible security threats and known attacks on distributed ledger
technologies to accompany the method, including sets of countermeasures. We
employed a semi-systematic literature review combined with method engineering
to develop a method that organizations can use to assess their cybersecurity
risk for distributed ledger applications. The method has subsequently been
evaluated in three case studies, which show that the method helps to
effectively conduct security risk assessments for distributed ledger
applications in these organizations.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12364" title="Abstract">arXiv:2401.12364</a> [<a href="/pdf/2401.12364" title="Download PDF">pdf</a>, <a href="/format/2401.12364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding the Search Towards Failure-Inducing Test Inputs Using Support  Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sorokin%2C+L">Lev Sorokin</a>, 
<a href="/search/cs?searchtype=author&query=Kerscher%2C+N">Niklas Kerscher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for DeepTest Workshop at ICSE '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In this paper, we present NSGA-II-SVM (Non-dominated Sorting Genetic
Algorithm with Support Vector Machine Guidance), a novel learnable evolutionary
and search-based testing algorithm that leverages Support Vector Machine (SVM)
classification models to direct the search towards failure-revealing test
inputs. Supported by genetic search, NSGA-II-SVM creates iteratively SVM-based
models of the test input space, learning which regions in the search space are
promising to be explored. A subsequent sampling and repetition of evolutionary
search iterations allow to refine and make the model more accurate in the
prediction. Our preliminary evaluation of NSGA-II-SVM by testing an Automated
Valet Parking system shows that NSGA-II-SVM is more effective in identifying
more critical test cases than a state of the art learnable evolutionary testing
technique as well as naive random search.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12369" title="Abstract">arXiv:2401.12369</a> [<a href="/pdf/2401.12369" title="Download PDF">pdf</a>, <a href="/format/2401.12369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SubgroupTE: Advancing Treatment Effect Estimation with Subgroup  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungyeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruoqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wenyu Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Precise estimation of treatment effects is crucial for evaluating
intervention effectiveness. While deep learning models have exhibited promising
performance in learning counterfactual representations for treatment effect
estimation (TEE), a major limitation in most of these models is that they treat
the entire population as a homogeneous group, overlooking the diversity of
treatment effects across potential subgroups that have varying treatment
effects. This limitation restricts the ability to precisely estimate treatment
effects and provide subgroup-specific treatment recommendations. In this paper,
we propose a novel treatment effect estimation model, named SubgroupTE, which
incorporates subgroup identification in TEE. SubgroupTE identifies
heterogeneous subgroups with different treatment responses and more precisely
estimates treatment effects by considering subgroup-specific causal effects. In
addition, SubgroupTE iteratively optimizes subgrouping and treatment effect
estimation networks to enhance both estimation and subgroup identification.
Comprehensive experiments on the synthetic and semi-synthetic datasets exhibit
the outstanding performance of SubgroupTE compared with the state-of-the-art
models on treatment effect estimation. Additionally, a real-world study
demonstrates the capabilities of SubgroupTE in enhancing personalized treatment
recommendations for patients with opioid use disorder (OUD) by advancing
treatment effect estimation with subgroup identification.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12375" title="Abstract">arXiv:2401.12375</a> [<a href="/pdf/2401.12375" title="Download PDF">pdf</a>, <a href="/ps/2401.12375" title="Download PostScript">ps</a>, <a href="/format/2401.12375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of an NLP-driven computer-based test guide for visually  impaired students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nemieboka%2C+T+F">Tubo Faustinah Nemieboka</a>, 
<a href="/search/cs?searchtype=author&query=Onyenwe%2C+I+E">Ikechukwu E. Onyenwe</a>, 
<a href="/search/cs?searchtype=author&query=Asogwa%2C+D+C">Doris C. Asogwa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Advanced Research in Computer and
  Communication Engineering (IJARCCE) Vol. 12, Issue 9, September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, advancements in Natural Language Processing (NLP) techniques
have revolutionized the field of accessibility and exclusivity of testing,
particularly for visually impaired students (VIS). CBT has shown in years back
its relevance in terms of administering exams electronically, making the test
process easier, providing quicker and more accurate results, and offering
greater flexibility and accessibility for candidates. Yet, its relevance was
not felt by the visually impaired students as they cannot access printed
documents. Hence, in this paper, we present an NLP-driven Computer-Based Test
guide for visually impaired students. It employs a speech technology
pre-trained methods to provide real-time assistance and support to visually
impaired students. The system utilizes NLP technologies to convert the
text-based questions and the associated options in a machine-readable format.
Subsequently, the speech technology pre-trained model processes the converted
text enabling the VIS to comprehend and analyze the content. Furthermore, we
validated that this pre-trained model is not perverse by testing for accuracy
using sample audio datasets labels (A, B, C, D, E, F, G) to compare with the
voice recordings obtained from 20 VIS which is been predicted by the system to
attain values for precision, recall, and F1-scores. These metrics are used to
assess the performance of the pre-trained model and have indicated that it is
proficient enough to give its better performance to the evaluated system. The
methodology adopted for this system is Object Oriented Analysis and Design
Methodology (OOADM) where Objects are discussed and built by modeling
real-world instances.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12377" title="Abstract">arXiv:2401.12377</a> [<a href="/pdf/2401.12377" title="Download PDF">pdf</a>, <a href="/format/2401.12377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ACS: Concurrent Kernel Execution on Irregular, Input-Dependent  Computational Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durvasula%2C+S">Sankeerth Durvasula</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Adrian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kiguru%2C+R">Raymond Kiguru</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yushi Guan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhonghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+N">Nandita Vijaykumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">GPUs are widely used to accelerate many important classes of workloads today.
However, we observe that several important emerging classes of workloads,
including simulation engines for deep reinforcement learning and dynamic neural
networks, are unable to fully utilize the massive parallelism that GPUs offer.
These applications tend to have kernels that are small in size, i.e., have few
thread blocks that do not saturate compute resources. Executing independent
kernels concurrently is a promising approach to improve parallelism and
utilization. However, this inter-kernel concurrency is difficult to leverage in
such workloads with existing approaches: First, the inter-kernel dependencies
and computational graph are input-dependent and vary each time the application
is executed. Second, the computational graphs tend to be irregular, requiring
fine-grain scheduling and synchronization; thus incurring significant
synchronization overheads if kernel execution is parallelized. In this work, we
propose ACS, a framework that enables lightweight detection of inter-kernel
dependencies and low overhead kernel scheduling at runtime. The key idea behind
ACS is to perform inter-kernel dependency checks for a small window of kernels
at runtime, similar to out-of order instruction scheduling. This enables
concurrent execution of kernels in applications whose computational graphs are
input dependent and require fine-grained scheduling. We propose ACS-SW, a
software-only open-source implementation of ACS and ACS-HW, a hardware-software
cooperative implementation. ACS-HW further reduces synchronization overheads by
reducing communication between the CPU and GPU. We evaluate ACS for deep RL
simulation and dynamic DNNs on both real hardware and a GPU simulator. We
demonstrate speedups of up to 2.19x (1.56x on average) by improving GPU
utilization with concurrent kernel execution.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12379" title="Abstract">arXiv:2401.12379</a> [<a href="/pdf/2401.12379" title="Download PDF">pdf</a>, <a href="/format/2401.12379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing the Effectiveness of Large Language Models on Text-to-SQL  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roberson%2C+R">Richard Roberson</a>, 
<a href="/search/cs?searchtype=author&query=Kaki%2C+G">Gowtham Kaki</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+A">Ashutosh Trivedi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Databases (cs.DB); Programming Languages (cs.PL)

</div>
<p class="mathjax">This study investigates various approaches to using Large Language Models
(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights
derived. Employing the popular Text-to-SQL dataset, spider, the goal was to
input a natural language question along with the database schema and output the
correct SQL SELECT query. The initial approach was to fine-tune a local and
open-source model to generate the SELECT query. After QLoRa fine-tuning
WizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy
for generated queries rose to a high of 61%. With the second approach, using
the fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error
correction), the execution accuracy reached a high of 82.1%. Of all the
incorrect queries, most can be categorized into a seven different categories of
what went wrong: selecting the wrong columns or wrong order of columns,
grouping by the wrong column, predicting the wrong values in conditionals,
using different aggregates than the ground truth, extra or too few JOIN
clauses, inconsistencies in the Spider dataset, and lastly completely incorrect
query structure. Most if not all of the queries fall into these categories and
it is insightful to understanding where the faults still lie with LLM program
synthesis and where they can be improved.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12380" title="Abstract">arXiv:2401.12380</a> [<a href="/pdf/2401.12380" title="Download PDF">pdf</a>, <a href="/format/2401.12380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A System for Human-Robot Teaming through End-User Programming and Shared  Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hagenow%2C+M">Michael Hagenow</a>, 
<a href="/search/cs?searchtype=author&query=Senft%2C+E">Emmanuel Senft</a>, 
<a href="/search/cs?searchtype=author&query=Radwin%2C+R">Robert Radwin</a>, 
<a href="/search/cs?searchtype=author&query=Gleicher%2C+M">Michael Gleicher</a>, 
<a href="/search/cs?searchtype=author&query=Zinn%2C+M">Michael Zinn</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24), March 11 - 14, 2024, Boulder, CO, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Many industrial tasks-such as sanding, installing fasteners, and wire
harnessing-are difficult to automate due to task complexity and variability. We
instead investigate deploying robots in an assistive role for these tasks,
where the robot assumes the physical task burden and the skilled worker
provides both the high-level task planning and low-level feedback necessary to
effectively complete the task. In this article, we describe the development of
a system for flexible human-robot teaming that combines state-of-the-art
methods in end-user programming and shared autonomy and its implementation in
sanding applications. We demonstrate the use of the system in two types of
sanding tasks, situated in aircraft manufacturing, that highlight two potential
workflows within the human-robot teaming setup. We conclude by discussing
challenges and opportunities in human-robot teaming identified during the
development, application, and demonstration of our system.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12382" title="Abstract">arXiv:2401.12382</a> [<a href="/pdf/2401.12382" title="Download PDF">pdf</a>, <a href="/ps/2401.12382" title="Download PostScript">ps</a>, <a href="/format/2401.12382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Longitudinal Sentiment Classification of Reddit Posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nwaoha%2C+F">Fabian Nwaoha</a>, 
<a href="/search/cs?searchtype=author&query=Gaffar%2C+Z">Ziyad Gaffar</a>, 
<a href="/search/cs?searchtype=author&query=Chun%2C+H+J">Ho Joon Chun</a>, 
<a href="/search/cs?searchtype=author&query=Sokolova%2C+M">Marina Sokolova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 10 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">We report results of a longitudinal sentiment classification of Reddit posts
written by students of four major Canadian universities. We work with the texts
of the posts, concentrating on the years 2020-2023. By finely tuning a
sentiment threshold to a range of [-0.075,0.075], we successfully built
classifiers proficient in categorizing post sentiments into positive and
negative categories. Noticeably, our sentiment classification results are
consistent across the four university data sets.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12383" title="Abstract">arXiv:2401.12383</a> [<a href="/pdf/2401.12383" title="Download PDF">pdf</a>, <a href="/format/2401.12383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Class of Algorithms for Finding Short Vectors in Lattices Lifted  from Co-dimension $k$ Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+R">Robert Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shor%2C+P+W">Peter W. Shor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">We introduce a new class of algorithms for finding a short vector in lattices
defined by codes of co-dimension $k$ over $\mathbb{Z}_P^d$, where $P$ is prime.
The co-dimension $1$ case is solved by exploiting the packing properties of the
projections mod $P$ of an initial set of non-lattice vectors onto a single dual
codeword. The technical tools we introduce are sorting of the projections
followed by single-step pairwise Euclidean reduction of the projections,
resulting in monotonic convergence of the positive-valued projections to zero.
The length of vectors grows by a geometric factor each iteration. For fixed $P$
and $d$, and large enough user-defined input sets, we show that it is possible
to minimize the number of iterations, and thus the overall length expansion
factor, to obtain a short lattice vector. Thus we obtain a novel approach for
controlling the output length, which resolves an open problem posed by Noah
Stephens-Davidowitz (the possibility of an approximation scheme for the
shortest-vector problem (SVP) which does not reduce to near-exact SVP). In our
approach, one may obtain short vectors even when the lattice dimension is quite
large, e.g., 8000. For fixed $P$, the algorithm yields shorter vectors for
larger $d$. We additionally present a number of extensions and generalizations
of our fundamental co-dimension $1$ method. These include a method for
obtaining many different lattice vectors by multiplying the dual codeword by an
integer and then modding by $P$; a co-dimension $k$ generalization; a large
input set generalization; and finally, a "block" generalization, which involves
the replacement of pairwise (Euclidean) reduction by a $k$-party
(non-Euclidean) reduction. The $k$-block generalization of our algorithm
constitutes a class of polynomial-time algorithms indexed by $k\geq 2$, which
yield successively improved approximations for the short vector problem.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12385" title="Abstract">arXiv:2401.12385</a> [<a href="/pdf/2401.12385" title="Download PDF">pdf</a>, <a href="/ps/2401.12385" title="Download PostScript">ps</a>, <a href="/format/2401.12385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Basic Feasible Functionals and the Interpretation Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baillot%2C+P">Patrick Baillot</a>, 
<a href="/search/cs?searchtype=author&query=Lago%2C+U+D">Ugo Dal Lago</a>, 
<a href="/search/cs?searchtype=author&query=Kop%2C+C">Cynthia Kop</a>, 
<a href="/search/cs?searchtype=author&query=Vale%2C+D">Deivid Vale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">The class of basic feasible functionals (BFF) is the analog of FP (polynomial
time functions) for type-two functionals, that is, functionals that can take
(first-order) functions as arguments. BFF can be defined by means of oracle
Turing machines of time bounded by a second-order polynomial. On the other
hand, higher-order term rewriting provides an elegant formalism for expressing
higher-order computation. We address the problem of characterizing the class
BFF by higher-order term rewriting. Various kinds of interpretations for
first-order term rewriting have been introduced in the literature for proving
termination and characterizing (first-order) complexity classes. Here we
consider a recently introduced notion of cost-size interpretations for
higher-order term rewriting and see definitions as ways of computing
functionals. We then prove that the class of functionals represented by
higher-order terms admitting a certain kind of cost-size interpretation is
exactly BFF.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12389" title="Abstract">arXiv:2401.12389</a> [<a href="/pdf/2401.12389" title="Download PDF">pdf</a>, <a href="/format/2401.12389" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Experience-Learning Inspired Two-Step Reward Method for Efficient Legged  Locomotion Learning Towards Natural and Robust Gaits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinghui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinze Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+W">Weizhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yufei Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Multi-legged robots offer enhanced stability in complex terrains, yet
autonomously learning natural and robust motions in such environments remains
challenging. Drawing inspiration from animals' progressive learning patterns,
from simple to complex tasks, we introduce a universal two-stage learning
framework with two-step reward setting based on self-acquired experience, which
efficiently enables legged robots to incrementally learn natural and robust
movements. In the first stage, robots learn through gait-related rewards to
track velocity on flat terrain, acquiring natural, robust movements and
generating effective motion experience data. In the second stage, mirroring
animal learning from existing experiences, robots learn to navigate challenging
terrains with natural and robust movements using adversarial imitation
learning. To demonstrate our method's efficacy, we trained both quadruped
robots and a hexapod robot, and the policy were successfully transferred to a
physical quadruped robot GO1, which exhibited natural gait patterns and
remarkable robustness in various terrains.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12391" title="Abstract">arXiv:2401.12391</a> [<a href="/pdf/2401.12391" title="Download PDF">pdf</a>, <a href="/ps/2401.12391" title="Download PostScript">ps</a>, <a href="/format/2401.12391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation of Pufferfish Privacy for Gaussian Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ni Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper studies how to approximate pufferfish privacy when the adversary's
prior belief of the published data is Gaussian distributed. Using Monge's
optimal transport plan, we show that $(\epsilon, \delta)$-pufferfish privacy is
attained if the additive Laplace noise is calibrated to the differences in mean
and variance of the Gaussian distributions conditioned on every discriminative
secret pair. A typical application is the private release of the summation (or
average) query, for which sufficient conditions are derived for approximating
$\epsilon$-statistical indistinguishability in individual's sensitive data. The
result is then extended to arbitrary prior beliefs trained by Gaussian mixture
models (GMMs): calibrating Laplace noise to a convex combination of differences
in mean and variance between Gaussian components attains
$(\epsilon,\delta)$-pufferfish privacy.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12392" title="Abstract">arXiv:2401.12392</a> [<a href="/pdf/2401.12392" title="Download PDF">pdf</a>, <a href="/format/2401.12392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Roadside Perception for Autonomous Vehicles: Insights from  Field Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rusheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Depu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shengyin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tinghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Karir%2C+T">Tai Karir</a>, 
<a href="/search/cs?searchtype=author&query=Maile%2C+M">Michael Maile</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H+X">Henry X. Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 figures, 8 tables, 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Roadside perception systems are increasingly crucial in enhancing traffic
safety and facilitating cooperative driving for autonomous vehicles. Despite
rapid technological advancements, a major challenge persists for this newly
arising field: the absence of standardized evaluation methods and benchmarks
for these systems. This limitation hampers the ability to effectively assess
and compare the performance of different systems, thus constraining progress in
this vital field. This paper introduces a comprehensive evaluation methodology
specifically designed to assess the performance of roadside perception systems.
Our methodology encompasses measurement techniques, metric selection, and
experimental trial design, all grounded in real-world field testing to ensure
the practical applicability of our approach.
<br />We applied our methodology in Mcity\footnote{\url{https://mcity.umich.edu/}},
a controlled testing environment, to evaluate various off-the-shelf perception
systems. This approach allowed for an in-depth comparative analysis of their
performance in realistic scenarios, offering key insights into their respective
strengths and limitations. The findings of this study are poised to inform the
development of industry-standard benchmarks and evaluation methods, thereby
enhancing the effectiveness of roadside perception system development and
deployment for autonomous vehicles. We anticipate that this paper will
stimulate essential discourse on standardizing evaluation methods for roadside
perception systems, thus pushing the frontiers of this technology. Furthermore,
our results offer both academia and industry a comprehensive understanding of
the capabilities of contemporary infrastructure-based perception systems.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12393" title="Abstract">arXiv:2401.12393</a> [<a href="/pdf/2401.12393" title="Download PDF">pdf</a>, <a href="/format/2401.12393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Learning-based Declarative Privacy-Preserving Framework for Federated  Data Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Gautier%2C+S">Summer Gautier</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepti Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Ambrish%2C+R+H">Rajan Hari Ambrish</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yancheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lakamsani%2C+H">Harsha Lakamsani</a>, 
<a href="/search/cs?searchtype=author&query=Giriyan%2C+D">Dhanush Giriyan</a>, 
<a href="/search/cs?searchtype=author&query=Maslanka%2C+S">Saajan Maslanka</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yingzhen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jia Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">It is challenging to balance the privacy and accuracy for federated query
processing over multiple private data silos. In this work, we will demonstrate
an end-to-end workflow for automating an emerging privacy-preserving technique
that uses a deep learning model trained using the Differentially-Private
Stochastic Gradient Descent (DP-SGD) algorithm to replace portions of actual
data to answer a query. Our proposed novel declarative privacy-preserving
workflow allows users to specify "what private information to protect" rather
than "how to protect". Under the hood, the system automatically chooses
query-model transformation plans as well as hyper-parameters. At the same time,
the proposed workflow also allows human experts to review and tune the selected
privacy-preserving mechanism for audit/compliance, and optimization purposes.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12405" title="Abstract">arXiv:2401.12405</a> [<a href="/pdf/2401.12405" title="Download PDF">pdf</a>, <a href="/format/2401.12405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Recovery Strategies for Dynamic Self-healing in Reactive  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sanabria%2C+M">Mateo Sanabria</a>, 
<a href="/search/cs?searchtype=author&query=Dusparic%2C+I">Ivana Dusparic</a>, 
<a href="/search/cs?searchtype=author&query=Cardozo%2C+N">Nicolas Cardozo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint accepted to 19th International Conference on Software Engineering for Adaptive and Self-Managing Systems (SEAMS24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Self-healing systems depend on following a set of predefined instructions to
recover from a known failure state. Failure states are generally detected based
on domain specific specialized metrics. Failure fixes are applied at predefined
application hooks that are not sufficiently expressive to manage different
failure types. Self-healing is usually applied in the context of distributed
systems, where the detection of failures is constrained to communication
problems, and resolution strategies often consist of replacing complete
components. Our proposal targets complex reactive systems, defining monitors as
predicates specifying satisfiability conditions of system properties. Such
monitors are functionally expressive and can be defined at run time to detect
failure states at any execution point. Once failure states are detected, we use
a Reinforcement Learning-based technique to learn a recovery strategy based on
users' corrective sequences. Finally, to execute the learned strategies, we
extract them as COP variations that activate dynamically whenever the failure
state is detected, overwriting the base system behavior with the recovery
strategy for that state. We validate the feasibility and effectiveness of our
framework through a prototypical reactive application for tracking mouse
movements, and the DeltaIoT exemplar for self-healing systems. Our results
demonstrate that with just the definition of monitors, the system is effective
in detecting and recovering from failures between 55%-92% of the cases in the
first application, and at par with the predefined strategies in the second
application.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12406" title="Abstract">arXiv:2401.12406</a> [<a href="/pdf/2401.12406" title="Download PDF">pdf</a>, <a href="/format/2401.12406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing In-context Learning via Linear Probe Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+M">Momin Abbas</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ram%2C+P">Parikshit Ram</a>, 
<a href="/search/cs?searchtype=author&query=Baracaldo%2C+N">Nathalie Baracaldo</a>, 
<a href="/search/cs?searchtype=author&query=Samulowitz%2C+H">Horst Samulowitz</a>, 
<a href="/search/cs?searchtype=author&query=Salonidis%2C+T">Theodoros Salonidis</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In-context learning (ICL) is a new paradigm for natural language processing
that utilizes Generative Pre-trained Transformer (GPT)-like models. This
approach uses prompts that include in-context demonstrations to generate the
corresponding output for a new query input. However, applying ICL in real cases
does not scale with the number of samples, and lacks robustness to different
prompt templates and demonstration permutations. In this paper, we first show
that GPT-like models using ICL result in unreliable predictions based on a new
metric based on Shannon entropy. Then, to solve this problem, we propose a new
technique called the Linear Probe Calibration (LinC), a method that calibrates
the model's output probabilities, resulting in reliable predictions and
improved performance, while requiring only minimal additional samples (as few
as five labeled data samples). LinC significantly enhances the ICL test
performance of GPT models on various benchmark datasets, with an average
improvement of up to 21%, and up to a 50% improvement in some cases, and
significantly boosts the performance of PEFT methods, especially in the low
resource regime. Moreover, LinC achieves lower expected calibration error, and
is highly robust to varying label proportions, prompt templates, and
demonstration permutations. Our code is available at
\url{https://github.com/mominabbass/LinC}.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12407" title="Abstract">arXiv:2401.12407</a> [<a href="/pdf/2401.12407" title="Download PDF">pdf</a>, <a href="/ps/2401.12407" title="Download PostScript">ps</a>, <a href="/format/2401.12407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comments on finite termination of the generalized Newton method for  absolute value equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Guo%2C+C">Chun-Hua Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the generalized Newton method (GNM) for the absolute value
equation (AVE) $Ax-|x|=b$. The method has finite termination property whenever
it is convergent, no matter whether the AVE has a unique solution. We prove
that GNM is convergent whenever $\rho(|A^{-1}|)&lt;1/3$. We also present new
results for the case where $A-I$ is a nonsingular $M$-matrix or an irreducible
singular $M$-matrix. When $A-I$ is an irreducible singular $M$-matrix, the AVE
may have infinitely many solutions. In this case, we show that GNM always
terminates with a uniquely identifiable solution, as long as the initial guess
has at least one nonpositive component.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12412" title="Abstract">arXiv:2401.12412</a> [<a href="/pdf/2401.12412" title="Download PDF">pdf</a>, <a href="/format/2401.12412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Program Decomposition and Translation with Static Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ibrahimzada%2C+A+R">Ali Reza Ibrahimzada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICSE SRC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rising popularity of Large Language Models (LLMs) has motivated exploring
their use in code-related tasks. Code LLMs with more than millions of
parameters are trained on a massive amount of code in different Programming
Languages (PLs). Such models are used for automating various Software
Engineering (SE) tasks using prompt engineering. However, given the very large
size of industry-scale project files, a major issue of these LLMs is their
limited context window size, motivating the question of "Can these LLMs process
very large files and can we effectively perform prompt engineering?". Code
translation aims to convert source code from one PL to another. In this work,
we assess the effect of method-level program decomposition on context window of
LLMs and investigate how this approach can enable translation of very large
files which originally could not be done due to out-of-context issue. Our
observations from 20 well-known java projects and approximately 60K methods
suggest that method-level program decomposition significantly improves the
limited context window problem of LLMs by 99.5%. Furthermore, our empirical
analysis indicate that with method-level decomposition, each input fragment on
average only consumes 5% of the context window, leaving more context space for
prompt engineering and the output. Finally, we investigate the effectiveness of
a Call Graph (CG) approach for translating very large files when doing
method-level program decomposition.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12413" title="Abstract">arXiv:2401.12413</a> [<a href="/pdf/2401.12413" title="Download PDF">pdf</a>, <a href="/format/2401.12413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual  Translation via Tiny Multi-Parallel Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+D">Di Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+S">Shaomu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Stap%2C+D">David Stap</a>, 
<a href="/search/cs?searchtype=author&query=Monz%2C+C">Christof Monz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Zero-shot translation is an open problem, aiming to translate between
language pairs unseen during training in Multilingual Machine Translation
(MMT). A common, albeit resource-consuming, solution is to mine as many
translation directions as possible to add to the parallel corpus. In this
paper, we show that the zero-shot capability of an English-centric model can be
easily enhanced by fine-tuning with a very small amount of multi-parallel data.
For example, on the EC30 dataset, we show that up to +21.7 ChrF non-English
overall improvements (870 directions) can be achieved by using only 100
multi-parallel samples, meanwhile preserving capability in English-centric
directions. We further study the size effect of fine-tuning data and its
transfer capabilities. Surprisingly, our empirical analysis shows that
comparable overall improvements can be achieved even through fine-tuning in a
small, randomly sampled direction set (10\%). Also, the resulting non-English
performance is quite close to the upper bound (complete translation). Due to
its high efficiency and practicality, we encourage the community 1) to consider
the use of the fine-tuning method as a strong baseline for zero-shot
translation and 2) to construct more comprehensive and high-quality
multi-parallel data to cover real-world demand.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12414" title="Abstract">arXiv:2401.12414</a> [<a href="/pdf/2401.12414" title="Download PDF">pdf</a>, <a href="/format/2401.12414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling  Autonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhaskara%2C+R">Ramchander Bhaskara</a>, 
<a href="/search/cs?searchtype=author&query=Georgakis%2C+G">Georgios Georgakis</a>, 
<a href="/search/cs?searchtype=author&query=Nash%2C+J">Jeremy Nash</a>, 
<a href="/search/cs?searchtype=author&query=Cameron%2C+M">Marissa Cameron</a>, 
<a href="/search/cs?searchtype=author&query=Bowkett%2C+J">Joseph Bowkett</a>, 
<a href="/search/cs?searchtype=author&query=Ansar%2C+A">Adnan Ansar</a>, 
<a href="/search/cs?searchtype=author&query=Majji%2C+M">Manoranjan Majji</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+P">Paul Backes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Software: <a href="https://github.com/nasa-jpl/guiss.">this https URL</a> IEEE Aerospace Conference 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">Sampling autonomy for icy moon lander missions requires understanding of
topographic and photometric properties of the sampling terrain. Unavailability
of high resolution visual datasets (either bird-eye view or point-of-view from
a lander) is an obstacle for selection, verification or development of
perception systems. We attempt to alleviate this problem by: 1) proposing
Graphical Utility for Icy moon Surface Simulations (GUISS) framework, for
versatile stereo dataset generation that spans the spectrum of bulk photometric
properties, and 2) focusing on a stereo-based visual perception system and
evaluating both traditional and deep learning-based algorithms for depth
estimation from stereo matching. The surface reflectance properties of icy moon
terrains (Enceladus and Europa) are inferred from multispectral datasets of
previous missions. With procedural terrain generation and physically valid
illumination sources, our framework can fit a wide range of hypotheses with
respect to visual representations of icy moon terrains. This is followed by a
study over the performance of stereo matching algorithms under different visual
hypotheses. Finally, we emphasize the standing challenges to be addressed for
simulating perception data assets for icy moons such as Enceladus and Europa.
Our code can be found here: https://github.com/nasa-jpl/guiss.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12415" title="Abstract">arXiv:2401.12415</a> [<a href="/pdf/2401.12415" title="Download PDF">pdf</a>, <a href="/format/2401.12415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On enforcing non-negativity in polynomial approximations in high  dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yuan Chen</a>, 
<a href="/search/math?searchtype=author&query=Xiu%2C+D">Dongbin Xiu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+X">Xiangxiong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Polynomial approximations of functions are widely used in scientific
computing. In certain applications, it is often desired to require the
polynomial approximation to be non-negative (resp. non-positive), or bounded
within a given range, due to constraints posed by the underlying physical
problems. Efficient numerical methods are thus needed to enforce such
conditions. In this paper, we discuss effective numerical algorithms for
polynomial approximation under non-negativity constraints. We first formulate
the constrained optimization problem, its primal and dual forms, and then
discuss efficient first-order convex optimization methods, with a particular
focus on high dimensional problems. Numerical examples are provided, for up to
$200$ dimensions, to demonstrate the effectiveness and scalability of the
methods.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12416" title="Abstract">arXiv:2401.12416</a> [<a href="/pdf/2401.12416" title="Download PDF">pdf</a>, <a href="/format/2401.12416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Reliability of Neural Networks at the Edge: Inverted  Normalization with Stochastic Affine Transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+T">Soyed Tuhin Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Danouchi%2C+K">Kamal Danouchi</a>, 
<a href="/search/cs?searchtype=author&query=Prenat%2C+G">Guillaume Prenat</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+L">Lorena Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B. Tahoori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Bayesian Neural Networks (BayNNs) naturally provide uncertainty in their
predictions, making them a suitable choice in safety-critical applications.
Additionally, their realization using memristor-based in-memory computing (IMC)
architectures enables them for resource-constrained edge applications. In
addition to predictive uncertainty, however, the ability to be inherently
robust to noise in computation is also essential to ensure functional safety.
In particular, memristor-based IMCs are susceptible to various sources of
non-idealities such as manufacturing and runtime variations, drift, and
failure, which can significantly reduce inference accuracy. In this paper, we
propose a method to inherently enhance the robustness and inference accuracy of
BayNNs deployed in IMC architectures. To achieve this, we introduce a novel
normalization layer combined with stochastic affine transformations. Empirical
results in various benchmark datasets show a graceful degradation in inference
accuracy, with an improvement of up to $58.11\%$.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12418" title="Abstract">arXiv:2401.12418</a> [<a href="/pdf/2401.12418" title="Download PDF">pdf</a>, <a href="/format/2401.12418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Improved Variational Inference for Deep Bayesian Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ober%2C+S+W">Sebastian W. Ober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis; University of Cambridge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep learning has revolutionized the last decade, being at the forefront of
extraordinary advances in a wide range of tasks including computer vision,
natural language processing, and reinforcement learning, to name but a few.
However, it is well-known that deep models trained via maximum likelihood
estimation tend to be overconfident and give poorly-calibrated predictions.
Bayesian deep learning attempts to address this by placing priors on the model
parameters, which are then combined with a likelihood to perform posterior
inference. Unfortunately, for deep models, the true posterior is intractable,
forcing the user to resort to approximations. In this thesis, we explore the
use of variational inference (VI) as an approximation, as it is unique in
simultaneously approximating the posterior and providing a lower bound to the
marginal likelihood. If tight enough, this lower bound can be used to optimize
hyperparameters and to facilitate model selection. However, this capacity has
rarely been used to its full extent for Bayesian neural networks, likely
because the approximate posteriors typically used in practice can lack the
flexibility to effectively bound the marginal likelihood. We therefore explore
three aspects of Bayesian learning for deep models: 1) we ask whether it is
necessary to perform inference over as many parameters as possible, or whether
it is reasonable to treat many of them as optimizable hyperparameters; 2) we
propose a variational posterior that provides a unified view of inference in
Bayesian neural networks and deep Gaussian processes; 3) we demonstrate how VI
can be improved in certain deep Gaussian process models by analytically
removing symmetries from the posterior, and performing inference on Gram
matrices instead of features. We hope that our contributions will provide a
stepping stone to fully realize the promises of VI in the future.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12419" title="Abstract">arXiv:2401.12419</a> [<a href="/pdf/2401.12419" title="Download PDF">pdf</a>, <a href="/format/2401.12419" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal News Understanding with Professionally Labelled Videos  (ReutersViLNews)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chou%2C+S">Shih-Han Chou</a>, 
<a href="/search/cs?searchtype=author&query=Kowal%2C+M">Matthew Kowal</a>, 
<a href="/search/cs?searchtype=author&query=Niknam%2C+Y">Yasmin Niknam</a>, 
<a href="/search/cs?searchtype=author&query=Moyano%2C+D">Diana Moyano</a>, 
<a href="/search/cs?searchtype=author&query=Mehdi%2C+S">Shayaan Mehdi</a>, 
<a href="/search/cs?searchtype=author&query=Pito%2C+R">Richard Pito</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Knopke%2C+I">Ian Knopke</a>, 
<a href="/search/cs?searchtype=author&query=Kocak%2C+S+A">Sedef Akinli Kocak</a>, 
<a href="/search/cs?searchtype=author&query=Sigal%2C+L">Leonid Sigal</a>, 
<a href="/search/cs?searchtype=author&query=Mohsenzadeh%2C+Y">Yalda Mohsenzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While progress has been made in the domain of video-language understanding,
current state-of-the-art algorithms are still limited in their ability to
understand videos at high levels of abstraction, such as news-oriented videos.
Alternatively, humans easily amalgamate information from video and language to
infer information beyond what is visually observable in the pixels. An example
of this is watching a news story, where the context of the event can play as
big of a role in understanding the story as the event itself. Towards a
solution for designing this ability in algorithms, we present a large-scale
analysis on an in-house dataset collected by the Reuters News Agency, called
Reuters Video-Language News (ReutersViLNews) dataset which focuses on
high-level video-language understanding with an emphasis on long-form news. The
ReutersViLNews Dataset consists of long-form news videos collected and labeled
by news industry professionals over several years and contains prominent news
reporting from around the world. Each video involves a single story and
contains action shots of the actual event, interviews with people associated
with the event, footage from nearby areas, and more. ReutersViLNews dataset
contains videos from seven subject categories: disaster, finance,
entertainment, health, politics, sports, and miscellaneous with annotations
from high-level to low-level, title caption, visual video description,
high-level story description, keywords, and location. We first present an
analysis of the dataset statistics of ReutersViLNews compared to previous
datasets. Then we benchmark state-of-the-art approaches for four different
video-language tasks. The results suggest that news-oriented videos are a
substantial challenge for current video-language understanding algorithms and
we conclude by providing future directions in designing approaches to solve the
ReutersViLNews dataset.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12421" title="Abstract">arXiv:2401.12421</a> [<a href="/pdf/2401.12421" title="Download PDF">pdf</a>, <a href="/format/2401.12421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mottaghi%2C+A">Ali Mottaghi</a>, 
<a href="/search/cs?searchtype=author&query=Jamal%2C+M+A">Mohammad Abdullah Jamal</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>, 
<a href="/search/cs?searchtype=author&query=Mohareri%2C+O">Omid Mohareri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Semi-supervised domain adaptation (SSDA) presents a critical hurdle in
computer vision, especially given the frequent scarcity of labeled data in
real-world settings. This scarcity often causes foundation models, trained on
extensive datasets, to underperform when applied to new domains. AdaEmbed, our
newly proposed methodology for SSDA, offers a promising solution to these
challenges. Leveraging the potential of unlabeled data, AdaEmbed facilitates
the transfer of knowledge from a labeled source domain to an unlabeled target
domain by learning a shared embedding space. By generating accurate and uniform
pseudo-labels based on the established embedding space, the model overcomes the
limitations of conventional SSDA, thus enhancing performance significantly. Our
method's effectiveness is validated through extensive experiments on benchmark
datasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbed
consistently outperforms all the baselines, setting a new state of the art for
SSDA. With its straightforward implementation and high data efficiency,
AdaEmbed stands out as a robust and pragmatic solution for real-world
scenarios, where labeled data is scarce. To foster further research and
application in this area, we are sharing the codebase of our unified framework
for semi-supervised domain adaptation.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12422" title="Abstract">arXiv:2401.12422</a> [<a href="/pdf/2401.12422" title="Download PDF">pdf</a>, <a href="/format/2401.12422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D  Occupancy Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ming%2C+Z">Zhenxing Ming</a>, 
<a href="/search/cs?searchtype=author&query=Berrio%2C+J+S">Julie Stephany Berrio</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+M">Mao Shan</a>, 
<a href="/search/cs?searchtype=author&query=Worrall%2C+S">Stewart Worrall</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper introduces InverseMatrixVT3D, an efficient method for transforming
multi-view image features into 3D feature volumes for 3D semantic occupancy
prediction. Existing methods for constructing 3D volumes often rely on depth
estimation, device-specific operators, or transformer queries, which hinders
the widespread adoption of 3D occupancy models. In contrast, our approach
leverages two projection matrices to store the static mapping relationships and
matrix multiplications to efficiently generate global Bird's Eye View (BEV)
features and local 3D feature volumes. Specifically, we achieve this by
performing matrix multiplications between multi-view image feature maps and two
sparse projection matrices. We introduce a sparse matrix handling technique for
the projection matrices to optimise GPU memory usage. Moreover, a global-local
attention fusion module is proposed to integrate the global BEV features with
the local 3D feature volumes to obtain the final 3D volume. We also employ a
multi-scale supervision mechanism to further enhance performance. Comprehensive
experiments on the nuScenes dataset demonstrate the simplicity and
effectiveness of our method. The code will be made available
at:https://github.com/DanielMing123/InverseMatrixVT3D
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12423" title="Abstract">arXiv:2401.12423</a> [<a href="/pdf/2401.12423" title="Download PDF">pdf</a>, <a href="/format/2401.12423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank, Pack, or Approve: Voting Methods in Participatory Budgeting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gelauff%2C+L">Lodewijk Gelauff</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashish Goel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Currently under review. Data set is available through: <a href="https://doi.org/10.25740/xd639dr9199">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Participatory budgeting is a popular method to engage residents in budgeting
decisions by local governments. The Stanford Participatory Budgeting platform
is an online platform that has been used to engage residents in more than 150
budgeting processes. We present a data set with anonymized budget opinions from
these processes with K-approval, K-ranking or knapsack primary ballots. For a
subset of the voters, it includes paired votes with a different elicitation
method in the same process. This presents a unique data set, as the voters,
projects and setting are all related to real-world decisions that the voters
have an actual interest in. With data from primary ballots we find that while
ballot complexity (number of projects to choose from, number of projects to
select and ballot length) is correlated with a higher median time spent by
voters, it is not correlated with a higher abandonment rate.
<br />We use vote pairs with different voting methods to analyze the effect of
voting methods on the cost of selected projects, more comprehensively than was
previously possible. In most elections, voters selected significantly more
expensive projects using K-approval than using knapsack, although we also find
a small number of examples with a significant effect in the opposite direction.
This effect happens at the aggregate level as well as for individual voters,
and is influenced both by the implicit constraints of the voting method and the
explicit constraints of the voting interface. Finally, we validate the use of
K-ranking elicitation to offer a paper alternative for knapsack voting.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12424" title="Abstract">arXiv:2401.12424</a> [<a href="/pdf/2401.12424" title="Download PDF">pdf</a>, <a href="/format/2401.12424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DALex: Lexicase-like Selection via Diverse Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+A">Andrew Ni</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Li Ding</a>, 
<a href="/search/cs?searchtype=author&query=Spector%2C+L">Lee Spector</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures. Submitted to EuroGP'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Lexicase selection has been shown to provide advantages over other selection
algorithms in several areas of evolutionary computation and machine learning.
In its standard form, lexicase selection filters a population or other
collection based on randomly ordered training cases that are considered one at
a time. This iterated filtering process can be time-consuming, particularly in
settings with large numbers of training cases. In this paper, we propose a new
method that is nearly equivalent to lexicase selection in terms of the
individuals that it selects, but which does so significantly more quickly. The
new method, called DALex (for Diversely Aggregated Lexicase), selects the best
individual with respect to a weighted sum of training case errors, where the
weights are randomly sampled. This allows us to formulate the core computation
required for selection as matrix multiplication instead of recursive loops of
comparisons, which in turn allows us to take advantage of optimized and
parallel algorithms designed for matrix multiplication for speedup.
Furthermore, we show that we can interpolate between the behavior of lexicase
selection and its "relaxed" variants, such as epsilon or batch lexicase
selection, by adjusting a single hyperparameter, named "particularity
pressure," which represents the importance granted to each individual training
case. Results on program synthesis, deep learning, symbolic regression, and
learning classifier systems demonstrate that DALex achieves significant
speedups over lexicase selection and its relaxed variants while maintaining
almost identical problem-solving performance. Under a fixed computational
budget, these savings free up resources that can be directed towards increasing
population size or the number of generations, enabling the potential for
solving more difficult problems.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12425" title="Abstract">arXiv:2401.12425</a> [<a href="/pdf/2401.12425" title="Download PDF">pdf</a>, <a href="/format/2401.12425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Neglected Tails of Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parashar%2C+S">Shubham Parashar</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+X">Xiangjue Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanan Li</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>, 
<a href="/search/cs?searchtype=author&query=Caverlee%2C+J">James Caverlee</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+S">Shu Kong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://shubhamprshr27.github.io/neglected-tails-of-vlms/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision-language models (VLMs) excel in zero-shot recognition but exhibit
drastically imbalanced performance across visual concepts. For example, CLIP,
despite an impressive mean zero-shot accuracy on ImageNet (72.7%), yields
$&lt;$10% on ten concepts (e.g., gyromitra and night snake), presumably, because
these concepts are under-represented in VLMs' imbalanced pretraining data. Yet,
assessing this imbalance is challenging as it is non-trivial to calculate the
frequency of specific concepts within VLMs' large-scale pretraining data. Our
work makes the first attempt to measure the concept frequency by analyzing
pretraining texts. We use off-the-shelf language models to help count relevant
texts that contain synonyms of the given concepts and resolve linguistic
ambiguity. We confirm that popular VLM datasets like LAION indeed exhibit
long-tailed concept distributions, which strongly correlate with per-class
accuracies. Further, contemporary multimodal systems, e.g., visual chatbots and
text-to-image generators, also struggle with the rare concepts identified by
our method. To mitigate VLMs' imbalanced performance in zero-shot recognition,
we propose REtrieval-Augmented Learning REAL. First, instead of prompting VLMs
using the original class names, REAL uses their most frequent synonyms found in
VLMs' pretraining texts. This already outperforms human-engineered and
LLM-generated prompts over nine benchmark datasets, likely because VLMs have
seen more images associated with the frequently used synonyms. Second, REAL
uses all the concept synonyms to retrieve a small, class-balanced set of
pretraining data to train a robust classifier. REAL surpasses the recent
retrieval-augmented solution REACT, using 400x less storage and 10,000x less
training time!
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12427" title="Abstract">arXiv:2401.12427</a> [<a href="/pdf/2401.12427" title="Download PDF">pdf</a>, <a href="/ps/2401.12427" title="Download PostScript">ps</a>, <a href="/format/2401.12427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order Conditions for Nonlinearly Partitioned Runge-Kutta Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tran%2C+B+K">Brian K. Tran</a>, 
<a href="/search/math?searchtype=author&query=Southworth%2C+B+S">Ben S. Southworth</a>, 
<a href="/search/math?searchtype=author&query=Buvoli%2C+T">Tommaso Buvoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Recently a new class of nonlinearly partitioned Runge-Kutta (NPRK) methods
was proposed for nonlinearly partitioned systems of ordinary differential
equations, $y' = F(y,y)$. The target class of problems are ones in which
different scales, stiffnesses, or physics are coupled in a nonlinear way,
wherein the desired partition cannot be written in a classical additive or
component-wise fashion. Here we use rooted-tree analysis to derive full order
conditions for NPRK$_M$ methods, where $M$ denotes the number of nonlinear
partitions. Due to the nonlinear coupling and thereby mixed product
differentials, it turns out the standard node-colored rooted-tree analysis used
in analyzing ODE integrators does not naturally apply. Instead we develop a new
edge-colored rooted-tree framework to address the nonlinear coupling. The
resulting order conditions are enumerated, provided directly for up to 4th
order with $M=2$ and 3rd-order with $M=3$, and related to existing order
conditions of additive and partitioned RK methods.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12428" title="Abstract">arXiv:2401.12428</a> [<a href="/pdf/2401.12428" title="Download PDF">pdf</a>, <a href="/format/2401.12428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+S">Songyun Qu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shixin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yintao He</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xuyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Ying Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 22 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">In recent years, various computing-in-memory (CIM) processors have been
presented, showing superior performance over traditional architectures. To
unleash the potential of various CIM architectures, such as device precision,
crossbar size, and crossbar number, it is necessary to develop compilation
tools that are fully aware of the CIM architectural details and implementation
diversity. However, due to the lack of architectural support in current popular
open-source compiling stacks, existing CIM designs either manually deploy
networks or build their own compilers, which is time-consuming and
labor-intensive. Although some works expose the specific CIM device programming
interfaces to compilers, they are often bound to a fixed CIM architecture,
lacking the flexibility to support the CIM architectures with different
computing granularity. On the other hand, existing compilation works usually
consider the scheduling of limited operation types (such as crossbar-bound
matrix-vector multiplication). Unlike conventional processors, CIM accelerators
are featured by their diverse architecture, circuit, and device, which cannot
be simply abstracted by a single level if we seek to fully explore the
advantages brought by CIM. Therefore, we propose CIM-MLC, a universal
multi-level compilation framework for general CIM architectures. We first
establish a general hardware abstraction for CIM architectures and computing
modes to represent various CIM accelerators. Based on the proposed abstraction,
CIM-MLC can compile tasks onto a wide range of CIM accelerators having
different devices, architectures, and programming interfaces. More importantly,
compared with existing compilation work, CIM-MLC can explore the mapping and
scheduling strategies across multiple architectural tiers, which form a
tractable yet effective design space, to achieve better scheduling and
instruction generation results.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12433" title="Abstract">arXiv:2401.12433</a> [<a href="/pdf/2401.12433" title="Download PDF">pdf</a>, <a href="/format/2401.12433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Garment Transfer Method Supervised by Distilled Knowledge of  Virtual Try-on Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+N">Naiyu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Lemiao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Kerui Hu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jianrong Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">When a shopper chooses garments online, garment transfer technology wears the
garment from the model image onto the shopper's image, allowing the shopper to
decide whether the garment is suitable for them. As garment transfer leverages
wild and cheap person image as garment condition, it has attracted tremendous
community attention and holds vast commercial potential. However, since the
ground truth of garment transfer is almost unavailable in reality, previous
studies have treated garment transfer as either pose transfer or garment-pose
disentanglement, and trained garment transfer in self-supervised learning, yet
do not cover garment transfer intentions completely. Therefore, the training
supervising the garment transfer is a rock-hard issue. Notably, virtual try-on
technology has exhibited superior performance using self-supervised learning.
We supervise the garment transfer training via knowledge distillation from
virtual try-on. Specifically, we first train the transfer parsing reasoning
model at multi-phases to provide shape guidance for downstream tasks. The
transfer parsing reasoning model learns the response and feature knowledge from
the try-on parsing reasoning model and absorbs the hard knowledge from the
ground truth. By leveraging the warping knowledge from virtual try-on, we
estimate a progressive flow to precisely warp the garment by learning the shape
and content correspondence. To enhance transfer realism, we propose a
well-designed arm regrowth task to infer exposed skin pixel content.
Experiments demonstrate that our method has state-of-the-art performance in
transferring garments between person compared with other virtual try-on and
garment transfer methods.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12435" title="Abstract">arXiv:2401.12435</a> [<a href="/pdf/2401.12435" title="Download PDF">pdf</a>, <a href="/ps/2401.12435" title="Download PostScript">ps</a>, <a href="/format/2401.12435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative Analysis of Molecular Transport in the Extracellular Space  Using Physics-Informed Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiayi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongfeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Q">Qingrui Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+H">Hanbo Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zu%2C+L">Lingyun Zu</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+X">Xiaobo Qu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Hongbin Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Analysis of PDEs (math.AP)

</div>
<p class="mathjax">The brain extracellular space (ECS), an irregular, extremely tortuous
nanoscale space located between cells or between cells and blood vessels, is
crucial for nerve cell survival. It plays a pivotal role in high-level brain
functions such as memory, emotion, and sensation. However, the specific form of
molecular transport within the ECS remain elusive. To address this challenge,
this paper proposes a novel approach to quantitatively analyze the molecular
transport within the ECS by solving an inverse problem derived from the
advection-diffusion equation (ADE) using a physics-informed neural network
(PINN). PINN provides a streamlined solution to the ADE without the need for
intricate mathematical formulations or grid settings. Additionally, the
optimization of PINN facilitates the automatic computation of the diffusion
coefficient governing long-term molecule transport and the velocity of
molecules driven by advection. Consequently, the proposed method allows for the
quantitative analysis and identification of the specific pattern of molecular
transport within the ECS through the calculation of the Peclet number.
Experimental validation on two datasets of magnetic resonance images (MRIs)
captured at different time points showcases the effectiveness of the proposed
method. Notably, our simulations reveal identical molecular transport patterns
between datasets representing rats with tracer injected into the same brain
region. These findings highlight the potential of PINN as a promising tool for
comprehensively exploring molecular transport within the ECS.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12436" title="Abstract">arXiv:2401.12436</a> [<a href="/pdf/2401.12436" title="Download PDF">pdf</a>, <a href="/format/2401.12436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chengyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiayin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Aimin Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differential privacy (DP) has achieved remarkable results in the field of
privacy-preserving machine learning. However, existing DP frameworks do not
satisfy all the conditions for becoming metrics, which prevents them from
deriving better basic private properties and leads to exaggerated values on
privacy budgets. We propose Wasserstein differential privacy (WDP), an
alternative DP framework to measure the risk of privacy leakage, which
satisfies the properties of symmetry and triangle inequality. We show and prove
that WDP has 13 excellent properties, which can be theoretical supports for the
better performance of WDP than other DP frameworks. In addition, we derive a
general privacy accounting method called Wasserstein accountant, which enables
WDP to be applied in stochastic gradient descent (SGD) scenarios containing
sub-sampling. Experiments on basic mechanisms, compositions and deep learning
show that the privacy budgets obtained by Wasserstein accountant are relatively
stable and less influenced by order. Moreover, the overestimation on privacy
budgets can be effectively alleviated. The code is available at
https://github.com/Hifipsysta/WDP.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12437" title="Abstract">arXiv:2401.12437</a> [<a href="/pdf/2401.12437" title="Download PDF">pdf</a>, <a href="/format/2401.12437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convex-Concave Zero-sum Markov Stackelberg Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goktas%2C+D">Denizalp Goktas</a>, 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Arjun Prakash</a>, 
<a href="/search/cs?searchtype=author&query=Greenwald%2C+A">Amy Greenwald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Zero-sum Markov Stackelberg games can be used to model myriad problems, in
domains ranging from economics to human robot interaction. In this paper, we
develop policy gradient methods that solve these games in continuous state and
action settings using noisy gradient estimates computed from observed
trajectories of play. When the games are convex-concave, we prove that our
algorithms converge to Stackelberg equilibrium in polynomial time. We also show
that reach-avoid problems are naturally modeled as convex-concave zero-sum
Markov Stackelberg games, and that Stackelberg equilibrium policies are more
effective than their Nash counterparts in these problems.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12439" title="Abstract">arXiv:2401.12439</a> [<a href="/pdf/2401.12439" title="Download PDF">pdf</a>, <a href="/format/2401.12439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAST: Video Polyp Segmentation with a Mixture-Attention Siamese  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Geng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junqing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+X">Xiaozhou Pu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+G">Ge-Peng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yongsheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hengfei Cui</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate segmentation of polyps from colonoscopy videos is of great
significance to polyp treatment and early prevention of colorectal cancer.
However, it is challenging due to the difficulties associated with modelling
long-range spatio-temporal relationships within a colonoscopy video. In this
paper, we address this challenging task with a novel Mixture-Attention Siamese
Transformer (MAST), which explicitly models the long-range spatio-temporal
relationships with a mixture-attention mechanism for accurate polyp
segmentation. Specifically, we first construct a Siamese transformer
architecture to jointly encode paired video frames for their feature
representations. We then design a mixture-attention module to exploit the
intra-frame and inter-frame correlations, enhancing the features with rich
spatio-temporal relationships. Finally, the enhanced features are fed to two
parallel decoders for predicting the segmentation maps. To the best of our
knowledge, our MAST is the first transformer model dedicated to video polyp
segmentation. Extensive experiments on the large-scale SUN-SEG benchmark
demonstrate the superior performance of MAST in comparison with the
cutting-edge competitors. Our code is publicly available at
https://github.com/Junqing-Yang/MAST.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12443" title="Abstract">arXiv:2401.12443</a> [<a href="/pdf/2401.12443" title="Download PDF">pdf</a>, <a href="/format/2401.12443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patch2QL: Discover Cognate Defects in Open Source Software Supply Chain  With Auto-generated Static Analysis Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fuwei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">In the open source software (OSS) ecosystem, there exists a complex software
supply chain, where developers upstream and downstream widely borrow and reuse
code. This results in the widespread occurrence of recurring defects, missing
fixes, and propagation issues. These are collectively referred to as cognate
defects, and their scale and threats have not received extensive attention and
systematic research. Software composition analysis and code clone detection
methods are unable to cover the various variant issues in the supply chain
scenario, while code static analysis, or static application security testing
(SAST) techniques struggle to target specific defects. In this paper, we
propose a novel technique for detecting cognate defects in OSS through the
automatic generation of SAST rules. Specifically, it extracts key syntax and
semantic information from pre- and post-patch versions of code through
structural comparison and control flow to data flow analysis, and generates
rules that matches these key elements. We have implemented a prototype tool
called Patch2QL and applied it to fundamental OSS in C/C++. In experiments, we
discovered 7 new vulnerabilities with medium to critical severity in the most
popular upstream software, as well as numerous potential security issues. When
analyzing downstream projects in the supply chain, we found a significant
number of representative cognate defects, clarifying the threat posed by this
issue. Additionally, compared to general-purpose SAST and signature-based
mechanisms, the generated rules perform better at discover all variants of
cognate defects.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12445" title="Abstract">arXiv:2401.12445</a> [<a href="/pdf/2401.12445" title="Download PDF">pdf</a>, <a href="/format/2401.12445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Session-level Normalization and Click-through Data Enhancement for  Session-based Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haonan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhicheng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+J">Jiaxin Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Since a user usually has to issue a sequence of queries and examine multiple
documents to resolve a complex information need in a search session,
researchers have paid much attention to evaluating search systems at the
session level rather than the single-query level. Most existing session-level
metrics evaluate each query separately and then aggregate the query-level
scores using a session-level weighting function. The assumptions behind these
metrics are that all queries in the session should be involved, and their
orders are fixed. However, if a search system could make the user satisfied
with her first few queries, she may not need any subsequent queries. Besides,
in most real-world search scenarios, due to a lack of explicit feedback from
real users, we can only leverage some implicit feedback, such as users' clicks,
as relevance labels for offline evaluation. Such implicit feedback might be
different from the real relevance in a search session as some documents may be
omitted in the previous query but identified in the later reformulations. To
address the above issues, we make two assumptions about session-based
evaluation, which explicitly describe an ideal session-search system and how to
enhance click-through data in computing session-level evaluation metrics. Based
on our assumptions, we design a session-level metric called Normalized
U-Measure (NUM). NUM evaluates a session as a whole and utilizes an ideal
session to normalize the result of the actual session. Besides, it infers
session-level relevance labels based on implicit feedback. Experiments on two
public datasets demonstrate the effectiveness of NUM by comparing it with
existing session-based metrics in terms of correlation with user satisfaction
and intuitiveness. We also conduct ablation studies to explore whether these
assumptions hold.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12447" title="Abstract">arXiv:2401.12447</a> [<a href="/pdf/2401.12447" title="Download PDF">pdf</a>, <a href="/format/2401.12447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NIV-SSD: Neighbor IoU-Voting Single-Stage Object Detector From Point  Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Quan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Previous single-stage detectors typically suffer the misalignment between
localization accuracy and classification confidence. To solve the misalignment
problem, we introduce a novel rectification method named neighbor IoU-voting
(NIV) strategy. Typically, classification and regression are treated as
separate branches, making it challenging to establish a connection between
them. Consequently, the classification confidence cannot accurately reflect the
regression quality. NIV strategy can serve as a bridge between classification
and regression branches by calculating two types of statistical data from the
regression output to correct the classification confidence. Furthermore, to
alleviate the imbalance of detection accuracy for complete objects with dense
points (easy objects) and incomplete objects with sparse points (difficult
objects), we propose a new data augmentation scheme named object resampling. It
undersamples easy objects and oversamples difficult objects by randomly
transforming part of easy objects into difficult objects. Finally, combining
the NIV strategy and object resampling augmentation, we design an efficient
single-stage detector termed NIV-SSD. Extensive experiments on several datasets
indicate the effectiveness of the NIV strategy and the competitive performance
of the NIV-SSD detector. The code will be available at
https://github.com/Say2L/NIV-SSD.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12451" title="Abstract">arXiv:2401.12451</a> [<a href="/pdf/2401.12451" title="Download PDF">pdf</a>, <a href="/format/2401.12451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods and strategies for improving the novel view synthesis quality of  neural radiation field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Ming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xing Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yanna Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural Radiation Field (NeRF) technology can learn a 3D implicit model of a
scene from 2D images and synthesize realistic novel view images. This
technology has received widespread attention from the industry and has good
application prospects. In response to the problem that the rendering quality of
NeRF images needs to be improved, many researchers have proposed various
methods to improve the rendering quality in the past three years. The latest
relevant papers are classified and reviewed, the technical principles behind
quality improvement are analyzed, and the future evolution direction of quality
improvement methods is discussed. This study can help researchers quickly
understand the current state and evolutionary context of technology in this
field, which is helpful in inspiring the development of more efficient
algorithms and promoting the application of NeRF technology in related fields.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12452" title="Abstract">arXiv:2401.12452</a> [<a href="/pdf/2401.12452" title="Download PDF">pdf</a>, <a href="/format/2401.12452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural  Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinjian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper introduces a novel self-supervised learning framework for
enhancing 3D perception in autonomous driving scenes. Specifically, our
approach, named NCLR, focuses on 2D-3D neural calibration, a novel pretext task
that estimates the rigid transformation aligning camera and LiDAR coordinate
systems. First, we propose the learnable transformation alignment to bridge the
domain gap between image and point cloud data, converting features into a
unified representation space for effective comparison and matching. Second, we
identify the overlapping area between the image and point cloud with the fused
features. Third, we establish dense 2D-3D correspondences to estimate the rigid
transformation. The framework not only learns fine-grained matching from points
to pixels but also achieves alignment of the image and point cloud at a
holistic level, understanding their relative pose. We demonstrate NCLR's
efficacy by applying the pre-trained backbone to downstream tasks, such as
LiDAR-based 3D semantic segmentation, object detection, and panoptic
segmentation. Comprehensive experiments on various datasets illustrate the
superiority of NCLR over existing self-supervised methods. The results confirm
that joint learning from different modalities significantly enhances the
network's understanding abilities and effectiveness of learned representation.
Code will be available at \url{https://github.com/Eaphan/NCLR}.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12453" title="Abstract">arXiv:2401.12453</a> [<a href="/pdf/2401.12453" title="Download PDF">pdf</a>, <a href="/format/2401.12453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;The teachers are confused as well&quot;: A Multiple-Stakeholder Ethics  Discussion on Large Language Models in Computing Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K+Z">Kyrie Zhixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kilhoffer%2C+Z">Zachary Kilhoffer</a>, 
<a href="/search/cs?searchtype=author&query=Sanfilippo%2C+M+R">Madelyn Rose Sanfilippo</a>, 
<a href="/search/cs?searchtype=author&query=Underwood%2C+T">Ted Underwood</a>, 
<a href="/search/cs?searchtype=author&query=Gumusel%2C+E">Ece Gumusel</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+M">Mengyi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Choudhry%2C+A">Abhinav Choudhry</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Jinjun Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Large Language Models (LLMs) are advancing quickly and impacting people's
lives for better or worse. In higher education, concerns have emerged such as
students' misuse of LLMs and degraded education outcomes. To unpack the ethical
concerns of LLMs for higher education, we conducted a case study consisting of
stakeholder interviews (n=20) in higher education computer science. We found
that students use several distinct mental models to interact with LLMs - LLMs
serve as a tool for (a) writing, (b) coding, and (c) information retrieval,
which differ somewhat in ethical considerations. Students and teachers brought
up ethical issues that directly impact them, such as inaccurate LLM responses,
hallucinations, biases, privacy leakage, and academic integrity issues.
Participants emphasized the necessity of guidance and rules for the use of LLMs
in higher education, including teaching digital literacy, rethinking education,
and having cautious and contextual policies. We reflect on the ethical
challenges and propose solutions.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12455" title="Abstract">arXiv:2401.12455</a> [<a href="/pdf/2401.12455" title="Download PDF">pdf</a>, <a href="/format/2401.12455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-agent deep reinforcement learning with centralized training and  decentralized execution for transportation infrastructure management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saifullah%2C+M">M. Saifullah</a>, 
<a href="/search/cs?searchtype=author&query=Papakonstantinou%2C+K+G">K.G. Papakonstantinou</a>, 
<a href="/search/cs?searchtype=author&query=Andriotis%2C+C+P">C.P. Andriotis</a>, 
<a href="/search/cs?searchtype=author&query=Stoffels%2C+S+M">S.M. Stoffels</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a multi-agent Deep Reinforcement Learning (DRL) framework for
managing large transportation infrastructure systems over their life-cycle.
Life-cycle management of such engineering systems is a computationally
intensive task, requiring appropriate sequential inspection and maintenance
decisions able to reduce long-term risks and costs, while dealing with
different uncertainties and constraints that lie in high-dimensional spaces. To
date, static age- or condition-based maintenance methods and risk-based or
periodic inspection plans have mostly addressed this class of optimization
problems. However, optimality, scalability, and uncertainty limitations are
often manifested under such approaches. The optimization problem in this work
is cast in the framework of constrained Partially Observable Markov Decision
Processes (POMDPs), which provides a comprehensive mathematical basis for
stochastic sequential decision settings with observation uncertainties, risk
considerations, and limited resources. To address significantly large state and
action spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL method
with Centralized Training and Decentralized Execution (CTDE), termed as
DDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method are
demonstrated in a generally representative and realistic example application of
an existing transportation network in Virginia, USA. The network includes
several bridge and pavement components with nonstationary degradation,
agency-imposed constraints, and traffic delay and risk considerations. Compared
to traditional management policies for transportation networks, the proposed
DDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposed
algorithmic framework provides near optimal solutions for transportation
infrastructure management under real-world constraints and complexities.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12456" title="Abstract">arXiv:2401.12456</a> [<a href="/pdf/2401.12456" title="Download PDF">pdf</a>, <a href="/ps/2401.12456" title="Download PostScript">ps</a>, <a href="/format/2401.12456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration and Improvement of Nerf-based 3D Scene Editing Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shun Fang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+M">Ming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xing Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">NeRF's high-quality scene synthesis capability was quickly accepted by
scholars in the years after it was proposed, and significant progress has been
made in 3D scene representation and synthesis. However, the high computational
cost limits intuitive and efficient editing of scenes, making NeRF's
development in the scene editing field facing many challenges. This paper
reviews the preliminary explorations of scholars on NeRF in the scene or object
editing field in recent years, mainly changing the shape and texture of scenes
or objects in new synthesized scenes; through the combination of residual
models such as GaN and Transformer with NeRF, the generalization ability of
NeRF scene editing has been further expanded, including realizing real-time new
perspective editing feedback, multimodal editing of text synthesized 3D scenes,
4D synthesis performance, and in-depth exploration in light and shadow editing,
initially achieving optimization of indirect touch editing and detail
representation in complex scenes. Currently, most NeRF editing methods focus on
the touch points and materials of indirect points, but when dealing with more
complex or larger 3D scenes, it is difficult to balance accuracy, breadth,
efficiency, and quality. Overcoming these challenges may become the direction
of future NeRF 3D scene editing technology.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12459" title="Abstract">arXiv:2401.12459</a> [<a href="/pdf/2401.12459" title="Download PDF">pdf</a>, <a href="/format/2401.12459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Socially and Morally Aware RL agent: Reward Design With LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaoyue Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">When we design and deploy an Reinforcement Learning (RL) agent, reward
functions motivates agents to achieve an objective. An incorrect or incomplete
specification of the objective can result in behavior that does not align with
human values - failing to adhere with social and moral norms that are ambiguous
and context dependent, and cause undesired outcomes such as negative side
effects and exploration that is unsafe. Previous work have manually defined
reward functions to avoid negative side effects, use human oversight for safe
exploration, or use foundation models as planning tools. This work studies the
ability of leveraging Large Language Models (LLM)' understanding of morality
and social norms on safe exploration augmented RL methods. This work evaluates
language model's result against human feedbacks and demonstrates language
model's capability as direct reward signals.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12461" title="Abstract">arXiv:2401.12461</a> [<a href="/pdf/2401.12461" title="Download PDF">pdf</a>, <a href="/format/2401.12461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Adversarial Training against Textual Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yichen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+K">Kun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Many adversarial defense methods have been proposed to enhance the
adversarial robustness of natural language processing models. However, most of
them introduce additional pre-set linguistic knowledge and assume that the
synonym candidates used by attackers are accessible, which is an ideal
assumption. We delve into adversarial training in the embedding space and
propose a Fast Adversarial Training (FAT) method to improve the model
robustness in the synonym-unaware scenario from the perspective of single-step
perturbation generation and perturbation initialization. Based on the
observation that the adversarial perturbations crafted by single-step and
multi-step gradient ascent are similar, FAT uses single-step gradient ascent to
craft adversarial examples in the embedding space to expedite the training
process. Based on the observation that the perturbations generated on the
identical training sample in successive epochs are similar, FAT fully utilizes
historical information when initializing the perturbation. Extensive
experiments demonstrate that FAT significantly boosts the robustness of BERT
models in the synonym-unaware scenario, and outperforms the defense baselines
under various attacks with character-level and word-level modifications.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12464" title="Abstract">arXiv:2401.12464</a> [<a href="/pdf/2401.12464" title="Download PDF">pdf</a>, <a href="/format/2401.12464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of posture and joint angle of human body using foot pressure  distribution: Morphological computation with human foot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+Y">Yo Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Nakashima%2C+Y">Yasutaka Nakashima</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">This paper proposes a novel contact and wearable sensing system for
estimating the upper body posture and joint angles (ankle, knee, and hip) of
the human body using foot pressure distribution information obtained from a
sensor attached to the plantar region. In the proposed estimation method,
sensors are installed only on the plantar region, which is the end of the human
body and the point of contact with the environment. The posture and joint
angles of other parts of the body are estimated using only this information. As
a contact and wearable sensor, the proposed system differs from previous
measurement systems in the sense that the sensor does not need to be placed
near the target joint or body. The estimation was carried out using a
multivariate linear regression model with the foot pressure distribution as the
input and the joint angle or posture as the output. The results reveal that it
is possible to estimate the posture and joint angles of the human body from
foot pressure distribution information (R2$\fallingdotseq$0.9). The proposed
estimation method was validated by morphological computation to confirm that it
is enabled by foot morphology. The validation approach compared the estimation
accuracy achieved when an object was interposed between the foot pressure
distribution sensor and the plantar region and the morphological relationship
of the plantar region to the environment varied. The results reveal that there
is a significant difference in the estimation accuracy between cases with and
without an intervening object, suggesting that the morphology of the plantar
region contributes to the estimation. Furthermore, the proposed estimation
method is considered as physical reservoir computing, wherein the human foot is
used as a computational resource.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12467" title="Abstract">arXiv:2401.12467</a> [<a href="/pdf/2401.12467" title="Download PDF">pdf</a>, <a href="/format/2401.12467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An open dataset for the evolution of oracle bone characters: EVOBC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haisu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Jinpeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaile Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Zhebin Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+L">Lianwen Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">The earliest extant Chinese characters originate from oracle bone
inscriptions, which are closely related to other East Asian languages. These
inscriptions hold immense value for anthropology and archaeology. However,
deciphering oracle bone script remains a formidable challenge, with only
approximately 1,600 of the over 4,500 extant characters elucidated to date.
Further scholarly investigation is required to comprehensively understand this
ancient writing system. Artificial Intelligence technology is a promising
avenue for deciphering oracle bone characters, particularly concerning their
evolution. However, one of the challenges is the lack of datasets mapping the
evolution of these characters over time. In this study, we systematically
collected ancient characters from authoritative texts and websites spanning six
historical stages: Oracle Bone Characters - OBC (15th century B.C.), Bronze
Inscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuries
B.C.), Spring and Autumn period Characters - SAC (770 to 476 B.C.), Warring
States period Characters - WSC (475 B.C. to 221 B.C.), and Clerical Script - CS
(221 B.C. to 220 A.D.). Subsequently, we constructed an extensive dataset,
namely EVolution Oracle Bone Characters (EVOBC), consisting of 229,170 images
representing 13,714 distinct character categories. We conducted validation and
simulated deciphering on the constructed dataset, and the results demonstrate
its high efficacy in aiding the study of oracle bone script. This openly
accessible dataset aims to digitalize ancient Chinese scripts across multiple
eras, facilitating the decipherment of oracle bone script by examining the
evolution of glyph forms.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12468" title="Abstract">arXiv:2401.12468</a> [<a href="/pdf/2401.12468" title="Download PDF">pdf</a>, <a href="/ps/2401.12468" title="Download PostScript">ps</a>, <a href="/format/2401.12468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum observability of probabilistic Boolean networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xu%2C+J">Jiayi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+S">Shihua Fu</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+L">Liyuan Xia</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jianjun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the minimum observability of probabilistic Boolean
networks (PBNs), the main objective of which is to add the fewest measurements
to make an unobservable PBN become observable. First of all, the algebraic form
of a PBN is established with the help of semi-tensor product (STP) of matrices.
By combining the algebraic forms of two identical PBNs into a parallel system,
a method to search the states that need to be H-distinguishable is proposed
based on the robust set reachability technique. Secondly, a necessary and
sufficient condition is given to find the minimum measurements such that a
given set can be H-distinguishable. Moreover, by comparing the numbers of
measurements for all the feasible H-distinguishable state sets, the least
measurements that make the system observable are gained. Finally, an example is
given to verify the validity of the obtained results.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12470" title="Abstract">arXiv:2401.12470</a> [<a href="/pdf/2401.12470" title="Download PDF">pdf</a>, <a href="/format/2401.12470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Graph Coloring: Understanding the Power and  Limits of Non-Label Invariant Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cummins%2C+C">Chase Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Veras%2C+R">Richard Veras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Register allocation is one of the most important problems for modern
compilers. With a practically unlimited number of user variables and a small
number of CPU registers, assigning variables to registers without conflicts is
a complex task. This work demonstrates the use of casting the register
allocation problem as a graph coloring problem. Using technologies such as
PyTorch and OpenAI Gymnasium Environments we will show that a Proximal Policy
Optimization model can learn to solve the graph coloring problem. We will also
show that the labeling of a graph is critical to the performance of the model
by taking the matrix representation of a graph and permuting it. We then test
the model's effectiveness on each of these permutations and show that it is not
effective when given a relabeling of the same graph. Our main contribution lies
in showing the need for label reordering invariant representations of graphs
for machine learning models to achieve consistent performance.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12471" title="Abstract">arXiv:2401.12471</a> [<a href="/pdf/2401.12471" title="Download PDF">pdf</a>, <a href="/ps/2401.12471" title="Download PostScript">ps</a>, <a href="/format/2401.12471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Shot Open-ended Video Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keat%2C+E+Y">Ee Yeo Keat</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Matyasko%2C+A">Alexander Matyasko</a>, 
<a href="/search/cs?searchtype=author&query=Fernando%2C+B">Basura Fernando</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Zero-shot open-ended inference on untrimmed videos poses a significant
challenge, especially when no annotated data is utilized to navigate the
inference direction. In this work, we aim to address this underexplored domain
by introducing an adaptable framework that efficiently combines both the frozen
vision-language (VL) model and off-the-shelf large language model (LLM) for
conducting zero-shot open-ended inference tasks without requiring any
additional training or fine-tuning. Our comprehensive experiments span various
video action datasets for goal inference and action recognition tasks. The
results demonstrate the framework's superior performance in goal inference
compared to conventional vision-language models in open-ended and close-ended
scenarios. Notably, the proposed framework exhibits the capability to
generalize effectively to action recognition tasks, underscoring its
versatility and potential contributions to advancing the video-based zero-shot
understanding.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12472" title="Abstract">arXiv:2401.12472</a> [<a href="/pdf/2401.12472" title="Download PDF">pdf</a>, <a href="/format/2401.12472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Learning in Distilled Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+V">Valerie Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+W">Kai Wen Ng</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+K">Kenneth Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Natural Language Processing models like BERT can provide state-of-the-art
word embeddings for downstream NLP tasks. However, these models yet to perform
well on Semantic Textual Similarity, and may be too large to be deployed as
lightweight edge applications. We seek to apply a suitable contrastive learning
method based on the SimCSE paper, to a model architecture adapted from a
knowledge distillation based model, DistilBERT, to address these two issues.
Our final lightweight model DistilFace achieves an average of 72.1 in
Spearman's correlation on STS tasks, a 34.2 percent improvement over BERT base.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12474" title="Abstract">arXiv:2401.12474</a> [<a href="/pdf/2401.12474" title="Download PDF">pdf</a>, <a href="/format/2401.12474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models are Superpositions of All Characters: Attaining  Arbitrary Role-play via Self-Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Keming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bowen Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Considerable efforts have been invested in augmenting the role-playing
proficiency of open-source large language models (LLMs) by emulating
proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor
role-play capabilities, owing to the extensive knowledge of characters and
potential dialogues ingrained in their vast training corpora. Thus, in this
study, we introduce Ditto, a self-alignment method for role-play. Ditto
capitalizes on character knowledge, encouraging an instruction-following LLM to
simulate role-play dialogues as a variant of reading comprehension. This method
creates a role-play training set comprising 4,000 characters, surpassing the
scale of currently available datasets by tenfold regarding the number of roles.
Subsequently, we fine-tune the LLM using this self-generated dataset to augment
its role-playing capabilities. Upon evaluating our meticulously constructed and
reproducible role-play benchmark and the roleplay subset of MT-Bench, Ditto, in
various parameter scales, consistently maintains a consistent role identity and
provides accurate role-specific knowledge in multi-turn role-play
conversations. Notably, it outperforms all open-source role-play baselines,
showcasing performance levels comparable to advanced proprietary chatbots.
Furthermore, we present the first comprehensive cross-supervision alignment
experiment in the role-play domain, revealing that the intrinsic capabilities
of LLMs confine the knowledge within role-play. Meanwhile, the role-play styles
can be easily acquired with the guidance of smaller models. We open-source
related resources at https://github.com/OFA-Sys/Ditto.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12478" title="Abstract">arXiv:2401.12478</a> [<a href="/pdf/2401.12478" title="Download PDF">pdf</a>, <a href="/format/2401.12478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mini-batch Submodular Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schwartzman%2C+G">Gregory Schwartzman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We present the first mini-batch algorithm for maximizing a non-negative
monotone decomposable submodular function, $F=\sum_{i=1}^N f^i$, under a set of
constraints. We improve over the sparsifier based approach both in theory and
in practice. We experimentally observe that our algorithm generates solutions
that are far superior to those generated by the sparsifier based approach.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12479" title="Abstract">arXiv:2401.12479</a> [<a href="/pdf/2401.12479" title="Download PDF">pdf</a>, <a href="/format/2401.12479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TD^2-Net: Toward Denoising and Debiasing for Dynamic Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zuopeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yaqi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic scene graph generation (SGG) focuses on detecting objects in a video
and determining their pairwise relationships. Existing dynamic SGG methods
usually suffer from several issues, including 1) Contextual noise, as some
frames might contain occluded and blurred objects. 2) Label bias, primarily due
to the high imbalance between a few positive relationship samples and numerous
negative ones. Additionally, the distribution of relationships exhibits a
long-tailed pattern. To address the above problems, in this paper, we introduce
a network named TD$^2$-Net that aims at denoising and debiasing for dynamic
SGG. Specifically, we first propose a denoising spatio-temporal transformer
module that enhances object representation with robust contextual information.
This is achieved by designing a differentiable Top-K object selector that
utilizes the gumbel-softmax sampling strategy to select the relevant
neighborhood for each object. Second, we introduce an asymmetrical reweighting
loss to relieve the issue of label bias. This loss function integrates
asymmetry focusing factors and the volume of samples to adjust the weights
assigned to individual samples. Systematic experimental results demonstrate the
superiority of our proposed TD$^2$-Net over existing state-of-the-art
approaches on Action Genome databases. In more detail, TD$^2$-Net outperforms
the second-best competitors by 12.7 \% on mean-Recall@10 for predicate
classification.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12480" title="Abstract">arXiv:2401.12480</a> [<a href="/pdf/2401.12480" title="Download PDF">pdf</a>, <a href="/format/2401.12480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explore Synergistic Interaction Across Frames for Interactive Video  Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Tao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Y">Yueting Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Interactive Video Object Segmentation (iVOS) is a challenging task that
requires real-time human-computer interaction. To improve the user experience,
it is important to consider the user's input habits, segmentation quality,
running time and memory consumption.However, existing methods compromise user
experience with single input mode and slow running speed. Specifically, these
methods only allow the user to interact with one single frame, which limits the
expression of the user's intent.To overcome these limitations and better align
with people's usage habits, we propose a framework that can accept multiple
frames simultaneously and explore synergistic interaction across frames (SIAF).
Concretely, we designed the Across-Frame Interaction Module that enables users
to annotate different objects freely on multiple frames. The AFI module will
migrate scribble information among multiple interactive frames and generate
multi-frame masks. Additionally, we employ the id-queried mechanism to process
multiple objects in batches. Furthermore, for a more efficient propagation and
lightweight model, we design a truncated re-propagation strategy to replace the
previous multi-round fusion module, which employs an across-round memory that
stores important interaction information. Our SwinB-SIAF achieves new
state-of-the-art performance on DAVIS 2017 (89.6%, J&amp;F@60). Moreover, our
R50-SIAF is more than 3 faster than the state-of-the-art competitor under
challenging multi-object scenarios.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12481" title="Abstract">arXiv:2401.12481</a> [<a href="/pdf/2401.12481" title="Download PDF">pdf</a>, <a href="/format/2401.12481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIRS-assisted Vehicular Networks with Rate-Splitting SWIPT Receivers:  Joint Trajectory and Communication Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nam%2C+G">Gyoungyoon Nam</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seokhyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+S">Seongah Jeong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this correspondence, we propose to use an intelligent reflective surface
(IRS) installed on unmanned aerial vehicle (UAV), referred to as aerial IRS
(AIRS), for vehicular networks, where simultaneous wireless information and
power transfer (SWIPT) receivers to concurrently allow information decoding
(ID) and energy harvesting (EH) are equipped at the battery-limited vehicles.
For efficiently supporting the multiple moving vehicles, we adopt
rate-splitting multiple access (RSMA) technique. With the aim of maximizing the
sum rate of vehicles, we jointly optimize trajectory and phase shift design of
AIRS, transmit power and rate allocation for RSMA along with power splitting
ratio for SWIPT implementation. Via simulations, the superior performances of
the proposed algorithm are validated compared to the conventional partial
optimizations.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12483" title="Abstract">arXiv:2401.12483</a> [<a href="/pdf/2401.12483" title="Download PDF">pdf</a>, <a href="/format/2401.12483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persona-centric Metamorphic Relation guided Robustness Evaluation for  Multi-turn Dialogue Modelling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanbing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Dong Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recently there has been significant progress in the field of dialogue system
thanks to the introduction of training paradigms such as fine-tune and prompt
learning. Persona can function as the prior knowledge for maintaining the
personality consistency of dialogue systems, which makes it perform well on
accuracy. Nonetheless, the conventional reference-based evaluation method falls
short in capturing the genuine text comprehension prowess of the model,
significantly relying on the quality of data annotation. In contrast, the
application of metamorphic testing offers a more profound insight into the
model's distinct capabilities without necessitating supplementary annotation
labels. This approach furnishes a more comprehensive portrayal of the model's
intricacies and exposes intricacies concealed within reference-based validation
techniques. Consequently, we introduce a persona-centric metamorphic relation
construction for metamorphic testing, aimed at evaluating both the persona
consistency and robustness of personalized dialogue models. For that reason,
this work evaluates several widely used training paradigms including learning
from scratch, pretrain + fine-tune and prompt learning in personalized dialogue
retrieval to know if they are more robust or if they have the same flaws as
their predecessor. Under three kinds of designed metamorphic relations with
consistent outputs, our experimental results reveal that prompt learning shows
stronger robustness compared to training from scratch and fine-tune. Although
tested retrieval models gain competitively high retrieval accuracy according to
the traditional reference-based validation, they are still fragile and
demonstrate various unexpected behaviors, thus there is still room for future
improvement in personalized dialogue retrieval.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12485" title="Abstract">arXiv:2401.12485</a> [<a href="/pdf/2401.12485" title="Download PDF">pdf</a>, <a href="/format/2401.12485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adiabatic Quantum Support Vector Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Date%2C+P">Prasanna Date</a>, 
<a href="/search/cs?searchtype=author&query=Woun%2C+D+J">Dong Jun Woun</a>, 
<a href="/search/cs?searchtype=author&query=Hamilton%2C+K">Kathleen Hamilton</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+E+A+C">Eduardo A. Coello Perez</a>, 
<a href="/search/cs?searchtype=author&query=Shekhar%2C+M+C">Mayanka Chandra Shekhar</a>, 
<a href="/search/cs?searchtype=author&query=Rios%2C+F">Francisco Rios</a>, 
<a href="/search/cs?searchtype=author&query=Gounley%2C+J">John Gounley</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+I">In-Saeng Suh</a>, 
<a href="/search/cs?searchtype=author&query=Humble%2C+T">Travis Humble</a>, 
<a href="/search/cs?searchtype=author&query=Tourassi%2C+G">Georgia Tourassi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Quantum Physics (quant-ph); Machine Learning (stat.ML)

</div>
<p class="mathjax">Adiabatic quantum computers can solve difficult optimization problems (e.g.,
the quadratic unconstrained binary optimization problem), and they seem well
suited to train machine learning models. In this paper, we describe an
adiabatic quantum approach for training support vector machines. We show that
the time complexity of our quantum approach is an order of magnitude better
than the classical approach. Next, we compare the test accuracy of our quantum
approach against a classical approach that uses the Scikit-learn library in
Python across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC),
Wine, Digits, and Lambeq). We show that our quantum approach obtains accuracies
on par with the classical approach. Finally, we perform a scalability study in
which we compute the total training times of the quantum approach and the
classical approach with increasing number of features and number of data points
in the training dataset. Our scalability results show that the quantum approach
obtains a 3.5--4.5 times speedup over the classical approach on datasets with
many (millions of) features.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12486" title="Abstract">arXiv:2401.12486</a> [<a href="/pdf/2401.12486" title="Download PDF">pdf</a>, <a href="/ps/2401.12486" title="Download PostScript">ps</a>, <a href="/format/2401.12486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quaternary codes and their binary images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yansheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+F">Fu Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Recently, simplicial complexes are used in constructions of several infinite
families of minimal and optimal linear codes by Hyun {\em et al.} Building upon
their research, in this paper more linear codes over the ring $\mathbb{Z}_4$
are constructed by simplicial complexes. Specifically, the Lee weight
distributions of the resulting quaternary codes are determined and two infinite
families of four-Lee-weight quaternary codes are obtained. Compared to the
databases of $\mathbb Z_4$ codes by Aydin {\em et al.}, at least nine new
quaternary codes are found. Thanks to the special structure of the defining
sets, we have the ability to determine whether the Gray images of certain
obtained quaternary codes are linear or not. This allows us to obtain two
infinite families of binary nonlinear codes and one infinite family of binary
minimal linear codes. Furthermore, utilizing these minimal binary codes, some
secret sharing schemes as a byproduct also are established.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12489" title="Abstract">arXiv:2401.12489</a> [<a href="/pdf/2401.12489" title="Download PDF">pdf</a>, <a href="/ps/2401.12489" title="Download PostScript">ps</a>, <a href="/format/2401.12489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning Method for the Wave Equation Based on Finite  Difference Residual Constraints Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xin Feng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jia-Xian Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lai-Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xiao-Gang Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Chinese language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The wave equation is an important physical partial differential equation, and
in recent years, deep learning has shown promise in accelerating or replacing
traditional numerical methods for solving it. However, existing deep learning
methods suffer from high data acquisition costs, low training efficiency, and
insufficient generalization capability for boundary conditions. To address
these issues, this paper proposes an unsupervised learning method for the wave
equation based on finite difference residual constraints. We construct a novel
finite difference residual constraint based on structured grids and finite
difference methods, as well as an unsupervised training strategy, enabling
convolutional neural networks to train without data and predict the forward
propagation process of waves. Experimental results show that finite difference
residual constraints have advantages over physics-informed neural networks
(PINNs) type physical information constraints, such as easier fitting, lower
computational costs, and stronger source term generalization capability, making
our method more efficient in training and potent in application.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12491" title="Abstract">arXiv:2401.12491</a> [<a href="/pdf/2401.12491" title="Download PDF">pdf</a>, <a href="/format/2401.12491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing and Understanding Creativity in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yunpu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+S">Shaohui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yifan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yuanbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zidong Du</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Ling Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yunji Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of natural language processing, the rapid development of large
language model (LLM) has attracted more and more attention. LLMs have shown a
high level of creativity in various tasks, but the methods for assessing such
creativity are inadequate. The assessment of LLM creativity needs to consider
differences from humans, requiring multi-dimensional measurement while
balancing accuracy and efficiency. This paper aims to establish an efficient
framework for assessing the level of creativity in LLMs. By adapting the
modified Torrance Tests of Creative Thinking, the research evaluates the
creative performance of various LLMs across 7 tasks, emphasizing 4 criteria
including Fluency, Flexibility, Originality, and Elaboration. In this context,
we develop a comprehensive dataset of 700 questions for testing and an
LLM-based evaluation method. In addition, this study presents a novel analysis
of LLMs' responses to diverse prompts and role-play situations. We found that
the creativity of LLMs primarily falls short in originality, while excelling in
elaboration. Besides, the use of prompts and the role-play settings of the
model significantly influence creativity. Additionally, the experimental
results also indicate that collaboration among multiple LLMs can enhance
originality. Notably, our findings reveal a consensus between human evaluations
and LLMs regarding the personality traits that influence creativity. The
findings underscore the significant impact of LLM design on creativity and
bridges artificial intelligence and human creativity, offering insights into
LLMs' creativity and potential applications.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12492" title="Abstract">arXiv:2401.12492</a> [<a href="/pdf/2401.12492" title="Download PDF">pdf</a>, <a href="/format/2401.12492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Human-Centered Language Modeling: Is it Better to Model  Groups, Individual Traits, or Both?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soni%2C+N">Nikita Soni</a>, 
<a href="/search/cs?searchtype=author&query=Balasubramanian%2C+N">Niranjan Balasubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+H+A">H. Andrew Schwartz</a>, 
<a href="/search/cs?searchtype=author&query=Hovy%2C+D">Dirk Hovy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Natural language processing has made progress in incorporating human context
into its models, but whether it is more effective to use group-wise attributes
(e.g., over-45-year-olds) or model individuals remains open. Group attributes
are technically easier but coarse: not all 45-year-olds write the same way. In
contrast, modeling individuals captures the complexity of each person's
identity. It allows for a more personalized representation, but we may have to
model an infinite number of users and require data that may be impossible to
get. We compare modeling human context via group attributes, individual users,
and combined approaches. Combining group and individual features significantly
benefits user-level regression tasks like age estimation or personality
assessment from a user's documents. Modeling individual users significantly
improves the performance of single document-level classification tasks like
stance and topic detection. We also find that individual-user modeling does
well even without user's historical data.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12496" title="Abstract">arXiv:2401.12496</a> [<a href="/pdf/2401.12496" title="Download PDF">pdf</a>, <a href="/format/2401.12496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DexTouch: Learning to Seek and Manipulate Objects with Tactile Dexterity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-Won Lee</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yuzhe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S">Soo-Chul Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://lee-kangwon.github.io/dextouch/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The sense of touch is an essential ability for skillfully performing a
variety of tasks, providing the capacity to search and manipulate objects
without relying on visual information. Extensive research has been conducted
over time to apply these human tactile abilities to robots. In this paper, we
introduce a multi-finger robot system designed to search for and manipulate
objects using the sense of touch without relying on visual information.
Randomly located target objects are searched using tactile sensors, and the
objects are manipulated for tasks that mimic daily-life. The objective of the
study is to endow robots with human-like tactile capabilities. To achieve this,
binary tactile sensors are implemented on one side of the robot hand to
minimize the Sim2Real gap. Training the policy through reinforcement learning
in simulation and transferring the trained policy to the real environment, we
demonstrate that object search and manipulation using tactile sensors is
possible even in an environment without vision information. In addition, an
ablation study was conducted to analyze the effect of tactile information on
manipulative tasks. Our project page is available at
https://lee-kangwon.github.io/dextouch/
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12497" title="Abstract">arXiv:2401.12497</a> [<a href="/pdf/2401.12497" title="Download PDF">pdf</a>, <a href="/format/2401.12497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Building Minimal and Reusable Causal State Abstractions for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zizhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Caroline Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Two desiderata of reinforcement learning (RL) algorithms are the ability to
learn from relatively little experience and the ability to learn policies that
generalize to a range of problem specifications. In factored state spaces, one
approach towards achieving both goals is to learn state abstractions, which
only keep the necessary variables for learning the tasks at hand. This paper
introduces Causal Bisimulation Modeling (CBM), a method that learns the causal
relationships in the dynamics and reward functions for each task to derive a
minimal, task-specific abstraction. CBM leverages and improves implicit
modeling to train a high-fidelity causal dynamics model that can be reused for
all tasks in the same environment. Empirical validation on manipulation
environments and Deepmind Control Suite reveals that CBM's learned implicit
dynamics models identify the underlying causal relationships and state
abstractions more accurately than explicit ones. Furthermore, the derived state
abstractions allow a task learner to achieve near-oracle levels of sample
efficiency and outperform baselines on all tasks.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12499" title="Abstract">arXiv:2401.12499</a> [<a href="/pdf/2401.12499" title="Download PDF">pdf</a>, <a href="/ps/2401.12499" title="Download PostScript">ps</a>, <a href="/format/2401.12499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Fundamental Tradeoff of Joint Communication and Quickest Change  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seo%2C+D">Daewon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+S+H">Sung Hoon Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this work, we take the initiative in studying the fundamental tradeoff
between communication and quickest change detection (QCD) under an integrated
sensing and communication setting. We formally establish a joint communication
and sensing problem for quickest change detection. Then, by utilizing constant
subblock-composition codes and a modified QuSum detection rule, which we call
subblock QuSum (SQS), we provide an inner bound on the fundamental tradeoff
between communication rate and change point detection delay in the asymptotic
regime of vanishing false alarm rate. We further provide a partial converse
that matches our inner bound for a certain class of codes. This implies that
the SQS detection strategy is asymptotically optimal for our codes as the false
alarm rate constraint vanishes. We also present some canonical examples of the
tradeoff region for a binary channel, a scalar Gaussian channel, and a MIMO
Gaussian channel.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12501" title="Abstract">arXiv:2401.12501</a> [<a href="/pdf/2401.12501" title="Download PDF">pdf</a>, <a href="/format/2401.12501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A parametrix method for elliptic surface PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goodwill%2C+T">Tristan Goodwill</a>, 
<a href="/search/math?searchtype=author&query=O%27Neil%2C+M">Michael O&#x27;Neil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Elliptic problems along smooth surfaces embedded in three dimensions occur in
thin-membrane mechanics, electromagnetics (harmonic vector fields), and
computational geometry. In this work, we present a parametrix-based integral
equation method applicable to several forms of variable coefficient surface
elliptic problems. Via the use of an approximate Green's function, the surface
PDEs are transformed into well-conditioned integral equations. We demonstrate
high-order numerical examples of this method applied to problems on general
surfaces using a variant of the fast multipole method based on smooth
interpolation properties of the kernel. Lastly, we discuss extensions of the
method to surfaces with boundaries.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12503" title="Abstract">arXiv:2401.12503</a> [<a href="/pdf/2401.12503" title="Download PDF">pdf</a>, <a href="/format/2401.12503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Language Model Meets with Reinforced Vision Vocabulary
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Haoran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingyu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Z">Zheng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">En Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jianjian Sun</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chunrui Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangyu Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI
community. However, the relatively large number of parameters (more than 7B) of
popular LVLMs makes it difficult to train and deploy on consumer GPUs,
discouraging many researchers with limited resources. Imagine how cool it would
be to experience all the features of current LVLMs on an old GTX1080ti (our
only game card). Accordingly, we present Vary-toy in this report, a small-size
Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we
introduce an improved vision vocabulary, allowing the model to not only possess
all features of Vary but also gather more generality. Specifically, we replace
negative samples of natural images with positive sample data driven by object
detection in the procedure of generating vision vocabulary, more sufficiently
utilizing the capacity of the vocabulary network and enabling it to efficiently
encode visual information corresponding to natural objects. For experiments,
Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1%
accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on
the homepage.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12507" title="Abstract">arXiv:2401.12507</a> [<a href="/pdf/2401.12507" title="Download PDF">pdf</a>, <a href="/format/2401.12507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Set Facial Expression Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yue Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuannan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+L">Lixiong Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weihong Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial expression recognition (FER) models are typically trained on datasets
with a fixed number of seven basic classes. However, recent research works
point out that there are far more expressions than the basic ones. Thus, when
these models are deployed in the real world, they may encounter unknown
classes, such as compound expressions that cannot be classified into existing
basic classes. To address this issue, we propose the open-set FER task for the
first time. Though there are many existing open-set recognition methods, we
argue that they do not work well for open-set FER because FER data are all
human faces with very small inter-class distances, which makes the open-set
samples very similar to close-set samples. In this paper, we are the first to
transform the disadvantage of small inter-class distance into an advantage by
proposing a new way for open-set FER. Specifically, we find that small
inter-class distance allows for sparsely distributed pseudo labels of open-set
samples, which can be viewed as symmetric noisy labels. Based on this novel
observation, we convert the open-set FER to a noisy label detection problem. We
further propose a novel method that incorporates attention map consistency and
cycle training to detect the open-set samples. Extensive experiments on various
FER datasets demonstrate that our method clearly outperforms state-of-the-art
open-set recognition methods by large margins. Code is available at
https://github.com/zyh-uaiaaaa.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12508" title="Abstract">arXiv:2401.12508</a> [<a href="/pdf/2401.12508" title="Download PDF">pdf</a>, <a href="/ps/2401.12508" title="Download PostScript">ps</a>, <a href="/format/2401.12508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Stochastic (Variance-Reduced) Proximal Gradient Method for  Regularized Expected Reward Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+L">Ling Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haizhao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider a regularized expected reward optimization problem in the
non-oblivious setting that covers many existing problems in reinforcement
learning (RL). In order to solve such an optimization problem, we apply and
analyze the classical stochastic proximal gradient method. In particular, the
method has shown to admit an $O(\epsilon^{-4})$ sample complexity to an
$\epsilon$-stationary point, under standard conditions. Since the variance of
the classical stochastic gradient estimator is typically large which slows down
the convergence, we also apply an efficient stochastic variance-reduce proximal
gradient method with an importance sampling based ProbAbilistic Gradient
Estimator (PAGE). To the best of our knowledge, the application of this method
represents a novel approach in addressing the general regularized reward
optimization problem. Our analysis shows that the sample complexity can be
improved from $O(\epsilon^{-4})$ to $O(\epsilon^{-3})$ under additional
conditions. Our results on the stochastic (variance-reduced) proximal gradient
method match the sample complexity of their most competitive counterparts under
similar settings in the RL literature.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12509" title="Abstract">arXiv:2401.12509</a> [<a href="/pdf/2401.12509" title="Download PDF">pdf</a>, <a href="/ps/2401.12509" title="Download PostScript">ps</a>, <a href="/format/2401.12509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital cloning of online social networks for language-sensitive  agent-based modeling of misinformation spread
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puri%2C+P">Prateek Puri</a>, 
<a href="/search/cs?searchtype=author&query=Hassler%2C+G">Gabriel Hassler</a>, 
<a href="/search/cs?searchtype=author&query=Shenk%2C+A">Anton Shenk</a>, 
<a href="/search/cs?searchtype=author&query=Katragadda%2C+S">Sai Katragadda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We develop a simulation framework for studying misinformation spread within
online social networks that blends agent-based modeling and natural language
processing techniques. While many other agent-based simulations exist in this
space, their ability to provide actionable insights in in part limited by their
lack of fidelity and generalizability to existing networks. To partially
address these concerns, we create a 'digital clone' of a known misinformation
sharing network by downloading social media histories for over ten thousand of
its users. We parse these histories to both extract the structure of the
network and model the nuanced ways in which information is shared and spread
among its members. Unlike many other agent-based methods in this space,
information sharing between users in our framework is sensitive to topic of
discussion, user preferences, and online community dynamics. To evaluate the
fidelity of our method, we seed our cloned network with a set of posts recorded
in the base network and compare propagation dynamics between the two, observing
reasonable agreement across the twin networks over a variety of metrics.
Lastly, we explore how the cloned network may serve as a flexible, low-cost
testbed for misinformation countermeasure evaluation and red teaming analysis.
We hope the tools explored here augment existing efforts in the space and
unlock new opportunities for misinformation countermeasure evaluation, a field
that may become increasingly important to consider with the anticipated rise of
misinformation campaigns fueled by generative artificial intelligence.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12511" title="Abstract">arXiv:2401.12511</a> [<a href="/pdf/2401.12511" title="Download PDF">pdf</a>, <a href="/format/2401.12511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Initialization for Data-Efficient Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Jianqiao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueqian Li</a>, 
<a href="/search/cs?searchtype=author&query=Lucey%2C+S">Simon Lucey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Training vision transformer networks on small datasets poses challenges. In
contrast, convolutional neural networks (CNNs) can achieve state-of-the-art
performance by leveraging their architectural inductive bias. In this paper, we
investigate whether this inductive bias can be reinterpreted as an
initialization bias within a vision transformer network. Our approach is
motivated by the finding that random impulse filters can achieve almost
comparable performance to learned filters in CNNs. We introduce a novel
initialization strategy for transformer networks that can achieve comparable
performance to CNNs on small datasets while preserving its architectural
flexibility.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12513" title="Abstract">arXiv:2401.12513</a> [<a href="/pdf/2401.12513" title="Download PDF">pdf</a>, <a href="/format/2401.12513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT  and SimCLR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turnbull%2C+R">Robert Turnbull</a>, 
<a href="/search/cs?searchtype=author&query=Mannix%2C+E">Evelyn Mannix</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The capacity to isolate and recognize individual characters from facsimile
images of papyrus manuscripts yields rich opportunities for digital analysis.
For this reason the `ICDAR 2023 Competition on Detection and Recognition of
Greek Letters on Papyri' was held as part of the 17th International Conference
on Document Analysis and Recognition. This paper discusses our submission to
the competition. We used an ensemble of YOLOv8 models to detect and classify
individual characters and employed two different approaches for refining the
character predictions, including a transformer based DeiT approach and a
ResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a
self-supervised learning method. Our submission won the recognition challenge
with a mAP of 42.2%, and was runner-up in the detection challenge with a mean
average precision (mAP) of 51.4%. At the more relaxed intersection over union
threshold of 0.5, we achieved the highest mean average precision and mean
average recall results for both detection and classification. We ran our
prediction pipeline on more than 4,500 images from the Oxyrhynchus Papyri to
illustrate the utility of our approach, and we release the results publicly in
multiple formats.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12517" title="Abstract">arXiv:2401.12517</a> [<a href="/pdf/2401.12517" title="Download PDF">pdf</a>, <a href="/format/2401.12517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing  High-Quality Implicit Neural Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Park%2C+D">Dogyun Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sihyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sojin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H+J">Hyunwoo J. Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Recent studies have introduced a new class of generative models for
synthesizing implicit neural representations (INRs) that capture arbitrary
continuous signals in various domains. These models opened the door for
domain-agnostic generative models, but they often fail to achieve high-quality
generation. We observed that the existing methods generate the weights of
neural networks to parameterize INRs and evaluate the network with fixed
positional embeddings (PEs). Arguably, this architecture limits the expressive
power of generative models and results in low-quality INR generation. To
address this limitation, we propose Domain-agnostic Latent Diffusion Model for
INRs (DDMI) that generates adaptive positional embeddings instead of neural
networks' weights. Specifically, we develop a Discrete-to-continuous space
Variational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and
the continuous signal functions in the shared latent space. Additionally, we
introduce a novel conditioning mechanism for evaluating INRs with the
hierarchically decomposed PEs to further enhance expressive power. Extensive
experiments across four modalities, e.g., 2D images, 3D shapes, Neural Radiance
Fields, and videos, with seven benchmark datasets, demonstrate the versatility
of DDMI and its superior performance compared to the existing INR generative
models.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12520" title="Abstract">arXiv:2401.12520</a> [<a href="/pdf/2401.12520" title="Download PDF">pdf</a>, <a href="/format/2401.12520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Key Information Retrieval to Classify the Unstructured Data Content of  Preferential Trade Agreements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Ziyi Meng</a>, 
<a href="/search/cs?searchtype=author&query=Gordeev%2C+S">Stepan Gordeev</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zijie Pan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dongjin Song</a>, 
<a href="/search/cs?searchtype=author&query=Steinbach%2C+S">Sandro Steinbach</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AI4TS Workshop@AAAI 2024 accepted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the rapid proliferation of textual data, predicting long texts has
emerged as a significant challenge in the domain of natural language
processing. Traditional text prediction methods encounter substantial
difficulties when grappling with long texts, primarily due to the presence of
redundant and irrelevant information, which impedes the model's capacity to
capture pivotal insights from the text. To address this issue, we introduce a
novel approach to long-text classification and prediction. Initially, we employ
embedding techniques to condense the long texts, aiming to diminish the
redundancy therein. Subsequently,the Bidirectional Encoder Representations from
Transformers (BERT) embedding method is utilized for text classification
training. Experimental outcomes indicate that our method realizes considerable
performance enhancements in classifying long texts of Preferential Trade
Agreements. Furthermore, the condensation of text through embedding methods not
only augments prediction accuracy but also substantially reduces computational
complexity. Overall, this paper presents a strategy for long-text prediction,
offering a valuable reference for researchers and engineers in the natural
language processing sphere.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12521" title="Abstract">arXiv:2401.12521</a> [<a href="/pdf/2401.12521" title="Download PDF">pdf</a>, <a href="/ps/2401.12521" title="Download PostScript">ps</a>, <a href="/format/2401.12521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Virtual Reality through Ihde&#x27;s Instrumental Realism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">He Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Carroll%2C+J+M">John M. Carroll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to iConference 2024 as a short paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Based on Ihde's theory, this paper explores the relationship between virtual
reality (VR) as an instrument and phenomenology. It reviews the "technological
revolution" spurred by the development of VR technology and discusses how VR
has been used to study subjective experience, explore perception and
embodiment, enhance empathy and perspective, and investigate altered states of
consciousness. The paper emphasizes the role of VR as an instrumental
technology, particularly its ability to expand human perception and cognition.
Reflecting on this in conjunction with the work of Husserl and Ihde, among
others, it revisits the potential of VR to provide new avenues for scientific
inquiry and experience and to transform our understanding of the world through
VR.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12522" title="Abstract">arXiv:2401.12522</a> [<a href="/pdf/2401.12522" title="Download PDF">pdf</a>, <a href="/format/2401.12522" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+F">Feng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+H">Hanling Yi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaotian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+G">Guangming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+R">Rong Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code at <a href="https://github.com/linfeng93/BiTA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) commonly employ autoregressive generation during
inference, leading to high memory bandwidth demand and consequently extended
latency. To mitigate this inefficiency, we present Bi-directional Tuning for
lossless Acceleration (BiTA), an innovative method expediting LLMs via
streamlined semi-autoregressive generation and draft verification. Inspired by
the concept of prompt tuning, we enhance LLMs with a parameter-efficient design
called bi-directional tuning for the capability in semi-autoregressive
generation. Employing efficient tree-based decoding, the models perform draft
candidate generation and verification in parallel, ensuring outputs identical
to their autoregressive counterparts under greedy sampling. BiTA serves as a
lightweight plug-in module, seamlessly boosting the inference efficiency of
existing LLMs without requiring additional assistance models or incurring
significant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat
achieves a 2.7$\times$ speedup on the MT-Bench benchmark. Extensive experiments
confirm our method surpasses state-of-the-art acceleration techniques.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12526" title="Abstract">arXiv:2401.12526</a> [<a href="/pdf/2401.12526" title="Download PDF">pdf</a>, <a href="/ps/2401.12526" title="Download PostScript">ps</a>, <a href="/format/2401.12526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined generalization analysis of the Deep Ritz Method and  Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Xu%2C+X">Xianliang Xu</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we present refined generalization bounds for the Deep Ritz
Method (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, we
focus on two prototype elliptic PDEs: Poisson equation and static Schr\"odinger
equation on the $d$-dimensional unit hypercube with the Neumann boundary
condition. And sharper generalization bounds are derived based on the
localization techniques under the assumptions that the exact solutions of the
PDEs lie in the Barron space or the general Sobolev spaces. For the PINNs, we
investigate the general linear second elliptic PDEs with Dirichlet boundary
condition.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12532" title="Abstract">arXiv:2401.12532</a> [<a href="/pdf/2401.12532" title="Download PDF">pdf</a>, <a href="/format/2401.12532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DAFA: Distance-Aware Fair Adversarial Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Saehyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+H">Hyemi Jang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junsung Park</a>, 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Ho Bae</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungroh Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The disparity in accuracy between classes in standard training is amplified
during adversarial training, a phenomenon termed the robust fairness problem.
Existing methodologies aimed to enhance robust fairness by sacrificing the
model's performance on easier classes in order to improve its performance on
harder ones. However, we observe that under adversarial attacks, the majority
of the model's predictions for samples from the worst class are biased towards
classes similar to the worst class, rather than towards the easy classes.
Through theoretical and empirical analysis, we demonstrate that robust fairness
deteriorates as the distance between classes decreases. Motivated by these
insights, we introduce the Distance-Aware Fair Adversarial training (DAFA)
methodology, which addresses robust fairness by taking into account the
similarities between classes. Specifically, our method assigns distinct loss
weights and adversarial margins to each class and adjusts them to encourage a
trade-off in robustness among similar classes. Experimental results across
various datasets demonstrate that our method not only maintains average robust
accuracy but also significantly improves the worst robust accuracy, indicating
a marked improvement in robust fairness compared to existing methods.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12533" title="Abstract">arXiv:2401.12533</a> [<a href="/pdf/2401.12533" title="Download PDF">pdf</a>, <a href="/format/2401.12533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Constrained $k$-Center Clustering with Background Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Longkun Guo</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+C">Chaoqi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+K">Kewen Liao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Center-based clustering has attracted significant research interest from both
theory and practice. In many practical applications, input data often contain
background knowledge that can be used to improve clustering results. In this
work, we build on widely adopted $k$-center clustering and model its input
background knowledge as must-link (ML) and cannot-link (CL) constraint sets.
However, most clustering problems including $k$-center are inherently
$\mathcal{NP}$-hard, while the more complex constrained variants are known to
suffer severer approximation and computation barriers that significantly limit
their applicability. By employing a suite of techniques including reverse
dominating sets, linear programming (LP) integral polyhedron, and LP duality,
we arrive at the first efficient approximation algorithm for constrained
$k$-center with the best possible ratio of 2. We also construct competitive
baseline algorithms and empirically evaluate our approximation algorithm
against them on a variety of real datasets. The results validate our
theoretical findings and demonstrate the great advantages of our algorithm in
terms of clustering cost, clustering quality, and running time.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12535" title="Abstract">arXiv:2401.12535</a> [<a href="/pdf/2401.12535" title="Download PDF">pdf</a>, <a href="/format/2401.12535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Vision Transformers Are Efficient Segmentation Learners  for Imperfect Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Seungho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Seoungyoon Kang</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+H">Hyunjung Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI2024 Edge Intelligence Workshop (EIW) accepted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study demonstrates a cost-effective approach to semantic segmentation
using self-supervised vision transformers (SSVT). By freezing the SSVT backbone
and training a lightweight segmentation head, our approach effectively utilizes
imperfect labels, thereby improving robustness to label imperfections.
Empirical experiments show significant performance improvements over existing
methods for various annotation types, including scribble, point-level, and
image-level labels. The research highlights the effectiveness of
self-supervised vision transformers in dealing with imperfect labels, providing
a practical and efficient solution for semantic segmentation while reducing
annotation costs. Through extensive experiments, we confirm that our method
outperforms baseline models for all types of imperfect labels. Especially under
the zero-shot vision-language-model-based label, our model exhibits 11.5\%p
performance gain compared to the baseline.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12538" title="Abstract">arXiv:2401.12538</a> [<a href="/pdf/2401.12538" title="Download PDF">pdf</a>, <a href="/format/2401.12538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Sources Information Fusion Learning for Multi-Points NLOS  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bohao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fenghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Mengbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chongwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qianqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Alhammadi%2C+A">Ahmed Alhammadi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">M&#xe9;rouane Debbah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Accurate localization of mobile terminals is crucial for integrated sensing
and communication systems. Existing fingerprint localization methods, which
deduce coordinates from channel information in pre-defined rectangular areas,
struggle with the heterogeneous fingerprint distribution inherent in
non-line-of-sight (NLOS) scenarios. To address the problem, we introduce a
novel multi-source information fusion learning framework referred to as the
Autosync Multi-Domain NLOS Localization (AMDNLoc). Specifically, AMDNLoc
employs a two-stage matched filter fused with a target tracking algorithm and
iterative centroid-based clustering to automatically and irregularly segment
NLOS regions, ensuring uniform fingerprint distribution within channel state
information across frequency, power, and time-delay domains. Additionally, the
framework utilizes a segment-specific linear classifier array, coupled with
deep residual network-based feature extraction and fusion, to establish the
correlation function between fingerprint features and coordinates within these
regions. Simulation results demonstrate that AMDNLoc significantly enhances
localization accuracy by over 55% compared with traditional convolutional
neural network on the wireless artificial intelligence research dataset.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12540" title="Abstract">arXiv:2401.12540</a> [<a href="/pdf/2401.12540" title="Download PDF">pdf</a>, <a href="/format/2401.12540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREditor: An Time-efficient Approach for Building a Domain-specific  Dense Retrieval Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Duanyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+W">Wenqiang Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jiancheng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, Codes are available at <a href="https://github.com/huangzichun/DREditor">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Deploying dense retrieval models efficiently is becoming increasingly
important across various industries. This is especially true for enterprise
search services, where customizing search engines to meet the time demands of
different enterprises in different domains is crucial. Motivated by this, we
develop a time-efficient approach called DREditor to edit the matching rule of
an off-the-shelf dense retrieval model to suit a specific domain. This is
achieved by directly calibrating the output embeddings of the model using an
efficient and effective linear mapping. This mapping is powered by an edit
operator that is obtained by solving a specially constructed least squares
problem. Compared to implicit rule modification via long-time finetuning, our
experimental results show that DREditor provides significant advantages on
different domain-specific datasets, dataset sources, retrieval models, and
computing devices. It consistently enhances time efficiency by 100-300 times
while maintaining comparable or even superior retrieval performance. In a
broader context, we take the first step to introduce a novel embedding
calibration approach for the retrieval task, filling the technical blank in the
current field of embedding calibration. This approach also paves the way for
building domain-specific dense retrieval models efficiently and inexpensively.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12542" title="Abstract">arXiv:2401.12542</a> [<a href="/pdf/2401.12542" title="Download PDF">pdf</a>, <a href="/ps/2401.12542" title="Download PostScript">ps</a>, <a href="/format/2401.12542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Party Private Set Intersection: A Circuit-Based Protocol with  Jaccard Similarity for Secure and Efficient Anomaly Detection in Network  Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jiuheng Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhili Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaomin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We present a new circuit-based protocol for multi-party private set
intersection (PSI) that allows m parties to compute the intersection of their
datasets without revealing any additional information about the items outside
the intersection. Building upon the two-party Sort-Compare-Shuffle (SCS)
protocol, we seamlessly extend it to a multi-party setting. Demonstrating its
practicality through implementation, our protocol exhibits acceptable
performance. Specifically, with 7 parties, each possessing a set size of
2^{12}, our protocol completes in just 19 seconds. Moreover, circuit-based
protocols like ours have an advantage over using custom protocols to perform
more complex computation. We substantiate this advantage by incorporating a
module for calculating the Jaccard similarity metric of the private sets which
can be used in the application domain of network traffic analysis for anomaly
detection. This extension showcases the versatility of our protocol beyond set
intersection computations, demonstrating its efficacy in preserving privacy
while efficiently identifying abnormal patterns in network flow.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12546" title="Abstract">arXiv:2401.12546</a> [<a href="/pdf/2401.12546" title="Download PDF">pdf</a>, <a href="/format/2401.12546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Building Myopic MPC Policies using Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orrico%2C+C+A">Christopher A. Orrico</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bokan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamoorthy%2C+D">Dinesh Krishnamoorthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">The application of supervised learning techniques in combination with model
predictive control (MPC) has recently generated significant interest,
particularly in the area of approximate explicit MPC, where function
approximators like deep neural networks are used to learn the MPC policy via
optimal state-action pairs generated offline. While the aim of approximate
explicit MPC is to closely replicate the MPC policy, substituting online
optimization with a trained neural network, the performance guarantees that
come with solving the online optimization problem are typically lost. This
paper considers an alternative strategy, where supervised learning is used to
learn the optimal value function offline instead of learning the optimal
policy. This can then be used as the cost-to-go function in a myopic MPC with a
very short prediction horizon, such that the online computation burden reduces
significantly without affecting the controller performance. This approach
differs from existing work on value function approximations in the sense that
it learns the cost-to-go function by using offline-collected state-value pairs,
rather than closed-loop performance data. The cost of generating the
state-value pairs used for training is addressed using a sensitivity-based data
augmentation scheme.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12550" title="Abstract">arXiv:2401.12550</a> [<a href="/pdf/2401.12550" title="Download PDF">pdf</a>, <a href="/format/2401.12550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UR4NNV: Neural Network Verification, Under-approximation Reachability  Works!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Taoran Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bai Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Ji Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenjing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Shaojun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wanwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, formal verification of deep neural networks (DNNs) has garnered
considerable attention, and over-approximation based methods have become
popular due to their effectiveness and efficiency. However, these strategies
face challenges in addressing the "unknown dilemma" concerning whether the
exact output region or the introduced approximation error violates the property
in question. To address this, this paper introduces the UR4NNV verification
framework, which utilizes under-approximation reachability analysis for DNN
verification for the first time. UR4NNV focuses on DNNs with Rectified Linear
Unit (ReLU) activations and employs a binary tree branch-based
under-approximation algorithm. In each epoch, UR4NNV under-approximates a
sub-polytope of the reachable set and verifies this polytope against the given
property. Through a trial-and-error approach, UR4NNV effectively falsifies DNN
properties while providing confidence levels when reaching verification epoch
bounds and failing falsifying properties. Experimental comparisons with
existing verification methods demonstrate the effectiveness and efficiency of
UR4NNV, significantly reducing the impact of the "unknown dilemma".
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12553" title="Abstract">arXiv:2401.12553</a> [<a href="/pdf/2401.12553" title="Download PDF">pdf</a>, <a href="/format/2401.12553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiarui Jin</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zexue He</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mengyue Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=McAuley%2C+J">Julian McAuley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> WWW 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Ranking items regarding individual user interests is a core technique of
multiple downstream tasks such as recommender systems. Learning such a
personalized ranker typically relies on the implicit feedback from users' past
click-through behaviors. However, collected feedback is biased toward
previously highly-ranked items and directly learning from it would result in a
"rich-get-richer" phenomenon. In this paper, we propose a simple yet sufficient
unbiased learning-to-rank paradigm named InfoRank that aims to simultaneously
address both position and popularity biases. We begin by consolidating the
impacts of those biases into a single observation factor, thereby providing a
unified approach to addressing bias-related issues. Subsequently, we minimize
the mutual information between the observation estimation and the relevance
estimation conditioned on the input features. By doing so, our relevance
estimation can be proved to be free of bias. To implement InfoRank, we first
incorporate an attention mechanism to capture latent correlations within
user-item features, thereby generating estimations of observation and
relevance. We then introduce a regularization term, grounded in conditional
mutual information, to promote conditional independence between relevance
estimation and observation estimation. Experimental evaluations conducted
across three extensive recommendation and search datasets reveal that InfoRank
learns more precise and unbiased ranking strategies.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12554" title="Abstract">arXiv:2401.12554</a> [<a href="/pdf/2401.12554" title="Download PDF">pdf</a>, <a href="/format/2401.12554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Write Parallel Code?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nichols%2C+D">Daniel Nichols</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J+H">Joshua H. Davis</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhaojun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Rajaram%2C+A">Arjun Rajaram</a>, 
<a href="/search/cs?searchtype=author&query=Bhatele%2C+A">Abhinav Bhatele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models are becoming an increasingly popular tool for software
development. Their ability to model and generate source code has been
demonstrated in a variety of contexts, including code completion,
summarization, translation, and lookup. However, they often struggle to
generate code for more complex tasks. In this paper, we explore the ability of
state-of-the-art language models to generate parallel code. We propose a
benchmark, PCGBench, consisting of a set of 420 tasks for evaluating the
ability of language models to generate parallel code, and we evaluate the
performance of several state-of-the-art open- and closed-source language models
on these tasks. We introduce novel metrics for comparing parallel code
generation performance and use them to explore how well each LLM performs on
various parallel programming models and computational problem types.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12557" title="Abstract">arXiv:2401.12557</a> [<a href="/pdf/2401.12557" title="Download PDF">pdf</a>, <a href="/ps/2401.12557" title="Download PostScript">ps</a>, <a href="/format/2401.12557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Balancing the AI Strength of Roles in Self-Play Training with Regret  Matching+
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoxi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">When training artificial intelligence for games encompassing multiple roles,
the development of a generalized model capable of controlling any character
within the game presents a viable option. This strategy not only conserves
computational resources and time during the training phase but also reduces
resource requirements during deployment. training such a generalized model
often encounters challenges related to uneven capabilities when controlling
different roles. A simple method is introduced based on Regret Matching+, which
facilitates a more balanced performance of strength by the model when
controlling various roles.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12561" title="Abstract">arXiv:2401.12561</a> [<a href="/pdf/2401.12561" title="Download PDF">pdf</a>, <a href="/format/2401.12561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EndoGaussian: Gaussian Splatting for Deformable Surgical Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yifan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yixuan Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Reconstructing deformable tissues from endoscopic stereo videos is essential
in many downstream surgical applications. However, existing methods suffer from
slow inference speed, which greatly limits their practical use. In this paper,
we introduce EndoGaussian, a real-time surgical scene reconstruction framework
that builds on 3D Gaussian Splatting. Our framework represents dynamic surgical
scenes as canonical Gaussians and a time-dependent deformation field, which
predicts Gaussian deformations at novel timestamps. Due to the efficient
Gaussian representation and parallel rendering pipeline, our framework
significantly accelerates the rendering speed compared to previous methods. In
addition, we design the deformation field as the combination of a lightweight
encoding voxel and an extremely tiny MLP, allowing for efficient Gaussian
tracking with a minor rendering burden. Furthermore, we design a holistic
Gaussian initialization method to fully leverage the surface distribution
prior, achieved by searching informative points from across the input image
sequence. Experiments on public endoscope datasets demonstrate that our method
can achieve real-time rendering speed (195 FPS real-time, 100$\times$ gain)
while maintaining the state-of-the-art reconstruction quality (35.925 PSNR) and
the fastest training speed (within 2 min/scene), showing significant promise
for intraoperative surgery applications. Code is available at:
\url{https://yifliu3.github.io/EndoGaussian/}.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12562" title="Abstract">arXiv:2401.12562</a> [<a href="/pdf/2401.12562" title="Download PDF">pdf</a>, <a href="/ps/2401.12562" title="Download PostScript">ps</a>, <a href="/format/2401.12562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning the cost-to-go for mixed-integer nonlinear model predictive  control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Orrico%2C+C+A">Christopher A. Orrico</a>, 
<a href="/search/eess?searchtype=author&query=Heemels%2C+W+P+M+H">W.P.M.H. Heemels</a>, 
<a href="/search/eess?searchtype=author&query=Krishnamoorthy%2C+D">Dinesh Krishnamoorthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Application of nonlinear model predictive control (NMPC) to problems with
hybrid dynamical systems, disjoint constraints, or discrete controls often
results in mixed-integer formulations with both continuous and discrete
decision variables. However, solving mixed-integer nonlinear programming
problems (MINLP) in real-time is challenging, which can be a limiting factor in
many applications. To address the computational complexity of solving mixed
integer nonlinear model predictive control problem in real-time, this paper
proposes an approximate mixed integer NMPC formulation based on value function
approximation. Leveraging Bellman's principle of optimality, the key idea here
is to divide the prediction horizon into two parts, where the optimal value
function of the latter part of the prediction horizon is approximated offline
using expert demonstrations. Doing so allows us to solve the MINMPC problem
with a considerably shorter prediction horizon online, thereby reducing the
online computation cost. The paper uses an inverted pendulum example with
discrete controls to illustrate this approach.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12564" title="Abstract">arXiv:2401.12564</a> [<a href="/pdf/2401.12564" title="Download PDF">pdf</a>, <a href="/format/2401.12564" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Contrastive Invariant Learning from the Causal Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mo%2C+Y">Yanhu Mo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+S">Shaohua Fan</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Graph contrastive learning (GCL), learning the node representation by
contrasting two augmented graphs in a self-supervised way, has attracted
considerable attention. GCL is usually believed to learn the invariant
representation. However, does this understanding always hold in practice? In
this paper, we first study GCL from the perspective of causality. By analyzing
GCL with the structural causal model (SCM), we discover that traditional GCL
may not well learn the invariant representations due to the non-causal
information contained in the graph. How can we fix it and encourage the current
GCL to learn better invariant representations? The SCM offers two requirements
and motives us to propose a novel GCL method. Particularly, we introduce the
spectral graph augmentation to simulate the intervention upon non-causal
factors. Then we design the invariance objective and independence objective to
better capture the causal factors. Specifically, (i) the invariance objective
encourages the encoder to capture the invariant information contained in causal
variables, and (ii) the independence objective aims to reduce the influence of
confounders on the causal variables. Experimental results demonstrate the
effectiveness of our approach on node classification tasks.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12566" title="Abstract">arXiv:2401.12566</a> [<a href="/pdf/2401.12566" title="Download PDF">pdf</a>, <a href="/format/2401.12566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Fact-Checking of Climate Change Claims with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leippold%2C+M">Markus Leippold</a>, 
<a href="/search/cs?searchtype=author&query=Vaghefi%2C+S+A">Saeid Ashraf Vaghefi</a>, 
<a href="/search/cs?searchtype=author&query=Stammbach%2C+D">Dominik Stammbach</a>, 
<a href="/search/cs?searchtype=author&query=Muccione%2C+V">Veruska Muccione</a>, 
<a href="/search/cs?searchtype=author&query=Bingler%2C+J">Julia Bingler</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jingwei Ni</a>, 
<a href="/search/cs?searchtype=author&query=Colesanti-Senni%2C+C">Chiara Colesanti-Senni</a>, 
<a href="/search/cs?searchtype=author&query=Wekhof%2C+T">Tobias Wekhof</a>, 
<a href="/search/cs?searchtype=author&query=Schimanski%2C+T">Tobias Schimanski</a>, 
<a href="/search/cs?searchtype=author&query=Gostlow%2C+G">Glen Gostlow</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tingyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Luterbacher%2C+J">Juerg Luterbacher</a>, 
<a href="/search/cs?searchtype=author&query=Huggel%2C+C">Christian Huggel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents Climinator, a novel AI-based tool designed to automate
the fact-checking of climate change claims. Utilizing an array of Large
Language Models (LLMs) informed by authoritative sources like the IPCC reports
and peer-reviewed scientific literature, Climinator employs an innovative
Mediator-Advocate framework. This design allows Climinator to effectively
synthesize varying scientific perspectives, leading to robust, evidence-based
evaluations. Our model demonstrates remarkable accuracy when testing claims
collected from Climate Feedback and Skeptical Science. Notably, when
integrating an advocate with a climate science denial perspective in our
framework, Climinator's iterative debate process reliably converges towards
scientific consensus, underscoring its adeptness at reconciling diverse
viewpoints into science-based, factual conclusions. While our research is
subject to certain limitations and necessitates careful interpretation, our
approach holds significant potential. We hope to stimulate further research and
encourage exploring its applicability in other contexts, including political
fact-checking and legal domains.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12568" title="Abstract">arXiv:2401.12568</a> [<a href="/pdf/2401.12568" title="Download PDF">pdf</a>, <a href="/format/2401.12568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for  Talking Face Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bi%2C+C">Chongke Bi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoxing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhilei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Talking face synthesis driven by audio is one of the current research
hotspots in the fields of multidimensional signal processing and multimedia.
Neural Radiance Field (NeRF) has recently been brought to this research field
in order to enhance the realism and 3D effect of the generated faces. However,
most existing NeRF-based methods either burden NeRF with complex learning tasks
while lacking methods for supervised multimodal feature fusion, or cannot
precisely map audio to the facial region related to speech movements. These
reasons ultimately result in existing methods generating inaccurate lip shapes.
This paper moves a portion of NeRF learning tasks ahead and proposes a talking
face synthesis method via NeRF with attention-based disentanglement (NeRF-AD).
In particular, an Attention-based Disentanglement module is introduced to
disentangle the face into Audio-face and Identity-face using speech-related
facial action unit (AU) information. To precisely regulate how audio affects
the talking face, we only fuse the Audio-face with audio feature. In addition,
AU information is also utilized to supervise the fusion of these two
modalities. Extensive qualitative and quantitative experiments demonstrate that
our NeRF-AD outperforms state-of-the-art methods in generating realistic
talking face videos, including image quality and lip synchronization. To view
video results, please refer to https://xiaoxingliu02.github.io/NeRF-AD.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12574" title="Abstract">arXiv:2401.12574</a> [<a href="/pdf/2401.12574" title="Download PDF">pdf</a>, <a href="/format/2401.12574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backpropagation Through Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wenshuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lijun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">A fundamental challenge in multi-agent reinforcement learning (MARL) is to
learn the joint policy in an extremely large search space, which grows
exponentially with the number of agents. Moreover, fully decentralized policy
factorization significantly restricts the search space, which may lead to
sub-optimal policies. In contrast, the auto-regressive joint policy can
represent a much richer class of joint policies by factorizing the joint policy
into the product of a series of conditional individual policies. While such
factorization introduces the action dependency among agents explicitly in
sequential execution, it does not take full advantage of the dependency during
learning. In particular, the subsequent agents do not give the preceding agents
feedback about their decisions. In this paper, we propose a new framework
Back-Propagation Through Agents (BPTA) that directly accounts for both agents'
own policy updates and the learning of their dependent counterparts. This is
achieved by propagating the feedback through action chains. With the proposed
framework, our Bidirectional Proximal Policy Optimisation (BPPO) outperforms
the state-of-the-art methods. Extensive experiments on matrix games,
StarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstrate
the effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12576" title="Abstract">arXiv:2401.12576</a> [<a href="/pdf/2401.12576" title="Download PDF">pdf</a>, <a href="/format/2401.12576" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMCheckup: Conversational Examination of Large Language Models via  Interpretability Tools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Anikina%2C+T">Tatiana Anikina</a>, 
<a href="/search/cs?searchtype=author&query=Feldhus%2C+N">Nils Feldhus</a>, 
<a href="/search/cs?searchtype=author&query=van+Genabith%2C+J">Josef van Genabith</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+L">Leonhard Hennig</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6ller%2C+S">Sebastian M&#xf6;ller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Interpretability tools that offer explanations in the form of a dialogue have
demonstrated their efficacy in enhancing users' understanding, as one-off
explanations may occasionally fall short in providing sufficient information to
the user. Current solutions for dialogue-based explanations, however, require
many dependencies and are not easily transferable to tasks they were not
designed for. With LLMCheckup, we present an easily accessible tool that allows
users to chat with any state-of-the-art large language model (LLM) about its
behavior. We enable LLMs to generate all explanations by themselves and take
care of intent recognition without fine-tuning, by connecting them with a broad
spectrum of Explainable AI (XAI) tools, e.g. feature attributions,
embedding-based similarity, and prompting strategies for counterfactual and
rationale generation. LLM (self-)explanations are presented as an interactive
dialogue that supports follow-up questions and generates suggestions.
LLMCheckup provides tutorials for operations available in the system, catering
to individuals with varying levels of expertise in XAI and supports multiple
input modalities. We introduce a new parsing strategy called multi-prompt
parsing substantially enhancing the parsing accuracy of LLMs. Finally, we
showcase the tasks of fact checking and commonsense question answering.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12578" title="Abstract">arXiv:2401.12578</a> [<a href="/pdf/2401.12578" title="Download PDF">pdf</a>, <a href="/format/2401.12578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ToDA: Target-oriented Diffusion Attacker against Recommendation System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhulin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+T">Ting Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">He Chang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xianglin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recommendation systems (RS) have become indispensable tools for web services
to address information overload, thus enhancing user experiences and bolstering
platforms' revenues. However, with their increasing ubiquity, security concerns
have also emerged. As the public accessibility of RS, they are susceptible to
specific malicious attacks where adversaries can manipulate user profiles,
leading to biased recommendations. Recent research often integrates additional
modules using generative models to craft these deceptive user profiles,
ensuring them are imperceptible while causing the intended harm. Albeit their
efficacy, these models face challenges of unstable training and the
exploration-exploitation dilemma, which can lead to suboptimal results. In this
paper, we pioneer to investigate the potential of diffusion models (DMs), for
shilling attacks. Specifically, we propose a novel Target-oriented Diffusion
Attack model (ToDA). It incorporates a pre-trained autoencoder that transforms
user profiles into a high dimensional space, paired with a Latent Diffusion
Attacker (LDA)-the core component of ToDA. LDA introduces noise into the
profiles within this latent space, adeptly steering the approximation towards
targeted items through cross-attention mechanisms. The global horizon,
implemented by a bipartite graph, is involved in LDA and derived from the
encoded user profile feature. This makes LDA possible to extend the generation
outwards the on-processing user feature itself, and bridges the gap between
diffused user features and target item features. Extensive experiments compared
to several SOTA baselines demonstrate ToDA's effectiveness. Specific studies
exploit the elaborative design of ToDA and underscore the potency of advanced
generative models in such contexts.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12582" title="Abstract">arXiv:2401.12582</a> [<a href="/pdf/2401.12582" title="Download PDF">pdf</a>, <a href="/format/2401.12582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigation of FlexAlgo for User-driven Path Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ku%C5%82acz%2C+J">Julia Ku&#x142;acz</a>, 
<a href="/search/cs?searchtype=author&query=Pawlus%2C+M">Martyna Pawlus</a>, 
<a href="/search/cs?searchtype=author&query=Boldrini%2C+L">Leonardo Boldrini</a>, 
<a href="/search/cs?searchtype=author&query=Grosso%2C+P">Paola Grosso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">This paper examines the Flexible Algorithm (FlexAlgo) for its potential to
enable user-driven path control in intra-domain Segment Routing (SR) enabled
networks. FlexAlgo is a relatively new approach to intra-domain routing that
allows multiple custom algorithms to coexist within a single domain. This
capability has the potential to provide users with greater control over the
paths their data takes through a network. The research includes a thorough
investigation of the FlexAlgo approach, including an examination of its
underlying techniques, as well as a practical implementation of a
FlexAlgo-based solution. We depict performed experiments where we implemented
FlexAlgo in three different scenarios. We also present how we developed an
automated tool for users to control traffic steering using preferred metrics
and constraints. The results of this investigation demonstrate the capabilities
of FlexAlgo as a means of enabling user-driven path control and therefore
increase security and trust of users towards the network.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12585" title="Abstract">arXiv:2401.12585</a> [<a href="/pdf/2401.12585" title="Download PDF">pdf</a>, <a href="/format/2401.12585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLANG: New Concept Comprehension of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+L">Lingrui Mei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shenghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+B">Baolong Bi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xueqi Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The dynamic nature of language, particularly evident in the realm of slang
and memes on the Internet, poses serious challenges to the adaptability of
large language models (LLMs). Traditionally anchored to static datasets, these
models often struggle to keep up with the rapid linguistic evolution
characteristic of online communities. This research addresses the critical need
to bridge this gap, aiming to enhance LLMs' comprehension of evolving new
concepts on the internet, without the high cost and impracticality of continual
retraining. To address this issue, we propose a new benchmark $\textbf{SLANG}$
to assess LLMs' proficiency in comprehending emerging linguistic trends and a
baseline approach $\textbf{FOCUS}$, which uses causal inference to enhance LLMs
to understand new phrases and usage patterns. This approach involves
scrutinizing real-world instances of linguistic shifts, serving as contextual
beacons, to form more precise and contextually relevant connections between
newly emerging expressions and their intended meanings. The empirical analysis
shows that our causal inference-based approach outperforms the traditional
models in terms of precision and relevance in the interpretation of Internet
slang and memes.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12586" title="Abstract">arXiv:2401.12586</a> [<a href="/pdf/2401.12586" title="Download PDF">pdf</a>, <a href="/format/2401.12586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C2Ideas: Supporting Creative Interior Color Design Ideation with Large  Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yihan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Manling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Hao Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Interior color design is a creative process that endeavors to allocate colors
to furniture and other elements within an interior space. While much research
focuses on generating realistic interior designs, these automated approaches
often misalign with user intention and disregard design rationales. Informed by
a need-finding preliminary study, we develop C2Ideas, an innovative system for
designers to creatively ideate color schemes enabled by an intent-aligned and
domain-oriented large language model. C2Ideas integrates a three-stage process:
Idea Prompting stage distills user intentions into color linguistic prompts;
Word-Color Association stage transforms the prompts into semantically and
stylistically coherent color schemes; and Interior Coloring stage assigns
colors to interior elements complying with design principles. We also develop
an interactive interface that enables flexible user refinement and
interpretable reasoning. C2Ideas has undergone a series of indoor cases and
user studies, demonstrating its effectiveness and high recognition of
interactive functionality by designers.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12588" title="Abstract">arXiv:2401.12588</a> [<a href="/pdf/2401.12588" title="Download PDF">pdf</a>, <a href="/format/2401.12588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpreting Equivariant Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hansen%2C+A+A">Andreas Abildtrup Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Calissano%2C+A">Anna Calissano</a>, 
<a href="/search/cs?searchtype=author&query=Feragen%2C+A">Aasa Feragen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Latent representations are used extensively for downstream tasks, such as
visualization, interpolation or feature extraction of deep learning models.
Invariant and equivariant neural networks are powerful and well-established
models for enforcing inductive biases. In this paper, we demonstrate that the
inductive bias imposed on the by an equivariant model must also be taken into
account when using latent representations. We show how not accounting for the
inductive biases leads to decreased performance on downstream tasks, and vice
versa, how accounting for inductive biases can be done effectively by using an
invariant projection of the latent representations. We propose principles for
how to choose such a projection, and show the impact of using these principles
in two common examples: First, we study a permutation equivariant variational
auto-encoder trained for molecule graph generation; here we show that invariant
projections can be designed that incur no loss of information in the resulting
invariant representation. Next, we study a rotation-equivariant representation
used for image classification. Here, we illustrate how random invariant
projections can be used to obtain an invariant representation with a high
degree of retained information. In both cases, the analysis of invariant latent
representations proves superior to their equivariant counterparts. Finally, we
illustrate that the phenomena documented here for equivariant neural networks
have counterparts in standard neural networks where invariance is encouraged
via augmentation. Thus, while these ambiguities may be known by experienced
developers of equivariant models, we make both the knowledge as well as
effective tools to handle the ambiguities available to the broader community.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12589" title="Abstract">arXiv:2401.12589</a> [<a href="/pdf/2401.12589" title="Download PDF">pdf</a>, <a href="/format/2401.12589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Superconvergent postprocessing of $C^0$ interior penalty method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cai%2C+Y">Ying Cai</a>, 
<a href="/search/math?searchtype=author&query=Guo%2C+H">Hailong Guo</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhimin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper focuses on the superconvergence analysis of the Hessian recovery
technique for the $C^0$ Interior Penalty Method (C0IP) in solving the
biharmonic equation. We establish interior error estimates for C0IP method that
serve as the superconvergent analysis tool. Using the argument of
superconvergence by difference quotient, we prove superconvergent results of
the recovered Hessian matrix on translation-invariant meshes. The Hessian
recovery technique enables us to construct an asymptotically exact ${\it a\,
posteriori}$ error estimator for the C0IP method. Numerical experiments are
provided to support our theoretical results.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12590" title="Abstract">arXiv:2401.12590</a> [<a href="/pdf/2401.12590" title="Download PDF">pdf</a>, <a href="/format/2401.12590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yifang Qin</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+W">Wei Ju</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yiyang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Collaborative Filtering (CF) is a pivotal research area in recommender
systems that capitalizes on collaborative similarities between users and items
to provide personalized recommendations. With the remarkable achievements of
node embedding-based Graph Neural Networks (GNNs), we explore the upper bounds
of expressiveness inherent to embedding-based methodologies and tackle the
challenges by reframing the CF task as a graph signal processing problem. To
this end, we propose PolyCF, a flexible graph signal filter that leverages
polynomial graph filters to process interaction signals. PolyCF exhibits the
capability to capture spectral features across multiple eigenspaces through a
series of Generalized Gram filters and is able to approximate the optimal
polynomial response function for recovering missing interactions. A graph
optimization objective and a pair-wise ranking objective are jointly used to
optimize the parameters of the convolution kernel. Experiments on three widely
adopted datasets demonstrate the superiority of PolyCF over current
state-of-the-art CF methods. Moreover, comprehensive studies empirically
validate each component's efficacy in the proposed PolyCF.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12592" title="Abstract">arXiv:2401.12592</a> [<a href="/pdf/2401.12592" title="Download PDF">pdf</a>, <a href="/format/2401.12592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from  RGB-D Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Hongchi Xia</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sifei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a new RGB-D object dataset captured in the wild called
WildRGB-D. Unlike most existing real-world object-centric datasets which only
come with RGB capturing, the direct capture of the depth channel allows better
3D annotations and broader downstream applications. WildRGB-D comprises
large-scale category-level RGB-D object videos, which are taken using an iPhone
to go around the objects in 360 degrees. It contains around 8500 recorded
objects and nearly 20000 RGB-D videos across 46 common object categories. These
videos are taken with diverse cluttered backgrounds with three setups to cover
as many real-world scenarios as possible: (i) a single object in one video;
(ii) multiple objects in one video; and (iii) an object with a static hand in
one video. The dataset is annotated with object masks, real-world scale camera
poses, and reconstructed aggregated point clouds from RGBD videos. We benchmark
four tasks with WildRGB-D including novel view synthesis, camera pose
estimation, object 6d pose estimation, and object surface reconstruction. Our
experiments show that the large-scale capture of RGB-D objects provides a large
potential to advance 3D object learning. Our project page is
https://wildrgbd.github.io/.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12593" title="Abstract">arXiv:2401.12593</a> [<a href="/pdf/2401.12593" title="Download PDF">pdf</a>, <a href="/format/2401.12593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOReGIn: Multi-Objective Recommendation at the Global and Individual  Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+E">Elizabeth G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Contreras%2C+D">David Contreras</a>, 
<a href="/search/cs?searchtype=author&query=Boratto%2C+L">Ludovico Boratto</a>, 
<a href="/search/cs?searchtype=author&query=Salam%C3%B3%2C+M">Maria Salam&#xf3;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to
guarantee multiple (often conflicting) goals. Besides accuracy, a MORS can
operate at the global level, where additional beyond-accuracy goals are met for
the system as a whole, or at the individual level, meaning that the
recommendations are tailored to the needs of each user. The state-of-the-art
MORSs either operate at the global or individual level, without assuming the
co-existence of the two perspectives. In this study, we show that when global
and individual objectives co-exist, MORSs are not able to meet both types of
goals. To overcome this issue, we present an approach that regulates the
recommendation lists so as to guarantee both global and individual
perspectives, while preserving its effectiveness. Specifically, as individual
perspective, we tackle genre calibration and, as global perspective, provider
fairness. We validate our approach on two real-world datasets, publicly
released with this paper.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12594" title="Abstract">arXiv:2401.12594</a> [<a href="/pdf/2401.12594" title="Download PDF">pdf</a>, <a href="/format/2401.12594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCORPION Cyber Range: Fully Customizable Cyberexercises, Gamification  and Learning Analytics to Train Cybersecurity Competencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nespoli%2C+P">Pantaleone Nespoli</a>, 
<a href="/search/cs?searchtype=author&query=Albaladejo-Gonz%C3%A1lez%2C+M">Mariano Albaladejo-Gonz&#xe1;lez</a>, 
<a href="/search/cs?searchtype=author&query=Valera%2C+J+A+P">Jos&#xe9; Antonio Pastor Valera</a>, 
<a href="/search/cs?searchtype=author&query=Ruip%C3%A9rez-Valiente%2C+J+A">Jos&#xe9; A. Ruip&#xe9;rez-Valiente</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Alfaro%2C+J">Joaquin Garcia-Alfaro</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A1rmol%2C+F+G">F&#xe9;lix G&#xf3;mez M&#xe1;rmol</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">It is undeniable that we are witnessing an unprecedented digital revolution.
However, recent years have been characterized by the explosion of cyberattacks,
making cybercrime one of the most profitable businesses on the planet. That is
why training in cybersecurity is increasingly essential to protect the assets
of cyberspace. One of the most vital tools to train cybersecurity competencies
is the Cyber Range, a virtualized environment that simulates realistic
networks. The paper at hand introduces SCORPION, a fully functional and
virtualized Cyber Range, which manages the authoring and automated deployment
of scenarios. In addition, SCORPION includes several elements to improve
student motivation, such as a gamification system with medals, points, or
rankings, among other elements. Such a gamification system includes an adaptive
learning module that is able to adapt the cyberexercise based on the users'
performance. Moreover, SCORPION leverages learning analytics that collects and
processes telemetric and biometric user data, including heart rate through a
smartwatch, which is available through a dashboard for instructors. Finally, we
developed a case study where SCORPION obtained 82.10\% in usability and 4.57
out of 5 in usefulness from the viewpoint of a student and an instructor. The
positive evaluation results are promising, indicating that SCORPION can become
an effective, motivating, and advanced cybersecurity training tool to help fill
current gaps in this context.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12596" title="Abstract">arXiv:2401.12596</a> [<a href="/pdf/2401.12596" title="Download PDF">pdf</a>, <a href="/format/2401.12596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniHDA: Towards Universal Hybrid Domain Adaptation of Image Generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hengjia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuqi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhanwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yibo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+w">weihang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuchun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+B">Boxi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative domain adaptation has achieved remarkable progress, enabling us to
adapt a pre-trained generator to a new target domain. However, existing methods
simply adapt the generator to a single target domain and are limited to a
single modality, either text-driven or image-driven. Moreover, they are prone
to overfitting domain-specific attributes, which inevitably compromises
cross-domain consistency. In this paper, we propose UniHDA, a unified and
versatile framework for generative hybrid domain adaptation with multi-modal
references from multiple domains. We use CLIP encoder to project multi-modal
references into a unified embedding space and then linear interpolate the
direction vectors from multiple target domains to achieve hybrid domain
adaptation. To ensure the cross-domain consistency, we propose a novel
cross-domain spatial structure (CSS) loss that maintains detailed spatial
structure information between source and target generator. Experiments show
that the adapted generator can synthesise realistic images with various
attribute compositions. Additionally, our framework is versatile to multiple
generators, \eg, StyleGAN2 and Diffusion Models.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12597" title="Abstract">arXiv:2401.12597</a> [<a href="/pdf/2401.12597" title="Download PDF">pdf</a>, <a href="/format/2401.12597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Privacy-, Budget-, and Deadline-Aware Service Optimization for  Large Medical Image Processing across Hybrid Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuandou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kanwal%2C+N">Neel Kanwal</a>, 
<a href="/search/cs?searchtype=author&query=Engan%2C+K">Kjersti Engan</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+C">Chunming Rong</a>, 
<a href="/search/cs?searchtype=author&query=Grosso%2C+P">Paola Grosso</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Efficiently processing medical images, such as whole slide images in digital
pathology, is essential for timely diagnosing high-risk diseases. However, this
demands advanced computing infrastructure, e.g., GPU servers for deep learning
inferencing, and local processing is time-consuming and costly. Besides,
privacy concerns further complicate the employment of remote cloud
infrastructures. While previous research has explored privacy and
security-aware workflow scheduling in hybrid clouds for distributed processing,
privacy-preserving data splitting, optimizing the service allocation of
outsourcing computation on split data to the cloud, and privacy evaluation for
large medical images still need to be addressed. This study focuses on
tailoring a virtual infrastructure within a hybrid cloud environment and
scheduling the image processing services while preserving privacy. We aim to
minimize the use of untrusted nodes, lower monetary costs, and reduce execution
time under privacy, budget, and deadline requirements. We consider a two-phase
solution and develop 1) a privacy-preserving data splitting algorithm and 2) a
greedy Pareto front-based algorithm for optimizing the service allocation. We
conducted experiments with real and simulated data to validate and compare our
method with a baseline. The results show that our privacy mechanism design
outperforms the baseline regarding the average lower band on individual privacy
and information gain for privacy evaluation. In addition, our approach can
obtain various Pareto optimal-based allocations with users' preferences on the
maximum number of untrusted nodes, budget, and time threshold. Our solutions
often dominate the baseline's solution and are superior on a tight budget.
Specifically, our approach has been ahead of baseline, up to 85.2% and 6.8% in
terms of the total financial and time costs, respectively.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12599" title="Abstract">arXiv:2401.12599</a> [<a href="/pdf/2401.12599" title="Download PDF">pdf</a>, <a href="/format/2401.12599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing Retrieval-Augmented Generation with Enhanced PDF  Structure Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Demiao Lin</a> (chatdoc.com)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">With the rapid development of Large Language Models (LLMs),
Retrieval-Augmented Generation (RAG) has become a predominant method in the
field of professional knowledge-based question answering. Presently, major
foundation model companies have opened up Embedding and Chat API interfaces,
and frameworks like LangChain have already integrated the RAG process. It
appears that the key models and steps in RAG have been resolved, leading to the
question: are professional knowledge QA systems now approaching perfection?
This article discovers that current primary methods depend on the premise of
accessing high-quality text corpora. However, since professional documents are
mainly stored in PDFs, the low accuracy of PDF parsing significantly impacts
the effectiveness of professional knowledge-based QA. We conducted an empirical
RAG experiment across hundreds of questions from the corresponding real-world
professional documents. The results show that, ChatDOC, a RAG system equipped
with a panoptic and pinpoint PDF parser, retrieves more accurate and complete
segments, and thus better answers. Empirical experiments show that ChatDOC is
superior to baseline on nearly 47% of questions, ties for 38% of cases, and
falls short on only 15% of cases. It shows that we may revolutionize RAG with
enhanced PDF structure recognition.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12600" title="Abstract">arXiv:2401.12600</a> [<a href="/pdf/2401.12600" title="Download PDF">pdf</a>, <a href="/format/2401.12600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EEND-M2F: Masked-attention mask transformers for speaker diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=H%C3%A4rk%C3%B6nen%2C+M">Marc H&#xe4;rk&#xf6;nen</a>, 
<a href="/search/cs?searchtype=author&query=Broughton%2C+S+J">Samuel J. Broughton</a>, 
<a href="/search/cs?searchtype=author&query=Samarakoon%2C+L">Lahiru Samarakoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we make the explicit connection between image segmentation
methods and end-to-end diarization methods. From these insights, we propose a
novel, fully end-to-end diarization model, EEND-M2F, based on the Mask2Former
architecture. Speaker representations are computed in parallel using a stack of
transformer decoders, in which irrelevant frames are explicitly masked from the
cross attention using predictions from previous layers. EEND-M2F is
lightweight, efficient, and truly end-to-end, as it does not require any
additional diarization, speaker verification, or segmentation models to run,
nor does it require running any clustering algorithms. Our model achieves
state-of-the-art performance on several public datasets, such as AMI,
AliMeeting and RAMC. Most notably our DER of 16.07% on DIHARD-III is the first
major improvement upon the challenge winning system.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12602" title="Abstract">arXiv:2401.12602</a> [<a href="/pdf/2401.12602" title="Download PDF">pdf</a>, <a href="/format/2401.12602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A coupling concept for Stokes-Darcy systems: the ICDD method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Discacciati%2C+M">Marco Discacciati</a>, 
<a href="/search/math?searchtype=author&query=Gervasio%2C+P">Paola Gervasio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We present a coupling framework for Stokes-Darcy systems valid for arbitrary
flow direction at low Reynolds numbers and for isotropic porous media. The
proposed method is based on an overlapping domain decomposition concept to
represent the transition region between the free-fluid and the porous-medium
regimes. Matching conditions at the interfaces of the decomposition impose the
continuity of velocity (on one interface) and pressure (on the other one) and
the resulting algorithm can be easily implemented in a non-intrusive way. The
numerical approximations of the fluid velocity and pressure obtained by the
studied method converge to the corresponding counterparts computed by direct
numerical simulation at the microscale, with convergence rates equal to
suitable powers of the scale separation parameter $\varepsilon$ in agreement
with classical results in homogenization.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12603" title="Abstract">arXiv:2401.12603</a> [<a href="/pdf/2401.12603" title="Download PDF">pdf</a>, <a href="/ps/2401.12603" title="Download PostScript">ps</a>, <a href="/format/2401.12603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASAP (Automatic Software for ASL Processing): A toolbox for processing  Arterial Spin Labeling images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abad%2C+V+M">Virginia Mato Abad</a>, 
<a href="/search/cs?searchtype=author&query=Garcia-Polo%2C+P">Pablo Garcia-Polo</a>, 
<a href="/search/cs?searchtype=author&query=ODaly%2C+O">Owen ODaly</a>, 
<a href="/search/cs?searchtype=author&query=Hernandez-Tamames%2C+J+A">Juan Antonio Hernandez-Tamames</a>, 
<a href="/search/cs?searchtype=author&query=Zelaya%2C+F">Fernando Zelaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The method of Arterial Spin Labeling (ASL) has experienced a significant rise
in its application to functional imaging, since it is the only technique
capable of measuring blood perfusion in a truly non-invasive manner. Currently,
there are no commercial packages for processing ASL data and there is no
recognised standard for normalising ASL data to a common frame of reference.
This work describes a new Automated Software for ASL Processing (ASAP) that can
automatically process several ASL datasets. ASAP includes functions for all
stages of image pre-processing: quantification, skull-stripping,
co-registration, partial volume correction and normalization. To assess the
applicability and validity of the toolbox, this work shows its application in
the study of hypoperfusion in a sample of healthy subjects at risk of
progressing to Alzheimer's Disease. ASAP requires limited user intervention,
minimising the possibility of random and systematic errors, and produces
cerebral blood flow maps that are ready for statistical group analysis. The
software is easy to operate and results in excellent quality of spatial
normalisation. The results found in this evaluation study are consistent with
previous studies that find decreased perfusion
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12604" title="Abstract">arXiv:2401.12604</a> [<a href="/pdf/2401.12604" title="Download PDF">pdf</a>, <a href="/format/2401.12604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Pigeonhole Principles and Ramsey in TFNP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Siddhartha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Robere%2C+R">Robert Robere</a>, 
<a href="/search/cs?searchtype=author&query=Xun%2C+Z">Zhiyang Xun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">The generalized pigeonhole principle says that if tN + 1 pigeons are put into
N holes then there must be a hole containing at least t + 1 pigeons. Let t-PPP
denote the class of all total NP-search problems reducible to finding such a
t-collision of pigeons. We introduce a new hierarchy of classes defined by the
problems t-PPP. In addition to being natural problems in TFNP, we show that
classes in and above the hierarchy are related to the notion of multi-collision
resistance in cryptography, and contain the problem underlying the breakthrough
average-case quantum advantage result shown by Yamakawa &amp; Zhandry (FOCS 2022).
<br />Finally, we give lower bound techniques for the black-box versions of t-PPP
for any t. In particular, we prove that RAMSEY is not in t-PPP, for any t that
is sub-polynomial in log (N), in the black-box setting. Goldberg and
Papadimitriou conjectured that RAMSEY reduces to 2-PPP, we thus refute it and
more in the black-box setting. We also provide an ensemble of black-box
separations which resolve the relative complexity of the t-PPP classes with
other well-known TFNP classes.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12609" title="Abstract">arXiv:2401.12609</a> [<a href="/pdf/2401.12609" title="Download PDF">pdf</a>, <a href="/format/2401.12609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Semi-supervised Unmixing using Non-convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rasti%2C+B">Behnood Rasti</a>, 
<a href="/search/cs?searchtype=author&query=Zouaoui%2C+A">Alexandre Zouaoui</a>, 
<a href="/search/cs?searchtype=author&query=Mairal%2C+J">Julien Mairal</a>, 
<a href="/search/cs?searchtype=author&query=Chanussot%2C+J">Jocelyn Chanussot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we introduce a novel linear model tailored for
semisupervised/library-based unmixing. Our model incorporates considerations
for library mismatch while enabling the enforcement of the abundance sum-to-one
constraint (ASC). Unlike conventional sparse unmixing methods, this model
involves nonconvex optimization, presenting significant computational
challenges. We demonstrate the efficacy of Alternating Methods of Multipliers
(ADMM) in cyclically solving these intricate problems. We propose two
semisupervised unmixing approaches, each relying on distinct priors applied to
the new model in addition to the ASC: sparsity prior and convexity constraint.
Our experimental results validate that enforcing the convexity constraint
outperforms the sparsity prior for the endmember library. These results are
corroborated across three simulated datasets (accounting for spectral
variability and varying pixel purity levels) and the Cuprite dataset.
Additionally, our comparison with conventional sparse unmixing methods
showcases considerable advantages of our proposed model, which entails
nonconvex optimization. Notably, our implementations of the proposed
algorithms-fast semisupervised unmixing (FaSUn) and sparse unmixing using
soft-shrinkage (SUnS)-prove considerably more efficient than traditional sparse
unmixing methods. SUnS and FaSUn were implemented using PyTorch and provided in
a dedicated Python package called Fast Semisupervised Unmixing (FUnmix), which
is open-source and available at https://github.com/BehnoodRasti/FUnmix
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12610" title="Abstract">arXiv:2401.12610</a> [<a href="/pdf/2401.12610" title="Download PDF">pdf</a>, <a href="/format/2401.12610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The twin peaks of learning neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demyanenko%2C+E">Elizaveta Demyanenko</a>, 
<a href="/search/cs?searchtype=author&query=Feinauer%2C+C">Christoph Feinauer</a>, 
<a href="/search/cs?searchtype=author&query=Malatesta%2C+E+M">Enrico M. Malatesta</a>, 
<a href="/search/cs?searchtype=author&query=Saglietti%2C+L">Luca Saglietti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 30 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">Recent works demonstrated the existence of a double-descent phenomenon for
the generalization error of neural networks, where highly overparameterized
models escape overfitting and achieve good test performance, at odds with the
standard bias-variance trade-off described by statistical learning theory. In
the present work, we explore a link between this phenomenon and the increase of
complexity and sensitivity of the function represented by neural networks. In
particular, we study the Boolean mean dimension (BMD), a metric developed in
the context of Boolean function analysis. Focusing on a simple teacher-student
setting for the random feature model, we derive a theoretical analysis based on
the replica method that yields an interpretable expression for the BMD, in the
high dimensional regime where the number of data points, the number of
features, and the input size grow to infinity. We find that, as the degree of
overparameterization of the network is increased, the BMD reaches an evident
peak at the interpolation threshold, in correspondence with the generalization
error peak, and then slowly approaches a low asymptotic value. The same
phenomenology is then traced in numerical experiments with different model
classes and training setups. Moreover, we find empirically that adversarially
initialized models tend to show higher BMD values, and that models that are
more robust to adversarial attacks exhibit a lower BMD.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12611" title="Abstract">arXiv:2401.12611</a> [<a href="/pdf/2401.12611" title="Download PDF">pdf</a>, <a href="/format/2401.12611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt Smells: An Omen for Undesirable Generative AI Outputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ronanki%2C+K">Krishna Ronanki</a>, 
<a href="/search/cs?searchtype=author&query=Cabrero-Daniel%2C+B">Beatriz Cabrero-Daniel</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+C">Christian Berger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CAIN 2024: Poster Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Recent Generative Artificial Intelligence (GenAI) trends focus on various
applications, including creating stories, illustrations, poems, articles,
computer code, music compositions, and videos. Extrinsic hallucinations are a
critical limitation of such GenAI, which can lead to significant challenges in
achieving and maintaining the trustworthiness of GenAI. In this paper, we
propose two new concepts that we believe will aid the research community in
addressing limitations associated with the application of GenAI models. First,
we propose a definition for the "desirability" of GenAI outputs and three
factors which are observed to influence it. Second, drawing inspiration from
Martin Fowler's code smells, we propose the concept of "prompt smells" and the
adverse effects they are observed to have on the desirability of GenAI outputs.
We expect our work will contribute to the ongoing conversation about the
desirability of GenAI outputs and help advance the field in a meaningful way.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12617" title="Abstract">arXiv:2401.12617</a> [<a href="/pdf/2401.12617" title="Download PDF">pdf</a>, <a href="/format/2401.12617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Joint Effect of Task Similarity and Overparameterization on  Catastrophic Forgetting -- An Analytical Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Evron%2C+I">Itay Evron</a>, 
<a href="/search/cs?searchtype=author&query=Goldfarb%2C+D">Daniel Goldfarb</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+N">Nir Weinberger</a>, 
<a href="/search/cs?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>, 
<a href="/search/cs?searchtype=author&query=Hand%2C+P">Paul Hand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the Twelfth International Conference on Learning Representations (ICLR 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In continual learning, catastrophic forgetting is affected by multiple
aspects of the tasks. Previous works have analyzed separately how forgetting is
affected by either task similarity or overparameterization. In contrast, our
paper examines how task similarity and overparameterization jointly affect
forgetting in an analyzable model. Specifically, we focus on two-task continual
linear regression, where the second task is a random orthogonal transformation
of an arbitrary first task (an abstraction of random permutation tasks). We
derive an exact analytical expression for the expected forgetting - and uncover
a nuanced pattern. In highly overparameterized models, intermediate task
similarity causes the most forgetting. However, near the interpolation
threshold, forgetting decreases monotonically with the expected task
similarity. We validate our findings with linear regression on synthetic data,
and with neural networks on established permutation task benchmarks.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12618" title="Abstract">arXiv:2401.12618</a> [<a href="/pdf/2401.12618" title="Download PDF">pdf</a>, <a href="/ps/2401.12618" title="Download PostScript">ps</a>, <a href="/format/2401.12618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computation of classical and $v$-adic $L$-series of $t$-motives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caruso%2C+X">Xavier Caruso</a> (IMB, CANARI), 
<a href="/search/cs?searchtype=author&query=Gazda%2C+Q">Quentin Gazda</a> (CMLS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">We design an algorithm for computing the $L$-series associated to an Anderson
$t$-motives, exhibiting quasilinear complexity with respect to the target
precision. Based on experiments, we conjecture that the order of vanishing at
$T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good
reduction does not depend on the finite place $v$.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12624" title="Abstract">arXiv:2401.12624</a> [<a href="/pdf/2401.12624" title="Download PDF">pdf</a>, <a href="/format/2401.12624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Distillation from Language-Oriented to Emergent Communication  for Multi-Agent Remote Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yongjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Sejin Seo</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jihong Park</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seong-Lyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Junil Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this work, we compare emergent communication (EC) built upon multi-agent
deep reinforcement learning (MADRL) and language-oriented semantic
communication (LSC) empowered by a pre-trained large language model (LLM) using
human language. In a multi-agent remote navigation task, with multimodal input
data comprising location and channel maps, it is shown that EC incurs high
training cost and struggles when using multimodal data, whereas LSC yields high
inference computing cost due to the LLM's large size. To address their
respective bottlenecks, we propose a novel framework of language-guided EC
(LEC) by guiding the EC training using LSC via knowledge distillation (KD).
Simulations corroborate that LEC achieves faster travel time while avoiding
areas with poor channel conditions, as well as speeding up the MADRL training
convergence by up to 61.8% compared to EC.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12627" title="Abstract">arXiv:2401.12627</a> [<a href="/pdf/2401.12627" title="Download PDF">pdf</a>, <a href="/ps/2401.12627" title="Download PostScript">ps</a>, <a href="/format/2401.12627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Channel Estimation and Joint Symbol Detection with Data-Driven  Factor Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmid%2C+L">Luca Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Raviv%2C+T">Tomer Raviv</a>, 
<a href="/search/cs?searchtype=author&query=Shlezinger%2C+N">Nir Shlezinger</a>, 
<a href="/search/cs?searchtype=author&query=Schmalen%2C+L">Laurent Schmalen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE for peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">We investigate the application of the factor graph framework for blind joint
channel estimation and symbol detection on time-variant linear inter-symbol
interference channels. In particular, we consider the expectation maximization
(EM) algorithm for maximum likelihood estimation, which typically suffers from
high complexity as it requires the computation of the symbol-wise posterior
distributions in every iteration. We address this issue by efficiently
approximating the posteriors using the belief propagation (BP) algorithm on a
suitable factor graph. By interweaving the iterations of BP and EM, the
detection complexity can be further reduced to a single BP iteration per EM
step. In addition, we propose a data-driven version of our algorithm that
introduces momentum in the BP updates and learns a suitable EM parameter update
schedule, thereby significantly improving the performance-complexity tradeoff
with a few offline training samples. Our numerical experiments demonstrate the
excellent performance of the proposed blind detector and show that it even
outperforms coherent BP detection in high signal-to-noise scenarios.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12630" title="Abstract">arXiv:2401.12630</a> [<a href="/pdf/2401.12630" title="Download PDF">pdf</a>, <a href="/format/2401.12630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Stack Optimization for CAM-Only DNN Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Lima%2C+J+P+C">Jo&#xe3;o Paulo C. de Lima</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+A">Asif Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Carro%2C+L">Luigi Carro</a>, 
<a href="/search/cs?searchtype=author&query=Castrillon%2C+J">Jeronimo Castrillon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at DATE24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">The accuracy of neural networks has greatly improved across various domains
over the past years. Their ever-increasing complexity, however, leads to
prohibitively high energy demands and latency in von Neumann systems. Several
computing-in-memory (CIM) systems have recently been proposed to overcome this,
but trade-offs involving accuracy, hardware reliability, and scalability for
large models remain a challenge. Additionally, for some CIM designs, the
activation movement still requires considerable time and energy. This paper
explores the combination of algorithmic optimizations for ternary weight neural
networks and associative processors (APs) implemented using racetrack memory
(RTM). We propose a novel compilation flow to optimize convolutions on APs by
reducing their arithmetic intensity. By leveraging the benefits of RTM-based
APs, this approach substantially reduces data transfers within the memory while
addressing accuracy, energy efficiency, and reliability concerns. Concretely,
our solution improves the energy efficiency of ResNet-18 inference on ImageNet
by 7.5x compared to crossbar in-memory accelerators while retaining software
accuracy.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12631" title="Abstract">arXiv:2401.12631</a> [<a href="/pdf/2401.12631" title="Download PDF">pdf</a>, <a href="/format/2401.12631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reply to Makelov et al. (2023)&#x27;s &quot;Interpretability Illusion&quot; Arguments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhengxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Geiger%2C+A">Atticus Geiger</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+A">Aryaman Arora</a>, 
<a href="/search/cs?searchtype=author&query=Icard%2C+T">Thomas Icard</a>, 
<a href="/search/cs?searchtype=author&query=Potts%2C+C">Christopher Potts</a>, 
<a href="/search/cs?searchtype=author&query=Goodman%2C+N+D">Noah D. Goodman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">We respond to the recent paper by Makelov et al. (2023), which reviews
subspace interchange intervention methods like distributed alignment search
(DAS; Geiger et al. 2023) and claims that these methods potentially cause
"interpretability illusions". We first review Makelov et al. (2023)'s technical
notion of what an "interpretability illusion" is, and then we show that even
intuitive and desirable explanations can qualify as illusions in this sense. As
a result, their method of discovering "illusions" can reject explanations they
consider "non-illusory". We then argue that the illusions Makelov et al. (2023)
see in practice are artifacts of their training and evaluation paradigms. We
close by emphasizing that, though we disagree with their core characterization,
Makelov et al. (2023)'s examples and discussion have undoubtedly pushed the
field of interpretability forward.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12632" title="Abstract">arXiv:2401.12632</a> [<a href="/pdf/2401.12632" title="Download PDF">pdf</a>, <a href="/format/2401.12632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Resilience of Collaborative AI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rimawi%2C+D">Diaeddin Rimawi</a>, 
<a href="/search/cs?searchtype=author&query=Liotta%2C+A">Antonio Liotta</a>, 
<a href="/search/cs?searchtype=author&query=Todescato%2C+M">Marco Todescato</a>, 
<a href="/search/cs?searchtype=author&query=Russo%2C+B">Barbara Russo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at the 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN 2024), Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">A Collaborative Artificial Intelligence System (CAIS) performs actions in
collaboration with the human to achieve a common goal. CAISs can use a trained
AI model to control human-system interaction, or they can use human interaction
to dynamically learn from humans in an online fashion. In online learning with
human feedback, the AI model evolves by monitoring human interaction through
the system sensors in the learning state, and actuates the autonomous
components of the CAIS based on the learning in the operational state.
Therefore, any disruptive event affecting these sensors may affect the AI
model's ability to make accurate decisions and degrade the CAIS performance.
Consequently, it is of paramount importance for CAIS managers to be able to
automatically track the system performance to understand the resilience of the
CAIS upon such disruptive events. In this paper, we provide a new framework to
model CAIS performance when the system experiences a disruptive event. With our
framework, we introduce a model of performance evolution of CAIS. The model is
equipped with a set of measures that aim to support CAIS managers in the
decision process to achieve the required resilience of the system. We tested
our framework on a real-world case study of a robot collaborating online with
the human, when the system is experiencing a disruptive event. The case study
shows that our framework can be adopted in CAIS and integrated into the online
execution of the CAIS activities.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12633" title="Abstract">arXiv:2401.12633</a> [<a href="/pdf/2401.12633" title="Download PDF">pdf</a>, <a href="/format/2401.12633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneity- and homophily-induced vulnerability of a P2P network  formation model: the IOTA auto-peering protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Campajola%2C+C">Carlo Campajola</a>, 
<a href="/search/cs?searchtype=author&query=Vallarano%2C+N">Nicolo Vallarano</a>, 
<a href="/search/cs?searchtype=author&query=Teixeira%2C+A+S">Andreia Sofia Teixeira</a>, 
<a href="/search/cs?searchtype=author&query=Tessone%2C+C+J">Claudio J. Tessone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">IOTA is a distributed ledger technology that relies on a peer-to-peer (P2P)
network for communications. Recently an auto-peering algorithm was proposed to
build connections among IOTA peers according to their "Mana" endowment, which
is an IOTA internal reputation system. This paper's goal is to detect potential
vulnerabilities and evaluate the resilience of the P2P network generated using
IOTA auto-peering algorithm against eclipse attacks. In order to do so, we
interpret IOTA's auto-peering algorithm as a random network formation model and
employ different network metrics to identify cost-efficient partitions of the
network. As a result, we present a potential strategy that an attacker can use
to eclipse a significant part of the network, providing estimates of costs and
potential damage caused by the attack. On the side, we provide an analysis of
the properties of IOTA auto-peering network ensemble, as an interesting class
of homophile random networks in between 1D lattices and regular Poisson graphs.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12634" title="Abstract">arXiv:2401.12634</a> [<a href="/pdf/2401.12634" title="Download PDF">pdf</a>, <a href="/ps/2401.12634" title="Download PostScript">ps</a>, <a href="/format/2401.12634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assisted Requirements Selection by Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=del+Sagrado%2C+J">Jos&#xe9; del Sagrado</a>, 
<a href="/search/cs?searchtype=author&query=del+%C3%81guila%2C+I+M">Isabel M del &#xc1;guila</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Requirements Engineering 26 (2021) 167-184
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Requirements selection is a decision-making process that enables project
managers to focus on the deliverables that add most value to the project
outcome. This task is performed to define which features or requirements will
be developed in the next release. It is a complex multi-criteria decision
process that has been focused by many research works because a balance between
business profits and investment is needed. The spectrum of prioritization
techniques spans from simple and qualitative to elaborated analytic
prioritization approaches that fall into the category of optimization
algorithms. This work studies the combination of the qualitative MoSCoW method
and cluster analysis for requirements selection. The feasibility of our
methodology has been tested on three case studies (with 20, 50 and 100
requirements). In each of them, the requirements have been clustered, then the
clustering configurations found have been evaluated using internal validation
measures for the compactness, connectivity and separability of the clusters.
The experimental results show the validity of clustering strategies for the
identification of the core set of requirements for the software product, being
the number of categories proposed by MoSCoW a good starting point in
requirements prioritization and negotiation.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12636" title="Abstract">arXiv:2401.12636</a> [<a href="/pdf/2401.12636" title="Download PDF">pdf</a>, <a href="/ps/2401.12636" title="Download PostScript">ps</a>, <a href="/format/2401.12636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stability prediction of the software requirements specification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=del+Sagrado%2C+J">J. del Sagrado</a>, 
<a href="/search/cs?searchtype=author&query=del+%C3%81guila%2C+I+M">I.M. del &#xc1;guila</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Software Qual J 26 (2018) 585-605
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Complex decision-making is a prominent aspect of Requirements Engineering.
This work presents the Bayesian network Requisites that predicts whether the
requirements specification documents have to be revised. We show how to
validate Requisites by means of metrics obtained from a large complex software
project. Besides, this Bayesian network has been integrated into a software
tool by defining a communication interface inside a multilayer architecture to
add this a new decision making functionality. It provides requirements
engineers a way of exploring the software requirement specification by
combining requirement metrics and the probability values estimated by the
Bayesian network.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12638" title="Abstract">arXiv:2401.12638</a> [<a href="/pdf/2401.12638" title="Download PDF">pdf</a>, <a href="/format/2401.12638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On The Axioms Of $\mathcal{M},\mathcal{N}$-Adhesive Categories
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castelnovo%2C+D">Davide Castelnovo</a>, 
<a href="/search/cs?searchtype=author&query=Miculan%2C+M">Marino Miculan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">Adhesive and quasiadhesive categories provide a general framework for the
study of algebraic graph rewriting systems. In a quasiadhesive category any two
regular subobjects have a join which is again a regular subobject. Vice versa,
if regular monos are adhesive, then the existence of a regular join for any
pair of regular subobjects entails quasiadhesivity. It is also known
(quasi)adhesive categories can be embedded in a Grothendieck topos via a
functor preserving pullbacks and pushouts along (regular) monomorphisms. In
this paper we extend these results to $\mathcal{M}, \mathcal{N}$-adhesive
categories, a concept recently introduced to generalize the notion of
(quasi)adhesivity. We introduce the notion of $\mathcal{N}$-adhesive morphism,
which allows us to express $\mathcal{M}, \mathcal{N}$-adhesivity as a condition
on the subobjects's posets. Moreover, $\mathcal{N}$-adhesive morphisms allows
us to show how an $\mathcal{M},\mathcal{N}$-adhesive category can be embedded
into a Grothendieck topos, preserving pullbacks and $\mathcal{M},
\mathcal{N}$-pushouts.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12639" title="Abstract">arXiv:2401.12639</a> [<a href="/pdf/2401.12639" title="Download PDF">pdf</a>, <a href="/format/2401.12639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Matching with Memoization for Regexes with Look-around and  Atomic Grouping (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fujinami%2C+H">Hiroya Fujinami</a>, 
<a href="/search/cs?searchtype=author&query=Hasuo%2C+I">Ichiro Hasuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ESOP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Regular expression (regex) matching is fundamental in many applications,
especially in web services. However, matching by backtracking -- preferred by
most real-world implementations for its practical performance and backward
compatibility -- can suffer from so-called catastrophic backtracking, which
makes the number of backtracking super-linear and leads to the well-known ReDoS
vulnerability. Inspired by a recent algorithm by Davis et al. that runs in
linear time for (non-extended) regexes, we study efficient backtracking
matching for regexes with two common extensions, namely look-around and atomic
grouping. We present linear-time backtracking matching algorithms for these
extended regexes. Their efficiency relies on memoization, much like the one by
Davis et al.; we also strive for smaller memoization tables by carefully
trimming their range. Our experiments -- we used some real-world regexes with
the aforementioned extensions -- confirm the performance advantage of our
algorithms.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12643" title="Abstract">arXiv:2401.12643</a> [<a href="/pdf/2401.12643" title="Download PDF">pdf</a>, <a href="/format/2401.12643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gray-Box Fuzzing via Gradient Descent and Boolean Expression Coverage  (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jon%C3%A1%C5%A1%2C+M">Martin Jon&#xe1;&#x161;</a>, 
<a href="/search/cs?searchtype=author&query=Strej%C4%8Dek%2C+J">Jan Strej&#x10d;ek</a>, 
<a href="/search/cs?searchtype=author&query=Trt%C3%ADk%2C+M">Marek Trt&#xed;k</a>, 
<a href="/search/cs?searchtype=author&query=Urban%2C+L">Luk&#xe1;&#x161; Urban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">We present a novel gray-box fuzzing algorithm monitoring executions of
instructions converting numerical values to Boolean ones. An important class of
such instructions evaluate predicates, e.g., *cmp in LLVM. That alone allows us
to infer the input dependency (c.f. the taint analysis) during the fuzzing
on-the-fly with reasonable accuracy, which in turn enables an effective use of
the gradient descent on these instructions (to invert the result of their
evaluation). Although the fuzzing attempts to maximize the coverage of the
instructions, there is an interesting correlation with the standard branch
coverage, which we are able to achieve indirectly. The evaluation on Test-Comp
2023 benchmarks shows that our approach, despite being a pure gray-box fuzzing,
is able to compete with the leading tools in the competition, which combine
fuzzing with other powerful techniques like model checking, symbolic execution,
or abstract interpretation.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12644" title="Abstract">arXiv:2401.12644</a> [<a href="/pdf/2401.12644" title="Download PDF">pdf</a>, <a href="/format/2401.12644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Feature Mask Optimization for Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lorasdagi%2C+M+E">Mehmet E. Lorasdagi</a>, 
<a href="/search/cs?searchtype=author&query=Turali%2C+M+Y">Mehmet Y. Turali</a>, 
<a href="/search/cs?searchtype=author&query=Koc%2C+A+T">Ali T. Koc</a>, 
<a href="/search/cs?searchtype=author&query=Kozat%2C+S+S">Suleyman S. Kozat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We investigate feature selection problem for generic machine learning (ML)
models. We introduce a novel framework that selects features considering the
predictions of the model. Our framework innovates by using a novel feature
masking approach to eliminate the features during the selection process,
instead of completely removing them from the dataset. This allows us to use the
same ML model during feature selection, unlike other feature selection methods
where we need to train the ML model again as the dataset has different
dimensions on each iteration. We obtain the mask operator using the predictions
of the ML model, which offers a comprehensive view on the subsets of the
features essential for the predictive performance of the model. A variety of
approaches exist in the feature selection literature. However, no study has
introduced a training-free framework for a generic ML model to select features
while considering the importance of the feature subsets as a whole, instead of
focusing on the individual features. We demonstrate significant performance
improvements on the real-life datasets under different settings using LightGBM
and Multi-Layer Perceptron as our ML models. Additionally, we openly share the
implementation code for our methods to encourage the research and the
contributions in this area.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12645" title="Abstract">arXiv:2401.12645</a> [<a href="/pdf/2401.12645" title="Download PDF">pdf</a>, <a href="/ps/2401.12645" title="Download PostScript">ps</a>, <a href="/format/2401.12645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Robustness of Deep Learning-aided Symbol Detectors to Varying  Conditions and Imperfect Channel Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chin-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Karanov%2C+B">Boris Karanov</a>, 
<a href="/search/cs?searchtype=author&query=van+Houtum%2C+W">Wim van Houtum</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+W">Wu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+A">Alex Young</a>, 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+A">Alex Alvarado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted paper at IEEE Wireless Communications and Networking Conference (WCNC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Recently, a data-driven Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm tailored to
channels with intersymbol interference has been introduced. This so-called
BCJRNet algorithm utilizes neural networks to calculate channel likelihoods.
BCJRNet has demonstrated resilience against inaccurate channel tap estimations
when applied to a time-invariant channel with ideal exponential decay profiles.
However, its generalization capabilities for practically-relevant time-varying
channels, where the receiver can only access incorrect channel parameters,
remain largely unexplored. The primary contribution of this paper is to expand
upon the results from existing literature to encompass a variety of imperfect
channel knowledge cases that appear in real-world transmissions. Our findings
demonstrate that BCJRNet significantly outperforms the conventional BCJR
algorithm for stationary transmission scenarios when learning from noisy
channel data and with imperfect channel decay profiles. However, this advantage
is shown to diminish when the operating channel is also rapidly time-varying.
Our results also show the importance of memory assumptions for conventional
BCJR and BCJRNet. An underestimation of the memory largely degrades the
performance of both BCJR and BCJRNet, especially in a slow-decaying channel. To
mimic a situation closer to a practical scenario, we also combined channel tap
uncertainty with imperfect channel memory knowledge. Somewhat surprisingly, our
results revealed improved performance when employing the conventional BCJR with
an underestimated memory assumption. BCJRNet, on the other hand, showed a
consistent performance improvement as the level of accurate memory knowledge
increased.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12646" title="Abstract">arXiv:2401.12646</a> [<a href="/pdf/2401.12646" title="Download PDF">pdf</a>, <a href="/format/2401.12646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Cooperation under Uncertain Incentive Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orzan%2C+N">Nicole Orzan</a>, 
<a href="/search/cs?searchtype=author&query=Acar%2C+E">Erman Acar</a>, 
<a href="/search/cs?searchtype=author&query=Grossi%2C+D">Davide Grossi</a>, 
<a href="/search/cs?searchtype=author&query=R%C4%83dulescu%2C+R">Roxana R&#x103;dulescu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Understanding the emergence of cooperation in systems of computational agents
is crucial for the development of effective cooperative AI. Interaction among
individuals in real-world settings are often sparse and occur within a broad
spectrum of incentives, which often are only partially known. In this work, we
explore how cooperation can arise among reinforcement learning agents in
scenarios characterised by infrequent encounters, and where agents face
uncertainty about the alignment of their incentives with those of others. To do
so, we train the agents under a wide spectrum of environments ranging from
fully competitive, to fully cooperative, to mixed-motives. Under this type of
uncertainty we study the effects of mechanisms, such as reputation and
intrinsic rewards, that have been proposed in the literature to foster
cooperation in mixed-motives environments. Our findings show that uncertainty
substantially lowers the agents' ability to engage in cooperative behaviour,
when that would be the best course of action. In this scenario, the use of
effective reputation mechanisms and intrinsic rewards boosts the agents'
capability to act nearly-optimally in cooperative environments, while greatly
enhancing cooperation in mixed-motive environments as well.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12648" title="Abstract">arXiv:2401.12648</a> [<a href="/pdf/2401.12648" title="Download PDF">pdf</a>, <a href="/format/2401.12648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistency Enhancement-Based Deep Multiview Clustering via Contrastive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hua Mao</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+W+L">Wai Lok Woo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xi Peng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Multiview clustering (MVC) segregates data samples into meaningful clusters
by synthesizing information across multiple views. Moreover, deep
learning-based methods have demonstrated their strong feature learning
capabilities in MVC scenarios. However, effectively generalizing feature
representations while maintaining consistency is still an intractable problem.
In addition, most existing deep clustering methods based on contrastive
learning overlook the consistency of the clustering representations during the
clustering process. In this paper, we show how the above problems can be
overcome and propose a consistent enhancement-based deep MVC method via
contrastive learning (CCEC). Specifically, semantic connection blocks are
incorporated into a feature representation to preserve the consistent
information among multiple views. Furthermore, the representation process for
clustering is enhanced through spectral clustering, and the consistency across
multiple views is improved. Experiments conducted on five datasets demonstrate
the effectiveness and superiority of our method in comparison with the
state-of-the-art (SOTA) methods. The code for this method can be accessed at
https://anonymous.4open.science/r/CCEC-E84E/.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12649" title="Abstract">arXiv:2401.12649</a> [<a href="/pdf/2401.12649" title="Download PDF">pdf</a>, <a href="/format/2401.12649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Space-time unfitted finite elements on moving explicit geometry  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Badia%2C+S">Santiago Badia</a>, 
<a href="/search/cs?searchtype=author&query=Martorell%2C+P+A">Pere A. Martorell</a>, 
<a href="/search/cs?searchtype=author&query=Verdugo%2C+F">Francesc Verdugo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This work proposes a novel variational approximation of partial differential
equations on moving geometries determined by explicit boundary representations.
The benefits of the proposed formulation are the ability to handle large
displacements of explicitly represented domain boundaries without generating
body-fitted meshes and remeshing techniques. For the space discretization, we
use a background mesh and an unfitted method that relies on integration on cut
cells only. We perform this intersection by using clipping algorithms. To deal
with the mesh movement, we pullback the equations to a reference configuration
(the spatial mesh at the initial time slab times the time interval) that is
constant in time. This way, the geometrical intersection algorithm is only
required in 3D, another key property of the proposed scheme. At the end of the
time slab, we compute the deformed mesh, intersect the deformed boundary with
the background mesh, and consider an exact transfer operator between meshes to
compute jump terms in the time discontinuous Galerkin integration. The transfer
is also computed using geometrical intersection algorithms. We demonstrate the
applicability of the method to fluid problems around rotating (2D and 3D)
geometries described by oriented boundary meshes. We also provide a set of
numerical experiments that show the optimal convergence of the method.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12652" title="Abstract">arXiv:2401.12652</a> [<a href="/pdf/2401.12652" title="Download PDF">pdf</a>, <a href="/format/2401.12652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arno%2C+H">Henri Arno</a>, 
<a href="/search/cs?searchtype=author&query=Mulier%2C+K">Klaas Mulier</a>, 
<a href="/search/cs?searchtype=author&query=Baeck%2C+J">Joke Baeck</a>, 
<a href="/search/cs?searchtype=author&query=Demeester%2C+T">Thomas Demeester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at the 6th Workshop on Financial Technology and Natural Language Processing (FinNLP) @ IJCNLP-AACL 2023 in Bali, Indonesia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computational Finance (q-fin.CP)

</div>
<p class="mathjax">In this paper, we present ECL, a novel multi-modal dataset containing the
textual and numerical data from corporate 10K filings and associated binary
bankruptcy labels. Furthermore, we develop and critically evaluate several
classical and neural bankruptcy prediction models using this dataset. Our
findings suggest that the information contained in each data modality is
complementary for bankruptcy prediction. We also see that the binary bankruptcy
prediction target does not enable our models to distinguish next year
bankruptcy from an unhealthy financial situation resulting in bankruptcy in
later years. Finally, we explore the use of LLMs in the context of our task. We
show how GPT-based models can be used to extract meaningful summaries from the
textual data but zero-shot bankruptcy prediction results are poor. All
resources required to access and update the dataset or replicate our
experiments are available on github.com/henriarnoUG/ECL.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12653" title="Abstract">arXiv:2401.12653</a> [<a href="/pdf/2401.12653" title="Download PDF">pdf</a>, <a href="/ps/2401.12653" title="Download PostScript">ps</a>, <a href="/format/2401.12653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Popular Matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+M">Martin Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Gangam%2C+R+R">Rohith Reddy Gangam</a>, 
<a href="/search/cs?searchtype=author&query=Shahkar%2C+P">Parnian Shahkar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in: Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We study popularity for matchings under preferences. This solution concept
captures matchings that do not lose against any other matching in a majority
vote by the agents. A popular matching is said to be robust if it is popular
among multiple instances. We present a polynomial-time algorithm for deciding
whether there exists a robust popular matching if instances only differ with
respect to the preferences of a single agent while obtaining NP-completeness if
two instances differ only by a downward shift of one alternative by four
agents. Moreover, we find a complexity dichotomy based on preference
completeness for the case where instances differ by making some options
unavailable.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12656" title="Abstract">arXiv:2401.12656</a> [<a href="/pdf/2401.12656" title="Download PDF">pdf</a>, <a href="/format/2401.12656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with  Multi-Granular Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+W">Wenqian Cui</a>, 
<a href="/search/cs?searchtype=author&query=Sarmento%2C+P">Pedro Sarmento</a>, 
<a href="/search/cs?searchtype=author&query=Barthet%2C+M">Mathieu Barthet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint is licensed under a Creative Commons Attribution 4.0 International License (CC BY 4.0). The Version of Record of this contribution is published in Proceedings of EvoMUSART: International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Loopable music generation systems enable diverse applications, but they often
lack controllability and customization capabilities. We argue that enhancing
controllability can enrich these models, with emotional expression being a
crucial aspect for both creators and listeners. Hence, building upon LooperGP,
a loopable tablature generation model, this paper explores endowing systems
with control over conveyed emotions. To enable such conditional generation, we
propose integrating musical knowledge by utilizing multi-granular semantic and
musical features during model training and inference. Specifically, we
incorporate song-level features (Emotion Labels, Tempo, and Mode) and bar-level
features (Tonal Tension) together to guide emotional expression. Through
algorithmic and human evaluations, we demonstrate the approach's effectiveness
in producing music conveying two contrasting target emotions, happiness and
sadness. An ablation study is also conducted to clarify the contributing
factors behind our approach's results.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12662" title="Abstract">arXiv:2401.12662</a> [<a href="/pdf/2401.12662" title="Download PDF">pdf</a>, <a href="/format/2401.12662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Human Expertise in Continuous Spaces: A Novel Interactive  Bayesian Optimization Framework with Preference Expected Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feith%2C+N">Nikolaus Feith</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+E">Elmar Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Interactive Machine Learning (IML) seeks to integrate human expertise into
machine learning processes. However, most existing algorithms cannot be applied
to Realworld Scenarios because their state spaces and/or action spaces are
limited to discrete values. Furthermore, the interaction of all existing
methods is restricted to deciding between multiple proposals. We therefore
propose a novel framework based on Bayesian Optimization (BO). Interactive
Bayesian Optimization (IBO) enables collaboration between machine learning
algorithms and humans. This framework captures user preferences and provides an
interface for users to shape the strategy by hand. Additionally, we've
incorporated a new acquisition function, Preference Expected Improvement (PEI),
to refine the system's efficiency using a probabilistic model of the user
preferences. Our approach is geared towards ensuring that machines can benefit
from human expertise, aiming for a more aligned and effective learning process.
In the course of this work, we applied our method to simulations and in a real
world task using a Franka Panda robot to show human-robot collaboration.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12664" title="Abstract">arXiv:2401.12664</a> [<a href="/pdf/2401.12664" title="Download PDF">pdf</a>, <a href="/format/2401.12664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial and rational interpolation: potential, barycentric weights,  and Lebesgue constants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+K">Kelong Zhao</a>, 
<a href="/search/math?searchtype=author&query=Xiang%2C+S">Shuhuang Xiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we focus on barycentric weights and Lebesgue constants for
Lagrange interpolation of arbitrary node distributions on \([-1,1]\). The
following three main works are included: estimates of upper and lower bounds on
the barycentric weights are given in terms of the logarithmic potential
function; for interpolation of non-equilibrium potentials, lower bounds with
exponentially growing parts of Lebesgue constants are given; and for
interpolation consistent with equilibrium potentials, non-exponentially growing
upper bounds on their Lebesgue constants are given. Based on the work in this
paper, we can discuss the behavior of the Lebesgue constant and the existence
of exponential convergence in a unified manner in the framework of potential
theory.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12665" title="Abstract">arXiv:2401.12665</a> [<a href="/pdf/2401.12665" title="Download PDF">pdf</a>, <a href="/format/2401.12665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengze Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jianjian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuhan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Chongjun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, foundational models such as CLIP and SAM have shown promising
performance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However,
either CLIP-based or SAM-based ZSAS methods still suffer from non-negligible
key drawbacks: 1) CLIP primarily focuses on global feature alignment across
different inputs, leading to imprecise segmentation of local anomalous parts;
2) SAM tends to generate numerous redundant masks without proper prompt
constraints, resulting in complex post-processing requirements. In this work,
we innovatively propose a CLIP and SAM collaboration framework called ClipSAM
for ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understanding
capability for anomaly localization and rough segmentation, which is further
used as the prompt constraints for SAM to refine the anomaly segmentation
results. In details, we introduce a crucial Unified Multi-scale Cross-modal
Interaction (UMCI) module for interacting language with visual features at
multiple scales of CLIP to reason anomaly positions. Then, we design a novel
Multi-level Mask Refinement (MMR) module, which utilizes the positional
information as multi-level prompts for SAM to acquire hierarchical levels of
masks and merges them. Extensive experiments validate the effectiveness of our
approach, achieving the optimal segmentation performance on the MVTec-AD and
VisA datasets.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12666" title="Abstract">arXiv:2401.12666</a> [<a href="/pdf/2401.12666" title="Download PDF">pdf</a>, <a href="/format/2401.12666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EL-VIT: Probing Vision Transformer with Interactive Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+P">Peifeng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chaoran Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhida Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Nowadays, Vision Transformer (ViT) is widely utilized in various computer
vision tasks, owing to its unique self-attention mechanism. However, the model
architecture of ViT is complex and often challenging to comprehend, leading to
a steep learning curve. ViT developers and users frequently encounter
difficulties in interpreting its inner workings. Therefore, a visualization
system is needed to assist ViT users in understanding its functionality. This
paper introduces EL-VIT, an interactive visual analytics system designed to
probe the Vision Transformer and facilitate a better understanding of its
operations. The system consists of four layers of visualization views. The
first three layers include model overview, knowledge background graph, and
model detail view. These three layers elucidate the operation process of ViT
from three perspectives: the overall model architecture, detailed explanation,
and mathematical operations, enabling users to understand the underlying
principles and the transition process between layers. The fourth interpretation
view helps ViT users and experts gain a deeper understanding by calculating the
cosine similarity between patches. Our two usage scenarios demonstrate the
effectiveness and usability of EL-VIT in helping ViT users understand the
working mechanism of ViT.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12671" title="Abstract">arXiv:2401.12671</a> [<a href="/pdf/2401.12671" title="Download PDF">pdf</a>, <a href="/format/2401.12671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context Matters: Pushing the Boundaries of Open-Ended Answer Generation  with Graph-Structured Knowledge Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Somnath Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+A">Amruit Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Layek%2C+S">Sayan Layek</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+A">Avik Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Hazra%2C+R">Rima Hazra</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Animesh Mukherjee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the continuously advancing AI landscape, crafting context-rich and
meaningful responses via Large Language Models (LLMs) is essential. Researchers
are becoming more aware of the challenges that LLMs with fewer parameters
encounter when trying to provide suitable answers to open-ended questions. To
address these hurdles, the integration of cutting-edge strategies, augmentation
of rich external domain knowledge to LLMs, offers significant improvements.
This paper introduces a novel framework that combines graph-driven context
retrieval in conjunction to knowledge graphs based enhancement, honing the
proficiency of LLMs, especially in domain specific community question answering
platforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on
various LLMs with different parameter sizes to evaluate their ability to ground
knowledge and determine factual accuracy in answers to open-ended questions.
Our methodology GraphContextGen consistently outperforms dominant text-based
retrieval systems, demonstrating its robustness and adaptability to a larger
number of use cases. This advancement highlights the importance of pairing
context rich data retrieval with LLMs, offering a renewed approach to knowledge
sourcing and generation in AI systems. We also show that, due to rich
contextual data retrieval, the crucial entities, along with the generated
answer, remain factually coherent with the gold answer.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12672" title="Abstract">arXiv:2401.12672</a> [<a href="/pdf/2401.12672" title="Download PDF">pdf</a>, <a href="/format/2401.12672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatGraph: Chat with Your Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Sen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lyu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+X">Xiaojun Ren</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yafei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Graph analysis is fundamental in real-world applications. Traditional
approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to
interact with graph data. However, these methods either require users to
possess high programming skills or support only a limited range of graph
analysis functionalities. To address the limitations, we propose a large
language model (LLM)-based framework called ChatGraph. With ChatGraph, users
can interact with graphs through natural language, making it easier to use and
more flexible than traditional approaches. The core of ChatGraph lies in
generating chains of graph analysis APIs based on the understanding of the
texts and graphs inputted in the user prompts. To achieve this, ChatGraph
consists of three main modules: an API retrieval module that searches for
relevant APIs, a graph-aware LLM module that enables the LLM to comprehend
graphs, and an API chain-oriented finetuning module that guides the LLM in
generating API chains.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12681" title="Abstract">arXiv:2401.12681</a> [<a href="/pdf/2401.12681" title="Download PDF">pdf</a>, <a href="/format/2401.12681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Yunhao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yisheng Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Kriging aims at estimating the attributes of unsampled geo-locations from
observations in the spatial vicinity or physical connections, which helps
mitigate skewed monitoring caused by under-deployed sensors. Existing works
assume that neighbors' information offers the basis for estimating the
attributes of the unobserved target while ignoring non-neighbors. However,
non-neighbors could also offer constructive information, and neighbors could
also be misleading. To this end, we propose ``Contrastive-Prototypical''
self-supervised learning for Kriging (KCP) to refine valuable information from
neighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we
conduct the Kriging task from a new perspective of representation: we aim to
first learn robust and general representations and then recover attributes from
representations. A neighboring contrastive module is designed that coarsely
learns the representations by narrowing the representation distance between the
target and its neighbors while pushing away the non-neighbors. In parallel, a
prototypical module is introduced to identify similar representations via
exchanged prediction, thus refining the misleading neighbors and recycling the
useful non-neighbors from the neighboring contrast component. As a result, not
all the neighbors and some of the non-neighbors will be used to infer the
target. To encourage the two modules above to learn general and robust
representations, we design an adaptive augmentation module that incorporates
data-driven attribute augmentation and centrality-based topology augmentation
over the spatiotemporal Kriging graph data. Extensive experiments on real-world
datasets demonstrate the superior performance of KCP compared to its peers with
6% improvements and exceptional transferability and robustness. The code is
available at https://github.com/bonaldli/KCP
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12683" title="Abstract">arXiv:2401.12683</a> [<a href="/pdf/2401.12683" title="Download PDF">pdf</a>, <a href="/format/2401.12683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLpowershap: Logistic Loss-based Automated Shapley Values Feature  Selection Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madakkatel%2C+I">Iqbal Madakkatel</a>, 
<a href="/search/cs?searchtype=author&query=Hypp%C3%B6nen%2C+E">Elina Hypp&#xf6;nen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Shapley values have been used extensively in machine learning, not only to
explain black box machine learning models, but among other tasks, also to
conduct model debugging, sensitivity and fairness analyses and to select
important features for robust modelling and for further follow-up analyses.
Shapley values satisfy certain axioms that promote fairness in distributing
contributions of features toward prediction or reducing error, after accounting
for non-linear relationships and interactions when complex machine learning
models are employed. Recently, a number of feature selection methods utilising
Shapley values have been introduced. Here, we present a novel feature selection
method, LLpowershap, which makes use of loss-based Shapley values to identify
informative features with minimal noise among the selected sets of features.
Our simulation results show that LLpowershap not only identifies higher number
of informative features but outputs fewer noise features compared to other
state-of-the-art feature selection methods. Benchmarking results on four
real-world datasets demonstrate higher or at par predictive performance of
LLpowershap compared to other Shapley based wrapper methods, or filter methods.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12686" title="Abstract">arXiv:2401.12686</a> [<a href="/pdf/2401.12686" title="Download PDF">pdf</a>, <a href="/format/2401.12686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fabian%2C+C">Christian Fabian</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+K">Kai Cui</a>, 
<a href="/search/cs?searchtype=author&query=Koeppl%2C+H">Heinz Koeppl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning the behavior of large agent populations is an important task for
numerous research areas. Although the field of multi-agent reinforcement
learning (MARL) has made significant progress towards solving these systems,
solutions for many agents often remain computationally infeasible and lack
theoretical guarantees. Mean Field Games (MFGs) address both of these issues
and can be extended to Graphon MFGs (GMFGs) to include network structures
between agents. Despite their merits, the real world applicability of GMFGs is
limited by the fact that graphons only capture dense graphs. Since most
empirically observed networks show some degree of sparsity, such as power law
graphs, the GMFG framework is insufficient for capturing these network
topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which
builds on the graph theoretical concept of graphexes. Graphexes are the
limiting objects to sparse graph sequences that also have other desirable
features such as the small world property. Learning equilibria in these games
is challenging due to the rich and sparse structure of the underlying graphs.
To tackle these challenges, we design a new learning algorithm tailored to the
GXMFG setup. This hybrid graphex learning approach leverages that the system
mainly consists of a highly connected core and a sparse periphery. After
defining the system and providing a theoretical analysis, we state our learning
approach and demonstrate its learning capabilities on both synthetic graphs and
real-world networks. This comparison shows that our GXMFG learning algorithm
successfully extends MFGs to a highly relevant class of hard, realistic
learning problems that are not accurately addressed by current MARL and MFG
methods.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12687" title="Abstract">arXiv:2401.12687</a> [<a href="/pdf/2401.12687" title="Download PDF">pdf</a>, <a href="/format/2401.12687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVL Calibration using Data-driven Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yampolsky%2C+Z">Zeev Yampolsky</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+I">Itzik Klein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages , 3 figures , 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Autonomous underwater vehicles (AUVs) are used in a wide range of underwater
applications, ranging from seafloor mapping to industrial operations. While
underwater, the AUV navigation solution commonly relies on the fusion between
inertial sensors and Doppler velocity logs (DVL). To achieve accurate DVL
measurements a calibration procedure should be conducted before the mission
begins. Model-based calibration approaches include filtering approaches
utilizing global navigation satellite system signals. In this paper, we propose
an end-to-end deep-learning framework for the calibration procedure. Using
stimulative data, we show that our proposed approach outperforms model-based
approaches by 35% in accuracy and 80% in the required calibration time.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12689" title="Abstract">arXiv:2401.12689</a> [<a href="/pdf/2401.12689" title="Download PDF">pdf</a>, <a href="/format/2401.12689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based Automated Model Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+R">Ru Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Heming Zou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yawen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zenan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The conventional evaluation protocols on machine learning models rely heavily
on a labeled, i.i.d-assumed testing dataset, which is not often present in real
world applications. The Automated Model Evaluation (AutoEval) shows an
alternative to this traditional workflow, by forming a proximal prediction
pipeline of the testing performance without the presence of ground-truth
labels. Despite its recent successes, the AutoEval frameworks still suffer from
an overconfidence issue, substantial storage and computational cost. In that
regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that
allows the AutoEval framework to be both more efficient and effective. The core
of the MDE is to establish a meta-distribution statistic, on the information
(energy) associated with individual samples, then offer a smoother
representation enabled by energy-based learning. We further provide our
theoretical insights by connecting the MDE with the classification loss. We
provide extensive experiments across modalities, datasets and different
architectural backbones to validate MDE's validity, together with its
superiority compared with prior approaches. We also prove MDE's versatility by
showing its seamless integration with large-scale models, and easy adaption to
learning scenarios with noisy- or imbalanced- labels.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12690" title="Abstract">arXiv:2401.12690</a> [<a href="/pdf/2401.12690" title="Download PDF">pdf</a>, <a href="/format/2401.12690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Availability-aware Service Placement Policy in Fog Computing Based on  Graph Partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lera%2C+I">Isaac Lera</a>, 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+C">Carlos Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Juiz%2C+C">Carlos Juiz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Internet of Things Journal. 6 - 2, pp. 3641-3651. IEEE-Inst
  Electrical Electronics Engineers Inc, 01/04/2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">This paper presents a policy for service placement of fog applications
inspired on complex networks and graph theory. We propose a twofold partition
process based on communities for the partition of the fog devices and based on
transitive closures for the application services partition. The allocation of
the services is performed sequentially by, firstly, mapping applications to
device communities and, secondly, mapping service transitive closures to fog
devices in the community. The underlying idea is to place as many inter-related
services as possible in the most nearby devices to the users. The optimization
objectives are the availability of the applications and the Quality of Service
(QoS) of the system, measured as the number of requests that are executed
before the application deadlines. We compared our solution with an Integer
Linear Programming approach, and the simulation results showed that our
proposal obtains higher QoS and availability when fails in the nodes are
considered.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12694" title="Abstract">arXiv:2401.12694</a> [<a href="/pdf/2401.12694" title="Download PDF">pdf</a>, <a href="/format/2401.12694" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pragmatic Communication in Multi-Agent Collaborative Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+X">Xianghe Pang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaoqi Qin</a>, 
<a href="/search/cs?searchtype=author&query=Eldar%2C+Y+C">Yonina C. Eldar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Ping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Collaborative perception allows each agent to enhance its perceptual
abilities by exchanging messages with others. It inherently results in a
trade-off between perception ability and communication costs. Previous works
transmit complete full-frame high-dimensional feature maps among agents,
resulting in substantial communication costs. To promote communication
efficiency, we propose only transmitting the information needed for the
collaborator's downstream task. This pragmatic communication strategy focuses
on three key aspects: i) pragmatic message selection, which selects
task-critical parts from the complete data, resulting in spatially and
temporally sparse feature vectors; ii) pragmatic message representation, which
achieves pragmatic approximation of high-dimensional feature vectors with a
task-adaptive dictionary, enabling communicating with integer indices; iii)
pragmatic collaborator selection, which identifies beneficial collaborators,
pruning unnecessary communication links. Following this strategy, we first
formulate a mathematical optimization framework for the
perception-communication trade-off and then propose PragComm, a multi-agent
collaborative perception system with two key components: i) single-agent
detection and tracking and ii) pragmatic collaboration. The proposed PragComm
promotes pragmatic communication and adapts to a wide range of communication
conditions. We evaluate PragComm for both collaborative 3D object detection and
tracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V and
V2X-SIM2.0. PragComm consistently outperforms previous methods with more than
32.7K times lower communication volume on OPV2V. Code is available at
github.com/PhyllisH/PragComm.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12698" title="Abstract">arXiv:2401.12698</a> [<a href="/pdf/2401.12698" title="Download PDF">pdf</a>, <a href="/ps/2401.12698" title="Download PostScript">ps</a>, <a href="/format/2401.12698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Algorithm for Multi-Objective Optimization of Container  Allocation in Cloud Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+C">Carlos Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Lera%2C+I">Isaac Lera</a>, 
<a href="/search/cs?searchtype=author&query=Juiz%2C+C">Carlos Juiz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Grid Computing. 16-1, pp. 113-135. Springer, 01/03/2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The use of containers in cloud architectures has become widespread because of
advantages such as limited overhead, easier and faster deployment and higher
portability. Moreover, they are a suitable architectural solution for
deployment of applications created using a microservices development pattern.
Despite the large number of solutions and implementations, open issues have not
been addressed in container automation and management. Container resource
allocation influences system performance and resource consumption so it is a
key factor for cloud providers. We propose a genetic algorithm approach, using
the Non-dominated Sorting Genetic Algorithm-II (NSGA-II), to optimize container
allocation and elasticity management due to the good results obtained with this
algorithm in other resource management optimization problems in cloud
architectures. The optimization has been focused on a tight use of the
resources and a reduction of the network overhead and system failure rate. A
model for cloud cluster, containers, microservices and four optimization
objectives is presented. Experimental results have shown that our approach is a
suitable solution to address the problem of container allocation and elasticity
and it obtains better objectives values than the container management policies
implemented in Kubernetes.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12699" title="Abstract">arXiv:2401.12699</a> [<a href="/pdf/2401.12699" title="Download PDF">pdf</a>, <a href="/format/2401.12699" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A lightweight decentralized service placement policy for performance  optimization in fog computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guerrero%2C+C">Carlos Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Lera%2C+I">Isaac Lera</a>, 
<a href="/search/cs?searchtype=author&query=Juiz%2C+C">Carlos Juiz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JOURNAL OF AMBIENT INTELLIGENCE AND HUMANIZED COMPUTING. 10 - 6,
  pp. 2447 - 2464. SPRINGER HEIDELBERG, 01/06/2019
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">A decentralized optimization policy for service placement in fog computing is
presented. The optimization is addressed to place most popular services as
closer to the users as possible. The experimental validation is done in the
iFogSim simulator and by comparing our algorithm with the simulator's built-in
policy. The simulation is characterized by modeling a microservice-based
application for different experiment sizes. Results showed that our
decentralized algorithm places most popular services closer to users, improving
network usage and service latency of the most requested applications, at the
expense of a latency increment for the less requested services and a greater
number of service migrations.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12700" title="Abstract">arXiv:2401.12700</a> [<a href="/pdf/2401.12700" title="Download PDF">pdf</a>, <a href="/format/2401.12700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing Recommender System via Cooperative Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenwang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Defu Lian</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+E">Enhong Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2210.13762">arXiv:2210.13762</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Recommender systems are often susceptible to well-crafted fake profiles,
leading to biased recommendations. Among existing defense methods,
data-processing-based methods inevitably exclude normal samples, while
model-based methods struggle to enjoy both generalization and robustness. To
this end, we suggest integrating data processing and the robust model to
propose a general framework, Triple Cooperative Defense (TCD), which employs
three cooperative models that mutually enhance data and thereby improve
recommendation robustness. Furthermore, Considering that existing attacks
struggle to balance bi-level optimization and efficiency, we revisit poisoning
attacks in recommender systems and introduce an efficient attack strategy,
Co-training Attack (Co-Attack), which cooperatively optimizes the attack
optimization and model training, considering the bi-level setting while
maintaining attack efficiency. Moreover, we reveal a potential reason for the
insufficient threat of existing attacks is their default assumption of
optimizing attacks in undefended scenarios. This overly optimistic setting
limits the potential of attacks. Consequently, we put forth a Game-based
Co-training Attack (GCoAttack), which frames the proposed CoAttack and TCD as a
game-theoretic process, thoroughly exploring CoAttack's attack potential in the
cooperative training of attack and defense. Extensive experiments on three real
datasets demonstrate TCD's superiority in enhancing model robustness.
Additionally, we verify that the two proposed attack strategies significantly
outperform existing attacks, with game-based GCoAttack posing a greater
poisoning threat than CoAttack.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12703" title="Abstract">arXiv:2401.12703</a> [<a href="/pdf/2401.12703" title="Download PDF">pdf</a>, <a href="/ps/2401.12703" title="Download PostScript">ps</a>, <a href="/format/2401.12703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Test Suites for Active Automata Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruger%2C+L">Loes Kruger</a>, 
<a href="/search/cs?searchtype=author&query=Junges%2C+S">Sebastian Junges</a>, 
<a href="/search/cs?searchtype=author&query=Rot%2C+J">Jurriaan Rot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended paper for TACAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">A bottleneck in modern active automata learning is to test whether a
hypothesized Mealy machine correctly describes the system under learning. The
search space for possible counterexamples is given by so-called test suites,
consisting of input sequences that have to be checked to decide whether a
counterexample exists. This paper shows that significantly smaller test suites
suffice under reasonable assumptions on the structure of the black box. These
smaller test suites help to refute false hypotheses during active automata
learning, even when the assumptions do not hold. We combine multiple test
suites using a multi-armed bandit setup that adaptively selects a test suite.
An extensive empirical evaluation shows the efficacy of our approach. For small
to medium-sized models, the performance gain is limited. However, the approach
allows learning models from large, industrial case studies that were beyond the
reach of known methods.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12707" title="Abstract">arXiv:2401.12707</a> [<a href="/pdf/2401.12707" title="Download PDF">pdf</a>, <a href="/ps/2401.12707" title="Download PostScript">ps</a>, <a href="/format/2401.12707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized Data-driven Consensus Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chang%2C+Z">Zeze Chang</a>, 
<a href="/search/eess?searchtype=author&query=Jiao%2C+J">Junjie Jiao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zhongkui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper considers a localized data-driven consensus problem for
leader-follower multi-agent systems with unknown discrete-time agent dynamics,
where each follower computes its local control gain using only their locally
collected state and input data. Both noiseless and noisy data-driven consensus
protocols are presented, which can handle the challenge of the heterogeneity in
control gains caused by the localized data sampling and achieve leader-follower
consensus. The design of these data-driven consensus protocols involves
low-dimensional linear matrix inequalities. In addition, the results are
extended to the case where only the leader's data are collected and exploited.
The effectiveness of the proposed methods is illustrated via simulation
examples.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12708" title="Abstract">arXiv:2401.12708</a> [<a href="/pdf/2401.12708" title="Download PDF">pdf</a>, <a href="/format/2401.12708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Neural Network Benchmarks for Selective Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pugnana%2C+A">Andrea Pugnana</a>, 
<a href="/search/cs?searchtype=author&query=Perini%2C+L">Lorenzo Perini</a>, 
<a href="/search/cs?searchtype=author&query=Davis%2C+J">Jesse Davis</a>, 
<a href="/search/cs?searchtype=author&query=Ruggieri%2C+S">Salvatore Ruggieri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">With the increasing deployment of machine learning models in many
socially-sensitive tasks, there is a growing demand for reliable and
trustworthy predictions. One way to accomplish these requirements is to allow a
model to abstain from making a prediction when there is a high risk of making
an error. This requires adding a selection mechanism to the model, which
selects those examples for which the model will provide a prediction. The
selective classification framework aims to design a mechanism that balances the
fraction of rejected predictions (i.e., the proportion of examples for which
the model does not make a prediction) versus the improvement in predictive
performance on the selected predictions. Multiple selective classification
frameworks exist, most of which rely on deep neural network architectures.
However, the empirical evaluation of the existing approaches is still limited
to partial comparisons among methods and settings, providing practitioners with
little insight into their relative merits. We fill this gap by benchmarking 18
baselines on a diverse set of 44 datasets that includes both image and tabular
data. Moreover, there is a mix of binary and multiclass tasks. We evaluate
these approaches using several criteria, including selective error rate,
empirical coverage, distribution of rejected instance's classes, and
performance on out-of-distribution instances. The results indicate that there
is not a single clear winner among the surveyed baselines, and the best method
depends on the users' objectives.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12711" title="Abstract">arXiv:2401.12711</a> [<a href="/pdf/2401.12711" title="Download PDF">pdf</a>, <a href="/format/2401.12711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Redundancy Matters: Machine Teaching of Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferri%2C+C">C&#xe8;sar Ferri</a>, 
<a href="/search/cs?searchtype=author&query=Garigliotti%2C+D">Dario Garigliotti</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A5vardstun%2C+B+A+T">Brigt Arve Toppe H&#xe5;vardstun</a>, 
<a href="/search/cs?searchtype=author&query=Hern%C3%A1ndez-Orallo%2C+J">Jos&#xe8; Hern&#xe1;ndez-Orallo</a>, 
<a href="/search/cs?searchtype=author&query=Telle%2C+J+A">Jan Arne Telle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 3 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In traditional machine teaching, a teacher wants to teach a concept to a
learner, by means of a finite set of examples, the witness set. But concepts
can have many equivalent representations. This redundancy strongly affects the
search space, to the extent that teacher and learner may not be able to easily
determine the equivalence class of each representation. In this common
situation, instead of teaching concepts, we explore the idea of teaching
representations. We work with several teaching schemas that exploit
representation and witness size (Eager, Greedy and Optimal) and analyze the
gains in teaching effectiveness for some representational languages (DNF
expressions and Turing-complete P3 programs). Our theoretical and experimental
results indicate that there are various types of redundancy, handled better by
the Greedy schema introduced here than by the Eager schema, although both can
be arbitrarily far away from the Optimal. For P3 programs we found that witness
sets are usually smaller than the programs they identify, which is an
illuminating justification of why machine teaching from examples makes sense at
all.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12713" title="Abstract">arXiv:2401.12713</a> [<a href="/pdf/2401.12713" title="Download PDF">pdf</a>, <a href="/format/2401.12713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generating Unsupervised Abstractive Explanations for Rumour Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bilal%2C+I+M">Iman Munire Bilal</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>, 
<a href="/search/cs?searchtype=author&query=Procter%2C+R">Rob Procter</a>, 
<a href="/search/cs?searchtype=author&query=Liakata%2C+M">Maria Liakata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The task of rumour verification in social media concerns assessing the
veracity of a claim on the basis of conversation threads that result from it.
While previous work has focused on predicting a veracity label, here we
reformulate the task to generate model-centric, free-text explanations of a
rumour's veracity. We follow an unsupervised approach by first utilising
post-hoc explainability methods to score the most important posts within a
thread and then we use these posts to generate informative explanatory
summaries by employing template-guided summarisation. To evaluate the
informativeness of the explanatory summaries, we exploit the few-shot learning
capabilities of a large language model (LLM). Our experiments show that LLMs
can have similar agreement to humans in evaluating summaries. Importantly, we
show that explanatory abstractive summaries are more informative and better
reflect the predicted rumour veracity than just using the highest ranking posts
in the thread.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12714" title="Abstract">arXiv:2401.12714</a> [<a href="/pdf/2401.12714" title="Download PDF">pdf</a>, <a href="/format/2401.12714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of large language models for assessing code maintainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dillmann%2C+M">Marc Dillmann</a>, 
<a href="/search/cs?searchtype=author&query=Siebert%2C+J">Julien Siebert</a>, 
<a href="/search/cs?searchtype=author&query=Trendowicz%2C+A">Adam Trendowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Increased availability of open-source software repositories and recent
advances in code analysis using large language models (LLMs) has triggered a
wave of new work to automate software engineering tasks that were previously
very difficult to automate. In this paper, we investigate a recent line of work
that hypothesises that comparing the probability of code generated by LLMs with
the probability the current code would have had can indicate potential quality
problems. We investigate the association between the cross-entropy of code
generated by ten different models (based on GPT2 and Llama2) and the following
quality aspects: readability, understandability, complexity, modularisation,
and overall maintainability assessed by experts and available in an benchmark
dataset. Our results show that, controlling for the number of logical lines of
codes (LLOC), cross-entropy computed by LLMs is indeed a predictor of
maintainability on a class level (the higher the cross-entropy the lower the
maintainability). However, this relation is reversed when one does not control
for LLOC (e.g., comparing small classes with longer ones). Furthermore, while
the complexity of LLMs affects the range of cross-entropy (smaller models tend
to have a wider range of cross-entropy), this plays a significant role in
predicting maintainability aspects. Our study limits itself on ten different
pretrained models (based on GPT2 and Llama2) and on maintainability aspects
collected by Schnappinger et al. When controlling for logical lines of code
(LLOC), cross-entropy is a predictor of maintainability. However, while related
work has shown the potential usefulness of cross-entropy at the level of tokens
or short sequences, at the class level this criterion alone may prove
insufficient to predict maintainability and further research is needed to make
best use of this information in practice.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12720" title="Abstract">arXiv:2401.12720</a> [<a href="/pdf/2401.12720" title="Download PDF">pdf</a>, <a href="/format/2401.12720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive View of the Biases of Toxicity and Sentiment Analysis  Methods Towards Utterances with African American English Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Resende%2C+G+H">Guilherme H. Resende</a>, 
<a href="/search/cs?searchtype=author&query=Nery%2C+L+F">Luiz F. Nery</a>, 
<a href="/search/cs?searchtype=author&query=Benevenuto%2C+F">Fabr&#xed;cio Benevenuto</a>, 
<a href="/search/cs?searchtype=author&query=Zannettou%2C+S">Savvas Zannettou</a>, 
<a href="/search/cs?searchtype=author&query=Figueiredo%2C+F">Flavio Figueiredo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Language is a dynamic aspect of our culture that changes when expressed in
different technologies/communities. Online social networks have enabled the
diffusion and evolution of different dialects, including African American
English (AAE). However, this increased usage is not without barriers. One
particular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity
(Google's Perspective and the open-source Detoxify) methods present biases
towards utterances with AAE expressions. Consider Google's Perspective to
understand bias. Here, an utterance such as ``All n*ggers deserve to die
respectfully. The police murder us.'' it reaches a higher toxicity than
``African-Americans deserve to die respectfully. The police murder us.''. This
score difference likely arises because the tool cannot understand the
re-appropriation of the term ``n*gger''. One explanation for this bias is that
AI models are trained on limited datasets, and using such a term in training
data is more likely to appear in a toxic utterance. While this may be
plausible, the tool will make mistakes regardless. Here, we study bias on two
Web-based (YouTube and Twitter) datasets and two spoken English datasets. Our
analysis shows how most models present biases towards AAE in most settings. We
isolate the impact of AAE expression usage via linguistic control features from
the Linguistic Inquiry and Word Count (LIWC) software, grammatical control
features extracted via Part-of-Speech (PoS) tagging from Natural Language
Processing (NLP) models, and the semantic of utterances by comparing sentence
embeddings from recent language models. We present consistent results on how a
heavy usage of AAE expressions may cause the speaker to be considered
substantially more toxic, even when speaking about nearly the same subject. Our
study complements similar analyses focusing on small datasets and/or one method
only.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12722" title="Abstract">arXiv:2401.12722</a> [<a href="/pdf/2401.12722" title="Download PDF">pdf</a>, <a href="/format/2401.12722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Falcon: Fair Active Learning using Multi-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tae%2C+K+H">Ki Hyun Tae</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hantian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaeyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+K">Kexin Rong</a>, 
<a href="/search/cs?searchtype=author&query=Whang%2C+S+E">Steven Euijong Whang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 12 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Biased data can lead to unfair machine learning models, highlighting the
importance of embedding fairness at the beginning of data analysis,
particularly during dataset curation and labeling. In response, we propose
Falcon, a scalable fair active learning framework. Falcon adopts a data-centric
approach that improves machine learning model fairness via strategic sample
selection. Given a user-specified group fairness measure, Falcon identifies
samples from "target groups" (e.g., (attribute=female, label=positive)) that
are the most informative for improving fairness. However, a challenge arises
since these target groups are defined using ground truth labels that are not
available during sample selection. To handle this, we propose a novel
trial-and-error method, where we postpone using a sample if the predicted label
is different from the expected one and falls outside the target group. We also
observe the trade-off that selecting more informative samples results in higher
likelihood of postponing due to undesired label prediction, and the optimal
balance varies per dataset. We capture the trade-off between informativeness
and postpone rate as policies and propose to automatically select the best
policy using adversarial multi-armed bandit methods, given their computational
efficiency and theoretical guarantees. Experiments show that Falcon
significantly outperforms existing fair active learning approaches in terms of
fairness and accuracy and is more efficient. In particular, only Falcon
supports a proper trade-off between accuracy and fairness where its maximum
fairness score is 1.8-4.5x higher than the second-best results.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12724" title="Abstract">arXiv:2401.12724</a> [<a href="/pdf/2401.12724" title="Download PDF">pdf</a>, <a href="/format/2401.12724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-scale Yarn Appearance Model with Fiber Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khattar%2C+A">Apoorv Khattar</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Junqui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Padovani%2C+E">Emiliano Padovani</a>, 
<a href="/search/cs?searchtype=author&query=Aurby%2C+J">Jean-Marie Aurby</a>, 
<a href="/search/cs?searchtype=author&query=Droske%2C+M">Marc Droske</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Ling-Qi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Montazeri%2C+Z">Zahra Montazeri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">Rendering realistic cloth has always been a challenge due to its intricate
structure. Cloth is made up of fibers, plies, and yarns, and previous
curved-based models, while detailed, were computationally expensive and
inflexible for large cloth. To address this, we propose a simplified approach.
<br />We introduce a geometric aggregation technique that reduces ray-tracing
computation by using fewer curves, focusing only on yarn curves. Our model
generates ply and fiber shapes implicitly, compensating for the lack of
explicit geometry with a novel shadowing component. We also present a shading
model that simplifies light interactions among fibers by categorizing them into
four components, accurately capturing specular and scattered light in both
forward and backward directions.
<br />To render large cloth efficiently, we propose a multi-scale solution based on
pixel coverage. Our yarn shading model outperforms previous methods, achieving
rendering speeds 3-5 times faster with less memory in near-field views.
Additionally, our multi-scale solution offers a 20% speed boost for distant
cloth observation.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12729" title="Abstract">arXiv:2401.12729</a> [<a href="/pdf/2401.12729" title="Download PDF">pdf</a>, <a href="/format/2401.12729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Object Detection Performance for Small Objects through  Synthetic Data Generation and Proportional Class-Balancing Technique: A  Comparative Study in Industrial Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+J">Jibinraj Antony</a>, 
<a href="/search/cs?searchtype=author&query=Hegiste%2C+V">Vinit Hegiste</a>, 
<a href="/search/cs?searchtype=author&query=Nazeri%2C+A">Ali Nazeri</a>, 
<a href="/search/cs?searchtype=author&query=Tavakoli%2C+H">Hooman Tavakoli</a>, 
<a href="/search/cs?searchtype=author&query=Walunj%2C+S">Snehal Walunj</a>, 
<a href="/search/cs?searchtype=author&query=Plociennik%2C+C">Christiane Plociennik</a>, 
<a href="/search/cs?searchtype=author&query=Ruskowski%2C+M">Martin Ruskowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented in conference ESAIM23 1st European Symposium on Artificial Intelligence in Manufacturing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Object Detection (OD) has proven to be a significant computer vision method
in extracting localized class information and has multiple applications in the
industry. Although many of the state-of-the-art (SOTA) OD models perform well
on medium and large sized objects, they seem to under perform on small objects.
In most of the industrial use cases, it is difficult to collect and annotate
data for small objects, as it is time-consuming and prone to human errors.
Additionally, those datasets are likely to be unbalanced and often result in an
inefficient model convergence. To tackle this challenge, this study presents a
novel approach that injects additional data points to improve the performance
of the OD models. Using synthetic data generation, the difficulties in data
collection and annotations for small object data points can be minimized and to
create a dataset with balanced distribution. This paper discusses the effects
of a simple proportional class-balancing technique, to enable better anchor
matching of the OD models. A comparison was carried out on the performances of
the SOTA OD models: YOLOv5, YOLOv7 and SSD, for combinations of real and
synthetic datasets within an industrial use case.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12731" title="Abstract">arXiv:2401.12731</a> [<a href="/pdf/2401.12731" title="Download PDF">pdf</a>, <a href="/format/2401.12731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Distributional Uncertainty of the SHAP score in Explainable Machine  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cifuentes%2C+S">Santiago Cifuentes</a>, 
<a href="/search/cs?searchtype=author&query=Bertossi%2C+L">Leopoldo Bertossi</a>, 
<a href="/search/cs?searchtype=author&query=Pardal%2C+N">Nina Pardal</a>, 
<a href="/search/cs?searchtype=author&query=Abriola%2C+S">Sergio Abriola</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+M+V">Maria Vanina Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+M">Miguel Romero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Attribution scores reflect how important the feature values in an input
entity are for the output of a machine learning model. One of the most popular
attribution scores is the SHAP score, which is an instantiation of the general
Shapley value used in coalition game theory. The definition of this score
relies on a probability distribution on the entity population. Since the exact
distribution is generally unknown, it needs to be assigned subjectively or be
estimated from data, which may lead to misleading feature scores. In this
paper, we propose a principled framework for reasoning on SHAP scores under
unknown entity population distributions. In our framework, we consider an
uncertainty region that contains the potential distributions, and the SHAP
score of a feature becomes a function defined over this region. We study the
basic problems of finding maxima and minima of this function, which allows us
to determine tight ranges for the SHAP scores of all features. In particular,
we pinpoint the complexity of these problems, and other related ones, showing
them to be NP-complete. Finally, we present experiments on a real-world
dataset, showing that our framework may contribute to a more robust feature
scoring.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12732" title="Abstract">arXiv:2401.12732</a> [<a href="/pdf/2401.12732" title="Download PDF">pdf</a>, <a href="/format/2401.12732" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural  Process
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaodong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sheng%2C+J">Jiawei Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiangxia Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Quangang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tingwen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by WSDM'2024 Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Cross-domain recommendation (CDR) has been proven as a promising way to
tackle the user cold-start problem, which aims to make recommendations for
users in the target domain by transferring the user preference derived from the
source domain. Traditional CDR studies follow the embedding and mapping (EMCDR)
paradigm, which transfers user representations from the source to target domain
by learning a user-shared mapping function, neglecting the user-specific
preference. Recent CDR studies attempt to learn user-specific mapping functions
in meta-learning paradigm, which regards each user's CDR as an individual task,
but neglects the preference correlations among users, limiting the beneficial
information for user representations. Moreover, both of the paradigms neglect
the explicit user-item interactions from both domains during the mapping
process. To address the above issues, this paper proposes a novel CDR framework
with neural process (NP), termed as CDRNP. Particularly, it develops the
meta-learning paradigm to leverage user-specific preference, and further
introduces a stochastic process by NP to capture the preference correlations
among the overlapping and cold-start users, thus generating more powerful
mapping functions by mapping the user-specific preference and common preference
correlations to a predictive probability distribution. In addition, we also
introduce a preference remainer to enhance the common preference from the
overlapping users, and finally devises an adaptive conditional decoder with
preference modulation to make prediction for cold-start users with items in the
target domain. Experimental results demonstrate that CDRNP outperforms previous
SOTA methods in three real-world CDR scenarios.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12733" title="Abstract">arXiv:2401.12733</a> [<a href="/pdf/2401.12733" title="Download PDF">pdf</a>, <a href="/format/2401.12733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TNANet: A Temporal-Noise-Aware Neural Network for Suicidal Ideation  Prediction with Noisy Physiological Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Niqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wenqi Ji</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xinxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+G">Guozhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+W">Wenting Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong-Jin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The robust generalization of deep learning models in the presence of inherent
noise remains a significant challenge, especially when labels are subjective
and noise is indiscernible in natural settings. This problem is particularly
pronounced in many practical applications. In this paper, we address a special
and important scenario of monitoring suicidal ideation, where time-series data,
such as photoplethysmography (PPG), is susceptible to such noise. Current
methods predominantly focus on image and text data or address artificially
introduced noise, neglecting the complexities of natural noise in time-series
analysis. To tackle this, we introduce a novel neural network model tailored
for analyzing noisy physiological time-series data, named TNANet, which merges
advanced encoding techniques with confidence learning, enhancing prediction
accuracy. Another contribution of our work is the collection of a specialized
dataset of PPG signals derived from real-world environments for suicidal
ideation prediction. Employing this dataset, our TNANet achieves the prediction
accuracy of 63.33% in a binary classification task, outperforming
state-of-the-art models. Furthermore, comprehensive evaluations were conducted
on three other well-known public datasets with artificially introduced noise to
rigorously test the TNANet's capabilities. These tests consistently
demonstrated TNANet's superior performance by achieving an accuracy improvement
of more than 10% compared to baseline methods.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12734" title="Abstract">arXiv:2401.12734</a> [<a href="/pdf/2401.12734" title="Download PDF">pdf</a>, <a href="/ps/2401.12734" title="Download PostScript">ps</a>, <a href="/format/2401.12734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the improved convergence of lifted distributional Gauss curvature  from Regge elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gopalakrishnan%2C+J">Jay Gopalakrishnan</a>, 
<a href="/search/math?searchtype=author&query=Neunteufel%2C+M">Michael Neunteufel</a>, 
<a href="/search/math?searchtype=author&query=Sch%C3%B6berl%2C+J">Joachim Sch&#xf6;berl</a>, 
<a href="/search/math?searchtype=author&query=Wardetzky%2C+M">Max Wardetzky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">Although Regge finite element functions are not continuous, useful
generalizations of nonlinear derivatives like the curvature, can be defined
using them. This paper is devoted to studying the convergence of the finite
element lifting of a generalized (distributional) Gauss curvature defined using
a metric tensor in the Regge finite element space. Specifically, we investigate
the interplay between the polynomial degree of the curvature lifting by
Lagrange elements and the degree of the metric tensor in the Regge finite
element space. Previously, a superconvergence result, where convergence rate of
one order higher than expected, was obtained when the metric is the canonical
Regge interpolant of the exact metric. In this work, we show that an even
higher order can be obtained if the degree of the curvature lifting is reduced
by one polynomial degre and if at least linear Regge elements are used. These
improved convergence rates are confirmed by numerical examples.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12736" title="Abstract">arXiv:2401.12736</a> [<a href="/pdf/2401.12736" title="Download PDF">pdf</a>, <a href="/format/2401.12736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dachong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuangzhuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent studies reveal that the remarkable performance of Vision transformers
(ViTs) benefits from large receptive fields. For this reason, the large
convolutional kernel design becomes an ideal solution to make Convolutional
Neural Networks (CNNs) great again. However, the typical large convolutional
kernels turn out to be hardware-unfriendly operators, resulting in discount
compatibility of various hardware platforms. Thus, it is unwise to simply
enlarge the convolutional kernel size. In this paper, we reveal that small
convolutional kernels and convolution operations can achieve the closing
effects of large kernel sizes. Then, we propose a shift-wise operator that
ensures the CNNs capture long-range dependencies with the help of the sparse
mechanism, while remaining hardware-friendly. Experimental results show that
our shift-wise operator significantly improves the accuracy of a regular CNN
while markedly reducing computational requirements. On the ImageNet-1k, our
shift-wise enhanced CNN model outperforms the state-of-the-art models. Code &amp;
models at https://github.com/lidc54/shift-wiseConv.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12739" title="Abstract">arXiv:2401.12739</a> [<a href="/pdf/2401.12739" title="Download PDF">pdf</a>, <a href="/ps/2401.12739" title="Download PostScript">ps</a>, <a href="/format/2401.12739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding University Hierarchy and Prestige in China through Domestic  Ph.D. Hiring Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+C">Chaolin Tian</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xunyi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yurui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Langtian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yifang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The academic job market for fresh Ph.D. students to pursue postdoctoral and
junior faculty positions plays a crucial role in shaping the future
orientations, developments, and status of the global academic system. In this
work, we focus on the domestic Ph.D. hiring network among universities in China
by exploring the doctoral education and academic employment of nearly 28,000
scientists across all Ph.D.-granting Chinese universities over three decades.
We employ the minimum violation rankings algorithm to decode the rankings for
universities based on the Ph.D. hiring network, which offers a deep
understanding of the structure and dynamics within the network. Our results
uncover a consistent, highly structured hierarchy within this hiring network,
indicating the imbalances wherein a limited number of universities serve as the
main sources of fresh Ph.D. across diverse disciplines. Furthermore, over time,
it has become increasingly challenging for Chinese Ph.D. graduates to secure
positions at institutions more prestigious than their alma maters. This study
quantitatively captures the evolving structure of talent circulation in the
domestic environment, providing valuable insights to enhance the organization,
diversity, and talent distribution in China's academic enterprise.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12743" title="Abstract">arXiv:2401.12743</a> [<a href="/pdf/2401.12743" title="Download PDF">pdf</a>, <a href="/format/2401.12743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlation-Embedded Transformer Tracking: A Single-Branch Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+F">Fei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wankou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chunyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+L">Lei Chu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yue Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wenjun Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Developing robust and discriminative appearance models has been a
long-standing research challenge in visual object tracking. In the prevalent
Siamese-based paradigm, the features extracted by the Siamese-like networks are
often insufficient to model the tracked targets and distractor objects, thereby
hindering them from being robust and discriminative simultaneously. While most
Siamese trackers focus on designing robust correlation operations, we propose a
novel single-branch tracking framework inspired by the transformer. Unlike the
Siamese-like feature extraction, our tracker deeply embeds cross-image feature
correlation in multiple layers of the feature network. By extensively matching
the features of the two images through multiple layers, it can suppress
non-target features, resulting in target-aware feature extraction. The output
features can be directly used for predicting target locations without
additional correlation steps. Thus, we reformulate the two-branch Siamese
tracking as a conceptually simple, fully transformer-based Single-Branch
Tracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBT
baseline, we summarize many effective design principles and propose an improved
tracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with a
local modeling layer to enhance shallow-level features. A unified relation
modeling is proposed to remove complex handcrafted layer pattern designs.
SuperSBT is further improved by masked image modeling pre-training, integrating
temporal modeling, and equipping with dedicated prediction heads. Thus,
SuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores in
LaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed of
SBT from 37 FPS to 81 FPS. Extensive experiments show that our method achieves
superior results on eight VOT benchmarks.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12744" title="Abstract">arXiv:2401.12744</a> [<a href="/pdf/2401.12744" title="Download PDF">pdf</a>, <a href="/ps/2401.12744" title="Download PostScript">ps</a>, <a href="/format/2401.12744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monadic Intersection Types, Relationally (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gavazzo%2C+F">Francesco Gavazzo</a>, 
<a href="/search/cs?searchtype=author&query=Treglia%2C+R">Riccardo Treglia</a>, 
<a href="/search/cs?searchtype=author&query=Vanoni%2C+G">Gabriele Vanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">We extend intersection types to a computational $\lambda$-calculus with
algebraic operations \`a la Plotkin and Power. We achieve this by considering
monadic intersections, whereby computational effects appear not only in the
operational semantics, but also in the type system. Since in the effectful
setting termination is not anymore the only property of interest, we want to
analyze the interactive behavior of typed programs with the environment.
Indeed, our type system is able to characterize the natural notion of
observation, both in the finite and in the infinitary setting, and for a wide
class of effects, such as output, cost, pure and probabilistic nondeterminism,
and combinations thereof. The main technical tool is a novel combination of
syntactic techniques with abstract relational reasoning, which allows us to
lift all the required notions, e.g. of typability and logical relation, to the
monadic setting.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12745" title="Abstract">arXiv:2401.12745</a> [<a href="/pdf/2401.12745" title="Download PDF">pdf</a>, <a href="/format/2401.12745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Utility of Probing Trajectories for Algorithm-Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Renau%2C+Q">Quentin Renau</a>, 
<a href="/search/cs?searchtype=author&query=Hart%2C+E">Emma Hart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the proceedings of the 27th International Conference, EvoApplications 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Machine-learning approaches to algorithm-selection typically take data
describing an instance as input. Input data can take the form of features
derived from the instance description or fitness landscape, or can be a direct
representation of the instance itself, i.e. an image or textual description.
Regardless of the choice of input, there is an implicit assumption that
instances that are similar will elicit similar performance from algorithm, and
that a model is capable of learning this relationship. We argue that viewing
algorithm-selection purely from an instance perspective can be misleading as it
fails to account for how an algorithm `views' similarity between instances. We
propose a novel `algorithm-centric' method for describing instances that can be
used to train models for algorithm-selection: specifically, we use short
probing trajectories calculated by applying a solver to an instance for a very
short period of time. The approach is demonstrated to be promising, providing
comparable or better results to computationally expensive landscape-based
feature-based approaches. Furthermore, projecting the trajectories into a
2-dimensional space illustrates that functions that are similar from an
algorithm-perspective do not necessarily correspond to the accepted
categorisation of these functions from a human perspective.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12747" title="Abstract">arXiv:2401.12747</a> [<a href="/pdf/2401.12747" title="Download PDF">pdf</a>, <a href="/format/2401.12747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOCK project Smart Port 2025 D3.1: &quot;To Twin Or Not To Twin&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Paredis%2C+R">Randy Paredis</a>, 
<a href="/search/eess?searchtype=author&query=Vangheluwe%2C+H">Hans Vangheluwe</a>, 
<a href="/search/eess?searchtype=author&query=Albertins%2C+P+A+R">Pamela Adelino Ramos Albertins</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">This document is a result of the COOCK project "Smart Port 2025: improving
and accelerating the operational efficiency of a harbour eco-system through the
application of intelligent technologies". It reports on the needs of companies
for modelling and simulation and AI-based techniques, with twinning systems in
particular. This document categorizes the purposes and Properties of Interest
for the use of Digital Twins. It further illustrates some of the twinning
usages, and touches on some of the potential architectural compositions for
twins. This last topic will be further elaborated in a followup report.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12751" title="Abstract">arXiv:2401.12751</a> [<a href="/pdf/2401.12751" title="Download PDF">pdf</a>, <a href="/format/2401.12751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+W">Wanjuan Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qingshan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+W">Wenbing Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Surface reconstruction has traditionally relied on the Multi-View Stereo
(MVS)-based pipeline, which often suffers from noisy and incomplete geometry.
This is due to that although MVS has been proven to be an effective way to
recover the geometry of the scenes, especially for locally detailed areas with
rich textures, it struggles to deal with areas with low texture and large
variations of illumination where the photometric consistency is unreliable.
Recently, Neural Implicit Surface Reconstruction (NISR) combines surface
rendering and volume rendering techniques and bypasses the MVS as an
intermediate step, which has emerged as a promising alternative to overcome the
limitations of traditional pipelines. While NISR has shown impressive results
on simple scenes, it remains challenging to recover delicate geometry from
uncontrolled real-world scenes which is caused by its underconstrained
optimization. To this end, the framework PSDF is proposed which resorts to
external geometric priors from a pretrained MVS network and internal geometric
priors inherent in the NISR model to facilitate high-quality neural implicit
surface learning. Specifically, the visibility-aware feature consistency loss
and depth prior-assisted sampling based on external geometric priors are
introduced. These proposals provide powerfully geometric consistency
constraints and aid in locating surface intersection points, thereby
significantly improving the accuracy and delicate reconstruction of NISR.
Meanwhile, the internal prior-guided importance rendering is presented to
enhance the fidelity of the reconstructed surface mesh by mitigating the biased
rendering issue in NISR. Extensive experiments on the Tanks and Temples dataset
show that PSDF achieves state-of-the-art performance on complex uncontrolled
scenes.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12755" title="Abstract">arXiv:2401.12755</a> [<a href="/pdf/2401.12755" title="Download PDF">pdf</a>, <a href="/ps/2401.12755" title="Download PostScript">ps</a>, <a href="/format/2401.12755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Risk Analysis of the Impact of AI on the Deliberate Biological  Threat Landscape
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walsh%2C+M+E">Matthew E. Walsh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">The perception that the convergence of biological engineering and artificial
intelligence (AI) could enable increased biorisk has recently drawn attention
to the governance of biotechnology and artificial intelligence. The 2023
Executive Order, Executive Order on the Safe, Secure, and Trustworthy
Development and Use of Artificial Intelligence, requires an assessment of how
artificial intelligence can increase biorisk. Within this perspective, we
present a simplistic framework for evaluating biorisk and demonstrate how this
framework falls short in achieving actionable outcomes for a biorisk manager.
We then suggest a potential path forward that builds upon existing risk
characterization work and justify why characterization efforts of AI-enabled
tools for engineering biology is needed.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12756" title="Abstract">arXiv:2401.12756</a> [<a href="/pdf/2401.12756" title="Download PDF">pdf</a>, <a href="/format/2401.12756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What the Weight?! A Unified Framework for Zero-Shot Knowledge  Composition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holtermann%2C+C">Carolin Holtermann</a>, 
<a href="/search/cs?searchtype=author&query=Frohmann%2C+M">Markus Frohmann</a>, 
<a href="/search/cs?searchtype=author&query=Rekabsaz%2C+N">Navid Rekabsaz</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of the ACL: EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The knowledge encapsulated in a model is the core factor determining its
final performance on downstream tasks. Much research in NLP has focused on
efficient methods for storing and adapting different types of knowledge, e.g.,
in dedicated modularized structures, and on how to effectively combine these,
e.g., by learning additional parameters. However, given the many possible
options, a thorough understanding of the mechanisms involved in these
compositions is missing, and hence it remains unclear which strategies to
utilize. To address this research gap, we propose a novel framework for
zero-shot module composition, which encompasses existing and some novel
variations for selecting, weighting, and combining parameter modules under a
single unified notion. Focusing on the scenario of domain knowledge and adapter
layers, our framework provides a systematic unification of concepts, allowing
us to conduct the first comprehensive benchmarking study of various zero-shot
knowledge composition strategies. In particular, we test two module combination
methods and five selection and weighting strategies for their effectiveness and
efficiency in an extensive experimental setup. Our results highlight the
efficacy of ensembling but also hint at the power of simple though
often-ignored weighting methods. Further in-depth analyses allow us to
understand the role of weighting vs. top-k selection, and show that, to a
certain extent, the performance of adapter composition can even be predicted.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12761" title="Abstract">arXiv:2401.12761</a> [<a href="/pdf/2401.12761" title="Download PDF">pdf</a>, <a href="/format/2401.12761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under  Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%B6dermann%2C+T">Tim Br&#xf6;dermann</a>, 
<a href="/search/cs?searchtype=author&query=Bruggemann%2C+D">David Bruggemann</a>, 
<a href="/search/cs?searchtype=author&query=Sakaridis%2C+C">Christos Sakaridis</a>, 
<a href="/search/cs?searchtype=author&query=Ta%2C+K">Kevin Ta</a>, 
<a href="/search/cs?searchtype=author&query=Liagouris%2C+O">Odysseas Liagouris</a>, 
<a href="/search/cs?searchtype=author&query=Corkill%2C+J">Jason Corkill</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Achieving level-5 driving automation in autonomous vehicles necessitates a
robust semantic visual perception system capable of parsing data from different
sensors across diverse conditions. However, existing semantic perception
datasets often lack important non-camera modalities typically used in
autonomous vehicles, or they do not exploit such modalities to aid and improve
semantic annotations in challenging conditions. To address this, we introduce
MUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverse
conditions under increased uncertainty. MUSES includes synchronized multimodal
recordings with 2D panoptic annotations for 2500 images captured under diverse
weather and illumination. The dataset integrates a frame camera, a lidar, a
radar, an event camera, and an IMU/GNSS sensor. Our new two-stage panoptic
annotation protocol captures both class-level and instance-level uncertainty in
the ground truth and enables the novel task of uncertainty-aware panoptic
segmentation we introduce, along with standard semantic and panoptic
segmentation. MUSES proves both effective for training and challenging for
evaluating models under diverse visual conditions, and it opens new avenues for
research in multimodal and uncertainty-aware dense semantic perception. Our
dataset and benchmark will be made publicly available.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12763" title="Abstract">arXiv:2401.12763</a> [<a href="/pdf/2401.12763" title="Download PDF">pdf</a>, <a href="/ps/2401.12763" title="Download PostScript">ps</a>, <a href="/format/2401.12763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The State-Dependent Channel with a Rate-Limited Cribbing Helper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lapidoth%2C+A">Amos Lapidoth</a>, 
<a href="/search/cs?searchtype=author&query=Steinberg%2C+Y">Yossef Steinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The capacity of a memoryless state-dependent channel is derived for a setting
in which the encoder is provided with rate-limited assistance from a cribbing
helper that observes the state sequence causally and the past channel inputs
strictly-causally. Said cribbing may increase capacity but not to the level
achievable by a message-cognizant helper.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12768" title="Abstract">arXiv:2401.12768</a> [<a href="/pdf/2401.12768" title="Download PDF">pdf</a>, <a href="/format/2401.12768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Can Self-Admitted Technical Debt Tell Us About Security? A  Mixed-Methods Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferreyra%2C+N+E+D">Nicol&#xe1;s E. D&#xed;az Ferreyra</a>, 
<a href="/search/cs?searchtype=author&query=Shahin%2C+M">Mojtaba Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Zahedi%2C+M">Mansorreh Zahedi</a>, 
<a href="/search/cs?searchtype=author&query=Quadri%2C+S">Sodiq Quadri</a>, 
<a href="/search/cs?searchtype=author&query=Scandariato%2C+R">Ricardo Scandariato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in the 21th International Conference on Mining Software Repositories (MSR '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimal
design and implementation choices reported in software artefacts (e.g., code
comments and commit messages) by developers themselves. Such reports have been
central to the study of software maintenance and evolution over the last
decades. However, they can also be deemed as dreadful sources of information on
potentially exploitable vulnerabilities and security flaws. This work
investigates the security implications of SATD from a technical and
developer-centred perspective. On the one hand, it analyses whether security
pointers disclosed inside SATD sources can be used to characterise
vulnerabilities in Open-Source Software (OSS) projects and repositories. On the
other hand, it delves into developers' perspectives regarding the motivations
behind this practice, its prevalence, and its potential negative consequences.
We followed a mixed-methods approach consisting of (i) the analysis of a
preexisting dataset containing 94,455 SATD instances and (ii) an online survey
with 222 OSS practitioners. We gathered 201 SATD instances through the dataset
analysis and mapped them to different Common Weakness Enumeration (CWE)
identifiers. Overall, 25 different types of CWEs were spotted across commit
messages, pull requests, code comments, and issue sections, from which 8 appear
among MITRE's Top-25 most dangerous ones. The survey shows that software
practitioners often place security pointers across SATD artefacts to promote a
security culture among their peers and help them spot flaky code sections,
among other motives. However, they also consider such a practice risky as it
may facilitate vulnerability exploits. Our findings suggest that preserving the
contextual integrity of security pointers disseminated across SATD artefacts is
critical to safeguard both commercial and OSS solutions against zero-day
attacks.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12780" title="Abstract">arXiv:2401.12780</a> [<a href="/pdf/2401.12780" title="Download PDF">pdf</a>, <a href="/format/2401.12780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for  Alleviating Over-squashing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Li Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhenhao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Junda Ye</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE ICDM 2023, Full paper, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have shown great power for learning and mining
on graphs, and Graph Structure Learning (GSL) plays an important role in
boosting GNNs with a refined graph. In the literature, most GSL solutions
either primarily focus on structure refinement with task-specific supervision
(i.e., node classification), or overlook the inherent weakness of GNNs
themselves (e.g., over-squashing), resulting in suboptimal performance despite
sophisticated designs. In light of these limitations, we propose to study
self-supervised graph structure-feature co-refinement for effectively
alleviating the issue of over-squashing in typical GNNs. In this paper, we take
a fundamentally different perspective of the Ricci curvature in Riemannian
geometry, in which we encounter the challenges of modeling, utilizing and
computing Ricci curvature. To tackle these challenges, we present a
self-supervised Riemannian model, DeepRicci. Specifically, we introduce a
latent Riemannian space of heterogeneous curvatures to model various Ricci
curvatures, and propose a gyrovector feature mapping to utilize Ricci curvature
for typical GNNs. Thereafter, we refine node features by geometric contrastive
learning among different geometric views, and simultaneously refine graph
structure by backward Ricci flow based on a novel formulation of differentiable
Ricci curvature. Finally, extensive experiments on public datasets show the
superiority of DeepRicci, and the connection between backward Ricci flow and
over-squashing. Codes of our work are given in https://github.com/RiemanGraph/.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12783" title="Abstract">arXiv:2401.12783</a> [<a href="/pdf/2401.12783" title="Download PDF">pdf</a>, <a href="/format/2401.12783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Review of Deep Learning Methods for Photoplethysmography Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nie%2C+G">Guangkun Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiabao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+G">Gongzheng Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Deyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+S">Shijia Geng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qinghao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+S">Shenda Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Photoplethysmography (PPG) is a highly promising device due to its advantages
in portability, user-friendly operation, and non-invasive capabilities to
measure a wide range of physiological information. Recent advancements in deep
learning have demonstrated remarkable outcomes by leveraging PPG signals for
tasks related to personal health management and other multifaceted
applications. In this review, we systematically reviewed papers that applied
deep learning models to process PPG data between January 1st of 2017 and July
31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed
from three key perspectives: tasks, models, and data. We finally extracted 193
papers where different deep learning frameworks were used to process PPG
signals. Based on the tasks addressed in these papers, we categorized them into
two major groups: medical-related, and non-medical-related. The medical-related
tasks were further divided into seven subgroups, including blood pressure
analysis, cardiovascular monitoring and diagnosis, sleep health, mental health,
respiratory monitoring and analysis, blood glucose analysis, as well as others.
The non-medical-related tasks were divided into four subgroups, which encompass
signal processing, biometric identification, electrocardiogram reconstruction,
and human activity recognition. In conclusion, significant progress has been
made in the field of using deep learning methods to process PPG data recently.
This allows for a more thorough exploration and utilization of the information
contained in PPG signals. However, challenges remain, such as limited quantity
and quality of publicly available databases, a lack of effective validation in
real-world scenarios, and concerns about the interpretability, scalability, and
complexity of deep learning models. Moreover, there are still emerging research
areas that require further investigation.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12789" title="Abstract">arXiv:2401.12789</a> [<a href="/pdf/2401.12789" title="Download PDF">pdf</a>, <a href="/format/2401.12789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual and Fully Non-Autoregressive ASR with Large Language Model  Fusion: A Comprehensive Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W+R">W. Ronny Huang</a>, 
<a href="/search/cs?searchtype=author&query=Allauzen%2C+C">Cyril Allauzen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tongzhou Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kilol Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Ke Hu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">James Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+S">Shuo-Yiin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Sainath%2C+T+N">Tara N. Sainath</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the era of large models, the autoregressive nature of decoding often
results in latency serving as a significant bottleneck. We propose a
non-autoregressive LM-fused ASR system that effectively leverages the
parallelization capabilities of accelerator hardware. Our approach combines the
Universal Speech Model (USM) and the PaLM 2 language model in per-segment
scoring mode, achieving an average relative WER improvement across all
languages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our
comprehensive ablation study analyzes key parameters such as LLM size, context
length, vocabulary size, fusion methodology. For instance, we explore the
impact of LLM size ranging from 128M to 340B parameters on ASR performance.
This study provides valuable insights into the factors influencing the
effectiveness of practical large-scale LM-fused speech recognition systems.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12790" title="Abstract">arXiv:2401.12790</a> [<a href="/pdf/2401.12790" title="Download PDF">pdf</a>, <a href="/format/2401.12790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MORPH: Towards Automated Concept Drift Adaptation for Malware Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+T">Md Tanvirul Alam</a>, 
<a href="/search/cs?searchtype=author&query=Fieblinger%2C+R">Romy Fieblinger</a>, 
<a href="/search/cs?searchtype=author&query=Mahara%2C+A">Ashim Mahara</a>, 
<a href="/search/cs?searchtype=author&query=Rastogi%2C+N">Nidhi Rastogi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Concept drift is a significant challenge for malware detection, as the
performance of trained machine learning models degrades over time, rendering
them impractical. While prior research in malware concept drift adaptation has
primarily focused on active learning, which involves selecting representative
samples to update the model, self-training has emerged as a promising approach
to mitigate concept drift. Self-training involves retraining the model using
pseudo labels to adapt to shifting data distributions. In this research, we
propose MORPH -- an effective pseudo-label-based concept drift adaptation
method specifically designed for neural networks. Through extensive
experimental analysis of Android and Windows malware datasets, we demonstrate
the efficacy of our approach in mitigating the impact of concept drift. Our
method offers the advantage of reducing annotation efforts when combined with
active learning. Furthermore, our method significantly improves over existing
works in automated concept drift adaptation for malware detection.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12794" title="Abstract">arXiv:2401.12794</a> [<a href="/pdf/2401.12794" title="Download PDF">pdf</a>, <a href="/format/2401.12794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking LLMs via Uncertainty Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fanghua Ye</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mingming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+J">Jianhui Pang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+D+F">Derek F. Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+E">Emine Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, preprints
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The proliferation of open-source Large Language Models (LLMs) from various
institutions has highlighted the urgent need for comprehensive evaluation
methods. However, current evaluation platforms, such as the widely recognized
HuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,
which is vital for thoroughly assessing LLMs. To bridge this gap, we introduce
a new benchmarking approach for LLMs that integrates uncertainty
quantification. Our examination involves eight LLMs (LLM series) spanning five
representative natural language processing tasks. Additionally, we introduce an
uncertainty-aware evaluation metric, UAcc, which takes into account both
prediction accuracy and prediction uncertainty. Our findings reveal that: I)
LLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs
may display greater uncertainty compared to their smaller counterparts; and
III) Instruction-finetuning tends to increase the uncertainty of LLMs. By
taking uncertainty into account, our new UAcc metric can either amplify or
diminish the relative improvement of one LLM over another and may even change
the relative ranking of two LLMs. These results underscore the significance of
incorporating uncertainty in the evaluation of LLMs.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12798" title="Abstract">arXiv:2401.12798</a> [<a href="/pdf/2401.12798" title="Download PDF">pdf</a>, <a href="/format/2401.12798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient Flow of Energy: A General and Efficient Approach for Entity  Alignment Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haifeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Shaoling Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+J">Jianxin Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Entity alignment (EA), a pivotal process in integrating multi-source
Knowledge Graphs (KGs), seeks to identify equivalent entity pairs across these
graphs. Most existing approaches regard EA as a graph representation learning
task, concentrating on enhancing graph encoders. However, the decoding process
in EA - essential for effective operation and alignment accuracy - has received
limited attention and remains tailored to specific datasets and model
architectures, necessitating both entity and additional explicit relation
embeddings. This specificity limits its applicability, particularly in
GNN-based models. To address this gap, we introduce a novel, generalized, and
efficient decoding approach for EA, relying solely on entity embeddings. Our
method optimizes the decoding process by minimizing Dirichlet energy, leading
to the gradient flow within the graph, to promote graph homophily. The
discretization of the gradient flow produces a fast and scalable approach,
termed Triple Feature Propagation (TFP). TFP innovatively channels gradient
flow through three views: entity-to-entity, entity-to-relation, and
relation-to-entity. This generalized gradient flow enables TFP to harness the
multi-view structural information of KGs. Rigorous experimentation on diverse
real-world datasets demonstrates that our approach significantly enhances
various EA methods. Notably, the approach achieves these advancements with less
than 6 seconds of additional computational time, establishing a new benchmark
in efficiency and adaptability for future EA methods.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12799" title="Abstract">arXiv:2401.12799</a> [<a href="/pdf/2401.12799" title="Download PDF">pdf</a>, <a href="/ps/2401.12799" title="Download PostScript">ps</a>, <a href="/format/2401.12799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Some convergence analysis for multicontinuum homogenization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Leung%2C+W+T">Wing Tat Leung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we provide an analysis of a recently proposed multicontinuum
homogenization technique. The analysis differs from those used in classical
homogenization methods for several reasons. First, the cell problems in
multicontinuum homogenization use constraint problems and can not be directly
substituted into the differential operator. Secondly, the problem contains high
contrast that remains in the homogenized problem. The homogenized problem
averages the microstructure while containing the small parameter. In this
analysis, we first based on our previous techniques, CEM-GMsFEM, to define a
CEM-downscaling operator that maps the multicontinuum quantities to an
approximated microscopic solution. Following the regularity assumption of the
multicontinuum quantities, we construct a downscaling operator and the
homogenized multicontinuum equations using the information of linear
approximation of the multicontinuum quantities. The error analysis is given by
the residual estimate of the homogenized equations and the well-posedness
assumption of the homogenized equations.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12800" title="Abstract">arXiv:2401.12800</a> [<a href="/pdf/2401.12800" title="Download PDF">pdf</a>, <a href="/ps/2401.12800" title="Download PostScript">ps</a>, <a href="/format/2401.12800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning in Physical Layer: Review on Data Driven End-to-End  Communication Systems and their Enabling Semantic Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+N">Nazmul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+S">Seokjoo Shin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Learning (DL) has enabled a paradigm shift in wireless communication
system with data driven end-to-end (E2E) learning and optimization of the
Physical Layer (PHY). By leveraging the representation learning of DL, E2E
systems exhibit enhanced adaptability and performance in complex wireless
environments, fulfilling the demands of 5G and beyond network systems and
applications. The evolution of data-driven techniques in the PHY has enabled
advanced semantic applications across various modalities including text, image,
audio, video, and multi-modal transmissions. These applications transcend from
traditional bit-level communication to semantic-level intelligent communication
systems, which are capable of understanding and adapting to the context and
intent of the data transmission. Although PHY as a DL architecture for
data-driven E2E communication is a key factor in enabling semantic
communication systems (SemCom), and various studies in recent years have
surveyed them separately, their combination has not been thoroughly reviewed.
Additionally, these are emerging fields that are still in their infancy, with
several techniques having been developed and evolved in recent years.
Therefore, this article provides a holistic review of data-driven PHY for E2E
communication system, and their enabling semantic applications across different
modalities. Furthermore, it identifies critical challenges and prospective
research directions, providing a pivotal reference for future development of DL
in PHY and SemCom.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12801" title="Abstract">arXiv:2401.12801</a> [<a href="/pdf/2401.12801" title="Download PDF">pdf</a>, <a href="/format/2401.12801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Target-To-User Association in Integrated Sensing and  Communication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cazzella%2C+L">Lorenzo Cazzella</a>, 
<a href="/search/cs?searchtype=author&query=Mizmizi%2C+M">Marouan Mizmizi</a>, 
<a href="/search/cs?searchtype=author&query=Tagliaferri%2C+D">Dario Tagliaferri</a>, 
<a href="/search/cs?searchtype=author&query=Badini%2C+D">Damiano Badini</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>, 
<a href="/search/cs?searchtype=author&query=Spagnolini%2C+U">Umberto Spagnolini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">In Integrated Sensing and Communication (ISAC) systems, matching the radar
targets with communication user equipments (UEs) is functional to several
communication tasks, such as proactive handover and beam prediction. In this
paper, we consider a radar-assisted communication system where a base station
(BS) is equipped with a multiple-input-multiple-output (MIMO) radar that has a
double aim: (i) associate vehicular radar targets to vehicular equipments (VEs)
in the communication beamspace and (ii) predict the beamforming vector for each
VE from radar data. The proposed target-to-user (T2U) association consists of
two stages. First, vehicular radar targets are detected from range-angle
images, and, for each, a beamforming vector is estimated. Then, the inferred
per-target beamforming vectors are matched with the ones utilized at the BS for
communication to perform target-to-user (T2U) association. Joint multi-target
detection and beam inference is obtained by modifying the you only look once
(YOLO) model, which is trained over simulated range-angle radar images.
Simulation results over different urban vehicular mobility scenarios show that
the proposed T2U method provides a probability of correct association that
increases with the size of the BS antenna array, highlighting the respective
increase of the separability of the VEs in the beamspace. Moreover, we show
that the modified YOLO architecture can effectively perform both beam
prediction and radar target detection, with similar performance in mean average
precision on the latter over different antenna array sizes.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12803" title="Abstract">arXiv:2401.12803</a> [<a href="/pdf/2401.12803" title="Download PDF">pdf</a>, <a href="/format/2401.12803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancements for 5G NR PRACH Reception: An AI/ML Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rohit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Yerrapragada%2C+A+K">Anil Kumar Yerrapragada</a>, 
<a href="/search/cs?searchtype=author&query=S%2C+J+K">Jeeva Keshav S</a>, 
<a href="/search/cs?searchtype=author&query=Ganti%2C+R+K">Radha Krishna Ganti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
<p class="mathjax">Random Access is an important step in enabling the initial attachment of a
User Equipment (UE) to a Base Station (gNB). The UE identifies itself by
embedding a Preamble Index (RAPID) in the phase rotation of a known base
sequence, which it transmits on the Physical Random Access Channel (PRACH). The
signal on the PRACH also enables the estimation of propagation delay, often
known as Timing Advance (TA), which is induced by virtue of the UE's position.
Traditional receivers estimate the RAPID and TA using correlation-based
techniques. This paper presents an alternative receiver approach that uses
AI/ML models, wherein two neural networks are proposed, one for the RAPID and
one for the TA. Different from other works, these two models can run in
parallel as opposed to sequentially. Experiments with both simulated data and
over-the-air hardware captures highlight the improved performance of the
proposed AI/ML-based techniques compared to conventional correlation methods.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12806" title="Abstract">arXiv:2401.12806</a> [<a href="/pdf/2401.12806" title="Download PDF">pdf</a>, <a href="/format/2401.12806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary structured physics-informed neural networks for solving equations  with rapidly changing solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanzhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Ying Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Physics-informed neural networks (PINNs), rooted in deep learning, have
emerged as a promising approach for solving partial differential equations
(PDEs). By embedding the physical information described by PDEs into
feedforward neural networks, PINNs are trained as surrogate models to
approximate solutions without the need for label data. Nevertheless, even
though PINNs have shown remarkable performance, they can face difficulties,
especially when dealing with equations featuring rapidly changing solutions.
These difficulties encompass slow convergence, susceptibility to becoming
trapped in local minima, and reduced solution accuracy. To address these
issues, we propose a binary structured physics-informed neural network (BsPINN)
framework, which employs binary structured neural network (BsNN) as the neural
network component. By leveraging a binary structure that reduces inter-neuron
connections compared to fully connected neural networks, BsPINNs excel in
capturing the local features of solutions more effectively and efficiently.
These features are particularly crucial for learning the rapidly changing in
the nature of solutions. In a series of numerical experiments solving Burgers
equation, Euler equation, Helmholtz equation, and high-dimension Poisson
equation, BsPINNs exhibit superior convergence speed and heightened accuracy
compared to PINNs. From these experiments, we discover that BsPINNs resolve the
issues caused by increased hidden layers in PINNs resulting in over-smoothing,
and prevent the decline in accuracy due to non-smoothness of PDEs solutions.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12808" title="Abstract">arXiv:2401.12808</a> [<a href="/pdf/2401.12808" title="Download PDF">pdf</a>, <a href="/ps/2401.12808" title="Download PostScript">ps</a>, <a href="/format/2401.12808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robot Expressing Emotions Through Gestures: Everyone Outside of Italy  Would Understand this?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Consoli%2C+I">Ilaria Consoli</a>, 
<a href="/search/cs?searchtype=author&query=Mattutino%2C+C">Claudio Mattutino</a>, 
<a href="/search/cs?searchtype=author&query=Gena%2C+C">Cristina Gena</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MedCHI workshop 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In the context of our research activities on affective computing and
human-robot interaction we are working on both the recognition of human's
emotions and the expression of emotions by robots. In our vision, robots will
be increasingly present in schools, factories, and homes, and their empathetic
behavior may foster their acceptance. In particular, in one of our research, we
sought to replicate gestures associated with specific emotions on a social
robot, NAO. Our focus was on Ekman's six primary emotions, along with five
emotions selected from Plutchik's wheel of emotions. In our opinion the
cultural component linked to the expression of emotions through gestures
certainly influenced both us and the participants. Thus, we would like to
investigate the influence of our culture in the gestural expression of emotion.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12815" title="Abstract">arXiv:2401.12815</a> [<a href="/pdf/2401.12815" title="Download PDF">pdf</a>, <a href="/format/2401.12815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COREC: Concurrent Non-Blocking Single-Queue Receive Driver for Low  Latency Networking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faltelli%2C+M">Marco Faltelli</a>, 
<a href="/search/cs?searchtype=author&query=Belocchi%2C+G">Giacomo Belocchi</a>, 
<a href="/search/cs?searchtype=author&query=Quaglia%2C+F">Francesco Quaglia</a>, 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+G">Giuseppe Bianchi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Existing network stacks tackle performance and scalability aspects by relying
on multiple receive queues. However, at software level, each queue is processed
by a single thread, which prevents simultaneous work on the same queue and
limits performance in terms of tail latency. To overcome this limitation, we
introduce COREC, the first software implementation of a concurrent non-blocking
single-queue receive driver. By sharing a single queue among multiple threads,
workload distribution is improved, leading to a work-conserving policy for
network stacks. On the technical side, instead of relying on traditional
critical sections - which would sequentialize the operations by threads - COREC
coordinates the threads that concurrently access the same receive queue in
non-blocking manner via atomic machine instructions from the Read-Modify-Write
(RMW) class. These instructions allow threads to access and update memory
locations atomically, based on specific conditions, such as the matching of a
target value selected by the thread. Also, they enable making any update
globally visible in the memory hierarchy, bypassing interference on memory
consistency caused by the CPU store buffers. Extensive evaluation results
demonstrate that the possible additional reordering, which our approach may
occasionally cause, is non-critical and has minimal impact on performance, even
in the worst-case scenario of a single large TCP flow, with performance
impairments accounting to at most 2-3 percent. Conversely, substantial latency
gains are achieved when handling UDP traffic, real-world traffic mix, and
multiple shorter TCP flows.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12818" title="Abstract">arXiv:2401.12818</a> [<a href="/pdf/2401.12818" title="Download PDF">pdf</a>, <a href="/ps/2401.12818" title="Download PostScript">ps</a>, <a href="/format/2401.12818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binomial Channel: On the Capacity-Achieving Distribution and Bounds on  the Capacity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zieder%2C+I">Ian Zieder</a>, 
<a href="/search/cs?searchtype=author&query=Favano%2C+A">Antonino Favano</a>, 
<a href="/search/cs?searchtype=author&query=Barletta%2C+L">Luca Barletta</a>, 
<a href="/search/cs?searchtype=author&query=Dytso%2C+A">Alex Dytso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 1 figure. Extended version of a paper submitted to IEEE ISIT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work considers a binomial noise channel. The paper can be roughly
divided into two parts. The first part is concerned with the properties of the
capacity-achieving distribution. In particular, for the binomial channel, it is
not known if the capacity-achieving distribution is unique since the output
space is finite (i.e., supported on integers $0, \ldots, n)$ and the input
space is infinite (i.e., supported on the interval $[0,1]$), and there are
multiple distributions that induce the same output distribution. This paper
shows that the capacity-achieving distribution is unique by appealing to the
total positivity property of the binomial kernel. In addition, we provide upper
and lower bounds on the cardinality of the support of the capacity-achieving
distribution. Specifically, an upper bound of order $ \frac{n}{2}$ is shown,
which improves on the previous upper bound of order $n$ due to Witsenhausen.
Moreover, a lower bound of order $\sqrt{n}$ is shown. Finally, additional
information about the locations and probability values of the support points is
established.
<br />The second part of the paper focuses on deriving upper and lower bounds on
capacity. In particular, firm bounds are established for all $n$ that show that
the capacity scales as $\frac{1}{2} \log(n)$.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12819" title="Abstract">arXiv:2401.12819</a> [<a href="/pdf/2401.12819" title="Download PDF">pdf</a>, <a href="/format/2401.12819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Layer Tying for Parameter-Efficient Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hay%2C+T+D">Tamir David Hay</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the pursuit of reducing the number of trainable parameters in deep
transformer networks, we employ Reinforcement Learning to dynamically select
layers during training and tie them together. Every few iterations, the RL
agent is asked whether to train each layer $i$ independently or to copy the
weights of a previous layer $j&lt;i$. This facilitates weight sharing, reduces the
number of trainable parameters, and also serves as an effective regularization
technique. Experimental evaluations validate that our model modestly
outperforms the baseline transformer model with regard to perplexity and
drastically reduces the number of trainable parameters. In particular, the
memory consumption during training is up to one order of magnitude less than
the conventional training method.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12820" title="Abstract">arXiv:2401.12820</a> [<a href="/pdf/2401.12820" title="Download PDF">pdf</a>, <a href="/format/2401.12820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained  Self-supervised Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sonal Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Sur%2C+A">Arijit Sur</a>, 
<a href="/search/cs?searchtype=author&query=Baruah%2C+R+D">Rashmi Dutta Baruah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript contains 13 pages, 9 figures and 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Successive proposals of several self-supervised training schemes continue to
emerge, taking one step closer to developing a universal foundation model. In
this process, the unsupervised downstream tasks are recognized as one of the
evaluation methods to validate the quality of visual features learned with a
self-supervised training scheme. However, unsupervised dense semantic
segmentation has not been explored as a downstream task, which can utilize and
evaluate the quality of semantic information introduced in patch-level feature
representations during self-supervised training of a vision transformer.
Therefore, this paper proposes a novel data-driven approach for unsupervised
semantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates
semantically consistent and dense pseudo annotate segmentation masks for the
unlabeled image dataset without using any visual-prior or synchronized data. We
compare these pseudo-annotated segmentation masks with ground truth masks for
evaluating recent self-supervised training schemes to learn shared semantic
properties at the patch level and discriminative semantic properties at the
segment level. Finally, we evaluate existing state-of-the-art self-supervised
training schemes with our proposed downstream task, i.e., DatUS^2. Also, the
best version of DatUS^2 outperforms the existing state-of-the-art method for
the unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47%
Pixel accuracy on the SUIM dataset. It also achieves a competitive level of
accuracy for a large-scale and complex dataset, i.e., the COCO dataset.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12822" title="Abstract">arXiv:2401.12822</a> [<a href="/pdf/2401.12822" title="Download PDF">pdf</a>, <a href="/format/2401.12822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Based Simulators for the Phosphorus Removal Process  Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mohammadi%2C+E">Esmaeel Mohammadi</a>, 
<a href="/search/eess?searchtype=author&query=Stokholm-Bjerregaard%2C+M">Mikkel Stokholm-Bjerregaard</a>, 
<a href="/search/eess?searchtype=author&query=Hansen%2C+A+A">Aviaja Anna Hansen</a>, 
<a href="/search/eess?searchtype=author&query=Nielsen%2C+P+H">Per Halkj&#xe6;r Nielsen</a>, 
<a href="/search/eess?searchtype=author&query=Ortiz-Arroyo%2C+D">Daniel Ortiz-Arroyo</a>, 
<a href="/search/eess?searchtype=author&query=Durdevic%2C+P">Petar Durdevic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Phosphorus removal is vital in wastewater treatment to reduce reliance on
limited resources. Deep reinforcement learning (DRL) is a machine learning
technique that can optimize complex and nonlinear systems, including the
processes in wastewater treatment plants, by learning control policies through
trial and error. However, applying DRL to chemical and biological processes is
challenging due to the need for accurate simulators. This study trained six
models to identify the phosphorus removal process and used them to create a
simulator for the DRL environment. Although the models achieved high accuracy
(&gt;97%), uncertainty and incorrect prediction behavior limited their performance
as simulators over longer horizons. Compounding errors in the models'
predictions were identified as one of the causes of this problem. This approach
for improving process control involves creating simulation environments for DRL
algorithms, using data from supervisory control and data acquisition (SCADA)
systems with a sufficient historical horizon without complex system modeling or
parameter estimation.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12824" title="Abstract">arXiv:2401.12824</a> [<a href="/pdf/2401.12824" title="Download PDF">pdf</a>, <a href="/format/2401.12824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAPPING: Debiasing Graph Neural Networks for Fair Node Classification  with Limited Sensitive Information Leakage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Ying Song</a>, 
<a href="/search/cs?searchtype=author&query=Palanisamy%2C+B">Balaji Palanisamy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Finished May last year. Remember to submit all papers to arXiv early without compromising the principles of conferences
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Despite remarkable success in diverse web-based applications, Graph Neural
Networks(GNNs) inherit and further exacerbate historical discrimination and
social stereotypes, which critically hinder their deployments in high-stake
domains such as online clinical diagnosis, financial crediting, etc. However,
current fairness research that primarily craft on i.i.d data, cannot be
trivially replicated to non-i.i.d. graph structures with topological dependence
among samples. Existing fair graph learning typically favors pairwise
constraints to achieve fairness but fails to cast off dimensional limitations
and generalize them into multiple sensitive attributes; besides, most studies
focus on in-processing techniques to enforce and calibrate fairness,
constructing a model-agnostic debiasing GNN framework at the pre-processing
stage to prevent downstream misuses and improve training reliability is still
largely under-explored. Furthermore, previous work on GNNs tend to enhance
either fairness or privacy individually but few probe into their interplays. In
this paper, we propose a novel model-agnostic debiasing framework named MAPPING
(\underline{M}asking \underline{A}nd \underline{P}runing and
Message-\underline{P}assing train\underline{ING}) for fair node classification,
in which we adopt the distance covariance($dCov$)-based fairness constraints to
simultaneously reduce feature and topology biases in arbitrary dimensions, and
combine them with adversarial debiasing to confine the risks of attribute
inference attacks. Experiments on real-world datasets with different GNN
variants demonstrate the effectiveness and flexibility of MAPPING. Our results
show that MAPPING can achieve better trade-offs between utility and fairness,
and mitigate privacy risks of sensitive information leakage.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12826" title="Abstract">arXiv:2401.12826</a> [<a href="/pdf/2401.12826" title="Download PDF">pdf</a>, <a href="/format/2401.12826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-Based Network Management for Better QoE in Multicast Short  Video Streaming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shisheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haojun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Y">Yingying Pei</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xuemin Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Multicast short video streaming can enhance bandwidth utilization by enabling
simultaneous video transmission to multiple users over shared wireless
channels. The existing network management schemes mainly rely on the sequential
buffering principle and general quality of experience (QoE) model, which may
deteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporal
variation. In this paper, we propose a digital twin (DT)-based network
management scheme to enhance QoE. Firstly, user status emulated by the DT is
utilized to estimate the transmission capabilities and watching probability
distributions of sub-multicast groups (SMGs) for an adaptive segment buffering.
The SMGs' buffers are aligned to the unique virtual buffers managed by the DT
for a fine-grained buffer update. Then, a multicast QoE model consisting of
rebuffering time, video quality, and quality variation is developed, by
considering the mutual influence of segment buffering among SMGs. Finally, a
joint optimization problem of segment version selection and slot division is
formulated to maximize QoE. To efficiently solve the problem, a
data-model-driven algorithm is proposed by integrating a convex optimization
method and a deep reinforcement learning algorithm. Simulation results based on
the real-world dataset demonstrate that the proposed DT-based network
management scheme outperforms benchmark schemes in terms of QoE improvement.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12830" title="Abstract">arXiv:2401.12830</a> [<a href="/pdf/2401.12830" title="Download PDF">pdf</a>, <a href="/format/2401.12830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Next Destination Prediction: A Novel LSTM Approach Using  Real-World Airline Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salihoglu%2C+S">Salih Salihoglu</a>, 
<a href="/search/cs?searchtype=author&query=Koksal%2C+G">Gulser Koksal</a>, 
<a href="/search/cs?searchtype=author&query=Abar%2C+O">Orhan Abar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the modern transportation industry, accurate prediction of travelers' next
destinations brings multiple benefits to companies, such as customer
satisfaction and targeted marketing. This study focuses on developing a precise
model that captures the sequential patterns and dependencies in travel data,
enabling accurate predictions of individual travelers' future destinations. To
achieve this, a novel model architecture with a sliding window approach based
on Long Short-Term Memory (LSTM) is proposed for destination prediction in the
transportation industry. The experimental results highlight satisfactory
performance and high scores achieved by the proposed model across different
data sizes and performance metrics. This research contributes to advancing
destination prediction methods, empowering companies to deliver personalized
recommendations and optimize customer experiences in the dynamic travel
landscape.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12832" title="Abstract">arXiv:2401.12832</a> [<a href="/pdf/2401.12832" title="Download PDF">pdf</a>, <a href="/ps/2401.12832" title="Download PostScript">ps</a>, <a href="/format/2401.12832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical approximation of the stochastic Cahn-Hilliard equation with  space-time white noise near the sharp interface limit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ba%C5%88as%2C+%C4%BD">&#x13d;ubom&#xed;r Ba&#x148;as</a>, 
<a href="/search/math?searchtype=author&query=Mukam%2C+J+D">Jean Daniel Mukam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the stochastic Cahn-Hilliard equation with additive space-time
white noise $\epsilon^{\gamma}\dot{W}$ in dimension $d=2,3$, where $\epsilon&gt;0$
is an interfacial width parameter. We study numerical approximation of the
equation which combines a structure preserving implicit time-discretization
scheme with a discrete approximation of the space-time white noise. We derive a
strong error estimate for the considered numerical approximation which is
robust with respect to the inverse of the interfacial width parameter
$\epsilon$. Furthermore, by a splitting approach, we show that for sufficiently
large scaling parameter $\gamma$, the numerical approximation of the stochastic
Cahn-Hilliard equation converges uniformly to the deterministic
Hele-Shaw/Mullins-Sekerka problem in the sharp interface limit
$\epsilon\rightarrow 0$.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12835" title="Abstract">arXiv:2401.12835</a> [<a href="/pdf/2401.12835" title="Download PDF">pdf</a>, <a href="/format/2401.12835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SGTR+: End-to-end Scene Graph Generation with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Rongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Songyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xuming He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TPAMI: <a href="https://ieeexplore.ieee.org/document/10315230">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scene Graph Generation (SGG) remains a challenging visual understanding task
due to its compositional property. Most previous works adopt a bottom-up,
two-stage or point-based, one-stage approach, which often suffers from high
time complexity or suboptimal designs. In this work, we propose a novel SGG
method to address the aforementioned issues, formulating the task as a
bipartite graph construction problem. To address the issues above, we create a
transformer-based end-to-end framework to generate the entity and entity-aware
predicate proposal set, and infer directed edges to form relation triplets.
Moreover, we design a graph assembling module to infer the connectivity of the
bipartite scene graph based on our entity-aware structure, enabling us to
generate the scene graph in an end-to-end manner. Based on bipartite graph
assembling paradigm, we further propose a new technical design to address the
efficacy of entity-aware modeling and optimization stability of graph
assembling. Equipped with the enhanced entity-aware design, our method achieves
optimal performance and time-complexity. Extensive experimental results show
that our design is able to achieve the state-of-the-art or comparable
performance on three challenging benchmarks, surpassing most of the existing
approaches and enjoying higher efficiency in inference. Code is available:
https://github.com/Scarecrow0/SGTR
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12842" title="Abstract">arXiv:2401.12842</a> [<a href="/pdf/2401.12842" title="Download PDF">pdf</a>, <a href="/format/2401.12842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterated Relevance Matrix Analysis (IRMA) for the identification of  class-discriminative subspaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B6vdal%2C+S">Sofie L&#xf6;vdal</a>, 
<a href="/search/cs?searchtype=author&query=Biehl%2C+M">Michael Biehl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures, 1 table. Submitted to Neurocomputing. Extension of 2023 ESANN conference contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce and investigate the iterated application of Generalized Matrix
Learning Vector Quantizaton for the analysis of feature relevances in
classification problems, as well as for the construction of
class-discriminative subspaces. The suggested Iterated Relevance Matrix
Analysis (IRMA) identifies a linear subspace representing the classification
specific information of the considered data sets using Generalized Matrix
Learning Vector Quantization (GMLVQ). By iteratively determining a new
discriminative subspace while projecting out all previously identified ones, a
combined subspace carrying all class-specific information can be found. This
facilitates a detailed analysis of feature relevances, and enables improved
low-dimensional representations and visualizations of labeled data sets.
Additionally, the IRMA-based class-discriminative subspace can be used for
dimensionality reduction and the training of robust classifiers with
potentially improved performance.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12843" title="Abstract">arXiv:2401.12843</a> [<a href="/pdf/2401.12843" title="Download PDF">pdf</a>, <a href="/format/2401.12843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An embedding-based distance for temporal graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dall%27Amico%2C+L">Lorenzo Dall&#x27;Amico</a>, 
<a href="/search/cs?searchtype=author&query=Barrat%2C+A">Alain Barrat</a>, 
<a href="/search/cs?searchtype=author&query=Cattuto%2C+C">Ciro Cattuto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We define a distance between temporal graphs based on graph embeddings built
using time-respecting random walks. We study both the case of matched graphs,
when there exists a known relation between the nodes, and the unmatched case,
when such a relation is unavailable and the graphs may be of different sizes.
We illustrate the interest of our distance definition, using both real and
synthetic temporal network data, by showing its ability to discriminate between
graphs with different structural and temporal properties. Leveraging
state-of-the-art machine learning techniques, we propose an efficient
implementation of distance computation that is viable for large-scale temporal
graphs.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12846" title="Abstract">arXiv:2401.12846</a> [<a href="/pdf/2401.12846" title="Download PDF">pdf</a>, <a href="/format/2401.12846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How well can large language models explain business processes?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahland%2C+D">Dirk Fahland</a>, 
<a href="/search/cs?searchtype=author&query=Fournier%2C+F">Fabian Fournier</a>, 
<a href="/search/cs?searchtype=author&query=Limonad%2C+L">Lior Limonad</a>, 
<a href="/search/cs?searchtype=author&query=Skarbovsky%2C+I">Inna Skarbovsky</a>, 
<a href="/search/cs?searchtype=author&query=Swevels%2C+A+J+E">Ava J.E. Swevels</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) are likely to play a prominent role in future
AI-augmented business process management systems (ABPMSs) catering
functionalities across all system lifecycle stages. One such system's
functionality is Situation-Aware eXplainability (SAX), which relates to
generating causally sound and yet human-interpretable explanations that take
into account the process context in which the explained condition occurred. In
this paper, we present the SAX4BPM framework developed to generate SAX
explanations. The SAX4BPM suite consists of a set of services and a central
knowledge repository. The functionality of these services is to elicit the
various knowledge ingredients that underlie SAX explanations. A key innovative
component among these ingredients is the causal process execution view. In this
work, we integrate the framework with an LLM to leverage its power to
synthesize the various input ingredients for the sake of improved SAX
explanations. Since the use of LLMs for SAX is also accompanied by a certain
degree of doubt related to its capacity to adequately fulfill SAX along with
its tendency for hallucination and lack of inherent capacity to reason, we
pursued a methodological evaluation of the quality of the generated
explanations. To this aim, we developed a designated scale and conducted a
rigorous user study. Our findings show that the input presented to the LLMs
aided with the guard-railing of its performance, yielding SAX explanations
having better-perceived fidelity. This improvement is moderated by the
perception of trust and curiosity. More so, this improvement comes at the cost
of the perceived interpretability of the explanation.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12848" title="Abstract">arXiv:2401.12848</a> [<a href="/pdf/2401.12848" title="Download PDF">pdf</a>, <a href="/format/2401.12848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Evasion from a Sensing-Limited Pursuer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maity%2C+D">Dipankar Maity</a>, 
<a href="/search/cs?searchtype=author&query=Von+Moll%2C+A">Alexander Von Moll</a>, 
<a href="/search/cs?searchtype=author&query=Shishika%2C+D">Daigo Shishika</a>, 
<a href="/search/cs?searchtype=author&query=Dorothy%2C+M">Michael Dorothy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at, and publication in the proceedings of, the 2024 American Control Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper investigates a partial-information pursuit evasion game in which
the Pursuer has a limited-range sensor to detect the Evader. Given a fixed
final time, we derive the optimal evasion strategy for the Evader to maximize
its distance from the pursuer at the end. Our analysis reveals that in certain
parametric regimes, the optimal Evasion strategy involves a 'risky' maneuver,
where the Evader's trajectory comes extremely close to the pursuer's sensing
boundary before moving behind the Pursuer. Additionally, we explore a special
case in which the Pursuer can choose the final time. In this scenario, we
determine a (Nash) equilibrium pair for both the final time and the evasion
strategy.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12849" title="Abstract">arXiv:2401.12849</a> [<a href="/pdf/2401.12849" title="Download PDF">pdf</a>, <a href="/format/2401.12849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning safety critics via a non-contractive binary bellman operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Castellano%2C+A">Agustin Castellano</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+H">Hancheng Min</a>, 
<a href="/search/cs?searchtype=author&query=Bazerque%2C+J+A">Juan Andr&#xe9;s Bazerque</a>, 
<a href="/search/cs?searchtype=author&query=Mallada%2C+E">Enrique Mallada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The inability to naturally enforce safety in Reinforcement Learning (RL),
with limited failures, is a core challenge impeding its use in real-world
applications. One notion of safety of vast practical relevance is the ability
to avoid (unsafe) regions of the state space. Though such a safety goal can be
captured by an action-value-like function, a.k.a. safety critics, the
associated operator lacks the desired contraction and uniqueness properties
that the classical Bellman operator enjoys. In this work, we overcome the
non-contractiveness of safety critic operators by leveraging that safety is a
binary property. To that end, we study the properties of the binary safety
critic associated with a deterministic dynamical system that seeks to avoid
reaching an unsafe region. We formulate the corresponding binary Bellman
equation (B2E) for safety and study its properties. While the resulting
operator is still non-contractive, we fully characterize its fixed points
representing--except for a spurious solution--maximal persistently safe regions
of the state space that can always avoid failure. We provide an algorithm that,
by design, leverages axiomatic knowledge of safe data to avoid spurious fixed
points.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12851" title="Abstract">arXiv:2401.12851</a> [<a href="/pdf/2401.12851" title="Download PDF">pdf</a>, <a href="/format/2401.12851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classification of grapevine varieties using UAV hyperspectral imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+A">Alfonso L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Ogayar%2C+C+J">Carlos Javier Ogayar</a>, 
<a href="/search/cs?searchtype=author&query=Feito%2C+F+R">Francisco Ram&#xf3;n Feito</a>, 
<a href="/search/cs?searchtype=author&query=Sousa%2C+J+J">Joaquim Jo&#xe3;o Sousa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The classification of different grapevine varieties is a relevant phenotyping
task in Precision Viticulture since it enables estimating the growth of
vineyard rows dedicated to different varieties, among other applications
concerning the wine industry. This task can be performed with destructive
methods that require time-consuming tasks, including data collection and
analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a
more efficient and less prohibitive approach to collecting hyperspectral data,
despite acquiring noisier data. Therefore, the first task is the processing of
these data to correct and downsample large amounts of data. In addition, the
hyperspectral signatures of grape varieties are very similar. In this work, a
Convolutional Neural Network (CNN) is proposed for classifying seventeen
varieties of red and white grape variants. Rather than classifying single
samples, these are processed together with their neighbourhood. Hence, the
extraction of spatial and spectral features is addressed with 1) a spatial
attention layer and 2) Inception blocks. The pipeline goes from processing to
dataset elaboration, finishing with the training phase. The fitted model is
evaluated in terms of response time, accuracy and data separability, and
compared with other state-of-the-art CNNs for classifying hyperspectral data.
Our network was proven to be much more lightweight with a reduced number of
input bands, a lower number of trainable weights and therefore, reduced
training time. Despite this, the evaluated metrics showed much better results
for our network (~99% overall accuracy), in comparison with previous works
barely achieving 81% OA.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12852" title="Abstract">arXiv:2401.12852</a> [<a href="/pdf/2401.12852" title="Download PDF">pdf</a>, <a href="/format/2401.12852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control-Aware Trajectory Predictions for Communication-Efficient Drone  Swarm Coordination in Cluttered Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Longhao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingyuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaidi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures, submitted to IEEE Transactions on Intelligent Vehicles
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Swarms of Unmanned Aerial Vehicles (UAV) have demonstrated enormous potential
in many industrial and commercial applications. However, before deploying UAVs
in the real world, it is essential to ensure they can operate safely in complex
environments, especially with limited communication capabilities. To address
this challenge, we propose a control-aware learning-based trajectory prediction
algorithm that can enable communication-efficient UAV swarm control in a
cluttered environment. Specifically, our proposed algorithm can enable each UAV
to predict the planned trajectories of its neighbors in scenarios with various
levels of communication capabilities. The predicted planned trajectories will
serve as input to a distributed model predictive control (DMPC) approach. The
proposed algorithm combines (1) a trajectory compression and reconstruction
model based on Variational Auto-Encoder, (2) a trajectory prediction model
based on EvolveGCN, a graph convolutional network (GCN) that can handle dynamic
graphs, and (3) a KKT-informed training approach that applies the
Karush-Kuhn-Tucker (KKT) conditions in the training process to encode DMPC
information into the trained neural network. We evaluate our proposed algorithm
in a funnel-like environment. Results show that the proposed algorithm
outperforms state-of-the-art benchmarks, providing close-to-optimal control
performance and robustness to limited communication capabilities and
measurement noises.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12853" title="Abstract">arXiv:2401.12853</a> [<a href="/pdf/2401.12853" title="Download PDF">pdf</a>, <a href="/format/2401.12853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyper-Realist Rendering: A Theoretical Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akleman%2C+E">Ergun Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+M">Murat Kurt</a>, 
<a href="/search/cs?searchtype=author&query=Akleman%2C+D">Derya Akleman</a>, 
<a href="/search/cs?searchtype=author&query=Bruins%2C+G">Gary Bruins</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+S">Sitong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+M">Meena Subramanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">This is the first paper in a series on hyper-realist rendering. In this
paper, we introduce the concept of hyper-realist rendering and present a
theoretical framework to obtain hyper-realist images. We are using the term
Hyper-realism as an umbrella word that captures all types of visual artifacts
that can evoke an impression of reality. The hyper-realist artifacts are visual
representations that are not necessarily created by following logical and
physical principles and can still be perceived as representations of reality.
This idea stems from the principles of representational arts, which attain
visually acceptable renderings of scenes without implementing strict physical
laws of optics and materials. The objective of this work is to demonstrate that
it is possible to obtain visually acceptable illusions of reality by employing
such artistic approaches. With representational art methods, we can even obtain
an alternate illusion of reality that looks more real even when it is not real.
This paper demonstrates that it is common to create illusions of reality in
visual arts with examples of paintings by representational artists. We propose
an approach to obtain expressive local and global illuminations to obtain these
stylistic illusions with a set of well-defined and formal methods.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12857" title="Abstract">arXiv:2401.12857</a> [<a href="/pdf/2401.12857" title="Download PDF">pdf</a>, <a href="/ps/2401.12857" title="Download PostScript">ps</a>, <a href="/format/2401.12857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous exercise recognition and evaluation in prescribed routines:  Approach to virtual coaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-de-Villa%2C+S">Sara Garc&#xed;a-de-Villa</a>, 
<a href="/search/cs?searchtype=author&query=Casillas-P%C3%A9rez%2C+D">David Casillas-P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Mart%C3%ADn%2C+A">Ana Jim&#xe9;nez-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Dom%C3%ADnguez%2C+J+J">Juan Jes&#xfa;s Garc&#xed;a-Dom&#xed;nguez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Expert Systems with Applications, Volume 199, 1 August 2022,
  116990
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Home-based physical therapies are effective if the prescribed exercises are
correctly executed and patients adhere to these routines. This is specially
important for older adults who can easily forget the guidelines from
therapists. Inertial Measurement Units (IMUs) are commonly used for tracking
exercise execution giving information of patients' motion data. In this work,
we propose the use of Machine Learning techniques to recognize which exercise
is being carried out and to assess if the recognized exercise is properly
executed by using data from four IMUs placed on the person limbs. To the best
of our knowledge, both tasks have never been addressed together as a unique
complex task before. However, their combination is needed for the complete
characterization of the performance of physical therapies. We evaluate the
performance of six machine learning classifiers in three contexts: recognition
and evaluation in a single classifier, recognition of correct exercises,
excluding the wrongly performed exercises, and a two-stage approach that first
recognizes the exercise and then evaluates it. We apply our proposal to a set
of 8 exercises of the upper-and lower-limbs designed for maintaining elderly
people health status. To do so, the motion of volunteers were monitored with 4
IMUs. We obtain accuracies of 88.4 \% and the 91.4 \% in the two initial
scenarios. In the third one, the recognition provides an accuracy of 96.2 \%,
whereas the exercise evaluation varies between 93.6 \% and 100.0 \%. This work
proves the feasibility of IMUs for a complete monitoring of physical therapies
in which we can get information of which exercise is being performed and its
quality, as a basis for designing virtual coaches.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12862" title="Abstract">arXiv:2401.12862</a> [<a href="/pdf/2401.12862" title="Download PDF">pdf</a>, <a href="/format/2401.12862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+S">Shaoheng Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+R">Rui Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yafei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Siheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Roadside unit (RSU) can significantly improve the safety and robustness of
autonomous vehicles through Vehicle-to-Everything (V2X) communication.
Currently, the usage of a single RSU mainly focuses on real-time inference and
V2X collaboration, while neglecting the potential value of the high-quality
data collected by RSU sensors. Integrating the vast amounts of data from
numerous RSUs can provide a rich source of data for model training. However,
the absence of ground truth annotations and the difficulty of transmitting
enormous volumes of data are two inevitable barriers to fully exploiting this
hidden value. In this paper, we introduce FedRSU, an innovative federated
learning framework for self-supervised scene flow estimation. In FedRSU, we
present a recurrent self-supervision training paradigm, where for each RSU, the
scene flow prediction of points at every timestamp can be supervised by its
subsequent future multi-modality observation. Another key component of FedRSU
is federated learning, where multiple devices collaboratively train an ML model
while keeping the training data local and private. With the power of the
recurrent self-supervised learning paradigm, FL is able to leverage innumerable
underutilized data from RSU. To verify the FedRSU framework, we construct a
large-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSU
clients, covering various scenarios, modalities, and sensor settings. Based on
RSU-SF, we show that FedRSU can greatly improve model performance in ITS and
provide a comprehensive benchmark under diverse FL scenarios. To the best of
our knowledge, we provide the first real-world LiDAR-camera multi-modal dataset
and benchmark for the FL community.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12863" title="Abstract">arXiv:2401.12863</a> [<a href="/pdf/2401.12863" title="Download PDF">pdf</a>, <a href="/format/2401.12863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+D">Debjyoti Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Modi%2C+S">Suraj Modi</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+S">Subhadarshi Panda</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rituraj Singh</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+G+S">Godawari Sudhakar Rao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated impressive performance in
natural language processing tasks by leveraging chain of thought (CoT) that
enables step-by-step thinking. Extending LLMs with multimodal capabilities is
the recent interest, but incurs computational cost and requires substantial
hardware resources. To address these challenges, we propose KAM-CoT a framework
that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities
for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a
two-stage training process with KG grounding to generate effective rationales
and answers. By incorporating external knowledge from KGs during reasoning, the
model gains a deeper contextual understanding reducing hallucinations and
enhancing the quality of answers. This knowledge-augmented CoT reasoning
empowers the model to handle questions requiring external context, providing
more informed answers. Experimental findings show KAM-CoT outperforms the
state-of-the-art methods. On the ScienceQA dataset, we achieve an average
accuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by
10%. Remarkably, KAM-CoT achieves these results with only 280M trainable
parameters at a time, demonstrating its cost-efficiency and effectiveness.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12866" title="Abstract">arXiv:2401.12866</a> [<a href="/pdf/2401.12866" title="Download PDF">pdf</a>, <a href="/format/2401.12866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported  Coordination of Mobile Crowdsourcing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bruns%2C+R">Ralf Bruns</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%B6tterl%2C+J">Jeremias D&#xf6;tterl</a>, 
<a href="/search/cs?searchtype=author&query=Dunkel%2C+J">J&#xfc;rgen Dunkel</a>, 
<a href="/search/cs?searchtype=author&query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sensors 2023, 23(2), 614
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Mobile crowdsourcing refers to systems where the completion of tasks
necessarily requires physical movement of crowdworkers in an on-demand
workforce. Evidence suggests that in such systems, tasks often get assigned to
crowdworkers who struggle to complete those tasks successfully, resulting in
high failure rates and low service quality. A promising solution to ensure
higher quality of service is to continuously adapt the assignment and respond
to failure-causing events by transferring tasks to better-suited workers who
use different routes or vehicles. However, implementing task transfers in
mobile crowdsourcing is difficult because workers are autonomous and may reject
transfer requests. Moreover, task outcomes are uncertain and need to be
predicted. In this paper, we propose different mechanisms to achieve outcome
prediction and task coordination in mobile crowdsourcing. First, we analyze
different data stream learning approaches for the prediction of task outcomes.
Second, based on the suggested prediction model, we propose and evaluate two
different approaches for task coordination with different degrees of autonomy:
an opportunistic approach for crowdshipping with collaborative, but
non-autonomous workers, and a market-based model with autonomous workers for
crowdsensing.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12869" title="Abstract">arXiv:2401.12869</a> [<a href="/pdf/2401.12869" title="Download PDF">pdf</a>, <a href="/format/2401.12869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TroVE: Inducing Verifiable and Efficient Toolboxes for Solving  Programmatic Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiruo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fried%2C+D">Daniel Fried</a>, 
<a href="/search/cs?searchtype=author&query=Neubig%2C+G">Graham Neubig</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Language models (LMs) can solve tasks such as answering questions about
tables or images by writing programs. However, using primitive functions often
leads to verbose and error-prone programs, and higher-level functions require
expert design. To enable better solutions without human labor, we ask code LMs
to curate reusable high-level functions, and use them to write solutions. We
present TROVE, a training-free method of inducing a verifiable and efficient
toolbox of functions, by generating via using, growing, and periodically
trimming the toolbox. On 11 datasets from math, table question answering, and
image reasoning tasks, TROVE consistently yields simpler solutions with higher
accuracy than baselines using CODELLAMA and previous methods using GPT, while
using 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more
accurate human verification than baselines. With the same pipeline, it creates
diverse functions for varied tasks and datasets, providing insights into their
individual characteristics.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12870" title="Abstract">arXiv:2401.12870</a> [<a href="/pdf/2401.12870" title="Download PDF">pdf</a>, <a href="/format/2401.12870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking the Potential: Multi-task Deep Learning for Spaceborne  Quantitative Monitoring of Fugitive Methane Plumes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+G">Guoxin Si</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shiliang Fu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Wei Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the intensification of global warming, the monitoring of methane
emission and detection of gas plumes from landfills have increasingly received
attention. We decompose methane emission monitoring into three sub-tasks:
methane concentration inversion, plume segmentation, and emission rate
estimation. Conventional algorithms have limitations: methane concentration
inversion usually uses the matched filter, which is sensitive to global
spectrum distribution and contains a large amount of noises. There is limited
research on plume segmentation, with many studies resorting to manual
segmentation that is likely to be subjective. The estimation of methane
emission rate often utilizes IME algorithm, which relies on obtaining
meteorological measurement data. Using the WENT landfill site in Hong Kong and
PRISMA hyperspectral satellite imagery, we propose a new deep learning-based
framework for quantitative monitoring of methane emissions from remote sensing
images based on physical simulation. We generate simulated methane plumes using
large eddy simulation (LES) and different concentration maps of fugitive
emission using the radiative transfer equation (RTE), while combining
augmentation techniques to create a simulated PRISMA dataset. We train a U-Net
network for methane concentration inversion, a Mask R-CNN network for methane
plume segmentation, and a ResNet-50 network for methane emission rate
estimation. All three deep networks achieve higher validation accuracy compared
to conventional algorithms. We further respectively combine the first two
sub-tasks and the last two sub-tasks to design the multi-task learning models -
MTL-01 and MTL-02, both of which achieve higher accuracy than single-task
models. Our research serves as a demonstration of applying multi-task deep
learning to quantitative methane monitoring and can be extended to a broad
range of methane monitoring tasks.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12872" title="Abstract">arXiv:2401.12872</a> [<a href="/pdf/2401.12872" title="Download PDF">pdf</a>, <a href="/format/2401.12872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging  Active Visual Depth Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiansu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shaffer%2C+E">Eric Shaffer</a>, 
<a href="/search/cs?searchtype=author&query=Soltanaghai%2C+E">Elahe Soltanaghai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM CHI 2024 Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Gaze interaction presents a promising avenue in Virtual Reality (VR) due to
its intuitive and efficient user experience. Yet, the depth control inherent in
our visual system remains underutilized in current methods. In this study, we
introduce FocusFlow, a hands-free interaction method that capitalizes on human
visual depth perception within the 3D scenes of Virtual Reality. We first
develop a binocular visual depth detection algorithm to understand eye input
characteristics. We then propose a layer-based user interface and introduce the
concept of 'Virtual Window' that offers an intuitive and robust gaze-depth VR
interaction, despite the constraints of visual depth accuracy and precision
spatially at further distances. Finally, to help novice users actively
manipulate their visual depth, we propose two learning strategies that use
different visual cues to help users master visual depth control. Our user
studies on 24 participants demonstrate the usability of our proposed virtual
window concept as a gaze-depth interaction method. In addition, our findings
reveal that the user experience can be enhanced through an effective learning
process with adaptive visual cues, helping users to develop muscle memory for
this brand-new input mechanism. We conclude the paper by discussing strategies
to optimize learning and potential research topics of gaze-depth interaction.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12873" title="Abstract">arXiv:2401.12873</a> [<a href="/pdf/2401.12873" title="Download PDF">pdf</a>, <a href="/format/2401.12873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Machine Translation with Human Feedback: An Exploration of  Quality Estimation as a Reward Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhiwei He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenxiang Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhuosheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhaopeng Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Insufficient modeling of human preferences within the reward model is a major
obstacle for leveraging human feedback to improve translation quality.
Fortunately, quality estimation (QE), which predicts the quality of a given
translation without reference, has achieved impressive alignment with human
evaluations in the last two years. In this work, we investigate the potential
of employing the QE model as the reward model (the QE-based reward model) to
predict human preferences for feedback training. We first identify the
overoptimization problem during QE-based feedback training, manifested as an
increase in reward while translation quality declines. We examine the problem
and argue that the vulnerability of the QE model might lead to high rewards for
incorrect translations, resulting in overoptimization and error propagation. To
address the problem, we adopt a simple yet effective method that uses heuristic
rules to detect the incorrect translations and assigns a penalty term to the
QE-based rewards for the detected incorrect translations. Experimental results
show that the proposed QE-based feedback training achieves consistent and
significant improvements across various settings, further verified through
human preference studies. Our subsequent analysis demonstrates the high data
efficiency of the proposed QE-based feedback training: the proposed approach
using a small amount of monolingual data can outperform systems using larger
parallel corpora.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12874" title="Abstract">arXiv:2401.12874</a> [<a href="/pdf/2401.12874" title="Download PDF">pdf</a>, <a href="/format/2401.12874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Understanding to Utilization: A Survey on Explainability for Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haoyan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Specia%2C+L">Lucia Specia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This survey paper delves into the burgeoning field of explainability for
Large Language Models (LLMs), a critical yet challenging aspect of natural
language processing. With LLMs playing a pivotal role in various applications,
their "black-box" nature raises concerns about transparency and ethical use.
This paper emphasizes the necessity for enhanced explainability in LLMs,
addressing both the general public's trust and the technical community's need
for a deeper understanding of these models. We concentrate on pre-trained
Transformer-based LLMs, such as LLaMA, which present unique interpretability
challenges due to their scale and complexity. Our review categorizes existing
explainability methods and discusses their application in improving model
transparency and reliability. We also discuss representative evaluation
methods, highlighting their strengths and limitations. The goal of this survey
is to bridge the gap between theoretical understanding and practical
application, offering insights for future research and development in the field
of LLM explainability.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12880" title="Abstract">arXiv:2401.12880</a> [<a href="/pdf/2401.12880" title="Download PDF">pdf</a>, <a href="/format/2401.12880" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Uncertainty Quantification for Stochastic Hyperbolic  Conservation Laws
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Harmon%2C+J+J">Jake J. Harmon</a>, 
<a href="/search/math?searchtype=author&query=Tokareva%2C+S">Svetlana Tokareva</a>, 
<a href="/search/math?searchtype=author&query=Zlotnik%2C+A">Anatoly Zlotnik</a>, 
<a href="/search/math?searchtype=author&query=Swart%2C+P+J">Pieter J. Swart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a predictor-corrector adaptive method for the study of hyperbolic
partial differential equations (PDEs) under uncertainty. Constructed around the
framework of stochastic finite volume (SFV) methods, our approach circumvents
sampling schemes or simulation ensembles while also preserving fundamental
properties, in particular hyperbolicity of the resulting systems and
conservation of the discrete solutions. Furthermore, we augment the existing
SFV theory with a priori convergence results for statistical quantities, in
particular push-forward densities, which we demonstrate through numerical
experiments. By linking refinement indicators to regions of the physical and
stochastic spaces, we drive anisotropic refinements of the discretizations,
introducing new degrees of freedom (DoFs) where deemed profitable. To
illustrate our proposed method, we consider a series of numerical examples for
non-linear hyperbolic PDEs based on Burgers' and Euler's equations.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12881" title="Abstract">arXiv:2401.12881</a> [<a href="/pdf/2401.12881" title="Download PDF">pdf</a>, <a href="/format/2401.12881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Diameter+2 in Truly Subquadratic Time for Unit-Disk Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hsien-Chih Chang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
<p class="mathjax">Finding the diameter of a graph in general cannot be done in truly
subquadratic assuming the Strong Exponential Time Hypothesis (SETH), even when
the underlying graph is unweighted and sparse. When restricting to concrete
classes of graphs and assuming SETH, planar graphs and minor-free graphs admit
truly subquadratic algorithms, while geometric intersection graphs of unit
balls, congruent equilateral triangles, and unit segments do not. Unit-disk
graphs are one of the major open cases where the complexity of diameter
computation remains unknown. More generally, it is conjectured that a truly
subquadratic time algorithm exists for pseudo-disk graphs.
<br />In this paper, we show a truly subquadratic algorithm of running time
$\tilde{O}(n^{2-1/18})$, for finding the diameter in a unit-disk graph, whose
output differs from the optimal solution by at most 2. This is the first
algorithm that provides an additive guarantee in distortion, independent of the
size or the diameter of the graph. Our algorithm requires two important
technical elements. First, we show that for the intersection graph of
pseudo-disks, the graph VC-dimension, either of $k$-hop balls or the distance
encoding vectors, is 4. This contracts to the VC dimension of the pseudo-disks
themselves as geometric ranges (which is known to be 3). Second, we introduce a
clique-based $r$-clustering for geometric intersection graphs, which is an
analog of the $r$-division construction for planar graphs. We also showcase the
new techniques by establishing new results for distance oracles for unit-disk
graphs with subquadratic storage and $O(1)$ query time. The results naturally
extend to unit $L_1$ or $L_\infty$-disks and fat pseudo-disks of similar size.
Last, if the pseudo-disks additionally have bounded ply, we have a truly
subquadratic algorithm to find the exact diameter.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12882" title="Abstract">arXiv:2401.12882</a> [<a href="/pdf/2401.12882" title="Download PDF">pdf</a>, <a href="/ps/2401.12882" title="Download PostScript">ps</a>, <a href="/format/2401.12882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Free $&#x3b4;$-Policy Iteration Based on Damped Newton Method for  Nonlinear Continuous-Time H$\infty$ Tracking Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents a {\delta}-PI algorithm which is based on damped Newton
method for the H{\infty} tracking control problem of unknown continuous-time
nonlinear system. A discounted performance function and an augmented system are
used to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJI
equation is a nonlinear partial differential equation, traditional
reinforcement learning methods for solving the tracking HJI equation are mostly
based on the Newton method, which usually only satisfies local convergence and
needs a good initial guess. Based upon the damped Newton iteration operator
equation, a generalized tracking Bellman equation is derived firstly. The
{\delta}-PI algorithm can seek the optimal solution of the tracking HJI
equation by iteratively solving the generalized tracking Bellman equation.
On-policy learning and off-policy learning {\delta}-PI reinforcement learning
methods are provided, respectively. Off-policy version {\delta}-PI algorithm is
a model-free algorithm which can be performed without making use of a priori
knowledge of the system dynamics. NN-based implementation scheme for the
off-policy {\delta}-PI algorithms is shown. The suitability of the model-free
{\delta}-PI algorithm is illustrated with a nonlinear system simulation.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12888" title="Abstract">arXiv:2401.12888</a> [<a href="/pdf/2401.12888" title="Download PDF">pdf</a>, <a href="/format/2401.12888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of  Big Data System, Data Mining, and Closed-Loop Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lincan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+W">Wei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yijun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The aspiration of the next generation's autonomous driving (AD) technology
relies on the dedicated integration and interaction among intelligent
perception, prediction, planning, and low-level control. There has been a huge
bottleneck regarding the upper bound of autonomous driving algorithm
performance, a consensus from academia and industry believes that the key to
surmount the bottleneck lies in data-centric autonomous driving technology.
Recent advancement in AD simulation, closed-loop model training, and AD big
data engine have gained some valuable experience. However, there is a lack of
systematic knowledge and deep understanding regarding how to build efficient
data-centric AD technology for AD algorithm self-evolution and better AD big
data accumulation. To fill in the identified research gaps, this article will
closely focus on reviewing the state-of-the-art data-driven autonomous driving
technologies, with an emphasis on the comprehensive taxonomy of autonomous
driving datasets characterized by milestone generations, key features, data
acquisition settings, etc. Furthermore, we provide a systematic review of the
existing benchmark closed-loop AD big data pipelines from the industrial
frontier, including the procedure of closed-loop frameworks, key technologies,
and empirical studies. Finally, the future directions, potential applications,
limitations and concerns are discussed to arouse efforts from both academia and
industry for promoting the further development of autonomous driving.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12895" title="Abstract">arXiv:2401.12895</a> [<a href="/pdf/2401.12895" title="Download PDF">pdf</a>, <a href="/format/2401.12895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ESC: Edge-attributed Skyline Community Search in Large-scale Bipartite  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+F">Fangda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xuanpu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yanghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guoxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Due to the ability of modeling relationships between two different types of
entities, bipartite graphs are naturally employed in many real-world
applications. Community Search in bipartite graphs is a fundamental problem and
has gained much attention. However, existing studies focus on measuring the
structural cohesiveness between two sets of vertices, while either completely
ignoring the edge attributes or only considering one-dimensional importance in
forming communities. In this paper, we introduce a novel community model, named
edge-attributed skyline community (ESC), which not only preserves the
structural cohesiveness but unravels the inherent dominance brought about by
multi-dimensional attributes on the edges of bipartite graphs. To search the
ESCs, we develop an elegant peeling algorithm by iteratively deleting edges
with the minimum attribute in each dimension. In addition, we also devise a
more efficient expanding algorithm to further reduce the search space and speed
up the filtering of unpromising vertices, where a upper bound is proposed and
proven. Extensive experiments on real-world large-scale datasets demonstrate
the efficiency, effectiveness, and scalability of the proposed ESC search
algorithms. A case study was conducted to compare with existing community
models, substantiating that our approach facilitates the precision and
diversity of results.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12900" title="Abstract">arXiv:2401.12900</a> [<a href="/pdf/2401.12900" title="Download PDF">pdf</a>, <a href="/format/2401.12900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar  Creation with 3D Gaussian Splatting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhongyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Z">Zhenyu Bao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+G">Guoping Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kanglin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Despite much progress, creating real-time high-fidelity head avatar is still
difficult and existing methods have to trade-off between speed and quality.
3DMM based methods often fail to model non-facial structures such as eyeglasses
and hairstyles, while neural implicit models suffer from deformation
inflexibility and rendering inefficiency.
<br />Although 3D Gaussian has been demonstrated to possess promising capability
for geometry representation and radiance field reconstruction, applying 3D
Gaussian in head avatar creation remains a major challenge since it is
difficult for 3D Gaussian to model the head shape variations caused by changing
poses and expressions. In this paper, we introduce PSAvatar, a novel framework
for animatable head avatar creation that utilizes discrete geometric primitive
to create a parametric morphable shape model and employs 3D Gaussian for fine
detail representation and high fidelity rendering. The parametric morphable
shape model is a Point-based Morphable Shape Model (PMSM) which uses points
instead of meshes for 3D representation to achieve enhanced representation
flexibility. The PMSM first converts the FLAME mesh to points by sampling on
the surfaces as well as off the meshes to enable the reconstruction of not only
surface-like structures but also complex geometries such as eyeglasses and
hairstyles. By aligning these points with the head shape in an
analysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussian
for fine detail representation and appearance modeling, thus enabling the
creation of high-fidelity avatars. We show that PSAvatar can reconstruct
high-fidelity head avatars of a variety of subjects and the avatars can be
animated in real-time ($\ge$ 25 fps at a resolution of 512 x 512 )
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12901" title="Abstract">arXiv:2401.12901</a> [<a href="/pdf/2401.12901" title="Download PDF">pdf</a>, <a href="/ps/2401.12901" title="Download PostScript">ps</a>, <a href="/format/2401.12901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivetti%2C+S">Steven Rivetti</a>, 
<a href="/search/cs?searchtype=author&query=Bjornson%2C+E">Emil Bjornson</a>, 
<a href="/search/cs?searchtype=author&query=Skoglund%2C+M">Mikael Skoglund</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at WCNC 2024. \c{opyright} 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In this paper, we study a cell-free multiple-input multiple-output network
equipped with integrated sensing and communication (ISAC) access points (APs).
The distributed APs are used to jointly serve the communication needs of user
equipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve).
To increase the system's robustness towards said Eve, we develop an ISAC
waveform model that includes artificial noise (AN) aimed at degrading the Eve
channel quality. The central processing unit receives the observations from
each AP and calculates the optimal precoding and AN covariance matrices by
solving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB)
minimization problem. Simulation results highlight an underlying trade-off
between sensing and communication performances: in particular, the UEs
signal-to-noise and interference ratio and the maximum Eve's signal to noise
ratio are directly proportional to the CRB. Furthermore, the optimal AN
covariance matrix is rank-1 and has a peak in the eve's direction, leading to a
surprising inverse-proportionality between the UEs-Eve distance and optimal-CRB
magnitude.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12902" title="Abstract">arXiv:2401.12902</a> [<a href="/pdf/2401.12902" title="Download PDF">pdf</a>, <a href="/format/2401.12902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Facing the Elephant in the Room: Visual Prompt Tuning or Full  Finetuning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Cheng Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As the scale of vision models continues to grow, the emergence of Visual
Prompt Tuning (VPT) as a parameter-efficient transfer learning technique has
gained attention due to its superior performance compared to traditional
full-finetuning. However, the conditions favoring VPT (the ``when") and the
underlying rationale (the ``why") remain unclear. In this paper, we conduct a
comprehensive analysis across 19 distinct datasets and tasks. To understand the
``when" aspect, we identify the scenarios where VPT proves favorable by two
dimensions: task objectives and data distributions. We find that VPT is
preferrable when there is 1) a substantial disparity between the original and
the downstream task objectives (e.g., transitioning from classification to
counting), or 2) a similarity in data distributions between the two tasks
(e.g., both involve natural images). In exploring the ``why" dimension, our
results indicate VPT's success cannot be attributed solely to overfitting and
optimization considerations. The unique way VPT preserves original features and
adds parameters appears to be a pivotal factor. Our study provides insights
into VPT's mechanisms, and offers guidance for its optimal utilization.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12914" title="Abstract">arXiv:2401.12914</a> [<a href="/pdf/2401.12914" title="Download PDF">pdf</a>, <a href="/format/2401.12914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emergent Communication Protocol Learning for Task Offloading in  Industrial Internet of Things
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mostafa%2C+S">Salwa Mostafa</a>, 
<a href="/search/cs?searchtype=author&query=Mota%2C+M+P">Mateus P. Mota</a>, 
<a href="/search/cs?searchtype=author&query=Valcarce%2C+A">Alvaro Valcarce</a>, 
<a href="/search/cs?searchtype=author&query=Bennis%2C+M">Mehdi Bennis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> GLOBECOM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this paper, we leverage a multi-agent reinforcement learning (MARL)
framework to jointly learn a computation offloading decision and multichannel
access policy with corresponding signaling. Specifically, the base station and
industrial Internet of Things mobile devices are reinforcement learning agents
that need to cooperate to execute their computation tasks within a deadline
constraint. We adopt an emergent communication protocol learning framework to
solve this problem. The numerical results illustrate the effectiveness of
emergent communication in improving the channel access success rate and the
number of successfully computed tasks compared to contention-based,
contention-free, and no-communication approaches. Moreover, the proposed task
offloading policy outperforms remote and local computation baselines.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12915" title="Abstract">arXiv:2401.12915</a> [<a href="/pdf/2401.12915" title="Download PDF">pdf</a>, <a href="/format/2401.12915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Red Teaming Visual Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mukai Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yuwei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Masood Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language
Models) to accept multimodal inputs. Since it has been verified that LLMs can
be induced to generate harmful or inaccurate content through specific test
cases (termed as Red Teaming), how VLMs perform in similar scenarios,
especially with their combination of textual and visual inputs, remains a
question. To explore this problem, we present a novel red teaming dataset
RTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal
jail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,
privacy, safety, fairness). Our RTVLM is the first red-teaming dataset to
benchmark current VLMs in terms of these 4 different aspects. Detailed analysis
shows that 10 prominent open-sourced VLMs struggle with the red teaming in
different degrees and have up to 31% performance gap with GPT-4V. Additionally,
we simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning
(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM
test set, 13% in MM-Hal, and without noticeable decline in MM-Bench,
overpassing other LLaVA-based models with regular alignment data. This reveals
that current open-sourced VLMs still lack red teaming alignment. Our code and
datasets will be open-source.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12917" title="Abstract">arXiv:2401.12917</a> [<a href="/pdf/2401.12917" title="Download PDF">pdf</a>, <a href="/format/2401.12917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Active Inference as a Model of Agency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Da+Costa%2C+L">Lancelot Da Costa</a>, 
<a href="/search/cs?searchtype=author&query=Tenka%2C+S">Samuel Tenka</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dominic Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sajid%2C+N">Noor Sajid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in RLDM2022 for the workshop 'RL as a model of agency'
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Is there a canonical way to think of agency beyond reward maximisation? In
this paper, we show that any type of behaviour complying with physically sound
assumptions about how macroscopic biological agents interact with the world
canonically integrates exploration and exploitation in the sense of minimising
risk and ambiguity about states of the world. This description, known as active
inference, refines the free energy principle, a popular descriptive framework
for action and perception originating in neuroscience. Active inference
provides a normative Bayesian framework to simulate and model agency that is
widely used in behavioural neuroscience, reinforcement learning (RL) and
robotics. The usefulness of active inference for RL is three-fold. \emph{a})
Active inference provides a principled solution to the exploration-exploitation
dilemma that usefully simulates biological agency. \emph{b}) It provides an
explainable recipe to simulate behaviour, whence behaviour follows as an
explainable mixture of exploration and exploitation under a generative world
model, and all differences in behaviour are explicit in differences in world
model. \emph{c}) This framework is universal in the sense that it is
theoretically possible to rewrite any RL algorithm conforming to the
descriptive assumptions of active inference as an active inference algorithm.
Thus, active inference can be used as a tool to uncover and compare the
commitments and assumptions of more specific models of agency.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12919" title="Abstract">arXiv:2401.12919</a> [<a href="/pdf/2401.12919" title="Download PDF">pdf</a>, <a href="/format/2401.12919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inertial Sensors for Human Motion Analysis: A Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Garc%C3%ADa-de-Villa%2C+S">Sara Garc&#xed;a-de-Villa</a>, 
<a href="/search/eess?searchtype=author&query=Casillas-P%C3%A9rez%2C+D">David Casillas-P&#xe9;rez</a>, 
<a href="/search/eess?searchtype=author&query=Jim%C3%A9nez-Mart%C3%ADn%2C+A">Ana Jim&#xe9;nez-Mart&#xed;n</a>, 
<a href="/search/eess?searchtype=author&query=Garc%C3%ADa-Dom%C3%ADnguez%2C+J+J">Juan Jes&#xfa;s Garc&#xed;a-Dom&#xed;nguez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. 72,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Inertial motion analysis is having a growing interest during the last decades
due to its advantages over classical optical systems. The technological
solution based on inertial measurement units allows the measurement of
movements in daily living environments, such as in everyday life, which is key
for a realistic assessment and understanding of movements. This is why research
in this field is still developing and different approaches are proposed. This
presents a systematic review of the different proposals for inertial motion
analysis found in the literature. The search strategy has been carried out on
eight different platforms, including journal articles and conference
proceedings, which are written in English and published until August 2022. The
results are analyzed in terms of the publishers, the sensors used, the
applications, the monitored units, the algorithms of use, the participants of
the studies, and the validation systems employed. In addition, we delve deeply
into the machine learning techniques proposed in recent years and in the
approaches to reduce the estimation error. In this way, we show an overview of
the research carried out in this field, going into more detail in recent years,
and providing some research directions for future work
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12920" title="Abstract">arXiv:2401.12920</a> [<a href="/pdf/2401.12920" title="Download PDF">pdf</a>, <a href="/format/2401.12920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Truck Parking Usage Prediction with Decomposed Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamaru%2C+R">Rei Tamaru</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Parker%2C+S">Steven Parker</a>, 
<a href="/search/cs?searchtype=author&query=Perry%2C+E">Ernie Perry</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+B">Bin Ran</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">Soyoung Ahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 3 tables, Manuscript for IEEE Transactions on Intelligent Transportation Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Truck parking on freight corridors faces various challenges, such as
insufficient parking spaces and compliance with Hour-of-Service (HOS)
regulations. These constraints often result in unauthorized parking practices,
causing safety concerns. To enhance the safety of freight operations, providing
accurate parking usage prediction proves to be a cost-effective solution.
Despite the existing research demonstrating satisfactory accuracy for
predicting individual truck parking site usage, few approaches have been
proposed for predicting usage with spatial dependencies of multiple truck
parking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN)
as a predictive framework for assessing parking usage across the entire state
to provide better truck parking information and mitigate unauthorized parking.
The framework leverages the topological structures of truck parking site
distributions and historical parking data to predict occupancy rates across a
state. To achieve this, we introduce a Regional Decomposition approach, which
effectively captures the geographical characteristics. We also introduce the
spatial module working efficiently with the temporal module. Evaluation results
demonstrate that the proposed model surpasses other baseline models, improving
the performance by more than $20\%$ compared with the original model. The
proposed model allows truck parking sites' percipience of the topological
structures and provides higher performance.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12921" title="Abstract">arXiv:2401.12921</a> [<a href="/pdf/2401.12921" title="Download PDF">pdf</a>, <a href="/format/2401.12921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A hypocoercivity-exploiting stabilised finite element method for  Kolmogorov equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dong%2C+Z">Zhaonan Dong</a>, 
<a href="/search/math?searchtype=author&query=Georgoulis%2C+E+H">Emmanuil H. Georgoulis</a>, 
<a href="/search/math?searchtype=author&query=Herbert%2C+P+J">Philip J. Herbert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new stabilised finite element method for the classical
Kolmogorov equation. The latter serves as a basic model problem for large
classes of kinetic-type equations and, crucially, is characterised by
degenerate diffusion. The stabilisation is constructed so that the resulting
method admits a \emph{numerical hypocoercivity} property, analogous to the
corresponding property of the PDE problem. More specifically, the stabilisation
is constructed so that spectral gap is possible in the resulting
``stronger-than-energy'' stabilisation norm, despite the degenerate nature of
the diffusion in Kolmogorov, thereby the method has a provably robust behaviour
as the ``time'' variable goes to infinity. We consider both a spatially
discrete version of the stabilised finite element method and a fully discrete
version, with the time discretisation realised by discontinuous Galerkin
timestepping. Both stability and a priori error bounds are proven in all cases.
Numerical experiments verify the theoretical findings.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12925" title="Abstract">arXiv:2401.12925</a> [<a href="/pdf/2401.12925" title="Download PDF">pdf</a>, <a href="/format/2401.12925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emotion-Aware Contrastive Adaptation Network for Source-Free  Cross-Corpus Speech Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jincen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sunan Li</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B">Bj&#xf6;rn Schuller</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+Y">Yuan Zong</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenming Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Cross-corpus speech emotion recognition (SER) aims to transfer emotional
knowledge from a labeled source corpus to an unlabeled corpus. However, prior
methods require access to source data during adaptation, which is unattainable
in real-life scenarios due to data privacy protection concerns. This paper
tackles a more practical task, namely source-free cross-corpus SER, where a
pre-trained source model is adapted to the target domain without access to
source data. To address the problem, we propose a novel method called
emotion-aware contrastive adaptation network (ECAN). The core idea is to
capture local neighborhood information between samples while considering the
global class-level adaptation. Specifically, we propose a nearest neighbor
contrastive learning to promote local emotion consistency among features of
highly similar samples. Furthermore, relying solely on nearest neighborhoods
may lead to ambiguous boundaries between clusters. Thus, we incorporate
supervised contrastive learning to encourage greater separation between
clusters representing different emotions, thereby facilitating improved
class-level adaptation. Extensive experiments indicate that our proposed ECAN
significantly outperforms state-of-the-art methods under the source-free
cross-corpus SER setting on several speech emotion corpora.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12926" title="Abstract">arXiv:2401.12926</a> [<a href="/pdf/2401.12926" title="Download PDF">pdf</a>, <a href="/format/2401.12926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DsDm: Model-Aware Dataset Selection with Datamodels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Engstrom%2C+L">Logan Engstrom</a>, 
<a href="/search/cs?searchtype=author&query=Feldmann%2C+A">Axel Feldmann</a>, 
<a href="/search/cs?searchtype=author&query=Madry%2C+A">Aleksander Madry</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">When selecting data for training large-scale models, standard practice is to
filter for examples that match human notions of data quality. Such filtering
yields qualitatively clean datapoints that intuitively should improve model
behavior. However, in practice the opposite can often happen: we find that
selecting according to similarity with "high quality" data sources may not
increase (and can even hurt) performance compared to randomly selecting data.
<br />To develop better methods for selecting data, we start by framing dataset
selection as an optimization problem that we can directly solve for: given
target tasks, a learning algorithm, and candidate data, select the subset that
maximizes model performance. This framework thus avoids handpicked notions of
data quality, and instead models explicitly how the learning process uses train
datapoints to predict on the target tasks. Our resulting method greatly
improves language model (LM) performance on both pre-specified tasks and
previously unseen tasks. Specifically, choosing target tasks representative of
standard LM problems and evaluating on diverse held-out benchmarks, our
selected datasets provide a 2x compute multiplier over baseline methods.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12930" title="Abstract">arXiv:2401.12930</a> [<a href="/pdf/2401.12930" title="Download PDF">pdf</a>, <a href="/format/2401.12930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pyAKI - An Open Source Solution to Automated KDIGO classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Porschen%2C+C">Christian Porschen</a>, 
<a href="/search/cs?searchtype=author&query=Ernsting%2C+J">Jan Ernsting</a>, 
<a href="/search/cs?searchtype=author&query=Brauckmann%2C+P">Paul Brauckmann</a>, 
<a href="/search/cs?searchtype=author&query=Weiss%2C+R">Raphael Weiss</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCrdemann%2C+T">Till W&#xfc;rdemann</a>, 
<a href="/search/cs?searchtype=author&query=Booke%2C+H">Hendrik Booke</a>, 
<a href="/search/cs?searchtype=author&query=Amini%2C+W">Wida Amini</a>, 
<a href="/search/cs?searchtype=author&query=Maidowski%2C+L">Ludwig Maidowski</a>, 
<a href="/search/cs?searchtype=author&query=Risse%2C+B">Benjamin Risse</a>, 
<a href="/search/cs?searchtype=author&query=Hahn%2C+T">Tim Hahn</a>, 
<a href="/search/cs?searchtype=author&query=von+Groote%2C+T">Thilo von Groote</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Acute Kidney Injury (AKI) is a frequent complication in critically ill
patients, affecting up to 50% of patients in the intensive care units. The lack
of standardized and open-source tools for applying the Kidney Disease Improving
Global Outcomes (KDIGO) criteria to time series data has a negative impact on
workload and study quality. This project introduces pyAKI, an open-source
pipeline addressing this gap by providing a comprehensive solution for
consistent KDIGO criteria implementation.
<br />The pyAKI pipeline was developed and validated using a subset of the Medical
Information Mart for Intensive Care (MIMIC)-IV database, a commonly used
database in critical care research. We defined a standardized data model in
order to ensure reproducibility. Validation against expert annotations
demonstrated pyAKI's robust performance in implementing KDIGO criteria.
Comparative analysis revealed its ability to surpass the quality of human
labels.
<br />This work introduces pyAKI as an open-source solution for implementing the
KDIGO criteria for AKI diagnosis using time series data with high accuracy and
performance.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12941" title="Abstract">arXiv:2401.12941</a> [<a href="/pdf/2401.12941" title="Download PDF">pdf</a>, <a href="/format/2401.12941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicultural Name Recognition For Previously Unseen Names
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loessberg-Zahl%2C+A">Alexandra Loessberg-Zahl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">State of the art Named Entity Recognition (NER) models have achieved an
impressive ability to extract common phrases from text that belong to labels
such as location, organization, time, and person. However, typical NER systems
that rely on having seen a specific entity in their training data in order to
label an entity perform poorly on rare or unseen entities ta in order to label
an entity perform poorly on rare or unseen entities (Derczynski et al., 2017).
This paper attempts to improve recognition of person names, a diverse category
that can grow any time someone is born or changes their name. In order for
downstream tasks to not exhibit bias based on cultural background, a model
should perform well on names from a variety of backgrounds. In this paper I
experiment with the training data and input structure of an English Bi-LSTM
name recognition model. I look at names from 103 countries to compare how well
the model performs on names from different cultures, specifically in the
context of a downstream task where extracted names will be matched to
information on file. I find that a model with combined character and word input
outperforms word-only models and may improve on accuracy compared to classical
NER models that are not geared toward identifying unseen entity values.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12942" title="Abstract">arXiv:2401.12942</a> [<a href="/pdf/2401.12942" title="Download PDF">pdf</a>, <a href="/format/2401.12942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear dynamics in neuromorphic photonic networks: physical  simulation in Verilog-A
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morison%2C+H">Hugh Morison</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Jagmeet Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kayed%2C+N+A">Nayem Al Kayed</a>, 
<a href="/search/cs?searchtype=author&query=Aadhi%2C+A">A. Aadhi</a>, 
<a href="/search/cs?searchtype=author&query=Moridsadat%2C+M">Maryam Moridsadat</a>, 
<a href="/search/cs?searchtype=author&query=Tamura%2C+M">Marcus Tamura</a>, 
<a href="/search/cs?searchtype=author&query=Tait%2C+A+N">Alexander N. Tait</a>, 
<a href="/search/cs?searchtype=author&query=Shastri%2C+B+J">Bhavin J. Shastri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures. Submitted to Physical Review Applied
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Applied Physics (physics.app-ph); Optics (physics.optics)

</div>
<p class="mathjax">Advances in silicon photonics technology have enabled the field of
neuromorphic photonics, where analog neuron-like processing elements are
implemented in silicon photonics technology. Accurate and scalable simulation
tools for photonic integrated circuits are critical for designing neuromorphic
photonic circuits. This is especially important when designing networks with
recurrent connections, where the dynamics of the system may give rise to
unstable and oscillatory solutions which need to be accurately modelled. These
tools must simultaneously simulate the analog electronics and the multi-channel
(wavelength-division-multiplexed) photonics contained in a photonic neuron to
accurately predict on-chip behaviour. In this paper, we utilize a Verilog-A
model of the photonic neural network to investigate the dynamics of recurrent
integrated circuits. We begin by reviewing the theory of continuous-time
recurrent neural networks as dynamical systems and the relation of these
dynamics to important physical features of photonic neurons such as
cascadability. We then present the neural dynamics of systems of one and two
neurons in the simulated Verilog-A circuit, which are compared to the expected
dynamics of the abstract CTRNN model. Due to the presence of parasitic circuit
elements in the Verilog-A simulation, it is seen that there is a topological
equivalence, but not an exact isomorphism, between the theoretical model and
the simulated model. The implications of these discrepancies for the design of
neuromorphic photonic circuits are discussed. Our findings pave the way for the
practical implementation of large-scale silicon photonic recurrent neural
networks.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12943" title="Abstract">arXiv:2401.12943</a> [<a href="/pdf/2401.12943" title="Download PDF">pdf</a>, <a href="/ps/2401.12943" title="Download PostScript">ps</a>, <a href="/format/2401.12943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Simplified 3D Finite Element Simulations of Three-core Armored Power  Cables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=del-Pino-L%C3%B3pez%2C+J+C">Juan Carlos del-Pino-L&#xf3;pez</a>, 
<a href="/search/eess?searchtype=author&query=Hatlo%2C+M">Marius Hatlo</a>, 
<a href="/search/eess?searchtype=author&query=Cruz-Romero%2C+P">Pedro Cruz-Romero</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Energies 2018, 11, 3081
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper analyzes different ways to simulate electromagnetically three-core
armored cables in 3D by means of the finite element method. Full periodic
models, as lengthy as 36 m, are developed to evaluate the accuracy when
simulating only a small portion of the cable, as commonly employed in the
literature. The adequate length and boundary conditions for having the same
accuracy of full periodic models are also studied. To this aim, five medium
voltage and high voltage armored cables are analyzed, obtaining the minimum
length of the cable that may be simulated for having accurate results in
shorter time and with less computational burden. This also results in the
proposal of a new method comprising the advantages of short geometries and the
applicability of periodic boundary conditions. Its accuracy is compared with
experimental measurements and the IEC standard for 145 kV and 245 kV cables.
The results show a very good agreement between simulations and measurements
(errors below 4 %), obtaining a reduction in the computation time of about 90
%. This new method brings a more effective tool for saving time and
computational resources in cable design and the development of new analytical
expressions for improving the IEC standard.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12945" title="Abstract">arXiv:2401.12945</a> [<a href="/pdf/2401.12945" title="Download PDF">pdf</a>, <a href="/format/2401.12945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lumiere: A Space-Time Diffusion Model for Video Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bar-Tal%2C+O">Omer Bar-Tal</a>, 
<a href="/search/cs?searchtype=author&query=Chefer%2C+H">Hila Chefer</a>, 
<a href="/search/cs?searchtype=author&query=Tov%2C+O">Omer Tov</a>, 
<a href="/search/cs?searchtype=author&query=Herrmann%2C+C">Charles Herrmann</a>, 
<a href="/search/cs?searchtype=author&query=Paiss%2C+R">Roni Paiss</a>, 
<a href="/search/cs?searchtype=author&query=Zada%2C+S">Shiran Zada</a>, 
<a href="/search/cs?searchtype=author&query=Ephrat%2C+A">Ariel Ephrat</a>, 
<a href="/search/cs?searchtype=author&query=Hur%2C+J">Junhwa Hur</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+O">Oliver Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Dekel%2C+T">Tali Dekel</a>, 
<a href="/search/cs?searchtype=author&query=Mosseri%2C+I">Inbar Mosseri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Webpage: <a href="https://lumiere-video.github.io/">this https URL</a> | Video: <a href="https://www.youtube.com/watch?v=wxLr02Dz2Sc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce Lumiere -- a text-to-video diffusion model designed for
synthesizing videos that portray realistic, diverse and coherent motion -- a
pivotal challenge in video synthesis. To this end, we introduce a Space-Time
U-Net architecture that generates the entire temporal duration of the video at
once, through a single pass in the model. This is in contrast to existing video
models which synthesize distant keyframes followed by temporal super-resolution
-- an approach that inherently makes global temporal consistency difficult to
achieve. By deploying both spatial and (importantly) temporal down- and
up-sampling and leveraging a pre-trained text-to-image diffusion model, our
model learns to directly generate a full-frame-rate, low-resolution video by
processing it in multiple space-time scales. We demonstrate state-of-the-art
text-to-video generation results, and show that our design easily facilitates a
wide range of content creation tasks and video editing applications, including
image-to-video, video inpainting, and stylized generation.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12946" title="Abstract">arXiv:2401.12946</a> [<a href="/pdf/2401.12946" title="Download PDF">pdf</a>, <a href="/format/2401.12946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coverage Axis++: Efficient Inner Point Selection for 3D Shape  Skeletonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zimeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+Z">Zhiyang Dou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Cheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+X">Xiaoxiao Long</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+S">Shiqing Xin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lingjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Komura%2C+T">Taku Komura</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaoming Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computational Geometry (cs.CG); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce Coverage Axis++, a novel and efficient approach to 3D shape
skeletonization. The current state-of-the-art approaches for this task often
rely on the watertightness of the input or suffer from substantial
computational costs, thereby limiting their practicality. To address this
challenge, Coverage Axis++ proposes a heuristic algorithm to select skeletal
points, offering a high-accuracy approximation of the Medial Axis Transform
(MAT) while significantly mitigating computational intensity for various shape
representations. We introduce a simple yet effective strategy that considers
both shape coverage and uniformity to derive skeletal points. The selection
procedure enforces consistency with the shape structure while favoring the
dominant medial balls, which thus introduces a compact underlying shape
representation in terms of MAT. As a result, Coverage Axis++ allows for
skeletonization for various shape representations (e.g., water-tight meshes,
triangle soups, point clouds), specification of the number of skeletal points,
few hyperparameters, and highly efficient computation with improved
reconstruction accuracy. Extensive experiments across a wide range of 3D shapes
validate the efficiency and effectiveness of Coverage Axis++. The code will be
publicly available once the paper is published.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12947" title="Abstract">arXiv:2401.12947</a> [<a href="/pdf/2401.12947" title="Download PDF">pdf</a>, <a href="/format/2401.12947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-Based Models Are Not Yet Perfect At Learning to Emulate  Structural Recursion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dylan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tigges%2C+C">Curt Tigges</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zory Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Biderman%2C+S">Stella Biderman</a>, 
<a href="/search/cs?searchtype=author&query=Raginsky%2C+M">Maxim Raginsky</a>, 
<a href="/search/cs?searchtype=author&query=Ringer%2C+T">Talia Ringer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.14699">arXiv:2305.14699</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">This paper investigates the ability of transformer-based models to learn
structural recursion from examples. Recursion is a universal concept in both
natural and formal languages. Structural recursion is central to the
programming language and formal mathematics tasks where symbolic tools
currently excel beyond neural models, such as inferring semantic relations
between datatypes and emulating program behavior. We introduce a general
framework that nicely connects the abstract concepts of structural recursion in
the programming language domain to concrete sequence modeling problems and
learned models' behavior. The framework includes a representation that captures
the general \textit{syntax} of structural recursion, coupled with two different
frameworks for understanding their \textit{semantics} -- one that is more
natural from a programming languages perspective and one that helps bridge that
perspective with a mechanistic understanding of the underlying transformer
architecture.
<br />With our framework as a powerful conceptual tool, we identify different
issues under various set-ups. The models trained to emulate recursive
computations cannot fully capture the recursion yet instead fit short-cut
algorithms and thus cannot solve certain edge cases that are under-represented
in the training distribution. In addition, it is difficult for state-of-the-art
large language models (LLMs) to mine recursive rules from in-context
demonstrations. Meanwhile, these LLMs fail in interesting ways when emulating
reduction (step-wise computation) of the recursive function.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12950" title="Abstract">arXiv:2401.12950</a> [<a href="/pdf/2401.12950" title="Download PDF">pdf</a>, <a href="/format/2401.12950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Semi-structured Subspace Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dold%2C+D">Daniel Dold</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCgamer%2C+D">David R&#xfc;gamer</a>, 
<a href="/search/cs?searchtype=author&query=Sick%2C+B">Beate Sick</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCrr%2C+O">Oliver D&#xfc;rr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Semi-structured regression models enable the joint modeling of interpretable
structured and complex unstructured feature effects. The structured model part
is inspired by statistical models and can be used to infer the input-output
relationship for features of particular importance. The complex unstructured
part defines an arbitrary deep neural network and thereby provides enough
flexibility to achieve competitive prediction performance. While these models
can also account for aleatoric uncertainty, there is still a lack of work on
accounting for epistemic uncertainty. In this paper, we address this problem by
presenting a Bayesian approximation for semi-structured regression models using
subspace inference. To this end, we extend subspace inference for joint
posterior sampling from a full parameter space for structured effects and a
subspace for unstructured effects. Apart from this hybrid sampling scheme, our
method allows for tunable complexity of the subspace and can capture multiple
minima in the loss landscape. Numerical experiments validate our approach's
efficacy in recovering structured effect parameter posteriors in
semi-structured models and approaching the full-space posterior distribution of
MCMC for increasing subspace dimension. Further, our approach exhibits
competitive predictive performance across simulated and real-world datasets.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12952" title="Abstract">arXiv:2401.12952</a> [<a href="/pdf/2401.12952" title="Download PDF">pdf</a>, <a href="/format/2401.12952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unifying framework for perturbative exponential factorizations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arnal%2C+A">Ana Arnal</a>, 
<a href="/search/math?searchtype=author&query=Casas%2C+F">Fernando Casas</a>, 
<a href="/search/math?searchtype=author&query=Chiralt%2C+C">Cristina Chiralt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a framework where Fer and Wilcox expansions for the solution of
differential equations are derived from two particular choices for the initial
transformation that seeds the product expansion. In this scheme intermediate
expansions can also be envisaged. Recurrence formulas are developed. A new
lower bound for the convergence of the Wilcox expansion is provided as well as
some applications of the results. In particular, two examples are worked out up
to high order of approximation to illustrate the behavior of the Wilcox
expansion.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12954" title="Abstract">arXiv:2401.12954</a> [<a href="/pdf/2401.12954" title="Download PDF">pdf</a>, <a href="/format/2401.12954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suzgun%2C+M">Mirac Suzgun</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/suzgunmirac/meta-prompting">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We introduce meta-prompting, an effective scaffolding technique designed to
enhance the functionality of language models (LMs). This approach transforms a
single LM into a multi-faceted conductor, adept at managing and integrating
multiple independent LM queries. By employing high-level instructions,
meta-prompting guides the LM to break down complex tasks into smaller, more
manageable subtasks. These subtasks are then handled by distinct "expert"
instances of the same LM, each operating under specific, tailored instructions.
Central to this process is the LM itself, in its role as the conductor, which
ensures seamless communication and effective integration of the outputs from
these expert models. It additionally employs its inherent critical thinking and
robust verification processes to refine and authenticate the end result. This
collaborative prompting approach empowers a single LM to simultaneously act as
a comprehensive orchestrator and a panel of diverse experts, significantly
enhancing its performance across a wide array of tasks. The zero-shot,
task-agnostic nature of meta-prompting greatly simplifies user interaction by
obviating the need for detailed, task-specific instructions. Furthermore, our
research demonstrates the seamless integration of external tools, such as a
Python interpreter, into the meta-prompting framework, thereby broadening its
applicability and utility. Through rigorous experimentation with GPT-4, we
establish the superiority of meta-prompting over conventional scaffolding
methods: When averaged across all tasks, including the Game of 24,
Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented
with a Python interpreter functionality, surpasses standard prompting by 17.1%,
expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12955" title="Abstract">arXiv:2401.12955</a> [<a href="/pdf/2401.12955" title="Download PDF">pdf</a>, <a href="/format/2401.12955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exponential perturbative expansions and coordinate transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Arnal%2C+A">Ana Arnal</a>, 
<a href="/search/math?searchtype=author&query=Casas%2C+F">Fernando Casas</a>, 
<a href="/search/math?searchtype=author&query=Chiralt%2C+C">Cristina Chiralt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a unified approach for different exponential perturbation
techniques used in the treatment of time-dependent quantum mechanical problems,
namely the Magnus expansion, the Floquet--Magnus expansion for periodic
systems, the quantum averaging technique and the Lie--Deprit perturbative
algorithms. Even the standard perturbation theory fits in this framework. The
approach is based on carrying out an appropriate change of coordinates (or
picture) in each case, and can be formulated for any time-dependent linear
system of ordinary differential equations. All the procedures (except the
standard perturbation theory) lead to approximate solutions preserving by
construction unitarity when applied to the time-dependent Schr\"odinger
equation.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12956" title="Abstract">arXiv:2401.12956</a> [<a href="/pdf/2401.12956" title="Download PDF">pdf</a>, <a href="/format/2401.12956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining the Role of Peer Acknowledgements on Social Annotations:  Unraveling the Psychological Underpinnings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaoshan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haolun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lajoie%2C+S">Susanne Lajoie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This study explores the impact of peer acknowledgement on learner engagement
and implicit psychological attributes in written annotations on an online
social reading platform. Participants included 91 undergraduates from a large
North American University. Using log file data, we analyzed the relationship
between learners' received peer acknowledgement and their subsequent annotation
behaviours using cross-lag regression. Higher peer acknowledgements correlate
with increased initiation of annotations and responses to peer annotations. By
applying text mining techniques and calculating Shapley values to analyze 1,969
social annotation entries, we identified prominent psychological themes within
three dimensions (i.e., affect, cognition, and motivation) that foster peer
acknowledgment in digital social annotation. These themes include positive
affect, openness to learning and discussion, and expression of motivation. The
findings assist educators in improving online learning communities and provide
guidance to technology developers in designing effective prompts, drawing from
both implicit psychological cues and explicit learning behaviours.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12959" title="Abstract">arXiv:2401.12959</a> [<a href="/pdf/2401.12959" title="Download PDF">pdf</a>, <a href="/ps/2401.12959" title="Download PostScript">ps</a>, <a href="/format/2401.12959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Emojis :) in Useful Code Review Comments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sharif Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Eisty%2C+N+U">Nasir U. Eisty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for inclusion in the Proceedings of the 3rd Intl. Workshop on NL-based Software Engineering co-located at 46th International Conference on Software Engineering (NLBSE@ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Emojis and emoticons serve as non-verbal cues and are increasingly prevalent
across various platforms, including Modern Code Review. These cues often carry
emotive or instructive weight for developers. Our study dives into the utility
of Code Review comments (CR comments) by scrutinizing the sentiments and
semantics conveyed by emojis within these comments. To assess the usefulness of
CR comments, we augment traditional 'textual' features and pre-trained
embeddings with 'emoji-specific' features and pre-trained embeddings. To
fortify our inquiry, we expand an existing dataset with emoji annotations,
guided by existing research on GitHub emoji usage, and re-evaluate the CR
comments accordingly. Our models, which incorporate textual and emoji-based
sentiment features and semantic understandings of emojis, substantially
outperform baseline metrics. The often-overlooked emoji elements in CR comments
emerge as key indicators of usefulness, suggesting that these symbols carry
significant weight.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12961" title="Abstract">arXiv:2401.12961</a> [<a href="/pdf/2401.12961" title="Download PDF">pdf</a>, <a href="/format/2401.12961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chatterbox: Robust Transport for LLM Token Streaming under Unstable  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hanchen Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuhan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yihua Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+S">Siddhant Ray</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Kuntai Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junchen Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">To render each generated token in real time, the LLM server generates
response tokens one by one and streams each generated token (or group of a few
tokens) through the network to the user right after it is generated, which we
refer to as LLM token streaming. However, under unstable network conditions,
the LLM token streaming experience could suffer greatly from stalls since one
packet loss could block the rendering of tokens contained in subsequent packets
even if they arrive on time. With a real-world measurement study, we show that
current applications including ChatGPT, Claude, and Bard all suffer from
increased stall under unstable network.
<br />For this emerging token streaming problem in LLM Chatbots, we propose a novel
transport layer scheme, called Chatterbox, which puts new generated tokens as
well as currently unacknowledged tokens in the next outgoing packet. This
ensures that each packet contains some new tokens and can be independently
rendered when received, thus avoiding aforementioned stalls caused by missing
packets. Through simulation under various network conditions, we show
Chatterbox reduces stall ratio (proportion of token rendering wait time) by
71.0% compared to the token streaming method commonly used by real chatbot
applications and by 31.6% compared to a custom packet duplication scheme. By
tailoring Chatterbox to fit the token-by-token generation of LLM, we enable the
Chatbots to respond like an eloquent speaker for users to better enjoy
pervasive AI.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12962" title="Abstract">arXiv:2401.12962</a> [<a href="/pdf/2401.12962" title="Download PDF">pdf</a>, <a href="/format/2401.12962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via  Cyclic Schedulers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liyanaarachchi%2C+S">Sahan Liyanaarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>, 
<a href="/search/cs?searchtype=author&query=Akar%2C+N">Nail Akar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
<p class="mathjax">In a communication setting where multiple sources share a single channel to
provide status updates to a remote monitor, source transmissions need to be
scheduled appropriately to maintain timely communication between each of the
sources and the monitor. We consider age-agnostic scheduling policies which are
advantageous due to their simplicity of implementation. Further, we focus on a
special class of age-agnostic policies, called cyclic schedulers, where each
source is scheduled based on a fixed cyclic pattern. We use weighted average
age of information (AoI) to quantify the timeliness of communication. We
develop a Markov chain formulation to compute the exact mean AoI for the case
of two-source cyclic schedulers. Based on the obtained age expression, we
develop an algorithm that generates near-optimal cyclic schedulers to minimize
the weighted average AoI for two heterogeneous sources, in the presence of
channel errors.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12963" title="Abstract">arXiv:2401.12963</a> [<a href="/pdf/2401.12963" title="Download PDF">pdf</a>, <a href="/format/2401.12963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoRT: Embodied Foundation Models for Large Scale Orchestration of  Robotic Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+M">Michael Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Dwibedi%2C+D">Debidatta Dwibedi</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Arenas%2C+M+G">Montse Gonzalez Arenas</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishnan%2C+K">Keerthana Gopalakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Hausman%2C+K">Karol Hausman</a>, 
<a href="/search/cs?searchtype=author&query=Ichter%2C+B">Brian Ichter</a>, 
<a href="/search/cs?searchtype=author&query=Irpan%2C+A">Alex Irpan</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+N">Nikhil Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Julian%2C+R">Ryan Julian</a>, 
<a href="/search/cs?searchtype=author&query=Kirmani%2C+S">Sean Kirmani</a>, 
<a href="/search/cs?searchtype=author&query=Leal%2C+I">Isabel Leal</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Edward Lee</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Leal%2C+I">Isabel Leal</a>, 
<a href="/search/cs?searchtype=author&query=Maddineni%2C+S">Sharath Maddineni</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+K">Kanishka Rao</a>, 
<a href="/search/cs?searchtype=author&query=Sadigh%2C+D">Dorsa Sadigh</a>, 
<a href="/search/cs?searchtype=author&query=Sanketi%2C+P">Pannag Sanketi</a>, 
<a href="/search/cs?searchtype=author&query=Sermanet%2C+P">Pierre Sermanet</a>, 
<a href="/search/cs?searchtype=author&query=Vuong%2C+Q">Quan Vuong</a>, 
<a href="/search/cs?searchtype=author&query=Welker%2C+S">Stefan Welker</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+F">Fei Xia</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Ted Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Steve Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Foundation models that incorporate language, vision, and more recently
actions have revolutionized the ability to harness internet scale data to
reason about useful tasks. However, one of the key challenges of training
embodied foundation models is the lack of data grounded in the physical world.
In this paper, we propose AutoRT, a system that leverages existing foundation
models to scale up the deployment of operational robots in completely unseen
scenarios with minimal human supervision. AutoRT leverages vision-language
models (VLMs) for scene understanding and grounding, and further uses large
language models (LLMs) for proposing diverse and novel instructions to be
performed by a fleet of robots. Guiding data collection by tapping into the
knowledge of foundation models enables AutoRT to effectively reason about
autonomy tradeoffs and safety while significantly scaling up data collection
for robot learning. We demonstrate AutoRT proposing instructions to over 20
robots across multiple buildings and collecting 77k real robot episodes via
both teleoperation and autonomous robot policies. We experimentally show that
such "in-the-wild" data collected by AutoRT is significantly more diverse, and
that AutoRT's use of LLMs allows for instruction following data collection
robots that can align to human preferences.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12965" title="Abstract">arXiv:2401.12965</a> [<a href="/pdf/2401.12965" title="Download PDF">pdf</a>, <a href="/format/2401.12965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Workspace Optimization Techniques to Improve Prediction of Human Motion  During Human-Robot Collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tung%2C+Y">Yi-Shiuan Tung</a>, 
<a href="/search/cs?searchtype=author&query=Luebbers%2C+M+B">Matthew B. Luebbers</a>, 
<a href="/search/cs?searchtype=author&query=Roncone%2C+A">Alessandro Roncone</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+B">Bradley Hayes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Conference on Human-Robot Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Understanding human intentions is critical for safe and effective human-robot
collaboration. While state of the art methods for human goal prediction utilize
learned models to account for the uncertainty of human motion data, that data
is inherently stochastic and high variance, hindering those models' utility for
interactions requiring coordination, including safety-critical or
close-proximity tasks. Our key insight is that robot teammates can deliberately
configure shared workspaces prior to interaction in order to reduce the
variance in human motion, realizing classifier-agnostic improvements in goal
prediction. In this work, we present an algorithmic approach for a robot to
arrange physical objects and project "virtual obstacles" using augmented
reality in shared human-robot workspaces, optimizing for human legibility over
a given set of tasks. We compare our approach against other workspace
arrangement strategies using two human-subjects studies, one in a virtual 2D
navigation domain and the other in a live tabletop manipulation domain
involving a robotic manipulator arm. We evaluate the accuracy of human motion
prediction models learned from each condition, demonstrating that our workspace
optimization technique with virtual obstacles leads to higher robot prediction
accuracy using less training data.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12970" title="Abstract">arXiv:2401.12970</a> [<a href="/pdf/2401.12970" title="Download PDF">pdf</a>, <a href="/format/2401.12970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Raidar: geneRative AI Detection viA Rewriting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengzhi Mao</a>, 
<a href="/search/cs?searchtype=author&query=Vondrick%2C+C">Carl Vondrick</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Junfeng Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We find that large language models (LLMs) are more likely to modify
human-written text than AI-generated text when tasked with rewriting. This
tendency arises because LLMs often perceive AI-generated text as high-quality,
leading to fewer modifications. We introduce a method to detect AI-generated
content by prompting LLMs to rewrite text and calculating the editing distance
of the output. We dubbed our geneRative AI Detection viA Rewriting method
Raidar. Raidar significantly improves the F1 detection scores of existing AI
content detection models -- both academic and commercial -- across various
domains, including News, creative writing, student essays, code, Yelp reviews,
and arXiv papers, with gains of up to 29 points. Operating solely on word
symbols without high-dimensional features, our method is compatible with black
box LLMs, and is inherently robust on new content. Our results illustrate the
unique imprint of machine-generated text through the lens of the machines
themselves.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12972" title="Abstract">arXiv:2401.12972</a> [<a href="/pdf/2401.12972" title="Download PDF">pdf</a>, <a href="/format/2401.12972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Efficacy of Text-Based Input Modalities for Action Anticipation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beedu%2C+A">Apoorva Beedu</a>, 
<a href="/search/cs?searchtype=author&query=Samel%2C+K">Karan Samel</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Although the task of anticipating future actions is highly uncertain,
information from additional modalities help to narrow down plausible action
choices. Each modality provides different environmental context for the model
to learn from. While previous multi-modal methods leverage information from
modalities such as video and audio, we primarily explore how text inputs for
actions and objects can also enable more accurate action anticipation.
Therefore, we propose a Multi-modal Anticipative Transformer (MAT), an
attention-based video transformer architecture that jointly learns from
multi-modal features and text captions. We train our model in two-stages, where
the model first learns to predict actions in the video clip by aligning with
captions, and during the second stage, we fine-tune the model to predict future
actions. Compared to existing methods, MAT has the advantage of learning
additional environmental context from two kinds of text inputs: action
descriptions during the pre-training stage, and the text inputs for detected
objects and actions during modality feature fusion. Through extensive
experiments, we evaluate the effectiveness of the pre-training stage, and show
that our model outperforms previous methods on all datasets. In addition, we
examine the impact of object and action information obtained via text and
perform extensive ablations. We evaluate the performance on on three datasets:
EpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that text
descriptions do indeed aid in more effective action anticipation.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12973" title="Abstract">arXiv:2401.12973</a> [<a href="/pdf/2401.12973" title="Download PDF">pdf</a>, <a href="/format/2401.12973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Context Language Learning: Arhitectures and Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aky%C3%BCrek%2C+E">Ekin Aky&#xfc;rek</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bailin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale neural language models exhibit a remarkable capacity for
in-context learning (ICL): they can infer novel functions from datasets
provided as input. Most of our current understanding of when and how ICL arises
comes from LMs trained on extremely simple learning problems like linear
regression and associative recall. There remains a significant gap between
these model problems and the "real" ICL exhibited by LMs trained on large text
corpora, which involves not just retrieval and function approximation but
free-form generation of language and other structured outputs. In this paper,
we study ICL through the lens of a new family of model problems we term in
context language learning (ICLL). In ICLL, LMs are presented with a set of
strings from a formal language, and must generate additional strings from the
same language. We focus on in-context learning of regular languages generated
by random finite automata. We evaluate a diverse set of neural sequence models
(including several RNNs, Transformers, and state-space model variants) on
regular ICLL tasks, aiming to answer three questions: (1) Which model classes
are empirically capable of ICLL? (2) What algorithmic solutions do successful
models implement to perform ICLL? (3) What architectural changes can improve
ICLL in less performant models? We first show that Transformers significantly
outperform neural sequence models with recurrent or convolutional
representations on ICLL tasks. Next, we provide evidence that their ability to
do so relies on specialized "n-gram heads" (higher-order variants of induction
heads) that compute input-conditional next-token distributions. Finally, we
show that hard-wiring these heads into recurrent and convolutional models
improves performance not just on ICLL, but natural language modeling --
improving the perplexity of 340M-parameter models by up to 1.14 points (6.7%)
on the SlimPajama dataset.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12975" title="Abstract">arXiv:2401.12975</a> [<a href="/pdf/2401.12975" title="Download PDF">pdf</a>, <a href="/format/2401.12975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAZARD Challenge: Embodied Decision Making in Dynamically Changing  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qinhong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sunli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yisong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haozhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Weihua Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J+B">Joshua B. Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+C">Chuang Gan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR 2024. The first two authors contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Recent advances in high-fidelity virtual environments serve as one of the
major driving forces for building intelligent embodied agents to perceive,
reason and interact with the physical world. Typically, these environments
remain unchanged unless agents interact with them. However, in real-world
scenarios, agents might also face dynamically changing environments
characterized by unexpected events and need to rapidly take action accordingly.
To remedy this gap, we propose a new simulated embodied benchmark, called
HAZARD, specifically designed to assess the decision-making abilities of
embodied agents in dynamic situations. HAZARD consists of three unexpected
disaster scenarios, including fire, flood, and wind, and specifically supports
the utilization of large language models (LLMs) to assist common sense
reasoning and decision-making. This benchmark enables us to evaluate autonomous
agents' decision-making capabilities across various pipelines, including
reinforcement learning (RL), rule-based, and search-based methods in
dynamically changing environments. As a first step toward addressing this
challenge using large language models, we further develop an LLM-based agent
and perform an in-depth analysis of its promise and challenge of solving these
challenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12977" title="Abstract">arXiv:2401.12977</a> [<a href="/pdf/2401.12977" title="Download PDF">pdf</a>, <a href="/format/2401.12977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhi-Hao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jia-Bin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Richardt%2C+C">Christian Richardt</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tuotuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Zollh%C3%B6fer%2C+M">Michael Zollh&#xf6;fer</a>, 
<a href="/search/cs?searchtype=author&query=Kopf%2C+J">Johannes Kopf</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shenlong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C">Changil Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Website: <a href="https://irisldr.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">While numerous 3D reconstruction and novel-view synthesis methods allow for
photorealistic rendering of a scene from multi-view images easily captured with
consumer cameras, they bake illumination in their representations and fall
short of supporting advanced applications like material editing, relighting,
and virtual object insertion. The reconstruction of physically based material
properties and lighting via inverse rendering promises to enable such
applications.
<br />However, most inverse rendering techniques require high dynamic range (HDR)
images as input, a setting that is inaccessible to most users. We present a
method that recovers the physically based material properties and
spatially-varying HDR lighting of a scene from multi-view, low-dynamic-range
(LDR) images. We model the LDR image formation process in our inverse rendering
pipeline and propose a novel optimization strategy for material, lighting, and
a camera response model. We evaluate our approach with synthetic and real
scenes compared to the state-of-the-art inverse rendering methods that take
either LDR or HDR input. Our method outperforms existing methods taking LDR
images as input, and allows for highly realistic relighting and object
insertion.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12978" title="Abstract">arXiv:2401.12978</a> [<a href="/pdf/2401.12978" title="Download PDF">pdf</a>, <a href="/format/2401.12978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Learning for the Primitives of 3D Affordance in General  Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonwoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sookwan Han</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+P">Patrick Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://sshowbiz.github.io/ZSP3A/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">One of the major challenges in AI is teaching machines to precisely respond
and utilize environmental functionalities, thereby achieving the affordance
awareness that humans possess. Despite its importance, the field has been
lagging in terms of learning, especially in 3D, as annotating affordance
accompanies a laborious process due to the numerous variations of human-object
interaction. The low availability of affordance data limits the learning in
terms of generalization for object categories, and also simplifies the
representation of affordance, capturing only a fraction of the affordance. To
overcome these challenges, we propose a novel, self-supervised method to
generate the 3D affordance examples given only a 3D object, without any manual
annotations. The method starts by capturing the 3D object into images and
creating 2D affordance images by inserting humans into the image via inpainting
diffusion models, where we present the Adaptive Mask algorithm to enable human
insertion without altering the original details of the object. The method
consequently lifts inserted humans back to 3D to create 3D human-object pairs,
where the depth ambiguity is resolved within a depth optimization framework
that utilizes pre-generated human postures from multiple viewpoints. We also
provide a novel affordance representation defined on relative orientations and
proximity between dense human and object points, that can be easily aggregated
from any 3D HOI datasets. The proposed representation serves as a primitive
that can be manifested to conventional affordance representations via simple
transformations, ranging from physically exerted affordances to nonphysical
ones. We demonstrate the efficacy of our method and representation by
generating the 3D affordance samples and deriving high-quality affordance
examples from the representation, including contact, orientation, and spatial
occupancies.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12979" title="Abstract">arXiv:2401.12979</a> [<a href="/pdf/2401.12979" title="Download PDF">pdf</a>, <a href="/format/2401.12979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GALA: Generating Animatable Layered Assets from a Single Scan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taeksoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byungjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+S">Shunsuke Saito</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The project page is available at <a href="https://snuvclab.github.io/gala/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present GALA, a framework that takes as input a single-layer clothed 3D
human mesh and decomposes it into complete multi-layered 3D assets. The outputs
can then be combined with other assets to create novel clothed human avatars
with any pose. Existing reconstruction approaches often treat clothed humans as
a single-layer of geometry and overlook the inherent compositionality of humans
with hairstyles, clothing, and accessories, thereby limiting the utility of the
meshes for downstream applications. Decomposing a single-layer mesh into
separate layers is a challenging task because it requires the synthesis of
plausible geometry and texture for the severely occluded regions. Moreover,
even with successful decomposition, meshes are not normalized in terms of poses
and body shapes, failing coherent composition with novel identities and poses.
To address these challenges, we propose to leverage the general knowledge of a
pretrained 2D diffusion model as geometry and appearance prior for humans and
other assets. We first separate the input mesh using the 3D surface
segmentation extracted from multi-view 2D segmentations. Then we synthesize the
missing geometry of different layers in both posed and canonical spaces using a
novel pose-guided Score Distillation Sampling (SDS) loss. Once we complete
inpainting high-fidelity 3D geometry, we also apply the same SDS loss to its
texture to obtain the complete appearance including the initially occluded
regions. Through a series of decomposition steps, we obtain multiple layers of
3D assets in a shared canonical space normalized in terms of poses and human
shapes, hence supporting effortless composition to novel identities and
reanimation with novel poses. Our experiments demonstrate the effectiveness of
our approach for decomposition, canonicalization, and composition tasks
compared to existing solutions.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Wed, 24 Jan 24</h3>
<dl>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12064" title="Abstract">arXiv:2401.12064</a> (cross-list from econ.GN) [<a href="/pdf/2401.12064" title="Download PDF">pdf</a>, <a href="/ps/2401.12064" title="Download PostScript">ps</a>, <a href="/format/2401.12064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Market Responses to Genuine Versus Strategic Generosity: An Empirical  Examination of NFT Charity Fundraisers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Liang%2C+C">Chen Liang</a>, 
<a href="/search/econ?searchtype=author&query=Tunc%2C+M">Murat Tunc</a>, 
<a href="/search/econ?searchtype=author&query=Burtch%2C+G">Gordon Burtch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Crypto donations now represent a significant fraction of charitable giving
worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale
of NFTs of artistic works with the proceeds donated to philanthropic causes,
have emerged as a novel development in this space. A unique aspect of NFT
charity fundraisers is the significant potential for donors to reap financial
gains from the rising value of purchased NFTs. Questions may arise about the
motivations of donors in these charity fundraisers, resulting in a negative
social image. NFT charity fundraisers thus offer a unique opportunity to
understand the economic consequences of a donor's social image. We investigate
these effects in the context of a large NFT charity fundraiser. We identify the
causal effect of purchasing an NFT within the charity fundraiser on a donor's
later market outcomes by leveraging random variation in transaction processing
times on the blockchain. Further, we demonstrate a clear pattern of
heterogeneity, based on an individual's decision to relist (versus hold) the
purchased charity NFTs (a sign of strategic generosity), and based on an
individual's degree of social exposure within the NFT marketplace. We show that
charity-NFT "relisters" experience significant penalties in the market, in
terms of the prices they are able to command on other NFT listings,
particularly among those who relist quickly and those who are more socially
exposed. Our study underscores the growing importance of digital visibility and
traceability, features that characterize crypto-philanthropy, and online
philanthropy more broadly.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12196" title="Abstract">arXiv:2401.12196</a> (cross-list from physics.bio-ph) [<a href="/pdf/2401.12196" title="Download PDF">pdf</a>, <a href="/format/2401.12196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Dynamics from Multicellular Graphs with Deep Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yang%2C+H">Haiqian Yang</a>, 
<a href="/search/physics?searchtype=author&query=Meyer%2C+F">Florian Meyer</a>, 
<a href="/search/physics?searchtype=author&query=Huang%2C+S">Shaoxun Huang</a>, 
<a href="/search/physics?searchtype=author&query=Yang%2C+L">Liu Yang</a>, 
<a href="/search/physics?searchtype=author&query=Lungu%2C+C">Cristiana Lungu</a>, 
<a href="/search/physics?searchtype=author&query=Olayioye%2C+M+A">Monilola A. Olayioye</a>, 
<a href="/search/physics?searchtype=author&query=Buehler%2C+M+J">Markus J. Buehler</a>, 
<a href="/search/physics?searchtype=author&query=Guo%2C+M">Ming Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG)

</div>
<p class="mathjax">The inference of multicellular self-assembly is the central quest of
understanding morphogenesis, including embryos, organoids, tumors, and many
others. However, it has been tremendously difficult to identify structural
features that can indicate multicellular dynamics. Here we propose to harness
the predictive power of graph-based deep neural networks (GNN) to discover
important graph features that can predict dynamics. To demonstrate, we apply a
physically informed GNN (piGNN) to predict the motility of multicellular
collectives from a snapshot of their positions both in experiments and
simulations. We demonstrate that piGNN is capable of navigating through complex
graph features of multicellular living systems, which otherwise can not be
achieved by classical mechanistic models. With increasing amounts of
multicellular data, we propose that collaborative efforts can be made to create
a multicellular data bank (MDB) from which it is possible to construct a large
multicellular graph model (LMGM) for general-purposed predictions of
multicellular organization.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12232" title="Abstract">arXiv:2401.12232</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.12232" title="Download PDF">pdf</a>, <a href="/ps/2401.12232" title="Download PostScript">ps</a>, <a href="/format/2401.12232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Modeling Of SiRNA Structure-Potency Relationship With  Applications Against Sars-Cov-2 Spike Gene
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Oshunyinka%2C+D">Damilola Oshunyinka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Master's thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The pharmaceutical Research and development (R&amp;D) process is lengthy and
costly, taking nearly a decade to bring a new drug to the market. However,
advancements in biotechnology, computational methods, and machine learning
algorithms have the potential to revolutionize drug discovery, speeding up the
process and improving patient outcomes. The COVID-19 pandemic has further
accelerated and deepened the recognition of the potential of these techniques,
especially in the areas of drug repurposing and efficacy predictions.
Meanwhile, non-small molecule therapeutic modalities such as cell therapies,
monoclonal antibodies, and RNA interference (RNAi) technology have gained
importance due to their ability to target specific disease pathways and/or
patient populations. In the field of RNAi, many experiments have been carried
out to design and select highly efficient siRNAs. However, the established
patterns for efficient siRNAs are sometimes contradictory and unable to
consistently determine the most potent siRNA molecules against a target mRNA.
Thus, this paper focuses on developing machine learning models based on the
cheminformatics representation of the nucleotide composition (i.e. AUTGC) of
siRNA to predict their potency and aid the selection of the most efficient
siRNAs for further development. The PLS (Partial Least Square) and SVR (Support
Vector Regression) machine learning models built in this work outperformed
previously published models. These models can help in predicting siRNA potency
and aid in selecting the best siRNA molecules for experimental validation and
further clinical development. The study has demonstrated the potential of
AI/machine learning models to help expedite siRNA-based drug discovery
including the discovery of potent siRNAs against SARS-CoV-2.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12237" title="Abstract">arXiv:2401.12237</a> (cross-list from math.AT) [<a href="/pdf/2401.12237" title="Download PDF">pdf</a>, <a href="/format/2401.12237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A distribution-guided Mapper algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tao%2C+Y">Yuyang Tao</a>, 
<a href="/search/math?searchtype=author&query=Ge%2C+S">Shufei Ge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Motivation: The Mapper algorithm is an essential tool to explore shape of
data in topology data analysis. With a dataset as an input, the Mapper
algorithm outputs a graph representing the topological features of the whole
dataset. This graph is often regarded as an approximation of a reeb graph of
data. The classic Mapper algorithm uses fixed interval lengths and overlapping
ratios, which might fail to reveal subtle features of data, especially when the
underlying structure is complex.
<br />Results: In this work, we introduce a distribution guided Mapper algorithm
named D-Mapper, that utilizes the property of the probability model and data
intrinsic characteristics to generate density guided covers and provides
enhanced topological features. Our proposed algorithm is a probabilistic
model-based approach, which could serve as an alternative to non-prababilistic
ones. Moreover, we introduce a metric accounting for both the quality of
overlap clustering and extended persistence homology to measure the performance
of Mapper type algorithm. Our numerical experiments indicate that the D-Mapper
outperforms the classical Mapper algorithm in various scenarios. We also apply
the D-Mapper to a SARS-COV-2 coronavirus RNA sequences dataset to explore the
topological structure of different virus variants. The results indicate that
the D-Mapper algorithm can reveal both vertical and horizontal evolution
processes of the viruses.
<br />Availability: Our package is available at
https://github.com/ShufeiGe/D-Mapper.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12238" title="Abstract">arXiv:2401.12238</a> (cross-list from eess.AS) [<a href="/pdf/2401.12238" title="Download PDF">pdf</a>, <a href="/format/2401.12238" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial Scaper: A Library to Simulate and Augment Soundscapes for Sound  Event Localization and Detection in Realistic Rooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Roman%2C+I+R">Iran R. Roman</a>, 
<a href="/search/eess?searchtype=author&query=Ick%2C+C">Christopher Ick</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+S">Sivan Ding</a>, 
<a href="/search/eess?searchtype=author&query=Roman%2C+A+S">Adrian S. Roman</a>, 
<a href="/search/eess?searchtype=author&query=McFee%2C+B">Brian McFee</a>, 
<a href="/search/eess?searchtype=author&query=Bello%2C+J+P">Juan P. Bello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, 1 table, to be presented at ICASSP 2024 in Seoul, South Korea
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Sound event localization and detection (SELD) is an important task in machine
listening. Major advancements rely on simulated data with sound events in
specific rooms and strong spatio-temporal labels. SELD data is simulated by
convolving spatialy-localized room impulse responses (RIRs) with sound
waveforms to place sound events in a soundscape. However, RIRs require manual
collection in specific rooms. We present SpatialScaper, a library for SELD data
simulation and augmentation. Compared to existing tools, SpatialScaper emulates
virtual rooms via parameters such as size and wall absorption. This allows for
parameterized placement (including movement) of foreground and background sound
sources. SpatialScaper also includes data augmentation pipelines that can be
applied to existing SELD data. As a case study, we use SpatialScaper to add
rooms to the DCASE SELD data. Training a model with our data led to progressive
performance improves as a direct function of acoustic diversity. These results
show that SpatialScaper is valuable to train robust SELD models.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12243" title="Abstract">arXiv:2401.12243</a> (cross-list from math.OC) [<a href="/pdf/2401.12243" title="Download PDF">pdf</a>, <a href="/format/2401.12243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Generation Policy Optimization (CGPO): Nonlinear Programming  for Policy Optimization in Mixed Discrete-Continuous MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gimelfarb%2C+M">Michael Gimelfarb</a>, 
<a href="/search/math?searchtype=author&query=Taitler%2C+A">Ayal Taitler</a>, 
<a href="/search/math?searchtype=author&query=Sanner%2C+S">Scott Sanner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Robotics (cs.RO); Symbolic Computation (cs.SC); Systems and Control (eess.SY)

</div>
<p class="mathjax">We propose Constraint-Generation Policy Optimization (CGPO) for optimizing
policy parameters within compact and interpretable policy classes for mixed
discrete-continuous Markov Decision Processes (DC-MDPs). CGPO is not only able
to provide bounded policy error guarantees over an infinite range of initial
states for many DC-MDPs with expressive nonlinear dynamics, but it can also
provably derive optimal policies in cases where it terminates with zero error.
Furthermore, CGPO can generate worst-case state trajectories to diagnose policy
deficiencies and provide counterfactual explanations of optimal actions. To
achieve such results, CGPO proposes a bi-level mixed-integer nonlinear
optimization framework for optimizing policies within defined expressivity
classes (i.e. piecewise (non)-linear) and reduces it to an optimal constraint
generation methodology that adversarially generates worst-case state
trajectories. Furthermore, leveraging modern nonlinear optimizers, CGPO can
obtain solutions with bounded optimality gap guarantees. We handle stochastic
transitions through explicit marginalization (where applicable) or
chance-constraints, providing high-probability policy performance guarantees.
We also present a road-map for understanding the computational complexities
associated with different expressivity classes of policy, reward, and
transition dynamics. We experimentally demonstrate the applicability of CGPO in
diverse domains, including inventory control, management of a system of water
reservoirs, and physics control. In summary, we provide a solution for deriving
structured, compact, and explainable policies with bounded performance
guarantees, enabling worst-case scenario generation and counterfactual policy
diagnostics.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12248" title="Abstract">arXiv:2401.12248</a> (cross-list from quant-ph) [<a href="/pdf/2401.12248" title="Download PDF">pdf</a>, <a href="/format/2401.12248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A two-circuit approach to reducing quantum resources for the quantum  lattice Boltzmann method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kocherla%2C+S">Sriharsha Kocherla</a>, 
<a href="/search/quant-ph?searchtype=author&query=Adams%2C+A">Austin Adams</a>, 
<a href="/search/quant-ph?searchtype=author&query=Song%2C+Z">Zhixin Song</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alexeev%2C+A">Alexander Alexeev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Bryngelson%2C+S+H">Spencer H. Bryngelson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Computational fluid dynamics (CFD) simulations often entail a large
computational burden on classical computers. At present, these simulations can
require up to trillions of grid points and millions of time steps. To reduce
costs, novel architectures like quantum computers may be intrinsically more
efficient at the appropriate computation. Current quantum algorithms for
solving CFD problems use a single quantum circuit and, in some cases,
lattice-based methods. We introduce the a novel multiple circuits algorithm
that makes use of a quantum lattice Boltzmann method (QLBM). The two-circuit
algorithm we form solves the Navier-Stokes equations with a marked reduction in
CNOT gates compared to existing QLBM circuits. The problem is cast as a stream
function--vorticity formulation of the 2D Navier-Stokes equations and verified
and tested on a 2D lid-driven cavity flow. We show that using separate circuits
for the stream function and vorticity lead to a marked CNOT reduction: 35% in
total CNOT count and 16% in combined gate depth. This strategy has the
additional benefit of the circuits being able to run concurrently, further
halving the seen gate depth. This work is intended as a step towards practical
quantum circuits for solving differential equation-based problems of scientific
interest.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12253" title="Abstract">arXiv:2401.12253</a> (cross-list from math.OC) [<a href="/pdf/2401.12253" title="Download PDF">pdf</a>, <a href="/format/2401.12253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Sinkhorn Algorithm with Sparse Newton Iterations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tang%2C+X">Xun Tang</a>, 
<a href="/search/math?searchtype=author&query=Shavlovsky%2C+M">Michael Shavlovsky</a>, 
<a href="/search/math?searchtype=author&query=Rahmanian%2C+H">Holakou Rahmanian</a>, 
<a href="/search/math?searchtype=author&query=Tardini%2C+E">Elisa Tardini</a>, 
<a href="/search/math?searchtype=author&query=Thekumparampil%2C+K+K">Kiran Koshy Thekumparampil</a>, 
<a href="/search/math?searchtype=author&query=Xiao%2C+T">Tesi Xiao</a>, 
<a href="/search/math?searchtype=author&query=Ying%2C+L">Lexing Ying</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Computing the optimal transport distance between statistical distributions is
a fundamental task in machine learning. One remarkable recent advancement is
entropic regularization and the Sinkhorn algorithm, which utilizes only matrix
scaling and guarantees an approximated solution with near-linear runtime.
Despite the success of the Sinkhorn algorithm, its runtime may still be slow
due to the potentially large number of iterations needed for convergence. To
achieve possibly super-exponential convergence, we present
Sinkhorn-Newton-Sparse (SNS), an extension to the Sinkhorn algorithm, by
introducing early stopping for the matrix scaling steps and a second stage
featuring a Newton-type subroutine. Adopting the variational viewpoint that the
Sinkhorn algorithm maximizes a concave Lyapunov potential, we offer the insight
that the Hessian matrix of the potential function is approximately sparse.
Sparsification of the Hessian results in a fast $O(n^2)$ per-iteration
complexity, the same as the Sinkhorn algorithm. In terms of total iteration
count, we observe that the SNS algorithm converges orders of magnitude faster
across a wide range of practical cases, including optimal transportation
between empirical distributions and calculating the Wasserstein $W_1, W_2$
distance of discretized densities. The empirical performance is corroborated by
a rigorous bound on the approximate sparsity of the Hessian matrix.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12264" title="Abstract">arXiv:2401.12264</a> (cross-list from eess.AS) [<a href="/pdf/2401.12264" title="Download PDF">pdf</a>, <a href="/format/2401.12264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoAVT: A Cognition-Inspired Unified Audio-Visual-Text Pre-Training Model  for Multimodal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yue%2C+X">Xianghu Yue</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+X">Xiaohai Tian</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Multimedia (cs.MM); Sound (cs.SD); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">There has been a long-standing quest for a unified audio-visual-text model to
enable various multimodal understanding tasks, which mimics the listening,
seeing and reading process of human beings. Humans tends to represent knowledge
using two separate systems: one for representing verbal (textual) information
and one for representing non-verbal (visual and auditory) information. These
two systems can operate independently but can also interact with each other.
Motivated by this understanding of human cognition, in this paper, we introduce
CoAVT -- a novel cognition-inspired Correlated Audio-Visual-Text pre-training
model to connect the three modalities. It contains a joint audio-visual encoder
that learns to encode audio-visual synchronization information together with
the audio and visual content for non-verbal information, and a text encoder to
handle textual input for verbal information. To bridge the gap between
modalities, CoAVT employs a query encoder, which contains a set of learnable
query embeddings, and extracts the most informative audiovisual features of the
corresponding text. Additionally, to leverage the correspondences between audio
and vision with language respectively, we also establish the audio-text and
visual-text bi-modal alignments upon the foundational audiovisual-text
tri-modal alignment to enhance the multimodal representation learning. Finally,
we jointly optimize CoAVT model with three multimodal objectives: contrastive
loss, matching loss and language modeling loss. Extensive experiments show that
CoAVT can learn strong multimodal correlations and be generalized to various
downstream tasks. CoAVT establishes new state-of-the-art performance on
text-video retrieval task on AudioCaps for both zero-shot and fine-tuning
settings, audio-visual event classification and audio-visual retrieval tasks on
AudioSet and VGGSound.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12272" title="Abstract">arXiv:2401.12272</a> (cross-list from stat.ML) [<a href="/pdf/2401.12272" title="Download PDF">pdf</a>, <a href="/format/2401.12272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transfer Learning for Nonparametric Regression: Non-asymptotic Minimax  Analysis and Adaptive Procedure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Cai%2C+T+T">T. Tony Cai</a>, 
<a href="/search/stat?searchtype=author&query=Pu%2C+H">Hongming Pu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Transfer learning for nonparametric regression is considered. We first study
the non-asymptotic minimax risk for this problem and develop a novel estimator
called the confidence thresholding estimator, which is shown to achieve the
minimax optimal risk up to a logarithmic factor. Our results demonstrate two
unique phenomena in transfer learning: auto-smoothing and super-acceleration,
which differentiate it from nonparametric regression in a traditional setting.
We then propose a data-driven algorithm that adaptively achieves the minimax
risk up to a logarithmic factor across a wide range of parameter spaces.
Simulation studies are conducted to evaluate the numerical performance of the
adaptive transfer learning algorithm, and a real-world example is provided to
demonstrate the benefits of the proposed method.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12329" title="Abstract">arXiv:2401.12329</a> (cross-list from physics.soc-ph) [<a href="/pdf/2401.12329" title="Download PDF">pdf</a>, <a href="/ps/2401.12329" title="Download PostScript">ps</a>, <a href="/format/2401.12329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a prioritised use of transportation infrastructures: the case of  vehicle-specific dynamic access restrictions to city centres
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Billhardt%2C+H">Holger Billhardt</a>, 
<a href="/search/physics?searchtype=author&query=Fern%C3%A1ndez%2C+A">Alberto Fern&#xe1;ndez</a>, 
<a href="/search/physics?searchtype=author&query=Mart%C3%AD%2C+P">Pasqual Mart&#xed;</a>, 
<a href="/search/physics?searchtype=author&query=Tejedor%2C+J+P">Javier Prieto Tejedor</a>, 
<a href="/search/physics?searchtype=author&query=Ossowski%2C+S">Sascha Ossowski</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Electronics, Volume 11, Issue 4 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Physics and Society (physics.soc-ph)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">One of the main problems that local authorities of large cities have to face
is the regulation of urban mobility. They need to provide the means to allow
for the efficient movement of people and distribution of goods. However, the
provisioning of transportation services needs to take into account general
global objectives, like reducing emissions and having more healthy living
environments, which may not always be aligned with individual interests. Urban
mobility is usually provided through a transport infrastructure that includes
all the elements that support mobility. On many occasions, the capacity of the
elements of this infrastructure is lower than the actual demand and thus
different transportation activities compete for their use. In this paper, we
argue that scarce transport infrastructure elements should be assigned
dynamically and in a prioritised manner to transport activities that have a
higher utility from the point of view of society; for example, activities that
produce less pollution and provide more value to society. In this paper, we
define a general model for prioritizing the use of a particular type of
transportation infrastructure element called time-unlimited elements, whose
usage time is unknown a priori, and illustrate its dynamics through two use
cases: vehicle-specific dynamic access restriction in city centres (i) based on
the usage levels of available parking spaces and (ii) to assure sustained
admissible air quality levels in the city centre. We carry out several
experiments using the SUMO traffic simulation tool to evaluate our proposal.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12362" title="Abstract">arXiv:2401.12362</a> (cross-list from stat.ML) [<a href="/pdf/2401.12362" title="Download PDF">pdf</a>, <a href="/format/2401.12362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VC dimension of Graph Neural Networks with Pfaffian activation functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=D%27Inverno%2C+G+A">Giuseppe Alessio D&#x27;Inverno</a>, 
<a href="/search/stat?searchtype=author&query=Bianchini%2C+M">Monica Bianchini</a>, 
<a href="/search/stat?searchtype=author&query=Scarselli%2C+F">Franco Scarselli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool
to learn tasks across a wide range of graph domains in a data-driven fashion;
based on a message passing mechanism, GNNs have gained increasing popularity
due to their intuitive formulation, closely linked with the Weisfeiler-Lehman
(WL) test for graph isomorphism, to which they have proven equivalent. From a
theoretical point of view, GNNs have been shown to be universal approximators,
and their generalization capability (namely, bounds on the Vapnik Chervonekis
(VC) dimension) has recently been investigated for GNNs with piecewise
polynomial activation functions. The aim of our work is to extend this analysis
on the VC dimension of GNNs to other commonly used activation functions, such
as sigmoid and hyperbolic tangent, using the framework of Pfaffian function
theory. Bounds are provided with respect to architecture parameters (depth,
number of neurons, input size) as well as with respect to the number of colors
resulting from the 1-WL test applied on the graph domain. The theoretical
analysis is supported by a preliminary experimental study.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12366" title="Abstract">arXiv:2401.12366</a> (cross-list from econ.TH) [<a href="/pdf/2401.12366" title="Download PDF">pdf</a>, <a href="/format/2401.12366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach to Second and Third Degree Price Discrimination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Bergemann%2C+D">Dirk Bergemann</a>, 
<a href="/search/econ?searchtype=author&query=Heumann%2C+T">Tibor Heumann</a>, 
<a href="/search/econ?searchtype=author&query=Wang%2C+M+C">Michael C. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">We analyze the welfare impact of a monopolist able to segment a multiproduct
market and offer differentiated price menus within each segment. We
characterize a family of extremal distributions such that all achievable
welfare outcomes can be reached by selecting segments from within these
distributions. This family of distributions arises as the solution to the
consumer maximizing distribution of values for multigood markets. With these
results, we analyze the effect of segmentation on consumer surplus and prices
in both interior and extremal markets, including conditions under which there
exists a segmentation benefiting all consumers. Finally, we present an
efficient algorithm for computing segmentations.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12388" title="Abstract">arXiv:2401.12388</a> (cross-list from math.OC) [<a href="/pdf/2401.12388" title="Download PDF">pdf</a>, <a href="/ps/2401.12388" title="Download PostScript">ps</a>, <a href="/format/2401.12388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Objective Multi-mode Time-Cost Tradeoff modeling in Construction  Projects Considering Productivity Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mohammadjafari%2C+A">Ali Mohammadjafari</a>, 
<a href="/search/math?searchtype=author&query=Ghannadpour%2C+S+F">Seyed Farid Ghannadpour</a>, 
<a href="/search/math?searchtype=author&query=Bagherpour%2C+M">Morteza Bagherpour</a>, 
<a href="/search/math?searchtype=author&query=Zandieh%2C+F">Fatemeh Zandieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 20 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">In today's construction industry, poor performance often arises due to
various factors related to time, finances, and quality. These factors
frequently lead to project delays and resource losses, particularly in terms of
financial resources. This research addresses the Multimode Resource-Constrained
Project Scheduling Problem (MRCPSP), a real-world challenge that takes into
account the time value of money and project payment planning. In this context,
project activities exhibit discrete cost profiles under different execution
conditions and can be carried out in multiple ways. This paper aims to achieve
two primary objectives: minimizing the net present value of project costs and
project completion times while simultaneously improving the project's
productivity index. To accomplish this, a mathematical programming model based
on certain assumptions is proposed. Several test cases are designed, and they
are rigorously evaluated using the methodology outlined in this paper to
validate the modeling approach. Recognizing the NP-hard nature of this problem,
a multi-objective genetic algorithm capable of solving large-scale instances is
developed. Finally, the effectiveness of the proposed solution is assessed by
comparing it to the performance of the NSGA-II algorithm using well-established
efficiency metrics. Results demonstrate the superior performance of the
algorithm introduced in this study.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12438" title="Abstract">arXiv:2401.12438</a> (cross-list from eess.IV) [<a href="/pdf/2401.12438" title="Download PDF">pdf</a>, <a href="/format/2401.12438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Federated Learning Approaches to Diagnosing COVID-19
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Adhikari%2C+R">Rittika Adhikari</a>, 
<a href="/search/eess?searchtype=author&query=Settles%2C+C">Christopher Settles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent pandemic has underscored the importance of accurately diagnosing
COVID-19 in hospital settings. A major challenge in this regard is
differentiating COVID-19 from other respiratory illnesses based on chest
X-rays, compounded by the restrictions of HIPAA compliance which limit the
comparison of patient X-rays. This paper introduces a HIPAA-compliant model to
aid in the diagnosis of COVID-19, utilizing federated learning. Federated
learning is a distributed machine learning approach that allows for algorithm
training across multiple decentralized devices using local data samples,
without the need for data sharing. Our model advances previous efforts in chest
X-ray diagnostic models. We examined leading models from established
competitions in this domain and developed our own models tailored to be
effective with specific hospital data. Considering the model's operation in a
federated learning context, we explored the potential impact of biased data
updates on the model's performance. To enhance hospital understanding of the
model's decision-making process and to verify that the model is not focusing on
irrelevant features, we employed a visualization technique that highlights key
features in chest X-rays indicative of a positive COVID-19 diagnosis.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12440" title="Abstract">arXiv:2401.12440</a> (cross-list from eess.AS) [<a href="/pdf/2401.12440" title="Download PDF">pdf</a>, <a href="/ps/2401.12440" title="Download PostScript">ps</a>, <a href="/format/2401.12440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Post-Training Embedding Alignment for Decoupling Enrollment and Runtime  Speaker Recognition Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+C">Chenyang Gao</a>, 
<a href="/search/eess?searchtype=author&query=Desplanques%2C+B">Brecht Desplanques</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+C+J+-">Chelsea J.-T. Ju</a>, 
<a href="/search/eess?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/eess?searchtype=author&query=Stolcke%2C+A">Andreas Stolcke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Automated speaker identification (SID) is a crucial step for the
personalization of a wide range of speech-enabled services. Typical SID systems
use a symmetric enrollment-verification framework with a single model to derive
embeddings both offline for voice profiles extracted from enrollment
utterances, and online from runtime utterances. Due to the distinct
circumstances of enrollment and runtime, such as different computation and
latency constraints, several applications would benefit from an asymmetric
enrollment-verification framework that uses different models for enrollment and
runtime embedding generation. To support this asymmetric SID where each of the
two models can be updated independently, we propose using a lightweight neural
network to map the embeddings from the two independent models to a shared
speaker embedding space. Our results show that this approach significantly
outperforms cosine scoring in a shared speaker logit space for models that were
trained with a contrastive loss on large datasets with many speaker identities.
This proposed Neural Embedding Speaker Space Alignment (NESSA) combined with an
asymmetric update of only one of the models delivers at least 60% of the
performance gain achieved by updating both models in the standard symmetric SID
approach.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12473" title="Abstract">arXiv:2401.12473</a> (cross-list from eess.AS) [<a href="/pdf/2401.12473" title="Download PDF">pdf</a>, <a href="/format/2401.12473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Unknown-number Speaker Separation with Transformer  Decoder-based Attractor
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Younglo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+S">Shukjae Choi</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+B">Byeong-Yeol Kim</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhong-Qiu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">We propose a novel speech separation model designed to separate mixtures with
an unknown number of speakers. The proposed model stacks 1) a dual-path
processing block that can model spectro-temporal patterns, 2) a transformer
decoder-based attractor (TDA) calculation module that can deal with an unknown
number of speakers, and 3) triple-path processing blocks that can model
inter-speaker relations. Given a fixed, small set of learned speaker queries
and the mixture embedding produced by the dual-path blocks, TDA infers the
relations of these queries and generates an attractor vector for each speaker.
The estimated attractors are then combined with the mixture embedding by
feature-wise linear modulation conditioning, creating a speaker dimension. The
mixture embedding, conditioned with speaker information produced by TDA, is fed
to the final triple-path blocks, which augment the dual-path blocks with an
additional pathway dedicated to inter-speaker processing. The proposed approach
outperforms the previous best reported in the literature, achieving 24.0 and
23.7 dB SI-SDR improvement (SI-SDRi) on WSJ0-2 and 3mix respectively, with a
single model trained to separate 2- and 3-speaker mixtures. The proposed model
also exhibits strong performance and generalizability at counting sources and
separating mixtures with up to 5 speakers.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12476" title="Abstract">arXiv:2401.12476</a> (cross-list from stat.ML) [<a href="/pdf/2401.12476" title="Download PDF">pdf</a>, <a href="/format/2401.12476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian identification of nonseparable Hamiltonians with multiplicative  noise using deep learning and reduced-order modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Galioto%2C+N">Nicholas Galioto</a>, 
<a href="/search/stat?searchtype=author&query=Sharma%2C+H">Harsh Sharma</a>, 
<a href="/search/stat?searchtype=author&query=Kramer%2C+B">Boris Kramer</a>, 
<a href="/search/stat?searchtype=author&query=Gorodetsky%2C+A+A">Alex Arkady Gorodetsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Dynamical Systems (math.DS); Data Analysis, Statistics and Probability (physics.data-an); Computation (stat.CO)

</div>
<p class="mathjax">This paper presents a structure-preserving Bayesian approach for learning
nonseparable Hamiltonian systems using stochastic dynamic models allowing for
statistically-dependent, vector-valued additive and multiplicative measurement
noise. The approach is comprised of three main facets. First, we derive a
Gaussian filter for a statistically-dependent, vector-valued, additive and
multiplicative noise model that is needed to evaluate the likelihood within the
Bayesian posterior. Second, we develop a novel algorithm for cost-effective
application of Bayesian system identification to high-dimensional systems.
Third, we demonstrate how structure-preserving methods can be incorporated into
the proposed framework, using nonseparable Hamiltonians as an illustrative
system class. We compare the Bayesian method to a state-of-the-art machine
learning method on a canonical nonseparable Hamiltonian model and a chaotic
double pendulum model with small, noisy training datasets. The results show
that using the Bayesian posterior as a training objective can yield upwards of
724 times improvement in Hamiltonian mean squared error using training data
with up to 10% multiplicative noise compared to a standard training objective.
Lastly, we demonstrate the utility of the novel algorithm for parameter
estimation of a 64-dimensional model of the spatially-discretized nonlinear
Schr\"odinger equation with data corrupted by up to 20% multiplicative noise.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12488" title="Abstract">arXiv:2401.12488</a> (cross-list from eess.IV) [<a href="/pdf/2401.12488" title="Download PDF">pdf</a>, <a href="/ps/2401.12488" title="Download PostScript">ps</a>, <a href="/format/2401.12488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automated Real-Time Approach for Image Processing and Segmentation of  Fluoroscopic Images and Videos Using a Single Deep Learning Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+V+D">Viet Dung Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=LaCour%2C+M+T">Michael T. LaCour</a>, 
<a href="/search/eess?searchtype=author&query=Komistek%2C+R+D">Richard D. Komistek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Image segmentation in total knee arthroplasty is crucial for precise
preoperative planning and accurate implant positioning, leading to improved
surgical outcomes and patient satisfaction. The biggest challenges of image
segmentation in total knee arthroplasty include accurately delineating complex
anatomical structures, dealing with image artifacts and noise, and developing
robust algorithms that can handle anatomical variations and pathologies
commonly encountered in patients. The potential of using machine learning for
image segmentation in total knee arthroplasty lies in its ability to improve
segmentation accuracy, automate the process, and provide real-time assistance
to surgeons, leading to enhanced surgical planning, implant placement, and
patient outcomes. This paper proposes a methodology to use deep learning for
robust and real-time total knee arthroplasty image segmentation. The deep
learning model, trained on a large dataset, demonstrates outstanding
performance in accurately segmenting both the implanted femur and tibia,
achieving an impressive mean-Average-Precision (mAP) of 88.83 when compared to
the ground truth while also achieving a real-time segmented speed of 20 frames
per second (fps). We have introduced a novel methodology for segmenting
implanted knee fluoroscopic or x-ray images that showcases remarkable levels of
accuracy and speed, paving the way for various potential extended applications.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12490" title="Abstract">arXiv:2401.12490</a> (cross-list from math.OC) [<a href="/pdf/2401.12490" title="Download PDF">pdf</a>, <a href="/ps/2401.12490" title="Download PostScript">ps</a>, <a href="/format/2401.12490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank augmented Lagrangian method for large-scale semidefinite  programming based on a hybrid convex-nonconvex approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Monteiro%2C+R+D+C">Renato D.C. Monteiro</a>, 
<a href="/search/math?searchtype=author&query=Sujanani%2C+A">Arnesh Sujanani</a>, 
<a href="/search/math?searchtype=author&query=Cifuentes%2C+D">Diego Cifuentes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">This paper introduces HALLaR, a new first-order method for solving
large-scale semidefinite programs (SDPs) with bounded domain. HALLaR is an
inexact augmented Lagrangian (AL) method where the AL subproblems are solved by
a novel hybrid low-rank (HLR) method. The recipe behind HLR is based on two key
ingredients: 1) an adaptive inexact proximal point method with inner
acceleration; 2) Frank-Wolfe steps to escape from spurious local stationary
points. In contrast to the low-rank method of Burer and Monteiro, HALLaR finds
a near-optimal solution (with provable complexity bounds) of SDP instances
satisfying strong duality. Computational results comparing HALLaR to
state-of-the-art solvers on several large SDP instances arising from maximum
stable set, phase retrieval, and matrix completion show that the former finds
higher accurate solutions in substantially less CPU time than the latter ones.
For example, in less than 20 minutes, HALLaR can solve a maximum stable set SDP
instance with dimension pair $(n,m)\approx (10^6,10^7)$ within $10^{-5}$
relative precision.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12547" title="Abstract">arXiv:2401.12547</a> (cross-list from econ.TH) [<a href="/pdf/2401.12547" title="Download PDF">pdf</a>, <a href="/ps/2401.12547" title="Download PostScript">ps</a>, <a href="/format/2401.12547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arrow&#x27;s single peaked domains, richness, and domains for plurality and  the Borda count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Markstr%C3%B6m%2C+K">Klas Markstr&#xf6;m</a>, 
<a href="/search/econ?searchtype=author&query=Riis%2C+S">S&#xf8;ren Riis</a>, 
<a href="/search/econ?searchtype=author&query=Zhou%2C+B">Bei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper we extend the study of Arrow's generalisation of Black's
single-peaked domain and connect this to domains where voting rules satisfy
different versions of independence of irrelevant alternatives.
<br />First we report on a computational generation of all non-isomorphic Arrow's
single-peaked domains on $n\leq 9$ alternatives. Next, we introduce a
quantitative measure of richness for domains, as the largest number $r$ such
that every alternative is given every rank between 1 and $r$ by the orders in
the domain. We investigate the richness of Arrow's single-peaked domains and
prove that Black's single-peaked domain has the highest possible richness, but
it is not the only domain which attains the maximum.
<br />After this we connect Arrow's single-peaked domains to the discussion by
Dasgupta, Maskin and others of domains on which plurality and the Borda count
satisfy different versions of Independence of Irrelevant alternatives (IIA).
For Nash's version of IIA and plurality, it turns out the domains are exactly
the duals of Arrow's single-peaked domains. As a consequence there can be at
most two alternatives which are ranked first in any such domain.
<br />For the Borda count both Arrow's and Nash's versions of IIA lead to a maximum
domain size which is exponentially smaller than $2^{n-1}$, the size of Black's
single-peaked domain.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12556" title="Abstract">arXiv:2401.12556</a> (cross-list from math.OC) [<a href="/pdf/2401.12556" title="Download PDF">pdf</a>, <a href="/format/2401.12556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximate solution of stochastic infinite horizon optimal control  problems for constrained linear uncertain systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Joa%2C+E">Eunhyek Joa</a>, 
<a href="/search/math?searchtype=author&query=Borrelli%2C+F">Francesco Borrelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Transactions on Automatic Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We propose a Model Predictive Control (MPC) with a single-step prediction
horizon to solve infinite horizon optimal control problems with the expected
sum of convex stage costs for constrained linear uncertain systems. The
proposed method relies on two techniques. First, we estimate the expected
values of the convex costs using a computationally tractable approximation,
achieved by sampling across the space of disturbances. Second, we implement a
data-driven approach to approximate the optimal value function and its
corresponding domain, through systematic exploration of the system's state
space. These estimates are subsequently used as the terminal cost and terminal
set within the proposed MPC. We prove recursive feasibility, robust constraint
satisfaction, and convergence in probability to the target set. Furthermore, we
prove that the estimated value function converges to the optimal value function
in a local region. The effectiveness of the proposed MPC is illustrated with
detailed numerical simulations and comparisons with a value iteration method
and a Learning MPC that minimizes a certainty equivalent cost.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12570" title="Abstract">arXiv:2401.12570</a> (cross-list from eess.AS) [<a href="/pdf/2401.12570" title="Download PDF">pdf</a>, <a href="/format/2401.12570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffMoog: a Differentiable Modular Synthesizer for Sound Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Uzrad%2C+N">Noy Uzrad</a>, 
<a href="/search/eess?searchtype=author&query=Barkan%2C+O">Oren Barkan</a>, 
<a href="/search/eess?searchtype=author&query=Elharar%2C+A">Almog Elharar</a>, 
<a href="/search/eess?searchtype=author&query=Shvartzman%2C+S">Shlomi Shvartzman</a>, 
<a href="/search/eess?searchtype=author&query=Laufer%2C+M">Moshe Laufer</a>, 
<a href="/search/eess?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>, 
<a href="/search/eess?searchtype=author&query=Koenigstein%2C+N">Noam Koenigstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 7 figures, 1 table, Our code is released at <a href="https://github.com/aisynth/diffmoog">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">This paper presents DiffMoog - a differentiable modular synthesizer with a
comprehensive set of modules typically found in commercial instruments. Being
differentiable, it allows integration into neural networks, enabling automated
sound matching, to replicate a given audio input. Notably, DiffMoog facilitates
modulation capabilities (FM/AM), low-frequency oscillators (LFOs), filters,
envelope shapers, and the ability for users to create custom signal chains. We
introduce an open-source platform that comprises DiffMoog and an end-to-end
sound matching framework. This framework utilizes a novel signal-chain loss and
an encoder network that self-programs its outputs to predict DiffMoogs
parameters based on the user-defined modular architecture. Moreover, we provide
insights and lessons learned towards sound matching using differentiable
synthesis. Combining robust sound capabilities with a holistic platform,
DiffMoog stands as a premier asset for expediting research in audio synthesis
and machine learning.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12587" title="Abstract">arXiv:2401.12587</a> (cross-list from eess.IV) [<a href="/pdf/2401.12587" title="Download PDF">pdf</a>, <a href="/format/2401.12587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Implicit Neural Representation Image Codec in Resource-limited  Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jiahong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zimo Liu</a>, 
<a href="/search/eess?searchtype=author&query=An%2C+B">Baoyi An</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+S">Shu-Tao Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Displaying high-quality images on edge devices, such as augmented reality
devices, is essential for enhancing the user experience. However, these devices
often face power consumption and computing resource limitations, making it
challenging to apply many deep learning-based image compression algorithms in
this field. Implicit Neural Representation (INR) for image compression is an
emerging technology that offers two key benefits compared to cutting-edge
autoencoder models: low computational complexity and parameter-free decoding.
It also outperforms many traditional and early neural compression methods in
terms of quality. In this study, we introduce a new Mixed Autoregressive Model
(MARM) to significantly reduce the decoding time for the current INR codec,
along with a new synthesis network to enhance reconstruction quality. MARM
includes our proposed Autoregressive Upsampler (ARU) blocks, which are highly
computationally efficient, and ARM from previous work to balance decoding time
and reconstruction quality. We also propose enhancing ARU's performance using a
checkerboard two-stage decoding strategy. Moreover, the ratio of different
modules can be adjusted to maintain a balance between quality and speed.
Comprehensive experiments demonstrate that our method significantly improves
computational efficiency while preserving image quality. With different
parameter settings, our method can outperform popular AE-based codecs in
constrained environments in terms of both quality and decoding time, or achieve
state-of-the-art reconstruction quality compared to other INR codecs.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12625" title="Abstract">arXiv:2401.12625</a> (cross-list from math.OC) [<a href="/pdf/2401.12625" title="Download PDF">pdf</a>, <a href="/format/2401.12625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benders decomposition for congested partial set covering location with  uncertain demand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Calamita%2C+A">Alice Calamita</a>, 
<a href="/search/math?searchtype=author&query=Ljubi%C4%87%2C+I">Ivana Ljubi&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Palagi%2C+L">Laura Palagi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we introduce a mixed integer quadratic formulation for the
congested variant of the partial set covering location problem, which involves
determining a subset of facility locations to open and efficiently allocating
customers to these facilities to minimize the combined costs of facility
opening and congestion while ensuring target coverage. To enhance the
resilience of the solution against demand fluctuations, we address the case
under uncertain customer demand using $\Gamma$-robustness. We formulate the
deterministic problem and its robust counterpart as mixed-integer quadratic
problems. We investigate the effect of the protection level in adapted
instances from the literature to provide critical insights into how sensitive
the planning is to the protection level. Moreover, since the size of the robust
counterpart grows with the number of customers, which could be significant in
real-world contexts, we propose the use of Benders decomposition to effectively
reduce the number of variables by projecting out of the master problem all the
variables dependent on the number of customers. We illustrate how to
incorporate our Benders approach within a mixed-integer second-order cone
programming (MISOCP) solver, addressing explicitly all the ingredients that are
instrumental for its success. We discuss single-tree and multi-tree approaches
and introduce a perturbation technique to deal with the degeneracy of the
Benders subproblem efficiently. Our tailored Benders approaches outperform the
perspective reformulation solved using the state-of-the-art MISOCP solver
Gurobi on adapted instances from the literature.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12641" title="Abstract">arXiv:2401.12641</a> (cross-list from math.LO) [<a href="/pdf/2401.12641" title="Download PDF">pdf</a>, <a href="/ps/2401.12641" title="Download PostScript">ps</a>, <a href="/format/2401.12641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential discontinuity and first-order problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pauly%2C+A">Arno Pauly</a>, 
<a href="/search/math?searchtype=author&query=Sold%C3%A0%2C+G">Giovanni Sold&#xe0;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); General Topology (math.GN)

</div>
<p class="mathjax">We explore the low levels of the structure of the continuous Weihrauch
degrees of first-order problems. In particular, we show that there exists a
minimal discontinuous first-order degree, namely that of $\accn$, without any
determinacy assumptions. The same degree is also revealed as the least
sequentially discontinuous one, i.e. the least degree with a representative
whose restriction to some sequence converging to a limit point is still
discontinuous.
<br />The study of games related to continuous Weihrauch reducibility constitutes
an important ingredient in the proof of the main theorem. We present some
initial additional results about the degrees of first-order problems that can
be obtained using this approach.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12667" title="Abstract">arXiv:2401.12667</a> (cross-list from stat.ML) [<a href="/pdf/2401.12667" title="Download PDF">pdf</a>, <a href="/ps/2401.12667" title="Download PostScript">ps</a>, <a href="/format/2401.12667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Selection via Robust Weighted Score for High Dimensional Binary  Class-Imbalanced Gene Expression Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Khan%2C+Z">Zardad Khan</a>, 
<a href="/search/stat?searchtype=author&query=Ali%2C+A">Amjad Ali</a>, 
<a href="/search/stat?searchtype=author&query=Aldahmani%2C+S">Saeed Aldahmani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, a robust weighted score for unbalanced data (ROWSU) is
proposed for selecting the most discriminative feature for high dimensional
gene expression binary classification with class-imbalance problem. The method
addresses one of the most challenging problems of highly skewed class
distributions in gene expression datasets that adversely affect the performance
of classification algorithms. First, the training dataset is balanced by
synthetically generating data points from minority class observations. Second,
a minimum subset of genes is selected using a greedy search approach. Third, a
novel weighted robust score, where the weights are computed by support vectors,
is introduced to obtain a refined set of genes. The highest-scoring genes based
on this approach are combined with the minimum subset of genes selected by the
greedy search approach to form the final set of genes. The novel method ensures
the selection of the most discriminative genes, even in the presence of skewed
class distribution, thus improving the performance of the classifiers. The
performance of the proposed ROWSU method is evaluated on $6$ gene expression
datasets. Classification accuracy and sensitivity are used as performance
metrics to compare the proposed ROWSU algorithm with several other
state-of-the-art methods. Boxplots and stability plots are also constructed for
a better understanding of the results. The results show that the proposed
method outperforms the existing feature selection procedures based on
classification performance from k nearest neighbours (kNN) and random forest
(RF) classifiers.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12717" title="Abstract">arXiv:2401.12717</a> (cross-list from physics.geo-ph) [<a href="/pdf/2401.12717" title="Download PDF">pdf</a>, <a href="/ps/2401.12717" title="Download PostScript">ps</a>, <a href="/format/2401.12717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gas trap prediction from 3D seismic and well test data using machine  learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Ivlev%2C+D">Dmitry Ivlev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The aim of this work is to create and apply a methodological approach for
predicting gas traps from 3D seismic data and gas well testing. The paper
formalizes the approach to creating a training dataset by selecting volumes
with established gas saturation and filtration properties within the seismic
wavefield. The training dataset thus created is used in a process stack of
sequential application of data processing methods and ensemble machine learning
algorithms. As a result, a cube of calibrated probabilities of belonging of the
study space to gas reservoirs was obtained. The high efficiency of this
approach is shown on a delayed test sample of three wells (blind wells). The
final value of the gas reservoir prediction quality metric f1 score was
0.893846.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12725" title="Abstract">arXiv:2401.12725</a> (cross-list from eess.IV) [<a href="/pdf/2401.12725" title="Download PDF">pdf</a>, <a href="/format/2401.12725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-View Topogram-Based Anatomy-Guided CT Reconstruction for Prospective  Risk Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Chang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Klein%2C+L">Laura Klein</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yixing Huang</a>, 
<a href="/search/eess?searchtype=author&query=Baader%2C+E">Edith Baader</a>, 
<a href="/search/eess?searchtype=author&query=Lell%2C+M">Michael Lell</a>, 
<a href="/search/eess?searchtype=author&query=Kachelrie%C3%9F%2C+M">Marc Kachelrie&#xdf;</a>, 
<a href="/search/eess?searchtype=author&query=Maier%2C+A">Andreas Maier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">To facilitate a prospective estimation of CT effective dose and risk
minimization process, a prospective spatial dose estimation and the known
anatomical structures are expected. To this end, a CT reconstruction method is
required to reconstruct CT volumes from as few projections as possible, i.e. by
using the topograms, with anatomical structures as correct as possible. In this
work, an optimized CT reconstruction model based on a generative adversarial
network (GAN) is proposed. The GAN is trained to reconstruct 3D volumes from an
anterior-posterior and a lateral CT projection. To enhance anatomical
structures, a pre-trained organ segmentation network and the 3D perceptual loss
are applied during the training phase, so that the model can then generate both
organ-enhanced CT volume and the organ segmentation mask. The proposed method
can reconstruct CT volumes with PSNR of 26.49, RMSE of 196.17, and SSIM of
0.64, compared to 26.21, 201.55 and 0.63 using the baseline method. In terms of
the anatomical structure, the proposed method effectively enhances the organ
shape and boundary and allows for a straight-forward identification of the
relevant anatomical structures. We note that conventional reconstruction
metrics fail to indicate the enhancement of anatomical structures. In addition
to such metrics, the evaluation is expanded with assessing the organ
segmentation performance. The average organ dice of the proposed method is 0.71
compared with 0.63 in baseline model, indicating the enhancement of anatomical
structures.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12764" title="Abstract">arXiv:2401.12764</a> (cross-list from math.OC) [<a href="/pdf/2401.12764" title="Download PDF">pdf</a>, <a href="/ps/2401.12764" title="Download PostScript">ps</a>, <a href="/format/2401.12764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Nonlinear Two-Time-Scale Stochastic Approximation: Achieving  $\mathcal{O}(1/k)$ Finite-Sample Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Doan%2C+T+T">Thinh T. Doan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes to develop a new variant of the two-time-scale stochastic
approximation to find the roots of two coupled nonlinear operators, assuming
only noisy samples of these operators can be observed. Our key idea is to
leverage the classic Ruppert-Polyak averaging technique to dynamically estimate
the operators through their samples. The estimated values of these averaging
steps will then be used in the two-time-scale stochastic approximation updates
to find the desired solution. Our main theoretical result is to show that under
the strongly monotone condition of the underlying nonlinear operators the
mean-squared errors of the iterates generated by the proposed method converge
to zero at an optimal rate $\mathcal{O}(1/k)$, where $k$ is the number of
iterations. Our result significantly improves the existing result of
two-time-scale stochastic approximation, where the best known finite-time
convergence rate is $\mathcal{O}(1/k^{2/3})$.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12771" title="Abstract">arXiv:2401.12771</a> (cross-list from eess.IV) [<a href="/pdf/2401.12771" title="Download PDF">pdf</a>, <a href="/ps/2401.12771" title="Download PostScript">ps</a>, <a href="/format/2401.12771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Intraoperative MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ottesen%2C+J+A">Jon Andr&#xe9; Ottesen</a>, 
<a href="/search/eess?searchtype=author&query=Storas%2C+T">Tryggve Storas</a>, 
<a href="/search/eess?searchtype=author&query=Vatnehol%2C+S+A+S">Svein Are Sirirud Vatnehol</a>, 
<a href="/search/eess?searchtype=author&query=L%C3%B8vland%2C+G">Grethe L&#xf8;vland</a>, 
<a href="/search/eess?searchtype=author&query=Vik-Mo%2C+E+O">Einar O. Vik-Mo</a>, 
<a href="/search/eess?searchtype=author&query=Schellhorn%2C+T">Till Schellhorn</a>, 
<a href="/search/eess?searchtype=author&query=Skogen%2C+K">Karoline Skogen</a>, 
<a href="/search/eess?searchtype=author&query=Larsson%2C+C">Christopher Larsson</a>, 
<a href="/search/eess?searchtype=author&query=Bj%C3%B8rnerud%2C+A">Atle Bj&#xf8;rnerud</a>, 
<a href="/search/eess?searchtype=author&query=Groote-Eindbaas%2C+I+R">Inge Rasmus Groote-Eindbaas</a>, 
<a href="/search/eess?searchtype=author&query=Caan%2C+M+W+A">Matthan W.A. Caan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Purpose: To evaluate the quality of deep learning reconstruction for
prospectively accelerated intraoperative magnetic resonance imaging (iMRI)
during resective brain tumor surgery.
<br />Materials and Methods: Accelerated iMRI was performed during brain surgery
using dual surface coils positioned around the area of resection. A deep
learning (DL) model was trained on the fastMRI neuro dataset to mimic the data
from the iMRI protocol. Evaluation was performed on imaging material from 40
patients imaged between 01.11.2021 - 01.06.2023 that underwent iMRI during
tumor resection surgery. A comparative analysis was conducted between the
conventional compressed sense (CS) method and the trained DL reconstruction
method. Blinded evaluation of multiple image quality metrics was performed by
two working neuro-radiologists and a working neurosurgeon on a 1 to 5 Likert
scale (1=non diagnostic, 2=poor, 3=acceptable, 4=good, 5=excellent), and the
favored reconstruction variant.
<br />Results: The DL reconstruction was strongly favored or favored over the CS
reconstruction for 33/40, 39/40, and 8/40 of cases for reader 1, 2, and 3,
respectively. Two of three readers consistently assigned higher ratings for the
DL reconstructions, and the DL reconstructions had a higher score than their
respective CS counterparts for 72%, 72%, and 14% of the cases for reader 1, 2,
and 3, respectively. Still, the DL reconstructions exhibited shortcomings such
as a striping artifact and reduced signal.
<br />Conclusion: DL shows promise to allow for high-quality reconstructions of
intraoperative MRI with equal to or improved perceived spatial resolution,
signal-to-noise ratio, diagnostic confidence, diagnostic conspicuity, and
spatial resolution compared to compressed sense.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12793" title="Abstract">arXiv:2401.12793</a> (cross-list from math.CO) [<a href="/pdf/2401.12793" title="Download PDF">pdf</a>, <a href="/ps/2401.12793" title="Download PostScript">ps</a>, <a href="/format/2401.12793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contractions in perfect graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dupont-Bouillard%2C+A">Alexandre Dupont-Bouillard</a>, 
<a href="/search/math?searchtype=author&query=Fouilhoux%2C+P">Pierre Fouilhoux</a>, 
<a href="/search/math?searchtype=author&query=Grappe%2C+R">Roland Grappe</a>, 
<a href="/search/math?searchtype=author&query=Lacroix%2C+M">Mathieu Lacroix</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">In this paper, we characterize the class of {\em contraction perfect} graphs
which are the graphs that remain perfect after the contraction of any edge set.
We prove that a graph is contraction perfect if and only if it is perfect and
the contraction of any single edge preserves its perfection. This yields a
characterization of contraction perfect graphs in terms of forbidden induced
subgraphs, and a polynomial algorithm to recognize them. We also define the
utter graph $u(G)$ which is the graph whose stable sets are in bijection with
the co-2-plexes of $G$, and prove that $u(G)$ is perfect if and only if $G$ is
contraction perfect.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12850" title="Abstract">arXiv:2401.12850</a> (cross-list from eess.AS) [<a href="/pdf/2401.12850" title="Download PDF">pdf</a>, <a href="/format/2401.12850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overlap-aware End-to-End Supervised Hierarchical Graph Clustering for  Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+P">Prachi Singh</a>, 
<a href="/search/eess?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">Speaker diarization, the task of segmenting an audio recording based on
speaker identity, constitutes an important speech pre-processing step for
several downstream applications. The conventional approach to diarization
involves multiple steps of embedding extraction and clustering, which are often
optimized in an isolated fashion. While end-to-end diarization systems attempt
to learn a single model for the task, they are often cumbersome to train and
require large supervised datasets. In this paper, we propose an end-to-end
supervised hierarchical clustering algorithm based on graph neural networks
(GNN), called End-to-end Supervised HierARchical Clustering (E-SHARC). The
E-SHARC approach uses front-end mel-filterbank features as input and jointly
learns an embedding extractor and the GNN clustering module, performing
representation learning, metric learning, and clustering with end-to-end
optimization. Further, with additional inputs from an external overlap
detector, the E-SHARC approach is capable of predicting the speakers in the
overlapping speech regions. The experimental evaluation on several benchmark
datasets like AMI, VoxConverse and DISPLACE, illustrates that the proposed
E-SHARC framework improves significantly over the state-of-art diarization
systems.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12861" title="Abstract">arXiv:2401.12861</a> (cross-list from quant-ph) [<a href="/pdf/2401.12861" title="Download PDF">pdf</a>, <a href="/format/2401.12861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Communication with Unreliable Entanglement Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lederman%2C+M">Meir Lederman</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pereg%2C+U">Uzi Pereg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Secure communication is considered with unreliable entanglement assistance,
where the adversary may intercept the legitimate receiver's entanglement
resource before communication takes place. The communication setting of
unreliable assistance, without security aspects, was originally motivated by
the extreme photon loss in practical communication systems. The operational
principle is to adapt the transmission rate to the availability of entanglement
assistance, without resorting to feedback and repetition. Here, we require
secrecy as well. An achievable secrecy rate region is derived for general
quantum wiretap channels, and a multi-letter secrecy capacity formula for the
special class of degraded channels.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12923" title="Abstract">arXiv:2401.12923</a> (cross-list from stat.ML) [<a href="/pdf/2401.12923" title="Download PDF">pdf</a>, <a href="/format/2401.12923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep multitask neural networks for solving some stochastic optimal  control problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Yeo%2C+C">Christian Yeo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Most existing neural network-based approaches for solving stochastic optimal
control problems using the associated backward dynamic programming principle
rely on the ability to simulate the underlying state variables. However, in
some problems, this simulation is infeasible, leading to the discretization of
state variable space and the need to train one neural network for each data
point. This approach becomes computationally inefficient when dealing with
large state variable spaces. In this paper, we consider a class of this type of
stochastic optimal control problems and introduce an effective solution
employing multitask neural networks. To train our multitask neural network, we
introduce a novel scheme that dynamically balances the learning across tasks.
Through numerical experiments on real-world derivatives pricing problems, we
prove that our method outperforms state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12924" title="Abstract">arXiv:2401.12924</a> (cross-list from stat.ML) [<a href="/pdf/2401.12924" title="Download PDF">pdf</a>, <a href="/format/2401.12924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Analysis of Support Vector Machine (SVM) on Challenging  Datasets for Forest Fire Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Kar%2C+A">Ankan Kar</a>, 
<a href="/search/stat?searchtype=author&query=Nath%2C+N">Nirjhar Nath</a>, 
<a href="/search/stat?searchtype=author&query=Kemprai%2C+U">Utpalraj Kemprai</a>, 
<a href="/search/stat?searchtype=author&query=Aman">Aman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures, accepted in IJCNS of SCIRP (not yet published)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">This article delves into the analysis of performance and utilization of
Support Vector Machines (SVMs) for the critical task of forest fire detection
using image datasets. With the increasing threat of forest fires to ecosystems
and human settlements, the need for rapid and accurate detection systems is of
utmost importance. SVMs, renowned for their strong classification capabilities,
exhibit proficiency in recognizing patterns associated with fire within images.
By training on labeled data, SVMs acquire the ability to identify distinctive
attributes associated with fire, such as flames, smoke, or alterations in the
visual characteristics of the forest area. The document thoroughly examines the
use of SVMs, covering crucial elements like data preprocessing, feature
extraction, and model training. It rigorously evaluates parameters such as
accuracy, efficiency, and practical applicability. The knowledge gained from
this study aids in the development of efficient forest fire detection systems,
enabling prompt responses and improving disaster management. Moreover, the
correlation between SVM accuracy and the difficulties presented by
high-dimensional datasets is carefully investigated, demonstrated through a
revealing case study. The relationship between accuracy scores and the
different resolutions used for resizing the training datasets has also been
discussed in this article. These comprehensive studies result in a definitive
overview of the difficulties faced and the potential sectors requiring further
improvement and focus.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12932" title="Abstract">arXiv:2401.12932</a> (cross-list from eess.IV) [<a href="/pdf/2401.12932" title="Download PDF">pdf</a>, <a href="/format/2401.12932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segmentation of tibiofemoral joint tissues from knee MRI using MtRA-Unet  and incorporating shape information: Data from the Osteoarthritis Initiative
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Daydar%2C+A">Akshay Daydar</a>, 
<a href="/search/eess?searchtype=author&query=Pramanick%2C+A">Alik Pramanick</a>, 
<a href="/search/eess?searchtype=author&query=Sur%2C+A">Arijit Sur</a>, 
<a href="/search/eess?searchtype=author&query=Kanagaraj%2C+S">Subramani Kanagaraj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Knee Osteoarthritis (KOA) is the third most prevalent Musculoskeletal
Disorder (MSD) after neck and back pain. To monitor such a severe MSD, a
segmentation map of the femur, tibia and tibiofemoral cartilage is usually
accessed using the automated segmentation algorithm from the Magnetic Resonance
Imaging (MRI) of the knee. But, in recent works, such segmentation is
conceivable only from the multistage framework thus creating data handling
issues and needing continuous manual inference rendering it unable to make a
quick and precise clinical diagnosis. In order to solve these issues, in this
paper the Multi-Resolution Attentive-Unet (MtRA-Unet) is proposed to segment
the femur, tibia and tibiofemoral cartilage automatically. The proposed work
has included a novel Multi-Resolution Feature Fusion (MRFF) and Shape
Reconstruction (SR) loss that focuses on multi-contextual information and
structural anatomical details of the femur, tibia and tibiofemoral cartilage.
Unlike previous approaches, the proposed work is a single-stage and end-to-end
framework producing a Dice Similarity Coefficient (DSC) of 98.5% for the femur,
98.4% for the tibia, 89.1% for Femoral Cartilage (FC) and 86.1% for Tibial
Cartilage (TC) for critical MRI slices that can be helpful to clinicians for
KOA grading. The time to segment MRI volume (160 slices) per subject is 22 sec.
which is one of the fastest among state-of-the-art. Moreover, comprehensive
experimentation on the segmentation of FC and TC which is of utmost importance
for morphology-based studies to check KOA progression reveals that the proposed
method has produced an excellent result with binary segmentation
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12934" title="Abstract">arXiv:2401.12934</a> (cross-list from stat.ML) [<a href="/pdf/2401.12934" title="Download PDF">pdf</a>, <a href="/format/2401.12934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward-Relevance-Filtered Linear Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+A">Angela Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference version accepted at AISTATS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper studies offline reinforcement learning with linear function
approximation in a setting with decision-theoretic, but not estimation
sparsity. The structural restrictions of the data-generating process presume
that the transitions factor into a sparse component that affects the reward and
could affect additional exogenous dynamics that do not affect the reward.
Although the minimally sufficient adjustment set for estimation of full-state
transition properties depends on the whole state, the optimal policy and
therefore state-action value function depends only on the sparse component: we
call this causal/decision-theoretic sparsity. We develop a method for
reward-filtering the estimation of the state-action value function to the
sparse component by a modification of thresholded lasso in least-squares policy
evaluation. We provide theoretical guarantees for our reward-filtered linear
fitted-Q-iteration, with sample complexity depending only on the size of the
sparse component.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12938" title="Abstract">arXiv:2401.12938</a> (cross-list from eess.IV) [<a href="/pdf/2401.12938" title="Download PDF">pdf</a>, <a href="/format/2401.12938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural deformation fields for template-based reconstruction of cortical  surfaces from MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bongratz%2C+F">Fabian Bongratz</a>, 
<a href="/search/eess?searchtype=author&query=Rickmann%2C+A">Anne-Marie Rickmann</a>, 
<a href="/search/eess?searchtype=author&query=Wachinger%2C+C">Christian Wachinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Medical Image Analysis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The reconstruction of cortical surfaces is a prerequisite for quantitative
analyses of the cerebral cortex in magnetic resonance imaging (MRI). Existing
segmentation-based methods separate the surface registration from the surface
extraction, which is computationally inefficient and prone to distortions. We
introduce Vox2Cortex-Flow (V2C-Flow), a deep mesh-deformation technique that
learns a deformation field from a brain template to the cortical surfaces of an
MRI scan. To this end, we present a geometric neural network that models the
deformation-describing ordinary differential equation in a continuous manner.
The network architecture comprises convolutional and graph-convolutional
layers, which allows it to work with images and meshes at the same time.
V2C-Flow is not only very fast, requiring less than two seconds to infer all
four cortical surfaces, but also establishes vertex-wise correspondences to the
template during reconstruction. In addition, V2C-Flow is the first approach for
cortex reconstruction that models white matter and pial surfaces jointly,
therefore avoiding intersections between them. Our comprehensive experiments on
internal and external test data demonstrate that V2C-Flow results in cortical
surfaces that are state-of-the-art in terms of accuracy. Moreover, we show that
the established correspondences are more consistent than in FreeSurfer and that
they can directly be utilized for cortex parcellation and group analyses of
cortical thickness.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12967" title="Abstract">arXiv:2401.12967</a> (cross-list from math.ST) [<a href="/pdf/2401.12967" title="Download PDF">pdf</a>, <a href="/format/2401.12967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measure transport with kernel mean embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+L">L. Wang</a>, 
<a href="/search/math?searchtype=author&query=N%C3%BCsken%2C+N">N. N&#xfc;sken</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Numerical Analysis (math.NA); Methodology (stat.ME)

</div>
<p class="mathjax">Kalman filters constitute a scalable and robust methodology for approximate
Bayesian inference, matching first and second order moments of the target
posterior. To improve the accuracy in nonlinear and non-Gaussian settings, we
extend this principle to include more or different characteristics, based on
kernel mean embeddings (KMEs) of probability measures into their corresponding
Hilbert spaces. Focusing on the continuous-time setting, we develop a family of
interacting particle systems (termed $\textit{KME-dynamics}$) that bridge
between the prior and the posterior, and that include the Kalman-Bucy filter as
a special case. A variant of KME-dynamics has recently been derived from an
optimal transport perspective by Maurais and Marzouk, and we expose further
connections to (kernelised) diffusion maps, leading to a variational
formulation of regression type. Finally, we conduct numerical experiments on
toy examples and the Lorenz-63 model, the latter of which show particular
promise for a hybrid modification (called Kalman-adjusted KME-dynamics).
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12974" title="Abstract">arXiv:2401.12974</a> (cross-list from eess.IV) [<a href="/pdf/2401.12974" title="Download PDF">pdf</a>, <a href="/format/2401.12974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SegmentAnyBone: A Universal Model that Segments Any Bone at Any Location  on MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gu%2C+H">Hanxue Gu</a>, 
<a href="/search/eess?searchtype=author&query=Colglazier%2C+R">Roy Colglazier</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+H">Haoyu Dong</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jikai Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yaqian Chen</a>, 
<a href="/search/eess?searchtype=author&query=Yildiz%2C+Z">Zafer Yildiz</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuwen Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jichen Yang</a>, 
<a href="/search/eess?searchtype=author&query=Willhite%2C+J">Jay Willhite</a>, 
<a href="/search/eess?searchtype=author&query=Meyer%2C+A+M">Alex M. Meyer</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+B">Brian Guo</a>, 
<a href="/search/eess?searchtype=author&query=Shah%2C+Y+A">Yashvi Atul Shah</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+E">Emily Luo</a>, 
<a href="/search/eess?searchtype=author&query=Rajput%2C+S">Shipra Rajput</a>, 
<a href="/search/eess?searchtype=author&query=Kuehn%2C+S">Sally Kuehn</a>, 
<a href="/search/eess?searchtype=author&query=Bulleit%2C+C">Clark Bulleit</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+K+A">Kevin A. Wu</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jisoo Lee</a>, 
<a href="/search/eess?searchtype=author&query=Ramirez%2C+B">Brandon Ramirez</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+D">Darui Lu</a>, 
<a href="/search/eess?searchtype=author&query=Levin%2C+J+M">Jay M. Levin</a>, 
<a href="/search/eess?searchtype=author&query=Mazurowski%2C+M+A">Maciej A. Mazurowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Magnetic Resonance Imaging (MRI) is pivotal in radiology, offering
non-invasive and high-quality insights into the human body. Precise
segmentation of MRIs into different organs and tissues would be highly
beneficial since it would allow for a higher level of understanding of the
image content and enable important measurements, which are essential for
accurate diagnosis and effective treatment planning. Specifically, segmenting
bones in MRI would allow for more quantitative assessments of musculoskeletal
conditions, while such assessments are largely absent in current radiological
practice. The difficulty of bone MRI segmentation is illustrated by the fact
that limited algorithms are publicly available for use, and those contained in
the literature typically address a specific anatomic area. In our study, we
propose a versatile, publicly available deep-learning model for bone
segmentation in MRI across multiple standard MRI locations. The proposed model
can operate in two modes: fully automated segmentation and prompt-based
segmentation. Our contributions include (1) collecting and annotating a new MRI
dataset across various MRI protocols, encompassing over 300 annotated volumes
and 8485 annotated slices across diverse anatomic regions; (2) investigating
several standard network architectures and strategies for automated
segmentation; (3) introducing SegmentAnyBone, an innovative foundational
model-based approach that extends Segment Anything Model (SAM); (4) comparative
analysis of our algorithm and previous approaches; and (5) generalization
analysis of our algorithm across different anatomical locations and MRI
sequences, as well as an external dataset. We publicly release our model at
https://github.com/mazurowski-lab/SegmentAnyBone.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Wed, 24 Jan 24</h3>
<dl>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1411.3603" title="Abstract">arXiv:1411.3603</a> (replaced) [<a href="/pdf/1411.3603" title="Download PDF">pdf</a>, <a href="/ps/1411.3603" title="Download PostScript">ps</a>, <a href="/format/1411.3603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication with Imperfectly Shared Randomness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canonne%2C+C+L">Cl&#xe9;ment L. Canonne</a>, 
<a href="/search/cs?searchtype=author&query=Guruswami%2C+V">Venkatesan Guruswami</a>, 
<a href="/search/cs?searchtype=author&query=Meka%2C+R">Raghu Meka</a>, 
<a href="/search/cs?searchtype=author&query=Sudan%2C+M">Madhu Sudan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected a small mistake in the proof of Theorem 2.3, pointed out by Jayanth Sadhasivan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.04251" title="Abstract">arXiv:2002.04251</a> (replaced) [<a href="/pdf/2002.04251" title="Download PDF">pdf</a>, <a href="/format/2002.04251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2.75D: Boosting learning by representing 3D Medical imaging to 2D  features for small data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Su%2C+R">Ruisheng Su</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+W">Weiyi Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenjin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/eess?searchtype=author&query=Mann%2C+R">Ritse Mann</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+T">Tao Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2003.13648" title="Abstract">arXiv:2003.13648</a> (replaced) [<a href="/e-print/2003.13648" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-supervised land classification for coastal zone based on deep  convolutional neural networks by incorporating dual-polarimetric  characteristics into training dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sun%2C+S">Sheng Sun</a>, 
<a href="/search/eess?searchtype=author&query=Marino%2C+A">Armando Marino</a>, 
<a href="/search/eess?searchtype=author&query=Shui%2C+W">Wenze Shui</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+Z">Zhongwen Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are sorry we would like to improve it
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.04107" title="Abstract">arXiv:2102.04107</a> (replaced) [<a href="/pdf/2102.04107" title="Download PDF">pdf</a>, <a href="/ps/2102.04107" title="Download PostScript">ps</a>, <a href="/format/2102.04107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An extended Knowledge Compilation Map for Conditional Preference  Statements-based and Generalized Additive Utilities-based Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fargier%2C+H">H&#xe9;l&#xe8;ne Fargier</a> (IRIT-ADRIA), 
<a href="/search/cs?searchtype=author&query=Mengel%2C+S">Stefan Mengel</a> (CRIL), 
<a href="/search/cs?searchtype=author&query=Mengin%2C+J">J&#xe9;r&#xf4;me Mengin</a> (IRIT-ADRIA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.01135" title="Abstract">arXiv:2106.01135</a> (replaced) [<a href="/pdf/2106.01135" title="Download PDF">pdf</a>, <a href="/ps/2106.01135" title="Download PostScript">ps</a>, <a href="/format/2106.01135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MNL-Bandit with Knapsacks: a near-optimal algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aznag%2C+A">Abdellah Aznag</a>, 
<a href="/search/cs?searchtype=author&query=Goyal%2C+V">Vineet Goyal</a>, 
<a href="/search/cs?searchtype=author&query=Perivier%2C+N">Noemie Perivier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.10936" title="Abstract">arXiv:2107.10936</a> (replaced) [<a href="/pdf/2107.10936" title="Download PDF">pdf</a>, <a href="/ps/2107.10936" title="Download PostScript">ps</a>, <a href="/format/2107.10936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimal Session Types for the $&#x3c0;$-calculus (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arslanagic%2C+A">Alen Arslanagic</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J+A">Jorge A. P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Palamariuc%2C+A">Anda-Amelia Palamariuc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a PPDP 2021 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.07869" title="Abstract">arXiv:2110.07869</a> (replaced) [<a href="/pdf/2110.07869" title="Download PDF">pdf</a>, <a href="/format/2110.07869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPGNN: Dual-Perception Graph Neural Network for Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Li Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+D">Dingyi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shaohuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wanlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Malu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+H">Hong Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Knowledge-Based Systems
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Knowledge-Based Systems 268 (2023): 110377
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.11334" title="Abstract">arXiv:2110.11334</a> (replaced) [<a href="/pdf/2110.11334" title="Download PDF">pdf</a>, <a href="/format/2110.11334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Out-of-Distribution Detection: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jingkang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Feel free to comment on our Overleaf manuscript: <a href="https://www.overleaf.com/9899719915wmccvdtwpkct#c25192">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.11628" title="Abstract">arXiv:2112.11628</a> (replaced) [<a href="/pdf/2112.11628" title="Download PDF">pdf</a>, <a href="/format/2112.11628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SkipNode: On Alleviating Performance Degradation for Deep Graph  Convolutional Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Weigang Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yibing Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Binbin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Z">Ziyu Guan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Baosheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W">Wei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03087" title="Abstract">arXiv:2202.03087</a> (replaced) [<a href="/pdf/2202.03087" title="Download PDF">pdf</a>, <a href="/format/2202.03087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Long-Term Person Re-Identification with Clothes Change
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingkun Li</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shupeng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Guang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jun Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.08082" title="Abstract">arXiv:2203.08082</a> (replaced) [<a href="/pdf/2203.08082" title="Download PDF">pdf</a>, <a href="/format/2203.08082" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regenerative Particle Thompson Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zeyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Hajek%2C+B">Bruce Hajek</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+N">Nakjung Choi</a>, 
<a href="/search/cs?searchtype=author&query=Walid%2C+A">Anwar Walid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Mainbody 14 pages, appendix 32 pages, 16 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> "Particle Thompson Sampling with Static Particles" and "Improving
  Particle Thompson Sampling through Regenerative Particles," 2023 57th Annual
  Conference on Information Sciences and Systems (CISS), Baltimore, MD, USA,
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13883" title="Abstract">arXiv:2203.13883</a> (replaced) [<a href="/pdf/2203.13883" title="Download PDF">pdf</a>, <a href="/format/2203.13883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Misinformation Detection: Approaches, Challenges and  Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdali%2C+S">Sara Abdali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Multimedia (cs.MM); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.13209" title="Abstract">arXiv:2204.13209</a> (replaced) [<a href="/pdf/2204.13209" title="Download PDF">pdf</a>, <a href="/format/2204.13209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust stabilization of polytopic systems via fast and reliable neural  network-based approximations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabiani%2C+F">Filippo Fabiani</a>, 
<a href="/search/eess?searchtype=author&query=Goulart%2C+P+J">Paul J. Goulart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05173" title="Abstract">arXiv:2205.05173</a> (replaced) [<a href="/pdf/2205.05173" title="Download PDF">pdf</a>, <a href="/format/2205.05173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Supervised Anomaly Detection in Computer Vision and Beyond: A  Survey and Outlook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hojjati%2C+H">Hadi Hojjati</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+T+K+K">Thi Kieu Khanh Ho</a>, 
<a href="/search/cs?searchtype=author&query=Armanfard%2C+N">Narges Armanfard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures, 5 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Neural Networks, Volume 172, April 2024, 106106
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.05587" title="Abstract">arXiv:2205.05587</a> (replaced) [<a href="/pdf/2205.05587" title="Download PDF">pdf</a>, <a href="/format/2205.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Choice of training label matters: how to best use deep learning for  quantitative MRI parameter estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Epstein%2C+S+C">Sean C. Epstein</a>, 
<a href="/search/physics?searchtype=author&query=Bray%2C+T+J+P">Timothy J. P. Bray</a>, 
<a href="/search/physics?searchtype=author&query=Hall-Craggs%2C+M">Margaret Hall-Craggs</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+H">Hui Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2024:002">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.13743" title="Abstract">arXiv:2205.13743</a> (replaced) [<a href="/pdf/2205.13743" title="Download PDF">pdf</a>, <a href="/format/2205.13743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Algorithmic Recourse with Preference Elicitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Toni%2C+G">Giovanni De Toni</a>, 
<a href="/search/cs?searchtype=author&query=Viappiani%2C+P">Paolo Viappiani</a>, 
<a href="/search/cs?searchtype=author&query=Teso%2C+S">Stefano Teso</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>, 
<a href="/search/cs?searchtype=author&query=Passerini%2C+A">Andrea Passerini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Transactions in Machine Learning Research (TMLR), January 2024. See <a href="https://openreview.net/forum?id=8sg2I9zXgO">this https URL</a> for the official submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00775" title="Abstract">arXiv:2206.00775</a> (replaced) [<a href="/pdf/2206.00775" title="Download PDF">pdf</a>, <a href="/format/2206.00775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Local Neighborhood-based Neural Networks for MR Image  Reconstruction from Undersampled Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liang%2C+S">Shijun Liang</a>, 
<a href="/search/eess?searchtype=author&query=Lahiri%2C+A">Anish Lahiri</a>, 
<a href="/search/eess?searchtype=author&query=Ravishankar%2C+S">Saiprasad Ravishankar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02059" title="Abstract">arXiv:2206.02059</a> (replaced) [<a href="/pdf/2206.02059" title="Download PDF">pdf</a>, <a href="/format/2206.02059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering GNNs via Edge-Aware Weisfeiler-Leman Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Transactions on Machine Learning Research (TMLR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11492" title="Abstract">arXiv:2206.11492</a> (replaced) [<a href="/pdf/2206.11492" title="Download PDF">pdf</a>, <a href="/format/2206.11492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradual Domain Adaptation via Normalizing Flows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sagawa%2C+S">Shogo Sagawa</a>, 
<a href="/search/stat?searchtype=author&query=Hino%2C+H">Hideitsu Hino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.02829" title="Abstract">arXiv:2207.02829</a> (replaced) [<a href="/pdf/2207.02829" title="Download PDF">pdf</a>, <a href="/format/2207.02829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Bilevel Optimization: Regret Analysis of Online Alternating  Gradient Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tarzanagh%2C+D+A">Davoud Ataee Tarzanagh</a>, 
<a href="/search/math?searchtype=author&query=Nazari%2C+P">Parvin Nazari</a>, 
<a href="/search/math?searchtype=author&query=Hou%2C+B">Bojian Hou</a>, 
<a href="/search/math?searchtype=author&query=Shen%2C+L">Li Shen</a>, 
<a href="/search/math?searchtype=author&query=Balzano%2C+L">Laura Balzano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at AISTATS 2024. v5: experiments are expanded
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.06648" title="Abstract">arXiv:2207.06648</a> (replaced) [<a href="/pdf/2207.06648" title="Download PDF">pdf</a>, <a href="/format/2207.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backpropagation in hyperbolic chaos via adjoint shadowing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ni%2C+A">Angxiu Ni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.13630" title="Abstract">arXiv:2207.13630</a> (replaced) [<a href="/pdf/2207.13630" title="Download PDF">pdf</a>, <a href="/format/2207.13630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Copositive Framework for Analysis of Hybrid Ising-Classical Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Brown%2C+R">Robin Brown</a>, 
<a href="/search/math?searchtype=author&query=Neira%2C+D+E+B">David E. Bernal Neira</a>, 
<a href="/search/math?searchtype=author&query=Venturelli%2C+D">Davide Venturelli</a>, 
<a href="/search/math?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Discrete Mathematics (cs.DM); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04883" title="Abstract">arXiv:2208.04883</a> (replaced) [<a href="/pdf/2208.04883" title="Download PDF">pdf</a>, <a href="/format/2208.04883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural-Rendezvous: Provably Robust Guidance and Control to Encounter  Interstellar Objects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsukamoto%2C+H">Hiroyasu Tsukamoto</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+S">Soon-Jo Chung</a>, 
<a href="/search/cs?searchtype=author&query=Donitz%2C+B">Benjamin Donitz</a>, 
<a href="/search/cs?searchtype=author&query=Ingham%2C+M">Michel Ingham</a>, 
<a href="/search/cs?searchtype=author&query=Mages%2C+D">Declan Mages</a>, 
<a href="/search/cs?searchtype=author&query=Nakka%2C+Y+K">Yashwanth Kumar Nakka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor Revision, AIAA Journal of Guidance, Control, and Dynamics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02021" title="Abstract">arXiv:2209.02021</a> (replaced) [<a href="/pdf/2209.02021" title="Download PDF">pdf</a>, <a href="/format/2209.02021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Robotics Meets Wireless Communications: An Introductory Tutorial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Licea%2C+D+B">Daniel Bonilla Licea</a>, 
<a href="/search/cs?searchtype=author&query=Ghogho%2C+M">Mounir Ghogho</a>, 
<a href="/search/cs?searchtype=author&query=Saska%2C+M">Martin Saska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 192 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.07805" title="Abstract">arXiv:2209.07805</a> (replaced) [<a href="/pdf/2209.07805" title="Download PDF">pdf</a>, <a href="/format/2209.07805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Benchmark for COVID-19 Predictive Modeling Using  Electronic Health Records in Intensive Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yinghao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenqing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Wen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Harrison%2C+E+M">Ewen M. Harrison</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Liantao Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Junyi Gao, Yinghao Zhu and Wenqing Wang contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09930" title="Abstract">arXiv:2209.09930</a> (replaced) [<a href="/pdf/2209.09930" title="Download PDF">pdf</a>, <a href="/format/2209.09930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Superpixel Generation and Clustering for Weakly Supervised  Segmentation of Brain Tumors in MR Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoo%2C+J+J">Jay J. Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Namdar%2C+K">Khashayar Namdar</a>, 
<a href="/search/cs?searchtype=author&query=Khalvati%2C+F">Farzad Khalvati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, LaTeX; updated methodology, added additional results, revised discussion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02651" title="Abstract">arXiv:2210.02651</a> (replaced) [<a href="/pdf/2210.02651" title="Download PDF">pdf</a>, <a href="/format/2210.02651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking the Evolution of Static Code Warnings: the State-of-the-Art and  a Better Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinqiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01758" title="Abstract">arXiv:2211.01758</a> (replaced) [<a href="/pdf/2211.01758" title="Download PDF">pdf</a>, <a href="/format/2211.01758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Algorithms for Stochastic Complementary Composite Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=d%27Aspremont%2C+A">Alexandre d&#x27;Aspremont</a>, 
<a href="/search/cs?searchtype=author&query=Guzm%C3%A1n%2C+C">Crist&#xf3;bal Guzm&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=Lezane%2C+C">Cl&#xe9;ment Lezane</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02365" title="Abstract">arXiv:2211.02365</a> (replaced) [<a href="/pdf/2211.02365" title="Download PDF">pdf</a>, <a href="/format/2211.02365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Robustness for the Skolem, Positivity and Ultimate Positivity  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akshay%2C+S">S. Akshay</a>, 
<a href="/search/cs?searchtype=author&query=Bazille%2C+H">Hugo Bazille</a>, 
<a href="/search/cs?searchtype=author&query=Genest%2C+B">Blaise Genest</a>, 
<a href="/search/cs?searchtype=author&query=Vahanwala%2C+M">Mihir Vahanwala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of conference paper which appeared in the proceedings of STACS'22
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.06598" title="Abstract">arXiv:2211.06598</a> (replaced) [<a href="/pdf/2211.06598" title="Download PDF">pdf</a>, <a href="/ps/2211.06598" title="Download PostScript">ps</a>, <a href="/format/2211.06598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Resource Utilization of Non-terrestrial Networks Using  Temporal Graph-based Deterministic Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Keyi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingchao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13525" title="Abstract">arXiv:2211.13525</a> (replaced) [<a href="/pdf/2211.13525" title="Download PDF">pdf</a>, <a href="/format/2211.13525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Search-Based Software Microbenchmark Prioritization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laaber%2C+C">Christoph Laaber</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03281" title="Abstract">arXiv:2212.03281</a> (replaced) [<a href="/pdf/2212.03281" title="Download PDF">pdf</a>, <a href="/format/2212.03281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Copula Conformal Prediction for Multi-step Time Series Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+S">Sophia Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rose Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04631" title="Abstract">arXiv:2212.04631</a> (replaced) [<a href="/pdf/2212.04631" title="Download PDF">pdf</a>, <a href="/format/2212.04631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Normalized Cross Density Functional: A Framework to Quantify  Statistical Dependence for Random Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B">Bo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Principe%2C+J+C">Jose C. Principe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09050" title="Abstract">arXiv:2212.09050</a> (replaced) [<a href="/pdf/2212.09050" title="Download PDF">pdf</a>, <a href="/format/2212.09050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determining Distributions of Security Means for WSNs based on the Model  of a Neighbourhood Watch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+B">Benjamin F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Langend%C3%B6rfer%2C+P">Peter Langend&#xf6;rfer</a>, 
<a href="/search/cs?searchtype=author&query=Hinze%2C+T">Thomas Hinze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Corrected implementation errors which led to measurement errors in the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11247" title="Abstract">arXiv:2212.11247</a> (replaced) [<a href="/pdf/2212.11247" title="Download PDF">pdf</a>, <a href="/format/2212.11247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Count-Free Weisfeiler--Leman and Group Isomorphism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+N+A">Nathaniel A. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Levet%2C+M">Michael Levet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.11487">arXiv:2112.11487</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC); Logic in Computer Science (cs.LO); Group Theory (math.GR)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12192" title="Abstract">arXiv:2212.12192</a> (replaced) [<a href="/pdf/2212.12192" title="Download PDF">pdf</a>, <a href="/format/2212.12192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Questions by Enhancing Text Generation with  Sentence Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quoc-Hung%2C+P">Pham Quoc-Hung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh-Tien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran-Tien%2C+M">Manh Tran-Tien</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+X">Xuan-Hieu Phan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper describes an on-going work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12970" title="Abstract">arXiv:2212.12970</a> (replaced) [<a href="/e-print/2212.12970" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refined Edge Usage of Graph Neural Networks for Edge Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jiarui Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yangkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Q">Quan Gan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wipf%2C+D">David Wipf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Need major revisions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13069" title="Abstract">arXiv:2212.13069</a> (replaced) [<a href="/pdf/2212.13069" title="Download PDF">pdf</a>, <a href="/format/2212.13069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homophily modulates double descent generalization in graph convolution  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Cheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liming Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Dokmani%C4%87%2C+I">Ivan Dokmani&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02424" title="Abstract">arXiv:2301.02424</a> (replaced) [<a href="/pdf/2301.02424" title="Download PDF">pdf</a>, <a href="/format/2301.02424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conformal Loss-Controlling Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaojun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyue Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04378" title="Abstract">arXiv:2301.04378</a> (replaced) [<a href="/pdf/2301.04378" title="Download PDF">pdf</a>, <a href="/format/2301.04378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss-Controlling Calibration for Predictive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Junzhi Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pingping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Shuo Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyue Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05833" title="Abstract">arXiv:2301.05833</a> (replaced) [<a href="/pdf/2301.05833" title="Download PDF">pdf</a>, <a href="/format/2301.05833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Coordination Fluid Flow Modeling and Experimental Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Uppaluru%2C+H">Harshvardhan Uppaluru</a>, 
<a href="/search/eess?searchtype=author&query=Ghuran%2C+M">Mohammad Ghuran</a>, 
<a href="/search/eess?searchtype=author&query=Rastgoftar%2C+H">Hossein Rastgoftar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06244" title="Abstract">arXiv:2301.06244</a> (replaced) [<a href="/pdf/2301.06244" title="Download PDF">pdf</a>, <a href="/format/2301.06244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haptic Transparency and Interaction Force Control for a Lower-Limb  Exoskeleton
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BC%C3%A7%C3%BCktabak%2C+E+B">Emek Bar&#x131;&#x15f; K&#xfc;&#xe7;&#xfc;ktabak</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yue Wen</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S+J">Sangjoon J. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Short%2C+M">Matthew Short</a>, 
<a href="/search/cs?searchtype=author&query=Ludvig%2C+D">Daniel Ludvig</a>, 
<a href="/search/cs?searchtype=author&query=Hargrove%2C+L">Levi Hargrove</a>, 
<a href="/search/cs?searchtype=author&query=Perreault%2C+E">Eric Perreault</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+K">Kevin Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Pons%2C+J">Jose Pons</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures. Accepted for publication in the IEEE Transactions on Robotics (T-RO)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11915" title="Abstract">arXiv:2301.11915</a> (replaced) [<a href="/pdf/2301.11915" title="Download PDF">pdf</a>, <a href="/format/2301.11915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Self-Supervised Pretraining with Part-Aware Representation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+J">Jiyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+M">Mingyu Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaokang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leye Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMLR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05154" title="Abstract">arXiv:2302.05154</a> (replaced) [<a href="/pdf/2302.05154" title="Download PDF">pdf</a>, <a href="/format/2302.05154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Industrial and Medical Anomaly Detection Through Cycle-Consistent  Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bougaham%2C+A">Arnaud Bougaham</a>, 
<a href="/search/cs?searchtype=author&query=Delchevalerie%2C+V">Valentin Delchevalerie</a>, 
<a href="/search/cs?searchtype=author&query=Adoui%2C+M+E">Mohammed El Adoui</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%A9nay%2C+B">Beno&#xee;t Fr&#xe9;nay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02444" title="Abstract">arXiv:2303.02444</a> (replaced) [<a href="/pdf/2303.02444" title="Download PDF">pdf</a>, <a href="/format/2303.02444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating Transformers via Sparse Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingzhen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at The Eleventh International Conference on Learning Representations (ICLR 2023). This latest Arxiv version includes a clarification of how ECE/MCE are computed (at page 10)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07700" title="Abstract">arXiv:2303.07700</a> (replaced) [<a href="/pdf/2303.07700" title="Download PDF">pdf</a>, <a href="/format/2303.07700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PATS: Patch Area Transportation with Subdivision for Local Feature  Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Junjie Ni</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yijin Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhaoyang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Hujun Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhaopeng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guofeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023. Project page: <a href="https://zju3dv.github.io/pats">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07846" title="Abstract">arXiv:2303.07846</a> (replaced) [<a href="/pdf/2303.07846" title="Download PDF">pdf</a>, <a href="/format/2303.07846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample-efficient Adversarial Imitation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jung%2C+D">Dahuin Jung</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hyungyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Sungroh Yoon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at JMLR (Journal of Machine Learning Research), A preliminary version of this manuscript was presented at Deep RL Workshop, NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08895" title="Abstract">arXiv:2303.08895</a> (replaced) [<a href="/pdf/2303.08895" title="Download PDF">pdf</a>, <a href="/format/2303.08895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rollout-Based Charging Strategy for Electric Trucks with  Hours-of-Service Regulations (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+T">Ting Bai</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yuchao Li</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%A5rtensson%2C+J">Jonas M&#xe5;rtensson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper published in IEEE Control Systems Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16180" title="Abstract">arXiv:2303.16180</a> (replaced) [<a href="/pdf/2303.16180" title="Download PDF">pdf</a>, <a href="/format/2303.16180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Coating by 3D Hybrid Programmable Matter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kostitsyna%2C+I">Irina Kostitsyna</a>, 
<a href="/search/cs?searchtype=author&query=Liedtke%2C+D">David Liedtke</a>, 
<a href="/search/cs?searchtype=author&query=Scheideler%2C+C">Christian Scheideler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06470" title="Abstract">arXiv:2304.06470</a> (replaced) [<a href="/pdf/2304.06470" title="Download PDF">pdf</a>, <a href="/format/2304.06470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Qualitative Failures of Image Generation Models and Their Application in  Detecting Deepfakes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borji%2C+A">Ali Borji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07468" title="Abstract">arXiv:2304.07468</a> (replaced) [<a href="/pdf/2304.07468" title="Download PDF">pdf</a>, <a href="/ps/2304.07468" title="Download PostScript">ps</a>, <a href="/format/2304.07468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limited Diffusion of Scientific Knowledge Forecasts Collapse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+D">Donghyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Danziger%2C+R+S">Robert S. Danziger</a>, 
<a href="/search/cs?searchtype=author&query=Rehman%2C+J">Jalees Rehman</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+J+A">James A. Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07809" title="Abstract">arXiv:2304.07809</a> (replaced) [<a href="/pdf/2304.07809" title="Download PDF">pdf</a>, <a href="/ps/2304.07809" title="Download PostScript">ps</a>, <a href="/format/2304.07809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Approach for Designing Well-Balanced Schemes for the Shallow Water  Equations: A Combination of Conservative and Primitive Formulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Abgrall%2C+R">Remi Abgrall</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+Y">Yongle Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09970" title="Abstract">arXiv:2304.09970</a> (replaced) [<a href="/pdf/2304.09970" title="Download PDF">pdf</a>, <a href="/format/2304.09970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning policies for resource allocation in business processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Middelhuis%2C+J">J. Middelhuis</a>, 
<a href="/search/cs?searchtype=author&query=Bianco%2C+R+L">R. Lo Bianco</a>, 
<a href="/search/cs?searchtype=author&query=Scherzer%2C+E">E. Scherzer</a>, 
<a href="/search/cs?searchtype=author&query=Bukhsh%2C+Z+A">Z. A. Bukhsh</a>, 
<a href="/search/cs?searchtype=author&query=Adan%2C+I+J+B+F">I. J. B. F. Adan</a>, 
<a href="/search/cs?searchtype=author&query=Dijkman%2C+R+M">R. M. Dijkman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13014" title="Abstract">arXiv:2304.13014</a> (replaced) [<a href="/pdf/2304.13014" title="Download PDF">pdf</a>, <a href="/format/2304.13014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Methods and datasets for segmentation of minimally invasive surgical  instruments in endoscopic images and videos: A review of the state of the art
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+T">Tobias Rueckert</a> (1), 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Palm%2C+C">Christoph Palm</a> (1 and 4) ((1) Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Germany, (2) Artificial Intelligence in Healthcare and Medicine, Klinikum rechts der Isar, Technical University of Munich, Germany, (3) Department of Computing, Imperial College London, UK, (4) Regensburg Center of Health Sciences and Technology (RCHST), OTH Regensburg, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Comput. Biol. Med. 169 (2024) 107929
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14391" title="Abstract">arXiv:2304.14391</a> (replaced) [<a href="/pdf/2304.14391" title="Download PDF">pdf</a>, <a href="/format/2304.14391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Energy-based Models are Zero-Shot Planners for Compositional Scene  Rearrangement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gkanatsios%2C+N">Nikolaos Gkanatsios</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+A">Ayush Jain</a>, 
<a href="/search/cs?searchtype=author&query=Xian%2C+Z">Zhou Xian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunchu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Atkeson%2C+C">Christopher Atkeson</a>, 
<a href="/search/cs?searchtype=author&query=Fragkiadaki%2C+K">Katerina Fragkiadaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally | RSS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02317" title="Abstract">arXiv:2305.02317</a> (replaced) [<a href="/pdf/2305.02317" title="Download PDF">pdf</a>, <a href="/format/2305.02317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Chain of Thought: Bridging Logical Gaps with Multimodal  Infillings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rose%2C+D">Daniel Rose</a>, 
<a href="/search/cs?searchtype=author&query=Himakunthala%2C+V">Vaishnavi Himakunthala</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+A">Andy Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ryan He</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+A">Alex Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yujie Lu</a>, 
<a href="/search/cs?searchtype=author&query=Saxon%2C+M">Michael Saxon</a>, 
<a href="/search/cs?searchtype=author&query=Sonar%2C+C">Chinmay Sonar</a>, 
<a href="/search/cs?searchtype=author&query=Mirza%2C+D">Diba Mirza</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W+Y">William Yang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03053" title="Abstract">arXiv:2305.03053</a> (replaced) [<a href="/pdf/2305.03053" title="Download PDF">pdf</a>, <a href="/format/2305.03053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZipIt! Merging Models from Different Tasks without Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoica%2C+G">George Stoica</a>, 
<a href="/search/cs?searchtype=author&query=Bolya%2C+D">Daniel Bolya</a>, 
<a href="/search/cs?searchtype=author&query=Bjorner%2C+J">Jakob Bjorner</a>, 
<a href="/search/cs?searchtype=author&query=Ramesh%2C+P">Pratik Ramesh</a>, 
<a href="/search/cs?searchtype=author&query=Hearn%2C+T">Taylor Hearn</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04435" title="Abstract">arXiv:2305.04435</a> (replaced) [<a href="/pdf/2305.04435" title="Download PDF">pdf</a>, <a href="/ps/2305.04435" title="Download PostScript">ps</a>, <a href="/format/2305.04435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication complexity of entanglement assisted multi-party  computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Meng%2C+R">Ruoyu Meng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ramamoorthy%2C+A">Aditya Ramamoorthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07992" title="Abstract">arXiv:2305.07992</a> (replaced) [<a href="/pdf/2305.07992" title="Download PDF">pdf</a>, <a href="/ps/2305.07992" title="Download PostScript">ps</a>, <a href="/format/2305.07992" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Capacity of DNA Labeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hanania%2C+D">Dganit Hanania</a>, 
<a href="/search/cs?searchtype=author&query=Bar-Lev%2C+D">Daniella Bar-Lev</a>, 
<a href="/search/cs?searchtype=author&query=Nogin%2C+Y">Yevgeni Nogin</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+Y">Yoav Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Yaakobi%2C+E">Eitan Yaakobi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09781" title="Abstract">arXiv:2305.09781</a> (replaced) [<a href="/pdf/2305.09781" title="Download PDF">pdf</a>, <a href="/format/2305.09781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecInfer: Accelerating Generative Large Language Model Serving with  Tree-based Speculative Inference and Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Oliaro%2C+G">Gabriele Oliaro</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinhao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zeyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhengxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+R+Y+Y">Rae Ying Yee Wong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Alan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lijie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoxiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chunan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Arfeen%2C+D">Daiyaan Arfeen</a>, 
<a href="/search/cs?searchtype=author&query=Abhyankar%2C+R">Reyna Abhyankar</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+Z">Zhihao Jia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11321" title="Abstract">arXiv:2305.11321</a> (replaced) [<a href="/pdf/2305.11321" title="Download PDF">pdf</a>, <a href="/format/2305.11321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JoIN: Joint GANs Inversion for Intrinsic Image Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+V">Viraj Shah</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+S">Svetlana Lazebnik</a>, 
<a href="/search/cs?searchtype=author&query=Philip%2C+J">Julien Philip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project webpage is available at <a href="https://virajshah.com/join">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13208" title="Abstract">arXiv:2305.13208</a> (replaced) [<a href="/pdf/2305.13208" title="Download PDF">pdf</a>, <a href="/format/2305.13208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Adversarial Attack on Image-guided Story Ending Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Youze Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenbo Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Richang Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14259" title="Abstract">arXiv:2305.14259</a> (replaced) [<a href="/pdf/2305.14259" title="Download PDF">pdf</a>, <a href="/format/2305.14259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Generate Novel Scientific Directions with Contextualized  Literature-based Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Downey%2C+D">Doug Downey</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Hope%2C+T">Tom Hope</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages. Code and resource is available at <a href="https://github.com/EagleW/CLBD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18417" title="Abstract">arXiv:2305.18417</a> (replaced) [<a href="/pdf/2305.18417" title="Download PDF">pdf</a>, <a href="/format/2305.18417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Determinantal Point Process Attention Over Grid Cell Code Supports Out  of Distribution Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S+S">Shanka Subhra Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Frankland%2C+S">Steven Frankland</a>, 
<a href="/search/cs?searchtype=author&query=Webb%2C+T">Taylor Webb</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D. Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages (including Appendix), 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18990" title="Abstract">arXiv:2305.18990</a> (replaced) [<a href="/pdf/2305.18990" title="Download PDF">pdf</a>, <a href="/ps/2305.18990" title="Download PostScript">ps</a>, <a href="/format/2305.18990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifiability of Points and Rigidity of Hypergraphs under Algebraic  Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cruickshank%2C+J">James Cruickshank</a>, 
<a href="/search/math?searchtype=author&query=Mohammadi%2C+F">Fatemeh Mohammadi</a>, 
<a href="/search/math?searchtype=author&query=Nixon%2C+A">Anthony Nixon</a>, 
<a href="/search/math?searchtype=author&query=Tanigawa%2C+S">Shin-ichi Tanigawa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Metric Geometry (math.MG)</span>; Computational Geometry (cs.CG); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19004" title="Abstract">arXiv:2305.19004</a> (replaced) [<a href="/pdf/2305.19004" title="Download PDF">pdf</a>, <a href="/ps/2305.19004" title="Download PostScript">ps</a>, <a href="/format/2305.19004" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient Algorithms for Robust MDPs with Non-Rectangular  Uncertainty Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+M">Mengmeng Li</a>, 
<a href="/search/math?searchtype=author&query=Kuhn%2C+D">Daniel Kuhn</a>, 
<a href="/search/math?searchtype=author&query=Sutter%2C+T">Tobias Sutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> comments are welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02272" title="Abstract">arXiv:2306.02272</a> (replaced) [<a href="/pdf/2306.02272" title="Download PDF">pdf</a>, <a href="/format/2306.02272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OWQ: Lessons learned from activation outliers for weight quantization in  large language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Changhun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jungyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taesu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyungjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunhyeok Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02869" title="Abstract">arXiv:2306.02869</a> (replaced) [<a href="/pdf/2306.02869" title="Download PDF">pdf</a>, <a href="/format/2306.02869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Online Model Selection With Regret Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacchiano%2C+A">Aldo Pacchiano</a>, 
<a href="/search/cs?searchtype=author&query=Dann%2C+C">Christoph Dann</a>, 
<a href="/search/cs?searchtype=author&query=Gentile%2C+C">Claudio Gentile</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03401" title="Abstract">arXiv:2306.03401</a> (replaced) [<a href="/pdf/2306.03401" title="Download PDF">pdf</a>, <a href="/format/2306.03401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Method for Tackling Unknown Participation Statistics in  Federated Averaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+M">Mingyue Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05739" title="Abstract">arXiv:2306.05739</a> (replaced) [<a href="/pdf/2306.05739" title="Download PDF">pdf</a>, <a href="/format/2306.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leaping through tree space: continuous phylogenetic inference for rooted  and unrooted trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Penn%2C+M+J">Matthew J Penn</a>, 
<a href="/search/q-bio?searchtype=author&query=Scheidwasser%2C+N">Neil Scheidwasser</a>, 
<a href="/search/q-bio?searchtype=author&query=Penn%2C+J">Joseph Penn</a>, 
<a href="/search/q-bio?searchtype=author&query=Donnelly%2C+C+A">Christl A Donnelly</a>, 
<a href="/search/q-bio?searchtype=author&query=Duch%C3%AAne%2C+D+A">David A Duch&#xea;ne</a>, 
<a href="/search/q-bio?searchtype=author&query=Bhatt%2C+S">Samir Bhatt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 3 figures, 2 tables, 20 supplementary pages, 3 supplementary figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Genome Biol. Evol. 15 (2023) evad213
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06075" title="Abstract">arXiv:2306.06075</a> (replaced) [<a href="/pdf/2306.06075" title="Download PDF">pdf</a>, <a href="/ps/2306.06075" title="Download PostScript">ps</a>, <a href="/format/2306.06075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSeaNet: Improving Underwater Object Detection using EfficientDet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Sanyam Jain</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07107" title="Abstract">arXiv:2306.07107</a> (replaced) [<a href="/pdf/2306.07107" title="Download PDF">pdf</a>, <a href="/format/2306.07107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A novel trajectory optimization algorithm for continuous-time model  predictive control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Das%2C+S">Souvik Das</a>, 
<a href="/search/math?searchtype=author&query=Ganguly%2C+S">Siddhartha Ganguly</a>, 
<a href="/search/math?searchtype=author&query=Anjali%2C+M">Muthyala Anjali</a>, 
<a href="/search/math?searchtype=author&query=Chatterjee%2C+D">Debasish Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Conference on Decision and Control (CDC), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09549" title="Abstract">arXiv:2306.09549</a> (replaced) [<a href="/pdf/2306.09549" title="Download PDF">pdf</a>, <a href="/format/2306.09549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yu%2C+H">Haiyang Yu</a>, 
<a href="/search/physics?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/physics?searchtype=author&query=Luo%2C+Y">Youzhi Luo</a>, 
<a href="/search/physics?searchtype=author&query=Strasser%2C+A">Alex Strasser</a>, 
<a href="/search/physics?searchtype=author&query=Qian%2C+X">Xiaofeng Qian</a>, 
<a href="/search/physics?searchtype=author&query=Qian%2C+X">Xiaoning Qian</a>, 
<a href="/search/physics?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023, Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14451" title="Abstract">arXiv:2306.14451</a> (replaced) [<a href="/pdf/2306.14451" title="Download PDF">pdf</a>, <a href="/format/2306.14451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Prompt-Enhanced Context Features for Weakly-Supervised Video  Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+Y">Yujiang Pu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoyu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lulu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14624" title="Abstract">arXiv:2306.14624</a> (replaced) [<a href="/pdf/2306.14624" title="Download PDF">pdf</a>, <a href="/ps/2306.14624" title="Download PostScript">ps</a>, <a href="/format/2306.14624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights From Insurance for Fair Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6hlich%2C+C">Christian Fr&#xf6;hlich</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+R+C">Robert C. Williamson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17396" title="Abstract">arXiv:2306.17396</a> (replaced) [<a href="/pdf/2306.17396" title="Download PDF">pdf</a>, <a href="/format/2306.17396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Koopman operator learning using invertible neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Meng%2C+Y">Yuhuang Meng</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+J">Jianguo Huang</a>, 
<a href="/search/math?searchtype=author&query=Qiu%2C+Y">Yue Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00384" title="Abstract">arXiv:2307.00384</a> (replaced) [<a href="/pdf/2307.00384" title="Download PDF">pdf</a>, <a href="/format/2307.00384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CasTGAN: Cascaded Generative Adversarial Network for Realistic Tabular  Data Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alshantti%2C+A">Abdallah Alshantti</a>, 
<a href="/search/cs?searchtype=author&query=Varagnolo%2C+D">Damiano Varagnolo</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+A">Adil Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Rahmati%2C+A">Aria Rahmati</a>, 
<a href="/search/cs?searchtype=author&query=Westad%2C+F">Frank Westad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02156" title="Abstract">arXiv:2307.02156</a> (replaced) [<a href="/pdf/2307.02156" title="Download PDF">pdf</a>, <a href="/format/2307.02156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hypercongestion, autonomous vehicle, and urban spatial structure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dantsuji%2C+T">Takao Dantsuji</a>, 
<a href="/search/eess?searchtype=author&query=Takayama%2C+Y">Yuki Takayama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02764" title="Abstract">arXiv:2307.02764</a> (replaced) [<a href="/pdf/2307.02764" title="Download PDF">pdf</a>, <a href="/format/2307.02764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Does Confidence-Based Cascade Deferral Suffice?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jitkrittum%2C+W">Wittawat Jitkrittum</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Neha Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Menon%2C+A+K">Aditya Krishna Menon</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+H">Harikrishna Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Rawat%2C+A+S">Ankit Singh Rawat</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Sanjiv Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.03212" title="Abstract">arXiv:2307.03212</a> (replaced) [<a href="/pdf/2307.03212" title="Download PDF">pdf</a>, <a href="/ps/2307.03212" title="Download PostScript">ps</a>, <a href="/format/2307.03212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Region-Wise Attentive Multi-View Representation Learning for Urban  Region Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+W">Weiliang Chan</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Q">Qianqian Ren</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CIKM '23: The 32nd ACM International Conference on Information and
  Knowledge Management Birmingham United Kingdom October 21 - 25, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07727" title="Abstract">arXiv:2307.07727</a> (replaced) [<a href="/pdf/2307.07727" title="Download PDF">pdf</a>, <a href="/ps/2307.07727" title="Download PostScript">ps</a>, <a href="/format/2307.07727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Mixing via Tensorization for Random Independent Sets on  Arbitrary Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Efthymiou%2C+C">Charilaos Efthymiou</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+T+P">Thomas P. Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Stefankovic%2C+D">Daniel Stefankovic</a>, 
<a href="/search/cs?searchtype=author&query=Vigoda%2C+E">Eric Vigoda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04853" title="Abstract">arXiv:2308.04853</a> (replaced) [<a href="/pdf/2308.04853" title="Download PDF">pdf</a>, <a href="/format/2308.04853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregated demand flexibility prediction of residential thermostatically  controlled loads and participation in electricity balance markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADn-Crespo%2C+A">Alejandro Mart&#xed;n-Crespo</a>, 
<a href="/search/eess?searchtype=author&query=Baeyens%2C+E">Enrique Baeyens</a>, 
<a href="/search/eess?searchtype=author&query=Saludes-Rodil%2C+S">Sergio Saludes-Rodil</a>, 
<a href="/search/eess?searchtype=author&query=Frechoso-Escudero%2C+F">Fernando Frechoso-Escudero</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06979" title="Abstract">arXiv:2308.06979</a> (replaced) [<a href="/pdf/2308.06979" title="Download PDF">pdf</a>, <a href="/format/2308.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sound Demixing Challenge 2023 $\unicode{x2013}$ Music Demixing Track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabbro%2C+G">Giorgio Fabbro</a>, 
<a href="/search/eess?searchtype=author&query=Uhlich%2C+S">Stefan Uhlich</a>, 
<a href="/search/eess?searchtype=author&query=Lai%2C+C">Chieh-Hsin Lai</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+W">Woosung Choi</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez-Ram%C3%ADrez%2C+M">Marco Mart&#xed;nez-Ram&#xed;rez</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+W">Weihsiang Liao</a>, 
<a href="/search/eess?searchtype=author&query=Gadelha%2C+I">Igor Gadelha</a>, 
<a href="/search/eess?searchtype=author&query=Ramos%2C+G">Geraldo Ramos</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+E">Eddie Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Rodrigues%2C+H">Hugo Rodrigues</a>, 
<a href="/search/eess?searchtype=author&query=St%C3%B6ter%2C+F">Fabian-Robert St&#xf6;ter</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%A9fossez%2C+A">Alexandre D&#xe9;fossez</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chakraborty%2C+D">Dipam Chakraborty</a>, 
<a href="/search/eess?searchtype=author&query=Mohanty%2C+S">Sharada Mohanty</a>, 
<a href="/search/eess?searchtype=author&query=Solovyev%2C+R">Roman Solovyev</a>, 
<a href="/search/eess?searchtype=author&query=Stempkovskiy%2C+A">Alexander Stempkovskiy</a>, 
<a href="/search/eess?searchtype=author&query=Habruseva%2C+T">Tatiana Habruseva</a>, 
<a href="/search/eess?searchtype=author&query=Goswami%2C+N">Nabarun Goswami</a>, 
<a href="/search/eess?searchtype=author&query=Harada%2C+T">Tatsuya Harada</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Minseok Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J+H">Jun Hyung Lee</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+Y">Yuanliang Dong</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xinran Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jiafeng Liu</a>, 
<a href="/search/eess?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07213" title="Abstract">arXiv:2308.07213</a> (replaced) [<a href="/pdf/2308.07213" title="Download PDF">pdf</a>, <a href="/format/2308.07213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using  Matchmaking for AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Houjiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Anubrata Das</a>, 
<a href="/search/cs?searchtype=author&query=Boltz%2C+A">Alexander Boltz</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Didi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pinaroc%2C+D">Daisy Pinaroc</a>, 
<a href="/search/cs?searchtype=author&query=Lease%2C+M">Matthew Lease</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M+K">Min Kyung Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10487" title="Abstract">arXiv:2308.10487</a> (replaced) [<a href="/pdf/2308.10487" title="Download PDF">pdf</a>, <a href="/format/2308.10487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+L">Lue Tao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu-Xuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wang-Zhou Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuan Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10610" title="Abstract">arXiv:2308.10610</a> (replaced) [<a href="/pdf/2308.10610" title="Download PDF">pdf</a>, <a href="/format/2308.10610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ultrafast and Ultralight Network-Based Intelligent System for Real-time  Diagnosis of Ear Diseases in Any Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yubiao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xiaoqiang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Meiping Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Haihua Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanmei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zefeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenrui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages,8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11477" title="Abstract">arXiv:2308.11477</a> (replaced) [<a href="/pdf/2308.11477" title="Download PDF">pdf</a>, <a href="/ps/2308.11477" title="Download PostScript">ps</a>, <a href="/format/2308.11477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved column-generation-based matheuristic for learning  classification trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patel%2C+K+K">Krunal Kishor Patel</a>, 
<a href="/search/cs?searchtype=author&query=Desaulniers%2C+G">Guy Desaulniers</a>, 
<a href="/search/cs?searchtype=author&query=Lodi%2C+A">Andrea Lodi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computers and Operations Research journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11624" title="Abstract">arXiv:2308.11624</a> (replaced) [<a href="/pdf/2308.11624" title="Download PDF">pdf</a>, <a href="/ps/2308.11624" title="Download PostScript">ps</a>, <a href="/format/2308.11624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revolutionizing TCAD Simulations with Universal Device Encoding and  Graph Attention Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guangxi Fan</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Leilai Shao</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+K+L">Kain Lu Low</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 13 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.12890" title="Abstract">arXiv:2308.12890</a> (replaced) [<a href="/pdf/2308.12890" title="Download PDF">pdf</a>, <a href="/format/2308.12890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Vote: Prompting for Rare Disease Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oniani%2C+D">David Oniani</a>, 
<a href="/search/cs?searchtype=author&query=Hilsman%2C+J">Jordan Hilsman</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+F">Fengyi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+S">Shiven Verma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14190" title="Abstract">arXiv:2308.14190</a> (replaced) [<a href="/pdf/2308.14190" title="Download PDF">pdf</a>, <a href="/format/2308.14190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Score-Based Generative Models for PET Image Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Singh%2C+I+R">Imraj RD Singh</a>, 
<a href="/search/eess?searchtype=author&query=Denker%2C+A">Alexander Denker</a>, 
<a href="/search/eess?searchtype=author&query=Barbano%2C+R">Riccardo Barbano</a>, 
<a href="/search/eess?searchtype=author&query=Kereta%2C+%C5%BD">&#x17d;eljko Kereta</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+B">Bangti Jin</a>, 
<a href="/search/eess?searchtype=author&query=Thielemans%2C+K">Kris Thielemans</a>, 
<a href="/search/eess?searchtype=author&query=Maass%2C+P">Peter Maass</a>, 
<a href="/search/eess?searchtype=author&query=Arridge%2C+S">Simon Arridge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2024:001">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16692" title="Abstract">arXiv:2308.16692</a> (replaced) [<a href="/pdf/2308.16692" title="Download PDF">pdf</a>, <a href="/format/2308.16692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shimin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yaqian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024. Project page is at <a href="https://0nutation.github.io/SpeechTokenizer.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01141" title="Abstract">arXiv:2309.01141</a> (replaced) [<a href="/pdf/2309.01141" title="Download PDF">pdf</a>, <a href="/format/2309.01141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VGDiffZero: Text-to-image Diffusion Models Can Be Zero-shot Visual  Grounders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Siteng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yachen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honggang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Donglin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02441" title="Abstract">arXiv:2309.02441</a> (replaced) [<a href="/pdf/2309.02441" title="Download PDF">pdf</a>, <a href="/format/2309.02441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonnegative moment coordinates on finite element geometries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dieci%2C+L">Luca Dieci</a>, 
<a href="/search/math?searchtype=author&query=Difonzo%2C+F+V">Fabio V. Difonzo</a>, 
<a href="/search/math?searchtype=author&query=Sukumar%2C+N">N. Sukumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04494" title="Abstract">arXiv:2309.04494</a> (replaced) [<a href="/pdf/2309.04494" title="Download PDF">pdf</a>, <a href="/format/2309.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Steady-State Solutions to the Equations Governing  Fluid Flow in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srinivasan%2C+S">Shriram Srinivasan</a>, 
<a href="/search/math?searchtype=author&query=Panda%2C+N">Nishant Panda</a>, 
<a href="/search/math?searchtype=author&query=Sundar%2C+K">Kaarthik Sundar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06801" title="Abstract">arXiv:2309.06801</a> (replaced) [<a href="/pdf/2309.06801" title="Download PDF">pdf</a>, <a href="/ps/2309.06801" title="Download PostScript">ps</a>, <a href="/format/2309.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defensive Alliances in Signed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arrighi%2C+E">Emmanuel Arrighi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhidan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+P">Petra Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08007" title="Abstract">arXiv:2309.08007</a> (replaced) [<a href="/pdf/2309.08007" title="Download PDF">pdf</a>, <a href="/ps/2309.08007" title="Download PostScript">ps</a>, <a href="/format/2309.08007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiariST: Streaming Speech Translation with Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+M">Mu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kanda%2C+N">Naoyuki Kanda</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junkun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Peidong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+J">Jian Xue</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Yoshioka%2C+T">Takuya Yoshioka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08363" title="Abstract">arXiv:2309.08363</a> (replaced) [<a href="/pdf/2309.08363" title="Download PDF">pdf</a>, <a href="/format/2309.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narratives of War: Ukrainian Memetic Warfare on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mejova%2C+Y">Yelena Mejova</a>, 
<a href="/search/cs?searchtype=author&query=Capozzi%2C+A">Arthur Capozzi</a>, 
<a href="/search/cs?searchtype=author&query=Monti%2C+C">Corrado Monti</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09085" title="Abstract">arXiv:2309.09085</a> (replaced) [<a href="/pdf/2309.09085" title="Download PDF">pdf</a>, <a href="/format/2309.09085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SynthTab: Leveraging Synthesized Data for Guitar Tablature Transcription
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zang%2C+Y">Yongyi Zang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cwitkowitz%2C+F">Frank Cwitkowitz</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Z">Zhiyao Duan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Information Retrieval (cs.IR); Multimedia (cs.MM); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09477" title="Abstract">arXiv:2309.09477</a> (replaced) [<a href="/pdf/2309.09477" title="Download PDF">pdf</a>, <a href="/format/2309.09477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Freedom Does An Effectiveness Metric Really Have?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moffat%2C+A">Alistair Moffat</a>, 
<a href="/search/cs?searchtype=author&query=Mackenzie%2C+J">Joel Mackenzie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear: Journal of the Association for Information Science and Technology, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09552" title="Abstract">arXiv:2309.09552</a> (replaced) [<a href="/pdf/2309.09552" title="Download PDF">pdf</a>, <a href="/format/2309.09552" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multitask Training Approach to Enhance Whisper with Contextual Biasing  and Open-Vocabulary Keyword Spotting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinglu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+M">Mengxin Ren</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xiaosong Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaofeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Piao%2C+M">Mengyao Piao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiawei Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+X">Xinglin Lv</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Miaomiao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yanqing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09967" title="Abstract">arXiv:2309.09967</a> (replaced) [<a href="/pdf/2309.09967" title="Download PDF">pdf</a>, <a href="/format/2309.09967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to Make Knockout Tournaments More Popular?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhary%2C+J">Juhi Chaudhary</a>, 
<a href="/search/cs?searchtype=author&query=Molter%2C+H">Hendrik Molter</a>, 
<a href="/search/cs?searchtype=author&query=Zehavi%2C+M">Meirav Zehavi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10016" title="Abstract">arXiv:2309.10016</a> (replaced) [<a href="/pdf/2309.10016" title="Download PDF">pdf</a>, <a href="/ps/2309.10016" title="Download PostScript">ps</a>, <a href="/format/2309.10016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluation of GPT-3 for Anti-Cancer Drug Sensitivity Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+S">Shaika Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Rajaganapathy%2C+S">Sivaraman Rajaganapathy</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cerhan%2C+J">James Cerhan</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+N">Nansu Zong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMIA Informatics Summit 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10140" title="Abstract">arXiv:2309.10140</a> (replaced) [<a href="/pdf/2309.10140" title="Download PDF">pdf</a>, <a href="/format/2309.10140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Framework for Neural Feature Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangxiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Lizhong Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 76 pages, 24 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10311" title="Abstract">arXiv:2309.10311</a> (replaced) [<a href="/pdf/2309.10311" title="Download PDF">pdf</a>, <a href="/format/2309.10311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource-Efficient Cooperative Online Scalar Field Mapping via  Distributed Sparse Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+T">Tianyi Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Ronghao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Senlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14347" title="Abstract">arXiv:2309.14347</a> (replaced) [<a href="/pdf/2309.14347" title="Download PDF">pdf</a>, <a href="/format/2309.14347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuous-time control synthesis under nested signal temporal logic  specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+P">Pian Yu</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+X">Xiao Tan</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Link to accompanying code: <a href="https://github.com/xiaotan-git/sTLT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16606" title="Abstract">arXiv:2309.16606</a> (replaced) [<a href="/pdf/2309.16606" title="Download PDF">pdf</a>, <a href="/format/2309.16606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;AI enhances our performance, I have no doubt this one will do the  same&quot;: The Placebo effect is robust to negative descriptions of AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kloft%2C+A+M">Agnes M. Kloft</a>, 
<a href="/search/cs?searchtype=author&query=Welsch%2C+R">Robin Welsch</a>, 
<a href="/search/cs?searchtype=author&query=Kosch%2C+T">Thomas Kosch</a>, 
<a href="/search/cs?searchtype=author&query=Villa%2C+S">Steeven Villa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17105" title="Abstract">arXiv:2309.17105</a> (replaced) [<a href="/pdf/2309.17105" title="Download PDF">pdf</a>, <a href="/format/2309.17105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Action Assessment via Task-Consistent Score-Discriminative  Feature Distribution Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Ling-An Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+J">Jing-Ke Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wei-Shi Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17189" title="Abstract">arXiv:2309.17189</a> (replaced) [<a href="/pdf/2309.17189" title="Download PDF">pdf</a>, <a href="/format/2309.17189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTFS-Net: Recurrent time-frequency modelling for efficient audio-visual  speech separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pegg%2C+S">Samuel Pegg</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaolin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.17226" title="Abstract">arXiv:2309.17226</a> (replaced) [<a href="/pdf/2309.17226" title="Download PDF">pdf</a>, <a href="/format/2309.17226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Optimization Based Time-Varying Control Barrier Functions  for Dynamic Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bolun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Khorrambakht%2C+R">Rooholla Khorrambakht</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+P">Prashanth Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Khorrami%2C+F">Farshad Khorrami</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00367" title="Abstract">arXiv:2310.00367</a> (replaced) [<a href="/pdf/2310.00367" title="Download PDF">pdf</a>, <a href="/format/2310.00367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with  TikZ
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Belouadi%2C+J">Jonas Belouadi</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>, 
<a href="/search/cs?searchtype=author&query=Eger%2C+S">Steffen Eger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICLR 2024 (poster); Project Page: <a href="https://github.com/potamides/AutomaTikZ">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00737" title="Abstract">arXiv:2310.00737</a> (replaced) [<a href="/pdf/2310.00737" title="Download PDF">pdf</a>, <a href="/format/2310.00737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenAI Against Humanity: Nefarious Applications of Generative Artificial  Intelligence and Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+E">Emilio Ferrara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in: Journal of Computational Social Science
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03025" title="Abstract">arXiv:2310.03025</a> (replaced) [<a href="/pdf/2310.03025" title="Download PDF">pdf</a>, <a href="/format/2310.03025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval meets Long Context Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xianchao Wu</a>, 
<a href="/search/cs?searchtype=author&query=McAfee%2C+L">Lawrence McAfee</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+S">Sandeep Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Bakhturina%2C+E">Evelina Bakhturina</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.03510" title="Abstract">arXiv:2310.03510</a> (replaced) [<a href="/pdf/2310.03510" title="Download PDF">pdf</a>, <a href="/format/2310.03510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervising Smart Home Device Interactions: A Profile-Based Firewall  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Keersmaeker%2C+F">Fran&#xe7;ois De Keersmaeker</a>, 
<a href="/search/cs?searchtype=author&query=Sadre%2C+R">Ramin Sadre</a>, 
<a href="/search/cs?searchtype=author&query=Pelsser%2C+C">Cristel Pelsser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages of body text, 16 pages total
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04691" title="Abstract">arXiv:2310.04691</a> (replaced) [<a href="/pdf/2310.04691" title="Download PDF">pdf</a>, <a href="/format/2310.04691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMO: Earth Mover Distance Optimization for Auto-Regressive Language  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Siyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K+Q">Kenny Q. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICLR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05207" title="Abstract">arXiv:2310.05207</a> (replaced) [<a href="/pdf/2310.05207" title="Download PDF">pdf</a>, <a href="/format/2310.05207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Facial Action Unit Detection Through Jointly Learning Facial  Landmark Detection and Domain Separation and Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Ziqiao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Li Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, published to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06166" title="Abstract">arXiv:2310.06166</a> (replaced) [<a href="/pdf/2310.06166" title="Download PDF">pdf</a>, <a href="/format/2310.06166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Threshold Policies with Tight Guarantees for Online Selection with  Convex Costs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xiaoqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Siyuan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Boutaba%2C+R">Raouf Boutaba</a>, 
<a href="/search/cs?searchtype=author&query=Leon-Garcia%2C+A">Alberto Leon-Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.07189" title="Abstract">arXiv:2310.07189</a> (replaced) [<a href="/pdf/2310.07189" title="Download PDF">pdf</a>, <a href="/format/2310.07189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpikePoint: An Efficient Point-based Spiking Neural Network for Event  Cameras Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yulong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haotian Fu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaopeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jie Song</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+B">Bojun Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICLR 2024 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08276" title="Abstract">arXiv:2310.08276</a> (replaced) [<a href="/pdf/2310.08276" title="Download PDF">pdf</a>, <a href="/format/2310.08276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Direction-Oriented Visual-semantic Embedding Model for Remote Sensing  Image-text Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Jiancheng Pan</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+C">Cong Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08535" title="Abstract">arXiv:2310.08535</a> (replaced) [<a href="/pdf/2310.08535" title="Download PDF">pdf</a>, <a href="/format/2310.08535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formally Specifying the High-Level Behavior of LLM-Based Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Crouse%2C+M">Maxwell Crouse</a>, 
<a href="/search/cs?searchtype=author&query=Abdelaziz%2C+I">Ibrahim Abdelaziz</a>, 
<a href="/search/cs?searchtype=author&query=Astudillo%2C+R">Ramon Astudillo</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+K">Kinjal Basu</a>, 
<a href="/search/cs?searchtype=author&query=Dan%2C+S">Soham Dan</a>, 
<a href="/search/cs?searchtype=author&query=Kumaravel%2C+S">Sadhana Kumaravel</a>, 
<a href="/search/cs?searchtype=author&query=Fokoue%2C+A">Achille Fokoue</a>, 
<a href="/search/cs?searchtype=author&query=Kapanipathi%2C+P">Pavan Kapanipathi</a>, 
<a href="/search/cs?searchtype=author&query=Roukos%2C+S">Salim Roukos</a>, 
<a href="/search/cs?searchtype=author&query=Lastras%2C+L">Luis Lastras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.08981" title="Abstract">arXiv:2310.08981</a> (replaced) [<a href="/pdf/2310.08981" title="Download PDF">pdf</a>, <a href="/format/2310.08981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-latency Speech Enhancement via Speech Token Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Huaying Xue</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiulian Peng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, ICASSP2024(accepted)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10316" title="Abstract">arXiv:2310.10316</a> (replaced) [<a href="/pdf/2310.10316" title="Download PDF">pdf</a>, <a href="/ps/2310.10316" title="Download PostScript">ps</a>, <a href="/format/2310.10316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral representation of two-sided signals from $\ell_\infty$ and  applications to signal processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dokuchaev%2C+N">Nikolai Dokuchaev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Functional Analysis (math.FA)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11047" title="Abstract">arXiv:2310.11047</a> (replaced) [<a href="/e-print/2310.11047" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Gamified Auditory-Verbal Training for Hearing-Challenged  Children at Intermediate and Advanced Rehabilitation Stages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yan Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+D">Danni Chang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+L">Lei Tu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The analysis section requires refinement
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13498" title="Abstract">arXiv:2310.13498</a> (replaced) [<a href="/pdf/2310.13498" title="Download PDF">pdf</a>, <a href="/format/2310.13498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Checking History-Determinism is NP-hard for Parity Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prakash%2C+A">Aditya Prakash</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of the paper accepted at FoSSaCS 2024. Some minor editorial changes from the previous version following suggestions from anonymous reviewers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13712" title="Abstract">arXiv:2310.13712</a> (replaced) [<a href="/pdf/2310.13712" title="Download PDF">pdf</a>, <a href="/format/2310.13712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Guidance and Interaction Strategies for LLM Use on Learner  Performance and Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H">Harsh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Musabirov%2C+I">Ilya Musabirov</a>, 
<a href="/search/cs?searchtype=author&query=Reza%2C+M">Mohi Reza</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiakai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Williams%2C+J+J">Joseph Jay Williams</a>, 
<a href="/search/cs?searchtype=author&query=Kuzminykh%2C+A">Anastasia Kuzminykh</a>, 
<a href="/search/cs?searchtype=author&query=Liut%2C+M">Michael Liut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.14037" title="Abstract">arXiv:2310.14037</a> (replaced) [<a href="/pdf/2310.14037" title="Download PDF">pdf</a>, <a href="/format/2310.14037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlock Multi-Modal Capability of Dense Retrieval via Visual Module  Plugin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianshuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Sen Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinze Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Chenyan Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yu Gu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+G">Ge Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15318" title="Abstract">arXiv:2310.15318</a> (replaced) [<a href="/pdf/2310.15318" title="Download PDF">pdf</a>, <a href="/format/2310.15318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained  Heterogeneous Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yihong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+N">Ning Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayu Li</a>, 
<a href="/search/cs?searchtype=author&query=Mortazavi%2C+M">Masood Mortazavi</a>, 
<a href="/search/cs?searchtype=author&query=Chawla%2C+N+V">Nitesh V. Chawla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WWW 2024 as research paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.17715" title="Abstract">arXiv:2310.17715</a> (replaced) [<a href="/pdf/2310.17715" title="Download PDF">pdf</a>, <a href="/format/2310.17715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Outlier Dimensions Encode Task-Specific Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rudman%2C+W">William Rudman</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Catherine Chen</a>, 
<a href="/search/cs?searchtype=author&query=Eickhoff%2C+C">Carsten Eickhoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version for EMNLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18304" title="Abstract">arXiv:2310.18304</a> (replaced) [<a href="/pdf/2310.18304" title="Download PDF">pdf</a>, <a href="/format/2310.18304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Stability Principle for Learning under Non-Stationarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chengpiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaizheng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18382" title="Abstract">arXiv:2310.18382</a> (replaced) [<a href="/pdf/2310.18382" title="Download PDF">pdf</a>, <a href="/format/2310.18382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Generative AI to Generative Internet of Things: Fundamentals,  Framework, and Outlooks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinbo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiangtian Nie</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiawen Kang</a>, 
<a href="/search/cs?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Hongyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guizani%2C+M">Mohsen Guizani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Science and Game Theory (cs.GT); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.19367" title="Abstract">arXiv:2310.19367</a> (replaced) [<a href="/pdf/2310.19367" title="Download PDF">pdf</a>, <a href="/ps/2310.19367" title="Download PostScript">ps</a>, <a href="/format/2310.19367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Pseudo-Linearization-Based Model Predictive Controller Design:  Direct Data-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sekine%2C+M">Mikiya Sekine</a>, 
<a href="/search/eess?searchtype=author&query=Tsuruhara%2C+S">Satoshi Tsuruhara</a>, 
<a href="/search/eess?searchtype=author&query=Ito%2C+K">Kazuhisa Ito</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 16 figures, 4 tables, To be submitted to IEEE Transactions on Control Systems Technology (TCST)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02099" title="Abstract">arXiv:2311.02099</a> (replaced) [<a href="/pdf/2311.02099" title="Download PDF">pdf</a>, <a href="/format/2311.02099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Safe Preference Learning Approach for Personalization with  Applications to Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karagulle%2C+R">Ruya Karagulle</a>, 
<a href="/search/cs?searchtype=author&query=Arechiga%2C+N">Nikos Arechiga</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+A">Andrew Best</a>, 
<a href="/search/cs?searchtype=author&query=DeCastro%2C+J">Jonathan DeCastro</a>, 
<a href="/search/cs?searchtype=author&query=Ozay%2C+N">Necmiye Ozay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 2 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02749" title="Abstract">arXiv:2311.02749</a> (replaced) [<a href="/pdf/2311.02749" title="Download PDF">pdf</a>, <a href="/format/2311.02749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Point Cloud to Mesh Reconstruction for Deformable Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansour%2C+E+A">Elham Amin Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hehui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Katzschmann%2C+R+K">Robert K. Katzschmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages with appendix,16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03131" title="Abstract">arXiv:2311.03131</a> (replaced) [<a href="/pdf/2311.03131" title="Download PDF">pdf</a>, <a href="/format/2311.03131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reservoir-Computing Model for Mapping and Forecasting Neuronal  Interactions from Electrophysiological Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Auslender%2C+I">Ilya Auslender</a>, 
<a href="/search/q-bio?searchtype=author&query=Letti%2C+G">Giorgio Letti</a>, 
<a href="/search/q-bio?searchtype=author&query=Heydari%2C+Y">Yasaman Heydari</a>, 
<a href="/search/q-bio?searchtype=author&query=Zaccaria%2C+C">Clara Zaccaria</a>, 
<a href="/search/q-bio?searchtype=author&query=Pavesi%2C+L">Lorenzo Pavesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Pre-submission draft
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Biological Physics (physics.bio-ph)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03206" title="Abstract">arXiv:2311.03206</a> (replaced) [<a href="/pdf/2311.03206" title="Download PDF">pdf</a>, <a href="/format/2311.03206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 5G-CT: Automated Deployment and Over-the-Air Testing of End-to-End Open  Radio Access Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bonati%2C+L">Leonardo Bonati</a>, 
<a href="/search/cs?searchtype=author&query=Polese%2C+M">Michele Polese</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=del+Prever%2C+P+B">Pietro Brach del Prever</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 listing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.05830" title="Abstract">arXiv:2311.05830</a> (replaced) [<a href="/pdf/2311.05830" title="Download PDF">pdf</a>, <a href="/ps/2311.05830" title="Download PostScript">ps</a>, <a href="/format/2311.05830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Sobol&#x27; sequence is not quasi-uniform in dimension 2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Goda%2C+T">Takashi Goda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10309" title="Abstract">arXiv:2311.10309</a> (replaced) [<a href="/pdf/2311.10309" title="Download PDF">pdf</a>, <a href="/format/2311.10309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imagination-Augmented Hierarchical Reinforcement Learning for Safe and  Interactive Autonomous Driving in Urban Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sang-Hyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+Y">Yoonjae Jung</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+S">Seung-Woo Seo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures; corrected typos, added references, revised experiments (results unchanged)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.10956" title="Abstract">arXiv:2311.10956</a> (replaced) [<a href="/pdf/2311.10956" title="Download PDF">pdf</a>, <a href="/ps/2311.10956" title="Download PostScript">ps</a>, <a href="/format/2311.10956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the degree of polynomials computing square roots mod p
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kedlaya%2C+K">Kiran Kedlaya</a>, 
<a href="/search/math?searchtype=author&query=Kopparty%2C+S">Swastik Kopparty</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages. Changes to previous version: We learnt that our upper bound for special $p$, Theorem 1.3, had been proved by Agou, Deligl\'ese and Nicolas in 2003. Added some relevant references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.12373" title="Abstract">arXiv:2311.12373</a> (replaced) [<a href="/pdf/2311.12373" title="Download PDF">pdf</a>, <a href="/format/2311.12373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Turing: A Comparative Analysis of Approaches for Detecting  Machine-Generated Text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adilazuarda%2C+M+F">Muhammad Farid Adilazuarda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13590" title="Abstract">arXiv:2311.13590</a> (replaced) [<a href="/pdf/2311.13590" title="Download PDF">pdf</a>, <a href="/format/2311.13590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Triangle-free $2$-matchings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paluch%2C+K">Katarzyna Paluch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed the definitions of a vulnerable triangle and an intractable hinge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13884" title="Abstract">arXiv:2311.13884</a> (replaced) [<a href="/pdf/2311.13884" title="Download PDF">pdf</a>, <a href="/format/2311.13884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlling Large Language Model-based Agents for Large-Scale  Decision-Making: An Actor-Critic Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+H">Hangyu Mao</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+J">Jingqing Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Ying Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Guoliang Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.14600" title="Abstract">arXiv:2311.14600</a> (replaced) [<a href="/pdf/2311.14600" title="Download PDF">pdf</a>, <a href="/format/2311.14600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Peer-to-Peer Data Distribution Layer for Efficient and  Collaborative Resource Optimization of Distributed Dataflow Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scheinert%2C+D">Dominik Scheinert</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">Soeren Becker</a>, 
<a href="/search/cs?searchtype=author&query=Will%2C+J">Jonathan Will</a>, 
<a href="/search/cs?searchtype=author&query=Englaender%2C+L">Luis Englaender</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 2 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE BigData (2023) 2339-2345
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15939" title="Abstract">arXiv:2311.15939</a> (replaced) [<a href="/pdf/2311.15939" title="Download PDF">pdf</a>, <a href="/format/2311.15939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Power of Prompt-driven Nucleus Instance Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shui%2C+Z">Zhongyi Shui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunlong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kai Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenglu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Sunyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Honglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruizhe Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16536" title="Abstract">arXiv:2311.16536</a> (replaced) [<a href="/pdf/2311.16536" title="Download PDF">pdf</a>, <a href="/format/2311.16536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalized Predictions of Glioblastoma Infiltration: Mathematical  Models, Physics-Informed Neural Networks and Multimodal Scans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R+Z">Ray Zirui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ezhov%2C+I">Ivan Ezhov</a>, 
<a href="/search/cs?searchtype=author&query=Balcerak%2C+M">Michal Balcerak</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+A">Andy Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>, 
<a href="/search/cs?searchtype=author&query=Menze%2C+B">Bjoern Menze</a>, 
<a href="/search/cs?searchtype=author&query=Lowengrub%2C+J">John Lowengrub</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Image and Video Processing (eess.IV); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16716" title="Abstract">arXiv:2311.16716</a> (replaced) [<a href="/pdf/2311.16716" title="Download PDF">pdf</a>, <a href="/format/2311.16716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphPro: Graph Pre-training and Prompt Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Da Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kangyi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WWW'2024, full paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.01185" title="Abstract">arXiv:2312.01185</a> (replaced) [<a href="/pdf/2312.01185" title="Download PDF">pdf</a>, <a href="/format/2312.01185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A ripple in time: a discontinuity in American history
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kolpakov%2C+A">Alexander Kolpakov</a>, 
<a href="/search/cs?searchtype=author&query=Rivin%2C+I">Igor Rivin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures; GitHub repository <a href="https://github.com/sashakolpakov/ripple_in_time">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02218" title="Abstract">arXiv:2312.02218</a> (replaced) [<a href="/pdf/2312.02218" title="Download PDF">pdf</a>, <a href="/format/2312.02218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WavePlanes: A compact Wavelet representation for Dynamic Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzarelli%2C+A">Adrian Azzarelli</a>, 
<a href="/search/cs?searchtype=author&query=Anantrasirichai%2C+N">Nantheera Anantrasirichai</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+D+R">David R Bull</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02246" title="Abstract">arXiv:2312.02246</a> (replaced) [<a href="/pdf/2312.02246" title="Download PDF">pdf</a>, <a href="/format/2312.02246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conditional Variational Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=della+Maggiora%2C+G">Gabriel della Maggiora</a>, 
<a href="/search/cs?searchtype=author&query=Croquevielle%2C+L+A">Luis Alberto Croquevielle</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+N">Nikita Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Horsley%2C+H">Harry Horsley</a>, 
<a href="/search/cs?searchtype=author&query=Heinis%2C+T">Thomas Heinis</a>, 
<a href="/search/cs?searchtype=author&query=Yakimovich%2C+A">Artur Yakimovich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Denoising Diffusion Probabilistic Models, Inverse Problems, Generative Models, Super Resolution, Phase Quantification, Variational Methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03311" title="Abstract">arXiv:2312.03311</a> (replaced) [<a href="/pdf/2312.03311" title="Download PDF">pdf</a>, <a href="/format/2312.03311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Nystrom Approximation for Preconditioning in Kernel Machines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Abedsoltan%2C+A">Amirhesam Abedsoltan</a>, 
<a href="/search/stat?searchtype=author&query=Pandit%2C+P">Parthe Pandit</a>, 
<a href="/search/stat?searchtype=author&query=Rademacher%2C+L">Luis Rademacher</a>, 
<a href="/search/stat?searchtype=author&query=Belkin%2C+M">Mikhail Belkin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03408" title="Abstract">arXiv:2312.03408</a> (replaced) [<a href="/pdf/2312.03408" title="Download PDF">pdf</a>, <a href="/format/2312.03408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-sourced Data Ecosystem in Autonomous Driving: the Present and  Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huilin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Feng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Lu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingdong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Futang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+K">Kai Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tiancai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+B">Beipeng Mu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaoqing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhihui Peng</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is a simplified English translation of corresponding Chinese article. Please refer to Chinese version for the complete content
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06934" title="Abstract">arXiv:2312.06934</a> (replaced) [<a href="/e-print/2312.06934" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Real Text Manipulation Detection: New Dataset and New Solution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+D">Dongliang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianjin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jishen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiang Bai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper needs to be improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07063" title="Abstract">arXiv:2312.07063</a> (replaced) [<a href="/pdf/2312.07063" title="Download PDF">pdf</a>, <a href="/format/2312.07063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Template Free Reconstruction of Human-object Interaction with Procedural  Interaction Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xianghui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Bhatnagar%2C+B+L">Bharat Lal Bhatnagar</a>, 
<a href="/search/cs?searchtype=author&query=Lenssen%2C+J+E">Jan Eric Lenssen</a>, 
<a href="/search/cs?searchtype=author&query=Pons-Moll%2C+G">Gerard Pons-Moll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 18 figures. Project page: <a href="https://virtualhumans.mpi-inf.mpg.de/procigen-hdm">this https URL</a> (updated the acknowledgement)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07294" title="Abstract">arXiv:2312.07294</a> (replaced) [<a href="/e-print/2312.07294" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Commonsense Reasoning Capability of Text-to-Image Generative  Models via Non-visual Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">Mianzhi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Mingyue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zheng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kanzhi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianbing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> It is an incomplete work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07913" title="Abstract">arXiv:2312.07913</a> (replaced) [<a href="/pdf/2312.07913" title="Download PDF">pdf</a>, <a href="/format/2312.07913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Text Watermarking in the Era of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Aiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Leyi Pan</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yijian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xuming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+L">Lijie Wen</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+I">Irwin King</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08673" title="Abstract">arXiv:2312.08673</a> (replaced) [<a href="/pdf/2312.08673" title="Download PDF">pdf</a>, <a href="/format/2312.08673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Beyond View: Handling Partially Missing Modality for  Audio-Visual Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Renjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hsiang-Ting Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09126" title="Abstract">arXiv:2312.09126</a> (replaced) [<a href="/pdf/2312.09126" title="Download PDF">pdf</a>, <a href="/format/2312.09126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Trustworthy AI Software Development Assistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maninger%2C+D">Daniel Maninger</a>, 
<a href="/search/cs?searchtype=author&query=Narasimhan%2C+K">Krishna Narasimhan</a>, 
<a href="/search/cs?searchtype=author&query=Mezini%2C+M">Mira Mezini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 1 figure; to be published in New Ideas and Emerging Results (ICSE-NIER'24), April 14-20, 2024, Lisbon, Portugal; updated version to reflect the information provided by ACM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11486" title="Abstract">arXiv:2312.11486</a> (replaced) [<a href="/pdf/2312.11486" title="Download PDF">pdf</a>, <a href="/format/2312.11486" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preference and Concurrence Aware Bayesian Graph Neural Networks for  Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hongjian Gu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yaochen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yingxue Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12433" title="Abstract">arXiv:2312.12433</a> (replaced) [<a href="/pdf/2312.12433" title="Download PDF">pdf</a>, <a href="/format/2312.12433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Any Object Amodally
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+C">Cheng-Yen Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Khurana%2C+T">Tarasha Khurana</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Achal Dave</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://tao-amodal.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12937" title="Abstract">arXiv:2312.12937</a> (replaced) [<a href="/pdf/2312.12937" title="Download PDF">pdf</a>, <a href="/format/2312.12937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Loss Functions for Training Decision Trees with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilton%2C+J">Jonathan Wilton</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+N">Nan Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI Conference on Artificial Intelligence 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13010" title="Abstract">arXiv:2312.13010</a> (replaced) [<a href="/pdf/2312.13010" title="Download PDF">pdf</a>, <a href="/format/2312.13010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and  Optimisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Dong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+Q">Qingwen Bu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J+M">Jie M.Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luck%2C+M">Michael Luck</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Heming Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14794" title="Abstract">arXiv:2312.14794</a> (replaced) [<a href="/pdf/2312.14794" title="Download PDF">pdf</a>, <a href="/format/2312.14794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Study on Compliance with Ranking Transparency in the  Software Documentation of EU Online Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sovrano%2C+F">Francesco Sovrano</a>, 
<a href="/search/cs?searchtype=author&query=Lognoul%2C+M">Micha&#xeb;l Lognoul</a>, 
<a href="/search/cs?searchtype=author&query=Bacchelli%2C+A">Alberto Bacchelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the 46th International Conference on Software Engineering (ICSE 2024), Software Engineering in Society (SEIS) track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15282" title="Abstract">arXiv:2312.15282</a> (replaced) [<a href="/pdf/2312.15282" title="Download PDF">pdf</a>, <a href="/format/2312.15282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Forecasting for Pricing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Schultz%2C+D">Douglas Schultz</a>, 
<a href="/search/stat?searchtype=author&query=Stephan%2C+J">Johannes Stephan</a>, 
<a href="/search/stat?searchtype=author&query=Sieber%2C+J">Julian Sieber</a>, 
<a href="/search/stat?searchtype=author&query=Yeh%2C+T">Trudie Yeh</a>, 
<a href="/search/stat?searchtype=author&query=Kunz%2C+M">Manuel Kunz</a>, 
<a href="/search/stat?searchtype=author&query=Doupe%2C+P">Patrick Doupe</a>, 
<a href="/search/stat?searchtype=author&query=Januschowski%2C+T">Tim Januschowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15975" title="Abstract">arXiv:2312.15975</a> (replaced) [<a href="/pdf/2312.15975" title="Download PDF">pdf</a>, <a href="/format/2312.15975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Filtered data based estimators for stochastic processes driven by  colored noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pavliotis%2C+G+A">Grigorios A. Pavliotis</a>, 
<a href="/search/math?searchtype=author&query=Reich%2C+S">Sebastian Reich</a>, 
<a href="/search/math?searchtype=author&query=Zanoni%2C+A">Andrea Zanoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16613" title="Abstract">arXiv:2312.16613</a> (replaced) [<a href="/pdf/2312.16613" title="Download PDF">pdf</a>, <a href="/format/2312.16613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Pretraining for Robust Personalized Voice Activity  Detection in Adverse Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bovbjerg%2C+H+S">Holger Severin Bovbjerg</a> (1), 
<a href="/search/cs?searchtype=author&query=Jensen%2C+J">Jesper Jensen</a> (1, 2), 
<a href="/search/cs?searchtype=author&query=%C3%98stergaard%2C+J">Jan &#xd8;stergaard</a> (1), 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zheng-Hua Tan</a> (1, 3) ((1) Aalborg University, (2) Oticon, (3) Pioneer Centre for AI, Denmark)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published at ICASSP2024, 14th of April 2024, Seoul, South Korea. Copyright (c) 2023 IEEE. 5 pages, 2, figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.00334" title="Abstract">arXiv:2401.00334</a> (replaced) [<a href="/pdf/2401.00334" title="Download PDF">pdf</a>, <a href="/format/2401.00334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainability-Driven Leaf Disease Classification Using Adversarial  Training and Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echim%2C+S">Sebastian-Vasile Echim</a>, 
<a href="/search/cs?searchtype=author&query=T%C4%83iatu%2C+I">Iulian-Marius T&#x103;iatu</a>, 
<a href="/search/cs?searchtype=author&query=Cercel%2C+D">Dumitru-Clementin Cercel</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+F">Florin Pop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures, Accepted by ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01520" title="Abstract">arXiv:2401.01520</a> (replaced) [<a href="/pdf/2401.01520" title="Download PDF">pdf</a>, <a href="/format/2401.01520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^{2}$-DMs:Skip-Step Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yixuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuangyin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01651" title="Abstract">arXiv:2401.01651</a> (replaced) [<a href="/pdf/2401.01651" title="Download PDF">pdf</a>, <a href="/format/2401.01651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AIGCBench: Comprehensive Evaluation of Image-to-Video Content Generated  by AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+F">Fanda Fan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunjie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wanling Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianfeng Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BenchCouncil Transactions on Benchmarks, Standards and Evaluations (TBench)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02994" title="Abstract">arXiv:2401.02994</a> (replaced) [<a href="/pdf/2401.02994" title="Download PDF">pdf</a>, <a href="/format/2401.02994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blending Is All You Need: Cheaper, Better Alternative to  Trillion-Parameters LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaoding Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zongyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liusie%2C+A">Adian Liusie</a>, 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vyas Raina</a>, 
<a href="/search/cs?searchtype=author&query=Mudupalli%2C+V">Vineet Mudupalli</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Beauchamp%2C+W">William Beauchamp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03179" title="Abstract">arXiv:2401.03179</a> (replaced) [<a href="/pdf/2401.03179" title="Download PDF">pdf</a>, <a href="/format/2401.03179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Informative ViT: Information Aggregation and Distribution for  Hyperspectral and LiDAR Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jie Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weiying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Geng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daixun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yunsong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04079" title="Abstract">arXiv:2401.04079</a> (replaced) [<a href="/pdf/2401.04079" title="Download PDF">pdf</a>, <a href="/format/2401.04079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RudolfV: A Foundation Model by Pathologists for Pathologists
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dippel%2C+J">Jonas Dippel</a>, 
<a href="/search/eess?searchtype=author&query=Feulner%2C+B">Barbara Feulner</a>, 
<a href="/search/eess?searchtype=author&query=Winterhoff%2C+T">Tobias Winterhoff</a>, 
<a href="/search/eess?searchtype=author&query=Schallenberg%2C+S">Simon Schallenberg</a>, 
<a href="/search/eess?searchtype=author&query=Dernbach%2C+G">Gabriel Dernbach</a>, 
<a href="/search/eess?searchtype=author&query=Kunft%2C+A">Andreas Kunft</a>, 
<a href="/search/eess?searchtype=author&query=Tietz%2C+S">Stephan Tietz</a>, 
<a href="/search/eess?searchtype=author&query=Jurmeister%2C+P">Philipp Jurmeister</a>, 
<a href="/search/eess?searchtype=author&query=Horst%2C+D">David Horst</a>, 
<a href="/search/eess?searchtype=author&query=Ruff%2C+L">Lukas Ruff</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Klauschen%2C+F">Frederick Klauschen</a>, 
<a href="/search/eess?searchtype=author&query=Alber%2C+M">Maximilian Alber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04494" title="Abstract">arXiv:2401.04494</a> (replaced) [<a href="/pdf/2401.04494" title="Download PDF">pdf</a>, <a href="/format/2401.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Asynchronous Work-Stealing for distributed load-balancing in  heterogeneous systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandes%2C+J+B">Jo&#xe3;o B. Fernandes</a>, 
<a href="/search/cs?searchtype=author&query=de+Assis%2C+%C3%8D+A+S">&#xcd;talo A. S. de Assis</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+I+M+S">Idalmis M. S. Martins</a>, 
<a href="/search/cs?searchtype=author&query=Barros%2C+T">Tiago Barros</a>, 
<a href="/search/cs?searchtype=author&query=Xavier-de-Souza%2C+S">Samuel Xavier-de-Souza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04867" title="Abstract">arXiv:2401.04867</a> (replaced) [<a href="/pdf/2401.04867" title="Download PDF">pdf</a>, <a href="/format/2401.04867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Koji Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Lala%2C+D">Divesh Lala</a>, 
<a href="/search/cs?searchtype=author&query=Ochi%2C+K">Keiko Ochi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>, 
<a href="/search/cs?searchtype=author&query=Skantze%2C+G">Gabriel Skantze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2024 (IWSDS 2024) and represents the author's version of the work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06827" title="Abstract">arXiv:2401.06827</a> (replaced) [<a href="/pdf/2401.06827" title="Download PDF">pdf</a>, <a href="/format/2401.06827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+G">Guiming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kaize Shi</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hong Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huaiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07440" title="Abstract">arXiv:2401.07440</a> (replaced) [<a href="/pdf/2401.07440" title="Download PDF">pdf</a>, <a href="/format/2401.07440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Fairness of Redistricting Ghost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jia-Wei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Amenta%2C+N">Nina Amenta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.07709" title="Abstract">arXiv:2401.07709</a> (replaced) [<a href="/pdf/2401.07709" title="Download PDF">pdf</a>, <a href="/format/2401.07709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Efficient Diffusion-Based Image Editing with Instant Attention  Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Siyu Zou</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiji Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yiyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jing He</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chaoyi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rongsheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhipeng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiaoshuai Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08119" title="Abstract">arXiv:2401.08119</a> (replaced) [<a href="/pdf/2401.08119" title="Download PDF">pdf</a>, <a href="/format/2401.08119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SpecSTG: A Fast Spectral Diffusion Framework for Probabilistic  Spatio-Temporal Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lequan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Andi Han</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08517" title="Abstract">arXiv:2401.08517</a> (replaced) [<a href="/pdf/2401.08517" title="Download PDF">pdf</a>, <a href="/format/2401.08517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supporting Student Decisions on Learning Recommendations: An LLM-Based  Chatbot with Knowledge Graph Contextualization for Conversational  Explainability and Mentoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abu-Rasheed%2C+H">Hasan Abu-Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Abdulsalam%2C+M+H">Mohamad Hussam Abdulsalam</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Christian Weber</a>, 
<a href="/search/cs?searchtype=author&query=Fathi%2C+M">Madjid Fathi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.08919" title="Abstract">arXiv:2401.08919</a> (replaced) [<a href="/pdf/2401.08919" title="Download PDF">pdf</a>, <a href="/format/2401.08919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Diacritization: A Context-Contrastive Inference Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=ElNokrashy%2C+M">Muhammad ElNokrashy</a>, 
<a href="/search/cs?searchtype=author&query=AlKhamissi%2C+B">Badr AlKhamissi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 equations, 5 tables, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09479" title="Abstract">arXiv:2401.09479</a> (replaced) [<a href="/pdf/2401.09479" title="Download PDF">pdf</a>, <a href="/format/2401.09479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vishwakarma%2C+R">Rahul Vishwakarma</a>, 
<a href="/search/cs?searchtype=author&query=Rezaei%2C+A">Amin Rezaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2024 Design, Automation and Test in Europe Conference | The European Event for Electronic System Design &amp; Test (accepted)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2024 Design, Automation and Test in Europe Conference | The
  European Event for Electronic System Design &amp; Test
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09495" title="Abstract">arXiv:2401.09495</a> (replaced) [<a href="/e-print/2401.09495" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IPR-NeRF: Ownership Verification meets Neural Radiance Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ong%2C+W+K">Win Kent Ong</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+W">Kam Woh Ng</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+C+S">Chee Seng Chan</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y+Z">Yi Zhe Song</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Error on result tabulation of state of the art method which might cause misleading to readers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09838" title="Abstract">arXiv:2401.09838</a> (replaced) [<a href="/pdf/2401.09838" title="Download PDF">pdf</a>, <a href="/format/2401.09838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATMA: Conformance Analysis Tool For Microservice Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+C">Clinton Cao</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+S">Simon Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Ferreyra%2C+N+E+D">Nicol&#xe1;s E. D&#xed;az Ferreyra</a>, 
<a href="/search/cs?searchtype=author&query=Verwer%2C+S">Sicco Verwer</a>, 
<a href="/search/cs?searchtype=author&query=Panichella%2C+A">Annibale Panichella</a>, 
<a href="/search/cs?searchtype=author&query=Scandariato%2C+R">Riccardo Scandariato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 5 figures, ICSE '24 Demonstration Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.09943" title="Abstract">arXiv:2401.09943</a> (replaced) [<a href="/pdf/2401.09943" title="Download PDF">pdf</a>, <a href="/format/2401.09943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance  Sparse Information Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruizhe Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xinke Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuchen Fang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jiayuan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yongxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yichen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+X">Xu Chu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junfeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yasha Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v1
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10134" title="Abstract">arXiv:2401.10134</a> (replaced) [<a href="/pdf/2401.10134" title="Download PDF">pdf</a>, <a href="/format/2401.10134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Large Language Model for Traffic Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenxi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qianxiong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhishuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Cheng Long</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revise
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10225" title="Abstract">arXiv:2401.10225</a> (replaced) [<a href="/pdf/2401.10225" title="Download PDF">pdf</a>, <a href="/format/2401.10225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatQA: Building GPT-4 Level Conversational QA Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ping%2C+W">Wei Ping</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+R">Rajarshi Roy</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+P">Peng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chankyu Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shoeybi%2C+M">Mohammad Shoeybi</a>, 
<a href="/search/cs?searchtype=author&query=Catanzaro%2C+B">Bryan Catanzaro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We added ChatQA-22B results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10302" title="Abstract">arXiv:2401.10302</a> (replaced) [<a href="/pdf/2401.10302" title="Download PDF">pdf</a>, <a href="/format/2401.10302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Quantum Solvers in Production: how to succeed in the NISQ era?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Osaba%2C+E">Eneko Osaba</a>, 
<a href="/search/cs?searchtype=author&query=Villar-Rodriguez%2C+E">Esther Villar-Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Gomez-Tejedor%2C+A">Aitor Gomez-Tejedor</a>, 
<a href="/search/cs?searchtype=author&query=Oregi%2C+I">Izaskun Oregi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10390" title="Abstract">arXiv:2401.10390</a> (replaced) [<a href="/pdf/2401.10390" title="Download PDF">pdf</a>, <a href="/ps/2401.10390" title="Download PostScript">ps</a>, <a href="/format/2401.10390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Interplay Between Network Metrics and Performance of Mobile Edge  Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moshiri%2C+P+F">Parisa Fard Moshiri</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+M">Murat Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Kantarci%2C+B">Burak Kantarci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, IEEE International Conference on Communications (ICC) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10543" title="Abstract">arXiv:2401.10543</a> (replaced) [<a href="/pdf/2401.10543" title="Download PDF">pdf</a>, <a href="/format/2401.10543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual acoustic word embeddings for zero-resource languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jacobs%2C+C">Christiaan Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10754" title="Abstract">arXiv:2401.10754</a> (replaced) [<a href="/pdf/2401.10754" title="Download PDF">pdf</a>, <a href="/format/2401.10754" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation for Traffic Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Finamore%2C+A">Alessandro Finamore</a>, 
<a href="/search/cs?searchtype=author&query=Michiardi%2C+P">Pietro Michiardi</a>, 
<a href="/search/cs?searchtype=author&query=Gallo%2C+M">Massimo Gallo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+D">Dario Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at Passive and Active Measurements (PAM), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10787" title="Abstract">arXiv:2401.10787</a> (replaced) [<a href="/pdf/2401.10787" title="Download PDF">pdf</a>, <a href="/ps/2401.10787" title="Download PostScript">ps</a>, <a href="/format/2401.10787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Online Certificate Status Protocol with Certificate Revocation  List for Smart Grid Public Key Infrastructure
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hong-Sheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhe-Yi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hsuan-Tung Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hung-Min Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.10852" title="Abstract">arXiv:2401.10852</a> (replaced) [<a href="/pdf/2401.10852" title="Download PDF">pdf</a>, <a href="/format/2401.10852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Resource Disaggregation for HPC with Serverless Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Copik%2C+M">Marcin Copik</a>, 
<a href="/search/cs?searchtype=author&query=Chrapek%2C+M">Marcin Chrapek</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+L">Larissa Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Calotoiu%2C+A">Alexandru Calotoiu</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11022" title="Abstract">arXiv:2401.11022</a> (replaced) [<a href="/pdf/2401.11022" title="Download PDF">pdf</a>, <a href="/format/2401.11022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formulating or Fixating: Effects of Examples on Problem Solving Vary as  a Function of Example Presentation Interface Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+J">Joel Chan</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zijian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Kamrah%2C+E">Eesh Kamrah</a>, 
<a href="/search/cs?searchtype=author&query=Fuge%2C+M">Mark Fuge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11033" title="Abstract">arXiv:2401.11033</a> (replaced) [<a href="/pdf/2401.11033" title="Download PDF">pdf</a>, <a href="/format/2401.11033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for  Large Language Models&#x27; Training?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raza%2C+S">Shaina Raza</a>, 
<a href="/search/cs?searchtype=author&query=Ghuge%2C+S">Shardul Ghuge</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Chen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Pandya%2C+D">Deval Pandya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11053" title="Abstract">arXiv:2401.11053</a> (replaced) [<a href="/pdf/2401.11053" title="Download PDF">pdf</a>, <a href="/format/2401.11053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamVoice: Streamable Context-Aware Language Modeling for Real-time  Zero-Shot Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhichao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yuanzhe Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinsheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuping Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11114" title="Abstract">arXiv:2401.11114</a> (replaced) [<a href="/pdf/2401.11114" title="Download PDF">pdf</a>, <a href="/format/2401.11114" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for  Resource-Limited Countries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuo%2C+K">Kuan-Ting Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Moukheiber%2C+D">Dana Moukheiber</a>, 
<a href="/search/cs?searchtype=author&query=Ordonez%2C+S+C">Sebastian Cajas Ordonez</a>, 
<a href="/search/cs?searchtype=author&query=Restrepo%2C+D">David Restrepo</a>, 
<a href="/search/cs?searchtype=author&query=Paddo%2C+A+R">Atika Rahman Paddo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tsung-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Moukheiber%2C+L">Lama Moukheiber</a>, 
<a href="/search/cs?searchtype=author&query=Moukheiber%2C+M">Mira Moukheiber</a>, 
<a href="/search/cs?searchtype=author&query=Moukheiber%2C+S">Sulaiman Moukheiber</a>, 
<a href="/search/cs?searchtype=author&query=Purkayastha%2C+S">Saptarshi Purkayastha</a>, 
<a href="/search/cs?searchtype=author&query=Kuo%2C+P">Po-Chih Kuo</a>, 
<a href="/search/cs?searchtype=author&query=Celi%2C+L+A">Leo Anthony Celi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the IJCAI 2023 Workshop on Bridge-AI: from Climate Change to Health Equity (BridgeAICCHE)., Macao, S.A.R
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11115" title="Abstract">arXiv:2401.11115</a> (replaced) [<a href="/pdf/2401.11115" title="Download PDF">pdf</a>, <a href="/format/2401.11115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MotionMix: Weakly-Supervised Diffusion for Controllable Motion  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+N+M">Nhat M. Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+K">Kehong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Chuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Mi%2C+M+B">Michael Bi Mi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 38th Association for the Advancement of Artificial Intelligence (AAAI) Conference on Artificial Intelligence, Main Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11127" title="Abstract">arXiv:2401.11127</a> (replaced) [<a href="/pdf/2401.11127" title="Download PDF">pdf</a>, <a href="/format/2401.11127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Bit Complexity of Dynamic Algebraic Formulas and their Determinants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anand%2C+E">Emile Anand</a>, 
<a href="/search/cs?searchtype=author&query=van+den+Brand%2C+J">Jan van den Brand</a>, 
<a href="/search/cs?searchtype=author&query=Ghadiri%2C+M">Mehrdad Ghadiri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Daniel Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, 1 Figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11160" title="Abstract">arXiv:2401.11160</a> (replaced) [<a href="/pdf/2401.11160" title="Download PDF">pdf</a>, <a href="/ps/2401.11160" title="Download PostScript">ps</a>, <a href="/format/2401.11160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Perfect and Distance-Optimal Sum-Rank Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11161" title="Abstract">arXiv:2401.11161</a> (replaced) [<a href="/pdf/2401.11161" title="Download PDF">pdf</a>, <a href="/format/2401.11161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BinaryAI: Binary Software Composition Analysis via Intelligent Binary  Source Code Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Ling Jiang</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+J">Junwen An</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Huihui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Q">Qiyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+S">Sen Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the 46th International Conference on Software Engineering (ICSE'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11202" title="Abstract">arXiv:2401.11202</a> (replaced) [<a href="/pdf/2401.11202" title="Download PDF">pdf</a>, <a href="/format/2401.11202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PartIR: Composing SPMD Partitioning Strategies for Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alabed%2C+S">Sami Alabed</a>, 
<a href="/search/cs?searchtype=author&query=Chrzaszcz%2C+B">Bart Chrzaszcz</a>, 
<a href="/search/cs?searchtype=author&query=Franco%2C+J">Juliana Franco</a>, 
<a href="/search/cs?searchtype=author&query=Grewe%2C+D">Dominik Grewe</a>, 
<a href="/search/cs?searchtype=author&query=Maclaurin%2C+D">Dougal Maclaurin</a>, 
<a href="/search/cs?searchtype=author&query=Molloy%2C+J">James Molloy</a>, 
<a href="/search/cs?searchtype=author&query=Natan%2C+T">Tom Natan</a>, 
<a href="/search/cs?searchtype=author&query=Norman%2C+T">Tamara Norman</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaoyue Pan</a>, 
<a href="/search/cs?searchtype=author&query=Paszke%2C+A">Adam Paszke</a>, 
<a href="/search/cs?searchtype=author&query=Rink%2C+N+A">Norman A. Rink</a>, 
<a href="/search/cs?searchtype=author&query=Schaarschmidt%2C+M">Michael Schaarschmidt</a>, 
<a href="/search/cs?searchtype=author&query=Sitdikov%2C+T">Timur Sitdikov</a>, 
<a href="/search/cs?searchtype=author&query=Swietlik%2C+A">Agnieszka Swietlik</a>, 
<a href="/search/cs?searchtype=author&query=Vytiniotis%2C+D">Dimitrios Vytiniotis</a>, 
<a href="/search/cs?searchtype=author&query=Wee%2C+J">Joel Wee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11203" title="Abstract">arXiv:2401.11203</a> (replaced) [<a href="/pdf/2401.11203" title="Download PDF">pdf</a>, <a href="/format/2401.11203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Hussieny%2C+H">Haitham El-Hussieny</a>, 
<a href="/search/cs?searchtype=author&query=Hameed%2C+I">Ibrahim Hameed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11447" title="Abstract">arXiv:2401.11447</a> (replaced) [<a href="/pdf/2401.11447" title="Download PDF">pdf</a>, <a href="/format/2401.11447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Model for Predicting Patient Adherence in Subcutaneous  Immunotherapy for Allergic Rhinitis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wenxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Q">Qingqing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Liping Si</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Smagt%2C+P">Patrick van der Smagt</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jun Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nutan Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11478" title="Abstract">arXiv:2401.11478</a> (replaced) [<a href="/pdf/2401.11478" title="Download PDF">pdf</a>, <a href="/format/2401.11478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D2K: Turning Historical Data into Retrievable Knowledge for Recommender  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jiarui Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weiwen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Ruiming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weinan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11488" title="Abstract">arXiv:2401.11488</a> (replaced) [<a href="/pdf/2401.11488" title="Download PDF">pdf</a>, <a href="/format/2401.11488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HARDCORE: H-field and power loss estimation for arbitrary waveforms with  residual, dilated convolutional neural networks in ferrite cores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kirchg%C3%A4ssner%2C+W">Wilhelm Kirchg&#xe4;ssner</a>, 
<a href="/search/eess?searchtype=author&query=F%C3%B6rster%2C+N">Nikolas F&#xf6;rster</a>, 
<a href="/search/eess?searchtype=author&query=Piepenbrock%2C+T">Till Piepenbrock</a>, 
<a href="/search/eess?searchtype=author&query=Schweins%2C+O">Oliver Schweins</a>, 
<a href="/search/eess?searchtype=author&query=Wallscheid%2C+O">Oliver Wallscheid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Competition submission version, slightly change author order
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG); Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11624" title="Abstract">arXiv:2401.11624</a> (replaced) [<a href="/pdf/2401.11624" title="Download PDF">pdf</a>, <a href="/format/2401.11624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-context Learning with Retrieved Demonstrations for Language Models: A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+M">Man Luo</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pasupat%2C+P">Panupong Pasupat</a>, 
<a href="/search/cs?searchtype=author&query=Kazemi%2C+M">Mehran Kazemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11687" title="Abstract">arXiv:2401.11687</a> (replaced) [<a href="/pdf/2401.11687" title="Download PDF">pdf</a>, <a href="/format/2401.11687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIM: An Efficient Temporal Interaction Module for Spiking Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Sicheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Dongcheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+G">Guobin Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Y">Yi Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9pages,6figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11748" title="Abstract">arXiv:2401.11748</a> (replaced) [<a href="/pdf/2401.11748" title="Download PDF">pdf</a>, <a href="/format/2401.11748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient  Inversion Attacks?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=sun%2C+Y">Yu sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Gaojian Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+X">Xianxun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kailang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Jian Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11788" title="Abstract">arXiv:2401.11788</a> (replaced) [<a href="/pdf/2401.11788" title="Download PDF">pdf</a>, <a href="/format/2401.11788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Obtaining the pseudoinverse solution of singular range-symmetric linear  systems with GMRES-type methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Du%2C+K">Kui Du</a>, 
<a href="/search/math?searchtype=author&query=Fan%2C+J">Jia-Jun Fan</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+F">Fang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11792" title="Abstract">arXiv:2401.11792</a> (replaced) [<a href="/pdf/2401.11792" title="Download PDF">pdf</a>, <a href="/format/2401.11792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Generalized end-to-end Autonomous Driving System with  Reinforcement Learning and Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Z">Zuojin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">YongQiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianyu Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11851" title="Abstract">arXiv:2401.11851</a> (replaced) [<a href="/pdf/2401.11851" title="Download PDF">pdf</a>, <a href="/format/2401.11851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yuhao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by 2024 IEEE International Symposium on Circuits and Systems (ISCAS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11901" title="Abstract">arXiv:2401.11901</a> (replaced) [<a href="/pdf/2401.11901" title="Download PDF">pdf</a>, <a href="/format/2401.11901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ORBGRAND: Achievable Rate for General Bit Channels and Application in  BICM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenyi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11923" title="Abstract">arXiv:2401.11923</a> (replaced) [<a href="/pdf/2401.11923" title="Download PDF">pdf</a>, <a href="/format/2401.11923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance  through Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Lin-Ping Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liangwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bingchuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wei Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.11969" title="Abstract">arXiv:2401.11969</a> (replaced) [<a href="/pdf/2401.11969" title="Download PDF">pdf</a>, <a href="/format/2401.11969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Claim Detection for Automated Fact-checking: A Survey on Monolingual,  Multilingual and Cross-Lingual Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panchendrarajan%2C+R">Rrubaa Panchendrarajan</a>, 
<a href="/search/cs?searchtype=author&query=Zubiaga%2C+A">Arkaitz Zubiaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Typo corrected
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12001" title="Abstract">arXiv:2401.12001</a> (replaced) [<a href="/pdf/2401.12001" title="Download PDF">pdf</a>, <a href="/format/2401.12001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Stereo-Confidence Out of the End-to-End Stereo-Matching Network  via Disparity Plane Sweep
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ka%2C+W">Woonghyun Ka</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024. The first two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12019" title="Abstract">arXiv:2401.12019</a> (replaced) [<a href="/pdf/2401.12019" title="Download PDF">pdf</a>, <a href="/format/2401.12019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered  by Multiple Disparity Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ka%2C+W">Woonghyun Ka</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+Y">Jae Young Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jaehyun Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Junmo Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024. The first two authors are equally contributed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12074" title="Abstract">arXiv:2401.12074</a> (replaced) [<a href="/pdf/2401.12074" title="Download PDF">pdf</a>, <a href="/format/2401.12074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepCERES: A Deep learning method for cerebellar lobule segmentation  using ultra-high resolution multimodal MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morell-Ortega%2C+S">Sergio Morell-Ortega</a>, 
<a href="/search/eess?searchtype=author&query=Ruiz-Perez%2C+M">Marina Ruiz-Perez</a>, 
<a href="/search/eess?searchtype=author&query=Gadea%2C+M">Marien Gadea</a>, 
<a href="/search/eess?searchtype=author&query=Vivo-Hernando%2C+R">Roberto Vivo-Hernando</a>, 
<a href="/search/eess?searchtype=author&query=Rubio%2C+G">Gregorio Rubio</a>, 
<a href="/search/eess?searchtype=author&query=Aparici%2C+F">Fernando Aparici</a>, 
<a href="/search/eess?searchtype=author&query=de+la+Iglesia-Vaya%2C+M">Maria de la Iglesia-Vaya</a>, 
<a href="/search/eess?searchtype=author&query=Catheline%2C+G">Gwenaelle Catheline</a>, 
<a href="/search/eess?searchtype=author&query=Coup%C3%A9%2C+P">Pierrick Coup&#xe9;</a>, 
<a href="/search/eess?searchtype=author&query=Manj%C3%B3n%2C+J+V">Jos&#xe9; V. Manj&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.12094" title="Abstract">arXiv:2401.12094</a> (replaced) [<a href="/pdf/2401.12094" title="Download PDF">pdf</a>, <a href="/ps/2401.12094" title="Download PostScript">ps</a>, <a href="/format/2401.12094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIQUE as an AND of Polynomial-Sized Monotone Constant-Depth Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodnar%2C+L">Levente Bodnar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item307">Cross-lists</a></li>
<li><a href="#item348">Replacements</a></li>
</ul>
<small>[ total of 562 entries:  <b>1-562</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
