<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Wed 10 Jan 24  to  Thu 11 Jan 24, announced Fri, 12 Jan 24</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item311">Cross-lists</a></li>
<li><a href="#item385">Replacements</a></li>
</ul>
<small>[ total of 576 entries:  <b>1-576</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Fri, 12 Jan 24</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05338" title="Abstract">arXiv:2401.05338</a> [<a href="/pdf/2401.05338" title="Download PDF">pdf</a>, <a href="/format/2401.05338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STR-Cert: Robustness Certification for Deep Text Recognition on Deep  Learning Pipelines and Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+D">Daqian Shao</a>, 
<a href="/search/cs?searchtype=author&query=Fesser%2C+L">Lukas Fesser</a>, 
<a href="/search/cs?searchtype=author&query=Kwiatkowska%2C+M">Marta Kwiatkowska</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Robustness certification, which aims to formally certify the predictions of
neural networks against adversarial inputs, has become an integral part of
important tool for safety-critical applications. Despite considerable progress,
existing certification methods are limited to elementary architectures, such as
convolutional networks, recurrent networks and recently Transformers, on
benchmark datasets such as MNIST. In this paper, we focus on the robustness
certification of scene text recognition (STR), which is a complex and
extensively deployed image-based sequence prediction problem. We tackle three
types of STR model architectures, including the standard STR pipelines and the
Vision Transformer. We propose STR-Cert, the first certification method for STR
models, by significantly extending the DeepPoly polyhedral verification
framework via deriving novel polyhedral bounds and algorithms for key STR model
components. Finally, we certify and compare STR models on six datasets,
demonstrating the efficiency and scalability of robustness certification,
particularly for the Vision Transformer.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05339" title="Abstract">arXiv:2401.05339</a> [<a href="/pdf/2401.05339" title="Download PDF">pdf</a>, <a href="/format/2401.05339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MicroGlam: Microscopic Skin Image Dataset with Cosmetics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chong%2C+T">Toby Chong</a>, 
<a href="/search/cs?searchtype=author&query=Chadwick%2C+A">Alina Chadwick</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+I">I-chao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Igarashi%2C+T">Takeo Igarashi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://github.com/tobyclh/MicroGlam">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">In this paper, we present a cosmetic-specific skin image dataset. It consists
of skin images from $45$ patches ($5$ skin patches each from $9$ participants)
of size $8mm^*8mm$ under three cosmetic products (i.e., foundation, blusher,
and highlighter). We designed a novel capturing device inspired by Light Stage.
Using the device, we captured over $600$ images of each skin patch under
diverse lighting conditions in $30$ seconds. We repeated the process for the
same skin patch under three cosmetic products. Finally, we demonstrate the
viability of the dataset with an image-to-image translation-based pipeline for
cosmetic rendering and compared our data-driven approach to an existing
cosmetic rendering method.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05345" title="Abstract">arXiv:2401.05345</a> [<a href="/pdf/2401.05345" title="Download PDF">pdf</a>, <a href="/format/2401.05345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISTWAR: Fast Differentiable Rendering on Raster-based Rendering  Pipelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Durvasula%2C+S">Sankeerth Durvasula</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Adrian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Fan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ruofan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Sanjaya%2C+P+K">Pawan Kumar Sanjaya</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+N">Nandita Vijaykumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Performance (cs.PF)

</div>
<p class="mathjax">Differentiable rendering is a technique used in an important emerging class
of visual computing applications that involves representing a 3D scene as a
model that is trained from 2D images using gradient descent. Recent works (e.g.
3D Gaussian Splatting) use a rasterization pipeline to enable rendering high
quality photo-realistic imagery at high speeds from these learned 3D models.
These methods have been demonstrated to be very promising, providing
state-of-art quality for many important tasks. However, training a model to
represent a scene is still a time-consuming task even when using powerful GPUs.
In this work, we observe that the gradient computation phase during training is
a significant bottleneck on GPUs due to the large number of atomic operations
that need to be processed. These atomic operations overwhelm atomic units in
the L2 partitions causing stalls. To address this challenge, we leverage the
observations that during the gradient computation: (1) for most warps, all
threads atomically update the same memory locations; and (2) warps generate
varying amounts of atomic traffic (since some threads may be inactive). We
propose DISTWAR, a software-approach to accelerate atomic operations based on
two key ideas: First, we enable warp-level reduction of threads at the SM
sub-cores using registers to leverage the locality in intra-warp atomic
updates. Second, we distribute the atomic computation between the warp-level
reduction at the SM and the L2 atomic units to increase the throughput of
atomic computation. Warps with many threads performing atomic updates to the
same memory locations are scheduled at the SM, and the rest using L2 atomic
units. We implement DISTWAR using existing warp-level primitives. We evaluate
DISTWAR on widely used raster-based differentiable rendering workloads. We
demonstrate significant speedups of 2.44x on average (up to 5.7x).
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05346" title="Abstract">arXiv:2401.05346</a> [<a href="/pdf/2401.05346" title="Download PDF">pdf</a>, <a href="/ps/2401.05346" title="Download PostScript">ps</a>, <a href="/format/2401.05346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task tree retrieval from FOON using search algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attapu%2C+A">Amitha Attapu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Robots can be very useful to automate tasks and reduce the human effort
required. But for the robot to know, how to perform tasks, we need to give it a
clear set of steps to follow. It is nearly impossible to provide a robot with
instructions for every possible task. Therefore we have a Universal Functional
object-oriented network (FOON) which was created and expanded and has a lot of
existing recipe information [1]. But certain tasks are complicated for robots
to perform and similarly, some tasks are complicated for humans to perform.
Therefore weights have been added to functional units to represent the chance
of successful execution of the motion by the robot [2]. Given a set of kitchen
items and a goal node, using Universal FOON, a robot must be able to determine
if the required items are present in the kitchen, and if yes, get the steps to
convert the required kitchen items to the goal node. Now through this paper, we
use two algorithms (IDS and GBFS) to retrieve a task tree (if possible) for a
goal node and a given set of kitchen items. The following would be the
different parts of the paper: Section II FOON creation, where we will discuss
the different terminologies related to FOON and visualization of FOON. In
Section III Methodology we discuss the IDS and GBFS search algorithms and the
two different heuristics implemented and used in GBFS. In Section IV
Experiment/Discussion, we compare the performance of different algorithms. In
the final section V, we specify the references of the papers that have been
cited.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05350" title="Abstract">arXiv:2401.05350</a> [<a href="/pdf/2401.05350" title="Download PDF">pdf</a>, <a href="/format/2401.05350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive operator selection utilising generalised experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aydin%2C+M+E">Mehmet Emin Aydin</a>, 
<a href="/search/cs?searchtype=author&query=Durgut%2C+R">Rafet Durgut</a>, 
<a href="/search/cs?searchtype=author&query=Rakib%2C+A">Abdur Rakib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to journal for publications, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Optimisation problems, particularly combinatorial optimisation problems, are
difficult to solve due to their complexity and hardness. Such problems have
been successfully solved by evolutionary and swarm intelligence algorithms,
especially in binary format. However, the approximation may suffer due to the
the issues in balance between exploration and exploitation activities (EvE),
which remain as the major challenge in this context. Although the complementary
usage of multiple operators is becoming more popular for managing EvE with
adaptive operator selection schemes, a bespoke adaptive selection system is
still an important topic in research. Reinforcement Learning (RL) has recently
been proposed as a way to customise and shape up a highly effective adaptive
selection system. However, it is still challenging to handle the problem in
terms of scalability. This paper proposes and assesses a RL-based novel
approach to help develop a generalised framework for gaining, processing, and
utilising the experiences for both the immediate and future use. The
experimental results support the proposed approach with a certain level of
success.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05352" title="Abstract">arXiv:2401.05352</a> [<a href="/pdf/2401.05352" title="Download PDF">pdf</a>, <a href="/format/2401.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Categories Discovery for Long-tailed Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Meinel%2C+C">Christoph Meinel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haojin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 out-of-distribution generalization in computer vision workshop paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalized Class Discovery (GCD) plays a pivotal role in discerning both
known and unknown categories from unlabeled datasets by harnessing the insights
derived from a labeled set comprising recognized classes. A significant
limitation in prevailing GCD methods is their presumption of an equitably
distributed category occurrence in unlabeled data. Contrary to this assumption,
visual classes in natural environments typically exhibit a long-tailed
distribution, with known or prevalent categories surfacing more frequently than
their rarer counterparts. Our research endeavors to bridge this disconnect by
focusing on the long-tailed Generalized Category Discovery (Long-tailed GCD)
paradigm, which echoes the innate imbalances of real-world unlabeled datasets.
In response to the unique challenges posed by Long-tailed GCD, we present a
robust methodology anchored in two strategic regularizations: (i) a reweighting
mechanism that bolsters the prominence of less-represented, tail-end
categories, and (ii) a class prior constraint that aligns with the anticipated
class distribution. Comprehensive experiments reveal that our proposed method
surpasses previous state-of-the-art GCD methods by achieving an improvement of
approximately 6 - 9% on ImageNet100 and competitive performance on CIFAR100.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05353" title="Abstract">arXiv:2401.05353</a> [<a href="/pdf/2401.05353" title="Download PDF">pdf</a>, <a href="/format/2401.05353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ImbaGCD: Imbalanced Generalized Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyun Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Ben Dai</a>, 
<a href="/search/cs?searchtype=author&query=Simsek%2C+F">Furkan Simsek</a>, 
<a href="/search/cs?searchtype=author&query=Meinel%2C+C">Christoph Meinel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haojin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023 Computer Vision in the Wild Workshop \textbf{Spotlight} paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generalized class discovery (GCD) aims to infer known and unknown categories
in an unlabeled dataset leveraging prior knowledge of a labeled set comprising
known classes. Existing research implicitly/explicitly assumes that the
frequency of occurrence for each category, whether known or unknown, is
approximately the same in the unlabeled data. However, in nature, we are more
likely to encounter known/common classes than unknown/uncommon ones, according
to the long-tailed property of visual classes. Therefore, we present a
challenging and practical problem, Imbalanced Generalized Category Discovery
(ImbaGCD), where the distribution of unlabeled data is imbalanced, with known
classes being more frequent than unknown ones. To address these issues, we
propose ImbaGCD, A novel optimal transport-based expectation maximization
framework that accomplishes generalized category discovery by aligning the
marginal class prior distribution. ImbaGCD also incorporates a systematic
mechanism for estimating the imbalanced class prior distribution under the GCD
setup. Our comprehensive experiments reveal that ImbaGCD surpasses previous
state-of-the-art GCD methods by achieving an improvement of approximately 2 -
4% on CIFAR-100 and 15 - 19% on ImageNet-100, indicating its superior
effectiveness in solving the Imbalanced GCD problem.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05355" title="Abstract">arXiv:2401.05355</a> [<a href="/pdf/2401.05355" title="Download PDF">pdf</a>, <a href="/format/2401.05355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Resource-Constraint EdgeAI model for Surface Defect  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mih%2C+A+N">Atah Nuh Mih</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hung Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kawnine%2C+A">Asfia Kawnine</a>, 
<a href="/search/cs?searchtype=author&query=Wachowicz%2C+M">Monica Wachowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Lightweight Edge AI, Resource-constraint ML, Surface Defect Detection
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Resource constraints have restricted several EdgeAI applications to machine
learning inference approaches, where models are trained on the cloud and
deployed to the edge device. This poses challenges such as bandwidth, latency,
and privacy associated with storing data off-site for model building. Training
on the edge device can overcome these challenges by eliminating the need to
transfer data to another device for storage and model development. On-device
training also provides robustness to data variations as models can be retrained
on newly acquired data to improve performance. We, therefore, propose a
lightweight EdgeAI architecture modified from Xception, for on-device training
in a resource-constraint edge environment. We evaluate our model on a PCB
defect detection task and compare its performance against existing lightweight
models - MobileNetV2, EfficientNetV2B0, and MobileViT-XXS. The results of our
experiment show that our model has a remarkable performance with a test
accuracy of 73.45% without pre-training. This is comparable to the test
accuracy of non-pre-trained MobileViT-XXS (75.40%) and much better than other
non-pre-trained models (MobileNetV2 - 50.05%, EfficientNetV2B0 - 54.30%). The
test accuracy of our model without pre-training is comparable to pre-trained
MobileNetV2 model - 75.45% and better than pre-trained EfficientNetV2B0 model -
58.10%. In terms of memory efficiency, our model performs better than
EfficientNetV2B0 and MobileViT-XXS. We find that the resource efficiency of
machine learning models does not solely depend on the number of parameters but
also depends on architectural considerations. Our method can be applied to
other resource-constraint applications while maintaining significant
performance.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05357" title="Abstract">arXiv:2401.05357</a> [<a href="/pdf/2401.05357" title="Download PDF">pdf</a>, <a href="/format/2401.05357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> U-SWIM: Universal Selective Write-Verify for Computing-in-Memory Neural  Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zheyu Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X+S">Xiaobo Sharon Hu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Architectures that incorporate Computing-in-Memory (CiM) using emerging
non-volatile memory (NVM) devices have become strong contenders for deep neural
network (DNN) acceleration due to their impressive energy efficiency. Yet, a
significant challenge arises when using these emerging devices: they can show
substantial variations during the weight-mapping process. This can severely
impact DNN accuracy if not mitigated. A widely accepted remedy for imperfect
weight mapping is the iterative write-verify approach, which involves verifying
conductance values and adjusting devices if needed. In all existing
publications, this procedure is applied to every individual device, resulting
in a significant programming time overhead. In our research, we illustrate that
only a small fraction of weights need this write-verify treatment for the
corresponding devices and the DNN accuracy can be preserved, yielding a notable
programming acceleration. Building on this, we introduce USWIM, a novel method
based on the second derivative. It leverages a single iteration of forward and
backpropagation to pinpoint the weights demanding write-verify. Through
extensive tests on diverse DNN designs and datasets, USWIM manifests up to a
10x programming acceleration against the traditional exhaustive write-verify
method, all while maintaining a similar accuracy level. Furthermore, compared
to our earlier SWIM technique, USWIM excels, showing a 7x speedup when dealing
with devices exhibiting non-uniform variations.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05358" title="Abstract">arXiv:2401.05358</a> [<a href="/pdf/2401.05358" title="Download PDF">pdf</a>, <a href="/ps/2401.05358" title="Download PostScript">ps</a>, <a href="/format/2401.05358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Future Intelligent Data link and Unit-Level Combat System Based on  Global Combat Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xinyan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jian Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jinyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The development of U.S. Army and NATO data link systems is introduced first,
and then the development trend of future intelligent data link is summarized
into integration, generalization, multifunctionality and high security. A
unit-level combat system architecture based on the global combat cloud, which
is capable of realizing the flexible scheduling of global combat resources and
maximizing the overall combat effectiveness, is proposed. Intelligent data link
is an important part of this solution, providing strong information support for
future urban unit-level warfare.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05362" title="Abstract">arXiv:2401.05362</a> [<a href="/pdf/2401.05362" title="Download PDF">pdf</a>, <a href="/format/2401.05362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DualTeacher: Bridging Coexistence of Unlabelled Classes for  Semi-supervised Incremental Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Ziqi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenbo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xingxing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jiachen Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Ai%2C+J">Jianyong Ai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianmin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In real-world applications, an object detector often encounters object
instances from new classes and needs to accommodate them effectively. Previous
work formulated this critical problem as incremental object detection (IOD),
which assumes the object instances of new classes to be fully annotated in
incremental data. However, as supervisory signals are usually rare and
expensive, the supervised IOD may not be practical for implementation. In this
work, we consider a more realistic setting named semi-supervised IOD (SSIOD),
where the object detector needs to learn new classes incrementally from a few
labelled data and massive unlabelled data without catastrophic forgetting of
old classes. A commonly-used strategy for supervised IOD is to encourage the
current model (as a student) to mimic the behavior of the old model (as a
teacher), but it generally fails in SSIOD because a dominant number of object
instances from old and new classes are coexisting and unlabelled, with the
teacher only recognizing a fraction of them. Observing that learning only the
classes of interest tends to preclude detection of other classes, we propose to
bridge the coexistence of unlabelled classes by constructing two teacher models
respectively for old and new classes, and using the concatenation of their
predictions to instruct the student. This approach is referred to as
DualTeacher, which can serve as a strong baseline for SSIOD with limited
resource overhead and no extra hyperparameters. We build various benchmarks for
SSIOD and perform extensive experiments to demonstrate the superiority of our
approach (e.g., the performance lead is up to 18.28 AP on MS-COCO). Our code is
available at \url{https://github.com/chuxiuhong/DualTeacher}.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05369" title="Abstract">arXiv:2401.05369</a> [<a href="/pdf/2401.05369" title="Download PDF">pdf</a>, <a href="/ps/2401.05369" title="Download PostScript">ps</a>, <a href="/format/2401.05369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Regression of Dynamic Network Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gandhi%2C+G">Govind Gandhi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 90 pages, 12 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">Growing interest in modelling complex systems from brains to societies to
cities using networks has led to increased efforts to describe generative
processes that explain those networks. Recent successes in machine learning
have prompted the usage of evolutionary computation, especially genetic
programming to evolve computer programs that effectively forage a
multidimensional search space to iteratively find better solutions that explain
network structure. Symbolic regression contributes to these approaches by
replicating network morphologies using both structure and processes, all while
not relying on the scientists intuition or expertise. It distinguishes itself
by introducing a novel formulation of a network generator and a parameter-free
fitness function to evaluate the generated network and is found to consistently
retrieve synthetically generated growth processes as well as simple,
interpretable rules for a range of empirical networks. We extend this approach
by modifying generator semantics to create and retrieve rules for time-varying
networks. Lexicon to study networks created dynamically in multiple stages is
introduced. The framework was improved using methods from the genetic
programming toolkit (recombination) and computational improvements (using
heuristic distance measures) and used to test the consistency and robustness of
the upgrades to the semantics using synthetically generated networks. Using
recombination was found to improve retrieval rate and fitness of the solutions.
The framework was then used on three empirical datasets - subway networks of
major cities, regions of street networks and semantic co-occurrence networks of
literature in Artificial Intelligence to illustrate the possibility of
obtaining interpretable, decentralised growth processes from complex networks.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05373" title="Abstract">arXiv:2401.05373</a> [<a href="/pdf/2401.05373" title="Download PDF">pdf</a>, <a href="/format/2401.05373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Spiking Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+N">Nan Yin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengzhu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=De+Masi%2C+G">Giulia De Masi</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+B">Bin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Huan Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The integration of Spiking Neural Networks (SNNs) and Graph Neural Networks
(GNNs) is gradually attracting attention due to the low power consumption and
high efficiency in processing the non-Euclidean data represented by graphs.
However, as a common problem, dynamic graph representation learning faces
challenges such as high complexity and large memory overheads. Current work
often uses SNNs instead of Recurrent Neural Networks (RNNs) by using binary
features instead of continuous ones for efficient training, which would
overlooks graph structure information and leads to the loss of details during
propagation. Additionally, optimizing dynamic spiking models typically requires
propagation of information across time steps, which increases memory
requirements. To address these challenges, we present a framework named
\underline{Dy}namic \underline{S}p\underline{i}king \underline{G}raph
\underline{N}eural Networks (\method{}). To mitigate the information loss
problem, \method{} propagates early-layer information directly to the last
layer for information compensation. To accommodate the memory requirements, we
apply the implicit differentiation on the equilibrium state, which does not
rely on the exact reverse of the forward computation. While traditional
implicit differentiation methods are usually used for static situations,
\method{} extends it to the dynamic graph setting. Extensive experiments on
three large-scale real-world dynamic graph datasets validate the effectiveness
of \method{} on dynamic node classification tasks with lower computational
costs.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05375" title="Abstract">arXiv:2401.05375</a> [<a href="/pdf/2401.05375" title="Download PDF">pdf</a>, <a href="/ps/2401.05375" title="Download PostScript">ps</a>, <a href="/format/2401.05375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classical Sorting Algorithms as a Model of Morphogenesis: self-sorting  arrays reveal unexpected competencies in a minimal model of basal  intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Taining Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Goldstein%2C+A">Adam Goldstein</a>, 
<a href="/search/cs?searchtype=author&query=Levin%2C+M">Michael Levin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">The emerging field of Diverse Intelligence seeks to identify, formalize, and
understand commonalities in behavioral competencies across a wide range of
implementations. Especially interesting are simple systems that provide
unexpected examples of memory, decision-making, or problem-solving in
substrates that at first glance do not appear to be complex enough to implement
such capabilities. We seek to develop tools to help understand the minimal
requirements for such capabilities, and to learn to recognize and predict basal
forms of intelligence in unconventional substrates. Here, we apply novel
analyses to the behavior of classical sorting algorithms, short pieces of code
which have been studied for many decades. To study these sorting algorithms as
a model of biological morphogenesis and its competencies, we break two
formerly-ubiquitous assumptions: top-down control (instead, showing how each
element within a array of numbers can exert minimal agency and implement
sorting policies from the bottom up), and fully reliable hardware (instead,
allowing some of the elements to be "damaged" and fail to execute the
algorithm). We quantitatively characterize sorting activity as the traversal of
a problem space, showing that arrays of autonomous elements sort themselves
more reliably and robustly than traditional implementations in the presence of
errors. Moreover, we find the ability to temporarily reduce progress in order
to navigate around a defect, and unexpected clustering behavior among the
elements in chimeric arrays whose elements follow one of two different
algorithms. The discovery of emergent problem-solving capacities in simple,
familiar algorithms contributes a new perspective to the field of Diverse
Intelligence, showing how basal forms of intelligence can emerge in simple
systems without being explicitly encoded in their underlying mechanics.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05377" title="Abstract">arXiv:2401.05377</a> [<a href="/pdf/2401.05377" title="Download PDF">pdf</a>, <a href="/ps/2401.05377" title="Download PostScript">ps</a>, <a href="/format/2401.05377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The impact of generative artificial intelligence on socioeconomic  inequalities and policy making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Capraro%2C+V">Valerio Capraro</a>, 
<a href="/search/cs?searchtype=author&query=Lentsch%2C+A">Austin Lentsch</a>, 
<a href="/search/cs?searchtype=author&query=Acemoglu%2C+D">Daron Acemoglu</a>, 
<a href="/search/cs?searchtype=author&query=Akgun%2C+S">Selin Akgun</a>, 
<a href="/search/cs?searchtype=author&query=Akhmedova%2C+A">Aisel Akhmedova</a>, 
<a href="/search/cs?searchtype=author&query=Bilancini%2C+E">Ennio Bilancini</a>, 
<a href="/search/cs?searchtype=author&query=Bonnefon%2C+J">Jean-Fran&#xe7;ois Bonnefon</a>, 
<a href="/search/cs?searchtype=author&query=Bra%C3%B1as-Garza%2C+P">Pablo Bra&#xf1;as-Garza</a>, 
<a href="/search/cs?searchtype=author&query=Butera%2C+L">Luigi Butera</a>, 
<a href="/search/cs?searchtype=author&query=Douglas%2C+K+M">Karen M. Douglas</a>, 
<a href="/search/cs?searchtype=author&query=Everett%2C+J+A+C">Jim A.C. Everett</a>, 
<a href="/search/cs?searchtype=author&query=Gigerenzer%2C+G">Gerd Gigerenzer</a>, 
<a href="/search/cs?searchtype=author&query=Greenhow%2C+C">Christine Greenhow</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+D+A">Daniel A. Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Holt-Lunstad%2C+J">Julianne Holt-Lunstad</a>, 
<a href="/search/cs?searchtype=author&query=Jetten%2C+J">Jolanda Jetten</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+S">Simon Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Longoni%2C+C">Chiara Longoni</a>, 
<a href="/search/cs?searchtype=author&query=Lunn%2C+P">Pete Lunn</a>, 
<a href="/search/cs?searchtype=author&query=Natale%2C+S">Simone Natale</a>, 
<a href="/search/cs?searchtype=author&query=Rahwan%2C+I">Iyad Rahwan</a>, 
<a href="/search/cs?searchtype=author&query=Selwyn%2C+N">Neil Selwyn</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vivek Singh</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+S">Siddharth Suri</a>, 
<a href="/search/cs?searchtype=author&query=Sutcliffe%2C+J">Jennifer Sutcliffe</a>, 
<a href="/search/cs?searchtype=author&query=Tomlinson%2C+J">Joe Tomlinson</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Linden%2C+S">Sander van der Linden</a>, 
<a href="/search/cs?searchtype=author&query=Van+Lange%2C+P+A+M">Paul A. M. Van Lange</a>, 
<a href="/search/cs?searchtype=author&query=Wall%2C+F">Friederike Wall</a>, 
<a href="/search/cs?searchtype=author&query=Van+Bavel%2C+J+J">Jay J. Van Bavel</a>, 
<a href="/search/cs?searchtype=author&query=Viale%2C+R">Riccardo Viale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Generative artificial intelligence, including chatbots like ChatGPT, has the
potential to both exacerbate and ameliorate existing socioeconomic
inequalities. In this article, we provide a state-of-the-art interdisciplinary
overview of the probable impacts of generative AI on four critical domains:
work, education, health, and information. Our goal is to warn about how
generative AI could worsen existing inequalities while illuminating directions
for using AI to resolve pervasive social problems. Generative AI in the
workplace can boost productivity and create new jobs, but the benefits will
likely be distributed unevenly. In education, it offers personalized learning
but may widen the digital divide. In healthcare, it improves diagnostics and
accessibility but could deepen pre-existing inequalities. For information, it
democratizes content creation and access but also dramatically expands the
production and proliferation of misinformation. Each section covers a specific
topic, evaluates existing research, identifies critical gaps, and recommends
research directions. We conclude with a section highlighting the role of
policymaking to maximize generative AI's potential to reduce inequalities while
mitigating its harmful effects. We discuss strengths and weaknesses of existing
policy frameworks in the European Union, the United States, and the United
Kingdom, observing that each fails to fully confront the socioeconomic
challenges we have identified. We contend that these policies should promote
shared prosperity through the advancement of generative AI. We suggest several
concrete policies to encourage further research and debate. This article
emphasizes the need for interdisciplinary collaborations to understand and
address the complex challenges of generative AI.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05379" title="Abstract">arXiv:2401.05379</a> [<a href="/pdf/2401.05379" title="Download PDF">pdf</a>, <a href="/format/2401.05379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoVisual Fusion Suite: A Comprehensive Evaluation of Image  Segmentation and Voice Conversion Tools on HuggingFace Platform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hashemi%2C+A">Amirreza Hashemi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This study presents a comprehensive evaluation of tools available on the
HuggingFace platform for two pivotal applications in artificial intelligence:
image segmentation and voice conversion. The primary objective was to identify
the top three tools within each category and subsequently install and configure
these tools on Linux systems. We leveraged the power of pre-trained
segmentation models such as SAM and DETR Model with ResNet-50 backbone for
image segmentation, and the so-vits-svc-fork model for voice conversion. This
paper delves into the methodologies and challenges encountered during the
implementation process, and showcases the successful combination of video
segmentation and voice conversion in a unified project named AutoVisual Fusion
Suite.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05380" title="Abstract">arXiv:2401.05380</a> [<a href="/pdf/2401.05380" title="Download PDF">pdf</a>, <a href="/format/2401.05380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Optimization for Chronic Disease Prediction with Bio-Inspired  Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dyoub%2C+A">Abeer Dyoub</a>, 
<a href="/search/cs?searchtype=author&query=Letteri%2C+I">Ivan Letteri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this study, we investigated the application of bio-inspired optimization
algorithms, including Genetic Algorithm, Particle Swarm Optimization, and Whale
Optimization Algorithm, for feature selection in chronic disease prediction.
The primary goal was to enhance the predictive accuracy of models streamline
data dimensionality, and make predictions more interpretable and actionable.
<br />The research encompassed a comparative analysis of the three bio-inspired
feature selection approaches across diverse chronic diseases, including
diabetes, cancer, kidney, and cardiovascular diseases. Performance metrics such
as accuracy, precision, recall, and f1 score are used to assess the
effectiveness of the algorithms in reducing the number of features needed for
accurate classification.
<br />The results in general demonstrate that the bio-inspired optimization
algorithms are effective in reducing the number of features required for
accurate classification. However, there have been variations in the performance
of the algorithms on different datasets.
<br />The study highlights the importance of data pre-processing and cleaning in
ensuring the reliability and effectiveness of the analysis.
<br />This study contributes to the advancement of predictive analytics in the
realm of chronic diseases. The potential impact of this work extends to early
intervention, precision medicine, and improved patient outcomes, providing new
avenues for the delivery of healthcare services tailored to individual needs.
The findings underscore the potential benefits of using bio-inspired
optimization algorithms for feature selection in chronic disease prediction,
offering valuable insights for improving healthcare outcomes.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05382" title="Abstract">arXiv:2401.05382</a> [<a href="/pdf/2401.05382" title="Download PDF">pdf</a>, <a href="/ps/2401.05382" title="Download PostScript">ps</a>, <a href="/format/2401.05382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved genetic programming for predicting semi autogenous grinding  mill throughput
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghasemi%2C+Z">Zahra Ghasemi</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+F">Frank Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Zanin%2C+M">Max Zanin</a>, 
<a href="/search/cs?searchtype=author&query=Karageorgos%2C+J">John Karageorgos</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Semi-autogenous grinding (SAG) mills play a pivotal role in the grinding
circuit of mineral processing plants. Accurate prediction of SAG mill
throughput as a crucial performance metric is of utmost importance. While
empirical models have been developed in previous studies for SAG mill
throughput prediction, the potential of applying machine learning (ML)
techniques for this purpose remains underexplored. Unlike empirical modelling,
which relies on expensive and time-consuming experimental data, ML techniques
can utilize data collected during regular operations. Genetic programming (GP)
is one of ML techniques that offers the advantage of providing a transparent
equation for precise mill throughput prediction. This study explores the
application of GP to predict SAG mill throughput and introduces five new GP
variants to enhance prediction performance. These variants extract multiple
equations, each accurately predicting mill throughput for specific clusters of
training data. These equations are then employed to predict mill throughput for
test data using various approaches. To assess the effect of distance measures
on the new GP variants, four different distance measures are employed.
Comparative analysis reveals that the new GP variants achieve an average
improvement of 12.49% in prediction accuracy. Further investigation of distance
measures indicates that the Euclidean distance measure yields the most accurate
results for the majority of data splits. Additionally, the most precise new GP
variant considers all equations and incorporates both the number of data points
in each data cluster and the distance to clusters when calculating the final
prediction. The developed GP variants in this study present a precise,
transparent, and cost-effective approach for modelling SAG mill throughput in
mineral processing plants.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05390" title="Abstract">arXiv:2401.05390</a> [<a href="/pdf/2401.05390" title="Download PDF">pdf</a>, <a href="/format/2401.05390" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generation of BIM data based on the automatic detection, identification  and localization of lamps in buildings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troncoso-Pastoriza%2C+F">Francisco Troncoso-Pastoriza</a>, 
<a href="/search/cs?searchtype=author&query=Egu%C3%ADa-Oller%2C+P">Pablo Egu&#xed;a-Oller</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz-Redondo%2C+R+P">Rebeca P. D&#xed;az-Redondo</a>, 
<a href="/search/cs?searchtype=author&query=Granada-%C3%81lvarez%2C+E">Enrique Granada-&#xc1;lvarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 19 figures, journal
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sustainable cities and society, 2018, vol. 36, p. 59-70
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper we introduce a method that supports the detection,
identification and localization of lamps in a building, with the main goal of
automatically feeding its energy model by means of Building Information
Modeling (BIM) methods. The proposed method, thus, provides useful information
to apply energy-saving strategies to reduce energy consumption in the building
sector through the correct management of the lighting infrastructure. Based on
the unique geometry and brightness of lamps and the use of only greyscale
images, our methodology is able to obtain accurate results despite its low
computational needs, resulting in near-real-time processing. The main novelty
is that the focus of the candidate search is not over the entire image but
instead only on a limited region that summarizes the specific characteristics
of the lamp. The information obtained from our approach was used on the Green
Building XML Schema to illustrate the automatic generation of BIM data from the
results of the algorithm.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05391" title="Abstract">arXiv:2401.05391</a> [<a href="/pdf/2401.05391" title="Download PDF">pdf</a>, <a href="/ps/2401.05391" title="Download PostScript">ps</a>, <a href="/format/2401.05391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient LLM inference solution on Intel GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hui Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yi Gan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Feng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jing Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yutao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hong Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuhua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoli Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinghui Gu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Transformer based Large Language Models (LLMs) have been widely used in many
fields, and the efficiency of LLM inference becomes hot topic in real
applications. However, LLMs are usually complicatedly designed in model
structure with massive operations and perform inference in the auto-regressive
mode, making it a challenging task to design a system with high efficiency.
<br />In this paper, we propose an efficient LLM inference solution with low
latency and high throughput. Firstly, we simplify the LLM decoder layer by
fusing data movement and element-wise operations to reduce the memory access
frequency and lower system latency. We also propose a segment KV cache policy
to keep key/value of the request and response tokens in separate physical
memory for effective device memory management, helping enlarge the runtime
batch size and improve system throughput. A customized
Scaled-Dot-Product-Attention kernel is designed to match our fusion policy
based on the segment KV cache solution. We implement our LLM inference solution
on Intel GPU and publish it publicly. Compared with the standard HuggingFace
implementation, the proposed solution achieves up to 7x lower token latency and
27x higher throughput for some popular LLMs on Intel GPU.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05392" title="Abstract">arXiv:2401.05392</a> [<a href="/pdf/2401.05392" title="Download PDF">pdf</a>, <a href="/format/2401.05392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AT-2FF: Adaptive Type-2 Fuzzy Filter for De-noising Images Corrupted  with Salt-and-Pepper
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Vikas Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Noise is inevitably common in digital images, leading to visual image
deterioration. Therefore, a suitable filtering method is required to lessen the
noise while preserving the image features (edges, corners, etc.). This paper
presents the efficient type-2 fuzzy weighted mean filter with an adaptive
threshold to remove the SAP noise. The present filter has two primary steps:
The first stage categorizes images as lightly, medium, and heavily corrupted
based on an adaptive threshold by comparing the M-ALD of processed pixels with
the upper and lower MF of the type-2 fuzzy identifier. The second stage
eliminates corrupted pixels by computing the appropriate weight using GMF with
the mean and variance of the uncorrupted pixels in the filter window.
Simulation results vividly show that the obtained denoised images preserve
image features, i.e., edges, corners, and other sharp structures, compared with
different filtering methods.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05396" title="Abstract">arXiv:2401.05396</a> [<a href="/pdf/2401.05396" title="Download PDF">pdf</a>, <a href="/format/2401.05396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loss it right: Euclidean and Riemannian Metrics in Learning-based Visual  Odometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%81lvarez-Tu%C3%B1%C3%B3n%2C+O">Olaya &#xc1;lvarez-Tu&#xf1;&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Brodskiy%2C+Y">Yury Brodskiy</a>, 
<a href="/search/cs?searchtype=author&query=Kayacan%2C+E">Erdal Kayacan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper overviews different pose representations and metric functions in
visual odometry (VO) networks. The performance of VO networks heavily relies on
how their architecture encodes the information. The choice of pose
representation and loss function significantly impacts network convergence and
generalization. We investigate these factors in the VO network DeepVO by
implementing loss functions based on Euler, quaternion, and chordal distance
and analyzing their influence on performance. The results of this study provide
insights into how loss functions affect the designing of efficient and accurate
VO networks for camera motion estimation. The experiments illustrate that a
distance that complies with the mathematical requirements of a metric, such as
the chordal distance, provides better generalization and faster convergence.
The code for the experiments can be found at
https://github.com/remaro-network/Loss_VO_right
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05398" title="Abstract">arXiv:2401.05398</a> [<a href="/pdf/2401.05398" title="Download PDF">pdf</a>, <a href="/ps/2401.05398" title="Download PostScript">ps</a>, <a href="/format/2401.05398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GeoAI in Social Science
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenwen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Artificial Intelligence; social science; deep learning; convergence; knowledge graph
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Handbook of Spatial Analysis in the Social Sciences, 291 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">GeoAI, or geospatial artificial intelligence, is an exciting new area that
leverages artificial intelligence (AI), geospatial big data, and massive
computing power to solve problems with high automation and intelligence. This
paper reviews the progress of AI in social science research, highlighting
important advancements in using GeoAI to fill critical data and knowledge gaps.
It also discusses the importance of breaking down data silos, accelerating
convergence among GeoAI research methods, as well as moving GeoAI beyond
geospatial benefits.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05399" title="Abstract">arXiv:2401.05399</a> [<a href="/pdf/2401.05399" title="Download PDF">pdf</a>, <a href="/ps/2401.05399" title="Download PostScript">ps</a>, <a href="/format/2401.05399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Assessment of Students&#x27; Code Comprehension using LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oli%2C+P">Priti Oli</a>, 
<a href="/search/cs?searchtype=author&query=Banjade%2C+R">Rabin Banjade</a>, 
<a href="/search/cs?searchtype=author&query=Chapagain%2C+J">Jeevan Chapagain</a>, 
<a href="/search/cs?searchtype=author&query=Rus%2C+V">Vasile Rus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Assessing student's answers and in particular natural language answers is a
crucial challenge in the field of education. Advances in machine learning,
including transformer-based models such as Large Language Models(LLMs), have
led to significant progress in various natural language tasks. Nevertheless,
amidst the growing trend of evaluating LLMs across diverse tasks, evaluating
LLMs in the realm of automated answer assesment has not received much
attention. To address this gap, we explore the potential of using LLMs for
automated assessment of student's short and open-ended answer. Particularly, we
use LLMs to compare students' explanations with expert explanations in the
context of line-by-line explanations of computer programs.
<br />For comparison purposes, we assess both Large Language Models (LLMs) and
encoder-based Semantic Textual Similarity (STS) models in the context of
assessing the correctness of students' explanation of computer code. Our
findings indicate that LLMs, when prompted in few-shot and chain-of-thought
setting perform comparable to fine-tuned encoder-based models in evaluating
students' short answers in programming domain.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05400" title="Abstract">arXiv:2401.05400</a> [<a href="/pdf/2401.05400" title="Download PDF">pdf</a>, <a href="/ps/2401.05400" title="Download PostScript">ps</a>, <a href="/format/2401.05400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Learning with Artificial Intelligence Speakers (CLAIS):  Pre-Service Elementary Science Teachers&#x27; Responses to the Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+G">Gyeong-Geon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Mun%2C+S">Seonyeong Mun</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+M">Myeong-Kyeong Shin</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+X">Xiaoming Zhai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This research aims to demonstrate that AI can function not only as a tool for
learning, but also as an intelligent agent with which humans can engage in
collaborative learning (CL) to change epistemic practices in science
classrooms. We adopted a design and development research approach, following
the Analysis, Design, Development, Implementation and Evaluation (ADDIE) model,
to prototype a tangible instructional system called Collaborative Learning with
AI Speakers (CLAIS). The CLAIS system is designed to have 3-4 human learners
join an AI speaker to form a small group, where humans and AI are considered as
peers participating in the Jigsaw learning process. The development was carried
out using the NUGU AI speaker platform. The CLAIS system was successfully
implemented in a Science Education course session with 15 pre-service
elementary science teachers. The participants evaluated the CLAIS system
through mixed methods surveys as teachers, learners, peers, and users.
Quantitative data showed that the participants' Intelligent-Technological,
Pedagogical, And Content Knowledge was significantly increased after the CLAIS
session, the perception of the CLAIS learning experience was positive, the peer
assessment on AI speakers and human peers was different, and the user
experience was ambivalent. Qualitative data showed that the participants
anticipated future changes in the epistemic process in science classrooms,
while acknowledging technical issues such as speech recognition performance and
response latency. This study highlights the potential of Human-AI Collaboration
for knowledge co-construction in authentic classroom settings and exemplify how
AI could shape the future landscape of epistemic practices in the classroom.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05401" title="Abstract">arXiv:2401.05401</a> [<a href="/pdf/2401.05401" title="Download PDF">pdf</a>, <a href="/format/2401.05401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain Similarity-Perceived Label Assignment for Domain Generalized  Underwater Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xisheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+P">Pinhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingjun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The inherent characteristics and light fluctuations of water bodies give rise
to the huge difference between different layers and regions in underwater
environments. When the test set is collected in a different marine area from
the training set, the issue of domain shift emerges, significantly compromising
the model's ability to generalize. The Domain Adversarial Learning (DAL)
training strategy has been previously utilized to tackle such challenges.
However, DAL heavily depends on manually one-hot domain labels, which implies
no difference among the samples in the same domain. Such an assumption results
in the instability of DAL. This paper introduces the concept of Domain
Similarity-Perceived Label Assignment (DSP). The domain label for each image is
regarded as its similarity to the specified domains. Through domain-specific
data augmentation techniques, we achieved state-of-the-art results on the
underwater cross-domain object detection benchmark S-UODAC2020. Furthermore, we
validated the effectiveness of our method in the Cityscapes dataset.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05403" title="Abstract">arXiv:2401.05403</a> [<a href="/pdf/2401.05403" title="Download PDF">pdf</a>, <a href="/format/2401.05403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Key Artificial Intelligence Technologies in Early Childhood  Education: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honghu%2C+Y">Yi Honghu</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+L">Liu Ting</a>, 
<a href="/search/cs?searchtype=author&query=Gongjin%2C+L">Lan Gongjin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Artificial Intelligence (AI) technologies have been applied in various
domains, including early childhood education (ECE). Integration of AI
educational technology is a recent significant trend in ECE. Currently, there
are more and more studies of AI in ECE. To date, there is a lack of survey
articles that discuss the studies of AI in ECE. In this paper, we provide an
up-to-date and in-depth overview of the key AI technologies in ECE that
provides a historical perspective, summarizes the representative works,
outlines open questions, discusses the trends and challenges through a detailed
bibliometric analysis, and provides insightful recommendations for future
research. We mainly discuss the studies that apply AI-based robots and AI
technologies to ECE, including improving the social interaction of children
with an autism spectrum disorder. This paper significantly contributes to
provide an up-to-date and in-depth survey that is suitable as introductory
material for beginners to AI in ECE, as well as supplementary material for
advanced users.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05412" title="Abstract">arXiv:2401.05412</a> [<a href="/pdf/2401.05412" title="Download PDF">pdf</a>, <a href="/format/2401.05412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Related Sensors Matters: 3D Human Motion Reconstruction Assisted  with Textual Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xueyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+X">Xiaojuan Ban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">Leveraging wearable devices for motion reconstruction has emerged as an
economical and viable technique. Certain methodologies employ sparse Inertial
Measurement Units (IMUs) on the human body and harness data-driven strategies
to model human poses. However, the reconstruction of motion based solely on
sparse IMUs data is inherently fraught with ambiguity, a consequence of
numerous identical IMU readings corresponding to different poses. In this
paper, we explore the spatial importance of multiple sensors, supervised by
text that describes specific actions. Specifically, uncertainty is introduced
to derive weighted features for each IMU. We also design a Hierarchical
Temporal Transformer (HTT) and apply contrastive learning to achieve precise
temporal and feature alignment of sensor data with textual semantics.
Experimental results demonstrate our proposed approach achieves significant
improvements in multiple metrics compared to existing methods. Notably, with
textual supervision, our method not only differentiates between ambiguous
actions such as sitting and standing but also produces more precise and natural
motion.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05415" title="Abstract">arXiv:2401.05415</a> [<a href="/pdf/2401.05415" title="Download PDF">pdf</a>, <a href="/ps/2401.05415" title="Download PostScript">ps</a>, <a href="/format/2401.05415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Generative AI in Global Diplomatic Practices: A Strategic  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bano%2C+M">Muneera Bano</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhri%2C+Z">Zahid Chaudhri</a>, 
<a href="/search/cs?searchtype=author&query=Zowghi%2C+D">Didar Zowghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">As Artificial Intelligence (AI) transforms the domain of diplomacy in the
21st century, this research addresses the pressing need to evaluate the
dualistic nature of these advancements, unpacking both the challenges they pose
and the opportunities they offer. It has been almost a year since the launch of
ChatGPT by OpenAI that revolutionised various work domains with its
capabilities. The scope of application of these capabilities to diplomacy is
yet to be fully explored or understood. Our research objective is to
systematically examine the current discourse on Digital and AI Diplomacy, thus
informing the development of a comprehensive framework for the role of
Generative AI in modern diplomatic practices. Through the systematic analysis
of 230 scholarly articles, we identified a spectrum of opportunities and
challenges, culminating in a strategic framework that captures the multifaceted
concepts for integration of Generative AI, setting a course for future research
and innovation in diplomacy.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05421" title="Abstract">arXiv:2401.05421</a> [<a href="/pdf/2401.05421" title="Download PDF">pdf</a>, <a href="/format/2401.05421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WildGEN: Long-horizon Trajectory Generation for Wildlife
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Al-Lawati%2C+A">Ali Al-Lawati</a>, 
<a href="/search/cs?searchtype=author&query=Eshra%2C+E">Elsayed Eshra</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+P">Prasenjit Mitra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 1st CIKM International Workshop on Knowledge Extraction and Management for Wildlife Conservation (InfoWild 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Trajectory generation is an important concern in pedestrian, vehicle, and
wildlife movement studies. Generated trajectories help enrich the training
corpus in relation to deep learning applications, and may be used to facilitate
simulation tasks. This is especially significant in the wildlife domain, where
the cost of obtaining additional real data can be prohibitively expensive,
time-consuming, and bear ethical considerations. In this paper, we introduce
WildGEN: a conceptual framework that addresses this challenge by employing a
Variational Auto-encoders (VAEs) based method for the acquisition of movement
characteristics exhibited by wild geese over a long horizon using a sparse set
of truth samples. A subsequent post-processing step of the generated
trajectories is performed based on smoothing filters to reduce excessive
wandering. Our evaluation is conducted through visual inspection and the
computation of the Hausdorff distance between the generated and real
trajectories. In addition, we utilize the Pearson Correlation Coefficient as a
way to measure how realistic the trajectories are based on the similarity of
clusters evaluated on the generated and real trajectories.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05424" title="Abstract">arXiv:2401.05424</a> [<a href="/pdf/2401.05424" title="Download PDF">pdf</a>, <a href="/format/2401.05424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Toolbox for Modelling Engagement with Educational Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuxiang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Djemili%2C+K">Karim Djemili</a>, 
<a href="/search/cs?searchtype=author&query=Elezi%2C+D">Denis Elezi</a>, 
<a href="/search/cs?searchtype=author&query=Shalman%2C+A">Aaneel Shalman</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Ortiz%2C+M">Mar&#xed;a P&#xe9;rez-Ortiz</a>, 
<a href="/search/cs?searchtype=author&query=Yilmaz%2C+E">Emine Yilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Shawe-Taylor%2C+J">John Shawe-Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Bulathwela%2C+S">Sahan Bulathwela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of AAAI Conference on Artificial Intelligence 2024. arXiv admin note: text overlap with <a href="/abs/2309.11527">arXiv:2309.11527</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">With the advancement and utility of Artificial Intelligence (AI),
personalising education to a global population could be a cornerstone of new
educational systems in the future. This work presents the PEEKC dataset and the
TrueLearn Python library, which contains a dataset and a series of online
learner state models that are essential to facilitate research on learner
engagement modelling.TrueLearn family of models was designed following the
"open learner" concept, using humanly-intuitive user representations. This
family of scalable, online models also help end-users visualise the learner
models, which may in the future facilitate user interaction with their
models/recommenders. The extensive documentation and coding examples make the
library highly accessible to both machine learning developers and educational
data mining and learning analytics practitioners. The experiments show the
utility of both the dataset and the library with predictive performance
significantly exceeding comparative baseline models. The dataset contains a
large amount of AI-related educational videos, which are of interest for
building and validating AI-specific educational recommenders.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05432" title="Abstract">arXiv:2401.05432</a> [<a href="/pdf/2401.05432" title="Download PDF">pdf</a>, <a href="/format/2401.05432" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep  Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hossain%2C+K+M">Khondoker Murad Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Oates%2C+T">Tim Oates</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">As deep neural networks and the datasets used to train them get larger, the
default approach to integrating them into research and commercial projects is
to download a pre-trained model and fine tune it. But these models can have
uncertain provenance, opening up the possibility that they embed hidden
malicious behavior such as trojans or backdoors, where small changes to an
input (triggers) can cause the model to produce incorrect outputs (e.g., to
misclassify). This paper introduces a novel approach to backdoor detection that
uses two tensor decomposition methods applied to network activations. This has
a number of advantages relative to existing detection methods, including the
ability to analyze multiple models at the same time, working across a wide
variety of network architectures, making no assumptions about the nature of
triggers used to alter network behavior, and being computationally efficient.
We provide a detailed description of the detection pipeline along with results
on models trained on the MNIST digit dataset, CIFAR-10 dataset, and two
difficult datasets from NIST's TrojAI competition. These results show that our
method detects backdoored networks more accurately and efficiently than current
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05433" title="Abstract">arXiv:2401.05433</a> [<a href="/pdf/2401.05433" title="Download PDF">pdf</a>, <a href="/format/2401.05433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Essay Scoring with Adversarial Weights Perturbation and  Metric-specific AttentionPooling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiaxin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+C">Chang Che</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qunwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article was accepted by 2023 International Conference on Information Network and Computer Communications(INCC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The objective of this study is to improve automated feedback tools designed
for English Language Learners (ELLs) through the utilization of data science
techniques encompassing machine learning, natural language processing, and
educational data analytics. Automated essay scoring (AES) research has made
strides in evaluating written essays, but it often overlooks the specific needs
of English Language Learners (ELLs) in language development. This study
explores the application of BERT-related techniques to enhance the assessment
of ELLs' writing proficiency within AES.
<br />To address the specific needs of ELLs, we propose the use of DeBERTa, a
state-of-the-art neural language model, for improving automated feedback tools.
DeBERTa, pretrained on large text corpora using self-supervised learning,
learns universal language representations adaptable to various natural language
understanding tasks. The model incorporates several innovative techniques,
including adversarial training through Adversarial Weights Perturbation (AWP)
and Metric-specific AttentionPooling (6 kinds of AP) for each label in the
competition.
<br />The primary focus of this research is to investigate the impact of
hyperparameters, particularly the adversarial learning rate, on the performance
of the model. By fine-tuning the hyperparameter tuning process, including the
influence of 6AP and AWP, the resulting models can provide more accurate
evaluations of language proficiency and support tailored learning tasks for
ELLs. This work has the potential to significantly benefit ELLs by improving
their English language proficiency and facilitating their educational journey.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05438" title="Abstract">arXiv:2401.05438</a> [<a href="/pdf/2401.05438" title="Download PDF">pdf</a>, <a href="/format/2401.05438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Designs for Combined 2D+3D Visual Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+J">Jiayi Hong</a>, 
<a href="/search/cs?searchtype=author&query=Hnatyshyn%2C+R">Rostyslav Hnatyshyn</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+E+A+D">Ebrar A. D. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Maciejewski%2C+R">Ross Maciejewski</a>, 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+T">Tobias Isenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">We examine visual representations of data that make use of combinations of
both 2D and 3D data mappings. Combining 2D and 3D representations is a common
technique that allows viewers to understand multiple facets of the data with
which they are interacting. While 3D representations focus on the spatial
character of the data or the dedicated 3D data mapping, 2D representations
often show abstract data properties and take advantage of the unique benefits
of mapping to a plane. Many systems have used unique combinations of both types
of data mappings effectively. Yet there are no systematic reviews of the
methods in linking 2D and 3D representations. We systematically survey the
relationships between 2D and 3D visual representations in major visualization
publications -- IEEE VIS, IEEE TVCG, and EuroVis -- from 2012 to 2022. We
closely examined 105 papers where 2D and 3D representations are connected
visually, interactively, or through animation. These approaches are designed
based on their visual environment, the relationships between their visual
representations, and their possible layouts. Through our analysis, we introduce
a design space as well as provide design guidelines for effectively linking 2D
and 3D visual representations.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05439" title="Abstract">arXiv:2401.05439</a> [<a href="/pdf/2401.05439" title="Download PDF">pdf</a>, <a href="/ps/2401.05439" title="Download PostScript">ps</a>, <a href="/format/2401.05439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-informed Deep Learning to Solve Three-dimensional Terzaghi  Consolidation Equation: Forward and Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+B">Biao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Heitor%2C+A">Ana Heitor</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaohui Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 11 figures, 6 tables, 23 equations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE)

</div>
<p class="mathjax">The emergence of neural networks constrained by physical governing equations
has sparked a new trend in deep learning research, which is known as
Physics-Informed Neural Networks (PINNs). However, solving high-dimensional
problems with PINNs is still a substantial challenge, the space complexity
brings difficulty to solving large multidirectional problems. In this paper, a
novel PINN framework to quickly predict several three-dimensional Terzaghi
consolidation cases under different conditions is proposed. Meanwhile, the loss
functions for different cases are introduced, and their differences in
three-dimensional consolidation problems are highlighted. The tuning strategies
for the PINNs framework for three-dimensional consolidation problems are
introduced. Then, the performance of PINNs is tested and compared with
traditional numerical methods adopted in forward problems, and the coefficients
of consolidation and the impact of noisy data in inverse problems are
identified. Finally, the results are summarized and presented from
three-dimensional simulations of PINNs, which show an accuracy rate of over 99%
compared with ground truth for both forward and inverse problems. These results
are desirable with good accuracy and can be used for soil settlement
prediction, which demonstrates that the proposed PINNs framework can learn the
three-dimensional consolidation PDE well.
<br />Keywords: Three-dimensional Terzaghi consolidation; Physics-informed neural
networks (PINNs); Forward problems; Inverse problems; soil settlement
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05442" title="Abstract">arXiv:2401.05442</a> [<a href="/pdf/2401.05442" title="Download PDF">pdf</a>, <a href="/format/2401.05442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Graphical Models: Structure Enables Offline Data-Driven  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuba%2C+J+G">Jakub Grudzien Kuba</a>, 
<a href="/search/cs?searchtype=author&query=Uehara%2C+M">Masatoshi Uehara</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While machine learning models are typically trained to solve prediction
problems, we might often want to use them for optimization problems. For
example, given a dataset of proteins and their corresponding fluorescence
levels, we might want to optimize for a new protein with the highest possible
fluorescence. This kind of data-driven optimization (DDO) presents a range of
challenges beyond those in standard prediction problems, since we need models
that successfully predict the performance of new designs that are better than
the best designs seen in the training set. It is not clear theoretically when
existing approaches can even perform better than the naive approach that simply
selects the best design in the dataset. In this paper, we study how structure
can enable sample-efficient data-driven optimization. To formalize the notion
of structure, we introduce functional graphical models (FGMs) and show
theoretically how they can provide for principled data-driven optimization by
decomposing the original high-dimensional optimization problem into smaller
sub-problems. This allows us to derive much more practical regret bounds for
DDO, and the result implies that DDO with FGMs can achieve nearly optimal
designs in situations where naive approaches fail due to insufficient coverage
of the offline data. We further present a data-driven optimization algorithm
that inferes the FGM structure itself, either over the original input variables
or a latent variable representation of the inputs.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05443" title="Abstract">arXiv:2401.05443</a> [<a href="/pdf/2401.05443" title="Download PDF">pdf</a>, <a href="/format/2401.05443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4PLC: Harnessing Large Language Models for Verifiable Programming of  PLCs in Industrial Control Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fakih%2C+M">Mohamad Fakih</a>, 
<a href="/search/cs?searchtype=author&query=Dharmaji%2C+R">Rahul Dharmaji</a>, 
<a href="/search/cs?searchtype=author&query=Moghaddas%2C+Y">Yasamin Moghaddas</a>, 
<a href="/search/cs?searchtype=author&query=Araya%2C+G+Q">Gustavo Quiros Araya</a>, 
<a href="/search/cs?searchtype=author&query=Ogundare%2C+O">Oluwatosin Ogundare</a>, 
<a href="/search/cs?searchtype=author&query=Faruque%2C+M+A+A">Mohammad Abdullah Al Faruque</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages; 8 figures; Appearing in the 46th International Conference on Software Engineering: Software Engineering in Practice; for demo website, see <a href="https://sites.google.com/uci.edu/llm4plc/home">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Programming Languages (cs.PL)

</div>
<p class="mathjax">Although Large Language Models (LLMs) have established pre-dominance in
automated code generation, they are not devoid of shortcomings. The pertinent
issues primarily relate to the absence of execution guarantees for generated
code, a lack of explainability, and suboptimal support for essential but niche
programming languages. State-of-the-art LLMs such as GPT-4 and LLaMa2 fail to
produce valid programs for Industrial Control Systems (ICS) operated by
Programmable Logic Controllers (PLCs). We propose LLM4PLC, a user-guided
iterative pipeline leveraging user feedback and external verification tools
including grammar checkers, compilers and SMV verifiers to guide the LLM's
generation. We further enhance the generation potential of LLM by employing
Prompt Engineering and model fine-tuning through the creation and usage of
LoRAs. We validate this system using a FischerTechnik Manufacturing TestBed
(MFTB), illustrating how LLMs can evolve from generating structurally flawed
code to producing verifiably correct programs for industrial applications. We
run a complete test suite on GPT-3.5, GPT-4, Code Llama-7B, a fine-tuned Code
Llama-7B model, Code Llama-34B, and a fine-tuned Code Llama-34B model. The
proposed pipeline improved the generation success rate from 47% to 72%, and the
Survey-of-Experts code quality from 2.25/10 to 7.75/10. To promote open
research, we share the complete experimental setup, the LLM Fine-Tuning
Weights, and the video demonstrations of the different programs on our
dedicated webpage.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05444" title="Abstract">arXiv:2401.05444</a> [<a href="/pdf/2401.05444" title="Download PDF">pdf</a>, <a href="/format/2401.05444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully Spiking Actor Network with Intra-layer Connections for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Ding Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+P">Peixi Peng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+T">Tiejun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yonghong Tian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With the help of special neuromorphic hardware, spiking neural networks
(SNNs) are expected to realize artificial intelligence (AI) with less energy
consumption. It provides a promising energy-efficient way for realistic control
tasks by combining SNNs with deep reinforcement learning (DRL). In this paper,
we focus on the task where the agent needs to learn multi-dimensional
deterministic policies to control, which is very common in real scenarios.
Recently, the surrogate gradient method has been utilized for training
multi-layer SNNs, which allows SNNs to achieve comparable performance with the
corresponding deep networks in this task. Most existing spike-based RL methods
take the firing rate as the output of SNNs, and convert it to represent
continuous action space (i.e., the deterministic policy) through a
fully-connected (FC) layer. However, the decimal characteristic of the firing
rate brings the floating-point matrix operations to the FC layer, making the
whole SNN unable to deploy on the neuromorphic hardware directly. To develop a
fully spiking actor network without any floating-point matrix operations, we
draw inspiration from the non-spiking interneurons found in insects and employ
the membrane voltage of the non-spiking neurons to represent the action. Before
the non-spiking neurons, multiple population neurons are introduced to decode
different dimensions of actions. Since each population is used to decode a
dimension of action, we argue that the neurons in each population should be
connected in time domain and space domain. Hence, the intra-layer connections
are used in output populations to enhance the representation capacity. Finally,
we propose a fully spiking actor network with intra-layer connections
(ILC-SAN).
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05450" title="Abstract">arXiv:2401.05450</a> [<a href="/pdf/2401.05450" title="Download PDF">pdf</a>, <a href="/ps/2401.05450" title="Download PostScript">ps</a>, <a href="/format/2401.05450" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reorienting Learning Game Design in Design-Based Research: a Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mandran%2C+N">Nadine Mandran</a>, 
<a href="/search/cs?searchtype=author&query=Prior%2C+E">Estelle Prior</a>, 
<a href="/search/cs?searchtype=author&query=Sanchez%2C+E">Eric Sanchez</a>, 
<a href="/search/cs?searchtype=author&query=Vermeulen%2C+M">Mathieu Vermeulen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">One of the main difficulties remains the collaboration between the various
experts involved in designing the Learning Games (LG). Our literature review
focuses on the pitfalls and principles that have been identified by various
authors in learning games design. Based on this review, a prototype was
designed to support the LG design process and to study more precisely the
collaboration between actors (teachers, researchers, game designers, data
analyst and computer scientist). Indeed, according to the state of the art, the
skills and knowledge involved in design are difficult to integrate. It has been
tested in a real-world scenario for designing learning games to teach
algorithmic. Through participant observation in thirty-three workshops
involving nine experts, we were able to identify recurring pitfalls as we
applied the recommendations in the literature. The analysis of these workshops
led to propose eight principles aimed at facilitating the collaboration between
the learning games design process and re-evaluating research on its.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05451" title="Abstract">arXiv:2401.05451</a> [<a href="/pdf/2401.05451" title="Download PDF">pdf</a>, <a href="/format/2401.05451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpenSkill: A faster asymmetric multi-team, multiplayer rating system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshy%2C+V">Vivek Joshy</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Open Source Software 9 (2024) 5901
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Assessing and comparing player skill in online multiplayer gaming
environments is essential for fair matchmaking and player engagement.
Traditional ranking models like Elo and Glicko-2, designed for two-player
games, are insufficient for the complexity of multi-player, asymmetric
team-based matches. To address this gap, the OpenSkill library offers a suite
of sophisticated, fast, and adaptable models tailored for such dynamics.
Drawing from Bayesian inference methods, OpenSkill provides a more accurate
representation of individual player contributions and speeds up the computation
of ranks. This paper introduces the OpenSkill library, featuring a Python
implementation of the Plackett-Luce model among others, highlighting its
performance advantages and predictive accuracy against proprietary systems like
TrueSkill. OpenSkill is a valuable tool for game developers and researchers,
ensuring a responsive and fair gaming experience by efficiently adjusting
player rankings based on game outcomes. The library's support for time decay
and diligent documentation further aid in its practical application, making it
a robust solution for the nuanced world of multiplayer ranking systems. This
paper also acknowledges areas for future enhancement, such as partial play and
contribution weighting, emphasizing the library's ongoing development to meet
the evolving needs of online gaming communities.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05453" title="Abstract">arXiv:2401.05453</a> [<a href="/pdf/2401.05453" title="Download PDF">pdf</a>, <a href="/format/2401.05453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dimensionality-Aware Outlier Detection: Theoretical and Experimental  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anderberg%2C+A">Alastair Anderberg</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>, 
<a href="/search/cs?searchtype=author&query=Campello%2C+R+J+G+B">Ricardo J. G. B. Campello</a>, 
<a href="/search/cs?searchtype=author&query=Houle%2C+M+E">Michael E. Houle</a>, 
<a href="/search/cs?searchtype=author&query=Marques%2C+H+O">Henrique O. Marques</a>, 
<a href="/search/cs?searchtype=author&query=Radovanovi%C4%87%2C+M">Milo&#x161; Radovanovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Zimek%2C+A">Arthur Zimek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures. Extended version of a paper accepted for publication at the SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We present a nonparametric method for outlier detection that takes full
account of local variations in intrinsic dimensionality within the dataset.
Using the theory of Local Intrinsic Dimensionality (LID), our
'dimensionality-aware' outlier detection method, DAO, is derived as an
estimator of an asymptotic local expected density ratio involving the query
point and a close neighbor drawn at random. The dimensionality-aware behavior
of DAO is due to its use of local estimation of LID values in a
theoretically-justified way. Through comprehensive experimentation on more than
800 synthetic and real datasets, we show that DAO significantly outperforms
three popular and important benchmark outlier detection methods: Local Outlier
Factor (LOF), Simplified LOF, and kNN.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05458" title="Abstract">arXiv:2401.05458</a> [<a href="/pdf/2401.05458" title="Download PDF">pdf</a>, <a href="/format/2401.05458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic  Dimensionality Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruofan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rundensteiner%2C+E">Elke Rundensteiner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is accepted by SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks (DNNs) have advanced many machine learning tasks, but
their performance is often harmed by noisy labels in real-world data.
Addressing this, we introduce CoLafier, a novel approach that uses Local
Intrinsic Dimensionality (LID) for learning with noisy labels. CoLafier
consists of two subnets: LID-dis and LID-gen. LID-dis is a specialized
classifier. Trained with our uniquely crafted scheme, LID-dis consumes both a
sample's features and its label to predict the label - which allows it to
produce an enhanced internal representation. We observe that LID scores
computed from this representation effectively distinguish between correct and
incorrect labels across various noise scenarios. In contrast to LID-dis,
LID-gen, functioning as a regular classifier, operates solely on the sample's
features. During training, CoLafier utilizes two augmented views per instance
to feed both subnets. CoLafier considers the LID scores from the two views as
produced by LID-dis to assign weights in an adapted loss function for both
subnets. Concurrently, LID-gen, serving as classifier, suggests pseudo-labels.
LID-dis then processes these pseudo-labels along with two views to derive LID
scores. Finally, these LID scores along with the differences in predictions
from the two subnets guide the label update decisions. This dual-view and
dual-subnet approach enhances the overall reliability of the framework. Upon
completion of the training, we deploy the LID-gen subnet of CoLafier as the
final classification model. CoLafier demonstrates improved prediction accuracy,
surpassing existing methods, particularly under severe label noise. For more
details, see the code at https://github.com/zdy93/CoLafier.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05459" title="Abstract">arXiv:2401.05459</a> [<a href="/pdf/2401.05459" title="Download PDF">pdf</a>, <a href="/format/2401.05459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personal LLM Agents: Insights and Survey about the Capability,  Efficiency and Security
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanchun Li</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hao Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiangyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yizhen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiacheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenxing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+R">Rui Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yile Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+H">Hanfei Geng</a>, 
<a href="/search/cs?searchtype=author&query=Luan%2C+J">Jian Luan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xuefeng Jin</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zilong Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+G">Guanjing Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Mengwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya-Qin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunxin Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/MobileLLM/Personal_LLM_Agents_Survey">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
<p class="mathjax">Since the advent of personal computing devices, intelligent personal
assistants (IPAs) have been one of the key technologies that researchers and
engineers have focused on, aiming to help users efficiently obtain information
and execute tasks, and provide users with more intelligent, convenient, and
rich interaction experiences. With the development of smartphones and IoT,
computing and sensing devices have become ubiquitous, greatly expanding the
boundaries of IPAs. However, due to the lack of capabilities such as user
intent understanding, task planning, tool using, and personal data management
etc., existing IPAs still have limited practicality and scalability. Recently,
the emergence of foundation models, represented by large language models
(LLMs), brings new opportunities for the development of IPAs. With the powerful
semantic understanding and reasoning capabilities, LLM can enable intelligent
agents to solve complex problems autonomously. In this paper, we focus on
Personal LLM Agents, which are LLM-based agents that are deeply integrated with
personal data and personal devices and used for personal assistance. We
envision that Personal LLM Agents will become a major software paradigm for
end-users in the upcoming era. To realize this vision, we take the first step
to discuss several important questions about Personal LLM Agents, including
their architecture, capability, efficiency and security. We start by
summarizing the key components and design choices in the architecture of
Personal LLM Agents, followed by an in-depth analysis of the opinions collected
from domain experts. Next, we discuss several key challenges to achieve
intelligent, efficient and secure Personal LLM Agents, followed by a
comprehensive survey of representative solutions to address these challenges.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05461" title="Abstract">arXiv:2401.05461</a> [<a href="/pdf/2401.05461" title="Download PDF">pdf</a>, <a href="/ps/2401.05461" title="Download PostScript">ps</a>, <a href="/format/2401.05461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The two-way knowledge interaction interface between humans and neural  networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhanliang He</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+N">Nuoye Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+P">Peiyi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guangming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite neural networks (NN) have been widely applied in various fields and
generally outperforms humans, they still lack interpretability to a certain
extent, and humans are unable to intuitively understand the decision logic of
NN. This also hinders the knowledge interaction between humans and NN,
preventing humans from getting involved to give direct guidance when NN's
decisions go wrong. While recent research in explainable AI has achieved
interpretability of NN from various perspectives, it has not yet provided
effective methods for knowledge exchange between humans and NN. To address this
problem, we constructed a two-way interaction interface that uses structured
representations of visual concepts and their relationships as the "language"
for knowledge exchange between humans and NN. Specifically, NN provide
intuitive reasoning explanations to humans based on the class-specific
structural concepts graph (C-SCG). On the other hand, humans can modify the
biases present in the C-SCG through their prior knowledge and reasoning
ability, and thus provide direct knowledge guidance to NN through this
interface. Through experimental validation, based on this interaction
interface, NN can provide humans with easily understandable explanations of the
reasoning process. Furthermore, human involvement and prior knowledge can
directly and effectively contribute to enhancing the performance of NN.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05462" title="Abstract">arXiv:2401.05462</a> [<a href="/pdf/2401.05462" title="Download PDF">pdf</a>, <a href="/format/2401.05462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Petri Nets for Smart Grids: The Story So Far
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ge%2C+M">Mouzhi Ge</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+B">Bruno Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Chren%2C+S">Stanislav Chren</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+J+M">Jos&#xe9; Miguel Blanco</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
<p class="mathjax">Since the energy domain is in a transformative shift towards sustainability,
the integration of new technologies and smart systems into traditional power
grids has emerged. As an effective approach, Petri Nets (PN) have been applied
to model and analyze the complex dynamics in Smart Grid (SG) environments.
However, we are currently missing an overview of types of PNs applied to
different areas and problems related to SGs. Therefore, this paper proposes
four fundamental research questions related to the application areas of PNs in
SGs, PNs types, aspects modelled by PNs in the identified areas, and the
validation methods in the evaluation. The answers to the research questions are
derived from a comprehensive and interdisciplinary literature analysis. The
results capture a valuable overview of PNs applications in the global energy
landscape and can offer indications for future research directions.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05465" title="Abstract">arXiv:2401.05465</a> [<a href="/pdf/2401.05465" title="Download PDF">pdf</a>, <a href="/format/2401.05465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D3GU: Multi-Target Active Domain Adaptation via Enhancing Domain  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Linghan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Motamed%2C+S">Saman Motamed</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+S">Shayok Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=De+la+Torre%2C+F">Fernando De la Torre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Poster at WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation (UDA) for image classification has made
remarkable progress in transferring classification knowledge from a labeled
source domain to an unlabeled target domain, thanks to effective domain
alignment techniques. Recently, in order to further improve performance on a
target domain, many Single-Target Active Domain Adaptation (ST-ADA) methods
have been proposed to identify and annotate the salient and exemplar target
samples. However, it requires one model to be trained and deployed for each
target domain and the domain label associated with each test sample. This
largely restricts its application in the ubiquitous scenarios with multiple
target domains. Therefore, we propose a Multi-Target Active Domain Adaptation
(MT-ADA) framework for image classification, named D3GU, to simultaneously
align different domains and actively select samples from them for annotation.
This is the first research effort in this field to our best knowledge. D3GU
applies Decomposed Domain Discrimination (D3) during training to achieve both
source-target and target-target domain alignments. Then during active sampling,
a Gradient Utility (GU) score is designed to weight every unlabeled target
image by its contribution towards classification and domain alignment tasks,
and is further combined with KMeans clustering to form GU-KMeans for diverse
image sampling. Extensive experiments on three benchmark datasets, Office31,
OfficeHome, and DomainNet, have been conducted to validate consistently
superior performance of D3GU for MT-ADA.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05467" title="Abstract">arXiv:2401.05467</a> [<a href="/pdf/2401.05467" title="Download PDF">pdf</a>, <a href="/format/2401.05467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Teaching for Building Modular AI Agents based on Zero-shot  Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taneja%2C+K">Karan Taneja</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashok Goel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The recent advances in large language models (LLMs) have led to the creation
of many modular AI agents. These agents employ LLMs as zero-shot learners to
perform sub-tasks in order to solve complex tasks set forth by human users. We
propose an approach to enhance the robustness and performance of modular AI
agents that utilize LLMs as zero-shot learners. Our iterative machine teaching
method offers an efficient way to teach AI agents over time with limited human
feedback, addressing the limit posed by the quality of zero-shot learning. We
advocate leveraging the data traces from initial deployments and outputs or
annotations from the zero-shot learners to train smaller and task-specific
substitute models which can reduce both the monetary costs and environmental
impact. Our machine teaching process avails human expertise to correct examples
with a high likelihood of misannotations. Results on three tasks, common to
conversational AI agents, show that close-to-oracle performance can be achieved
with supervision on 20-70% of the dataset depending upon the complexity of the
task and performance of zero-shot learners.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05468" title="Abstract">arXiv:2401.05468</a> [<a href="/pdf/2401.05468" title="Download PDF">pdf</a>, <a href="/format/2401.05468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Introducing New Node Prediction in Graph Mining: Predicting All Links  from Isolated Nodes with Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zanardini%2C+D">Damiano Zanardini</a>, 
<a href="/search/cs?searchtype=author&query=Serrano%2C+E">Emilio Serrano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper introduces a new problem in the field of graph mining and social
network analysis called new node prediction. More technically, the task can be
categorized as zero-shot out-of-graph all-links prediction. This challenging
problem aims to predict all links from a new, isolated, and unobserved node
that was previously disconnected from the graph. Unlike classic approaches to
link prediction (including few-shot out-of-graph link prediction), this problem
presents two key differences: (1) the new node has no existing links from which
to extract patterns for new predictions; and (2) the goal is to predict not
just one, but all the links of this new node, or at least a significant part of
them. Experiments demonstrate that an architecture based on Deep Graph Neural
Networks can learn to solve this challenging problem in a bibliographic
citation network.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05476" title="Abstract">arXiv:2401.05476</a> [<a href="/pdf/2401.05476" title="Download PDF">pdf</a>, <a href="/ps/2401.05476" title="Download PostScript">ps</a>, <a href="/format/2401.05476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CADgpt: Harnessing Natural Language Processing for 3D Modelling to  Enhance Computer-Aided Design Workflows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kapsalis%2C+T">Timo Kapsalis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">This paper introduces CADgpt, an innovative plugin integrating Natural
Language Processing (NLP) with Rhino3D for enhancing 3D modelling in
computer-aided design (CAD) environments. Leveraging OpenAI's GPT-4, CADgpt
simplifies the CAD interface, enabling users, particularly beginners, to
perform complex 3D modelling tasks through intuitive natural language commands.
This approach significantly reduces the learning curve associated with
traditional CAD software, fostering a more inclusive and engaging educational
environment. The paper discusses CADgpt's technical architecture, including its
integration within Rhino3D and the adaptation of GPT-4 capabilities for CAD
tasks. It presents case studies demonstrating CADgpt's efficacy in various
design scenarios, highlighting its potential to democratise design education by
making sophisticated design tools accessible to a broader range of students.
The discussion further explores CADgpt's implications for pedagogy and
curriculum development, emphasising its role in enhancing creative exploration
and conceptual thinking in design education.
<br />Keywords: Natural Language Processing, Computer-Aided Design, 3D Modelling,
Design Automation, Design Education, Architectural Education
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05477" title="Abstract">arXiv:2401.05477</a> [<a href="/pdf/2401.05477" title="Download PDF">pdf</a>, <a href="/format/2401.05477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Standardizing Your Training Process for Human Activity Recognition  Models: A Comprehensive Review in the Tunable Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiran Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yexu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Riedel%2C+T">Till Riedel</a>, 
<a href="/search/cs?searchtype=author&query=Beigl%2C+M">Michael Beigl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, deep learning has emerged as a potent tool across a
multitude of domains, leading to a surge in research pertaining to its
application in the wearable human activity recognition (WHAR) domain. Despite
the rapid development, concerns have been raised about the lack of
standardization and consistency in the procedures used for experimental model
training, which may affect the reproducibility and reliability of research
results. In this paper, we provide an exhaustive review of contemporary deep
learning research in the field of WHAR and collate information pertaining to
the training procedure employed in various studies. Our findings suggest that a
major trend is the lack of detail provided by model training protocols.
Besides, to gain a clearer understanding of the impact of missing descriptions,
we utilize a control variables approach to assess the impact of key tunable
components (e.g., optimization techniques and early stopping criteria) on the
inter-subject generalization capabilities of HAR models. With insights from the
analyses, we define a novel integrated training procedure tailored to the WHAR
model. Empirical results derived using five well-known \ac{whar} benchmark
datasets and three classical HAR model architectures demonstrate the
effectiveness of our proposed methodology: in particular, there is a
significant improvement in macro F1 leave one subject out cross-validation
performance.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05478" title="Abstract">arXiv:2401.05478</a> [<a href="/pdf/2401.05478" title="Download PDF">pdf</a>, <a href="/format/2401.05478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Population Graph Cross-Network Node Classification for Autism Detection  Across Sample Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stephens%2C+A">Anna Stephens</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+F">Francisco Santos</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+P">Pang-Ning Tan</a>, 
<a href="/search/cs?searchtype=author&query=Esfahanian%2C+A">Abdol-Hossein Esfahanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear ICDM DMBIH workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph neural networks (GNN) are a powerful tool for combining imaging and
non-imaging medical information for node classification tasks. Cross-network
node classification extends GNN techniques to account for domain drift,
allowing for node classification on an unlabeled target network. In this paper
we present OTGCN, a powerful, novel approach to cross-network node
classification. This approach leans on concepts from graph convolutional
networks to harness insights from graph data structures while simultaneously
applying strategies rooted in optimal transport to correct for the domain drift
that can occur between samples from different data collection sites. This
blended approach provides a practical solution for scenarios with many distinct
forms of data collected across different locations and equipment. We
demonstrate the effectiveness of this approach at classifying Autism Spectrum
Disorder subjects using a blend of imaging and non-imaging data.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05479" title="Abstract">arXiv:2401.05479</a> [<a href="/pdf/2401.05479" title="Download PDF">pdf</a>, <a href="/ps/2401.05479" title="Download PostScript">ps</a>, <a href="/format/2401.05479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The recursive scheme of clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miniak-G%C3%B3recka%2C+A">Alicja Miniak-G&#xf3;recka</a>, 
<a href="/search/cs?searchtype=author&query=Podlaski%2C+K">Krzysztof Podlaski</a>, 
<a href="/search/cs?searchtype=author&query=Gwizda%C5%82%C5%82a%2C+T">Tomasz Gwizda&#x142;&#x142;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The problem of data clustering is one of the most important in data analysis.
It can be problematic when dealing with experimental data characterized by
measurement uncertainties and errors. Our paper proposes a recursive scheme for
clustering data obtained in geographical (climatological) experiments. The
discussion of results obtained by k-means and SOM methods with the developed
recursive procedure is presented. We show that the clustering using the new
approach gives more acceptable results when compared to experts assessments.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05501" title="Abstract">arXiv:2401.05501</a> [<a href="/pdf/2401.05501" title="Download PDF">pdf</a>, <a href="/format/2401.05501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deflating the Chinese Balloon: Types of Twitter Bots in US-China balloon  incident
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>, 
<a href="/search/cs?searchtype=author&query=Carley%2C+K+M">Kathleen M. Carley</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPJ Data Sci. 12, 63 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">As digitalization increases, countries employ digital diplomacy, harnessing
digital resources to project their desired image. Digital diplomacy also
encompasses the interactivity of digital platforms, providing a trove of public
opinion that diplomatic agents can collect. Social media bots actively
participate in political events through influencing political communication and
purporting coordinated narratives to influence human behavior. This article
provides a methodology towards identifying three types of bots: General Bots,
News Bots and Bridging Bots, then further identify these classes of bots on
Twitter during a diplomatic incident involving the United States and China.
Using a series of computational methods, this article examines the impact of
bots on the topics disseminated, the influence and the use of information
maneuvers of bots within the social communication network. Among others, our
results observe that all three types of bots are present across the two
countries; bots geotagged to the US are generally concerned with the balloon
location while those geotagged to China discussed topics related to escalating
tensions; and perform different extent of positive narrative and network
information maneuvers.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05502" title="Abstract">arXiv:2401.05502</a> [<a href="/pdf/2401.05502" title="Download PDF">pdf</a>, <a href="/ps/2401.05502" title="Download PostScript">ps</a>, <a href="/format/2401.05502" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity-aware clustering: Computational Complexity and Approximation  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thejaswi%2C+S">Suhas Thejaswi</a>, 
<a href="/search/cs?searchtype=author&query=Gadekar%2C+A">Ameet Gadekar</a>, 
<a href="/search/cs?searchtype=author&query=Ordozgoiti%2C+B">Bruno Ordozgoiti</a>, 
<a href="/search/cs?searchtype=author&query=Gionis%2C+A">Aristides Gionis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Algorithmic Fairness, Fair Clustering, Diversity-aware Clustering, Intersectionaly, Subgroup fairness
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we study diversity-aware clustering problems where the data
points are associated with multiple attributes resulting in intersecting
groups. A clustering solution need to ensure that a minimum number of cluster
centers are chosen from each group while simultaneously minimizing the
clustering objective, which can be either $k$-median, $k$-means or
$k$-supplier. We present parameterized approximation algorithms with
approximation ratios $1+ \frac{2}{e}$, $1+\frac{8}{e}$ and $3$ for
diversity-aware $k$-median, diversity-aware $k$-means and diversity-aware
$k$-supplier, respectively. The approximation ratios are tight assuming Gap-ETH
and FPT $\neq$ W[2]. For fair $k$-median and fair $k$-means with disjoint
faicility groups, we present parameterized approximation algorithm with
approximation ratios $1+\frac{2}{e}$ and $1+\frac{8}{e}$, respectively. For
fair $k$-supplier with disjoint facility groups, we present a polynomial-time
approximation algorithm with factor $3$, improving the previous best known
approximation ratio of factor $5$.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05507" title="Abstract">arXiv:2401.05507</a> [<a href="/pdf/2401.05507" title="Download PDF">pdf</a>, <a href="/format/2401.05507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xueyu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Ziyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shuang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+Z">Ziwei Chai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guoyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuwu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jing Su</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingjing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Ming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianbo Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+K">Kun Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hongxia Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+F">Fei Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce "InfiAgent-DABench", the first benchmark
specifically designed to evaluate LLM-based agents in data analysis tasks. This
benchmark contains DAEval, a dataset consisting of 311 data analysis questions
derived from 55 CSV files, and an agent framework to evaluate LLMs as data
analysis agents. We adopt a format-prompting technique, ensuring questions to
be closed-form that can be automatically evaluated. Our extensive benchmarking
of 23 state-of-the-art LLMs uncovers the current challenges encountered in data
analysis tasks. In addition, we have developed DAAgent, a specialized agent
trained on instruction-tuning datasets. Evaluation datasets and toolkits for
InfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05509" title="Abstract">arXiv:2401.05509</a> [<a href="/pdf/2401.05509" title="Download PDF">pdf</a>, <a href="/format/2401.05509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Ensemble Model Towards Secured Industrial IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Injadat%2C+M">MohammadNoor Injadat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented in 24th International Arab Conference on Information Technology (ACIT'2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The continued growth in the deployment of Internet-of-Things (IoT) devices
has been fueled by the increased connectivity demand, particularly in
industrial environments. However, this has led to an increase in the number of
network related attacks due to the increased number of potential attack
surfaces. Industrial IoT (IIoT) devices are prone to various network related
attacks that can have severe consequences on the manufacturing process as well
as on the safety of the workers in the manufacturing plant. One promising
solution that has emerged in recent years for attack detection is Machine
learning (ML). More specifically, ensemble learning models have shown great
promise in improving the performance of the underlying ML models. Accordingly,
this paper proposes a framework based on the combined use of Bayesian
Optimization-Gaussian Process (BO-GP) with an ensemble tree-based learning
model to improve the performance of intrusion and attack detection in IIoT
environments. The proposed framework's performance is evaluated using the
Windows 10 dataset collected by the Cyber Range and IoT labs at University of
New South Wales. Experimental results illustrate the improvement in detection
accuracy, precision, and F-score when compared to standard tree and ensemble
tree models.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05511" title="Abstract">arXiv:2401.05511</a> [<a href="/pdf/2401.05511" title="Download PDF">pdf</a>, <a href="/format/2401.05511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Elicitation and Contrasting Narratives on Engagement,  Recall and Attitude Change with News Articles Containing Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rogha%2C+M">Milad Rogha</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+S">Subham Sah</a>, 
<a href="/search/cs?searchtype=author&query=Karduni%2C+A">Alireza Karduni</a>, 
<a href="/search/cs?searchtype=author&query=Markant%2C+D">Douglas Markant</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+W">Wenwen Dou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">News articles containing data visualizations play an important role in
informing the public on issues ranging from public health to politics. Recent
research on the persuasive appeal of data visualizations suggests that prior
attitudes can be notoriously difficult to change. Inspired by an NYT article,
we designed two experiments to evaluate the impact of elicitation and
contrasting narratives on attitude change, recall, and engagement. We
hypothesized that eliciting prior beliefs leads to more elaborative thinking
that ultimately results in higher attitude change, better recall, and
engagement. Our findings revealed that visual elicitation leads to higher
engagement in terms of feelings of surprise. While there is an overall attitude
change across all experiment conditions, we did not observe a significant
effect of belief elicitation on attitude change. With regard to recall error,
while participants in the draw trend elicitation exhibited significantly lower
recall error than participants in the categorize trend condition, we found no
significant difference in recall error when comparing elicitation conditions to
no elicitation. In a follow-up study, we added contrasting narratives with the
purpose of making the main visualization (communicating data on the focal
issue) appear strikingly different. Compared to the results of study 1, we
found that contrasting narratives improved engagement in terms of surprise and
interest but interestingly resulted in higher recall error and no significant
change in attitude. We discuss the effects of elicitation and contrasting
narratives in the context of topic involvement and the strengths of temporal
trends encoded in the data visualization.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05516" title="Abstract">arXiv:2401.05516</a> [<a href="/pdf/2401.05516" title="Download PDF">pdf</a>, <a href="/format/2401.05516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D  Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">GeonU Kim</a>, 
<a href="/search/cs?searchtype=author&query=Youwang%2C+K">Kim Youwang</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+T">Tae-Hyun Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://kim-geonu.github.io/FPRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR)

</div>
<p class="mathjax">We present FPRF, a feed-forward photorealistic style transfer method for
large-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with
arbitrary, multiple style reference images without additional optimization
while preserving multi-view appearance consistency. Prior arts required tedious
per-style/-scene optimization and were limited to small-scale 3D scenes. FPRF
efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D
neural radiance field, which inherits AdaIN's feed-forward stylization
machinery, supporting arbitrary style reference images. Furthermore, FPRF
supports multi-reference stylization with the semantic correspondence matching
and local AdaIN, which adds diverse user control for 3D scene styles. FPRF also
preserves multi-view consistency by applying semantic matching and style
transfer processes directly onto queried features in 3D space. In experiments,
we demonstrate that FPRF achieves favorable photorealistic quality 3D scene
stylization for large-scale scenes with diverse reference images. Project page:
https://kim-geonu.github.io/FPRF/
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05518" title="Abstract">arXiv:2401.05518</a> [<a href="/pdf/2401.05518" title="Download PDF">pdf</a>, <a href="/format/2401.05518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Correlated Quantization for Faster Nonconvex Distributed Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panferov%2C+A">Andrei Panferov</a>, 
<a href="/search/cs?searchtype=author&query=Demidovich%2C+Y">Yury Demidovich</a>, 
<a href="/search/cs?searchtype=author&query=Rammal%2C+A">Ahmad Rammal</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">Quantization (Alistarh et al., 2017) is an important (stochastic) compression
technique that reduces the volume of transmitted bits during each communication
round in distributed model training. Suresh et al. (2022) introduce correlated
quantizers and show their advantages over independent counterparts by analyzing
distributed SGD communication complexity. We analyze the forefront distributed
non-convex optimization algorithm MARINA (Gorbunov et al., 2022) utilizing the
proposed correlated quantizers and show that it outperforms the original MARINA
and distributed SGD of Suresh et al. (2022) with regard to the communication
complexity. We significantly refine the original analysis of MARINA without any
additional assumptions using the weighted Hessian variance (Tyurin et al.,
2022), and then we expand the theoretical framework of MARINA to accommodate a
substantially broader range of potentially correlated and biased compressors,
thus dilating the applicability of the method beyond the conventional
independent unbiased compressor setup. Extensive experimental results
corroborate our theoretical findings.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05520" title="Abstract">arXiv:2401.05520</a> [<a href="/pdf/2401.05520" title="Download PDF">pdf</a>, <a href="/format/2401.05520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Pampas to Pixels: Fine-Tuning Diffusion Models for Ga&#xfa;cho  Heritage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amadeus%2C+M">Marcellus Amadeus</a>, 
<a href="/search/cs?searchtype=author&query=Casta%C3%B1eda%2C+W+A+C">William Alberto Cruz Casta&#xf1;eda</a>, 
<a href="/search/cs?searchtype=author&query=Zanella%2C+A+F">Andr&#xe9; Felipe Zanella</a>, 
<a href="/search/cs?searchtype=author&query=Mahlow%2C+F+R+P">Felipe Rodrigues Perche Mahlow</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Generative AI has become pervasive in society, witnessing significant
advancements in various domains. Particularly in the realm of Text-to-Image
(TTI) models, Latent Diffusion Models (LDMs), showcase remarkable capabilities
in generating visual content based on textual prompts. This paper addresses the
potential of LDMs in representing local cultural concepts, historical figures,
and endangered species. In this study, we use the cultural heritage of Rio
Grande do Sul (RS), Brazil, as an illustrative case. Our objective is to
contribute to the broader understanding of how generative models can help to
capture and preserve the cultural and historical identity of regions. The paper
outlines the methodology, including subject selection, dataset creation, and
the fine-tuning process. The results showcase the images generated, alongside
the challenges and feasibility of each concept. In conclusion, this work shows
the power of these models to represent and preserve unique aspects of diverse
regions and communities.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05521" title="Abstract">arXiv:2401.05521</a> [<a href="/pdf/2401.05521" title="Download PDF">pdf</a>, <a href="/format/2401.05521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Current Effect-eliminated Optimal Target Assignment and Motion Planning  for a Multi-UUV System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Danjie Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S+X">Simon X. Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by IEEE Transactions on Intelligent Transportation Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">The paper presents an innovative approach (CBNNTAP) that addresses the
complexities and challenges introduced by ocean currents when optimizing target
assignment and motion planning for a multi-unmanned underwater vehicle (UUV)
system. The core of the proposed algorithm involves the integration of several
key components. Firstly, it incorporates a bio-inspired neural network-based
(BINN) approach which predicts the most efficient paths for individual UUVs
while simultaneously ensuring collision avoidance among the vehicles. Secondly,
an efficient target assignment component is integrated by considering the path
distances determined by the BINN algorithm. In addition, a critical innovation
within the CBNNTAP algorithm is its capacity to address the disruptive effects
of ocean currents, where an adjustment component is seamlessly integrated to
counteract the deviations caused by these currents, which enhances the accuracy
of both motion planning and target assignment for the UUVs. The effectiveness
of the CBNNTAP algorithm is demonstrated through comprehensive simulation
results and the outcomes underscore the superiority of the developed algorithm
in nullifying the effects of static and dynamic ocean currents in 2D and 3D
scenarios.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05525" title="Abstract">arXiv:2401.05525</a> [<a href="/pdf/2401.05525" title="Download PDF">pdf</a>, <a href="/format/2401.05525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Safe Load Balancing based on Control Barrier Functions and Deep  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinh%2C+L">Lam Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Quang%2C+P+T+A">Pham Tran Anh Quang</a>, 
<a href="/search/cs?searchtype=author&query=Leguay%2C+J">J&#xe9;r&#xe9;mie Leguay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE/IFIP NOMS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Reinforcement Learning (DRL) algorithms have recently made significant
strides in improving network performance. Nonetheless, their practical use is
still limited in the absence of safe exploration and safe decision-making. In
the context of commercial solutions, reliable and safe-to-operate systems are
of paramount importance. Taking this problem into account, we propose a safe
learning-based load balancing algorithm for Software Defined-Wide Area Network
(SD-WAN), which is empowered by Deep Reinforcement Learning (DRL) combined with
a Control Barrier Function (CBF). It safely projects unsafe actions into
feasible ones during both training and testing, and it guides learning towards
safe policies. We successfully implemented the solution on GPU to accelerate
training by approximately 110x times and achieve model updates for on-policy
methods within a few seconds, making the solution practical. We show that our
approach delivers near-optimal Quality-of-Service (QoS performance in terms of
end-to-end delay while respecting safety requirements related to link capacity
constraints. We also demonstrated that on-policy learning based on Proximal
Policy Optimization (PPO) performs better than off-policy learning with Deep
Deterministic Policy Gradient (DDPG) when both are combined with a CBF for safe
load balancing.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05529" title="Abstract">arXiv:2401.05529</a> [<a href="/pdf/2401.05529" title="Download PDF">pdf</a>, <a href="/format/2401.05529" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MicroFuzz: An Efficient Fuzzing Framework for Microservices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+P">Peng Di</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yiyi Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE-SEIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper presents a novel fuzzing framework, called MicroFuzz, specifically
designed for Microservices. Mocking-Assisted Seed Execution, Distributed
Tracing, Seed Refresh and Pipeline Parallelism approaches are adopted to
address the environmental complexities and dynamics of Microservices and
improve the efficiency of fuzzing. MicroFuzz has been successfully implemented
and deployed in Ant Group, a prominent FinTech company. Its performance has
been evaluated in three distinct industrial scenarios: normalized fuzzing,
iteration testing, and taint verification.Throughout five months of operation,
MicroFuzz has diligently analyzed a substantial codebase, consisting of 261
Apps with over 74.6 million lines of code (LOC). The framework's effectiveness
is evident in its detection of 5,718 potential quality or security risks, with
1,764 of them confirmed and fixed as actual security threats by software
specialists. Moreover, MicroFuzz significantly increased program coverage by
12.24% and detected program behavior by 38.42% in the iteration testing.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05530" title="Abstract">arXiv:2401.05530</a> [<a href="/pdf/2401.05530" title="Download PDF">pdf</a>, <a href="/ps/2401.05530" title="Download PostScript">ps</a>, <a href="/format/2401.05530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus Focus for Object Detection and minority classes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Salgado%2C+E+I+V">Erik Isai Valle Salgado</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yaqi Han</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+L">Linchao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinghui Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ensemble methods exploit the availability of a given number of classifiers or
detectors trained in single or multiple source domains and tasks to address
machine learning problems such as domain adaptation or multi-source transfer
learning. Existing research measures the domain distance between the sources
and the target dataset, trains multiple networks on the same data with
different samples per class, or combines predictions from models trained under
varied hyperparameters and settings. Their solutions enhanced the performance
on small or tail categories but hurt the rest. To this end, we propose a
modified consensus focus for semi-supervised and long-tailed object detection.
We introduce a voting system based on source confidence that spots the
contribution of each model in a consensus, lets the user choose the relevance
of each class in the target label space so that it relaxes minority bounding
boxes suppression, and combines multiple models' results without discarding the
poisonous networks. Our tests on synthetic driving datasets retrieved higher
confidence and more accurate bounding boxes than the NMS, soft-NMS, and WBF.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05531" title="Abstract">arXiv:2401.05531</a> [<a href="/pdf/2401.05531" title="Download PDF">pdf</a>, <a href="/ps/2401.05531" title="Download PostScript">ps</a>, <a href="/format/2401.05531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VI-PANN: Harnessing Transfer Learning and Uncertainty-Aware Variational  Inference for Improved Generalization in Audio Pattern Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+J">John Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Orescanin%2C+M">Marko Orescanin</a>, 
<a href="/search/cs?searchtype=author&query=Eckstrand%2C+E">Eric Eckstrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Transfer learning (TL) is an increasingly popular approach to training deep
learning (DL) models that leverages the knowledge gained by training a
foundation model on diverse, large-scale datasets for use on downstream tasks
where less domain- or task-specific data is available. The literature is rich
with TL techniques and applications; however, the bulk of the research makes
use of deterministic DL models which are often uncalibrated and lack the
ability to communicate a measure of epistemic (model) uncertainty in
prediction. Unlike their deterministic counterparts, Bayesian DL (BDL) models
are often well-calibrated, provide access to epistemic uncertainty for a
prediction, and are capable of achieving competitive predictive performance. In
this study, we propose variational inference pre-trained audio neural networks
(VI-PANNs). VI-PANNs are a variational inference variant of the popular
ResNet-54 architecture which are pre-trained on AudioSet, a large-scale audio
event detection dataset. We evaluate the quality of the resulting uncertainty
when transferring knowledge from VI-PANNs to other downstream acoustic
classification tasks using the ESC-50, UrbanSound8K, and DCASE2013 datasets. We
demonstrate, for the first time, that it is possible to transfer calibrated
uncertainty information along with knowledge from upstream tasks to enhance a
model's capability to perform downstream tasks.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05533" title="Abstract">arXiv:2401.05533</a> [<a href="/pdf/2401.05533" title="Download PDF">pdf</a>, <a href="/format/2401.05533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Smocking through Fabric-Thread Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Ningfeng Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jing Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sorkine-Hornung%2C+O">Olga Sorkine-Hornung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>

</div>
<p class="mathjax">We formalize Italian smocking, an intricate embroidery technique that gathers
flat fabric into pleats along meandering lines of stitches, resulting in pleats
that fold and gather where the stitching veers. In contrast to English
smocking, characterized by colorful stitches decorating uniformly shaped
pleats, and Canadian smocking, which uses localized knots to form voluminous
pleats, Italian smocking permits the fabric to move freely along the stitched
threads following curved paths, resulting in complex and unpredictable pleats
with highly diverse, irregular structures, achieved simply by pulling on the
threads. We introduce a novel method for digital previewing of Italian smocking
results, given the thread stitching path as input. Our method uses a
coarse-grained mass-spring system to simulate the interaction between the
threads and the fabric. This configuration guides the fine-level fabric
deformation through an adaptation of the state-of-the-art simulator, C-IPC. Our
method models the general problem of fabric-thread interaction and can be
readily adapted to preview Canadian smocking as well. We compare our results to
baseline approaches and physical fabrications to demonstrate the accuracy of
our method.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05538" title="Abstract">arXiv:2401.05538</a> [<a href="/pdf/2401.05538" title="Download PDF">pdf</a>, <a href="/format/2401.05538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-objective Feature Selection in Remote Health Monitoring  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+L+N">Le Ngu Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Casado%2C+C+%C3%81">Constantino &#xc1;lvarez Casado</a>, 
<a href="/search/cs?searchtype=author&query=Ca%C3%B1ellas%2C+M+L">Manuel Lage Ca&#xf1;ellas</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anirban Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N">Nhi Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Jayagopi%2C+D+B">Dinesh Babu Jayagopi</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+M+B">Miguel Bordallo L&#xf3;pez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Radio frequency (RF) signals have facilitated the development of non-contact
human monitoring tasks, such as vital signs measurement, activity recognition,
and user identification. In some specific scenarios, an RF signal analysis
framework may prioritize the performance of one task over that of others. In
response to this requirement, we employ a multi-objective optimization approach
inspired by biological principles to select discriminative features that
enhance the accuracy of breathing patterns recognition while simultaneously
impeding the identification of individual users. This approach is validated
using a novel vital signs dataset consisting of 50 subjects engaged in four
distinct breathing patterns. Our findings indicate a remarkable result: a
substantial divergence in accuracy between breathing recognition and user
identification. As a complementary viewpoint, we present a contrariwise result
to maximize user identification accuracy and minimize the system's capacity for
breathing activity recognition.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05544" title="Abstract">arXiv:2401.05544</a> [<a href="/pdf/2401.05544" title="Download PDF">pdf</a>, <a href="/format/2401.05544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodePrompt: Improving Source Code-Related Classification with Knowledge  Features through Prompt Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Senlin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yu-Ming Shang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengjun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Researchers have explored the potential of utilizing pre-trained language
models, such as CodeBERT, to improve source code-related tasks. Previous
studies have mainly relied on CodeBERT's text embedding capability and the
`[CLS]' sentence embedding information as semantic representations for
fine-tuning downstream source code-related tasks. However, these methods
require additional neural network layers to extract effective features,
resulting in higher computational costs. Furthermore, existing approaches have
not leveraged the rich knowledge contained in both source code and related
text, which can lead to lower accuracy. This paper presents a novel approach,
CodePrompt, which utilizes rich knowledge recalled from a pre-trained model by
prompt learning and an attention mechanism to improve source code-related
classification tasks. Our approach initially motivates the language model with
prompt information to retrieve abundant knowledge associated with the input as
representative features, thus avoiding the need for additional neural network
layers and reducing computational costs. Subsequently, we employ an attention
mechanism to aggregate multiple layers of related knowledge for each task as
final features to boost their accuracy. We conducted extensive experiments on
four downstream source code-related tasks to evaluate our approach and our
results demonstrate that CodePrompt achieves new state-of-the-art performance
on the accuracy metric while also exhibiting computation cost-saving
capabilities.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05548" title="Abstract">arXiv:2401.05548</a> [<a href="/pdf/2401.05548" title="Download PDF">pdf</a>, <a href="/format/2401.05548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-HEEP: An Open-Source, Configurable and Extendible RISC-V  Microcontroller for the Exploration of Ultra-Low-Power Edge Accelerators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machetti%2C+S">Simone Machetti</a>, 
<a href="/search/cs?searchtype=author&query=Schiavone%2C+P+D">Pasquale Davide Schiavone</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+T+C">Thomas Christoph M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Pe%C3%B3n-Quir%C3%B3s%2C+M">Miguel Pe&#xf3;n-Quir&#xf3;s</a>, 
<a href="/search/cs?searchtype=author&query=Atienza%2C+D">David Atienza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">The field of edge computing has witnessed remarkable growth owing to the
increasing demand for real-time processing of data in applications. However,
challenges persist due to limitations in performance and power consumption. To
overcome these challenges, heterogeneous architectures have emerged that
combine host processors with specialized accelerators tailored to specific
applications, leading to improved performance and reduced power consumption.
However, most of the existing platforms lack the necessary configurability and
extendability options for integrating custom accelerators. To overcome these
limitations, we introduce in this paper the eXtendible Heterogeneous
Energy-Efficient Platform (X-HEEP). X-HEEP is an open-source platform designed
to natively support the integration of ultra-low-power edge accelerators. It
provides customization options to match specific application requirements by
exploring various core types, bus topologies, addressing modes, memory sizes,
and peripherals. Moreover, the platform prioritizes energy efficiency by
implementing low-power strategies, such as clock-gating and power-gating. We
demonstrate the real-world applicability of X-HEEP by providing an integration
example tailored for healthcare applications that includes a coarse-grained
reconfigurable array (CGRA) and in-memory computing (IMC) accelerators. The
resulting design, called HEEPocrates, has been implemented both in field
programmable gate array (FPGA) on the Xilinx Zynq-7020 chip and in silicon with
TSMC 65 nm low-power CMOS technology. We run a set of healthcare applications
and measure their energy consumption to demonstrate the alignment of our chip
with other state-of-the-art microcontrollers commonly adopted in this domain.
Moreover, we showcase the energy benefit of 4.9 x gained by exploiting the
integrated CGRA accelerator, compared to running on the host CPU.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05551" title="Abstract">arXiv:2401.05551</a> [<a href="/pdf/2401.05551" title="Download PDF">pdf</a>, <a href="/format/2401.05551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Useful Blunders: Can Automated Speech Recognition Errors Improve  Downstream Dementia Classification?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changye Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Weizhe Xu</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+T">Trevor Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Pakhomov%2C+S">Serguei Pakhomov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear on Journal of Biomedical Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">\textbf{Objectives}: We aimed to investigate how errors from automatic speech
recognition (ASR) systems affect dementia classification accuracy, specifically
in the ``Cookie Theft'' picture description task. We aimed to assess whether
imperfect ASR-generated transcripts could provide valuable information for
distinguishing between language samples from cognitively healthy individuals
and those with Alzheimer's disease (AD).
<br />\textbf{Methods}: We conducted experiments using various ASR models, refining
their transcripts with post-editing techniques. Both these imperfect ASR
transcripts and manually transcribed ones were used as inputs for the
downstream dementia classification. We conducted comprehensive error analysis
to compare model performance and assess ASR-generated transcript effectiveness
in dementia classification.
<br />\textbf{Results}: Imperfect ASR-generated transcripts surprisingly
outperformed manual transcription for distinguishing between individuals with
AD and those without in the ``Cookie Theft'' task. These ASR-based models
surpassed the previous state-of-the-art approach, indicating that ASR errors
may contain valuable cues related to dementia. The synergy between ASR and
classification models improved overall accuracy in dementia classification.
<br />\textbf{Conclusion}: Imperfect ASR transcripts effectively capture linguistic
anomalies linked to dementia, improving accuracy in classification tasks. This
synergy between ASR and classification models underscores ASR's potential as a
valuable tool in assessing cognitive impairment and related clinical
applications.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05553" title="Abstract">arXiv:2401.05553</a> [<a href="/pdf/2401.05553" title="Download PDF">pdf</a>, <a href="/ps/2401.05553" title="Download PostScript">ps</a>, <a href="/format/2401.05553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization by linear kinetic equations and mean-field Langevin  dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pareschi%2C+L">Lorenzo Pareschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Statistical Mechanics (cond-mat.stat-mech)

</div>
<p class="mathjax">Probably one of the most striking examples of the close connections between
global optimization processes and statistical physics is the simulated
annealing method, inspired by the famous Monte Carlo algorithm devised by
Metropolis et al. in the middle of the last century. In this paper we show how
the tools of linear kinetic theory allow to describe this gradient-free
algorithm from the perspective of statistical physics and how convergence to
the global minimum can be related to classical entropy inequalities. This
analysis highlight the strong link between linear Boltzmann equations and
stochastic optimization methods governed by Markov processes. Thanks to this
formalism we can establish the connections between the simulated annealing
process and the corresponding mean-field Langevin dynamics characterized by a
stochastic gradient descent approach. Generalizations to other selection
strategies in simulated annealing that avoid the acceptance-rejection dynamic
are also provided.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05554" title="Abstract">arXiv:2401.05554</a> [<a href="/pdf/2401.05554" title="Download PDF">pdf</a>, <a href="/ps/2401.05554" title="Download PostScript">ps</a>, <a href="/format/2401.05554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising the take-off dynamics and energy efficiency in  spring-driven jumping robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+J">John Lo</a>, 
<a href="/search/cs?searchtype=author&query=Parslew%2C+B">Ben Parslew</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">Previous design methodologies for spring-driven jumping robots focused on
jump height optimization for specific tasks. In doing so, numerous designs have
been proposed including using nonlinear spring-linkages to increase the elastic
energy storage and jump height. However, these systems can never achieve their
theoretical maximum jump height due to taking off before the spring energy is
fully released, resulting in an incomplete transfer of stored elastic energy to
gravitational potential energy. This paper presents low-order models aimed at
characterising the energy conversion during the acceleration phase of jumping.
It also proposes practical solutions for increasing the energy efficiency of
jumping robots. A dynamic analysis is conducted on a multibody system comprised
of rotational links, which is experimentally validated using a physical
demonstrator. The analysis reveals that inefficient energy conversion is
attributed to inertial effects caused by rotational and unsprung masses. Since
these masses cannot be entirely eliminated from a physical linkage, a practical
approach to improving energy efficiency involves structural redesign to reduce
structural mass and moments of inertia while maintaining compliance with
structural strength and stiffness requirements.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05558" title="Abstract">arXiv:2401.05558</a> [<a href="/pdf/2401.05558" title="Download PDF">pdf</a>, <a href="/format/2401.05558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From geometry to generating functions: rectangulations and permutations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asinowski%2C+A">Andrei Asinowski</a>, 
<a href="/search/cs?searchtype=author&query=Banderier%2C+C">Cyril Banderier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Geometry (cs.CG); Formal Languages and Automata Theory (cs.FL); Combinatorics (math.CO)

</div>
<p class="mathjax">We enumerate several classes of pattern-avoiding rectangulations. We
establish bijective links with pattern-avoiding permutations, prove that their
generating functions are algebraic, and confirm several conjectures by Merino
and M\"utze. We also analyze a new class of rectangulations, called whirls,
using a generating tree.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05561" title="Abstract">arXiv:2401.05561</a> [<a href="/pdf/2401.05561" title="Download PDF">pdf</a>, <a href="/format/2401.05561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrustLLM: Trustworthiness in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Siyuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chujie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+W">Wenhan Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiner Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhengliang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yixin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yijue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhikun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chaowei Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+E">Eric Xing</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Furong Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+H">Heng Ji</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Huaxiu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Kellis%2C+M">Manolis Kellis</a>, 
<a href="/search/cs?searchtype=author&query=Zitnik%2C+M">Marinka Zitnik</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Meng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+M">Mohit Bansal</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+J">Jian Pei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jianfeng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jieyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiliang Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jindong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+J">John Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Backes%2C+M">Michael Backes</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+N+Z">Neil Zhenqiang Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Q">Quanquan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+R">Rex Ying</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Jana%2C+S">Suman Jana</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Willian Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xuyu Wang</a>,  et al. (4 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is still under work and we welcome your contribution
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs), exemplified by ChatGPT, have gained
considerable attention for their excellent natural language processing
capabilities. Nonetheless, these LLMs present many challenges, particularly in
the realm of trustworthiness. Therefore, ensuring the trustworthiness of LLMs
emerges as an important topic. This paper introduces TrustLLM, a comprehensive
study of trustworthiness in LLMs, including principles for different dimensions
of trustworthiness, established benchmark, evaluation, and analysis of
trustworthiness for mainstream LLMs, and discussion of open challenges and
future directions. Specifically, we first propose a set of principles for
trustworthy LLMs that span eight different dimensions. Based on these
principles, we further establish a benchmark across six dimensions including
truthfulness, safety, fairness, robustness, privacy, and machine ethics. We
then present a study evaluating 16 mainstream LLMs in TrustLLM, consisting of
over 30 datasets. Our findings firstly show that in general trustworthiness and
utility (i.e., functional effectiveness) are positively related. Secondly, our
observations reveal that proprietary LLMs generally outperform most open-source
counterparts in terms of trustworthiness, raising concerns about the potential
risks of widely accessible open-source LLMs. However, a few open-source LLMs
come very close to proprietary ones. Thirdly, it is important to note that some
LLMs may be overly calibrated towards exhibiting trustworthiness, to the extent
that they compromise their utility by mistakenly treating benign prompts as
harmful and consequently not responding. Finally, we emphasize the importance
of ensuring transparency not only in the models themselves but also in the
technologies that underpin trustworthiness. Knowing the specific trustworthy
technologies that have been employed is crucial for analyzing their
effectiveness.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05562" title="Abstract">arXiv:2401.05562</a> [<a href="/pdf/2401.05562" title="Download PDF">pdf</a>, <a href="/ps/2401.05562" title="Download PostScript">ps</a>, <a href="/format/2401.05562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brave: Byzantine-Resilient and Privacy-Preserving Peer-to-Peer Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhangchen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+F">Fengqing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+L">Luyao Niu</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+J">Jinyuan Jia</a>, 
<a href="/search/cs?searchtype=author&query=Poovendran%2C+R">Radha Poovendran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated learning (FL) enables multiple participants to train a global
machine learning model without sharing their private training data.
Peer-to-peer (P2P) FL advances existing centralized FL paradigms by eliminating
the server that aggregates local models from participants and then updates the
global model. However, P2P FL is vulnerable to (i) honest-but-curious
participants whose objective is to infer private training data of other
participants, and (ii) Byzantine participants who can transmit arbitrarily
manipulated local models to corrupt the learning process. P2P FL schemes that
simultaneously guarantee Byzantine resilience and preserve privacy have been
less studied. In this paper, we develop Brave, a protocol that ensures
Byzantine Resilience And privacy-preserving property for P2P FL in the presence
of both types of adversaries. We show that Brave preserves privacy by
establishing that any honest-but-curious adversary cannot infer other
participants' private data by observing their models. We further prove that
Brave is Byzantine-resilient, which guarantees that all benign participants
converge to an identical model that deviates from a global model trained
without Byzantine adversaries by a bounded distance. We evaluate Brave against
three state-of-the-art adversaries on a P2P FL for image classification tasks
on benchmark datasets CIFAR10 and MNIST. Our results show that the global model
learned with Brave in the presence of adversaries achieves comparable
classification accuracy to a global model trained in the absence of any
adversary.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05563" title="Abstract">arXiv:2401.05563</a> [<a href="/pdf/2401.05563" title="Download PDF">pdf</a>, <a href="/format/2401.05563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparency as Delayed Observability in Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dwarakanath%2C+K">Kshama Dwarakanath</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>, 
<a href="/search/cs?searchtype=author&query=Oyebode%2C+T">Toks Oyebode</a>, 
<a href="/search/cs?searchtype=author&query=Balch%2C+T">Tucker Balch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Is transparency always beneficial in complex systems such as traffic networks
and stock markets? How is transparency defined in multi-agent systems, and what
is its optimal degree at which social welfare is highest? We take an
agent-based view to define transparency (or its lacking) as delay in agent
observability of environment states, and utilize simulations to analyze the
impact of delay on social welfare. To model the adaptation of agent strategies
with varying delays, we model agents as learners maximizing the same objectives
under different delays in a simulated environment. Focusing on two agent types
- constrained and unconstrained, we use multi-agent reinforcement learning to
evaluate the impact of delay on agent outcomes and social welfare. Empirical
demonstration of our framework in simulated financial markets shows opposing
trends in outcomes of the constrained and unconstrained agents with delay, with
an optimal partial transparency regime at which social welfare is maximal.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05566" title="Abstract">arXiv:2401.05566</a> [<a href="/pdf/2401.05566" title="Download PDF">pdf</a>, <a href="/format/2401.05566" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sleeper Agents: Training Deceptive LLMs that Persist Through Safety  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hubinger%2C+E">Evan Hubinger</a>, 
<a href="/search/cs?searchtype=author&query=Denison%2C+C">Carson Denison</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+J">Jesse Mu</a>, 
<a href="/search/cs?searchtype=author&query=Lambert%2C+M">Mike Lambert</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=MacDiarmid%2C+M">Monte MacDiarmid</a>, 
<a href="/search/cs?searchtype=author&query=Lanham%2C+T">Tamera Lanham</a>, 
<a href="/search/cs?searchtype=author&query=Ziegler%2C+D+M">Daniel M. Ziegler</a>, 
<a href="/search/cs?searchtype=author&query=Maxwell%2C+T">Tim Maxwell</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+N">Newton Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Jermyn%2C+A">Adam Jermyn</a>, 
<a href="/search/cs?searchtype=author&query=Askell%2C+A">Amanda Askell</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+A">Ansh Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Anil%2C+C">Cem Anil</a>, 
<a href="/search/cs?searchtype=author&query=Duvenaud%2C+D">David Duvenaud</a>, 
<a href="/search/cs?searchtype=author&query=Ganguli%2C+D">Deep Ganguli</a>, 
<a href="/search/cs?searchtype=author&query=Barez%2C+F">Fazl Barez</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J">Jack Clark</a>, 
<a href="/search/cs?searchtype=author&query=Ndousse%2C+K">Kamal Ndousse</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+K">Kshitij Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Sellitto%2C+M">Michael Sellitto</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+M">Mrinank Sharma</a>, 
<a href="/search/cs?searchtype=author&query=DasSarma%2C+N">Nova DasSarma</a>, 
<a href="/search/cs?searchtype=author&query=Grosse%2C+R">Roger Grosse</a>, 
<a href="/search/cs?searchtype=author&query=Kravec%2C+S">Shauna Kravec</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yuntao Bai</a>, 
<a href="/search/cs?searchtype=author&query=Witten%2C+Z">Zachary Witten</a>, 
<a href="/search/cs?searchtype=author&query=Favaro%2C+M">Marina Favaro</a>, 
<a href="/search/cs?searchtype=author&query=Brauner%2C+J">Jan Brauner</a>, 
<a href="/search/cs?searchtype=author&query=Karnofsky%2C+H">Holden Karnofsky</a>, 
<a href="/search/cs?searchtype=author&query=Christiano%2C+P">Paul Christiano</a>, 
<a href="/search/cs?searchtype=author&query=Bowman%2C+S+R">Samuel R. Bowman</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+L">Logan Graham</a>, 
<a href="/search/cs?searchtype=author&query=Kaplan%2C+J">Jared Kaplan</a>, 
<a href="/search/cs?searchtype=author&query=Mindermann%2C+S">S&#xf6;ren Mindermann</a>, 
<a href="/search/cs?searchtype=author&query=Greenblatt%2C+R">Ryan Greenblatt</a>, 
<a href="/search/cs?searchtype=author&query=Shlegeris%2C+B">Buck Shlegeris</a>, 
<a href="/search/cs?searchtype=author&query=Schiefer%2C+N">Nicholas Schiefer</a>, 
<a href="/search/cs?searchtype=author&query=Perez%2C+E">Ethan Perez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)

</div>
<p class="mathjax">Humans are capable of strategically deceptive behavior: behaving helpfully in
most situations, but then behaving very differently in order to pursue
alternative objectives when given the opportunity. If an AI system learned such
a deceptive strategy, could we detect it and remove it using current
state-of-the-art safety training techniques? To study this question, we
construct proof-of-concept examples of deceptive behavior in large language
models (LLMs). For example, we train models that write secure code when the
prompt states that the year is 2023, but insert exploitable code when the
stated year is 2024. We find that such backdoored behavior can be made
persistent, so that it is not removed by standard safety training techniques,
including supervised fine-tuning, reinforcement learning, and adversarial
training (eliciting unsafe behavior and then training to remove it). The
backdoored behavior is most persistent in the largest models and in models
trained to produce chain-of-thought reasoning about deceiving the training
process, with the persistence remaining even when the chain-of-thought is
distilled away. Furthermore, rather than removing backdoors, we find that
adversarial training can teach models to better recognize their backdoor
triggers, effectively hiding the unsafe behavior. Our results suggest that,
once a model exhibits deceptive behavior, standard techniques could fail to
remove such deception and create a false impression of safety.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05569" title="Abstract">arXiv:2401.05569</a> [<a href="/pdf/2401.05569" title="Download PDF">pdf</a>, <a href="/format/2401.05569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SENet: Visual Detection of Online Social Engineering Attack Campaigns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozen%2C+I">Irfan Ozen</a>, 
<a href="/search/cs?searchtype=author&query=Subramani%2C+K">Karthika Subramani</a>, 
<a href="/search/cs?searchtype=author&query=Vadrevu%2C+P">Phani Vadrevu</a>, 
<a href="/search/cs?searchtype=author&query=Perdisci%2C+R">Roberto Perdisci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Social engineering (SE) aims at deceiving users into performing actions that
may compromise their security and privacy. These threats exploit weaknesses in
human's decision making processes by using tactics such as pretext, baiting,
impersonation, etc. On the web, SE attacks include attack classes such as
scareware, tech support scams, survey scams, sweepstakes, etc., which can
result in sensitive data leaks, malware infections, and monetary loss. For
instance, US consumers lose billions of dollars annually due to various SE
attacks. Unfortunately, generic social engineering attacks remain understudied,
compared to other important threats, such as software vulnerabilities and
exploitation, network intrusions, malicious software, and phishing. The few
existing technical studies that focus on social engineering are limited in
scope and mostly focus on measurements rather than developing a generic
defense. To fill this gap, we present SEShield, a framework for in-browser
detection of social engineering attacks. SEShield consists of three main
components: (i) a custom security crawler, called SECrawler, that is dedicated
to scouting the web to collect examples of in-the-wild SE attacks; (ii) SENet,
a deep learning-based image classifier trained on data collected by SECrawler
that aims to detect the often glaring visual traits of SE attack pages; and
(iii) SEGuard, a proof-of-concept extension that embeds SENet into the web
browser and enables real-time SE attack detection. We perform an extensive
evaluation of our system and show that SENet is able to detect new instances of
SE attacks with a detection rate of up to 99.6% at 1% false positive, thus
providing an effective first defense against SE attacks on the web.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05570" title="Abstract">arXiv:2401.05570</a> [<a href="/pdf/2401.05570" title="Download PDF">pdf</a>, <a href="/format/2401.05570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Siamese Networks with Soft Labels for Unsupervised Lesion Detection and  Patch Pretraining on Screening Mammograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Vorst%2C+K">Kevin Van Vorst</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Li Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Self-supervised learning has become a popular way to pretrain a deep learning
model and then transfer it to perform downstream tasks. However, most of these
methods are developed on large-scale image datasets that contain natural
objects with clear textures, outlines, and distinct color contrasts. It remains
uncertain whether these methods are equally effective for medical imaging,
where the regions of interest often blend subtly and indistinctly with the
surrounding tissues. In this study, we propose an alternative method that uses
contralateral mammograms to train a neural network to encode similar embeddings
when a pair contains both normal images and different embeddings when a pair
contains normal and abnormal images. Our approach leverages the natural
symmetry of human body as weak labels to learn to distinguish abnormal lesions
from background tissues in a fully unsupervised manner. Our findings suggest
that it's feasible by incorporating soft labels derived from the Euclidean
distances between the embeddings of the image pairs into the Siamese network
loss. Our method demonstrates superior performance in mammogram patch
classification compared to existing self-supervised learning methods. This
approach not only leverages a vast amount of image data effectively but also
minimizes reliance on costly labels, a significant advantage particularly in
the field of medical imaging.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05572" title="Abstract">arXiv:2401.05572</a> [<a href="/pdf/2401.05572" title="Download PDF">pdf</a>, <a href="/format/2401.05572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by the 38th AAAI 2024 workshop: "Cooperative Multi-Agent Systems Decision-Making and Learning: From Individual Needs to Swarm Intelligence"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)

</div>
<p class="mathjax">Innate values describe agents' intrinsic motivations, which reflect their
inherent interests and preferences to pursue goals and drive them to develop
diverse skills satisfying their various needs. The essence of reinforcement
learning (RL) is learning from interaction based on reward-driven (such as
utilities) behaviors, much like natural agents. It is an excellent model to
describe the innate-values-driven (IV) behaviors of AI agents. Especially in
multi-agent systems (MAS), building the awareness of AI agents to balance the
group utilities and system costs and satisfy group members' needs in their
cooperation is a crucial problem for individuals learning to support their
community and integrate human society in the long term. This paper proposes a
hierarchical compound intrinsic value reinforcement learning model --
innate-values-driven reinforcement learning termed IVRL to describe the complex
behaviors of multi-agent interaction in their cooperation. We implement the
IVRL architecture in the StarCraft Multi-Agent Challenge (SMAC) environment and
compare the cooperative performance within three characteristics of innate
value agents (Coward, Neutral, and Reckless) through three benchmark
multi-agent RL algorithms: QMIX, IQL, and QTRAN. The results demonstrate that
by organizing individual various needs rationally, the group can achieve better
performance with lower costs effectively.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05577" title="Abstract">arXiv:2401.05577</a> [<a href="/pdf/2401.05577" title="Download PDF">pdf</a>, <a href="/format/2401.05577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLP: Vision Language Planning for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chenbin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+B">Burhaneddin Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Nesti%2C+T">Tommaso Nesti</a>, 
<a href="/search/cs?searchtype=author&query=Mallik%2C+A">Abhirup Mallik</a>, 
<a href="/search/cs?searchtype=author&query=Allievi%2C+A+G">Alessandro G Allievi</a>, 
<a href="/search/cs?searchtype=author&query=Velipasalar%2C+S">Senem Velipasalar</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+L">Liu Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Autonomous driving is a complex and challenging task that aims at safe motion
planning through scene understanding and reasoning. While vision-only
autonomous driving methods have recently achieved notable performance, through
enhanced scene understanding, several key issues, including lack of reasoning,
low generalization performance and long-tail scenarios, still need to be
addressed. In this paper, we present VLP, a novel Vision-Language-Planning
framework that exploits language models to bridge the gap between linguistic
understanding and autonomous driving. VLP enhances autonomous driving systems
by strengthening both the source memory foundation and the self-driving car's
contextual understanding. VLP achieves state-of-the-art end-to-end planning
performance on the challenging NuScenes dataset by achieving 35.9\% and 60.5\%
reduction in terms of average L2 error and collision rates, respectively,
compared to the previous best method. Moreover, VLP shows improved performance
in challenging long-tail scenarios and strong generalization capabilities when
faced with new urban environments.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05578" title="Abstract">arXiv:2401.05578</a> [<a href="/pdf/2401.05578" title="Download PDF">pdf</a>, <a href="/ps/2401.05578" title="Download PostScript">ps</a>, <a href="/format/2401.05578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Cerebral Blood Flow Analysis via Extreme Learning Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+Z">Zhenya Zang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">David Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We introduce a rapid and precise analytical approach for analyzing cerebral
blood flow (CBF) using Diffuse Correlation Spectroscopy (DCS) with the
application of the Extreme Learning Machine (ELM). Our evaluation of ELM and
existing algorithms involves a comprehensive set of metrics. We assess these
algorithms using synthetic datasets for both semi-infinite and multi-layer
models. The results demonstrate that ELM consistently achieves higher fidelity
across various noise levels and optical parameters, showcasing robust
generalization ability and outperforming iterative fitting algorithms. Through
a comparison with a computationally efficient neural network, ELM attains
comparable accuracy with reduced training and inference times. Notably, the
absence of a back-propagation process in ELM during training results in
significantly faster training speeds compared to existing neural network
approaches. This proposed strategy holds promise for edge computing
applications with online training capabilities.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05579" title="Abstract">arXiv:2401.05579</a> [<a href="/pdf/2401.05579" title="Download PDF">pdf</a>, <a href="/format/2401.05579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Augmented Surprise-guided Sequential Learning Framework for  Predicting the Melt Pool Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raihan%2C+A+S">Ahmed Shoyeb Raihan</a>, 
<a href="/search/cs?searchtype=author&query=Khosravi%2C+H">Hamed Khosravi</a>, 
<a href="/search/cs?searchtype=author&query=Bhuiyan%2C+T+H">Tanveer Hossain Bhuiyan</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Imtiaz Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Metal Additive Manufacturing (MAM) has reshaped the manufacturing industry,
offering benefits like intricate design, minimal waste, rapid prototyping,
material versatility, and customized solutions. However, its full industry
adoption faces hurdles, particularly in achieving consistent product quality. A
crucial aspect for MAM's success is understanding the relationship between
process parameters and melt pool characteristics. Integrating Artificial
Intelligence (AI) into MAM is essential. Traditional machine learning (ML)
methods, while effective, depend on large datasets to capture complex
relationships, a significant challenge in MAM due to the extensive time and
resources required for dataset creation. Our study introduces a novel
surprise-guided sequential learning framework, SurpriseAF-BO, signaling a
significant shift in MAM. This framework uses an iterative, adaptive learning
process, modeling the dynamics between process parameters and melt pool
characteristics with limited data, a key benefit in MAM's cyber manufacturing
context. Compared to traditional ML models, our sequential learning method
shows enhanced predictive accuracy for melt pool dimensions. Further improving
our approach, we integrated a Conditional Tabular Generative Adversarial
Network (CTGAN) into our framework, forming the CT-SurpriseAF-BO. This produces
synthetic data resembling real experimental data, improving learning
effectiveness. This enhancement boosts predictive precision without requiring
additional physical experiments. Our study demonstrates the power of advanced
data-driven techniques in cyber manufacturing and the substantial impact of
sequential AI and ML, particularly in overcoming MAM's traditional challenges.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05580" title="Abstract">arXiv:2401.05580</a> [<a href="/pdf/2401.05580" title="Download PDF">pdf</a>, <a href="/ps/2401.05580" title="Download PostScript">ps</a>, <a href="/format/2401.05580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Blood Flow Assessment in Diffuse Correlation Spectroscopy: A  Transfer Learning Approach with Noise Robustness Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xingda Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">David Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Diffuse correlation spectroscopy (DCS) is an emerging noninvasive technique
that measures the tissue blood flow, by using near-infrared coherent
point-source illumination to detect spectral changes. While machine learning
has demonstrated significant potential for measuring blood flow index (BFi), an
open question concerning the success of this approach pertains to its
robustness in scenarios involving deviations between datasets with varying
Signal-to-Noise Ratios (SNRs) originating from diverse clinical applications
and various setups. This study proposes a transfer learning approach, aims to
assess the influence of SNRs on the generalization ability of learned features,
and demonstrate the robustness for transfer learning. A synthetic dataset with
varying levels of added noise is utilized to simulate different SNRs. The
proposed network takes a 1x64 autocorrelation curve as input and generates BFi
and the correlation parameter beta. The proposed model demonstrates excellent
performance across different SNRs, exhibiting enhanced fitting accuracy,
particularly for low SNR datasets when compared with other fitting methods.
This highlights its potential for clinical diagnosis and treatment across
various scenarios under different clinical setups.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05583" title="Abstract">arXiv:2401.05583</a> [<a href="/pdf/2401.05583" title="Download PDF">pdf</a>, <a href="/format/2401.05583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Priors for Dynamic View Synthesis from Monocular Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+P">Peiye Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Siarohin%2C+A">Aliaksandr Siarohin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junli Cao</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+G">Guocheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hsin-Ying Lee</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Dynamic novel view synthesis aims to capture the temporal evolution of visual
content within videos. Existing methods struggle to distinguishing between
motion and structure, particularly in scenarios where camera poses are either
unknown or constrained compared to object motion. Furthermore, with information
solely from reference images, it is extremely challenging to hallucinate unseen
regions that are occluded or partially observed in the given videos. To address
these issues, we first finetune a pretrained RGB-D diffusion model on the video
frames using a customization technique. Subsequently, we distill the knowledge
from the finetuned model to a 4D representations encompassing both dynamic and
static Neural Radiance Fields (NeRF) components. The proposed pipeline achieves
geometric consistency while preserving the scene identity. We perform thorough
experiments to evaluate the efficacy of the proposed method qualitatively and
quantitatively. Our results demonstrate the robustness and utility of our
approach in challenging cases, further advancing dynamic novel view synthesis.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05584" title="Abstract">arXiv:2401.05584</a> [<a href="/pdf/2401.05584" title="Download PDF">pdf</a>, <a href="/ps/2401.05584" title="Download PostScript">ps</a>, <a href="/format/2401.05584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FourCastNeXt: Improving FourCastNet Training with Limited Compute
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+E">Edison Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+M">Maruf Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mahendru%2C+R">Rahul Mahendru</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cook%2C+H">Harrison Cook</a>, 
<a href="/search/cs?searchtype=author&query=Leeuwenburg%2C+T">Tennessee Leeuwenburg</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+B">Ben Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, the FourCastNet Neural Earth System Model (NESM) has shown
impressive results on predicting various atmospheric variables, trained on the
ERA5 reanalysis dataset. While FourCastNet enjoys quasi-linear time and memory
complexity in sequence length compared to quadratic complexity in vanilla
transformers, training FourCastNet on ERA5 from scratch still requires large
amount of compute resources, which is expensive or even inaccessible to most
researchers. In this work, we will show improved methods that can train
FourCastNet using only 1% of the compute required by the baseline, while
maintaining model performance or par or even better than the baseline.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05585" title="Abstract">arXiv:2401.05585</a> [<a href="/pdf/2401.05585" title="Download PDF">pdf</a>, <a href="/ps/2401.05585" title="Download PostScript">ps</a>, <a href="/format/2401.05585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Technical Report: Time-Bounded Resilience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kirigin%2C+T+B">Tajana Ban Kirigin</a>, 
<a href="/search/cs?searchtype=author&query=Comer%2C+J">Jesse Comer</a>, 
<a href="/search/cs?searchtype=author&query=Kanovich%2C+M">Max Kanovich</a>, 
<a href="/search/cs?searchtype=author&query=Scedrov%2C+A">Andre Scedrov</a>, 
<a href="/search/cs?searchtype=author&query=Talcott%2C+C">Carolyn Talcott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Most research on formal system design has focused on optimizing various
measures of efficiency. However, insufficient attention has been given to the
design of systems optimizing resilience, the ability of systems to adapt to
unexpected changes or adversarial disruptions. In our prior work, we formalized
the intuitive notion of resilience as a property of cyber-physical systems by
using a multiset rewriting language with explicit time. In the present work, we
study the computational complexity of a formalization of time-bounded
resilience problems for the class of progressing timed systems (PTS), where,
intuitively, only a finite number of actions can be carried out in a bounded
time period. We show that, in the time-bounded model with n (potentially
adversarially chosen) updates, the corresponding time-bounded resilience
problem is complete for the $\Sigma^P_{2n+1}$ class of the polynomial
hierarchy, PH. To support the formal models and complexity results, we perform
automated experiments for time-bounded verification using the rewriting logic
tool Maude.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05587" title="Abstract">arXiv:2401.05587</a> [<a href="/pdf/2401.05587" title="Download PDF">pdf</a>, <a href="/format/2401.05587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Making Informed Decisions: Supporting Cobot Integration Considering  Business and Worker Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sullivan%2C+D">Dakota Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+N+T">Nathan Thomas White</a>, 
<a href="/search/cs?searchtype=author&query=Schoen%2C+A">Andrew Schoen</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+B">Bilge Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures. To be published in Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction (HRI '24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robots are ubiquitous in small-to-large-scale manufacturers. While
collaborative robots (cobots) have significant potential in these settings due
to their flexibility and ease of use, proper integration is critical to realize
their full potential. Specifically, cobots need to be integrated in ways that
utilize their strengths, improve manufacturing performance, and facilitate use
in concert with human workers. Effective integration requires careful
consideration and the knowledge of roboticists, manufacturing engineers, and
business administrators. We propose an approach involving the stages of
planning, analysis, development, and presentation, to inform manufacturers
about cobot integration within their facilities prior to the integration
process. We contextualize our approach in a case study with an SME collaborator
and discuss insights learned.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05593" title="Abstract">arXiv:2401.05593</a> [<a href="/pdf/2401.05593" title="Download PDF">pdf</a>, <a href="/format/2401.05593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reverse Projection: Real-Time Local Space Texture Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lim%2C+A+X+W">Adrian Xuan Wei Lim</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+C">Conor Griffin</a>, 
<a href="/search/cs?searchtype=author&query=Kyger%2C+N">Nicholas Kyger</a>, 
<a href="/search/cs?searchtype=author&query=Baghernezhad%2C+F">Faraz Baghernezhad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present Reverse Projection, a novel projective texture mapping technique
for painting a decal directly to the texture of a 3D object. Designed to be
used in games, this technique works in real-time. By using projection
techniques that are computed in local space textures and outward-looking, users
using low-end android devices to high-end gaming desktops are able to enjoy the
personalization of their assets. We believe our proposed pipeline is a step in
improving the speed and versatility of model painting.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05594" title="Abstract">arXiv:2401.05594</a> [<a href="/pdf/2401.05594" title="Download PDF">pdf</a>, <a href="/format/2401.05594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Distance-based Expansion of Low-Density Latent Regions for  Unknown Class Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mallick%2C+P">Prakash Mallick</a>, 
<a href="/search/cs?searchtype=author&query=Dayoub%2C+F">Feras Dayoub</a>, 
<a href="/search/cs?searchtype=author&query=Sherrah%2C+J">Jamie Sherrah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Full length pages, followed by 2 supplementary pages, total of 9 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the significant challenge in open-set object detection
(OSOD): the tendency of state-of-the-art detectors to erroneously classify
unknown objects as known categories with high confidence. We present a novel
approach that effectively identifies unknown objects by distinguishing between
high and low-density regions in latent space. Our method builds upon the
Open-Det (OD) framework, introducing two new elements to the loss function.
These elements enhance the known embedding space's clustering and expand the
unknown space's low-density regions. The first addition is the Class
Wasserstein Anchor (CWA), a new function that refines the classification
boundaries. The second is a spectral normalisation step, improving the
robustness of the model. Together, these augmentations to the existing
Contrastive Feature Learner (CFL) and Unknown Probability Learner (UPL) loss
functions significantly improve OSOD performance. Our proposed OpenDet-CWA
(OD-CWA) method demonstrates: a) a reduction in open-set errors by
approximately 17%-22%, b) an enhancement in novelty detection capability by
1.5%-16%, and c) a decrease in the wilderness index by 2%-20% across various
open-set scenarios. These results represent a substantial advancement in the
field, showcasing the potential of our approach in managing the complexities of
open-set object detection.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05596" title="Abstract">arXiv:2401.05596</a> [<a href="/pdf/2401.05596" title="Download PDF">pdf</a>, <a href="/ps/2401.05596" title="Download PostScript">ps</a>, <a href="/format/2401.05596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource  Unsupervised Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shilong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Z">Zhiliang Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Liang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zhihua Wen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Dongsheng Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Low-resource languages (LRLs) face challenges in supervised neural machine
translation due to limited parallel data, prompting research into unsupervised
methods. Unsupervised neural machine translation (UNMT) methods, including
back-translation, transfer learning, and pivot-based translation, offer
practical solutions for LRL translation, but they are hindered by issues like
synthetic data noise, language bias, and error propagation, which can
potentially be mitigated by Large Language Models (LLMs). LLMs have advanced
NMT with in-context learning (ICL) and supervised fine-tuning methods, but
insufficient training data results in poor performance in LRLs. We argue that
LLMs can mitigate the linguistic noise with auxiliary languages to improve
translations in LRLs. In this paper, we propose Probability-driven Meta-graph
Prompter (POMP), a novel approach employing a dynamic, sampling-based graph of
multiple auxiliary languages to enhance LLMs' translation capabilities for
LRLs. POMP involves constructing a directed acyclic meta-graph for each source
language, from which we dynamically sample multiple paths to prompt LLMs to
mitigate the linguistic noise and improve translations during training. We use
the BLEURT metric to evaluate the translations and back-propagate rewards,
estimated by scores, to update the probabilities of auxiliary languages in the
paths. Our experiments show significant improvements in the translation quality
of three LRLs, demonstrating the effectiveness of our approach.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05602" title="Abstract">arXiv:2401.05602</a> [<a href="/pdf/2401.05602" title="Download PDF">pdf</a>, <a href="/ps/2401.05602" title="Download PostScript">ps</a>, <a href="/format/2401.05602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nucleus subtype classification using inter-modality learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Remedios%2C+L+W">Lucas W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+S">Shunxing Bao</a>, 
<a href="/search/cs?searchtype=author&query=Remedios%2C+S+W">Samuel W. Remedios</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+H">Ho Hin Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+L+Y">Leon Y. Cai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Thomas Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Ruining Deng</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Can Cui</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lau%2C+K+S">Ken S. Lau</a>, 
<a href="/search/cs?searchtype=author&query=Roland%2C+J+T">Joseph T. Roland</a>, 
<a href="/search/cs?searchtype=author&query=Washington%2C+M+K">Mary K. Washington</a>, 
<a href="/search/cs?searchtype=author&query=Coburn%2C+L+A">Lori A. Coburn</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+K+T">Keith T. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Huo%2C+Y">Yuankai Huo</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding the way cells communicate, co-locate, and interrelate is
essential to understanding human physiology. Hematoxylin and eosin (H&amp;E)
staining is ubiquitously available both for clinical studies and research. The
Colon Nucleus Identification and Classification (CoNIC) Challenge has recently
innovated on robust artificial intelligence labeling of six cell types on H&amp;E
stains of the colon. However, this is a very small fraction of the number of
potential cell classification types. Specifically, the CoNIC Challenge is
unable to classify epithelial subtypes (progenitor, endocrine, goblet),
lymphocyte subtypes (B, helper T, cytotoxic T), or connective subtypes
(fibroblasts, stromal). In this paper, we propose to use inter-modality
learning to label previously un-labelable cell types on virtual H&amp;E. We
leveraged multiplexed immunofluorescence (MxIF) histology imaging to identify
14 subclasses of cell types. We performed style transfer to synthesize virtual
H&amp;E from MxIF and transferred the higher density labels from MxIF to these
virtual H&amp;E images. We then evaluated the efficacy of learning in this
approach. We identified helper T and progenitor nuclei with positive predictive
values of $0.34 \pm 0.15$ (prevalence $0.03 \pm 0.01$) and $0.47 \pm 0.1$
(prevalence $0.07 \pm 0.02$) respectively on virtual H&amp;E. This approach
represents a promising step towards automating annotation in digital pathology.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05603" title="Abstract">arXiv:2401.05603</a> [<a href="/pdf/2401.05603" title="Download PDF">pdf</a>, <a href="/ps/2401.05603" title="Download PostScript">ps</a>, <a href="/format/2401.05603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring How FoMO, Social Media Addiction, and Subjective Norms  Influence Personal Moderation Configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhaver%2C+S">Shagun Jhaver</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Personal moderation tools on social media platforms allow users to control
their feeds by configuring the acceptable toxicity thresholds for their feed
content or muting inappropriate accounts. This research examines how the
end-user configuration of these tools is shaped by four critical psychosocial
factors - fear of missing out (FoMO), social media addiction, subjective norms,
and trust in moderation systems. Findings from a nationally representative
sample of 1,061 participants show that FoMO and social media addiction make
Facebook users more vulnerable to content-based harms by reducing their
likelihood of adopting personal moderation tools to hide inappropriate posts.
In contrast, descriptive and injunctive norms positively influence the use of
these tools. Further, trust in Facebook's moderation systems also significantly
affects users' engagement with personal moderation. This analysis highlights
qualitatively different pathways through which FoMO and social media addiction
make affected users disproportionately unsafe and offers design and policy
solutions to address this challenge.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05604" title="Abstract">arXiv:2401.05604</a> [<a href="/pdf/2401.05604" title="Download PDF">pdf</a>, <a href="/format/2401.05604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REBUS: A Robust Evaluation Benchmark of Understanding Symbols
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gritsevskiy%2C+A">Andrew Gritsevskiy</a>, 
<a href="/search/cs?searchtype=author&query=Panickssery%2C+A">Arjun Panickssery</a>, 
<a href="/search/cs?searchtype=author&query=Kirtland%2C+A">Aaron Kirtland</a>, 
<a href="/search/cs?searchtype=author&query=Kauffman%2C+D">Derik Kauffman</a>, 
<a href="/search/cs?searchtype=author&query=Gundlach%2C+H">Hans Gundlach</a>, 
<a href="/search/cs?searchtype=author&query=Gritsevskaya%2C+I">Irina Gritsevskaya</a>, 
<a href="/search/cs?searchtype=author&query=Cavanagh%2C+J">Joe Cavanagh</a>, 
<a href="/search/cs?searchtype=author&query=Chiang%2C+J">Jonathan Chiang</a>, 
<a href="/search/cs?searchtype=author&query=La+Roux%2C+L">Lydia La Roux</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+M">Michelle Hung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 5 figures. For code, see <a href="http://github.com/cvndsh/rebus">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY)

</div>
<p class="mathjax">We propose a new benchmark evaluating the performance of multimodal large
language models on rebus puzzles. The dataset covers 333 original examples of
image-based wordplay, cluing 13 categories such as movies, composers, major
cities, and food. To achieve good performance on the benchmark of identifying
the clued word or phrase, models must combine image recognition and string
manipulation with hypothesis testing, multi-step reasoning, and an
understanding of human cognition, making for a complex, multimodal evaluation
of capabilities. We find that proprietary models such as GPT-4V and Gemini Pro
significantly outperform all other tested models. However, even the best model
has a final accuracy of just 24%, highlighting the need for substantial
improvements in reasoning. Further, models rarely understand all parts of a
puzzle, and are almost always incapable of retroactively explaining the correct
answer. Our benchmark can therefore be used to identify major shortcomings in
the knowledge and reasoning of multimodal large language models.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05605" title="Abstract">arXiv:2401.05605</a> [<a href="/pdf/2401.05605" title="Download PDF">pdf</a>, <a href="/format/2401.05605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws for Forgetting When Fine-Tuning Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kalajdzievski%2C+D">Damjan Kalajdzievski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study and quantify the problem of forgetting when fine-tuning pre-trained
large language models (LLMs) on a downstream task. We find that
parameter-efficient fine-tuning (PEFT) strategies, such as Low-Rank Adapters
(LoRA), still suffer from catastrophic forgetting. In particular, we identify a
strong inverse linear relationship between the fine-tuning performance and the
amount of forgetting when fine-tuning LLMs with LoRA. We further obtain precise
scaling laws that show forgetting increases as a shifted power law in the
number of parameters fine-tuned and the number of update steps. We also examine
the impact of forgetting on knowledge, reasoning, and the safety guardrails
trained into Llama 2 7B chat. Our study suggests that forgetting cannot be
avoided through early stopping or by varying the number of parameters
fine-tuned. We believe this opens up an important safety-critical direction for
future research to evaluate and develop fine-tuning schemes which mitigate
forgetting
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05609" title="Abstract">arXiv:2401.05609</a> [<a href="/pdf/2401.05609" title="Download PDF">pdf</a>, <a href="/ps/2401.05609" title="Download PostScript">ps</a>, <a href="/format/2401.05609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A cable finite element formulation based on exact tension field for  static nonlinear analysis of cable structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qikun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Suiyin Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper introduces a cable finite element model based on an accurate
description of the tension field for the static nonlinear analysis of cable
structures. The proposed cable element is developed using the geometrically
exact beam model that adequately considers the effects of large displacements.
By neglecting flexural stiffness and shear deformation, the formulation of the
cable finite element for scenarios involving given unstrained length and
undetermined unstrained length is respectively presented. Additionally, the
implementations of solutions based on complete tangent matrix and element
internal iteration are introduced. Numerical examples are conducted to validate
the accuracy of the presented formulation for cable analysis under various
conditions and to demonstrate the computational efficiency of the proposed
element and solution method. The results indicate that the proposed cable
finite element not only exhibits extremely high accuracy but also effectively
addresses the problem of determining the cable state with an unknown unstrained
length, demonstrating the wide applicability of the proposed element. Through
the utilization of an iteration algorithm with arc-length control and the
introduction of additional control conditions, the proposed cable finite
element can be further utilized to solve complex practical engineering
problems.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05610" title="Abstract">arXiv:2401.05610</a> [<a href="/pdf/2401.05610" title="Download PDF">pdf</a>, <a href="/format/2401.05610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Q-Learning for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dax%2C+V+M">Victoria M. Dax</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Leahy%2C+K">Kevin Leahy</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> GLIndA Workshop NeurIPS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph-structured data is ubiquitous throughout natural and social sciences,
and Graph Neural Networks (GNNs) have recently been shown to be effective at
solving prediction and inference problems on graph data. In this paper, we
propose and demonstrate that GNNs can be applied to solve Combinatorial
Optimization (CO) problems. CO concerns optimizing a function over a discrete
solution space that is often intractably large. To learn to solve CO problems,
we formulate the optimization process as a sequential decision making problem,
where the return is related to how close the candidate solution is to
optimality. We use a GNN to learn a policy to iteratively build increasingly
promising candidate solutions. We present preliminary evidence that GNNs
trained through Q-Learning can solve CO problems with performance approaching
state-of-the-art heuristic-based solvers, using only a fraction of the
parameters and training time.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05612" title="Abstract">arXiv:2401.05612</a> [<a href="/pdf/2401.05612" title="Download PDF">pdf</a>, <a href="/format/2401.05612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing for Appropriate Reliance:Designing for Appropriate Reliance:  The Roles of AI Uncertainty Presentation, Initial User Decision, and User  Demographics in AI-Assisted Decision-Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shiye Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CSCW2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Appropriate reliance is critical to achieving synergistic human-AI
collaboration. For instance, when users over-rely on AI assistance, their
human-AI team performance is bounded by the model's capability. This work
studies how the presentation of model uncertainty may steer users'
decision-making toward fostering appropriate reliance. Our results demonstrate
that showing the calibrated model uncertainty alone is inadequate. Rather,
calibrating model uncertainty and presenting it in a frequency format allow
users to adjust their reliance accordingly and help reduce the effect of
confirmation bias on their decisions. Furthermore, the critical nature of our
skin cancer screening task skews participants' judgment, causing their reliance
to vary depending on their initial decision. Additionally, step-wise multiple
regression analyses revealed how user demographics such as age and familiarity
with probability and statistics influence human-AI collaborative
decision-making. We discuss the potential for model uncertainty presentation,
initial user decision, and user demographics to be incorporated in designing
personalized AI aids for appropriate reliance.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05614" title="Abstract">arXiv:2401.05614</a> [<a href="/pdf/2401.05614" title="Download PDF">pdf</a>, <a href="/ps/2401.05614" title="Download PostScript">ps</a>, <a href="/format/2401.05614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Attention and Hybrid Features for Replay and Deep-Fake Audio  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Due to the successful application of deep learning, audio spoofing detection
has made significant progress. Spoofed audio with speech synthesis or voice
conversion can be well detected by many countermeasures. However, an automatic
speaker verification system is still vulnerable to spoofing attacks such as
replay or Deep-Fake audio. Deep-Fake audio means that the spoofed utterances
are generated using text-to-speech (TTS) and voice conversion (VC) algorithms.
Here, we propose a novel framework based on hybrid features with the
self-attention mechanism. It is expected that hybrid features can be used to
get more discrimination capacity. Firstly, instead of only one type of
conventional feature, deep learning features and Mel-spectrogram features will
be extracted by two parallel paths: convolution neural networks and a
short-time Fourier transform (STFT) followed by Mel-frequency. Secondly,
features will be concatenated by a max-pooling layer. Thirdly, there is a
Self-attention mechanism for focusing on essential elements. Finally, ResNet
and a linear layer are built to get the results. Experimental results reveal
that the hybrid features, compared with conventional features, can cover more
details of an utterance. We achieve the best Equal Error Rate (EER) of 9.67\%
in the physical access (PA) scenario and 8.94\% in the Deep fake task on the
ASVspoof 2021 dataset. Compared with the best baseline system, the proposed
approach improves by 74.60\% and 60.05\%, respectively.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05618" title="Abstract">arXiv:2401.05618</a> [<a href="/pdf/2401.05618" title="Download PDF">pdf</a>, <a href="/format/2401.05618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Benefits of a Concise Chain of Thought on Problem-Solving in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Renze%2C+M">Matthew Renze</a>, 
<a href="/search/cs?searchtype=author&query=Guven%2C+E">Erhan Guven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> All code, data, and supplemental materials are available on GitHub at <a href="https://github.com/matthewrenze/jhu-concise-cot">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this paper, we introduce Concise Chain-of-Thought (CCoT) prompting. We
compared standard CoT and CCoT prompts to see how conciseness impacts response
length and correct-answer accuracy. We evaluated this using GPT-3.5 and GPT-4
with a multiple-choice question-and-answer (MCQA) benchmark. CCoT reduced
average response length by 48.70% for both GPT-3.5 and GPT-4 while having a
negligible impact on problem-solving performance. However, on math problems,
GPT-3.5 with CCoT incurs a performance penalty of 27.69%. Overall, CCoT leads
to an average per-token cost reduction of 22.67%. These results have practical
implications for AI systems engineers using LLMs to solve real-world problems
with CoT prompt-engineering techniques. In addition, these results provide more
general insight for AI researchers studying the emergent behavior of
step-by-step reasoning in LLMs.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05624" title="Abstract">arXiv:2401.05624</a> [<a href="/pdf/2401.05624" title="Download PDF">pdf</a>, <a href="/ps/2401.05624" title="Download PostScript">ps</a>, <a href="/format/2401.05624" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Spectral Element Method for the Euler Equations on Unbounded  Domains in Multiple Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Tissaoui%2C+Y">Yassine Tissaoui</a>, 
<a href="/search/math?searchtype=author&query=Kelly%2C+J+F">James F. Kelly</a>, 
<a href="/search/math?searchtype=author&query=Marras%2C+S">Simone Marras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">Mitigating the impact of waves leaving a numerical domain has been a
persistent challenge in numerical modeling. Reducing wave reflection at the
domain boundary is crucial for accurate simulations. Absorbing layers, while
common, often incur significant computational costs. This paper introduces an
efficient application of a Legendre-Laguerre basis for absorbing layers for
two-dimensional non-linear compressible Euler equations. The method couples a
spectral-element bounded domain with a semi-infinite region, employing a tensor
product of Lagrange and scaled Laguerre basis functions. The semi-infinite
region serves as an absorbing layer for our simulations. In comparison to
existing methods with similar absorbing layer extensions, our approach, a
pioneering application to the Euler equations, demonstrates substantial
computational savings. The study marks the first application of semi-infinite
elements to mitigate wave reflection in the solution of the Euler equations,
particularly in nonhydrostatic atmospheric modeling. A comprehensive set of
tests demonstrates the method's versatility for general systems of conservation
laws, with a focus on its effectiveness in damping vertically propagating
gravity waves in a linear hydrostatic mountain simulation a benchmark for
atmospheric models. Across all tests, our model consistently exhibits notable
performance improvements compared to a traditional Rayleigh damping approach.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05625" title="Abstract">arXiv:2401.05625</a> [<a href="/pdf/2401.05625" title="Download PDF">pdf</a>, <a href="/format/2401.05625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Face-GPS: A Comprehensive Technique for Quantifying Facial Muscle  Dynamics in Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juni Kim</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhikang Dong</a>, 
<a href="/search/cs?searchtype=author&query=Polak%2C+P">Pawel Polak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce a novel method that combines differential geometry, kernels
smoothing, and spectral analysis to quantify facial muscle activity from widely
accessible video recordings, such as those captured on personal smartphones.
Our approach emphasizes practicality and accessibility. It has significant
potential for applications in national security and plastic surgery.
Additionally, it offers remote diagnosis and monitoring for medical conditions
such as stroke, Bell's palsy, and acoustic neuroma. Moreover, it is adept at
detecting and classifying emotions, from the overt to the subtle. The proposed
face muscle analysis technique is an explainable alternative to deep learning
methods and a non-invasive substitute to facial electromyography (fEMG).
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05626" title="Abstract">arXiv:2401.05626</a> [<a href="/pdf/2401.05626" title="Download PDF">pdf</a>, <a href="/format/2401.05626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Composable Dynamic Sparse Dataflow Architecture for Efficient  Event-based Vision Processing on FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yizhao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baoheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuhao Ding</a>, 
<a href="/search/cs?searchtype=author&query=So%2C+H+K">Hayden Kwok-Hay So</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to FPGA'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Event-based vision represents a paradigm shift in how vision information is
captured and processed. By only responding to dynamic intensity changes in the
scene, event-based sensing produces far less data than conventional frame-based
cameras, promising to springboard a new generation of high-speed, low-power
machines for edge intelligence. However, processing such dynamically sparse
input originated from event cameras efficiently in real time, particularly with
complex deep neural networks (DNN), remains a formidable challenge. Existing
solutions that employ GPUs and other frame-based DNN accelerators often
struggle to efficiently process the dynamically sparse event data, missing the
opportunities to improve processing efficiency with sparse data. To address
this, we propose ESDA, a composable dynamic sparse dataflow architecture that
allows customized DNN accelerators to be constructed rapidly on FPGAs for
event-based vision tasks. ESDA is a modular system that is composed of a set of
parametrizable modules for each network layer type. These modules share a
uniform sparse token-feature interface and can be connected easily to compose
an all-on-chip dataflow accelerator on FPGA for each network model. To fully
exploit the intrinsic sparsity in event data, ESDA incorporates the use of
submanifold sparse convolutions that largely enhance the activation sparsity
throughout the layers while simplifying hardware implementation. Finally, a
network architecture and hardware implementation co-optimizing framework that
allows tradeoffs between accuracy and performance is also presented.
Experimental results demonstrate that when compared with existing GPU and
hardware-accelerated solutions, ESDA achieves substantial speedup and
improvement in energy efficiency across different applications, and it allows
much wider design space for real-world deployments.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05627" title="Abstract">arXiv:2401.05627</a> [<a href="/pdf/2401.05627" title="Download PDF">pdf</a>, <a href="/format/2401.05627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deterministic Near-Linear Time Minimum Cut in Weighted Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henzinger%2C+M">Monika Henzinger</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jason Li</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+S">Satish Rao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SODA 2024, 60 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In 1996, Karger [Kar96] gave a startling randomized algorithm that finds a
minimum-cut in a (weighted) graph in time $O(m\log^3n)$ which he termed
near-linear time meaning linear (in the size of the input) times a
polylogarthmic factor. In this paper, we give the first deterministic algorithm
which runs in near-linear time for weighted graphs.
<br />Previously, the breakthrough results of Kawarabayashi and Thorup [KT19] gave
a near-linear time algorithm for simple graphs. The main technique here is a
clustering procedure that perfectly preserves minimum cuts. Recently, Li [Li21]
gave an $m^{1+o(1)}$ deterministic minimum-cut algorithm for weighted graphs;
this form of running time has been termed "almost-linear''. Li uses
almost-linear time deterministic expander decompositions which do not perfectly
preserve minimum cuts, but he can use these clusterings to, in a sense,
"derandomize'' the methods of Karger.
<br />In terms of techniques, we provide a structural theorem that says there
exists a sparse clustering that preserves minimum cuts in a weighted graph with
$o(1)$ error. In addition, we construct it deterministically in near linear
time. This was done exactly for simple graphs in [KT19, HRW20] and with
polylogarithmic error for weighted graphs in [Li21]. Extending the techniques
in [KT19, HRW20] to weighted graphs presents significant challenges, and
moreover, the algorithm can only polylogarithmically approximately preserve
minimum cuts. A remaining challenge is to reduce the
polylogarithmic-approximate clusterings to $1+o(1/\log n)$-approximate so that
they can be applied recursively as in [Li21] over $O(\log n)$ many levels. This
is an additional challenge that requires building on properties of
tree-packings in the presence of a wide range of edge weights to, for example,
find sources for local flow computations which identify minimum cuts that cross
clusters.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05628" title="Abstract">arXiv:2401.05628</a> [<a href="/pdf/2401.05628" title="Download PDF">pdf</a>, <a href="/format/2401.05628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Multi-Source Directed Reachability via Shortcuts and Matrix  Multiplication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkin%2C+M">Michael Elkin</a>, 
<a href="/search/cs?searchtype=author&query=Trehan%2C+C">Chhaya Trehan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a set $S \subseteq V$,
$|S| = n^{\sigma}$ (for some $0 &lt; \sigma \le 1$) of designated sources, the $S
\times V$-direcahability problem is to compute for every $s \in S$, the set of
all the vertices reachable from $s$ in $G$. Known naive algorithms for this
problem either run a BFS/DFS separately from every source, and as a result
require $O(m \cdot n^{\sigma})$ time, or compute the transitive closure of $G$
in $\tilde O(n^{\omega})$ time, where $\omega &lt; 2.371552\ldots$ is the matrix
multiplication exponent. Hence, the current state-of-the-art bound for the
problem on graphs with $m = \Theta(n^{\mu})$ edges in $\tilde O(n^{\min \{\mu +
\sigma, \omega \}})$. Our first contribution is an algorithm with running time
$\tilde O(n^{1 + \tiny{\frac{2}{3}} \omega(\sigma)})$ for this problem, where
$\omega(\sigma)$ is the rectangular matrix multiplication exponent. Using
current state-of-the-art estimates on $\omega(\sigma)$, our exponent is better
than $\min \{2 + \sigma, \omega \}$ for $\tilde \sigma \le \sigma \le 0.53$,
where $1/3 &lt; \tilde \sigma &lt; 0.3336$ is a universal constant.
<br />Our second contribution is a sequence of algorithms $\mathcal A_0, \mathcal
A_1, \mathcal A_2, \ldots$ for the $S \times V$-direachability problem. We
argue that under a certain assumption that we introduce, for every $\tilde
\sigma \le \sigma &lt; 1$, there exists a sufficiently large index $k = k(\sigma)$
so that $\mathcal A_k$ improves upon the current state-of-the-art bounds for $S
\times V$-direachability with $|S| = n^{\sigma}$, in the densest regime $\mu
=2$. We show that to prove this assumption, it is sufficient to devise an
algorithm that computes a rectangular max-min matrix product roughly as
efficiently as ordinary $(+, \cdot)$ matrix product.
<br />Our algorithms heavily exploit recent constructions of directed shortcuts by
Kogan and Parter.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05629" title="Abstract">arXiv:2401.05629</a> [<a href="/pdf/2401.05629" title="Download PDF">pdf</a>, <a href="/format/2401.05629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Performance-Oriented Control Barrier Functions Under Complex  Safety Constraints and Limited Actuation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaoru Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fazlyab%2C+M">Mahyar Fazlyab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was submitted to L4DC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Control Barrier Functions (CBFs) provide an elegant framework for designing
safety filters for nonlinear control systems by constraining their trajectories
to an invariant subset of a prespecified safe set. However, the task of finding
a CBF that concurrently maximizes the volume of the resulting control invariant
set while accommodating complex safety constraints, particularly in high
relative degree systems with actuation constraints, continues to pose a
substantial challenge. In this work, we propose a novel self-supervised
learning framework that holistically addresses these hurdles. Given a Boolean
composition of multiple state constraints that define the safe set, our
approach starts with building a single continuously differentiable function
whose 0-superlevel set provides an inner approximation of the safe set. We then
use this function together with a smooth neural network to parameterize the CBF
candidate. Finally, we design a training loss function based on a
Hamilton-Jacobi partial differential equation to train the CBF while enlarging
the volume of the induced control invariant set. We demonstrate the
effectiveness of our approach via numerical experiments.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05631" title="Abstract">arXiv:2401.05631</a> [<a href="/pdf/2401.05631" title="Download PDF">pdf</a>, <a href="/format/2401.05631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DrawTalking: Building Interactive Worlds by Sketching and Speaking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+K+T">Karl Toby Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Kazi%2C+R+H">Rubaiat Habib Kazi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Li-Yi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+H">Haijun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Perlin%2C+K">Ken Perlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Graphics (cs.GR)

</div>
<p class="mathjax">We introduce an interactive approach, DrawTalking, in which the user builds
interactive worlds by sketching and speaking. It emphasizes user control and
flexibility, and gives programming-like capability without code. We implemented
it on the iPad. An open-ended study shows the mechanics resonate and are
applicable to many creative-exploratory use cases. We hope to inspire and
inform research in future natural user-centered interfaces.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05632" title="Abstract">arXiv:2401.05632</a> [<a href="/pdf/2401.05632" title="Download PDF">pdf</a>, <a href="/format/2401.05632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language Processing for Dialects of a Language: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joshi%2C+A">Aditya Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Dabre%2C+R">Raj Dabre</a>, 
<a href="/search/cs?searchtype=author&query=Kanojia%2C+D">Diptesh Kanojia</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+H">Haolan Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>, 
<a href="/search/cs?searchtype=author&query=Dippold%2C+D">Doris Dippold</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper is under review at ACM Computing Surveys. Please reach out to the authors in the case of feedback
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">State-of-the-art natural language processing (NLP) models are trained on
massive training corpora, and report a superlative performance on evaluation
datasets. This survey delves into an important attribute of these datasets: the
dialect of a language. Motivated by the performance degradation of NLP models
for dialectic datasets and its implications for the equity of language
technologies, we survey past research in NLP for dialects in terms of datasets,
and approaches. We describe a wide range of NLP tasks in terms of two
categories: natural language understanding (NLU) (for tasks such as dialect
classification, sentiment analysis, parsing, and NLU benchmarks) and natural
language generation (NLG) (for summarisation, machine translation, and dialogue
systems). The survey is also broad in its coverage of languages which include
English, Arabic, German among others. We observe that past work in NLP
concerning dialects goes deeper than mere dialect classification, and . This
includes early approaches that used sentence transduction that lead to the
recent approaches that integrate hypernetworks into LoRA. We expect that this
survey will be useful to NLP researchers interested in building equitable
language technologies by rethinking LLM benchmarks and model architectures.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05633" title="Abstract">arXiv:2401.05633</a> [<a href="/pdf/2401.05633" title="Download PDF">pdf</a>, <a href="/format/2401.05633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transforming Image Super-Resolution: A ConvFormer-based Efficient  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Gang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junpeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitting to TIP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Recent progress in single-image super-resolution (SISR) has achieved
remarkable performance, yet the computational costs of these methods remain a
challenge for deployment on resource-constrained devices. Especially for
transformer-based methods, the self-attention mechanism in such models brings
great breakthroughs while incurring substantial computational costs. To tackle
this issue, we introduce the Convolutional Transformer layer (ConvFormer) and
the ConvFormer-based Super-Resolution network (CFSR), which offer an effective
and efficient solution for lightweight image super-resolution tasks. In detail,
CFSR leverages the large kernel convolution as the feature mixer to replace the
self-attention module, efficiently modeling long-range dependencies and
extensive receptive fields with a slight computational cost. Furthermore, we
propose an edge-preserving feed-forward network, simplified as EFN, to obtain
local feature aggregation and simultaneously preserve more high-frequency
information. Extensive experiments demonstrate that CFSR can achieve an
advanced trade-off between computational cost and performance when compared to
existing lightweight SR methods. Compared to state-of-the-art methods, e.g.
ShuffleMixer, the proposed CFSR achieves 0.39 dB gains on Urban100 dataset for
x2 SR task while containing 26% and 31% fewer parameters and FLOPs,
respectively. Code and pre-trained models are available at
https://github.com/Aitical/CFSR.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05638" title="Abstract">arXiv:2401.05638</a> [<a href="/pdf/2401.05638" title="Download PDF">pdf</a>, <a href="/format/2401.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatSAM: Efficient Materials Microstructure Extraction via Visual Large  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changtai Li</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xu Han</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Chao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Ban%2C+X">Xiaojuan Ban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 6 figures, initial version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate and efficient extraction of microstructures in microscopic images of
materials plays a critical role in the exploration of structure-property
relationships and the optimization of process parameters. Deep learning-based
image segmentation techniques that rely on manual annotation are time-consuming
and labor-intensive and hardly meet the demand for model transferability and
generalization. Segment Anything Model (SAM), a large visual model with
powerful deep feature representation and zero-shot generalization capabilities,
has provided new solutions for image segmentation. However, directly applying
SAM to segmenting microstructures in microscopic images of materials without
human annotation cannot achieve the expected results, as the difficulty of
adapting its native prompt engineering to the dense and dispersed
characteristics of key microstructures in materials microscopy images. In this
paper, we propose MatSAM, a general and efficient microstructure extraction
solution based on SAM. A new point-based prompts generation strategy is
designed, grounded on the distribution and shape of materials microstructures.
It generates prompts for different microscopic images, fuses the prompts of the
region of interest (ROI) key points and grid key points, and integrates
post-processing methods for quantitative characterization of materials
microstructures. For common microstructures including grain boundary and phase,
MatSAM achieves superior segmentation performance to conventional methods and
is even preferable to supervised learning methods evaluated on 18 materials
microstructures imaged by the optical microscope (OM) and scanning electron
microscope (SEM). We believe that MatSAM can significantly reduce the cost of
quantitative characterization of materials microstructures and accelerate the
design of new materials.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05639" title="Abstract">arXiv:2401.05639</a> [<a href="/pdf/2401.05639" title="Download PDF">pdf</a>, <a href="/format/2401.05639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-State Prescribed Performance-Based Consensus of Double-Integrator  Multi-Agent Systems with Jointly Connected Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hou%2C+Y">Yahui Hou</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+B">Bin Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the full-state prescribed performance-based consensus
problem for double-integrator multi-agent systems with jointly connected
topologies. To improve the transient performance, a distributed prescribed
performance control protocol consisting of the transformed relative position
and the transformed relative velocity is proposed, where the communication
topology satisfies the jointly connected assumption. Different from the
existing literatures, two independent transient performance specifications
imposed on relative positions and relative velocities can be guaranteed
simultaneously. A numerical example is ultimately used to validate the
effectiveness of proposed protocol.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05641" title="Abstract">arXiv:2401.05641</a> [<a href="/pdf/2401.05641" title="Download PDF">pdf</a>, <a href="/format/2401.05641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When eBPF Meets Machine Learning: On-the-fly OS Kernel  Compartmentalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tiejin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Q">Qinrun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yueqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Q">Qingkai Zeng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Compartmentalization effectively prevents initial corruption from turning
into a successful attack. This paper presents O2C, a pioneering system designed
to enforce OS kernel compartmentalization on the fly. It not only provides
immediate remediation for sudden threats but also maintains consistent system
availability through the enforcement process.
<br />O2C is empowered by the newest advancements of the eBPF ecosystem which
allows to instrument eBPF programs that perform enforcement actions into the
kernel at runtime. O2C takes the lead in embedding a machine learning model
into eBPF programs, addressing unique challenges in on-the-fly
compartmentalization. Our comprehensive evaluation shows that O2C effectively
confines damage within the compartment. Further, we validate that decision tree
is optimally suited for O2C owing to its advantages in processing tabular data,
its explainable nature, and its compliance with the eBPF ecosystem. Last but
not least, O2C is lightweight, showing negligible overhead and excellent
sacalability system-wide.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05642" title="Abstract">arXiv:2401.05642</a> [<a href="/pdf/2401.05642" title="Download PDF">pdf</a>, <a href="/format/2401.05642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Prediction of Synchronization-Reversal Data Races
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zheng Shi</a>, 
<a href="/search/cs?searchtype=author&query=Mathur%2C+U">Umang Mathur</a>, 
<a href="/search/cs?searchtype=author&query=Pavlogiannis%2C+A">Andreas Pavlogiannis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICSE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Dynamic data race detection has emerged as a key technique for ensuring
reliability of concurrent software in practice. However, dynamic approaches can
often miss data races owing to nondeterminism in the thread scheduler.
Predictive race detection techniques cater to this shortcoming by inferring
alternate executions that may expose data races without re-executing the
underlying program. More formally, the dynamic data race prediction problem
asks, given a trace \sigma of an execution of a concurrent program, can \sigma
be correctly reordered to expose a data race? Existing state-of-the art
techniques for data race prediction either do not scale to executions arising
from real world concurrent software, or only expose a limited class of data
races, such as those that can be exposed without reversing the order of
synchronization operations.
<br />In general, exposing data races by reasoning about synchronization reversals
is an intractable problem. In this work, we identify a class of data races,
called Optimistic Sync(hronization)-Reversal races that can be detected in a
tractable manner and often include non-trivial data races that cannot be
exposed by prior tractable techniques. We also propose a sound algorithm OSR
for detecting all optimistic sync-reversal data races in overall quadratic
time, and show that the algorithm is optimal by establishing a matching lower
bound. Our experiments demonstrate the effectiveness of OSR on our extensive
suite of benchmarks, OSR reports the largest number of data races, and scales
well to large execution traces.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05646" title="Abstract">arXiv:2401.05646</a> [<a href="/pdf/2401.05646" title="Download PDF">pdf</a>, <a href="/format/2401.05646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Attribute Description Embedding for Cloth-Changing Person  Re-identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Chunlei Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Boyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Decheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Nannan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Ruimin Hu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinbo Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, 52 references, submitted to CVPR 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Cloth-changing person re-identification (CC-ReID) aims to match persons who
change clothes over long periods. The key challenge in CC-ReID is to extract
clothing-independent features, such as face, hairstyle, body shape, and gait.
Current research mainly focuses on modeling body shape using multi-modal
biological features (such as silhouettes and sketches). However, it does not
fully leverage the personal description information hidden in the original RGB
image. Considering that there are certain attribute descriptions which remain
unchanged after the changing of cloth, we propose a Masked Attribute
Description Embedding (MADE) method that unifies personal visual appearance and
attribute description for CC-ReID. Specifically, handling variable
clothing-sensitive information, such as color and type, is challenging for
effective modeling. To address this, we mask the clothing and color information
in the personal attribute description extracted through an attribute detection
model. The masked attribute description is then connected and embedded into
Transformer blocks at various levels, fusing it with the low-level to
high-level features of the image. This approach compels the model to discard
clothing information. Experiments are conducted on several CC-ReID benchmarks,
including PRCC, LTCC, Celeb-reID-light, and LaST. Results demonstrate that MADE
effectively utilizes attribute description, enhancing cloth-changing person
re-identification performance, and compares favorably with state-of-the-art
methods. The code is available at https://github.com/moon-wh/MADE.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05650" title="Abstract">arXiv:2401.05650</a> [<a href="/pdf/2401.05650" title="Download PDF">pdf</a>, <a href="/format/2401.05650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Detecting Cherry-picking in News Coverage Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaradat%2C+I">Israa Jaradat</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengkai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Cherry-picking refers to the deliberate selection of evidence or facts that
favor a particular viewpoint while ignoring or distorting evidence that
supports an opposing perspective. Manually identifying instances of
cherry-picked statements in news stories can be challenging, particularly when
the opposing viewpoint's story is absent. This study introduces Cherry, an
innovative approach for automatically detecting cherry-picked statements in
news articles by finding missing important statements in the target news story.
Cherry utilizes the analysis of news coverage from multiple sources to identify
instances of cherry-picking. Our approach relies on language models that
consider contextual information from other news sources to classify statements
based on their importance to the event covered in the target news story.
Furthermore, this research introduces a novel dataset specifically designed for
cherry-picking detection, which was used to train and evaluate the performance
of the models. Our best performing model achieves an F-1 score of about %89 in
detecting important statements when tested on unseen set of news stories.
Moreover, results show the importance incorporating external knowledge from
alternative unbiased narratives when assessing a statement's importance.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05653" title="Abstract">arXiv:2401.05653</a> [<a href="/pdf/2401.05653" title="Download PDF">pdf</a>, <a href="/ps/2401.05653" title="Download PostScript">ps</a>, <a href="/format/2401.05653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantifying Marketing Performance at Channel-Partner Level by Using  Marketing Mix Modeling (MMM) and Shapley Value Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Sean Tang</a>, 
<a href="/search/cs?searchtype=author&query=Musunuru%2C+S">Sriya Musunuru</a>, 
<a href="/search/cs?searchtype=author&query=Zong%2C+B">Baoshi Zong</a>, 
<a href="/search/cs?searchtype=author&query=Thornton%2C+B">Brooks Thornton</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper explores the application of Shapley Value Regression in dissecting
marketing performance at channel-partner level, complementing channel-level
Marketing Mix Modeling (MMM). Utilizing real-world data from the financial
services industry, we demonstrate the practicality of Shapley Value Regression
in evaluating individual partner contributions. Although structured in-field
testing along with cooperative game theory is most accurate, it can often be
highly complex and expensive to conduct. Shapley Value Regression is thus a
more feasible approach to disentangle the influence of each marketing partner
within a marketing channel. We also propose a simple method to derive adjusted
coefficients of Shapley Value Regression and compares it with alternative
approaches.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05654" title="Abstract">arXiv:2401.05654</a> [<a href="/pdf/2401.05654" title="Download PDF">pdf</a>, <a href="/format/2401.05654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Conversational Diagnostic AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+T">Tao Tu</a>, 
<a href="/search/cs?searchtype=author&query=Palepu%2C+A">Anil Palepu</a>, 
<a href="/search/cs?searchtype=author&query=Schaekermann%2C+M">Mike Schaekermann</a>, 
<a href="/search/cs?searchtype=author&query=Saab%2C+K">Khaled Saab</a>, 
<a href="/search/cs?searchtype=author&query=Freyberg%2C+J">Jan Freyberg</a>, 
<a href="/search/cs?searchtype=author&query=Tanno%2C+R">Ryutaro Tanno</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Amy Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Brenna Li</a>, 
<a href="/search/cs?searchtype=author&query=Amin%2C+M">Mohamed Amin</a>, 
<a href="/search/cs?searchtype=author&query=Tomasev%2C+N">Nenad Tomasev</a>, 
<a href="/search/cs?searchtype=author&query=Azizi%2C+S">Shekoofeh Azizi</a>, 
<a href="/search/cs?searchtype=author&query=Singhal%2C+K">Karan Singhal</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yong Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Le Hou</a>, 
<a href="/search/cs?searchtype=author&query=Webson%2C+A">Albert Webson</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+K">Kavita Kulkarni</a>, 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+S+S">S Sara Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=Semturs%2C+C">Christopher Semturs</a>, 
<a href="/search/cs?searchtype=author&query=Gottweis%2C+J">Juraj Gottweis</a>, 
<a href="/search/cs?searchtype=author&query=Barral%2C+J">Joelle Barral</a>, 
<a href="/search/cs?searchtype=author&query=Chou%2C+K">Katherine Chou</a>, 
<a href="/search/cs?searchtype=author&query=Corrado%2C+G+S">Greg S Corrado</a>, 
<a href="/search/cs?searchtype=author&query=Matias%2C+Y">Yossi Matias</a>, 
<a href="/search/cs?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+V">Vivek Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 5 figures in main text, 19 figures in appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">At the heart of medicine lies the physician-patient dialogue, where skillful
history-taking paves the way for accurate diagnosis, effective management, and
enduring trust. Artificial Intelligence (AI) systems capable of diagnostic
dialogue could increase accessibility, consistency, and quality of care.
However, approximating clinicians' expertise is an outstanding grand challenge.
Here, we introduce AMIE (Articulate Medical Intelligence Explorer), a Large
Language Model (LLM) based AI system optimized for diagnostic dialogue.
<br />AMIE uses a novel self-play based simulated environment with automated
feedback mechanisms for scaling learning across diverse disease conditions,
specialties, and contexts. We designed a framework for evaluating
clinically-meaningful axes of performance including history-taking, diagnostic
accuracy, management reasoning, communication skills, and empathy. We compared
AMIE's performance to that of primary care physicians (PCPs) in a randomized,
double-blind crossover study of text-based consultations with validated patient
actors in the style of an Objective Structured Clinical Examination (OSCE). The
study included 149 case scenarios from clinical providers in Canada, the UK,
and India, 20 PCPs for comparison with AMIE, and evaluations by specialist
physicians and patient actors. AMIE demonstrated greater diagnostic accuracy
and superior performance on 28 of 32 axes according to specialist physicians
and 24 of 26 axes according to patient actors. Our research has several
limitations and should be interpreted with appropriate caution. Clinicians were
limited to unfamiliar synchronous text-chat which permits large-scale
LLM-patient interactions but is not representative of usual clinical practice.
While further research is required before AMIE could be translated to
real-world settings, the results represent a milestone towards conversational
diagnostic AI.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05655" title="Abstract">arXiv:2401.05655</a> [<a href="/pdf/2401.05655" title="Download PDF">pdf</a>, <a href="/ps/2401.05655" title="Download PostScript">ps</a>, <a href="/format/2401.05655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling the Tapestry of Automated Essay Scoring: A Comprehensive  Investigation of Accuracy, Fairness, and Generalizability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaixun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Rakovi%C4%87%2C+M">Mladen Rakovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+Q">Quanlong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Ga%C5%A1evi%C4%87%2C+D">Dragan Ga&#x161;evi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guanliang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Automatic Essay Scoring (AES) is a well-established educational pursuit that
employs machine learning to evaluate student-authored essays. While much effort
has been made in this area, current research primarily focuses on either (i)
boosting the predictive accuracy of an AES model for a specific prompt (i.e.,
developing prompt-specific models), which often heavily relies on the use of
the labeled data from the same target prompt; or (ii) assessing the
applicability of AES models developed on non-target prompts to the intended
target prompt (i.e., developing the AES models in a cross-prompt setting).
Given the inherent bias in machine learning and its potential impact on
marginalized groups, it is imperative to investigate whether such bias exists
in current AES methods and, if identified, how it intervenes with an AES
model's accuracy and generalizability. Thus, our study aimed to uncover the
intricate relationship between an AES model's accuracy, fairness, and
generalizability, contributing practical insights for developing effective AES
models in real-world education. To this end, we meticulously selected nine
prominent AES methods and evaluated their performance using seven metrics on an
open-sourced dataset, which contains over 25,000 essays and various demographic
information about students such as gender, English language learner status, and
economic status. Through extensive evaluations, we demonstrated that: (1)
prompt-specific models tend to outperform their cross-prompt counterparts in
terms of predictive accuracy; (2) prompt-specific models frequently exhibit a
greater bias towards students of different economic statuses compared to
cross-prompt models; (3) in the pursuit of generalizability, traditional
machine learning models coupled with carefully engineered features hold greater
potential for achieving both high accuracy and fairness than complex neural
network models.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05659" title="Abstract">arXiv:2401.05659</a> [<a href="/pdf/2401.05659" title="Download PDF">pdf</a>, <a href="/format/2401.05659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engineering Adaptive Information Graphics for Disabled Communities: A  Case Study with Public Space Indoor Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madugalla%2C+A">Anuradha Madugalla</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yutan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+M+H">Min Hee Cho</a>, 
<a href="/search/cs?searchtype=author&query=Gamage%2C+L+K">Lasith Koswatta Gamage</a>, 
<a href="/search/cs?searchtype=author&query=Leao%2C+T">Tristan Leao</a>, 
<a href="/search/cs?searchtype=author&query=Thiele%2C+S">Sam Thiele</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Most software applications contain graphics such as charts, diagrams and
maps. Currently, these graphics are designed with a ``one size fits all"
approach and do not cater to the needs of people with disabilities. Therefore,
when using software with graphics, a colour-impaired user may struggle to
interpret graphics with certain colours, and a person with dyslexia may
struggle to read the text labels in the graphic. Our research addresses this
issue by developing a framework that generates adaptive and accessible
information graphics for multiple disabilities. Uniquely, the approach also
serves people with multiple simultaneous disabilities. To achieve these, we
used a case study of public space floorplans presented via a web tool and
worked with four disability groups: people with low vision, colour blindness,
dyslexia and mobility impairment. Our research involved gathering requirements
from 3 accessibility experts and 80 participants with disabilities, developing
a system to generate adaptive graphics that address the identified
requirements, and conducting an evaluation with 7 participants with
disabilities. The evaluation showed that users found our solution easy to use
and suitable for most of their requirements. The study also provides
recommendations for front-end developers on engineering accessible graphics for
their software and discusses the implications of our work on society from the
perspective of public space owners and end users.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05661" title="Abstract">arXiv:2401.05661</a> [<a href="/pdf/2401.05661" title="Download PDF">pdf</a>, <a href="/format/2401.05661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intersection properties of finite disk collections
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Espinoza%2C+J+F">Jes&#xfa;s F. Espinoza</a>, 
<a href="/search/cs?searchtype=author&query=Esquer-P%C3%A9rez%2C+C+G">Cynthia G. Esquer-P&#xe9;rez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">In this work we study the intersection properties of a finite disk system in
the euclidean space. We accomplish this by utilizing subsets of spheres with
varying dimensions and analyze specific points within them, referred to as
poles. Additionally, we introduce two applications: estimating the common scale
factor for the radii that makes the re-scaled disks intersects in a single
point, this is the \v{C}ech scale, and constructing the minimal Axis-Aligned
Bounding Box (AABB) that encloses the intersection of all disks in the system.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05664" title="Abstract">arXiv:2401.05664</a> [<a href="/pdf/2401.05664" title="Download PDF">pdf</a>, <a href="/format/2401.05664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Root Cause Analysis on Energy Efficiency with Transfer Entropy Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Energy efficiency is a big concern in industrial sectors. Finding the root
cause of anomaly state of energy efficiency can help to improve energy
efficiency of industrial systems and therefore save energy cost. In this
research, we propose to use transfer entropy (TE) for root cause analysis on
energy efficiency of industrial systems. A method, called TE flow, is proposed
in that a TE flow from physical measurements of each subsystem to the energy
efficiency indicator along timeline is considered as causal strength for
diagnosing root cause of anomaly states of energy efficiency of a system. The
copula entropy-based nonparametric TE estimator is used in the proposed method.
We conducted experiments on real data collected from a compressing air system
to verify the proposed method. Experimental results show that the TE flow
method successfully identified the root cause of the energy (in)efficiency of
the system.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05665" title="Abstract">arXiv:2401.05665</a> [<a href="/pdf/2401.05665" title="Download PDF">pdf</a>, <a href="/format/2401.05665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmented Reality User Interface for Command, Control, and Supervision  of Large Multi-Agent Teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Regal%2C+F">Frank Regal</a>, 
<a href="/search/cs?searchtype=author&query=Suarez%2C+C">Chris Suarez</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+F">Fabian Parra</a>, 
<a href="/search/cs?searchtype=author&query=Pryor%2C+M">Mitch Pryor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at The Second International Horizons of an Extended Robotics Reality (XR-ROB) Workshop - IEEE IROS 2023 | Workshop Website: <a href="https://sites.google.com/view/xr-robotics-iros2023/home?authuser=0">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Multi-agent human-robot teaming allows for the potential to gather
information about various environments more efficiently by exploiting and
combining the strengths of humans and robots. In industries like defense,
search and rescue, first-response, and others alike, heterogeneous human-robot
teams show promise to accelerate data collection and improve team safety by
removing humans from unknown and potentially hazardous situations. This work
builds upon AugRE, an Augmented Reality (AR) based scalable human-robot teaming
framework. It enables users to localize and communicate with 50+ autonomous
agents. Through our efforts, users are able to command, control, and supervise
agents in large teams, both line-of-sight and non-line-of-sight, without the
need to modify the environment prior and without requiring users to use typical
hardware (i.e. joysticks, keyboards, laptops, tablets, etc.) in the field. The
demonstrated work shows early indications that combining these AR-HMD-based
user interaction modalities for command, control, and supervision will help
improve human-robot team collaboration, robustness, and trust.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05667" title="Abstract">arXiv:2401.05667</a> [<a href="/pdf/2401.05667" title="Download PDF">pdf</a>, <a href="/format/2401.05667" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EsaCL: Efficient Continual Learning of Sparse Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weijieying Ren</a>, 
<a href="/search/cs?searchtype=author&query=Honavar%2C+V+G">Vasant G Honavar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SDM 2024 : SIAM International Conference on Data Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A key challenge in the continual learning setting is to efficiently learn a
sequence of tasks without forgetting how to perform previously learned tasks.
Many existing approaches to this problem work by either retraining the model on
previous tasks or by expanding the model to accommodate new tasks. However,
these approaches typically suffer from increased storage and computational
requirements, a problem that is worsened in the case of sparse models due to
need for expensive re-training after sparsification. To address this challenge,
we propose a new method for efficient continual learning of sparse models
(EsaCL) that can automatically prune redundant parameters without adversely
impacting the model's predictive power, and circumvent the need of retraining.
We conduct a theoretical analysis of loss landscapes with parameter pruning,
and design a directional pruning (SDP) strategy that is informed by the
sharpness of the loss function with respect to the model parameters. SDP
ensures model with minimal loss of predictive accuracy, accelerating the
learning of sparse models at each stage. To accelerate model update, we
introduce an intelligent data selection (IDS) strategy that can identify
critical instances for estimating loss landscape, yielding substantially
improved data efficiency. The results of our experiments show that EsaCL
achieves performance that is competitive with the state-of-the-art methods on
three continual learning benchmarks, while using substantially reduced memory
and computational resources.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05668" title="Abstract">arXiv:2401.05668</a> [<a href="/pdf/2401.05668" title="Download PDF">pdf</a>, <a href="/format/2401.05668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges, Adaptations, and Fringe Benefits of Conducting Software  Engineering Research with Human Participants during the COVID-19 Pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Madugalla%2C+A">Anuradha Madugalla</a>, 
<a href="/search/cs?searchtype=author&query=Kanij%2C+T">Tanjila Kanij</a>, 
<a href="/search/cs?searchtype=author&query=Hoda%2C+R">Rashina Hoda</a>, 
<a href="/search/cs?searchtype=author&query=Hidellaarachchi%2C+D">Dulaji Hidellaarachchi</a>, 
<a href="/search/cs?searchtype=author&query=Pant%2C+A">Aastha Pant</a>, 
<a href="/search/cs?searchtype=author&query=Ferdousi%2C+S">Samia Ferdousi</a>, 
<a href="/search/cs?searchtype=author&query=Grundy%2C+J">John Grundy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The COVID-19 pandemic changed the way we live, work and the way we conduct
research. With the restrictions of lockdowns and social distancing, various
impacts were experienced by many software engineering researchers, especially
whose studies depend on human participants. We conducted a mixed methods study
to understand the extent of this impact. Through a detailed survey with 89
software engineering researchers working with human participants around the
world and a further nine follow-up interviews, we identified the key challenges
faced, the adaptations made, and the surprising fringe benefits of conducting
research involving human participants during the pandemic. Our findings also
revealed that in retrospect, many researchers did not wish to revert to the old
ways of conducting human-oriented research. Based on our analysis and insights,
we share recommendations on how to conduct remote studies with human
participants effectively in an increasingly hybrid world when face-to-face
engagement is not possible or where remote participation is preferred.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05669" title="Abstract">arXiv:2401.05669</a> [<a href="/pdf/2401.05669" title="Download PDF">pdf</a>, <a href="/format/2401.05669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConcEPT: Concept-Enhanced Pre-Training for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhouhong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jiaqing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Dakuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yanghua Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12pages. Work completed in 2023.01
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pre-trained language models (PLMs) have been prevailing in state-of-the-art
methods for natural language processing, and knowledge-enhanced PLMs are
further proposed to promote model performance in knowledge-intensive tasks.
However, conceptual knowledge, one essential kind of knowledge for human
cognition, still remains understudied in this line of research. This limits
PLMs' performance in scenarios requiring human-like cognition, such as
understanding long-tail entities with concepts. In this paper, we propose
ConcEPT, which stands for Concept-Enhanced Pre-Training for language models, to
infuse conceptual knowledge into PLMs. ConcEPT exploits external taxonomies
with entity concept prediction, a novel pre-training objective to predict the
concepts of entities mentioned in the pre-training contexts. Unlike previous
concept-enhanced methods, ConcEPT can be readily adapted to various downstream
applications without entity linking or concept mapping. Results of extensive
experiments show the effectiveness of ConcEPT in four tasks such as entity
typing, which validates that our model gains improved conceptual knowledge with
concept-enhanced pre-training.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05673" title="Abstract">arXiv:2401.05673</a> [<a href="/pdf/2401.05673" title="Download PDF">pdf</a>, <a href="/format/2401.05673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing and Debugging Normative Requirements via Satisfiability  Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+N">Nick Feng</a>, 
<a href="/search/cs?searchtype=author&query=Marsso%2C+L">Lina Marsso</a>, 
<a href="/search/cs?searchtype=author&query=Yaman%2C+S+G">Sinem Getir Yaman</a>, 
<a href="/search/cs?searchtype=author&query=Baatartogtokh%2C+Y">Yesugen Baatartogtokh</a>, 
<a href="/search/cs?searchtype=author&query=Ayad%2C+R">Reem Ayad</a>, 
<a href="/search/cs?searchtype=author&query=de+Mello%2C+V+O">Vict&#xf3;ria Oldemburgo de Mello</a>, 
<a href="/search/cs?searchtype=author&query=Townsend%2C+B">Beverley Townsend</a>, 
<a href="/search/cs?searchtype=author&query=Standen%2C+I">Isobel Standen</a>, 
<a href="/search/cs?searchtype=author&query=Stefanakos%2C+I">Ioannis Stefanakos</a>, 
<a href="/search/cs?searchtype=author&query=Imrie%2C+C">Calum Imrie</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigues%2C+G+N">Gena&#xed;na Nunes Rodrigues</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcanti%2C+A">Ana Cavalcanti</a>, 
<a href="/search/cs?searchtype=author&query=Calinescu%2C+R">Radu Calinescu</a>, 
<a href="/search/cs?searchtype=author&query=Chechik%2C+M">Marsha Chechik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">As software systems increasingly interact with humans in application domains
such as transportation and healthcare, they raise concerns related to the
social, legal, ethical, empathetic, and cultural (SLEEC) norms and values of
their stakeholders. Normative non-functional requirements (N-NFRs) are used to
capture these concerns by setting SLEEC-relevant boundaries for system
behavior. Since N-NFRs need to be specified by multiple stakeholders with
widely different, non-technical expertise (ethicists, lawyers, regulators, end
users, etc.), N-NFR elicitation is very challenging. To address this challenge,
we introduce N-Check, a novel tool-supported formal approach to N-NFR analysis
and debugging. N-Check employs satisfiability checking to identify a broad
spectrum of N-NFR well-formedness issues (WFI), such as conflicts, redundancy,
restrictiveness, insufficiency, yielding diagnostics which pinpoint their
causes in a user-friendly way that enables non-technical stakeholders to
understand and fix them. We show the effectiveness and usability of our
approach through nine case studies in which teams of ethicists, lawyers,
philosophers, psychologists, safety analysts, and engineers used N-Check to
analyse and debug 233 N-NFRs comprising 62 issues for the software underpinning
the operation of systems ranging from assistive-care robots and tree-disease
detection drones to manufacturing collaborative robots.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05674" title="Abstract">arXiv:2401.05674</a> [<a href="/pdf/2401.05674" title="Download PDF">pdf</a>, <a href="/format/2401.05674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of numerical methods for the Navier-Stokes-Fourier system  driven by uncertain initial/boundary data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Feireisl%2C+E">Eduard Feireisl</a>, 
<a href="/search/math?searchtype=author&query=Lukacova-Medvidova%2C+M">Maria Lukacova-Medvidova</a>, 
<a href="/search/math?searchtype=author&query=She%2C+B">Bangwei She</a>, 
<a href="/search/math?searchtype=author&query=Yuan%2C+Y">Yuhuan Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the Navier-Stokes-Fourier system governing the motion of a
general compressible, heat conducting, Newtonian fluid driven by random
initial/boundary data. Convergence of the stochastic collocation and Monte
Carlo numerical methods is shown under the hypothesis that approximate
solutions are bounded in probability. Abstract results are illustrated by
numerical experiments for the Rayleigh-Benard convection problem.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05675" title="Abstract">arXiv:2401.05675</a> [<a href="/pdf/2401.05675" title="Download PDF">pdf</a>, <a href="/format/2401.05675" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parrot: Pareto-optimal Multi-Reward Reinforcement Learning Framework for  Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+S+H">Seung Hyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+J">Junjie Ke</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+I">Innfarn Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jiahui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+F">Fei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Entis%2C+G">Glenn Entis</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sangpil Kim</a>, 
<a href="/search/cs?searchtype=author&query=Essa%2C+I">Irfan Essa</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Feng Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent works demonstrate that using reinforcement learning (RL) with quality
rewards can enhance the quality of generated images in text-to-image (T2I)
generation. However, a simple aggregation of multiple rewards may cause
over-optimization in certain metrics and degradation in others, and it is
challenging to manually find the optimal weights. An effective strategy to
jointly optimize multiple rewards in RL for T2I generation is highly desirable.
This paper introduces Parrot, a novel multi-reward RL framework for T2I
generation. Through the use of the batch-wise Pareto optimal selection, Parrot
automatically identifies the optimal trade-off among different rewards during
the RL optimization of the T2I generation. Additionally, Parrot employs a joint
optimization approach for the T2I model and the prompt expansion network,
facilitating the generation of quality-aware text prompts, thus further
enhancing the final image quality. To counteract the potential catastrophic
forgetting of the original user prompt due to prompt expansion, we introduce
original prompt centered guidance at inference time, ensuring that the
generated image remains faithful to the user input. Extensive experiments and a
user study demonstrate that Parrot outperforms several baseline methods across
various quality criteria, including aesthetics, human preference, image
sentiment, and text-image alignment.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05676" title="Abstract">arXiv:2401.05676</a> [<a href="/pdf/2401.05676" title="Download PDF">pdf</a>, <a href="/format/2401.05676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Self- and Cross-Triplet Correlations for Human-Object  Interaction Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Weibo Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Weihong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jiandong Tian</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Liangqiong Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Honghai Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human-Object Interaction (HOI) detection plays a vital role in scene
understanding, which aims to predict the HOI triplet in the form of &lt;human,
object, action&gt;. Existing methods mainly extract multi-modal features (e.g.,
appearance, object semantics, human pose) and then fuse them together to
directly predict HOI triplets. However, most of these methods focus on seeking
for self-triplet aggregation, but ignore the potential cross-triplet
dependencies, resulting in ambiguity of action prediction. In this work, we
propose to explore Self- and Cross-Triplet Correlations (SCTC) for HOI
detection. Specifically, we regard each triplet proposal as a graph where
Human, Object represent nodes and Action indicates edge, to aggregate
self-triplet correlation. Also, we try to explore cross-triplet dependencies by
jointly considering instance-level, semantic-level, and layout-level relations.
Besides, we leverage the CLIP model to assist our SCTC obtain interaction-aware
feature by knowledge distillation, which provides useful action clues for HOI
detection. Extensive experiments on HICO-DET and V-COCO datasets verify the
effectiveness of our proposed SCTC.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05680" title="Abstract">arXiv:2401.05680</a> [<a href="/pdf/2401.05680" title="Download PDF">pdf</a>, <a href="/format/2401.05680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of Graph Neural Networks in Aiding Defensive Cyber Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Shaswata Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+T">Trisha Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Neupane%2C+S">Subash Neupane</a>, 
<a href="/search/cs?searchtype=author&query=Piplai%2C+A">Aritran Piplai</a>, 
<a href="/search/cs?searchtype=author&query=Mittal%2C+S">Sudip Mittal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 9 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In an increasingly interconnected world, where information is the lifeblood
of modern society, regular cyber-attacks sabotage the confidentiality,
integrity, and availability of digital systems and information. Additionally,
cyber-attacks differ depending on the objective and evolve rapidly to disguise
defensive systems. However, a typical cyber-attack demonstrates a series of
stages from attack initiation to final resolution, called an attack life cycle.
These diverse characteristics and the relentless evolution of cyber attacks
have led cyber defense to adopt modern approaches like Machine Learning to
bolster defensive measures and break the attack life cycle. Among the adopted
ML approaches, Graph Neural Networks have emerged as a promising approach for
enhancing the effectiveness of defensive measures due to their ability to
process and learn from heterogeneous cyber threat data. In this paper, we look
into the application of GNNs in aiding to break each stage of one of the most
renowned attack life cycles, the Lockheed Martin Cyber Kill Chain. We address
each phase of CKC and discuss how GNNs contribute to preparing and preventing
an attack from a defensive standpoint. Furthermore, We also discuss open
research areas and further improvement scopes.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05683" title="Abstract">arXiv:2401.05683</a> [<a href="/pdf/2401.05683" title="Download PDF">pdf</a>, <a href="/format/2401.05683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning Meets Mechanism Design: Key Results and Some Novel  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sankar%2C+V+U">V. Udaya Sankar</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+V+S">Vishisht Srihari Rao</a>, 
<a href="/search/cs?searchtype=author&query=Narahari%2C+Y">Y. Narahari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mechanism design is essentially reverse engineering of games and involves
inducing a game among strategic agents in a way that the induced game satisfies
a set of desired properties in an equilibrium of the game. Desirable properties
for a mechanism include incentive compatibility, individual rationality,
welfare maximisation, revenue maximisation (or cost minimisation), fairness of
allocation, etc. It is known from mechanism design theory that only certain
strict subsets of these properties can be simultaneously satisfied exactly by
any given mechanism. Often, the mechanisms required by real-world applications
may need a subset of these properties that are theoretically impossible to be
simultaneously satisfied. In such cases, a prominent recent approach is to use
a deep learning based approach to learn a mechanism that approximately
satisfies the required properties by minimizing a suitably defined loss
function. In this paper, we present, from relevant literature, technical
details of using a deep learning approach for mechanism design and provide an
overview of key results in this topic. We demonstrate the power of this
approach for three illustrative case studies: (a) efficient energy management
in a vehicular network (b) resource allocation in a mobile network (c)
designing a volume discount procurement auction for agricultural inputs.
Section 6 concludes the paper.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05686" title="Abstract">arXiv:2401.05686</a> [<a href="/pdf/2401.05686" title="Download PDF">pdf</a>, <a href="/format/2401.05686" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self Expanding Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Appolinary%2C+B">Blaise Appolinary</a>, 
<a href="/search/cs?searchtype=author&query=Deaconu%2C+A">Alex Deaconu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sophia Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a novel method for dynamically expanding
Convolutional Neural Networks (CNNs) during training, aimed at meeting the
increasing demand for efficient and sustainable deep learning models. Our
approach, drawing from the seminal work on Self-Expanding Neural Networks
(SENN), employs a natural expansion score as an expansion criteria to address
the common issue of over-parameterization in deep convolutional neural
networks, thereby ensuring that the model's complexity is finely tuned to the
task's specific needs. A significant benefit of this method is its eco-friendly
nature, as it obviates the necessity of training multiple models of different
sizes. We employ a strategy where a single model is dynamically expanded,
facilitating the extraction of checkpoints at various complexity levels,
effectively reducing computational resource use and energy consumption while
also expediting the development cycle by offering diverse model complexities
from a single training session. We evaluate our method on the CIFAR-10 dataset
and our experimental results validate this approach, demonstrating that
dynamically adding layers not only maintains but also improves CNN performance,
underscoring the effectiveness of our expansion criteria. This approach marks a
considerable advancement in developing adaptive, scalable, and environmentally
considerate neural network architectures, addressing key challenges in the
field of deep learning.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05689" title="Abstract">arXiv:2401.05689</a> [<a href="/pdf/2401.05689" title="Download PDF">pdf</a>, <a href="/format/2401.05689" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCorrect: An Unsupervised Framework for Automatic Speech Recognition  Error Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+X">Xiaosong Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Daimeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Hengchao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengzhe Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinglu Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Chang Su</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Error correction techniques have been used to refine the output sentences
from automatic speech recognition (ASR) models and achieve a lower word error
rate (WER). Previous works usually adopt end-to-end models and has strong
dependency on Pseudo Paired Data and Original Paired Data. But when only
pre-training on Pseudo Paired Data, previous models have negative effect on
correction. While fine-tuning on Original Paired Data, the source side data
must be transcribed by a well-trained ASR model, which takes a lot of time and
not universal. In this paper, we propose UCorrect, an unsupervised
Detector-Generator-Selector framework for ASR Error Correction. UCorrect has no
dependency on the training data mentioned before. The whole procedure is first
to detect whether the character is erroneous, then to generate some candidate
characters and finally to select the most confident one to replace the error
character. Experiments on the public AISHELL-1 dataset and WenetSpeech dataset
show the effectiveness of UCorrect for ASR error correction: 1) it achieves
significant WER reduction, achieves 6.83\% even without fine-tuning and 14.29\%
after fine-tuning; 2) it outperforms the popular NAR correction models by a
large margin with a competitive low latency; and 3) it is an universal method,
as it reduces all WERs of the ASR model with different decoding strategies and
reduces all WERs of ASR models trained on different scale datasets.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05690" title="Abstract">arXiv:2401.05690</a> [<a href="/pdf/2401.05690" title="Download PDF">pdf</a>, <a href="/format/2401.05690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Array Enabled Near-Field Communications: Beam Pattern Analysis  and Hybrid Beamforming Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Cong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haodong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Li Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuo Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In this paper, we propose to exploit sparse arrays for enabling near-field communications and characterize its unique beam pattern for facilitating its hybrid beamforming design
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Extremely large-scale array (XL-array) has emerged as a promising technology
to enable near-field communications for achieving enhanced spectrum efficiency
and spatial resolution, by drastically increasing the number of antennas.
However, this also inevitably incurs higher hardware and energy cost, which may
not be affordable in future wireless systems. To address this issue, we propose
in this paper to exploit two types of sparse arrays (SAs) for enabling
near-field communications. Specifically, we first consider the linear sparse
array (LSA) and characterize its near-field beam pattern. It is shown that
despite the achieved beam-focusing gain, the LSA introduces several undesired
grating-lobes, which have comparable beam power with the main-lobe and are
focused on specific regions. An efficient hybrid beamforming design is then
proposed for the LSA to deal with the potential strong inter-user interference
(IUI). Next, we consider another form of SA, called extended coprime array
(ECA), which is composed of two LSA subarrays with different (coprime)
inter-antenna spacing. By characterizing the ECA near-field beam pattern, we
show that compared with the LSA with the same array sparsity, the ECA can
greatly suppress the beam power of near-field grating-lobes thanks to the
offset effect of the two subarrays, albeit with a larger number of
grating-lobes. This thus motivates us to propose a customized two-phase hybrid
beamforming design for the ECA. Finally, numerical results are presented to
demonstrate the rate performance gain of the proposed two SAs over the
conventional uniform linear array (ULA).
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05695" title="Abstract">arXiv:2401.05695</a> [<a href="/pdf/2401.05695" title="Download PDF">pdf</a>, <a href="/format/2401.05695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Physician Diagnostic Logic into Large Language Models:  Preference Learning from Process Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+C">Chengfeng Dou</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenpin Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haiyan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yongqiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhenwei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The use of large language models in medical dialogue generation has garnered
significant attention, with a focus on improving response quality and fluency.
While previous studies have made progress in optimizing model performance for
single-round medical Q&amp;A tasks, there is a need to enhance the model's
capability for multi-round conversations to avoid logical inconsistencies. To
address this, we propose an approach called preference learning from process
feedback~(PLPF), which integrates the doctor's diagnostic logic into LLMs. PLPF
involves rule modeling, preference data generation, and preference alignment to
train the model to adhere to the diagnostic process. Experimental results using
Standardized Patient Testing show that PLPF enhances the diagnostic accuracy of
the baseline model in medical conversations by 17.6%, outperforming traditional
reinforcement learning from human feedback. Additionally, PLPF demonstrates
effectiveness in both multi-round and single-round dialogue tasks, showcasing
its potential for improving medical dialogue generation.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05698" title="Abstract">arXiv:2401.05698</a> [<a href="/pdf/2401.05698" title="Download PDF">pdf</a>, <a href="/format/2401.05698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiCMAE: Hierarchical Contrastive Masked Autoencoder for Self-Supervised  Audio-Visual Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Licai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+Z">Zheng Lian</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 8 figures, 15 tables. Full Abstract is shown in the pdf file. Codes and models will be publicly available at <a href="https://github.com/sunlicai/HiCMAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-Visual Emotion Recognition (AVER) has garnered increasing attention in
recent years for its critical role in creating emotion-ware intelligent
machines. Previous efforts in this area are dominated by the supervised
learning paradigm. Despite significant progress, supervised learning is meeting
its bottleneck due to the longstanding data scarcity issue in AVER. Motivated
by recent advances in self-supervised learning, we propose Hierarchical
Contrastive Masked Autoencoder (HiCMAE), a novel self-supervised framework that
leverages large-scale self-supervised pre-training on vast unlabeled
audio-visual data to promote the advancement of AVER. Following prior arts in
self-supervised audio-visual representation learning, HiCMAE adopts two primary
forms of self-supervision for pre-training, namely masked data modeling and
contrastive learning. Unlike them which focus exclusively on top-layer
representations while neglecting explicit guidance of intermediate layers,
HiCMAE develops a three-pronged strategy to foster hierarchical audio-visual
feature learning and improve the overall quality of learned representations. To
verify the effectiveness of HiCMAE, we conduct extensive experiments on 9
datasets covering both categorical and dimensional AVER tasks. Experimental
results show that our method significantly outperforms state-of-the-art
supervised and self-supervised audio-visual methods, which indicates that
HiCMAE is a powerful audio-visual emotion representation learner. Codes and
models will be publicly available at https://github.com/sunlicai/HiCMAE.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05700" title="Abstract">arXiv:2401.05700</a> [<a href="/pdf/2401.05700" title="Download PDF">pdf</a>, <a href="/format/2401.05700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R-BI: Regularized Batched Inputs enhance Incremental Decoding Framework  for Low-Latency Simultaneous Speech Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jiaxin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhanglin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+H">Hengchao Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+D">Daimeng Wei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Rao%2C+Z">Zhiqiang Rao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaojun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Incremental Decoding is an effective framework that enables the use of an
offline model in a simultaneous setting without modifying the original model,
making it suitable for Low-Latency Simultaneous Speech Translation. However,
this framework may introduce errors when the system outputs from incomplete
input. To reduce these output errors, several strategies such as Hold-$n$,
LA-$n$, and SP-$n$ can be employed, but the hyper-parameter $n$ needs to be
carefully selected for optimal performance. Moreover, these strategies are more
suitable for end-to-end systems than cascade systems. In our paper, we propose
a new adaptable and efficient policy named "Regularized Batched Inputs". Our
method stands out by enhancing input diversity to mitigate output errors. We
suggest particular regularization techniques for both end-to-end and cascade
systems. We conducted experiments on IWSLT Simultaneous Speech Translation
(SimulST) tasks, which demonstrate that our approach achieves low latency while
maintaining no more than 2 BLEU points loss compared to offline systems.
Furthermore, our SimulST systems attained several new state-of-the-art results
in various language directions.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05702" title="Abstract">arXiv:2401.05702</a> [<a href="/pdf/2401.05702" title="Download PDF">pdf</a>, <a href="/format/2401.05702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Anomaly Detection and Explanation via Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Hui Lv</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qianru Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video Anomaly Detection (VAD) aims to localize abnormal events on the
timeline of long-range surveillance videos. Anomaly-scoring-based methods have
been prevailing for years but suffer from the high complexity of thresholding
and low explanability of detection results. In this paper, we conduct pioneer
research on equipping video-based large language models (VLLMs) in the
framework of VAD, making the VAD model free from thresholds and able to explain
the reasons for the detected anomalies. We introduce a novel network module
Long-Term Context (LTC) to mitigate the incapability of VLLMs in long-range
context modeling. We design a three-phase training method to improve the
efficiency of fine-tuning VLLMs by substantially minimizing the requirements
for VAD data and lowering the costs of annotating instruction-tuning data. Our
trained model achieves the top performance on the anomaly videos of the
UCF-Crime and TAD benchmarks, with the AUC improvements of +3.86\% and +4.96\%,
respectively. More impressively, our approach can provide textual explanations
for detected anomalies.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05705" title="Abstract">arXiv:2401.05705</a> [<a href="/pdf/2401.05705" title="Download PDF">pdf</a>, <a href="/ps/2401.05705" title="Download PostScript">ps</a>, <a href="/format/2401.05705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization of the discrete source problem in the nonlinear  diffusive-logistic equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Krivorotko%2C+O">Olga Krivorotko</a>, 
<a href="/search/math?searchtype=author&query=Zvonareva%2C+T">Tatiana Zvonareva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">A numerical algorithm for regularization of the solution of the source
problem for the diffusion-logistic model based on information about the process
at fixed moments of time of integral type has been developed. The peculiarity
of the problem under study is the discrete formulation in space and
impossibility to apply classical algorithms for its numerical solution. The
regularization of the problem is based on the application of A.N. Tikhonov's
approach and a priori information about the source of the process. The problem
was formulated in a variational formulation and solved by the global tensor
optimization method. It is shown that in the case of noisy data regularization
improves the accuracy of the reconstructed source.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05707" title="Abstract">arXiv:2401.05707</a> [<a href="/pdf/2401.05707" title="Download PDF">pdf</a>, <a href="/format/2401.05707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CAT-LLM: Prompting Large Language Models with Text Style Definition for  Chinese Article-style Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Z">Zhen Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+D">Dinghao Xi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhiyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Liumin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Text style transfer is increasingly prominent in online entertainment and
social media. However, existing research mainly concentrates on style transfer
within individual English sentences, while ignoring the complexity of long
Chinese texts, which limits the wider applicability of style transfer in
digital media realm. To bridge this gap, we propose a Chinese Article-style
Transfer framework (CAT-LLM), leveraging the capabilities of Large Language
Models (LLMs). CAT-LLM incorporates a bespoke, pluggable Text Style Definition
(TSD) module aimed at comprehensively analyzing text features in articles,
prompting LLMs to efficiently transfer Chinese article-style. The TSD module
integrates a series of machine learning algorithms to analyze article-style
from both words and sentences levels, thereby aiding LLMs thoroughly grasp the
target style without compromising the integrity of the original text. In
addition, this module supports dynamic expansion of internal style trees,
showcasing robust compatibility and allowing flexible optimization in
subsequent research. Moreover, we select five Chinese articles with distinct
styles and create five parallel datasets using ChatGPT, enhancing the models'
performance evaluation accuracy and establishing a novel paradigm for
evaluating subsequent research on article-style transfer. Extensive
experimental results affirm that CAT-LLM outperforms current research in terms
of transfer accuracy and content preservation, and has remarkable applicability
to various types of LLMs.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05708" title="Abstract">arXiv:2401.05708</a> [<a href="/pdf/2401.05708" title="Download PDF">pdf</a>, <a href="/format/2401.05708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeReX: A Reconfigurable Design of Multi-bit Ferroelectric  Compute-in-Memory for Nearest Neighbor Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhicheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Che-Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+R">Ruibin Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4mpfe%2C+T">Thomas K&#xe4;mpfe</a>, 
<a href="/search/cs?searchtype=author&query=Imani%2C+M">Mohsen Imani</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Can Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, 3 tables. Accepted by Design Automation and Test in Europe (DATE) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Rapid advancements in artificial intelligence have given rise to
transformative models, profoundly impacting our lives. These models demand
massive volumes of data to operate effectively, exacerbating the data-transfer
bottleneck inherent in the conventional von-Neumann architecture.
Compute-in-memory (CIM), a novel computing paradigm, tackles these issues by
seamlessly embedding in-memory search functions, thereby obviating the need for
data transfers. However, existing non-volatile memory (NVM)-based accelerators
are application specific. During the similarity based associative search
operation, they only support a single, specific distance metric, such as
Hamming, Manhattan, or Euclidean distance in measuring the query against the
stored data, calling for reconfigurable in-memory solutions adaptable to
various applications. To overcome such a limitation, in this paper, we present
FeReX, a reconfigurable associative memory (AM) that accommodates various
distance metrics including Hamming, Manhattan, and Euclidean distances.
Leveraging multi-bit ferroelectric field-effect transistors (FeFETs) as the
proxy and a hardware-software co-design approach, we introduce a constrained
satisfaction problem (CSP)-based method to automate AM search input voltage and
stored voltage configurations for different distance based search functions.
Device-circuit co-simulations first validate the effectiveness of the proposed
FeReX methodology for reconfigurable search distance functions. Then, we
benchmark FeReX in the context of k-nearest neighbor (KNN) and hyperdimensional
computing (HDC), which highlights the robustness of FeReX and demonstrates up
to 250x speedup and 10^4 energy savings compared with GPU.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05709" title="Abstract">arXiv:2401.05709</a> [<a href="/pdf/2401.05709" title="Download PDF">pdf</a>, <a href="/format/2401.05709" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probability-based Distance Estimation Model for 3D DV-Hop Localization  in WSNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Penghong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenrui Li</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaopeng Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Debin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Localization is one of the pivotal issues in wireless sensor network
applications. In 3D localization studies, most algorithms focus on enhancing
the location prediction process, lacking theoretical derivation of the
detection distance of an anchor node at the varying hops, engenders a
localization performance bottleneck. To address this issue, we propose a
probability-based average distance estimation (PADE) model that utilizes the
probability distribution of node distances detected by an anchor node. The aim
is to mathematically derive the average distances of nodes detected by an
anchor node at different hops. First, we develop a probability-based maximum
distance estimation (PMDE) model to calculate the upper bound of the distance
detected by an anchor node. Then, we present the PADE model, which relies on
the upper bound obtained of the distance by the PMDE model. Finally, the
obtained average distance is used to construct a distance loss function, and it
is embedded with the traditional distance loss function into a multi-objective
genetic algorithm to predict the locations of unknown nodes. The experimental
results demonstrate that the proposed method achieves state-of-the-art
performance in random and multimodal distributed sensor networks. The average
localization accuracy is improved by 3.49\%-12.66\% and 3.99%-22.34%,
respectively.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05710" title="Abstract">arXiv:2401.05710</a> [<a href="/pdf/2401.05710" title="Download PDF">pdf</a>, <a href="/format/2401.05710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Distributional Reward Critic Architecture for Perturbed-Reward  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhihui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Perrault%2C+A">Andrew Perrault</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We study reinforcement learning in the presence of an unknown reward
perturbation. Existing methodologies for this problem make strong assumptions
including reward smoothness, known perturbations, and/or perturbations that do
not modify the optimal policy. We study the case of unknown arbitrary
perturbations that discretize and shuffle reward space, but have the property
that the true reward belongs to the most frequently observed class after
perturbation. This class of perturbations generalizes existing classes (and, in
the limit, all continuous bounded perturbations) and defeats existing methods.
We introduce an adaptive distributional reward critic and show theoretically
that it can recover the true rewards under technical conditions. Under the
targeted perturbation in discrete and continuous control tasks, we win/tie the
highest return in 40/57 settings (compared to 16/57 for the best baseline).
Even under the untargeted perturbation, we still win an edge over the baseline
designed especially for that setting.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05711" title="Abstract">arXiv:2401.05711</a> [<a href="/pdf/2401.05711" title="Download PDF">pdf</a>, <a href="/format/2401.05711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Indoor Fingerprinting Localization based on Few-Shot  Meta-Learning with CSI Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jiyu Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+C">Chenpei Han</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuhua Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yizhuo Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">While fingerprinting localization is favored for its effectiveness, it is
hindered by high data acquisition costs and the inaccuracy of static
database-based estimates. Addressing these issues, this letter presents an
innovative indoor localization method using a data-efficient meta-learning
algorithm. This approach, grounded in the ``Learning to Learn'' paradigm of
meta-learning, utilizes historical localization tasks to improve adaptability
and learning efficiency in dynamic indoor environments. We introduce a
task-weighted loss to enhance knowledge transfer within this framework. Our
comprehensive experiments confirm the method's robustness and superiority over
current benchmarks, achieving a notable 23.13\% average gain in Mean Euclidean
Distance, particularly effective in scenarios with limited CSI data.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05712" title="Abstract">arXiv:2401.05712</a> [<a href="/pdf/2401.05712" title="Download PDF">pdf</a>, <a href="/format/2401.05712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BOD: Blindly Optimal Data Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thomas Hoang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Still working on other parts
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Combining discovery and augmentation is important in the era of data usage
when it comes to predicting the outcome of tasks. However, having to ask the
user the utility function to discover the goal to achieve the optimal small
rightful dataset is not an optimal solution. The existing solutions do not make
good use of this combination, hence underutilizing the data. In this paper, we
introduce a novel goal-oriented framework, called BOD: Blindly Optimal Data
Discovery, that involves humans in the loop and comparing utility scores every
time querying in the process without knowing the utility function. This
establishes the promise of using BOD: Blindly Optimal Data Discovery for modern
data science solutions.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05715" title="Abstract">arXiv:2401.05715</a> [<a href="/pdf/2401.05715" title="Download PDF">pdf</a>, <a href="/ps/2401.05715" title="Download PostScript">ps</a>, <a href="/format/2401.05715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recoverable robust shortest path problem under interval uncertainty  representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jackiewicz%2C+M">Marcel Jackiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Kasperski%2C+A">Adam Kasperski</a>, 
<a href="/search/cs?searchtype=author&query=Zielinski%2C+P">Pawel Zielinski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">In this paper, the recoverable robust shortest path problem under interval
uncertainty representations is discussed. This problem is known to be strongly
NP-hard and also hard to approximate in general digraphs. In this paper, the
class of acyclic digraphs is considered. It is shown that for the traditional
interval uncertainty, the problem can be solved in polynomial time for all
natural, known from the literature, neighborhoods. Efficient algorithms for
various classes of acyclic digraphs are constructed. Some negative results for
general digraphs are strengthened. Finally, some exact and approximate methods
of solving the problem under budgeted interval uncertainty are proposed.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05716" title="Abstract">arXiv:2401.05716</a> [<a href="/pdf/2401.05716" title="Download PDF">pdf</a>, <a href="/format/2401.05716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature  and Bayesian Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Scarlett%2C+J">Jonathan Scarlett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">In this paper, we study the problem of estimating the normalizing constant
$\int e^{-\lambda f(x)}dx$ through queries to the black-box function $f$, where
$f$ belongs to a reproducing kernel Hilbert space (RKHS), and $\lambda$ is a
problem parameter. We show that to estimate the normalizing constant within a
small relative error, the level of difficulty depends on the value of
$\lambda$: When $\lambda$ approaches zero, the problem is similar to Bayesian
quadrature (BQ), while when $\lambda$ approaches infinity, the problem is
similar to Bayesian optimization (BO). More generally, the problem varies
between BQ and BO. We find that this pattern holds true even when the function
evaluations are noisy, bringing new aspects to this topic. Our findings are
supported by both algorithm-independent lower bounds and algorithmic upper
bounds, as well as simulation studies conducted on a variety of benchmark
functions.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05725" title="Abstract">arXiv:2401.05725</a> [<a href="/pdf/2401.05725" title="Download PDF">pdf</a>, <a href="/ps/2401.05725" title="Download PostScript">ps</a>, <a href="/format/2401.05725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAR-RIS Enhanced UAV-Enabled MEC Networks with Bi-Directional Task  Offloading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Han Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaoyan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+P">Pengcheng Mu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weile Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+K">Kai-Kit Wong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kun Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">A simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) enhanced unnamed aerial vehicle (UAV)-enabled multi-user
mobile edge computing (MEC) scheme is proposed in this paper. Different from
the existing MEC works, the proposed scheme allows bi-directional offloading
where users can simultaneously offload their computing tasks to the MEC servers
situated at the ground base station (BS) and aerial UAV with the assistance of
the STARRIS. Specifically, we formulate an optimization problem aiming at
maximizing the energy efficiency of the system while ensuring the quality of
service (QoS) constraint by jointly optimizing the resource allocation, user
scheduling, passive beamforming of the STAR-RIS, and the UAV trajectory. An
iterative algorithm designed with the Dinkelbach's algorithm and the successive
convex approximation (SCA) is proposed to effectively handle the formulated
non-convex optimization problem. Simulation results indicate that the proposed
STAR-RIS enhanced UAV-enabled MEC scheme possesses significant advantages in
enhancing the system energy efficiency over other baseline schemes including
the conventional RIS-aided scheme.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05727" title="Abstract">arXiv:2401.05727</a> [<a href="/pdf/2401.05727" title="Download PDF">pdf</a>, <a href="/format/2401.05727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero Resource Cross-Lingual Part Of Speech Tagging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chopra%2C+S">Sahil Chopra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Part of speech tagging in zero-resource settings can be an effective approach
for low-resource languages when no labeled training data is available. Existing
systems use two main techniques for POS tagging i.e. pretrained multilingual
large language models(LLM) or project the source language labels into the zero
resource target language and train a sequence labeling model on it. We explore
the latter approach using the off-the-shelf alignment module and train a hidden
Markov model(HMM) to predict the POS tags. We evaluate transfer learning setup
with English as a source language and French, German, and Spanish as target
languages for part-of-speech tagging. Our conclusion is that projected
alignment data in zero-resource language can be beneficial to predict POS tags.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05730" title="Abstract">arXiv:2401.05730</a> [<a href="/pdf/2401.05730" title="Download PDF">pdf</a>, <a href="/format/2401.05730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Contrastive Learning with Efficient Combinatorial Positive  Pairing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeill Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+D">Duhun Hwang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Eunjung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+J">Jangwon Suh</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jimyeong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Rhee%2C+W">Wonjong Rhee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the past few years, contrastive learning has played a central role for the
success of visual unsupervised representation learning. Around the same time,
high-performance non-contrastive learning methods have been developed as well.
While most of the works utilize only two views, we carefully review the
existing multi-view methods and propose a general multi-view strategy that can
improve learning speed and performance of any contrastive or non-contrastive
method. We first analyze CMC's full-graph paradigm and empirically show that
the learning speed of $K$-views can be increased by $_{K}\mathrm{C}_{2}$ times
for small learning rate and early training. Then, we upgrade CMC's full-graph
by mixing views created by a crop-only augmentation, adopting small-size views
as in SwAV multi-crop, and modifying the negative sampling. The resulting
multi-view strategy is called ECPP (Efficient Combinatorial Positive Pairing).
We investigate the effectiveness of ECPP by applying it to SimCLR and assessing
the linear evaluation performance for CIFAR-10 and ImageNet-100. For each
benchmark, we achieve a state-of-the-art performance. In case of ImageNet-100,
ECPP boosted SimCLR outperforms supervised learning.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05731" title="Abstract">arXiv:2401.05731</a> [<a href="/pdf/2401.05731" title="Download PDF">pdf</a>, <a href="/ps/2401.05731" title="Download PostScript">ps</a>, <a href="/format/2401.05731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Grobner-Shirshov bases for Markov semirings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+X">Xiaohui Niu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenxi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongzhi Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">In order to investigate the relationship between Shannon information measure
of random variables, scholars such as Yeung utilized information diagrams to
explore the structured representation of information measures, establishing
correspondences with sets. However, this method has limitations when studying
information measures of five or more random variables. In this paper, we
consider employing algebraic methods to study the relationship of information
measures of random variables. By introducing a semiring generated by random
variables, we establish correspondences between sets and elements of the
semiring. Utilizing the Grobner-Shirshov basis, we present the structure of the
semiring and its standard form. Furthermore, we delve into the structure of the
semiring generated under Markov chain conditions (referred to as Markov
semiring), obtaining its standard form.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05735" title="Abstract">arXiv:2401.05735</a> [<a href="/pdf/2401.05735" title="Download PDF">pdf</a>, <a href="/format/2401.05735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-Centric Diffusion for Efficient Video Editing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kahatapitiya%2C+K">Kumara Kahatapitiya</a>, 
<a href="/search/cs?searchtype=author&query=Karjauv%2C+A">Adil Karjauv</a>, 
<a href="/search/cs?searchtype=author&query=Abati%2C+D">Davide Abati</a>, 
<a href="/search/cs?searchtype=author&query=Porikli%2C+F">Fatih Porikli</a>, 
<a href="/search/cs?searchtype=author&query=Asano%2C+Y+M">Yuki M. Asano</a>, 
<a href="/search/cs?searchtype=author&query=Habibian%2C+A">Amirhossein Habibian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Diffusion-based video editing have reached impressive quality and can
transform either the global style, local structure, and attributes of given
video inputs, following textual edit prompts. However, such solutions typically
incur heavy memory and computational costs to generate temporally-coherent
frames, either in the form of diffusion inversion and/or cross-frame attention.
In this paper, we conduct an analysis of such inefficiencies, and suggest
simple yet effective modifications that allow significant speed-ups whilst
maintaining quality. Moreover, we introduce Object-Centric Diffusion, coined as
OCD, to further reduce latency by allocating computations more towards
foreground edited regions that are arguably more important for perceptual
quality. We achieve this by two novel proposals: i) Object-Centric Sampling,
decoupling the diffusion steps spent on salient regions or background,
allocating most of the model capacity to the former, and ii) Object-Centric 3D
Token Merging, which reduces cost of cross-frame attention by fusing redundant
tokens in unimportant background regions. Both techniques are readily
applicable to a given video editing model \textit{without} retraining, and can
drastically reduce its memory and computational cost. We evaluate our proposals
on inversion-based and control-signal-based editing pipelines, and show a
latency reduction up to 10x for a comparable synthesis quality.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05736" title="Abstract">arXiv:2401.05736</a> [<a href="/pdf/2401.05736" title="Download PDF">pdf</a>, <a href="/format/2401.05736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Retrieval for Knowledge-based Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lerner%2C+P">Paul Lerner</a>, 
<a href="/search/cs?searchtype=author&query=Ferret%2C+O">Olivier Ferret</a> (LIST (CEA), DIASI), 
<a href="/search/cs?searchtype=author&query=Guinaudeau%2C+C">Camille Guinaudeau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Knowledge-based Visual Question Answering about Named Entities is a
challenging task that requires retrieving information from a multimodal
Knowledge Base. Named entities have diverse visual representations and are
therefore difficult to recognize. We argue that cross-modal retrieval may help
bridge the semantic gap between an entity and its depictions, and is foremost
complementary with mono-modal retrieval. We provide empirical evidence through
experiments with a multimodal dual encoder, namely CLIP, on the recent ViQuAE,
InfoSeek, and Encyclopedic-VQA datasets. Additionally, we study three different
strategies to fine-tune such a model: mono-modal, cross-modal, or joint
training. Our method, which combines mono-and cross-modal retrieval, is
competitive with billion-parameter models on the three datasets, while being
conceptually simpler and computationally cheaper.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05737" title="Abstract">arXiv:2401.05737</a> [<a href="/pdf/2401.05737" title="Download PDF">pdf</a>, <a href="/format/2401.05737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An experimental evaluation of Deep Reinforcement Learning algorithms for  HVAC control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manjavacas%2C+A">Antonio Manjavacas</a>, 
<a href="/search/cs?searchtype=author&query=Campoy-Nieves%2C+A">Alejandro Campoy-Nieves</a>, 
<a href="/search/cs?searchtype=author&query=Jim%C3%A9nez-Raboso%2C+J">Javier Jim&#xe9;nez-Raboso</a>, 
<a href="/search/cs?searchtype=author&query=Molina-Solana%2C+M">Miguel Molina-Solana</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Romero%2C+J">Juan G&#xf3;mez-Romero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Artificial Intelligence Review. Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Heating, Ventilation, and Air Conditioning (HVAC) systems are a major driver
of energy consumption in commercial and residential buildings. Recent studies
have shown that Deep Reinforcement Learning (DRL) algorithms can outperform
traditional reactive controllers. However, DRL-based solutions are generally
designed for ad hoc setups and lack standardization for comparison. To fill
this gap, this paper provides a critical and reproducible evaluation, in terms
of comfort and energy consumption, of several state-of-the-art DRL algorithms
for HVAC control. The study examines the controllers' robustness, adaptability,
and trade-off between optimization goals by using the Sinergym framework. The
results obtained confirm the potential of DRL algorithms, such as SAC and TD3,
in complex scenarios and reveal several challenges related to generalization
and incremental learning.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05738" title="Abstract">arXiv:2401.05738</a> [<a href="/pdf/2401.05738" title="Download PDF">pdf</a>, <a href="/format/2401.05738" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LKCA: Large Kernel Convolutional Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenghao Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Boheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Pengbo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qingzi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lingyun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We revisit the relationship between attention mechanisms and large kernel
ConvNets in visual transformers and propose a new spatial attention named Large
Kernel Convolutional Attention (LKCA). It simplifies the attention operation by
replacing it with a single large kernel convolution. LKCA combines the
advantages of convolutional neural networks and visual transformers, possessing
a large receptive field, locality, and parameter sharing. We explained the
superiority of LKCA from both convolution and attention perspectives, providing
equivalent code implementations for each view. Experiments confirm that LKCA
implemented from both the convolutional and attention perspectives exhibit
equivalent performance. We extensively experimented with the LKCA variant of
ViT in both classification and segmentation tasks. The experiments demonstrated
that LKCA exhibits competitive performance in visual tasks. Our code will be
made publicly available at https://github.com/CatworldLee/LKCA.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05739" title="Abstract">arXiv:2401.05739</a> [<a href="/pdf/2401.05739" title="Download PDF">pdf</a>, <a href="/format/2401.05739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Inlining Binary Function Similarity Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+A">Ang Jia</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Ming Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Wuxia Jin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE 2024 (Second Cycle). Camera-ready version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Binary function similarity detection plays an important role in a wide range
of security applications. Existing works usually assume that the query function
and target function share equal semantics and compare their full semantics to
obtain the similarity. However, we find that the function mapping is more
complex, especially when function inlining happens.
<br />In this paper, we will systematically investigate cross-inlining binary
function similarity detection. We first construct a cross-inlining dataset by
compiling 51 projects using 9 compilers, with 4 optimizations, to 6
architectures, with 2 inlining flags, which results in two datasets both with
216 combinations. Then we construct the cross-inlining function mappings by
linking the common source functions in these two datasets. Through analysis of
this dataset, we find that three cross-inlining patterns widely exist while
existing work suffers when detecting cross-inlining binary function similarity.
Next, we propose a pattern-based model named CI-Detector for cross-inlining
matching. CI-Detector uses the attributed CFG to represent the semantics of
binary functions and GNN to embed binary functions into vectors. CI-Detector
respectively trains a model for these three cross-inlining patterns. Finally,
the testing pairs are input to these three models and all the produced
similarities are aggregated to produce the final similarity. We conduct several
experiments to evaluate CI-Detector. Results show that CI-Detector can detect
cross-inlining pairs with a precision of 81% and a recall of 97%, which exceeds
all state-of-the-art works.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05740" title="Abstract">arXiv:2401.05740</a> [<a href="/pdf/2401.05740" title="Download PDF">pdf</a>, <a href="/ps/2401.05740" title="Download PostScript">ps</a>, <a href="/format/2401.05740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved bound for the price of anarchy for related machine  scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berger%2C+A">Andre Berger</a>, 
<a href="/search/cs?searchtype=author&query=Rouhani%2C+A">Arman Rouhani</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+M">Marc Schr&#xf6;der</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In this paper, we introduce an improved upper bound for the efficiency of
Nash equilibria in utilitarian scheduling games on related machines. The
machines have varying speeds and adhere to the Shortest Processing Time (SPT)
policy as the global order for job processing. The goal of each job is to
minimize its completion time, while the social objective is to minimize the sum
of completion times. Our main result provides an upper bound of
$2-\frac{1}{2\cdot(2m-1)}$ on the price of anarchy for the general case of $m$
machines. We improve this bound to 3/2 for the case of two machines, and to
$2-\frac{1}{2\cdot m}$ for the general case of $m$ machines when the machines
have divisible speeds.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05743" title="Abstract">arXiv:2401.05743</a> [<a href="/pdf/2401.05743" title="Download PDF">pdf</a>, <a href="/ps/2401.05743" title="Download PostScript">ps</a>, <a href="/format/2401.05743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consistent Query Answering for Existential Rules under Tuple-Deletion  Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marconi%2C+L">Lorenzo Marconi</a>, 
<a href="/search/cs?searchtype=author&query=Rosati%2C+R">Riccardo Rosati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages including appendix. arXiv admin note: text overlap with <a href="/abs/2207.09198">arXiv:2207.09198</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">We study consistent query answering over knowledge bases expressed by
existential rules. Specifically, we establish the data complexity of consistent
query answering and repair checking under tuple-deletion semantics for a
general class of disjunctive existential rules and for several subclasses
thereof (acyclic, linear, full, guarded, and sticky). In particular, we
identify several cases in which the above problems are tractable or even
first-order rewritable, and present new query rewriting techniques that can be
the basis for practical inconsistency-tolerant query answering systems.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05744" title="Abstract">arXiv:2401.05744</a> [<a href="/pdf/2401.05744" title="Download PDF">pdf</a>, <a href="/format/2401.05744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Is Not the Only Choice: Counterfactual Reasoning for  Path-Based Explainable Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yicong Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiangguo Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sixiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guandong Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review by TKDE (2nd round)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Compared with only pursuing recommendation accuracy, the explainability of a
recommendation model has drawn more attention in recent years. Many graph-based
recommendations resort to informative paths with the attention mechanism for
the explanation. Unfortunately, these attention weights are intentionally
designed for model accuracy but not explainability. Recently, some researchers
have started to question attention-based explainability because the attention
weights are unstable for different reproductions, and they may not always align
with human intuition. Inspired by the counterfactual reasoning from causality
learning theory, we propose a novel explainable framework targeting path-based
recommendations, wherein the explainable weights of paths are learned to
replace attention weights. Specifically, we design two counterfactual reasoning
algorithms from both path representation and path topological structure
perspectives. Moreover, unlike traditional case studies, we also propose a
package of explainability evaluation solutions with both qualitative and
quantitative methods. We conduct extensive experiments on three real-world
datasets, the results of which further demonstrate the effectiveness and
reliability of our method.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05745" title="Abstract">arXiv:2401.05745</a> [<a href="/pdf/2401.05745" title="Download PDF">pdf</a>, <a href="/format/2401.05745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surface Normal Estimation with Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+B+S">Barry Shichen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Paetzold%2C+J">Johannes Paetzold</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H+H">Huy H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Echizen%2C+I">Isao Echizen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jiapeng Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose the use of a Transformer to accurately predict normals from point
clouds with noise and density variations. Previous learning-based methods
utilize PointNet variants to explicitly extract multi-scale features at
different input scales, then focus on a surface fitting method by which local
point cloud neighborhoods are fitted to a geometric surface approximated by
either a polynomial function or a multi-layer perceptron (MLP). However,
fitting surfaces to fixed-order polynomial functions can suffer from
overfitting or underfitting, and learning MLP-represented hyper-surfaces
requires pre-generated per-point weights. To avoid these limitations, we first
unify the design choices in previous works and then propose a simplified
Transformer-based model to extract richer and more robust geometric features
for the surface normal estimation task. Through extensive experiments, we
demonstrate that our Transformer-based method achieves state-of-the-art
performance on both the synthetic shape dataset PCPNet, and the real-world
indoor scene dataset SceneNN, exhibiting more noise-resilient behavior and
significantly faster inference. Most importantly, we demonstrate that the
sophisticated hand-designed modules in existing works are not necessary to
excel at the task of surface normal estimation.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05746" title="Abstract">arXiv:2401.05746</a> [<a href="/pdf/2401.05746" title="Download PDF">pdf</a>, <a href="/format/2401.05746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modality and Within-Modality Regularization for Audio-Visual  DeepFake Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+H">Heqing Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Meng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuchen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chng%2C+E+S">Eng Siong Chng</a>, 
<a href="/search/cs?searchtype=author&query=Rajan%2C+D">Deepu Rajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">Audio-visual deepfake detection scrutinizes manipulations in public video
using complementary multimodal cues. Current methods, which train on fused
multimodal data for multimodal targets face challenges due to uncertainties and
inconsistencies in learned representations caused by independent modality
manipulations in deepfake videos. To address this, we propose cross-modality
and within-modality regularization to preserve modality distinctions during
multimodal representation learning. Our approach includes an audio-visual
transformer module for modality correspondence and a cross-modality
regularization module to align paired audio-visual signals, preserving modality
distinctions. Simultaneously, a within-modality regularization module refines
unimodal representations with modality-specific targets to retain
modal-specific details. Experimental results on the public audio-visual
dataset, FakeAVCeleb, demonstrate the effectiveness and competitiveness of our
approach.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05749" title="Abstract">arXiv:2401.05749</a> [<a href="/pdf/2401.05749" title="Download PDF">pdf</a>, <a href="/format/2401.05749" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Shocking Amount of the Web is Machine Translated: Insights from  Multi-Way Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thompson%2C+B">Brian Thompson</a>, 
<a href="/search/cs?searchtype=author&query=Dhaliwal%2C+M+P">Mehak Preet Dhaliwal</a>, 
<a href="/search/cs?searchtype=author&query=Frisch%2C+P">Peter Frisch</a>, 
<a href="/search/cs?searchtype=author&query=Domhan%2C+T">Tobias Domhan</a>, 
<a href="/search/cs?searchtype=author&query=Federico%2C+M">Marcello Federico</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We show that content on the web is often translated into many languages, and
the low quality of these multi-way translations indicates they were likely
created using Machine Translation (MT). Multi-way parallel, machine generated
content not only dominates the translations in lower resource languages; it
also constitutes a large fraction of the total web content in those languages.
We also find evidence of a selection bias in the type of content which is
translated into many languages, consistent with low quality English content
being translated en masse into many lower resource languages, via MT. Our work
raises serious concerns about training models such as multilingual large
language models on both monolingual and bilingual data scraped from the web.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05750" title="Abstract">arXiv:2401.05750</a> [<a href="/pdf/2401.05750" title="Download PDF">pdf</a>, <a href="/format/2401.05750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GO-NeRF: Generating Virtual Objects in Neural Radiance Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+P">Peng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+F">Feitong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yinda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xiaojuan Qi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite advances in 3D generation, the direct creation of 3D objects within
an existing 3D scene represented as NeRF remains underexplored. This process
requires not only high-quality 3D object generation but also seamless
composition of the generated 3D content into the existing NeRF. To this end, we
propose a new method, GO-NeRF, capable of utilizing scene context for
high-quality and harmonious 3D object generation within an existing NeRF. Our
method employs a compositional rendering formulation that allows the generated
3D objects to be seamlessly composited into the scene utilizing learned
3D-aware opacity maps without introducing unintended scene modification.
Moreover, we also develop tailored optimization objectives and training
strategies to enhance the model's ability to exploit scene context and mitigate
artifacts, such as floaters, originating from 3D object generation within a
scene. Extensive experiments on both feed-forward and $360^o$ scenes show the
superior performance of our proposed GO-NeRF in generating objects harmoniously
composited with surrounding scenes and synthesizing high-quality novel view
images. Project page at {\url{https://daipengwa.github.io/GO-NeRF/}.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05752" title="Abstract">arXiv:2401.05752</a> [<a href="/pdf/2401.05752" title="Download PDF">pdf</a>, <a href="/format/2401.05752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Generalizable Models via Disentangling Spurious and Enhancing  Potential Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Na Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+L">Lei Qi</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jintao Guo</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yinghuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yang Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain generalization (DG) intends to train a model on multiple source
domains to ensure that it can generalize well to an arbitrary unseen target
domain. The acquisition of domain-invariant representations is pivotal for DG
as they possess the ability to capture the inherent semantic information of the
data, mitigate the influence of domain shift, and enhance the generalization
capability of the model. Adopting multiple perspectives, such as the sample and
the feature, proves to be effective. The sample perspective facilitates data
augmentation through data manipulation techniques, whereas the feature
perspective enables the extraction of meaningful generalization features. In
this paper, we focus on improving the generalization ability of the model by
compelling it to acquire domain-invariant representations from both the sample
and feature perspectives by disentangling spurious correlations and enhancing
potential correlations. 1) From the sample perspective, we develop a frequency
restriction module, guiding the model to focus on the relevant correlations
between object features and labels, thereby disentangling spurious
correlations. 2) From the feature perspective, the simple Tail Interaction
module implicitly enhances potential correlations among all samples from all
source domains, facilitating the acquisition of domain-invariant
representations across multiple domains for the model. The experimental results
show that Convolutional Neural Networks (CNNs) or Multi-Layer Perceptrons
(MLPs) with a strong baseline embedded with these two modules can achieve
superior results, e.g., an average accuracy of 92.30% on Digits-DG.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05753" title="Abstract">arXiv:2401.05753</a> [<a href="/pdf/2401.05753" title="Download PDF">pdf</a>, <a href="/ps/2401.05753" title="Download PostScript">ps</a>, <a href="/format/2401.05753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEC: Bit-Level Static Analysis for Reliability against Soft Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ko%2C+Y">Yousun Ko</a>, 
<a href="/search/cs?searchtype=author&query=Burgstaller%2C+B">Bernd Burgstaller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures, to be published in International Symposium on Code Generation and Optimization (CGO) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Soft errors are a type of transient digital signal corruption that occurs in
digital hardware components such as the internal flip-flops of CPU pipelines,
the register file, memory cells, and even internal communication buses. Soft
errors are caused by environmental radioactivity, magnetic interference,
lasers, and temperature fluctuations, either unintentionally, or as part of a
deliberate attempt to compromise a system and expose confidential data.
<br />We propose a bit-level error coalescing (BEC) static program analysis and its
two use cases to understand and improve program reliability against soft
errors. The BEC analysis tracks each bit corruption in the register file and
classifies the effect of the corruption by its semantics at compile time. The
usefulness of the proposed analysis is demonstrated in two scenarios, fault
injection campaign pruning, and reliability-aware program transformation.
Experimental results show that bit-level analysis pruned up to 30.04 % of
exhaustive fault injection campaigns (13.71 % on average), without loss of
accuracy. Program vulnerability was reduced by up to 13.11 % (4.94 % on
average) through bit-level vulnerability-aware instruction scheduling. The
analysis has been implemented within LLVM and evaluated on the RISC-V
architecture.
<br />To the best of our knowledge, the proposed BEC analysis is the first
bit-level compiler analysis for program reliability against soft errors. The
proposed method is generic and not limited to a specific computer architecture.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05757" title="Abstract">arXiv:2401.05757</a> [<a href="/pdf/2401.05757" title="Download PDF">pdf</a>, <a href="/ps/2401.05757" title="Download PostScript">ps</a>, <a href="/format/2401.05757" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intuitive Control of Scraping and Rubbing Through Audio-tactile  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aramaki%2C+M">Mitsuko Aramaki</a> (PRISM), 
<a href="/search/cs?searchtype=author&query=Bernard%2C+C">Corentin Bernard</a> (PRISM), 
<a href="/search/cs?searchtype=author&query=Kronland-Martinet%2C+R">Richard Kronland-Martinet</a> (PRISM), 
<a href="/search/cs?searchtype=author&query=Poirot%2C+S">Samuel Poirot</a> (PRISM), 
<a href="/search/cs?searchtype=author&query=Ystad%2C+S">S&#xf8;lvi Ystad</a> (PRISM)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 16th International Symposium on CMMR, Future University Hakodate,
  Japan; Asia University, Japan; Nihon University, Japan; Laboratoire PRISM,
  Marseille, France, Nov 2023, Tokyo, France
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS); Classical Physics (physics.class-ph)

</div>
<p class="mathjax">Intuitive control of synthesis processes is an ongoing challenge within the
domain of auditory perception and cognition. Previous works on sound modelling
combined with psychophysical tests have enabled our team to develop a
synthesizer that provides intuitive control of actions and objects based on
semantic descriptions for sound sources. In this demo we present an augmented
version of the synthesizer in which we added tactile stimulations to increase
the sensation of true continuous friction interactions (rubbing and scratching)
with the simulated objects. This is of interest for several reasons. Firstly,
it enables to evaluate the realism of our sound model in presence of
stimulations from other modalities. Secondly it enables to compare tactile and
auditory signal structures linked to the same evocation, and thirdly it
provides a tool to investigate multimodal perception and how stimulations from
different modalities should be combined to provide realistic user interfaces.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05759" title="Abstract">arXiv:2401.05759</a> [<a href="/pdf/2401.05759" title="Download PDF">pdf</a>, <a href="/ps/2401.05759" title="Download PostScript">ps</a>, <a href="/format/2401.05759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Analytic Gr{&#xf6;}bner Bases and Tropical Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vaccon%2C+T">Tristan Vaccon</a> (UNILIM), 
<a href="/search/cs?searchtype=author&query=Verron%2C+T">Thibaut Verron</a> (JKU)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ISSAC 2023: International Symposium on Symbolic and Algebraic
  Computation 2023, Jul 2023, Troms{{\o}}, Norway. pp.517-525
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Algebraic Geometry (math.AG); Number Theory (math.NT)

</div>
<p class="mathjax">A universal analytic Gr{\"o}bner basis (UAGB) of an ideal of a Tate algebra
is a set containing a local Gr{\"o}bner basis for all suitable convergence
radii. In a previous article, the authors proved the existence of finite UAGB's
for polynomial ideals, leaving open the question of how to compute them. In
this paper, we provide an algorithm computing a UAGB for a given polynomial
ideal, by traversing the Gr{\"o}bner fan of the ideal. As an application, it
offers a new point of view on algorithms for computing tropical varieties of
homogeneous polynomial ideals, which typically rely on lifting the computations
to an algebra of power series. Motivated by effective computations in tropical
analytic geometry, we also examine local bases for more general convergence
conditions, constraining the radii to a convex polyhedron. In this setting, we
provide an algorithm to compute local Gr{\"o}bner bases and discuss obstacles
towards proving the existence of finite UAGBs. CCS CONCEPTS $\bullet$ Computing
methodologies $\rightarrow$ Algebraic algorithms.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05761" title="Abstract">arXiv:2401.05761</a> [<a href="/pdf/2401.05761" title="Download PDF">pdf</a>, <a href="/ps/2401.05761" title="Download PostScript">ps</a>, <a href="/format/2401.05761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models vs. Search Engines: Evaluating User Preferences  Across Varied Information Retrieval Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caramancion%2C+K+M">Kevin Matthe Caramancion</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 20 figures, conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This study embarked on a comprehensive exploration of user preferences
between Search Engines and Large Language Models (LLMs) in the context of
various information retrieval scenarios. Conducted with a sample size of 100
internet users (N=100) from across the United States, the research delved into
20 distinct use cases ranging from factual searches, such as looking up
COVID-19 guidelines, to more subjective tasks, like seeking interpretations of
complex concepts in layman's terms. Participants were asked to state their
preference between using a traditional search engine or an LLM for each
scenario. This approach allowed for a nuanced understanding of how users
perceive and utilize these two predominant digital tools in differing contexts.
The use cases were carefully selected to cover a broad spectrum of typical
online queries, thus ensuring a comprehensive analysis of user preferences. The
findings reveal intriguing patterns in user choices, highlighting a clear
tendency for participants to favor search engines for direct, fact-based
queries, while LLMs were more often preferred for tasks requiring nuanced
understanding and language processing. These results offer valuable insights
into the current state of digital information retrieval and pave the way for
future innovations in this field. This study not only sheds light on the
specific contexts in which each tool is favored but also hints at the potential
for developing hybrid models that leverage the strengths of both search engines
and LLMs. The insights gained from this research are pivotal for developers,
researchers, and policymakers in understanding the evolving landscape of
digital information retrieval and user interaction with these technologies.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05767" title="Abstract">arXiv:2401.05767</a> [<a href="/pdf/2401.05767" title="Download PDF">pdf</a>, <a href="/format/2401.05767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifelogging As An Extreme Form of Personal Information Management --  What Lessons To Learn
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Ly-Duyen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Gurrin%2C+C">Cathal Gurrin</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Data Engineering Bulletin 47 (4), 18-29, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Personal data includes the digital footprints that we leave behind as part of
our everyday activities, both online and offline in the real world. It includes
data we collect ourselves, such as from wearables, as well as the data
collected by others about our online behaviour and activities. Sometimes we are
able to use the personal data we ourselves collect, in order to examine some
parts of our lives but for the most part, our personal data is leveraged by
third parties including internet companies, for services like targeted
advertising and recommendations. Lifelogging is a form of extreme personal data
gathering and in this article we present an overview of the tools used to
manage access to lifelogs as demonstrated at the most recent of the annual
Lifelog Search Challenge benchmarking workshops. Here, experimental systems are
showcased in live, real time information seeking tasks by real users. This
overview of these systems' capabilities show the range of possibilities for
accessing our own personal data which may, in time, become more easily
available as consumer-level services.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05768" title="Abstract">arXiv:2401.05768</a> [<a href="/pdf/2401.05768" title="Download PDF">pdf</a>, <a href="/format/2401.05768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Data Augmentation Techniques for Coffee Leaf Disease  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gheorghiu%2C+A">Adrian Gheorghiu</a>, 
<a href="/search/cs?searchtype=author&query=T%C4%83iatu%2C+I">Iulian-Marius T&#x103;iatu</a>, 
<a href="/search/cs?searchtype=author&query=Cercel%2C+D">Dumitru-Clementin Cercel</a>, 
<a href="/search/cs?searchtype=author&query=Marin%2C+I">Iuliana Marin</a>, 
<a href="/search/cs?searchtype=author&query=Pop%2C+F">Florin Pop</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICAART 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The detection and classification of diseases in Robusta coffee leaves are
essential to ensure that plants are healthy and the crop yield is kept high.
However, this job requires extensive botanical knowledge and much wasted time.
Therefore, this task and others similar to it have been extensively researched
subjects in image classification. Regarding leaf disease classification, most
approaches have used the more popular PlantVillage dataset while completely
disregarding other datasets, like the Robusta Coffee Leaf (RoCoLe) dataset. As
the RoCoLe dataset is imbalanced and does not have many samples, fine-tuning of
pre-trained models and multiple augmentation techniques need to be used. The
current paper uses the RoCoLe dataset and approaches based on deep learning for
classifying coffee leaf diseases from images, incorporating the pix2pix model
for segmentation and cycle-generative adversarial network (CycleGAN) for
augmentation. Our study demonstrates the effectiveness of Transformer-based
models, online augmentations, and CycleGAN augmentation in improving leaf
disease classification. While synthetic data has limitations, it complements
real data, enhancing model performance. These findings contribute to developing
robust techniques for plant disease detection and classification.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05771" title="Abstract">arXiv:2401.05771</a> [<a href="/pdf/2401.05771" title="Download PDF">pdf</a>, <a href="/ps/2401.05771" title="Download PostScript">ps</a>, <a href="/format/2401.05771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learn From Zoom: Decoupled Supervised Contrastive Learning For WCE Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+K">Kunpeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhiying Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yongxin Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Accurate lesion classification in Wireless Capsule Endoscopy (WCE) images is
vital for early diagnosis and treatment of gastrointestinal (GI) cancers.
However, this task is confronted with challenges like tiny lesions and
background interference. Additionally, WCE images exhibit higher intra-class
variance and inter-class similarities, adding complexity. To tackle these
challenges, we propose Decoupled Supervised Contrastive Learning for WCE image
classification, learning robust representations from zoomed-in WCE images
generated by Saliency Augmentor. Specifically, We use uniformly down-sampled
WCE images as anchors and WCE images from the same class, especially their
zoomed-in images, as positives. This approach empowers the Feature Extractor to
capture rich representations from various views of the same image, facilitated
by Decoupled Supervised Contrastive Learning. Training a linear Classifier on
these representations within 10 epochs yields an impressive 92.01% overall
accuracy, surpassing the prior state-of-the-art (SOTA) by 0.72% on a blend of
two publicly accessible WCE datasets. Code is available at:
https://github.com/Qiukunpeng/DSCL.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05772" title="Abstract">arXiv:2401.05772</a> [<a href="/pdf/2401.05772" title="Download PDF">pdf</a>, <a href="/format/2401.05772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knowledge Translation: A New Pathway for Model Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wujie Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Defang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Can Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep learning has witnessed significant advancements in recent years at the
cost of increasing training, inference, and model storage overhead. While
existing model compression methods strive to reduce the number of model
parameters while maintaining high accuracy, they inevitably necessitate the
re-training of the compressed model or impose architectural constraints. To
overcome these limitations, this paper presents a novel framework, termed
\textbf{K}nowledge \textbf{T}ranslation (KT), wherein a ``translation'' model
is trained to receive the parameters of a larger model and generate compressed
parameters. The concept of KT draws inspiration from language translation,
which effectively employs neural networks to convert different languages,
maintaining identical meaning. Accordingly, we explore the potential of neural
networks to convert models of disparate sizes, while preserving their
functionality. We propose a comprehensive framework for KT, introduce data
augmentation strategies to enhance model performance despite restricted
training data, and successfully demonstrate the feasibility of KT on the MNIST
dataset. Code is available at \url{https://github.com/zju-SWJ/KT}.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05777" title="Abstract">arXiv:2401.05777</a> [<a href="/pdf/2401.05777" title="Download PDF">pdf</a>, <a href="/format/2401.05777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probing Structured Semantics Understanding and Generation of Language  Models via Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+S">Shulin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiaxin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingjian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ARR, 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancement in the capabilities of large language models (LLMs) has
triggered a new surge in LLMs' evaluation. Most recent evaluation works tends
to evaluate the comprehensive ability of LLMs over series of tasks. However,
the deep structure understanding of natural language is rarely explored. In
this work, we examine the ability of LLMs to deal with structured semantics on
the tasks of question answering with the help of the human-constructed formal
language. Specifically, we implement the inter-conversion of natural and formal
language through in-context learning of LLMs to verify their ability to
understand and generate the structured logical forms. Extensive experiments
with models of different sizes and in different formal languages show that
today's state-of-the-art LLMs' understanding of the logical forms can approach
human level overall, but there still are plenty of room in generating correct
logical forms, which suggest that it is more effective to use LLMs to generate
more natural language training data to reinforce a small model than directly
answering questions with LLMs. Moreover, our results also indicate that models
exhibit considerable sensitivity to different formal languages. In general, the
formal language with the lower the formalization level, i.e. the more similar
it is to natural language, is more LLMs-friendly.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05778" title="Abstract">arXiv:2401.05778</a> [<a href="/pdf/2401.05778" title="Download PDF">pdf</a>, <a href="/format/2401.05778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language  Model Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Tianyu Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+C">Chuanpu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yong Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xinhao Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yunpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qinglin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Ziyi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peiyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhixing Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Junwu Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xinyu Kong</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Z">Zujie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have strong capabilities in solving diverse
natural language processing tasks. However, the safety and security issues of
LLM systems have become the major obstacle to their widespread application.
Many studies have extensively investigated risks in LLM systems and developed
the corresponding mitigation strategies. Leading-edge enterprises such as
OpenAI, Google, Meta, and Anthropic have also made lots of efforts on
responsible LLMs. Therefore, there is a growing need to organize the existing
studies and establish comprehensive taxonomies for the community. In this
paper, we delve into four essential modules of an LLM system, including an
input module for receiving prompts, a language model trained on extensive
corpora, a toolchain module for development and deployment, and an output
module for exporting LLM-generated content. Based on this, we propose a
comprehensive taxonomy, which systematically analyzes potential risks
associated with each module of an LLM system and discusses the corresponding
mitigation strategies. Furthermore, we review prevalent benchmarks, aiming to
facilitate the risk assessment of LLM systems. We hope that this paper can help
LLM participants embrace a systematic perspective to build their responsible
LLM systems.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05779" title="Abstract">arXiv:2401.05779</a> [<a href="/pdf/2401.05779" title="Download PDF">pdf</a>, <a href="/format/2401.05779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EraseDiff: Erasing Data Influence in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+T">Trung Le</a>, 
<a href="/search/cs?searchtype=author&query=Hayat%2C+M">Munawar Hayat</a>, 
<a href="/search/cs?searchtype=author&query=Harandi%2C+M">Mehrtash Harandi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Diffusion Model, Machine Unlearning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In response to data protection regulations and the ``right to be forgotten'',
in this work, we introduce an unlearning algorithm for diffusion models. Our
algorithm equips a diffusion model with a mechanism to mitigate the concerns
related to data memorization. To achieve this, we formulate the unlearning
problem as a bi-level optimization problem, wherein the outer objective is to
preserve the utility of the diffusion model on the remaining data. The inner
objective aims to scrub the information associated with forgetting data by
deviating the learnable generative process from the ground-truth denoising
procedure. To solve the resulting bi-level problem, we adopt a first-order
method, having superior practical performance while being vigilant about the
diffusion process and solving a bi-level problem therein. Empirically, we
demonstrate that our algorithm can preserve the model utility, effectiveness,
and efficiency while removing across two widely-used diffusion models and in
both conditional and unconditional image generation scenarios. In our
experiments, we demonstrate the unlearning of classes, attributes, and even a
race from face and object datasets such as UTKFace, CelebA, CelebA-HQ, and
CIFAR10.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05782" title="Abstract">arXiv:2401.05782</a> [<a href="/pdf/2401.05782" title="Download PDF">pdf</a>, <a href="/format/2401.05782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online input design for discrimination of linear models using concave  minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Noom%2C+J">Jacques Noom</a>, 
<a href="/search/eess?searchtype=author&query=Soloviev%2C+O">Oleg Soloviev</a>, 
<a href="/search/eess?searchtype=author&query=Smith%2C+C">Carlas Smith</a>, 
<a href="/search/eess?searchtype=author&query=Verhaegen%2C+M">Michel Verhaegen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Stochastic Closed-Loop Active Fault Diagnosis (CLAFD) aims to select the
input sequentially in order to improve the discrimination of different models
by minimizing the predicted error probability. As computation of these error
probabilities encompasses the evaluation of multidimensional probability
integrals, relaxation methods are of interest. This manuscript presents a new
method that allows to make an improved trade-off between three factors --
namely maximized accuracy of diagnosis, minimized number of consecutive
measurements to achieve that accuracy, and minimized computational effort per
time step -- with respect to the state-of-the-art. It relies on minimizing an
upper bound on the error probability, which is in the case of linear models
with Gaussian noise proven to be concave in the most challenging discrimination
conditions. A simulation study is conducted both for open-loop and feedback
controlled candidate models. The results demonstrate the favorable trade-off
using the new contributions in this manuscript.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05783" title="Abstract">arXiv:2401.05783</a> [<a href="/pdf/2401.05783" title="Download PDF">pdf</a>, <a href="/format/2401.05783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What Else Would I Like? A User Simulator using Alternatives for Improved  Evaluation of Fashion Conversational Recommendation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vlachou%2C+M">Maria Vlachou</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Craig Macdonald</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">In Conversational Recommendation Systems (CRS), a user can provide feedback
on recommended items at each interaction turn, leading the CRS towards more
desirable recommendations. Currently, different types of CRS offer various
possibilities for feedback, i.e., natural language feedback, or answering
clarifying questions. In most cases, a user simulator is employed for training
as well as evaluating the CRS. Such user simulators typically critique the
current retrieved items based on knowledge of a single target item. Still,
evaluating systems in offline settings with simulators suffers from problems,
such as focusing entirely on a single target item (not addressing the
exploratory nature of a recommender system), and exhibiting extreme patience
(consistent feedback over a large number of turns). To overcome these
limitations, we obtain extra judgements for a selection of alternative items in
common CRS datasets, namely Shoes and Fashion IQ Dresses. Going further, we
propose improved user simulators that allow simulated users not only to express
their preferences about alternative items to their original target, but also to
change their mind and level of patience. In our experiments using the relative
image captioning CRS setting and different CRS models, we find that using the
knowledge of alternatives by the simulator can have a considerable impact on
the evaluation of existing CRS models, specifically that the existing
single-target evaluation underestimates their effectiveness, and when simulated
users are allowed to instead consider alternatives, the system can rapidly
respond to more quickly satisfy the user.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05787" title="Abstract">arXiv:2401.05787</a> [<a href="/pdf/2401.05787" title="Download PDF">pdf</a>, <a href="/format/2401.05787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidence to Generate (E2G): A Single-agent Two-step Prompting for  Context Grounded and Retrieval Augmented Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parvez%2C+M+R">Md Rizwan Parvez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While chain-of-thought (CoT) prompting has revolutionized how LLMs perform
reasoning tasks, its current methods and variations (e.g, Self-consistency,
ReACT, Reflexion, Tree-of-Thoughts (ToT), Cumulative Reasoning (CR)) suffer
from limitations like slowness, limited context grounding, hallucination and
inconsistent outputs. To overcome these challenges, we introduce Evidence to
Generate (E2G), a novel single-agent, two-step prompting framework. Instead of
unverified reasoning claims, this innovative approach leverages the power of
"evidence for decision making" by first focusing exclusively on the thought
sequences (the series of intermediate steps) explicitly mentioned in the
context which then serve as extracted evidence, guiding the LLM's output
generation process with greater precision and efficiency. This simple yet
powerful approach unlocks the true potential of chain-of-thought like
prompting, paving the way for faster, more reliable, and more contextually
aware reasoning in LLMs. \tool achieves remarkable results robustly across a
wide range of knowledge-intensive reasoning and generation tasks, surpassing
baseline approaches with state-of-the-art LLMs. For example, (i) on LogiQA
benchmark using GPT-4 as backbone model, \tool achieves a new state-of-the
Accuracy of 53.8% exceeding CoT by 18%, ToT by 11%, CR by 9% (ii) a variant of
E2G with PaLM2 outperforms the variable-shot performance of Gemini Ultra by 0.9
F1 points, reaching an F1 score of 83.3 on a subset of DROP.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05790" title="Abstract">arXiv:2401.05790</a> [<a href="/pdf/2401.05790" title="Download PDF">pdf</a>, <a href="/ps/2401.05790" title="Download PostScript">ps</a>, <a href="/format/2401.05790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development in times of hype: How freelancers explore Generative AI?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dolata%2C+M">Mateusz Dolata</a>, 
<a href="/search/cs?searchtype=author&query=Lange%2C+N">Norbert Lange</a>, 
<a href="/search/cs?searchtype=author&query=Schwabe%2C+G">Gerhard Schwabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The rise of generative AI has led many companies to hire freelancers to
harness its potential. However, this technology presents unique challenges to
developers who have not previously engaged with it. Freelancers may find these
challenges daunting due to the absence of organizational support and their
reliance on positive client feedback. In a study involving 52 freelance
developers, we identified multiple challenges associated with developing
solutions based on generative AI. Freelancers often struggle with aspects they
perceive as unique to generative AI such as unpredictability of its output, the
occurrence of hallucinations, and the inconsistent effort required due to
trial-and-error prompting cycles. Further, the limitations of specific
frameworks, such as token limits and long response times, add to the
complexity. Hype-related issues, such as inflated client expectations and a
rapidly evolving technological ecosystem, further exacerbate the difficulties.
To address these issues, we propose Software Engineering for Generative AI
(SE4GenAI) and Hype-Induced Software Engineering (HypeSE) as areas where the
software engineering community can provide effective guidance. This support is
essential for freelancers working with generative AI and other emerging
technologies.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05792" title="Abstract">arXiv:2401.05792</a> [<a href="/pdf/2401.05792" title="Download PDF">pdf</a>, <a href="/format/2401.05792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering Low-rank Subspaces for Language-agnostic Multilingual  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhihui Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Handong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tong Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures, EMNLP 2022 (main conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large pretrained multilingual language models (ML-LMs) have shown remarkable
capabilities of zero-shot cross-lingual transfer, without direct cross-lingual
supervision. While these results are promising, follow-up works found that,
within the multilingual embedding spaces, there exists strong language identity
information which hinders the expression of linguistic factors shared across
languages. For semantic tasks like cross-lingual sentence retrieval, it is
desired to remove such language identity signals to fully leverage semantic
information. In this work, we provide a novel view of projecting away
language-specific factors from a multilingual embedding space. Specifically, we
discover that there exists a low-rank subspace that primarily encodes
information irrelevant to semantics (e.g., syntactic information). To identify
this subspace, we present a simple but effective unsupervised method based on
singular value decomposition with multiple monolingual corpora as input. Once
the subspace is found, we can directly project the original embeddings into the
null space to boost language agnosticism without finetuning. We systematically
evaluate our method on various tasks including the challenging
language-agnostic QA retrieval task. Empirical results show that applying our
method consistently leads to improvements over commonly used ML-LMs.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05794" title="Abstract">arXiv:2401.05794</a> [<a href="/pdf/2401.05794" title="Download PDF">pdf</a>, <a href="/ps/2401.05794" title="Download PostScript">ps</a>, <a href="/format/2401.05794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds on the price of feedback for mistake-bounded online learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geneson%2C+J">Jesse Geneson</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Linus Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We improve several worst-case bounds for various online learning scenarios
from (Auer and Long, Machine Learning, 1999). In particular, we sharpen an
upper bound for delayed ambiguous reinforcement learning by a factor of 2, an
upper bound for learning compositions of families of functions by a factor of
2.41, and an upper bound for agnostic learning by a factor of 1.09. We also
improve a lower bound from the same paper for learning compositions of $k$
families of functions by a factor of $\Theta(\ln{k})$, matching the upper bound
up to a constant factor. In addition, we solve a problem from (Long,
Theoretical Computer Science, 2020) on the price of bandit feedback with
respect to standard feedback for multiclass learning, and we improve an upper
bound from (Feng et al., Theoretical Computer Science, 2023) on the price of
$r$-input delayed ambiguous reinforcement learning by a factor of $r$, matching
a lower bound from the same paper up to the leading term.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05797" title="Abstract">arXiv:2401.05797</a> [<a href="/pdf/2401.05797" title="Download PDF">pdf</a>, <a href="/format/2401.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STAKESURE: Proof of Stake Mechanisms with Strong Cryptoeconomic Safety
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deb%2C+S">Soubhik Deb</a>, 
<a href="/search/cs?searchtype=author&query=Raynor%2C+R">Robert Raynor</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S">Sreeram Kannan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">As of July 15, 2023, Ethererum, which is a Proof-of-Stake (PoS) blockchain
[1] has around 410 Billion USD in total assets on chain (popularly referred to
as total-value-locked, TVL) but has only 33 Billion USD worth of ETH staked in
securing the underlying consensus of the chain [2]. A preliminary analysis
might suggest that as the amount staked is far less (11x less) than the value
secured, the Ethereum blockchain is insecure and "over-leveraged" in a purely
cryptoeconomic sense. In this work, we investigate how Ethereum, or, more
generally, any PoS blockchain can be made secure despite this apparent
imbalance. Towards that end, we attempt to formalize a model for analyzing the
cryptoeconomic safety of PoS blockchain, which separately analyzes the
cost-of-corruption, the cost incurred by an attacker, and the
profit-from-corruption, the profit gained by an attacker. We derive sharper
bounds on profit-from-corruption, as well as new confirmation rules that
significantly decrease this upper-bound. We evaluate cost-of-corruption and
profit-from-corruption only from the perspective of attacking safety. Finally,
we present a new "insurance" mechanism, STAKESURE, for allocating the slashed
funds in a PoS system, that has several highly desirable properties: solving
common information problem in existing blockchains, creating a mechanism for
provably safe bridging, and providing the first sharp solution for
automatically adjusting how much economic security is sufficient in a PoS
system. Finally, we show that the system satisfies a notion of strong
cryptoeconomic safety, which guarantees that no honest transactor ever loses
money, and creates a closed system of Karma, which not only ensures that the
attacker suffers a loss of funds but also that the harmed parties are
sufficiently compensated.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05799" title="Abstract">arXiv:2401.05799</a> [<a href="/pdf/2401.05799" title="Download PDF">pdf</a>, <a href="/format/2401.05799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Heterogeneous LLM Agents for Financial Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+F">Frank Xing</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); General Finance (q-fin.GN)

</div>
<p class="mathjax">Large language models (LLMs) have drastically changed the possible ways to
design intelligent systems, shifting the focuses from massive data acquisition
and new modeling training to human alignment and strategical elicitation of the
full potential of existing pre-trained models. This paradigm shift, however, is
not fully realized in financial sentiment analysis (FSA), due to the
discriminative nature of this task and a lack of prescriptive knowledge of how
to leverage generative models in such a context. This study investigates the
effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for
FSA. Rooted in Minsky's theory of mind and emotions, a design framework with
heterogeneous LLM agents is proposed. The framework instantiates specialized
agents using prior domain knowledge of the types of FSA errors and reasons on
the aggregated agent discussions. Comprehensive evaluation on FSA datasets show
that the framework yields better accuracies, especially when the discussions
are substantial. This study contributes to the design foundations and paves new
avenues for LLMs-based FSA. Implications on business and management are also
discussed.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05800" title="Abstract">arXiv:2401.05800</a> [<a href="/pdf/2401.05800" title="Download PDF">pdf</a>, <a href="/format/2401.05800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Spatiotemporal Process for Multivariate Time Series Anomaly  Detection with Missing Values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Koh%2C+H+Y">Huan Yee Koh</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Ming Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+L">Lianhua Chi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haishuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+K+T">Khoa T. Phan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y+P">Yi-Ping Phoebe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wei Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Information Fusion
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The detection of anomalies in multivariate time series data is crucial for
various practical applications, including smart power grids, traffic flow
forecasting, and industrial process control. However, real-world time series
data is usually not well-structured, posting significant challenges to existing
approaches: (1) The existence of missing values in multivariate time series
data along variable and time dimensions hinders the effective modeling of
interwoven spatial and temporal dependencies, resulting in important patterns
being overlooked during model training; (2) Anomaly scoring with
irregularly-sampled observations is less explored, making it difficult to use
existing detectors for multivariate series without fully-observed values. In
this work, we introduce a novel framework called GST-Pro, which utilizes a
graph spatiotemporal process and anomaly scorer to tackle the aforementioned
challenges in detecting anomalies on irregularly-sampled multivariate time
series. Our approach comprises two main components. First, we propose a graph
spatiotemporal process based on neural controlled differential equations. This
process enables effective modeling of multivariate time series from both
spatial and temporal perspectives, even when the data contains missing values.
Second, we present a novel distribution-based anomaly scoring mechanism that
alleviates the reliance on complete uniform observations. By analyzing the
predictions of the graph spatiotemporal process, our approach allows anomalies
to be easily detected. Our experimental results show that the GST-Pro method
can effectively detect anomalies in time series data and outperforms
state-of-the-art methods, regardless of whether there are missing values
present in the data. Our code is available: https://github.com/huankoh/GST-Pro.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05802" title="Abstract">arXiv:2401.05802</a> [<a href="/pdf/2401.05802" title="Download PDF">pdf</a>, <a href="/format/2401.05802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferability of HRI Research: Potential and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johal%2C+W">Wafa Johal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI Spring Symposium 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With advancement of robotics and artificial intelligence, applications for
robotics are flourishing. Human-robot interaction (HRI) is an important area of
robotics as it allows robots to work closer to humans (with them or for them).
One crucial factor for the success of HRI research is transferability, which
refers to the ability of research outputs to be adopted by industry and provide
benefits to society. In this paper, we explore the potentials and challenges of
transferability in HRI research. Firstly, we examine the current state of HRI
research and identify various types of contributions that could lead to
successful outcomes. Secondly, we discuss the potential benefits for each type
of contribution and identify factors that could facilitate industry adoption of
HRI research. However, we also recognize that there are several challenges
associated with transferability, such as the diversity of well-defined
job/skill-sets required from HRI practitioners, the lack of industry-led
research, and the lack of standardization in HRI research methods. We discuss
these challenges and propose potential solutions to bridge the gap between
industry expectations and academic research in HRI.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05806" title="Abstract">arXiv:2401.05806</a> [<a href="/pdf/2401.05806" title="Download PDF">pdf</a>, <a href="/format/2401.05806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-Driven Semantic Discovery Network for Visible-Infrared Person  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xiaoyan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+N">Neng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dapeng Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Visible-infrared person re-identification (VIReID) primarily deals with
matching identities across person images from different modalities. Due to the
modality gap between visible and infrared images, cross-modality identity
matching poses significant challenges. Recognizing that high-level semantics of
pedestrian appearance, such as gender, shape, and clothing style, remain
consistent across modalities, this paper intends to bridge the modality gap by
infusing visual features with high-level semantics. Given the capability of
CLIP to sense high-level semantic information corresponding to visual
representations, we explore the application of CLIP within the domain of
VIReID. Consequently, we propose a CLIP-Driven Semantic Discovery Network
(CSDN) that consists of Modality-specific Prompt Learner, Semantic Information
Integration (SII), and High-level Semantic Embedding (HSE). Specifically,
considering the diversity stemming from modality discrepancies in language
descriptions, we devise bimodal learnable text tokens to capture
modality-private semantic information for visible and infrared images,
respectively. Additionally, acknowledging the complementary nature of semantic
details across different modalities, we integrate text features from the
bimodal language descriptions to achieve comprehensive semantics. Finally, we
establish a connection between the integrated text features and the visual
features across modalities. This process embed rich high-level semantic
information into visual representations, thereby promoting the modality
invariance of visual representations. The effectiveness and superiority of our
proposed CSDN over existing methods have been substantiated through
experimental evaluations on multiple widely used benchmarks. The code will be
released at \url{https://github.com/nengdong96/CSDN}.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05807" title="Abstract">arXiv:2401.05807</a> [<a href="/pdf/2401.05807" title="Download PDF">pdf</a>, <a href="/format/2401.05807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the representation and methodology for wide and short range head pose  estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cobo%2C+A">Alejandro Cobo</a>, 
<a href="/search/cs?searchtype=author&query=Valle%2C+R">Roberto Valle</a>, 
<a href="/search/cs?searchtype=author&query=Buenaposada%2C+J+M">Jos&#xe9; M. Buenaposada</a>, 
<a href="/search/cs?searchtype=author&query=Baumela%2C+L">Luis Baumela</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Head pose estimation (HPE) is a problem of interest in computer vision to
improve the performance of face processing tasks in semi-frontal or profile
settings. Recent applications require the analysis of faces in the full
360{\deg} rotation range. Traditional approaches to solve the semi-frontal and
profile cases are not directly amenable for the full rotation case. In this
paper we analyze the methodology for short- and wide-range HPE and discuss
which representations and metrics are adequate for each case. We show that the
popular Euler angles representation is a good choice for short-range HPE, but
not at extreme rotations. However, the Euler angles' gimbal lock problem
prevents them from being used as a valid metric in any setting. We also revisit
the current cross-data set evaluation methodology and note that the lack of
alignment between the reference systems of the training and test data sets
negatively biases the results of all articles in the literature. We introduce a
procedure to quantify this misalignment and a new methodology for cross-data
set HPE that establishes new, more accurate, SOTA for the 300W-LP|Biwi
benchmark. We also propose a generalization of the geodesic angular distance
metric that enables the construction of a loss that controls the contribution
of each training sample to the optimization of the model. Finally, we introduce
a wide range HPE benchmark based on the CMU Panoptic data set.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05808" title="Abstract">arXiv:2401.05808</a> [<a href="/pdf/2401.05808" title="Download PDF">pdf</a>, <a href="/format/2401.05808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Consensus of Networked Random Nonlinear Multi-agent Systems  with Intermittent Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Azarbahram%2C+A">Ali Azarbahram</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The paper proposes an intermittent communication mechanism for the tracking
consensus of high-order nonlinear multi-agent systems (MASs) surrounded by
random disturbances. Each collaborating agent is described by a class of
high-order nonlinear uncertain strict-feedback dynamics which is disturbed by a
wide stationary process representing the external noise. The resiliency level
of this networked control system (NCS) to the failures of physical devices or
unreliability of communication channels is analyzed by introducing a linear
auxiliary trajectory of the system. More precisely, the unreliability of
communication channels sometimes makes an agent incapable of sensing the local
information or receiving it from neighboring nodes. Therefore, an intermittent
communication scheme is proposed among the follower agents as a consequence of
employing the linear auxiliary dynamics. The closed-loop networked system
signals are proved to be noise-to-state practically stable in probability
(NSpS-P). It has been justified that each agent follows the trajectory of the
corresponding local auxiliary virtual system practically in probability. The
simulation experiments finally quantify the effectiveness of our proposed
approach in terms of providing a resilient performance against unreliability of
communication channels and reaching the tracking consensus.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05811" title="Abstract">arXiv:2401.05811</a> [<a href="/pdf/2401.05811" title="Download PDF">pdf</a>, <a href="/format/2401.05811" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning LLMs with Contrastive Alignment Instructions for Machine  Translation in Unseen, Low-resource Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+Z">Zhuoyuan Mao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yen Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This article introduces contrastive alignment instructions (AlignInstruct) to
address two challenges in machine translation (MT) on large language models
(LLMs). One is the expansion of supported languages to previously unseen ones.
The second relates to the lack of data in low-resource languages. Model
fine-tuning through MT instructions (MTInstruct) is a straightforward approach
to the first challenge. However, MTInstruct is limited by weak cross-lingual
signals inherent in the second challenge. AlignInstruct emphasizes
cross-lingual supervision via a cross-lingual discriminator built using
statistical word alignments. Our results based on fine-tuning the BLOOMZ models
(1b1, 3b, and 7b1) in up to 24 unseen languages showed that: (1) LLMs can
effectively translate unseen languages using MTInstruct; (2) AlignInstruct led
to consistent improvements in translation quality across 48 translation
directions involving English; (3) Discriminator-based instructions outperformed
their generative counterparts as cross-lingual instructions; (4) AlignInstruct
improved performance in 30 zero-shot directions.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05818" title="Abstract">arXiv:2401.05818</a> [<a href="/pdf/2401.05818" title="Download PDF">pdf</a>, <a href="/ps/2401.05818" title="Download PostScript">ps</a>, <a href="/format/2401.05818" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to write a CHI paper (asking for a friend)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinson%2C+R">Raquel Robinson</a>, 
<a href="/search/cs?searchtype=author&query=Alvarez%2C+A">Alberto Alvarez</a>, 
<a href="/search/cs?searchtype=author&query=Mekler%2C+E">Elisa Mekler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Writing and genre conventions are extant to any scientific community, and CHI
is no different. In this paper, we present the early phases of an AI tool we
created called KITSUNE, which supports authors in placing their work into the
format of a CHI paper, taking into account many conventions that are
ever-present in CHI papers. We describe the development of the tool with the
intent to promote discussion around how writing conventions are upheld and
unquestioned by the CHI community, and how this translates to the work
produced. In addition, we bring up questions surrounding how the introduction
of LLMs into academic writing fundamentally change how conventions will be
upheld now and in the future
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05820" title="Abstract">arXiv:2401.05820</a> [<a href="/pdf/2401.05820" title="Download PDF">pdf</a>, <a href="/format/2401.05820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implications of Noise in Resistive Memory on Deep Neural Networks for  Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Emonds%2C+Y">Yannick Emonds</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+K">Kai Xi</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6ning%2C+H">Holger Fr&#xf6;ning</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Performance (cs.PF)

</div>
<p class="mathjax">Resistive memory is a promising alternative to SRAM, but is also an
inherently unstable device that requires substantial effort to ensure correct
read and write operations. To avoid the associated costs in terms of area, time
and energy, the present work is concerned with exploring how much noise in
memory operations can be tolerated by image classification tasks based on
neural networks. We introduce a special noisy operator that mimics the noise in
an exemplary resistive memory unit, explore the resilience of convolutional
neural networks on the CIFAR-10 classification task, and discuss a couple of
countermeasures to improve this resilience.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05821" title="Abstract">arXiv:2401.05821</a> [<a href="/pdf/2401.05821" title="Download PDF">pdf</a>, <a href="/format/2401.05821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delfosse%2C+Q">Quentin Delfosse</a>, 
<a href="/search/cs?searchtype=author&query=Sztwiertnia%2C+S">Sebastian Sztwiertnia</a>, 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+M">Mark Rothermel</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 of main text, 7 of appendix, 3 main figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Reward sparsity, difficult credit assignment, and misalignment are only a few
of the many issues that make it difficult, if not impossible, for deep
reinforcement learning (RL) agents to learn optimal policies. Unfortunately,
the black-box nature of deep networks impedes the inclusion of domain experts
who could interpret the model and correct wrong behavior. To this end, we
introduce Successive Concept Bottlenecks Agents (SCoBots), which make the whole
decision pipeline transparent via the integration of consecutive concept
bottleneck layers. SCoBots make use of not only relevant object properties but
also of relational concepts. Our experimental results provide strong evidence
that SCoBots allow domain experts to efficiently understand and regularize
their behavior, resulting in potentially better human-aligned RL. In this way,
SCoBots enabled us to identify a misalignment problem in the most simple and
iconic video game, Pong, and resolve it.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05822" title="Abstract">arXiv:2401.05822</a> [<a href="/pdf/2401.05822" title="Download PDF">pdf</a>, <a href="/format/2401.05822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Goal-Oriented Agents for Evolving Problems Observed via  Conversation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Free%2C+M">Michael Free</a>, 
<a href="/search/cs?searchtype=author&query=Langworthy%2C+A">Andrew Langworthy</a>, 
<a href="/search/cs?searchtype=author&query=Dimitropoulaki%2C+M">Mary Dimitropoulaki</a>, 
<a href="/search/cs?searchtype=author&query=Thompson%2C+S">Simon Thompson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Artificial Intelligence XL. SGAI 2023. Lecture Notes in Computer
  Science, vol 14381. 142-155
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The objective of this work is to train a chatbot capable of solving evolving
problems through conversing with a user about a problem the chatbot cannot
directly observe. The system consists of a virtual problem (in this case a
simple game), a simulated user capable of answering natural language questions
that can observe and perform actions on the problem, and a Deep Q-Network
(DQN)-based chatbot architecture. The chatbot is trained with the goal of
solving the problem through dialogue with the simulated user using
reinforcement learning. The contributions of this paper are as follows: a
proposed architecture to apply a conversational DQN-based agent to evolving
problems, an exploration of training methods such as curriculum learning on
model performance and the effect of modified reward functions in the case of
increasing environment complexity.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05824" title="Abstract">arXiv:2401.05824</a> [<a href="/pdf/2401.05824" title="Download PDF">pdf</a>, <a href="/format/2401.05824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Youth WellTech: A Global Remote Co-Design Sprint for Youth Mental Health  Technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phang%2C+K">Kenji Phang</a>, 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+S+S">Siddharth Saarathi Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Ikwuegbu%2C+C">Chino Ikwuegbu</a>, 
<a href="/search/cs?searchtype=author&query=Ramos%2C+G">Gonzalo Ramos</a>, 
<a href="/search/cs?searchtype=author&query=Ford%2C+D">Denae Ford</a>, 
<a href="/search/cs?searchtype=author&query=Okoli%2C+E">Ebele Okoli</a>, 
<a href="/search/cs?searchtype=author&query=Chishti%2C+S+M+K">Salman Muin Kayser Chishti</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+J">Jina Suh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Case Study, 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Mental health is a pressing concern in today's digital age, particularly
among youth who are deeply intertwined with technology. Despite the influx of
technology solutions addressing mental health issues, youth often remain
sidelined during the design process. While co-design methods have been employed
to improve participation by youth, many such initiatives are limited to design
activities and lack training for youth to research and develop solutions for
themselves. In this case study, we detail our 8-week remote, collaborative
research initiative called Youth WellTech, designed to facilitate remote
co-design sprints aimed at equipping youth with the tools and knowledge to
envision and design tech futures for their own communities. We pilot this
initiative with 12 student technology evangelists across 8 countries globally
to foster the sharing of mental health challenges and diverse perspectives. We
highlight insights from our experiences running this global program remotely,
its structure, and recommendations for co-research.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05826" title="Abstract">arXiv:2401.05826</a> [<a href="/pdf/2401.05826" title="Download PDF">pdf</a>, <a href="/format/2401.05826" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crumbled Cookie Exploring E-commerce Websites Cookie Policies with Data  Protection Regulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+N">Nivedita Singh</a>, 
<a href="/search/cs?searchtype=author&query=Do%2C+Y">Yejin Do</a>, 
<a href="/search/cs?searchtype=author&query=Fouad%2C+Y+Y+I">Yongsang Yu. Imane Fouad</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jungrae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoungshick Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Despite stringent data protection regulations such as the General Data
Protection Regulation (GDPR), the California Consumer Privacy Act (CCPA), and
other country-specific regulations, many websites continue to use cookies to
track user activities. Recent studies have revealed several data protection
violations, resulting in significant penalties, especially for multinational
corporations. Motivated by the question of why these data protection violations
continue to occur despite strong data protection regulations, we examined 360
popular e-commerce websites in multiple countries to analyze whether they
comply with regulations to protect user privacy from a cookie perspective.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05827" title="Abstract">arXiv:2401.05827</a> [<a href="/pdf/2401.05827" title="Download PDF">pdf</a>, <a href="/ps/2401.05827" title="Download PostScript">ps</a>, <a href="/format/2401.05827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hallucination Benchmark in Medical Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinge Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Yunsoo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Honghan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The recent success of large language and vision models on vision question
answering (VQA), particularly their applications in medicine (Med-VQA), has
shown a great potential of realizing effective visual assistants for
healthcare. However, these models are not extensively tested on the
hallucination phenomenon in clinical settings. Here, we created a hallucination
benchmark of medical images paired with question-answer sets and conducted a
comprehensive evaluation of the state-of-the-art models. The study provides an
in-depth analysis of current models limitations and reveals the effectiveness
of various prompting strategies.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05831" title="Abstract">arXiv:2401.05831</a> [<a href="/pdf/2401.05831" title="Download PDF">pdf</a>, <a href="/format/2401.05831" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting Silhouette: From Micro to Macro Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vardakas%2C+G">Georgios Vardakas</a>, 
<a href="/search/cs?searchtype=author&query=Pavlopoulos%2C+J">John Pavlopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Likas%2C+A">Aristidis Likas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Silhouette coefficient is an established internal clustering evaluation
measure that produces a score per data point, assessing the quality of its
clustering assignment. To assess the quality of the clustering of the whole
dataset, the scores of all the points in the dataset are typically averaged
into a single value, a strategy which we call as micro-averaging. As we
illustrate in this work, by using a synthetic example, this micro-averaging
strategy is sensitive both to cluster imbalance and outliers (background
noise). To address these issues, we propose an alternative aggregation
strategy, which first averages the silhouette scores at a cluster level and
then (macro) averages the scores across the clusters. Based on the same
synthetic example, we show that the proposed macro-averaged silhouette score is
robust to cluster imbalance and background noise. We have conducted an
experimental study showing that our macro-averaged variant provides better
estimates of the ground truth number of clusters on several cases compared to
the typical micro-averaged score.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05833" title="Abstract">arXiv:2401.05833</a> [<a href="/pdf/2401.05833" title="Download PDF">pdf</a>, <a href="/ps/2401.05833" title="Download PostScript">ps</a>, <a href="/format/2401.05833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Extreme Value Theory Based Channel Modeling for  Ultra-Reliable Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrnia%2C+N">Niloofar Mehrnia</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Attaining ultra-reliable communication (URC) in fifth-generation (5G) and
beyond networks requires deriving statistics of channel in ultra-reliable
region by modeling the extreme events. Extreme value theory (EVT) has been
previously adopted in channel modeling to characterize the lower tail of
received powers in URC systems. In this paper, we propose a multivariate EVT
(MEVT)-based channel modeling methodology for tail of the joint distribution of
multi-channel by characterizing the multivariate extremes of multiple-input
multiple-output (MIMO) system. The proposed approach derives lower tail
statistics of received power of each channel by using the generalized Pareto
distribution (GPD). Then, tail of the joint distribution is modeled as a
function of estimated GPD parameters based on two approaches: logistic
distribution, which utilizes logistic distribution to determine dependency
factors among the Frechet transformed tail sequence and obtain a bi-variate
extreme value model, and Poisson point process, which estimates probability
measure function of the Pickands angular component to model bi-variate extreme
values. Finally, validity of the proposed models is assessed by incorporating
the mean constraint on probability measure function of Pichanks coordinates.
Based on the data collected within the engine compartment of Fiat Linea, we
demonstrate the superiority of proposed methodology compared to the
conventional extrapolation-based methods in providing the best fit to the
multivariate extremes.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05834" title="Abstract">arXiv:2401.05834</a> [<a href="/pdf/2401.05834" title="Download PDF">pdf</a>, <a href="/ps/2401.05834" title="Download PostScript">ps</a>, <a href="/format/2401.05834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Online Paging in Multi-Core Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mari%2C+M">Mathieu Mari</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Anish Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+R">Runtian Ren</a>, 
<a href="/search/cs?searchtype=author&query=Sankowski%2C+P">Piotr Sankowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Web requests are growing exponentially since the 90s due to the rapid
development of the Internet. This process was further accelerated by the
introduction of cloud services. It has been observed statistically that memory
or web requests generally follow power-law distribution, Breslau et al.
INFOCOM'99. That is, the $i^{\text{th}}$ most popular web page is requested
with a probability proportional to $1 / i^{\alpha}$ ($\alpha &gt; 0$ is a
constant). Furthermore, this study, which was performed more than 20 years ago,
indicated Zipf-like behavior, i.e., that $\alpha \le 1$. Surprisingly, the
memory access traces coming from petabyte-size modern cloud systems not only
show that $\alpha$ can be bigger than one but also illustrate a shifted
power-law distribution -- called Pareto type II or Lomax. These previously not
reported phenomenon calls for statistical explanation.
<br />Our first contribution is a new statistical {\it multi-core power-law} model
indicating that double-power law can be attributed to the presence of multiple
cores running many virtual machines in parallel on such systems. We verify
experimentally the applicability of this model using the Kolmogorov-Smirnov
test (K-S test).
<br />The second contribution of this paper is a theoretical analysis indicating
why LRU and LFU-based algorithms perform well in practice on data satisfying
power-law or multi-core assumptions. We provide an explanation by studying the
online paging problem in the stochastic input model, i.e., the input is a
random sequence with each request independently drawn from a page set according
to a distribution $\pi$. We derive formulas (as a function of the page
probabilities in $\pi$) to upper bound their ratio-of-expectations, which help
in establishing O(1) performance ratio given the random sequence following
power-law and multi-core power-law distributions.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05835" title="Abstract">arXiv:2401.05835</a> [<a href="/pdf/2401.05835" title="Download PDF">pdf</a>, <a href="/format/2401.05835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Analysis of Affine Transformations in Cloud-based MPC:  Vulnerability to Side-knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hosseinalizadeh%2C+T">Teimour Hosseinalizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Schl%C3%BCter%2C+N">Nils Schl&#xfc;ter</a>, 
<a href="/search/eess?searchtype=author&query=Darup%2C+M+S">Moritz Schulze Darup</a>, 
<a href="/search/eess?searchtype=author&query=Monshizadeh%2C+N">Nima Monshizadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Search for the optimizer in computationally demanding model predictive
control (MPC) setups can be facilitated by Cloud as a service provider in
cyber-physical systems. This advantage introduces the risk that Cloud can
obtain unauthorized access to the privacy-sensitive parameters of the system
and cost function. To solve this issue, i.e., preventing Cloud from accessing
the parameters while benefiting from Cloud computation, random affine
transformations provide an exact yet light weight in computation solution. This
research deals with analyzing privacy preserving properties of these
transformations when they are adopted for MPC problems. We consider two common
strategies for outsourcing the optimization required in MPC problems, namely
separate and dense forms, and establish that random affine transformations
utilized in these forms are vulnerable to side-knowledge from Cloud.
Specifically, we prove that the privacy guarantees of these methods and their
extensions for separate form are undermined when a mild side-knowledge about
the problem in terms of structure of MPC cost function is available. In
addition, while we prove that outsourcing the MPC problem in the dense form
inherently leads to some degree of privacy for the system and cost function
parameters, we also establish that affine transformations applied to this form
are nevertheless prone to be undermined by a Cloud with mild side-knowledge.
Numerical simulations confirm our results.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05836" title="Abstract">arXiv:2401.05836</a> [<a href="/pdf/2401.05836" title="Download PDF">pdf</a>, <a href="/ps/2401.05836" title="Download PostScript">ps</a>, <a href="/format/2401.05836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On State Estimation in Multi-Sensor Fusion Navigation: Optimization and  Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xveqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuantai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weijie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaohong Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The essential of navigation, perception, and decision-making which are basic
tasks for intelligent robots, is to estimate necessary system states. Among
them, navigation is fundamental for other upper applications, providing precise
position and orientation, by integrating measurements from multiple sensors.
With observations of each sensor appropriately modelled, multi-sensor fusion
tasks for navigation are reduced to the state estimation problem which can be
solved by two approaches: optimization and filtering. Recent research has shown
that optimization-based frameworks outperform filtering-based ones in terms of
accuracy. However, both methods are based on maximum likelihood estimation
(MLE) and should be theoretically equivalent with the same linearization
points, observation model, measurements, and Gaussian noise assumption. In this
paper, we deeply dig into the theories and existing strategies utilized in both
optimization-based and filtering-based approaches. It is demonstrated that the
two methods are equal theoretically, but this equivalence corrupts due to
different strategies applied in real-time operation. By adjusting existing
strategies of the filtering-based approaches, the Monte-Carlo simulation and
vehicular ablation experiments based on visual odometry (VO) indicate that the
strategy adjusted filtering strictly equals to optimization. Therefore, future
research on sensor-fusion problems should concentrate on their own algorithms
and strategies rather than state estimation approaches.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05840" title="Abstract">arXiv:2401.05840</a> [<a href="/pdf/2401.05840" title="Download PDF">pdf</a>, <a href="/format/2401.05840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding AI&#x27;s Nudge: A Unified Framework to Predict Human Behavior in  AI-assisted Decision Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuoyan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhuoran Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+M">Ming Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the rapid development of AI-based decision aids, different forms of AI
assistance have been increasingly integrated into the human decision making
processes. To best support humans in decision making, it is essential to
quantitatively understand how diverse forms of AI assistance influence humans'
decision making behavior. To this end, much of the current research focuses on
the end-to-end prediction of human behavior using ``black-box'' models, often
lacking interpretations of the nuanced ways in which AI assistance impacts the
human decision making process. Meanwhile, methods that prioritize the
interpretability of human behavior predictions are often tailored for one
specific form of AI assistance, making adaptations to other forms of assistance
difficult. In this paper, we propose a computational framework that can provide
an interpretable characterization of the influence of different forms of AI
assistance on decision makers in AI-assisted decision making. By
conceptualizing AI assistance as the ``{\em nudge}'' in human decision making
processes, our approach centers around modelling how different forms of AI
assistance modify humans' strategy in weighing different information in making
their decisions. Evaluations on behavior data collected from real human
decision makers show that the proposed framework outperforms various baselines
in accurately predicting human behavior in AI-assisted decision making. Based
on the proposed framework, we further provide insights into how individuals
with different cognitive styles are nudged by AI assistance differently.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05841" title="Abstract">arXiv:2401.05841</a> [<a href="/pdf/2401.05841" title="Download PDF">pdf</a>, <a href="/format/2401.05841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the number of iterations of the DBA algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Br%C3%BCning%2C+F">Frederik Br&#xfc;ning</a>, 
<a href="/search/cs?searchtype=author&query=Driemel%2C+A">Anne Driemel</a>, 
<a href="/search/cs?searchtype=author&query=Erg%C3%BCr%2C+A">Alperen Erg&#xfc;r</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6glin%2C+H">Heiko R&#xf6;glin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The DTW Barycenter Averaging (DBA) algorithm is a widely used algorithm for
estimating the mean of a given set of point sequences. In this context, the
mean is defined as a point sequence that minimises the sum of dynamic time
warping distances (DTW). The algorithm is similar to the $k$-means algorithm in
the sense that it alternately repeats two steps: (1) computing an optimal
assignment to the points of the current mean, and (2) computing an optimal mean
under the current assignment. The popularity of DBA can be attributed to the
fact that it works well in practice, despite any theoretical guarantees to be
known. In our paper, we aim to initiate a theoretical study of the number of
iterations that DBA performs until convergence. We assume the algorithm is
given $n$ sequences of $m$ points in $\mathbb{R}^d$ and a parameter $k$ that
specifies the length of the mean sequence to be computed. We show that, in
contrast to its fast running time in practice, the number of iterations can be
exponential in $k$ in the worst case - even if the number of input sequences is
$n=2$. We complement these findings with experiments on real-world data that
suggest this worst-case behaviour is likely degenerate. To better understand
the performance of the algorithm on non-degenerate input, we study DBA in the
model of smoothed analysis, upper-bounding the expected number of iterations in
the worst case under random perturbations of the input. Our smoothed upper
bound is polynomial in $k$, $n$ and $d$, and for constant $n$, it is also
polynomial in $m$. For our analysis, we adapt the set of techniques that were
developed for analysing $k$-means and observe that this set of techniques is
not sufficient to obtain tight bounds for general $n$.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05842" title="Abstract">arXiv:2401.05842</a> [<a href="/pdf/2401.05842" title="Download PDF">pdf</a>, <a href="/ps/2401.05842" title="Download PostScript">ps</a>, <a href="/format/2401.05842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Categorical Approach to DIBI Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+J">Jialu Bao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+J">Justin Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Alexandra Silva</a>, 
<a href="/search/cs?searchtype=author&query=Zanasi%2C+F">Fabio Zanasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The logic of Dependence and Independence Bunched Implications (DIBI) is a
logic to reason about conditional independence (CI); for instance, DIBI
formulas can characterise CI in probability distributions and relational
databases, using the probabilistic and relational DIBI models, respectively.
Despite the similarity of the probabilistic and relational models, a uniform,
more abstract account remains unsolved. The laborious case-by-case verification
of the frame conditions required for constructing new models also calls for
such a treatment. In this paper, we develop an abstract framework for
systematically constructing DIBI models, using category theory as the unifying
mathematical language. In particular, we use string diagrams -- a graphical
presentation of monoidal categories -- to give a uniform definition of the
parallel composition and subkernel relation in DIBI models. Our approach not
only generalises known models, but also yields new models of interest and
reduces properties of DIBI models to structures in the underlying categories.
Furthermore, our categorical framework enables a logical notion of CI, in terms
of the satisfaction of specific DIBI formulas. We compare it with string
diagrammatic approaches to CI and show that it is an extension of string
diagrammatic CI under reasonable conditions.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05845" title="Abstract">arXiv:2401.05845</a> [<a href="/pdf/2401.05845" title="Download PDF">pdf</a>, <a href="/ps/2401.05845" title="Download PostScript">ps</a>, <a href="/format/2401.05845" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Reconstruction via MIS Queries
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konrad%2C+C">Christian Konrad</a>, 
<a href="/search/cs?searchtype=author&query=O%27Sullivan%2C+C">Conor O&#x27;Sullivan</a>, 
<a href="/search/cs?searchtype=author&query=Traistaru%2C+V">Victor Traistaru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We consider the Graph Reconstruction problem given only query access to the
input graph via a Maximal Independent Set oracle. In this setting, in each
round, the player submits a query consisting of a subset of vertices to the
oracle, and the oracle returns any maximal independent set in the subgraph
induced by the queried vertices. The goal for the player is to learn all the
edges of the input graph.
<br />In this paper, we give tight (up to a logarithmic factor) upper and lower
bounds for this problem:
<br />1. We give a randomized query algorithm that uses $O(\Delta^2 \log n)$
non-adaptive queries and succeeds with high probability to reconstruct an
$n$-vertex graph with maximum degree $\Delta$. Using the probabilistic method,
we also show that a non-adaptive deterministic algorithm that executes
$O(\Delta^3 \log n)$ queries exists.
<br />2. We give two lower bounds that apply to arbitrary adaptive randomized
algorithms that succeed with probability greater than $\frac{1}{2}$. We show
that, for such algorithms, $\Omega(\Delta^2)$ rounds are necessary in graphs of
maximum degree $\Delta$, and that $\Omega(\log n)$ rounds are necessary even
when the input graph is an $n$-vertex cycle.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05849" title="Abstract">arXiv:2401.05849</a> [<a href="/pdf/2401.05849" title="Download PDF">pdf</a>, <a href="/format/2401.05849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Intentions to Speak Using Accelerometer Data In-the-Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Litian Li</a>, 
<a href="/search/cs?searchtype=author&query=Molhoek%2C+J">Jord Molhoek</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jing Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Humans have good natural intuition to recognize when another person has
something to say. It would be interesting if an AI can also recognize
intentions to speak. Especially in scenarios when an AI is guiding a group
discussion, this can be a useful skill. This work studies the inference of
successful and unsuccessful intentions to speak from accelerometer data. This
is chosen because it is privacy-preserving and feasible for in-the-wild
settings since it can be placed in a smart badge. Data from a real-life social
networking event is used to train a machine-learning model that aims to infer
intentions to speak. A subset of unsuccessful intention-to-speak cases in the
data is annotated. The model is trained on the successful intentions to speak
and evaluated on both the successful and unsuccessful cases. In conclusion,
there is useful information in accelerometer data, but not enough to reliably
capture intentions to speak. For example, posture shifts are correlated with
intentions to speak, but people also often shift posture without having an
intention to speak, or have an intention to speak without shifting their
posture. More modalities are likely needed to reliably infer intentions to
speak.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05850" title="Abstract">arXiv:2401.05850</a> [<a href="/pdf/2401.05850" title="Download PDF">pdf</a>, <a href="/format/2401.05850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Loss Based Frame-wise Feature disentanglement for Polyphonic  Sound Event Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+Y">Yadong Guan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiqing Han</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hongwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wenjie Song</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guibin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+T">Tieran Zheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yongjun He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by icassp2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Overlapping sound events are ubiquitous in real-world environments, but
existing end-to-end sound event detection (SED) methods still struggle to
detect them effectively. A critical reason is that these methods represent
overlapping events using shared and entangled frame-wise features, which
degrades the feature discrimination. To solve the problem, we propose a
disentangled feature learning framework to learn a category-specific
representation. Specifically, we employ different projectors to learn the
frame-wise features for each category. To ensure that these feature does not
contain information of other categories, we maximize the common information
between frame-wise features within the same category and propose a frame-wise
contrastive loss. In addition, considering that the labeled data used by the
proposed method is limited, we propose a semi-supervised frame-wise contrastive
loss that can leverage large amounts of unlabeled data to achieve feature
disentanglement. The experimental results demonstrate the effectiveness of our
method.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05856" title="Abstract">arXiv:2401.05856</a> [<a href="/pdf/2401.05856" title="Download PDF">pdf</a>, <a href="/format/2401.05856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seven Failure Points When Engineering a Retrieval Augmented Generation  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barnett%2C+S">Scott Barnett</a>, 
<a href="/search/cs?searchtype=author&query=Kurniawan%2C+S">Stefanus Kurniawan</a>, 
<a href="/search/cs?searchtype=author&query=Thudumu%2C+S">Srikanth Thudumu</a>, 
<a href="/search/cs?searchtype=author&query=Brannelly%2C+Z">Zach Brannelly</a>, 
<a href="/search/cs?searchtype=author&query=Abdelrazek%2C+M">Mohamed Abdelrazek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software engineers are increasingly adding semantic search capabilities to
applications using a strategy known as Retrieval Augmented Generation (RAG). A
RAG system involves finding documents that semantically match a query and then
passing the documents to a large language model (LLM) such as ChatGPT to
extract the right answer using an LLM. RAG systems aim to: a) reduce the
problem of hallucinated responses from LLMs, b) link sources/references to
generated responses, and c) remove the need for annotating documents with
meta-data. However, RAG systems suffer from limitations inherent to information
retrieval systems and from reliance on LLMs. In this paper, we present an
experience report on the failure points of RAG systems from three case studies
from separate domains: research, education, and biomedical. We share the
lessons learned and present 7 failure points to consider when designing a RAG
system. The two key takeaways arising from our work are: 1) validation of a RAG
system is only feasible during operation, and 2) the robustness of a RAG system
evolves rather than designed in at the start. We conclude with a list of
potential research directions on RAG systems for the software engineering
community.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05857" title="Abstract">arXiv:2401.05857</a> [<a href="/pdf/2401.05857" title="Download PDF">pdf</a>, <a href="/format/2401.05857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Dynamic Event-triggered Consensus Under Asynchronous Denial of  Service
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Azarbahram%2C+A">Ali Azarbahram</a>, 
<a href="/search/eess?searchtype=author&query=Amini%2C+A">Amir Amini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This article proposes a secure implementation for consensus using a dynamic
event-triggered (DET) communication scheme in high-order nonlinear multi-agent
systems (MAS) under asynchronous (distributed) denial of service (DoS) attacks.
By introducing a linear auxiliary trajectory of the system, the DET data
transmission scheme among the neighboring agents is employed to reduce the
communication for each agent. The asynchronous DoS attacks can block each
communication channel among the cooperative agents independently in an unknown
pattern. To guarantee state consensus of auxiliary MAS under DoS, a linear
matrix inequality (LMI) based optimization approach is proposed which
simultaneously designs all the unknown DET communication parameters as well as
the state feedback control gain. In addition to asynchronous DoS attacks over
the graph topology, the destructive effects of independent DoS attacks over the
communication links between actual and auxiliary states are compensated as an
additional layer of resiliency for the system. The output of each agent
ultimately tracks the auxiliary state of the system and this results in the
output consensus.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05859" title="Abstract">arXiv:2401.05859</a> [<a href="/pdf/2401.05859" title="Download PDF">pdf</a>, <a href="/ps/2401.05859" title="Download PostScript">ps</a>, <a href="/format/2401.05859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Construction of $q$-ary Codes Correcting a Burst of at most $t$  Deletions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+W">Wentu Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+K">Kui Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this paper, for any fixed integer $q&gt;2$, we construct $q$-ary codes
correcting a burst of at most $t$ deletions with redundancy $\log n+8\log\log
n+o(\log\log n)+\gamma_{q,t}$ bits and near-linear encoding/decoding
complexity, where $n$ is the message length and $\gamma_{q,t}$ is a constant
that only depends on $q$ and $t$. In previous works there are constructions of
such codes with redundancy $\log n+O(\log q\log\log n)$ bits or $\log
n+O(t^2\log\log n)+O(t\log q)$. The redundancy of our new construction is
independent of $q$ and $t$ in the second term.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05860" title="Abstract">arXiv:2401.05860</a> [<a href="/pdf/2401.05860" title="Download PDF">pdf</a>, <a href="/format/2401.05860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence-Based Curriculum Learning for Multi-Agent Path Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phan%2C+T">Thomy Phan</a>, 
<a href="/search/cs?searchtype=author&query=Driscoll%2C+J">Joseph Driscoll</a>, 
<a href="/search/cs?searchtype=author&query=Romberg%2C+J">Justin Romberg</a>, 
<a href="/search/cs?searchtype=author&query=Koenig%2C+S">Sven Koenig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAMAS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">A wide range of real-world applications can be formulated as Multi-Agent Path
Finding (MAPF) problem, where the goal is to find collision-free paths for
multiple agents with individual start and goal locations. State-of-the-art MAPF
solvers are mainly centralized and depend on global information, which limits
their scalability and flexibility regarding changes or new maps that would
require expensive replanning. Multi-agent reinforcement learning (MARL) offers
an alternative way by learning decentralized policies that can generalize over
a variety of maps. While there exist some prior works that attempt to connect
both areas, the proposed techniques are heavily engineered and very complex due
to the integration of many mechanisms that limit generality and are expensive
to use. We argue that much simpler and general approaches are needed to bring
the areas of MARL and MAPF closer together with significantly lower costs. In
this paper, we propose Confidence-based Auto-Curriculum for Team Update
Stability (CACTUS) as a lightweight MARL approach to MAPF. CACTUS defines a
simple reverse curriculum scheme, where the goal of each agent is randomly
placed within an allocation radius around the agent's start location. The
allocation radius increases gradually as all agents improve, which is assessed
by a confidence-based measure. We evaluate CACTUS in various maps of different
sizes, obstacle densities, and numbers of agents. Our experiments demonstrate
better performance and generalization capabilities than state-of-the-art MARL
approaches with less than 600,000 trainable parameters, which is less than 5%
of the neural network size of current MARL approaches to MAPF.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05861" title="Abstract">arXiv:2401.05861</a> [<a href="/pdf/2401.05861" title="Download PDF">pdf</a>, <a href="/format/2401.05861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Boosting Many-to-Many Multilingual Machine Translation with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengzhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhongjun He</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hua Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haifeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The training paradigm for machine translation has gradually shifted, from
learning neural machine translation (NMT) models with extensive parallel
corpora to instruction finetuning on pretrained multilingual large language
models (LLMs) with high-quality translation pairs. In this paper, we focus on
boosting the many-to-many multilingual translation performance of LLMs with an
emphasis on zero-shot translation directions. We demonstrate that prompt
strategies adopted during instruction finetuning are crucial to zero-shot
translation performance and introduce a cross-lingual consistency
regularization, XConST, to bridge the representation gap among different
languages and improve zero-shot translation performance. XConST is not a new
method, but a version of CrossConST (Gao et al., 2023a) adapted for
multilingual finetuning on LLMs with translation instructions. Experimental
results on ALMA (Xu et al., 2023) and LLaMA-2 (Touvron et al., 2023) show that
our approach consistently improves translation performance. Our implementations
are available at https://github.com/gpengzhi/CrossConST-LLM.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05868" title="Abstract">arXiv:2401.05868</a> [<a href="/pdf/2401.05868" title="Download PDF">pdf</a>, <a href="/format/2401.05868" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient N-to-M Checkpointing Algorithm for Finite Element Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ham%2C+D+A">David A. Ham</a>, 
<a href="/search/cs?searchtype=author&query=Hapla%2C+V">Vaclav Hapla</a>, 
<a href="/search/cs?searchtype=author&query=Knepley%2C+M+G">Matthew G. Knepley</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+L">Lawrence Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Sagiyama%2C+K">Koki Sagiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">In this work, we introduce a new algorithm for N-to-M checkpointing in finite
element simulations. This new algorithm allows efficient saving/loading of
functions representing physical quantities associated with the mesh
representing the physical domain. Specifically, the algorithm allows for using
different numbers of parallel processes for saving and loading, allowing for
restarting and post-processing on the process count appropriate to the given
phase of the simulation and other conditions. For demonstration, we implemented
this algorithm in PETSc, the Portable, Extensible Toolkit for Scientific
Computation, and added a convenient high-level interface into Firedrake, a
system for solving partial differential equations using finite element methods.
We evaluated our new implementation by saving and loading data involving 8.2
billion finite element degrees of freedom using 8,192 parallel processes on
ARCHER2, the UK National Supercomputing Service.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05870" title="Abstract">arXiv:2401.05870</a> [<a href="/pdf/2401.05870" title="Download PDF">pdf</a>, <a href="/format/2401.05870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced  Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanzhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinze Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhongrui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zeke Xie</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+L">Lei Tian</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xinyan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Junjun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingming Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The goal of Arbitrary Style Transfer (AST) is injecting the artistic features
of a style reference into a given image/video. Existing methods usually focus
on pursuing the balance between style and content, whereas ignoring the
significant demand for flexible and customized stylization results and thereby
limiting their practical application. To address this critical issue, a novel
AST approach namely HiCAST is proposed, which is capable of explicitly
customizing the stylization results according to various source of semantic
clues. In the specific, our model is constructed based on Latent Diffusion
Model (LDM) and elaborately designed to absorb content and style instance as
conditions of LDM. It is characterized by introducing of \textit{Style
Adapter}, which allows user to flexibly manipulate the output results by
aligning multi-level style information and intrinsic knowledge in LDM. Lastly,
we further extend our model to perform video AST. A novel learning objective is
leveraged for video diffusion model training, which significantly improve
cross-frame temporal consistency in the premise of maintaining stylization
strength. Qualitative and quantitative comparisons as well as comprehensive
user studies demonstrate that our HiCAST outperforms the existing SoTA methods
in generating visually plausible stylization results.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05871" title="Abstract">arXiv:2401.05871</a> [<a href="/pdf/2401.05871" title="Download PDF">pdf</a>, <a href="/format/2401.05871" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Personality Recognition in Dialogue by Data Augmentation and  Heterogeneous Conversational Graph Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yahui Fu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Haiyue Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2024 (IWSDS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Personality recognition is useful for enhancing robots' ability to tailor
user-adaptive responses, thus fostering rich human-robot interactions. One of
the challenges in this task is a limited number of speakers in existing
dialogue corpora, which hampers the development of robust, speaker-independent
personality recognition models. Additionally, accurately modeling both the
interdependencies among interlocutors and the intra-dependencies within the
speaker in dialogues remains a significant issue. To address the first
challenge, we introduce personality trait interpolation for speaker data
augmentation. For the second, we propose heterogeneous conversational graph
networks to independently capture both contextual influences and inherent
personality traits. Evaluations on the RealPersonaChat corpus demonstrate our
method's significant improvements over existing baselines.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05872" title="Abstract">arXiv:2401.05872</a> [<a href="/pdf/2401.05872" title="Download PDF">pdf</a>, <a href="/ps/2401.05872" title="Download PostScript">ps</a>, <a href="/format/2401.05872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Logical Predicates in Higher-Order Mathematical Operational Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goncharov%2C+S">Sergey Goncharov</a>, 
<a href="/search/cs?searchtype=author&query=Santamaria%2C+A">Alessio Santamaria</a>, 
<a href="/search/cs?searchtype=author&query=Schr%C3%B6der%2C+L">Lutz Schr&#xf6;der</a>, 
<a href="/search/cs?searchtype=author&query=Tsampas%2C+S">Stelios Tsampas</a>, 
<a href="/search/cs?searchtype=author&query=Urbat%2C+H">Henning Urbat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Programming Languages (cs.PL)

</div>
<p class="mathjax">We present a systematic approach to logical predicates based on universal
coalgebra and higher-order abstract GSOS, thus making a first step towards a
unifying theory of logical relations. We first observe that logical predicates
are special cases of coalgebraic invariants on mixed-variance functors. We then
introduce the notion of a locally maximal logical refinement of a given
predicate, with a view to enabling inductive reasoning, and identify sufficient
conditions on the overall setup in which locally maximal logical refinements
canonically exist. Finally, we develop induction-up-to techniques that simplify
inductive proofs via logical predicates on systems encoded as (certain classes
of) higher-order GSOS laws by identifying and abstracting away from their
boiler-plate part.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05876" title="Abstract">arXiv:2401.05876</a> [<a href="/pdf/2401.05876" title="Download PDF">pdf</a>, <a href="/format/2401.05876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe reinforcement learning in uncertain contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+D">Dominik Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6n%2C+T+B">Thomas B. Sch&#xf6;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted final version to appear in the IEEE Transactions on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">When deploying machine learning algorithms in the real world, guaranteeing
safety is an essential asset. Existing safe learning approaches typically
consider continuous variables, i.e., regression tasks. However, in practice,
robotic systems are also subject to discrete, external environmental changes,
e.g., having to carry objects of certain weights or operating on frozen, wet,
or dry surfaces. Such influences can be modeled as discrete context variables.
In the existing literature, such contexts are, if considered, mostly assumed to
be known. In this work, we drop this assumption and show how we can perform
safe learning when we cannot directly measure the context variables. To achieve
this, we derive frequentist guarantees for multi-class classification, allowing
us to estimate the current context from measurements. Further, we propose an
approach for identifying contexts through experiments. We discuss under which
conditions we can retain theoretical guarantees and demonstrate the
applicability of our algorithm on a Furuta pendulum with camera measurements of
different weights that serve as contexts.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05879" title="Abstract">arXiv:2401.05879</a> [<a href="/pdf/2401.05879" title="Download PDF">pdf</a>, <a href="/ps/2401.05879" title="Download PostScript">ps</a>, <a href="/format/2401.05879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOIO: You Only Iterate Once by mining and fusing multiple necessary  global information in the optical flow estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yu Jing</a>, 
<a href="/search/cs?searchtype=author&query=Yujuan%2C+T">Tan Yujuan</a>, 
<a href="/search/cs?searchtype=author&query=Ao%2C+R">Ren Ao</a>, 
<a href="/search/cs?searchtype=author&query=Duo%2C+L">Liu Duo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2104.02409">arXiv:2104.02409</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Occlusions pose a significant challenge to optical flow algorithms that even
rely on global evidences. We consider an occluded point to be one that is
imaged in the reference frame but not in the next. Estimating the motion of
these points is extremely difficult, particularly in the two-frame setting.
Previous work only used the current frame as the only input, which could not
guarantee providing correct global reference information for occluded points,
and had problems such as long calculation time and poor accuracy in predicting
optical flow at occluded points. To enable both high accuracy and efficiency,
We fully mine and utilize the spatiotemporal information provided by the frame
pair, design a loopback judgment algorithm to ensure that correct global
reference information is obtained, mine multiple necessary global information,
and design an efficient refinement module that fuses these global information.
Specifically, we propose a YOIO framework, which consists of three main
components: an initial flow estimator, a multiple global information extraction
module, and a unified refinement module. We demonstrate that optical flow
estimates in the occluded regions can be significantly improved in only one
iteration without damaging the performance in non-occluded regions. Compared
with GMA, the optical flow prediction accuracy of this method in the occluded
area is improved by more than 10%, and the occ_out area exceeds 15%, while the
calculation time is 27% shorter. This approach, running up to 18.9fps with
436*1024 image resolution, obtains new state-of-the-art results on the
challenging Sintel dataset among all published and unpublished approaches that
can run in real-time, suggesting a new paradigm for accurate and efficient
optical flow estimation.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05881" title="Abstract">arXiv:2401.05881</a> [<a href="/pdf/2401.05881" title="Download PDF">pdf</a>, <a href="/ps/2401.05881" title="Download PostScript">ps</a>, <a href="/format/2401.05881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Volume Transfer: A New Design Concept for Fabric-Based Pneumatic  Exosuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chendong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Dapeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiachen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yiming Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Li Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The fabric-based pneumatic exosuit is now a hot research topic because it is
lighter and softer than traditional exoskeletons. Existing research focused
more on the mechanical properties of the exosuit (e.g., torque and speed), but
less on its wearability (e.g., appearance and comfort). This work presents a
new design concept for fabric-based pneumatic exosuits Volume Transfer, which
means transferring the volume of pneumatic actuators beyond the garments
profile to the inside. This allows for a concealed appearance and a larger
stress area while maintaining adequate torques. In order to verify this
concept, we develop a fabric-based pneumatic exosuit for knee extension
assistance. Its profile is only 26mm and its stress area wraps around almost
half of the leg. We use a mathematical model and simulation to determine the
parameters of the exosuit, avoiding multiple iterations of the prototype.
Experiment results show that the exosuit can generate a torque of 7.6Nm at a
pressure of 90kPa and produce a significant reduction in the electromyography
activity of the knee extensor muscles. We believe that Volume Transfer could be
utilized prevalently in future fabric-based pneumatic exosuit designs to
achieve a significant improvement in wearability.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05882" title="Abstract">arXiv:2401.05882</a> [<a href="/pdf/2401.05882" title="Download PDF">pdf</a>, <a href="/ps/2401.05882" title="Download PostScript">ps</a>, <a href="/format/2401.05882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme Value Theory Based Rate Selection for Ultra-Reliable  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrnia%2C+N">Niloofar Mehrnia</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures including 7 subfigures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in IEEE Transactions on Vehicular Technology, vol. 71, no. 6, pp.
  6727-6731, June 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Ultra-reliable low latency communication (URLLC) requires the packet error
rate to be on the order of $10^{-9}$-$10^{-5}$. Determining the appropriate
transmission rate to satisfy this ultra-reliability constraint requires
deriving the statistics of the channel in the ultra-reliable region and then
incorporating these statistics into the rate selection. In this paper, we
propose a framework for determining the rate selection for ultra-reliable
communications based on the extreme value theory (EVT). We first model the
wireless channel at URLLC by estimating the parameters of the generalized
Pareto distribution (GPD) best fitting to the tail distribution of the received
powers, i.e., the power values below a certain threshold. Then, we determine
the maximum transmission rate by incorporating the Pareto distribution into the
rate selection function. Finally, we validate the selected rate by computing
the resulting error probability. Based on the data collected within the engine
compartment of Fiat Linea, we demonstrate the superior performance of the
proposed methodology in determining the maximum transmission rate compared to
the traditional extrapolation-based approaches.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05883" title="Abstract">arXiv:2401.05883</a> [<a href="/pdf/2401.05883" title="Download PDF">pdf</a>, <a href="/format/2401.05883" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Deduplication For Socia Media Data Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianming Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work In Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Social media data is plagued by the redundancy problem caused by its noisy
nature, leading to increased training time and model bias. To address this
issue, we propose a novel approach called generative duplication. It aims to
remove duplicate text from noisy social media data and mitigate model bias. By
doing so, it can improve social media language understanding performance and
save training time. Extensive experiments demonstrate that the proposed
generative deduplication can effectively reduce training samples while
improving performance. This evidence suggests the effectiveness of generative
deduplication and its importance in social media language understanding.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05888" title="Abstract">arXiv:2401.05888</a> [<a href="/pdf/2401.05888" title="Download PDF">pdf</a>, <a href="/ps/2401.05888" title="Download PostScript">ps</a>, <a href="/format/2401.05888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporation of Confidence Interval into Rate Selection Based on the  Extreme Value Theory for Ultra-Reliable Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrnia%2C+N">Niloofar Mehrnia</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures including 14 subfigures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 Joint European Conference on Networks and Communications &amp; 6G
  Summit (EuCNC/6G Summit), Grenoble, France, 2022, pp. 118-123
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Proper determination of the transmission rate in ultra-reliable low latency
communication (URLLC) needs to incorporate a confidence interval (CI) for the
estimated parameters due to the large amount of data required for their
accurate estimation. In this paper, we propose a framework based on the extreme
value theory (EVT) for determining the transmission rate along with its
corresponding CI for an ultra-reliable communication system. This framework
consists of characterizing the statistics of extreme events by fitting the
generalized Pareto distribution (GPD) to the channel tail, deriving the GPD
parameters and their associated CIs, and obtaining the transmission rate within
a confidence interval. Based on the data collected within the engine
compartment of Fiat Linea, we demonstrate the accuracy of the estimated rate
obtained through the EVT-based framework considering the confidence interval
for the GPD parameters. Additionally, we show that proper estimation of the
transmission rate based on the proposed framework requires a lower number of
samples compared to the traditional extrapolation-based approaches.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05891" title="Abstract">arXiv:2401.05891</a> [<a href="/pdf/2401.05891" title="Download PDF">pdf</a>, <a href="/format/2401.05891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR data acquisition and processing for ecology applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ciobotari%2C+I">Ion Ciobotari</a>, 
<a href="/search/cs?searchtype=author&query=Pr%C3%ADncipe%2C+A">Adriana Pr&#xed;ncipe</a>, 
<a href="/search/cs?searchtype=author&query=Oliveira%2C+M+A">Maria Alexandra Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+J+N">Jo&#xe3;o Nuno Silva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The collection of ecological data in the field is essential to diagnose,
monitor and manage ecosystems in a sustainable way. Since acquisition of this
information through traditional methods are generally time-consuming, due to
the capability of recording large volumes of data in short time periods,
automation of data acquisition sees a growing trend. Terrestrial laser scanners
(TLS), particularly LiDAR sensors, have been used in ecology, allowing to
reconstruct the 3D structure of vegetation, and thus, infer ecosystem
characteristics based on the spatial variation of the density of points.
However, the low amount of information obtained per beam, lack of data analysis
tools and the high cost of the equipment limit their use. This way, a low-cost
TLS (&lt;10k$) was developed along with data acquisition and processing mechanisms
applicable in two case studies: an urban garden and a target area for
ecological restoration. The orientation of LiDAR was modified to make
observations in the vertical plane and a motor was integrated for its rotation,
enabling the acquisition of 360 degree data with high resolution. Motion and
location sensors were also integrated for automatic error correction and
georeferencing. From the data generated, histograms of point density variation
along the vegetation height were created, where shrub stratum was easily
distinguishable from tree stratum, and maximum tree height and shrub cover were
calculated. These results agreed with the field data, whereby the developed TLS
has proved to be effective in calculating metrics of structural complexity of
vegetation.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05892" title="Abstract">arXiv:2401.05892</a> [<a href="/pdf/2401.05892" title="Download PDF">pdf</a>, <a href="/format/2401.05892" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recognition Complexity of Subgraphs of 2- and 3-Connected Planar Cubic  Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goetze%2C+M">Miriam Goetze</a>, 
<a href="/search/cs?searchtype=author&query=Jungeblut%2C+P">Paul Jungeblut</a>, 
<a href="/search/cs?searchtype=author&query=Ueckerdt%2C+T">Torsten Ueckerdt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">We study the recognition complexity of subgraphs of 2- and 3-connected planar
cubic graphs. Recently, we presented [ESA 2022] a quadratic-time algorithm to
recognize subgraphs of planar cubic bridgeless (but not necessarily connected)
graphs, both in the variable and fixed embedding setting (the latter only for
2-connected inputs). Here, we extend our results in two directions: First, we
present a quartic-time algorithm to recognize subgraphs of 2-connected planar
cubic graphs in the fixed embedding setting, even for disconnected inputs.
Second, we prove NP-hardness of recognizing subgraphs of 3-connected planar
cubic graphs in the variable embedding setting.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05894" title="Abstract">arXiv:2401.05894</a> [<a href="/pdf/2401.05894" title="Download PDF">pdf</a>, <a href="/ps/2401.05894" title="Download PostScript">ps</a>, <a href="/format/2401.05894" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Energy Management Method for Hybrid PV/Battery/Load  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Banaei%2C+M">Mohsen Banaei</a>, 
<a href="/search/eess?searchtype=author&query=Ebrahimy%2C+R">Razgar Ebrahimy</a>, 
<a href="/search/eess?searchtype=author&query=Madsen%2C+H">Henrik Madsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a computationally lightweight algorithm is introduced for
hybrid PV/Battery/Load systems that is price responsive, responds fast, does
not require powerful hardware, and considers the operational limitations of the
system. The method is applied to two buildings equipped with PV and battery.
Simulation results show that the method can give results that are up to 3.9%
more expensive than the Model predictive control (MPC) approach while the
runtime of the program is up to 1000 times less than the MPC. Also, while the
runtime of the proposed method is in the range of the self-consumption
maximization (SCM) approach as the fastest method, its electricity cost is
about 3.2% cheaper than the SCM method. Simulation results also show that in
case of providing grid services by the battery the difference between
electricity cost of the proposed approach and MPC can reduce which makes the
method good for such applications.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05895" title="Abstract">arXiv:2401.05895</a> [<a href="/pdf/2401.05895" title="Download PDF">pdf</a>, <a href="/format/2401.05895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Linear Tree Commitment-based Ownership Protection for Distributed  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+T">Tianxiu Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gai%2C+K">Keke Gai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liehuang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Distributed machine learning enables parallel training of extensive datasets
by delegating computing tasks across multiple workers. Despite the cost
reduction benefits of distributed machine learning, the dissemination of final
model weights often leads to potential conflicts over model ownership as
workers struggle to substantiate their involvement in the training computation.
To address the above ownership issues and prevent accidental failures and
malicious attacks, verifying the computational integrity and effectiveness of
workers becomes particularly crucial in distributed machine learning. In this
paper, we proposed a novel binary linear tree commitment-based ownership
protection model to ensure computational integrity with limited overhead and
concise proof. Due to the frequent updates of parameters during training, our
commitment scheme introduces a maintainable tree structure to reduce the costs
of updating proofs. Distinguished from SNARK-based verifiable computation, our
model achieves efficient proof aggregation by leveraging inner product
arguments. Furthermore, proofs of model weights are watermarked by worker
identity keys to prevent commitments from being forged or duplicated. The
performance analysis and comparison with SNARK-based hash commitments validate
the efficacy of our model in preserving computational integrity within
distributed machine learning.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05896" title="Abstract">arXiv:2401.05896</a> [<a href="/pdf/2401.05896" title="Download PDF">pdf</a>, <a href="/format/2401.05896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Role of Deep Learning in Advancing Proactive Cybersecurity Measures  for Smart Grid Networks: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdi%2C+N">Nima Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Albaseer%2C+A">Abdullatif Albaseer</a>, 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+M">Mohamed Abdallah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the IEEE internet of Things journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">As smart grids (SG) increasingly rely on advanced technologies like sensors
and communication systems for efficient energy generation, distribution, and
consumption, they become enticing targets for sophisticated cyberattacks. These
evolving threats demand robust security measures to maintain the stability and
resilience of modern energy systems. While extensive research has been
conducted, a comprehensive exploration of proactive cyber defense strategies
utilizing Deep Learning (DL) in {SG} remains scarce in the literature. This
survey bridges this gap, studying the latest DL techniques for proactive cyber
defense. The survey begins with an overview of related works and our distinct
contributions, followed by an examination of SG infrastructure. Next, we
classify various cyber defense techniques into reactive and proactive
categories. A significant focus is placed on DL-enabled proactive defenses,
where we provide a comprehensive taxonomy of DL approaches, highlighting their
roles and relevance in the proactive security of SG. Subsequently, we analyze
the most significant DL-based methods currently in use. Further, we explore
Moving Target Defense, a proactive defense strategy, and its interactions with
DL methodologies. We then provide an overview of benchmark datasets used in
this domain to substantiate the discourse.{ This is followed by a critical
discussion on their practical implications and broader impact on cybersecurity
in Smart Grids.} The survey finally lists the challenges associated with
deploying DL-based security systems within SG, followed by an outlook on future
developments in this key field.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05897" title="Abstract">arXiv:2401.05897</a> [<a href="/pdf/2401.05897" title="Download PDF">pdf</a>, <a href="/format/2401.05897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necessary and Sufficient Conditions for Avoiding Babuska&#x27;s Paradox on  Simplicial Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bartels%2C+S">S&#xf6;ren Bartels</a>, 
<a href="/search/math?searchtype=author&query=Tscherner%2C+P">Philipp Tscherner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">It is shown that discretizations based on variational or weak formulations of
the plate bending problem with simple support boundary conditions do not lead
to failure of convergence when polygonal domain approximations are used and the
imposed boundary conditions are compatible with the nodal interpolation of the
restriction of certain regular functions to approximating domains. It is
further shown that this is optimal in the sense that a full realization of the
boundary conditions leads to failure of convergence for conforming methods. The
abstract conditions imply that standard nonconforming and discontinuous
Galerkin methods converge correctly while conforming methods require a suitable
relaxation of the boundary condition. The results are confirmed by numerical
experiments.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05898" title="Abstract">arXiv:2401.05898</a> [<a href="/pdf/2401.05898" title="Download PDF">pdf</a>, <a href="/format/2401.05898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Partial Compress-and-Forward Strategy for Relay-assisted Wireless  Networks Based on Rateless Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weihang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shikh-Bahaei%2C+M">Mohammad Shikh-Bahaei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In this work, we propose a novel partial compress-and-forward (PCF) scheme
for improving the maximum achievable transmission rate of a diamond relay
network with two noisy relays. PCF combines conventional compress-and-forward
(CF) and amplify-and-forward (AF) protocols, enabling one relay to operate
alternately in the CF or the AF mode, while the other relay works purely in the
CF mode. As the direct link from the source to the destination is unavailable,
and there is no noiseless relay in the diamond network, messages received from
both relays must act as side information for each other and must be decoded
jointly. We propose a joint decoder to decode two Luby transform (LT) codes
received from both relays corresponding to the same original message. Numerical
results show that PCF can achieve significant performance improvements compared
to decode-and-forward (DF) and pure CF protocols when at least the channels
connected to one of the relays are of high quality.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05899" title="Abstract">arXiv:2401.05899</a> [<a href="/pdf/2401.05899" title="Download PDF">pdf</a>, <a href="/format/2401.05899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimistic Model Rollouts for Pessimistic Offline Policy Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+Y">Yuanzhao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiying Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zijian Gao</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xudong Gong</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kele Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+D">Dawei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Bo%2C+D">Ding Bo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huaimin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Model-based offline reinforcement learning (RL) has made remarkable progress,
offering a promising avenue for improving generalization with synthetic model
rollouts. Existing works primarily focus on incorporating pessimism for policy
optimization, usually via constructing a Pessimistic Markov Decision Process
(P-MDP). However, the P-MDP discourages the policies from learning in
out-of-distribution (OOD) regions beyond the support of offline datasets, which
can under-utilize the generalization ability of dynamics models. In contrast,
we propose constructing an Optimistic MDP (O-MDP). We initially observed the
potential benefits of optimism brought by encouraging more OOD rollouts.
Motivated by this observation, we present ORPO, a simple yet effective
model-based offline RL framework. ORPO generates Optimistic model Rollouts for
Pessimistic offline policy Optimization. Specifically, we train an optimistic
rollout policy in the O-MDP to sample more OOD model rollouts. Then we relabel
the sampled state-action pairs with penalized rewards and optimize the output
policy in the P-MDP. Theoretically, we demonstrate that the performance of
policies trained with ORPO can be lower-bounded in linear MDPs. Experimental
results show that our framework significantly outperforms P-MDP baselines by a
margin of 30%, achieving state-of-the-art performance on the widely-used
benchmark. Moreover, ORPO exhibits notable advantages in problems that require
generalization.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05901" title="Abstract">arXiv:2401.05901</a> [<a href="/pdf/2401.05901" title="Download PDF">pdf</a>, <a href="/format/2401.05901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConKeD: Multiview contrastive descriptor learning for keypoint-based  retinal image registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivas-Villar%2C+D">David Rivas-Villar</a>, 
<a href="/search/cs?searchtype=author&query=Hervella%2C+%C3%81+S">&#xc1;lvaro S. Hervella</a>, 
<a href="/search/cs?searchtype=author&query=Rouco%2C+J">Jos&#xe9; Rouco</a>, 
<a href="/search/cs?searchtype=author&query=Novo%2C+J">Jorge Novo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Retinal image registration is of utmost importance due to its wide
applications in medical practice. In this context, we propose ConKeD, a novel
deep learning approach to learn descriptors for retinal image registration. In
contrast to current registration methods, our approach employs a novel
multi-positive multi-negative contrastive learning strategy that enables the
utilization of additional information from the available training samples. This
makes it possible to learn high quality descriptors from limited training data.
To train and evaluate ConKeD, we combine these descriptors with domain-specific
keypoints, particularly blood vessel bifurcations and crossovers, that are
detected using a deep neural network. Our experimental results demonstrate the
benefits of the novel multi-positive multi-negative strategy, as it outperforms
the widely used triplet loss technique (single-positive and single-negative) as
well as the single-positive multi-negative alternative. Additionally, the
combination of ConKeD with the domain-specific keypoints produces comparable
results to the state-of-the-art methods for retinal image registration, while
offering important advantages such as avoiding pre-processing, utilizing fewer
training samples, and requiring fewer detected keypoints, among others.
Therefore, ConKeD shows a promising potential towards facilitating the
development and application of deep learning-based methods for retinal image
registration.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05902" title="Abstract">arXiv:2401.05902</a> [<a href="/pdf/2401.05902" title="Download PDF">pdf</a>, <a href="/format/2401.05902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Asymmetric Feedback Detection for Rate-adaptive HARQ with  Unreliable Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Weihang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Shikh-Bahaei%2C+M">Mohammad Shikh-Bahaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2305.02948">arXiv:2305.02948</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">This work considers downlink incremental redundancy Hybrid Automatic Repeat
Request (IR-HARQ) over unreliable feedback channels. Since the impact of
positive feedback (i.e., ACK) error is smaller than that of negative feedback
(i.e., NACK) error, an asymmetric feedback detection scheme is proposed to
protect NACK and further reduce the outage probability. We formulate the HARQ
process as a Markov Decision Process (MDP) model to adapt to the transmission
rate of each transmission attempt without enriched feedback and additional
feedback cost. We aim to optimize the performance of HARQ process under certain
outage probability requirements by finding optimal asymmetric detection
thresholds. Numerical results obtained on the downlink Rayleigh fading channel
and 5G new radio (NR) PUCCH feedback channel show that by applying asymmetric
feedback detection and adaptive rate allocation, higher throughput can be
achieved under outage probability limitations.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05906" title="Abstract">arXiv:2401.05906</a> [<a href="/pdf/2401.05906" title="Download PDF">pdf</a>, <a href="/format/2401.05906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PartSTAD: 2D-to-3D Part Segmentation Task Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyunjin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Sung%2C+M">Minhyuk Sung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce PartSTAD, a method designed for the task adaptation of 2D-to-3D
segmentation lifting. Recent studies have highlighted the advantages of
utilizing 2D segmentation models to achieve high-quality 3D segmentation
through few-shot adaptation. However, previous approaches have focused on
adapting 2D segmentation models for domain shift to rendered images and
synthetic text descriptions, rather than optimizing the model specifically for
3D segmentation. Our proposed task adaptation method finetunes a 2D bounding
box prediction model with an objective function for 3D segmentation. We
introduce weights for 2D bounding boxes for adaptive merging and learn the
weights using a small additional neural network. Additionally, we incorporate
SAM, a foreground segmentation model on a bounding box, to improve the
boundaries of 2D segments and consequently those of 3D segmentation. Our
experiments on the PartNet-Mobility dataset show significant improvements with
our task adaptation approach, achieving a 7.0%p increase in mIoU and a 5.2%p
improvement in mAP_50 for semantic and instance segmentation compared to the
SotA few-shot 3D segmentation model.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05907" title="Abstract">arXiv:2401.05907</a> [<a href="/pdf/2401.05907" title="Download PDF">pdf</a>, <a href="/format/2401.05907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Image Deblurring Networks based on Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Kang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This article introduces a sliding window model for defocus deblurring that
achieves the best performance to date with extremely low memory usage. Named
Swintormer, the method utilizes a diffusion model to generate latent prior
features that assist in restoring more detailed images. It also extends the
sliding window strategy to specialized Transformer blocks for efficient
inference. Additionally, we have further optimized Multiply-Accumulate
operations (Macs). Compared to the currently top-performing GRL method, our
Swintormer model drastically reduces computational complexity from 140.35 GMACs
to 8.02 GMacs, while also improving the Signal-to-Noise Ratio (SNR) for defocus
deblurring from 27.04 dB to 27.07 dB. This new method allows for the processing
of higher resolution images on devices with limited memory, significantly
expanding potential application scenarios. The article concludes with an
ablation study that provides an in-depth analysis of the impact of each network
module on final performance. The source code and model will be available at the
following website: https://github.com/bnm6900030/swintormer.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05908" title="Abstract">arXiv:2401.05908</a> [<a href="/pdf/2401.05908" title="Download PDF">pdf</a>, <a href="/ps/2401.05908" title="Download PostScript">ps</a>, <a href="/format/2401.05908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with  Epilepsy Medical Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Toshihisa Tanaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With large training datasets and massive amounts of computing sources, large
language models (LLMs) achieve remarkable performance in comprehensive and
generative ability. Based on those powerful LLMs, the model fine-tuned with
domain-specific datasets posseses more specialized knowledge and thus is more
practical like medical LLMs. However, the existing fine-tuned medical LLMs are
limited to general medical knowledge with English language. For
disease-specific problems, the model's response is inaccurate and sometimes
even completely irrelevant, especially when using a language other than
English. In this work, we focus on the particular disease of Epilepsy with
Japanese language and introduce a customized LLM termed as EpilepsyLLM. Our
model is trained from the pre-trained LLM by fine-tuning technique using
datasets from the epilepsy domain. The datasets contain knowledge of basic
information about disease, common treatment methods and drugs, and important
notes in life and work. The experimental results demonstrate that EpilepsyLLM
can provide more reliable and specialized medical knowledge responses.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05909" title="Abstract">arXiv:2401.05909</a> [<a href="/pdf/2401.05909" title="Download PDF">pdf</a>, <a href="/format/2401.05909" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoboCup 2023 Humanoid AdultSize Winner NimbRo: NimbRoNet3 Visual  Perception and Responsive Gait with Waveform In-walk Kicks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pavlichenko%2C+D">Dmytro Pavlichenko</a>, 
<a href="/search/cs?searchtype=author&query=Ficht%2C+G">Grzegorz Ficht</a>, 
<a href="/search/cs?searchtype=author&query=Villar-Corrales%2C+A">Angel Villar-Corrales</a>, 
<a href="/search/cs?searchtype=author&query=Denninger%2C+L">Luis Denninger</a>, 
<a href="/search/cs?searchtype=author&query=Brocker%2C+J">Julia Brocker</a>, 
<a href="/search/cs?searchtype=author&query=Sinen%2C+T">Tim Sinen</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+M">Michael Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Behnke%2C+S">Sven Behnke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for: RoboCup 2023: Robot World Cup XXVI, LNCS, Springer, to appear 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The RoboCup Humanoid League holds annual soccer robot world championships
towards the long-term objective of winning against the FIFA world champions by
2050. The participating teams continuously improve their systems. This paper
presents the upgrades to our humanoid soccer system, leading our team NimbRo to
win the Soccer Tournament in the Humanoid AdultSize League at RoboCup 2023 in
Bordeaux, France. The mentioned upgrades consist of: an updated model
architecture for visual perception, extended fused angles feedback mechanisms
and an additional COM-ZMP controller for walking robustness, and parametric
in-walk kicks through waveforms.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05912" title="Abstract">arXiv:2401.05912</a> [<a href="/pdf/2401.05912" title="Download PDF">pdf</a>, <a href="/format/2401.05912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompt-based mental health screening from social media text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+W+R+d">Wesley Ramos dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Paraboni%2C+I">Ivandre Paraboni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This article presents a method for prompt-based mental health screening from
a large and noisy dataset of social media text. Our method uses GPT 3.5.
prompting to distinguish publications that may be more relevant to the task,
and then uses a straightforward bag-of-words text classifier to predict actual
user labels. Results are found to be on pair with a BERT mixture of experts
classifier, and incurring only a fraction of its computational costs.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05914" title="Abstract">arXiv:2401.05914</a> [<a href="/pdf/2401.05914" title="Download PDF">pdf</a>, <a href="/format/2401.05914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Teachers Can Use Large Language Models and Bloom&#x27;s Taxonomy to  Create Educational Quizzes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Elkins%2C+S">Sabina Elkins</a>, 
<a href="/search/cs?searchtype=author&query=Kochmar%2C+E">Ekaterina Kochmar</a>, 
<a href="/search/cs?searchtype=author&query=Cheung%2C+J+C+K">Jackie C.K. Cheung</a>, 
<a href="/search/cs?searchtype=author&query=Serban%2C+I">Iulian Serban</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 figures. Accepted to the main track of the EAAI-24: The 14th Symposium on Educational Advances in Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Question generation (QG) is a natural language processing task with an
abundance of potential benefits and use cases in the educational domain. In
order for this potential to be realized, QG systems must be designed and
validated with pedagogical needs in mind. However, little research has assessed
or designed QG approaches with the input from real teachers or students. This
paper applies a large language model-based QG approach where questions are
generated with learning goals derived from Bloom's taxonomy. The automatically
generated questions are used in multiple experiments designed to assess how
teachers use them in practice. The results demonstrate that teachers prefer to
write quizzes with automatically generated questions, and that such quizzes
have no loss in quality compared to handwritten versions. Further, several
metrics indicate that automatically generated questions can even improve the
quality of the quizzes created, showing the promise for large scale use of QG
in the classroom setting.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05925" title="Abstract">arXiv:2401.05925</a> [<a href="/pdf/2401.05925" title="Download PDF">pdf</a>, <a href="/format/2401.05925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dou%2C+B">Bin Dou</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yongjia Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaohui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zejian Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We propose Compact and Swift Segmenting 3D Gaussians(CoSSegGaussians), a
method for compact 3D-consistent scene segmentation at fast rendering speed
with only RGB images input. Previous NeRF-based 3D segmentation methods have
relied on implicit or voxel neural scene representation and ray-marching volume
rendering which are time consuming. Recent 3D Gaussian Splatting significantly
improves the rendering speed, however, existing Gaussians-based segmentation
methods(eg: Gaussian Grouping) fail to provide compact segmentation masks
especially in zero-shot segmentation, which is mainly caused by the lack of
robustness and compactness for straightforwardly assigning learnable parameters
to each Gaussian when encountering inconsistent 2D machine-generated labels.
Our method aims to achieve compact and reliable zero-shot scene segmentation
swiftly by mapping fused spatial and semantically meaningful features for each
Gaussian point with a shallow decoding network. Specifically, our method
firstly optimizes Gaussian points' position, convariance and color attributes
under the supervision of RGB images. After Gaussian Locating, we distill
multi-scale DINO features extracted from images through unprojection to each
Gaussian, which is then incorporated with spatial features from the fast point
features processing network, i.e. RandLA-Net. Then the shallow decoding MLP is
applied to the multi-scale fused features to obtain compact segmentation.
Experimental results show that our model can perform high-quality zero-shot
scene segmentation, as our model outperforms other segmentation methods on both
semantic and panoptic segmentation task, meanwhile consumes approximately only
10% segmenting time compared to NeRF-based segmentation. Code and more results
will be available at https://David-Dou.github.io/CoSSegGaussians
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05926" title="Abstract">arXiv:2401.05926</a> [<a href="/pdf/2401.05926" title="Download PDF">pdf</a>, <a href="/format/2401.05926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Commit Message Generation: A Preliminary  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Linghao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingshu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Peng Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 31st IEEE International Conference on Software Analysis, Evolution, and Reengineering (SANER)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A commit message is a textual description of the code changes in a commit,
which is a key part of the Git version control system (VCS). It captures the
essence of software updating. Therefore, it can help developers understand code
evolution and facilitate efficient collaboration between developers. However,
it is time-consuming and labor-intensive to write good and valuable commit
messages. Some researchers have conducted extensive studies on the automatic
generation of commit messages and proposed several methods for this purpose,
such as generation-based and retrieval-based models. However, seldom studies
explored whether large language models (LLMs) can be effectively used for the
automatic generation of commit messages. To this end, this paper designed and
conducted a series of experiments to comprehensively evaluate the performance
of popular open-source and closed-source LLMs, i.e., Llama 2 and ChatGPT, in
commit message generation. The results indicate that considering the BLEU and
Rouge-L metrics, LLMs surpass existing methods in certain indicators but lag
behind in others. After human evaluations, however, LLMs show a distinct
advantage over all these existing methods. Especially, in 78% of the 366
samples, the commit messages generated by LLMs were evaluated by humans as the
best. This work not only reveals the promising potential of using LLMs to
generate commit messages, but also explores the limitations of commonly used
metrics in evaluating the quality of automatically generated commit messages.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05928" title="Abstract">arXiv:2401.05928</a> [<a href="/pdf/2401.05928" title="Download PDF">pdf</a>, <a href="/format/2401.05928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Unhelpfulness in Emotional Support Conversations with  Multifaceted AI Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiashuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chunpu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Leong%2C+C+T">Chak Tou Leong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">An emotional support conversation system aims to alleviate users' emotional
distress and assist them in addressing their challenges. To generate supportive
responses, it is critical to consider multiple factors such as empathy, support
strategies, and response coherence, as established in prior methods.
Nonetheless, previous models occasionally generate unhelpful responses, which
intend to provide support but display counterproductive effects. According to
psychology and communication theories, poor performance in just one
contributing factor might cause a response to be unhelpful. From the model
training perspective, since these models have not been exposed to unhelpful
responses during their training phase, they are unable to distinguish if the
tokens they generate might result in unhelpful responses during inference. To
address this issue, we introduce a novel model-agnostic framework named
mitigating unhelpfulness with multifaceted AI feedback for emotional support
(Muffin). Specifically, Muffin employs a multifaceted AI feedback module to
assess the helpfulness of responses generated by a specific model with
consideration of multiple factors. Using contrastive learning, it then reduces
the likelihood of the model generating unhelpful responses compared to the
helpful ones. Experimental results demonstrate that Muffin effectively
mitigates the generation of unhelpful responses while slightly increasing
response fluency and relevance.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05930" title="Abstract">arXiv:2401.05930</a> [<a href="/pdf/2401.05930" title="Download PDF">pdf</a>, <a href="/format/2401.05930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kai%2C+J">Jushi Kai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hai Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouhan Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) demonstrate great performance in text
generation. However, LLMs are still suffering from hallucinations. In this
work, we propose an inference-time method, Self-Highlighted Hesitation (SH2),
to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in
information theory that for an LLM, the tokens predicted with lower
probabilities are prone to be more informative than others. Our analysis shows
that the tokens assigned with lower probabilities by an LLM are more likely to
be closely related to factual information, such as nouns, proper nouns, and
adjectives. Therefore, we propose to ''highlight'' the factual information by
selecting the tokens with the lowest probabilities and concatenating them to
the original context, thus forcing the model to repeatedly read and hesitate on
these tokens before generation. During decoding, we also adopt contrastive
decoding to emphasize the difference in the output probabilities brought by the
hesitation. Experimental results demonstrate that our SH2, requiring no
additional data or models, can effectively help LLMs elicit factual knowledge
and distinguish hallucinated contexts. Significant and consistent improvements
are achieved by SH2 for LLaMA-7b and LLaMA2-7b on multiple hallucination tasks.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05932" title="Abstract">arXiv:2401.05932</a> [<a href="/pdf/2401.05932" title="Download PDF">pdf</a>, <a href="/format/2401.05932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiffDA: a diffusion model for weather-scale data assimilation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Langwen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gianinazzi%2C+L">Lukas Gianinazzi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yuejiang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Dueben%2C+P+D">Peter D. Dueben</a>, 
<a href="/search/cs?searchtype=author&query=Hoefler%2C+T">Torsten Hoefler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The generation of initial conditions via accurate data assimilation is
crucial for reliable weather forecasting and climate modeling. We propose the
DiffDA as a machine learning based data assimilation method capable of
assimilating atmospheric variables using predicted states and sparse
observations. We adapt the pretrained GraphCast weather forecast model as a
denoising diffusion model. Our method applies two-phase conditioning: on the
predicted state during both training and inference, and on sparse observations
during inference only. As a byproduct, this strategy also enables the
post-processing of predictions into the future, for which no observations are
available.Through experiments based on a reanalysis dataset, we have verified
that our method can produce assimilated global atmospheric data consistent with
observations at 0.25degree resolution. The experiments also show that the
initial conditions that are generated via our approach can be used for forecast
models with a loss of lead time of at most 24 hours when compared to initial
conditions of state-of-the-art data assimilation suites. This enables to apply
the method to real world applications such as the creation of reanalysis
datasets with autoregressive data assimilation.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05933" title="Abstract">arXiv:2401.05933</a> [<a href="/pdf/2401.05933" title="Download PDF">pdf</a>, <a href="/ps/2401.05933" title="Download PostScript">ps</a>, <a href="/format/2401.05933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time Series Forecasting of HIV/AIDS in the Philippines Using Deep  Learning: Does COVID-19 Epidemic Matter?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aribe%2C+S+G">Sales G. Aribe Jr.</a>, 
<a href="/search/cs?searchtype=author&query=Gerardo%2C+B+D">Bobby D. Gerardo</a>, 
<a href="/search/cs?searchtype=author&query=Medina%2C+R+P">Ruji P. Medina</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, Published with International Journal of Emerging Technology and Advanced Engineering (IJETAE)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Emerging Technology and Advanced
  Engineering, 12(9), 144-157 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">With a 676% growth rate in HIV incidence between 2010 and 2021, the HIV/AIDS
epidemic in the Philippines is the one that is spreading the quickest in the
western Pacific. Although the full effects of COVID-19 on HIV services and
development are still unknown, it is predicted that such disruptions could lead
to a significant increase in HIV casualties. Therefore, the nation needs some
modeling and forecasting techniques to foresee the spread pattern and enhance
the governments prevention, treatment, testing, and care program. In this
study, the researcher uses Multilayer Perceptron Neural Network to forecast
time series during the period when the COVID-19 pandemic strikes the nation,
using statistics taken from the HIV/AIDS and ART Registry of the Philippines.
After training, validation, and testing of data, the study finds that the
predicted cumulative cases in the nation by 2030 will reach 145,273.
Additionally, there is very little difference between observed and anticipated
HIV epidemic levels, as evidenced by reduced RMSE, MAE, and MAPE values as well
as a greater coefficient of determination. Further research revealed that the
Philippines seems far from achieving Sustainable Development Goal 3 of Project
2030 due to an increase in the nations rate of new HIV infections. Despite the
detrimental effects of COVID-19 spread on HIV/AIDS efforts nationwide, the
Philippine government, under the Marcos administration, must continue to adhere
to the United Nations 90-90-90 targets by enhancing its ART program and
ensuring that all vital health services are readily accessible and available.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05939" title="Abstract">arXiv:2401.05939</a> [<a href="/pdf/2401.05939" title="Download PDF">pdf</a>, <a href="/format/2401.05939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DREQ: Document Re-Ranking Using Entity-based Query Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Shubham Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Mackie%2C+I">Iain Mackie</a>, 
<a href="/search/cs?searchtype=author&query=Dalton%2C+J">Jeff Dalton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented as a full paper at ECIR 2024 in Glasgpow, UK
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While entity-oriented neural IR models have advanced significantly, they
often overlook a key nuance: the varying degrees of influence individual
entities within a document have on its overall relevance. Addressing this gap,
we present DREQ, an entity-oriented dense document re-ranking model. Uniquely,
we emphasize the query-relevant entities within a document's representation
while simultaneously attenuating the less relevant ones, thus obtaining a
query-specific entity-centric document representation. We then combine this
entity-centric document representation with the text-centric representation of
the document to obtain a "hybrid" representation of the document. We learn a
relevance score for the document using this hybrid representation. Using four
large-scale benchmarks, we show that DREQ outperforms state-of-the-art neural
and non-neural re-ranking methods, highlighting the effectiveness of our
entity-oriented representation approach.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05940" title="Abstract">arXiv:2401.05940</a> [<a href="/pdf/2401.05940" title="Download PDF">pdf</a>, <a href="/format/2401.05940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mutation-based Consistency Testing for Evaluating the Code Understanding  Capability of LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Ziyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+D">Donghwan Shin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an author-preprint. The published version will be included in the proceedings of CAIN 2024 (co-located with ICSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) have shown remarkable capabilities in processing
both natural and programming languages, which have enabled various applications
in software engineering, such as requirement engineering, code generation, and
software testing. However, existing code generation benchmarks do not
necessarily assess the code understanding performance of LLMs, especially for
the subtle inconsistencies that may arise between code and its semantics
described in natural language.
<br />In this paper, we propose a novel method to systematically assess the code
understanding performance of LLMs, particularly focusing on subtle differences
between code and its descriptions, by introducing code mutations to existing
code generation datasets. Code mutations are small changes that alter the
semantics of the original code, creating a mismatch with the natural language
description. We apply different types of code mutations, such as operator
replacement and statement deletion, to generate inconsistent code-description
pairs. We then use these pairs to test the ability of LLMs to correctly detect
the inconsistencies.
<br />We propose a new LLM testing method, called Mutation-based Consistency
Testing (MCT), and conduct a case study on the two popular LLMs, GPT-3.5 and
GPT-4, using the state-of-the-art code generation benchmark, HumanEval-X, which
consists of six programming languages (Python, C++, Java, Go, JavaScript, and
Rust). We compare the performance of the LLMs across different types of code
mutations and programming languages and analyze the results. We find that the
LLMs show significant variation in their code understanding performance and
that they have different strengths and weaknesses depending on the mutation
type and language.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05943" title="Abstract">arXiv:2401.05943</a> [<a href="/pdf/2401.05943" title="Download PDF">pdf</a>, <a href="/format/2401.05943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoK: Analysis techniques for WebAssembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harnes%2C+H">H&#xe5;kon Harnes</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+D">Donn Morrison</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">WebAssembly is a low-level bytecode language that allows high-level languages
like C, C++, and Rust to be executed in the browser at near-native performance.
In recent years, WebAssembly has gained widespread adoption is now natively
supported by all modern browsers. However, vulnerabilities in memory-unsafe
languages, like C and C++, can translate into vulnerabilities in WebAssembly
binaries. Unfortunately, most WebAssembly binaries are compiled from such
memory-unsafe languages, and these vulnerabilities have been shown to be
practical in real-world scenarios. WebAssembly smart contracts have also been
found to be vulnerable, causing significant financial loss. Additionally,
WebAssembly has been used for malicious purposes like cryptojacking. To address
these issues, several analysis techniques for WebAssembly binaries have been
proposed. In this paper, we conduct a comprehensive literature review of these
techniques and categorize them based on their analysis strategy and objectives.
Furthermore, we compare and evaluate the techniques using quantitative data,
highlighting their strengths and weaknesses. In addition, one of the main
contributions of this paper is the identification of future research directions
based on the thorough literature review conducted.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05946" title="Abstract">arXiv:2401.05946</a> [<a href="/pdf/2401.05946" title="Download PDF">pdf</a>, <a href="/format/2401.05946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Cognitive Maps from Transformer Representations for Efficient  Planning in Partially Observed Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dedieu%2C+A">Antoine Dedieu</a>, 
<a href="/search/cs?searchtype=author&query=Lehrach%2C+W">Wolfgang Lehrach</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guangyao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=George%2C+D">Dileep George</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A1zaro-Gredilla%2C+M">Miguel L&#xe1;zaro-Gredilla</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Despite their stellar performance on a wide range of tasks, including
in-context tasks only revealed during inference, vanilla transformers and
variants trained for next-token predictions (a) do not learn an explicit world
model of their environment which can be flexibly queried and (b) cannot be used
for planning or navigation. In this paper, we consider partially observed
environments (POEs), where an agent receives perceptually aliased observations
as it navigates, which makes path planning hard. We introduce a transformer
with (multiple) discrete bottleneck(s), TDB, whose latent codes learn a
compressed representation of the history of observations and actions. After
training a TDB to predict the future observation(s) given the history, we
extract interpretable cognitive maps of the environment from its active
bottleneck(s) indices. These maps are then paired with an external solver to
solve (constrained) path planning problems. First, we show that a TDB trained
on POEs (a) retains the near perfect predictive performance of a vanilla
transformer or an LSTM while (b) solving shortest path problems exponentially
faster. Second, a TDB extracts interpretable representations from text
datasets, while reaching higher in-context accuracy than vanilla sequence
models. Finally, in new POEs, a TDB (a) reaches near-perfect in-context
accuracy, (b) learns accurate in-context cognitive maps (c) solves in-context
path planning problems.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05947" title="Abstract">arXiv:2401.05947</a> [<a href="/pdf/2401.05947" title="Download PDF">pdf</a>, <a href="/format/2401.05947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blockchain-based Decentralized Time Lock Machines: Automated Reveal of  Time-sensitive Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhuolun Li</a>, 
<a href="/search/cs?searchtype=author&query=Majumdar%2C+S">Srijoni Majumdar</a>, 
<a href="/search/cs?searchtype=author&query=Pournaras%2C+E">Evangelos Pournaras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Conditional Information Reveal (CIR) automates the release of information
upon meeting specific pre-defined conditions, such as time or location. This
paper advances the understanding and implementation of CIR by introducing a new
paradigm to highlight the security challenges in CIR design, and proposes a
decentralized architecture as a design guideline for secure CIR systems.
Furthermore, in the context of time-sensitive data sharing, this paper proposes
a practical timed-release cryptography system employing the proposed
architecture and a novel verifiable secret sharing scheme. Key achievements of
this study include the creation of an open-source prototype for practical
deployment and a comprehensive system evaluation that highlights the enhanced
security and efficiency of the proposed system. Furthermore, the paper delves
into the application of this system in E-voting scenarios, illustrating its
capacity to secure and ensure fair electronic voting processes.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05949" title="Abstract">arXiv:2401.05949</a> [<a href="/pdf/2401.05949" title="Download PDF">pdf</a>, <a href="/format/2401.05949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Vulnerabilities in Large Language Models: In-context Learning  Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shuai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Meihuizi Jia</a>, 
<a href="/search/cs?searchtype=author&query=Tuan%2C+L+A">Luu Anh Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jinming Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In-context learning, a paradigm bridging the gap between pre-training and
fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in
few-shot settings. Unlike traditional fine-tuning methods, in-context learning
adapts pre-trained models to unseen tasks without updating any parameters.
Despite being widely applied, in-context learning is vulnerable to malicious
attacks. In this work, we raise security concerns regarding this paradigm. Our
studies demonstrate that an attacker can manipulate the behavior of large
language models by poisoning the demonstration context, without the need for
fine-tuning the model. Specifically, we have designed a new backdoor attack
method, named ICLAttack, to target large language models based on in-context
learning. Our method encompasses two types of attacks: poisoning demonstration
examples and poisoning prompts, which can make models behave in accordance with
predefined intentions. ICLAttack does not require additional fine-tuning to
implant a backdoor, thus preserving the model's generality. Furthermore, the
poisoned examples are correctly labeled, enhancing the natural stealth of our
attack method. Extensive experimental results across several language models,
ranging in size from 1.3B to 40B parameters, demonstrate the effectiveness of
our attack method, exemplified by a high average attack success rate of 95.0%
across the three datasets on OPT models. Our findings highlight the
vulnerabilities of language models, and we hope this work will raise awareness
of the possible security threats associated with in-context learning.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05950" title="Abstract">arXiv:2401.05950</a> [<a href="/pdf/2401.05950" title="Download PDF">pdf</a>, <a href="/format/2401.05950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Kite-Platform Interactions in Offshore Airborne Wind Energy  Systems: Frequency Analysis and Control Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Trombini%2C+S">Sofia Trombini</a>, 
<a href="/search/eess?searchtype=author&query=Pasta%2C+E">Edoardo Pasta</a>, 
<a href="/search/eess?searchtype=author&query=Fagiano%2C+L">Lorenzo Fagiano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This study investigates deep offshore, pumping Airborne Wind Energy systems,
focusing on the kite-platform interaction. The considered system includes a 360
m2 soft-wing kite, connected by a tether to a winch installed on a
10-meter-deep spar with four mooring lines. Wind power is converted into
electricity with a feedback controlled periodic trajectory of the kite and
corresponding reeling motion of the tether. An analysis of the mutual influence
between the platform and the kite dynamics, with different wave regimes,
reveals a rather small sensitivity of the flight pattern to the platform
oscillations; on the other hand, the frequency of tether force oscillations can
be close to the platform resonance peaks, resulting in possible increased
fatigue loads and damage of the floating and submerged components. A control
design procedure is then proposed to avoid this problem, acting on the kite
path planner. Simulation results confirm the effectiveness of the approach.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05952" title="Abstract">arXiv:2401.05952</a> [<a href="/pdf/2401.05952" title="Download PDF">pdf</a>, <a href="/format/2401.05952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Chujie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dongping Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qihui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yue Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+Y">Yao Wan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the remarkable development and widespread applications of large language
models (LLMs), the use of machine-generated text (MGT) is becoming increasingly
common. This trend brings potential risks, particularly to the quality and
completeness of information in fields such as news and education. Current
research predominantly addresses the detection of pure MGT without adequately
addressing mixed scenarios including AI-revised Human-Written Text (HWT) or
human-revised MGT. To confront this challenge, we introduce mixcase, a novel
concept representing a hybrid text form involving both machine-generated and
human-generated content. We collected mixcase instances generated from multiple
daily text-editing scenarios and composed MixSet, the first dataset dedicated
to studying these mixed modification scenarios. We conduct experiments to
evaluate the efficacy of popular MGT detectors, assessing their effectiveness,
robustness, and generalization performance. Our findings reveal that existing
detectors struggle to identify mixcase as a separate class or MGT, particularly
in dealing with subtle modifications and style adaptability. This research
underscores the urgent need for more fine-grain detectors tailored for mixcase,
offering valuable insights for future research. Code and Models are available
at https://github.com/Dongping-Chen/MixSet.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05956" title="Abstract">arXiv:2401.05956</a> [<a href="/pdf/2401.05956" title="Download PDF">pdf</a>, <a href="/ps/2401.05956" title="Download PostScript">ps</a>, <a href="/format/2401.05956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A k-swap Local Search for Makespan Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rohwedder%2C+L">Lars Rohwedder</a>, 
<a href="/search/cs?searchtype=author&query=Safari%2C+A">Ashkan Safari</a>, 
<a href="/search/cs?searchtype=author&query=Vredeveld%2C+T">Tjark Vredeveld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">Local search is a widely used technique for tackling challenging optimization
problems, offering significant advantages in terms of computational efficiency
and exhibiting strong empirical behavior across a wide range of problem
domains. In this paper, we address a scheduling problem on two identical
parallel machines with the objective of \emph{makespan minimization}. For this
problem, we consider a local search neighborhood, called \emph{$k$-swap}, which
is a more generalized version of the widely-used \emph{swap} and \emph{jump}
neighborhoods. The $k$-swap neighborhood is obtained by swapping at most $k$
jobs between two machines in our schedule. First, we propose an algorithm for
finding an improving neighbor in the $k$-swap neighborhood which is faster than
the naive approach, and prove an almost matching lower bound on any such an
algorithm. Then, we analyze the number of local search steps required to
converge to a local optimum with respect to the $k$-swap neighborhood. For the
case $k = 2$ (similar to the swap neighborhood), we provide a polynomial upper
bound on the number of local search steps, and for the case $k = 3$, we provide
an exponential lower bound. Finally, we conduct computational experiments on
various families of instances, and we discuss extensions to more than two
machines in our schedule.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05960" title="Abstract">arXiv:2401.05960</a> [<a href="/pdf/2401.05960" title="Download PDF">pdf</a>, <a href="/format/2401.05960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Insides OptVerse AI Solver: Design Principles and  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangzhou Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+H">Hui-Ling Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Weilin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+M">Meng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yimin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhenan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zirui Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Y">Yufei Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhihai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Z">Zijie Geng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haoyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zhiwu An</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Muming Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianshu Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Defeng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+T">Tao Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+J">Jia Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+M">Mingxuan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jianye Hao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jun Yao</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+K">Kun Mao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In an era of digital ubiquity, efficient resource management and
decision-making are paramount across numerous industries. To this end, we
present a comprehensive study on the integration of machine learning (ML)
techniques into Huawei Cloud's OptVerse AI Solver, which aims to mitigate the
scarcity of real-world mathematical programming instances, and to surpass the
capabilities of traditional optimization techniques. We showcase our methods
for generating complex SAT and MILP instances utilizing generative models that
mirror multifaceted structures of real-world problem. Furthermore, we introduce
a training framework leveraging augmentation policies to maintain solvers'
utility in dynamic environments. Besides the data generation and augmentation,
our proposed approaches also include novel ML-driven policies for personalized
solver strategies, with an emphasis on applications like graph convolutional
networks for initial basis selection and reinforcement learning for advanced
presolving and cut selection. Additionally, we detail the incorporation of
state-of-the-art parameter tuning algorithms which markedly elevate solver
performance. Compared with traditional solvers such as Gurobi and SCIP, our
ML-augmented OptVerse AI Solver demonstrates superior speed and precision
across both established benchmarks and real-world scenarios, reinforcing the
practical imperative and effectiveness of machine learning techniques in
mathematical programming solvers.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05961" title="Abstract">arXiv:2401.05961</a> [<a href="/pdf/2401.05961" title="Download PDF">pdf</a>, <a href="/format/2401.05961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Securing an Application Layer Gateway: An Industrial Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cesarano%2C+C">Carmine Cesarano</a>, 
<a href="/search/cs?searchtype=author&query=Natella%2C+R">Roberto Natella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Application Layer Gateways (ALGs) play a crucial role in securing critical
systems, including railways, industrial automation, and defense applications,
by segmenting networks at different levels of criticality. However, they
require rigorous security testing to prevent software vulnerabilities, not only
at the network level but also at the application layer (e.g., deep traffic
inspection components). This paper presents a vulnerability-driven methodology
for the comprehensive security testing of ALGs. We present the methodology in
the context of an industrial case study in the railways domain, and a
simulation-based testing environment to support the methodology.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05963" title="Abstract">arXiv:2401.05963</a> [<a href="/pdf/2401.05963" title="Download PDF">pdf</a>, <a href="/format/2401.05963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A uniform non-linear subdivision scheme reproducing polynomials at any  non-uniform grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=L%C3%B3pez-Ure%C3%B1a%2C+S">Sergio L&#xf3;pez-Ure&#xf1;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we introduce a novel non-linear uniform subdivision scheme for
the generation of curves in $\mathbb{R}^n$, $n\geq2$. This scheme is
distinguished by its capacity to reproduce second-degree polynomial data on
non-uniform grids without necessitating prior knowledge of the grid
specificities. Our approach exploits the potential of annihilation operators to
infer the underlying grid, thereby obviating the need for end-users to specify
such information. We define the scheme in a non-stationary manner, ensuring
that it progressively approaches a classical linear scheme as the iteration
number increases, all while preserving its polynomial reproduction capability.
<br />The convergence is established through two distinct theoretical methods.
Firstly, we propose a new class of schemes, including ours, for which we
establish $\mathcal{C}^1$ convergence by combining results from the analysis of
quasilinear schemes and asymptotically equivalent linear non-uniform
non-stationary schemes. Secondly, we adapt conventional analytical tools for
non-linear schemes to the non-stationary case, allowing us to again conclude
the convergence of the proposed class of schemes.
<br />We show its practical usefulness through numerical examples, showing that the
generated curves are curvature continuous.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05964" title="Abstract">arXiv:2401.05964</a> [<a href="/pdf/2401.05964" title="Download PDF">pdf</a>, <a href="/ps/2401.05964" title="Download PostScript">ps</a>, <a href="/format/2401.05964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An attempt to generate new bridge types from latent space of PixelCNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongjun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Try to generate new bridge types using generative artificial intelligence
technology. Using symmetric structured image dataset of three-span beam bridge,
arch bridge, cable-stayed bridge and suspension bridge , based on Python
programming language, TensorFlow and Keras deep learning platform framework ,
PixelCNN is constructed and trained. The model can capture the statistical
structure of the images and calculate the probability distribution of the next
pixel when the previous pixels are given. From the obtained latent space
sampling, new bridge types different from the training dataset can be
generated. PixelCNN can organically combine different structural components on
the basis of human original bridge types, creating new bridge types that have a
certain degree of human original ability. Autoregressive models cannot
understand the meaning of the sequence, while multimodal models combine
regression and autoregressive models to understand the sequence. Multimodal
models should be the way to achieve artificial general intelligence in the
future.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05965" title="Abstract">arXiv:2401.05965</a> [<a href="/pdf/2401.05965" title="Download PDF">pdf</a>, <a href="/format/2401.05965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAP: SPMD DNN Training on Heterogeneous GPU Clusters with Automated  Program Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Diao%2C+L">Lansong Diao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zongyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EuroSys '24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Single-Program-Multiple-Data (SPMD) parallelism has recently been adopted to
train large deep neural networks (DNNs). Few studies have explored its
applicability on heterogeneous clusters, to fully exploit available resources
for large model learning. This paper presents \OurSystem, an automated system
designed to expedite SPMD DNN training on heterogeneous clusters. \OurSystem
jointly optimizes the tensor sharding strategy, sharding ratios across
heterogeneous devices and the communication methods for tensor exchanges for
optimized distributed training with SPMD parallelism. We novelly formulate
model partitioning as a program synthesis problem, in which we generate a
distributed program from scratch on a distributed instruction set that
semantically resembles the program designed for a single device, and
systematically explore the solution space with an A*-based search algorithm. We
derive the optimal tensor sharding ratios by formulating it as a linear
programming problem. Additionally, \OurSystem explores tensor communication
optimization in a heterogeneous cluster and integrates it as part of the
program synthesis process, for automatically choosing optimal collective
communication primitives and applying sufficient factor broadcasting technique.
Extensive experiments on representative workloads demonstrate that \OurSystem
achieves up to 2.41x speed-up on heterogeneous clusters.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05967" title="Abstract">arXiv:2401.05967</a> [<a href="/pdf/2401.05967" title="Download PDF">pdf</a>, <a href="/format/2401.05967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph  Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yihua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The primary aim of Knowledge Graph embeddings (KGE) is to learn
low-dimensional representations of entities and relations for predicting
missing facts. While rotation-based methods like RotatE and QuatE perform well
in KGE, they face two challenges: limited model flexibility requiring
proportional increases in relation size with entity dimension, and difficulties
in generalizing the model for higher-dimensional rotations. To address these
issues, we introduce OrthogonalE, a novel KGE model employing matrices for
entities and block-diagonal orthogonal matrices with Riemannian optimization
for relations. This approach enhances the generality and flexibility of KGE
models. The experimental results indicate that our new KGE model, OrthogonalE,
is both general and flexible, significantly outperforming state-of-the-art KGE
models while substantially reducing the number of relation parameters.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05968" title="Abstract">arXiv:2401.05968</a> [<a href="/pdf/2401.05968" title="Download PDF">pdf</a>, <a href="/format/2401.05968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Feature Fusion Architecture For Resource-Constrained Crowd  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chaudhuri%2C+Y">Yashwardhan Chaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Ankit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Phukan%2C+O+C">Orchid Chetia Phukan</a>, 
<a href="/search/cs?searchtype=author&query=Buduru%2C+A+B">Arun Balaji Buduru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Crowd counting finds direct applications in real-world situations, making
computational efficiency and performance crucial. However, most of the previous
methods rely on a heavy backbone and a complex downstream architecture that
restricts the deployment. To address this challenge and enhance the versatility
of crowd-counting models, we introduce two lightweight models. These models
maintain the same downstream architecture while incorporating two distinct
backbones: MobileNet and MobileViT. We leverage Adjacent Feature Fusion to
extract diverse scale features from a Pre-Trained Model (PTM) and subsequently
combine these features seamlessly. This approach empowers our models to achieve
improved performance while maintaining a compact and efficient design. With the
comparison of our proposed models with previously available state-of-the-art
(SOTA) methods on ShanghaiTech-A ShanghaiTech-B and UCF-CC-50 dataset, it
achieves comparable results while being the most computationally efficient
model. Finally, we present a comparative study, an extensive ablation study,
along with pruning to show the effectiveness of our models.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05969" title="Abstract">arXiv:2401.05969</a> [<a href="/pdf/2401.05969" title="Download PDF">pdf</a>, <a href="/format/2401.05969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Aware Deep Reinforcement Learning for the Traveling Officer  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strau%C3%9F%2C+N">Niklas Strau&#xdf;</a>, 
<a href="/search/cs?searchtype=author&query=Schubert%2C+M">Matthias Schubert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIAM SDM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The traveling officer problem (TOP) is a challenging stochastic optimization
task. In this problem, a parking officer is guided through a city equipped with
parking sensors to fine as many parking offenders as possible. A major
challenge in TOP is the dynamic nature of parking offenses, which randomly
appear and disappear after some time, regardless of whether they have been
fined. Thus, solutions need to dynamically adjust to currently fineable parking
offenses while also planning ahead to increase the likelihood that the officer
arrives during the offense taking place. Though various solutions exist, these
methods often struggle to take the implications of actions on the ability to
fine future parking violations into account. This paper proposes SATOP, a novel
spatial-aware deep reinforcement learning approach for TOP. Our novel state
encoder creates a representation of each action, leveraging the spatial
relationships between parking spots, the agent, and the action. Furthermore, we
propose a novel message-passing module for learning future inter-action
correlations in the given environment. Thus, the agent can estimate the
potential to fine further parking violations after executing an action. We
evaluate our method using an environment based on real-world data from
Melbourne. Our results show that SATOP consistently outperforms
state-of-the-art TOP agents and is able to fine up to 22% more parking
offenses.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05971" title="Abstract">arXiv:2401.05971</a> [<a href="/pdf/2401.05971" title="Download PDF">pdf</a>, <a href="/format/2401.05971" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UAVD4L: A Large-Scale Dataset for UAV 6-DoF Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Rouwan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiaoya Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Juelin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuxiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Maojun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+S">Shen Yan</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 3DV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Despite significant progress in global localization of Unmanned Aerial
Vehicles (UAVs) in GPS-denied environments, existing methods remain constrained
by the availability of datasets. Current datasets often focus on small-scale
scenes and lack viewpoint variability, accurate ground truth (GT) pose, and UAV
build-in sensor data. To address these limitations, we introduce a large-scale
6-DoF UAV dataset for localization (UAVD4L) and develop a two-stage 6-DoF
localization pipeline (UAVLoc), which consists of offline synthetic data
generation and online visual localization. Additionally, based on the 6-DoF
estimator, we design a hierarchical system for tracking ground target in 3D
space. Experimental results on the new dataset demonstrate the effectiveness of
the proposed approach. Code and dataset are available at
https://github.com/RingoWRW/UAVD4L
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05975" title="Abstract">arXiv:2401.05975</a> [<a href="/pdf/2401.05975" title="Download PDF">pdf</a>, <a href="/format/2401.05975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end Learnable Clustering for Intent Learning in Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Shihao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+J">Jun Xia</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingwei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jian Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenliang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guannan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kejun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinwang Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Mining users' intents plays a crucial role in sequential recommendation. The
recent approach, ICLRec, was introduced to extract underlying users' intents
using contrastive learning and clustering. While it has shown effectiveness,
the existing method suffers from complex and cumbersome alternating
optimization, leading to two main issues. Firstly, the separation of
representation learning and clustering optimization within a generalized
expectation maximization (EM) framework often results in sub-optimal
performance. Secondly, performing clustering on the entire dataset hampers
scalability for large-scale industry data. To address these challenges, we
propose a novel intent learning method called \underline{ELCRec}, which
integrates representation learning into an \underline{E}nd-to-end
\underline{L}earnable \underline{C}lustering framework for
\underline{Rec}ommendation. Specifically, we encode users' behavior sequences
and initialize the cluster centers as learnable network parameters.
Additionally, we design a clustering loss that guides the networks to
differentiate between different cluster centers and pull similar samples
towards their respective cluster centers. This allows simultaneous optimization
of recommendation and clustering using mini-batch data. Moreover, we leverage
the learned cluster centers as self-supervision signals for representation
learning, resulting in further enhancement of recommendation performance.
Extensive experiments conducted on open benchmarks and industry data validate
the superiority, effectiveness, and efficiency of our proposed ELCRec method.
Code is available at: https://github.com/yueliu1999/ELCRec.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05984" title="Abstract">arXiv:2401.05984</a> [<a href="/pdf/2401.05984" title="Download PDF">pdf</a>, <a href="/format/2401.05984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HybridOctree_Hex: Hybrid Octree-Based Adaptive All-Hexahedral Mesh  Generation with Jacobian Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hua Tong</a>, 
<a href="/search/cs?searchtype=author&query=Halilaj%2C+E">Eni Halilaj</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y+J">Yongjie Jessica Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present a new software package "HybridOctree_Hex" for adaptive
all-hexahedral mesh generation based on hybrid octree and quality improvement
with Jacobian control. The proposed HybridOctree_Hex begins by detecting
curvatures and narrow regions of the input boundary to identify key surface
features and initialize an octree structure. Subsequently, a strongly balanced
octree is constructed using the balancing and pairing rules. Inspired by our
earlier preliminary hybrid octree-based work, templates are designed to
guarantee an all-hexahedral dual mesh generation directly from the strongly
balanced octree. With these pre-defined templates, the sophisticated hybrid
octree construction step is skipped to achieve an efficient implementation.
After that, elements outside and around the boundary are removed to create a
core mesh. The boundary points of the core mesh are connected to their
corresponding closest points on the surface to fill the buffer zone and build
the final mesh. Coupled with smart Laplacian smoothing, HybridOctree_Hex takes
advantage of a delicate optimization-based quality improvement method
considering geometric fitting, Jacobian and scaled Jacobian to achieve the
minimum scaled Jacobian higher than $0.5$. We empirically verify the robustness
and efficiency of our method by running the HybridOctree_Hex software on dozens
of complex 3D models without any manual intervention or parameter adjustment.
We provide the HybridOctree_Hex source codes, comprehensive results,
encompassing mesh input/output files and statistical data presented at
https://github.com/CMU-CBML/HybridOctree_Hex.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05986" title="Abstract">arXiv:2401.05986</a> [<a href="/pdf/2401.05986" title="Download PDF">pdf</a>, <a href="/format/2401.05986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LogPTR: Variable-Aware Log Parsing with Pointer Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yifan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+B">Bingxu Chai</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Siyu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ying Li</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Due to the sheer size of software logs, developers rely on automated log
analysis. Log parsing, which parses semi-structured logs into a structured
format, is a prerequisite of automated log analysis. However, existing log
parsers are unsatisfactory when applied in practice because: 1) they ignore
categories of variables, and 2) have poor generalization ability. To address
the limitations of existing approaches, we propose LogPTR, the first end-to-end
variable-aware log parser that can extract the static and dynamic parts in
logs, and further identify the categories of variables. The key of LogPTR is
using pointer network to copy words from the log message. We have performed
extensive experiments on 16 public log datasets and the results show that
LogPTR outperforms state-of-the-art log parsers both on general log parsing
that extracts the log template and variable-aware log parsing that further
identifies the category of variables.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05987" title="Abstract">arXiv:2401.05987</a> [<a href="/pdf/2401.05987" title="Download PDF">pdf</a>, <a href="/ps/2401.05987" title="Download PostScript">ps</a>, <a href="/format/2401.05987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction as a service: a data space for off-site image  reconstruction in magnetic particle imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=von+Gladiss%2C+A">Anselm von Gladiss</a>, 
<a href="/search/cs?searchtype=author&query=Ahmadian%2C+A+S">Amir Shayan Ahmadian</a>, 
<a href="/search/cs?searchtype=author&query=J%C3%BCrjens%2C+J">Jan J&#xfc;rjens</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Magnetic particle imaging (MPI) is an emerging medical imaging modality which
offers a unique combination of high temporal and spatial resolution,
sensitivity and biocompatibility. For system-matrix (SM) based image
reconstruction in MPI, a huge amount of calibration data needs to be acquired
prior to reconstruction in a time-consuming procedure. Conventionally, the data
is recorded on-site inside the scanning device, which significantly limits the
time that the scanning device is available for patient care in a clinical
setting. Due to its size, handling the calibration data can be challenging. To
solve these issues of recording and handling the data, data spaces could be
used, as it has been shown that the calibration data can be measured in
dedicated devices off-site. We propose a data space aimed at improving the
efficiency of SM-based image reconstruction in MPI. The data space consists of
imaging facilities, calibration data providers and reconstruction experts. Its
specifications follow the reference architecture model of international data
spaces (IDS). Use-cases of image reconstruction in MPI are formulated. The
stakeholders and tasks are listed and mapped to the terminology of IDS. The
signal chain in MPI is analysed to identify a minimum information model which
is used by the data space.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05993" title="Abstract">arXiv:2401.05993</a> [<a href="/pdf/2401.05993" title="Download PDF">pdf</a>, <a href="/ps/2401.05993" title="Download PostScript">ps</a>, <a href="/format/2401.05993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Opportunistic Source Synthesis Method for Smart Electromagnetic  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Da+R%C3%B9%2C+P">Pietro Da R&#xf9;</a>, 
<a href="/search/eess?searchtype=author&query=Benoni%2C+A">Arianna Benoni</a>, 
<a href="/search/eess?searchtype=author&query=Salucci%2C+M">Marco Salucci</a>, 
<a href="/search/eess?searchtype=author&query=Rocca%2C+P">Paolo Rocca</a>, 
<a href="/search/eess?searchtype=author&query=Massa%2C+A">Andrea Massa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In the framework of the "Smart ElectroMagnetic Environment" (SEME), an
innovative strategy leveraging Equivalence Source concepts is introduced for
enhancing the performance of large-scale outdoor wireless communication
systems. The proposed Opportunistic Sources Synthesis (OSS) approach is aimed
at unconventionally synthesizing the primary source (i.e., the base transceiver
station (BTS) antenna array), so that the complex scattering phenomena induced
in the surrounding scatterers are profitably exploited to enhance the received
power within user-defined regions of interest (RoIs). To yield a
computationally feasible synthesis process, an innovative
"Embedded-plus-Environment Patterns" (EPEPs) method is introduced. A set of
representative numerical examples, concerned with realistic large-scale outdoor
scenarios, is presented to assess the effectiveness and the efficiency of the
proposed optimization-driven approach for a realistic SEME implementation.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05994" title="Abstract">arXiv:2401.05994</a> [<a href="/pdf/2401.05994" title="Download PDF">pdf</a>, <a href="/format/2401.05994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGARD: A multigrid framework for high-performance, error-controlled data  compression and refactoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Q">Qian Gong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Whitney%2C+B">Ben Whitney</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+X">Xin Liang</a>, 
<a href="/search/cs?searchtype=author&query=Reshniak%2C+V">Viktor Reshniak</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+T">Tania Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaemoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rangarajan%2C+A">Anand Rangarajan</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+L">Lipeng Wan</a>, 
<a href="/search/cs?searchtype=author&query=Vidal%2C+N">Nicolas Vidal</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gainaru%2C+A">Ana Gainaru</a>, 
<a href="/search/cs?searchtype=author&query=Podhorszki%2C+N">Norbert Podhorszki</a>, 
<a href="/search/cs?searchtype=author&query=Archibald%2C+R">Richard Archibald</a>, 
<a href="/search/cs?searchtype=author&query=Ranka%2C+S">Sanjay Ranka</a>, 
<a href="/search/cs?searchtype=author&query=Klasky%2C+S">Scott Klasky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SoftwareX, 24(2023), 101590
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We describe MGARD, a software providing MultiGrid Adaptive Reduction for
floating-point scientific data on structured and unstructured grids. With
exceptional data compression capability and precise error control, MGARD
addresses a wide range of requirements, including storage reduction,
high-performance I/O, and in-situ data analysis. It features a unified
application programming interface (API) that seamlessly operates across diverse
computing architectures. MGARD has been optimized with highly-tuned GPU kernels
and efficient memory and device management mechanisms, ensuring scalable and
rapid operations.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05995" title="Abstract">arXiv:2401.05995</a> [<a href="/pdf/2401.05995" title="Download PDF">pdf</a>, <a href="/format/2401.05995" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-Embedding Convergence Network on Siamese Architecture for Fake  Reviews
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dasgupta%2C+S">Sankarshan Dasgupta</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+J">James Buckley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multimedia (cs.MM)</span>

</div>
<p class="mathjax">In this new digital era, accessibility to real-world events is moving towards
web-based modules. This is mostly visible on e-commerce websites where there is
limited availability of physical verification. With this unforeseen
development, we depend on the verification in the virtual world to influence
our decisions. One of the decision making process is deeply based on review
reading. Reviews play an important part in this transactional process. And
seeking a real review can be very tenuous work for the user. On the other hand,
fake review heavily impacts these transaction records of a product. The article
presents an implementation of a Siamese network for detecting fake reviews. The
fake reviews dataset, consisting of 40K reviews, preprocessed with different
techniques. The cleaned data is passed through embeddings generated by MiniLM
BERT for contextual relationship and Word2Vec for semantic relationship to form
vectors. Further, the embeddings are trained in a Siamese network with LSTM
layers connected to fuzzy logic for decision-making. The results show that fake
reviews can be detected with high accuracy on a siamese network for prediction
and verification.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05998" title="Abstract">arXiv:2401.05998</a> [<a href="/pdf/2401.05998" title="Download PDF">pdf</a>, <a href="/format/2401.05998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combating Adversarial Attacks with Multi-Agent Debate
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chern%2C+S">Steffi Chern</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Andy Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While state-of-the-art language models have achieved impressive results, they
remain susceptible to inference-time adversarial attacks, such as adversarial
prompts generated by red teams <a href="/abs/2209.07858">arXiv:2209.07858</a>. One approach proposed to
improve the general quality of language model generations is multi-agent
debate, where language models self-evaluate through discussion and feedback
<a href="/abs/2305.14325">arXiv:2305.14325</a>. We implement multi-agent debate between current
state-of-the-art language models and evaluate models' susceptibility to red
team attacks in both single- and multi-agent settings. We find that multi-agent
debate can reduce model toxicity when jailbroken or less capable models are
forced to debate with non-jailbroken or more capable models. We also find
marginal improvements through the general usage of multi-agent interactions. We
further perform adversarial prompt content classification via embedding
clustering, and analyze the susceptibility of different models to different
types of attack topics.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05999" title="Abstract">arXiv:2401.05999</a> [<a href="/pdf/2401.05999" title="Download PDF">pdf</a>, <a href="/format/2401.05999" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Mixed-Initiative Co-Creativity in Game Design: A Tutorial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Margarido%2C+S">Solange Margarido</a>, 
<a href="/search/cs?searchtype=author&query=Roque%2C+L">Lic&#xed;nio Roque</a>, 
<a href="/search/cs?searchtype=author&query=Machado%2C+P">Penousal Machado</a>, 
<a href="/search/cs?searchtype=author&query=Martins%2C+P">Pedro Martins</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">In recent years, there has been a growing application of mixed-initiative
co-creative approaches in the creation of video games. The rapid advances in
the capabilities of artificial intelligence (AI) systems further propel
creative collaboration between humans and computational agents. In this
tutorial, we present guidelines for researchers and practitioners to develop
game design tools with a high degree of mixed-initiative co-creativity
(MI-CCy). We begin by reviewing a selection of current works that will serve as
case studies and categorize them by the type of game content they address. We
introduce the MI-CCy Quantifier, a framework that can be used by researchers
and developers to assess co-creative tools on their level of MI-CCy through a
visual scheme of quantifiable criteria scales. We demonstrate the usage of the
MI-CCy Quantifier by applying it to the selected works. This analysis enabled
us to discern prevalent patterns within these tools, as well as features that
contribute to a higher level of MI-CCy. We highlight current gaps in MI-CCy
approaches within game design, which we propose as pivotal aspects to tackle in
the development of forthcoming approaches.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06003" title="Abstract">arXiv:2401.06003</a> [<a href="/pdf/2401.06003" title="Download PDF">pdf</a>, <a href="/format/2401.06003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franke%2C+L">Linus Franke</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+D">Darius R&#xfc;ckert</a>, 
<a href="/search/cs?searchtype=author&query=Fink%2C+L">Laura Fink</a>, 
<a href="/search/cs?searchtype=author&query=Stamminger%2C+M">Marc Stamminger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Point-based radiance field rendering has demonstrated impressive results for
novel view synthesis, offering a compelling blend of rendering quality and
computational efficiency. However, also latest approaches in this domain are
not without their shortcomings. 3D Gaussian Splatting [Kerbl and Kopanas et al.
2023] struggles when tasked with rendering highly detailed scenes, due to
blurring and cloudy artifacts. On the other hand, ADOP [R\"uckert et al. 2022]
can accommodate crisper images, but the neural reconstruction network decreases
performance, it grapples with temporal instability and it is unable to
effectively address large gaps in the point cloud.
<br />In this paper, we present TRIPS (Trilinear Point Splatting), an approach that
combines ideas from both Gaussian Splatting and ADOP. The fundamental concept
behind our novel technique involves rasterizing points into a screen-space
image pyramid, with the selection of the pyramid layer determined by the
projected point size. This approach allows rendering arbitrarily large points
using a single trilinear write. A lightweight neural network is then used to
reconstruct a hole-free image including detail beyond splat resolution.
Importantly, our render pipeline is entirely differentiable, allowing for
automatic optimization of both point sizes and positions.
<br />Our evaluation demonstrate that TRIPS surpasses existing state-of-the-art
methods in terms of rendering quality while maintaining a real-time frame rate
of 60 frames per second on readily available hardware. This performance extends
to challenging scenarios, such as scenes featuring intricate geometry,
expansive landscapes, and auto-exposed footage.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06009" title="Abstract">arXiv:2401.06009</a> [<a href="/pdf/2401.06009" title="Download PDF">pdf</a>, <a href="/ps/2401.06009" title="Download PostScript">ps</a>, <a href="/format/2401.06009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sea ice detection using concurrent multispectral and synthetic aperture  radar imagery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rogers%2C+M+S+J">Martin S J Rogers</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+M">Maria Fox</a>, 
<a href="/search/cs?searchtype=author&query=Fleming%2C+A">Andrew Fleming</a>, 
<a href="/search/cs?searchtype=author&query=van+Zeeland%2C+L">Louisa van Zeeland</a>, 
<a href="/search/cs?searchtype=author&query=Wilkinson%2C+J">Jeremy Wilkinson</a>, 
<a href="/search/cs?searchtype=author&query=Hosking%2C+J+S">J. Scott Hosking</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 10 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Synthetic Aperture Radar (SAR) imagery is the primary data type used for sea
ice mapping due to its spatio-temporal coverage and the ability to detect sea
ice independent of cloud and lighting conditions. Automatic sea ice detection
using SAR imagery remains problematic due to the presence of ambiguous signal
and noise within the image. Conversely, ice and water are easily
distinguishable using multispectral imagery (MSI), but in the polar regions the
ocean's surface is often occluded by cloud or the sun may not appear above the
horizon for many months. To address some of these limitations, this paper
proposes a new tool trained using concurrent multispectral Visible and SAR
imagery for sea Ice Detection (ViSual\_IceD). ViSual\_IceD is a convolution
neural network (CNN) that builds on the classic U-Net architecture by
containing two parallel encoder stages, enabling the fusion and concatenation
of MSI and SAR imagery containing different spatial resolutions. The
performance of ViSual\_IceD is compared with U-Net models trained using
concatenated MSI and SAR imagery as well as models trained exclusively on MSI
or SAR imagery. ViSual\_IceD outperforms the other networks, with a F1 score
1.60\% points higher than the next best network, and results indicate that
ViSual\_IceD is selective in the image type it uses during image segmentation.
Outputs from ViSual\_IceD are compared to sea ice concentration products
derived from the AMSR2 Passive Microwave (PMW) sensor. Results highlight how
ViSual\_IceD is a useful tool to use in conjunction with PMW data, particularly
in coastal regions. As the spatial-temporal coverage of MSI and SAR imagery
continues to increase, ViSual\_IceD provides a new opportunity for robust,
accurate sea ice coverage detection in polar regions.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06010" title="Abstract">arXiv:2401.06010</a> [<a href="/pdf/2401.06010" title="Download PDF">pdf</a>, <a href="/format/2401.06010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention to detail: inter-resolution knowledge distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=del+Amor%2C+R">Roc&#xed;o del Amor</a>, 
<a href="/search/cs?searchtype=author&query=Silva-Rodr%C3%ADguez%2C+J">Julio Silva-Rodr&#xed;guez</a>, 
<a href="/search/cs?searchtype=author&query=Colomer%2C+A">Adri&#xe1;n Colomer</a>, 
<a href="/search/cs?searchtype=author&query=Naranjo%2C+V">Valery Naranjo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> EUSIPCO 2023 - Code available at <a href="https://github.com/cvblab/Mitosis-UTS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The development of computer vision solutions for gigapixel images in digital
pathology is hampered by significant computational limitations due to the large
size of whole slide images. In particular, digitizing biopsies at high
resolutions is a time-consuming process, which is necessary due to the
worsening results from the decrease in image detail. To alleviate this issue,
recent literature has proposed using knowledge distillation to enhance the
model performance at reduced image resolutions. In particular, soft labels and
features extracted at the highest magnification level are distilled into a
model that takes lower-magnification images as input. However, this approach
fails to transfer knowledge about the most discriminative image regions in the
classification process, which may be lost when the resolution is decreased. In
this work, we propose to distill this information by incorporating attention
maps during training. In particular, our formulation leverages saliency maps of
the target class via grad-CAMs, which guides the lower-resolution Student model
to match the Teacher distribution by minimizing the l2 distance between them.
Comprehensive experiments on prostate histology image grading demonstrate that
the proposed approach substantially improves the model performance across
different image resolutions compared to previous literature.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06013" title="Abstract">arXiv:2401.06013</a> [<a href="/pdf/2401.06013" title="Download PDF">pdf</a>, <a href="/format/2401.06013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surgical-DINO: Adapter Learning of Foundation Model for Depth Estimation  in Endoscopic Surgery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beilei%2C+C">Cui Beilei</a>, 
<a href="/search/cs?searchtype=author&query=Mobarakol%2C+I">Islam Mobarakol</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+B">Bai Long</a>, 
<a href="/search/cs?searchtype=author&query=Hongliang%2C+R">Ren Hongliang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IPCAI 2024 (IJCAR Special Issue)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Purpose: Depth estimation in robotic surgery is vital in 3D reconstruction,
surgical navigation and augmented reality visualization. Although the
foundation model exhibits outstanding performance in many vision tasks,
including depth estimation (e.g., DINOv2), recent works observed its
limitations in medical and surgical domain-specific applications. This work
presents a low-ranked adaptation (LoRA) of the foundation model for surgical
depth estimation. Methods: We design a foundation model-based depth estimation
method, referred to as Surgical-DINO, a low-rank adaptation of the DINOv2 for
depth estimation in endoscopic surgery. We build LoRA layers and integrate them
into DINO to adapt with surgery-specific domain knowledge instead of
conventional fine-tuning. During training, we freeze the DINO image encoder,
which shows excellent visual representation capacity, and only optimize the
LoRA layers and depth decoder to integrate features from the surgical scene.
Results: Our model is extensively validated on a MICCAI challenge dataset of
SCARED, which is collected from da Vinci Xi endoscope surgery. We empirically
show that Surgical-DINO significantly outperforms all the state-of-the-art
models in endoscopic depth estimation tasks. The analysis with ablation studies
has shown evidence of the remarkable effect of our LoRA layers and adaptation.
Conclusion: Surgical-DINO shed some light on the successful adaptation of the
foundation models into the surgical domain for depth estimation. There is clear
evidence in the results that zero-shot prediction on pre-trained weights in
computer vision datasets or naive fine-tuning is not sufficient to use the
foundation model in the surgical domain directly. Code is available at
https://github.com/BeileiCui/SurgicalDINO.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06019" title="Abstract">arXiv:2401.06019</a> [<a href="/pdf/2401.06019" title="Download PDF">pdf</a>, <a href="/format/2401.06019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic UAV-based Airport Pavement Inspection Using Mixed Real and  Virtual Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alonso%2C+P">Pablo Alonso</a>, 
<a href="/search/cs?searchtype=author&query=de+Gordoa%2C+J+A+I">Jon Ander I&#xf1;iguez de Gordoa</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+J+D">Juan Diego Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+S">Sara Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=Iriarte%2C+F+J">Francisco Javier Iriarte</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+M">Marcos Nieto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures, published in proceedings of 15th International Conference on Machine Vision (ICMV)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. SPIE 12701, Fifteenth International Conference on Machine
  Vision (ICMV 2022), 1270118
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Runway and taxiway pavements are exposed to high stress during their
projected lifetime, which inevitably leads to a decrease in their condition
over time. To make sure airport pavement condition ensure uninterrupted and
resilient operations, it is of utmost importance to monitor their condition and
conduct regular inspections. UAV-based inspection is recently gaining
importance due to its wide range monitoring capabilities and reduced cost. In
this work, we propose a vision-based approach to automatically identify
pavement distress using images captured by UAVs. The proposed method is based
on Deep Learning (DL) to segment defects in the image. The DL architecture
leverages the low computational capacities of embedded systems in UAVs by using
an optimised implementation of EfficientNet feature extraction and Feature
Pyramid Network segmentation. To deal with the lack of annotated data for
training we have developed a synthetic dataset generation methodology to extend
available distress datasets. We demonstrate that the use of a mixed dataset
composed of synthetic and real training images yields better results when
testing the training models in real application scenarios.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06021" title="Abstract">arXiv:2401.06021</a> [<a href="/pdf/2401.06021" title="Download PDF">pdf</a>, <a href="/format/2401.06021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Driven Parallel Trajectory Optimization in Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Groot%2C+O">Oscar de Groot</a>, 
<a href="/search/cs?searchtype=author&query=Ferranti%2C+L">Laura Ferranti</a>, 
<a href="/search/cs?searchtype=author&query=Gavrila%2C+D">Dariu Gavrila</a>, 
<a href="/search/cs?searchtype=author&query=Alonso-Mora%2C+J">Javier Alonso-Mora</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ground robots navigating in complex, dynamic environments must compute
collision-free trajectories to avoid obstacles safely and efficiently.
Nonconvex optimization is a popular method to compute a trajectory in
real-time. However, these methods often converge to locally optimal solutions
and frequently switch between different local minima, leading to inefficient
and unsafe robot motion. In this work, We propose a novel topology-driven
trajectory optimization strategy for dynamic environments that plans multiple
distinct evasive trajectories to enhance the robot's behavior and efficiency. A
global planner iteratively generates trajectories in distinct homotopy classes.
These trajectories are then optimized by local planners working in parallel.
While each planner shares the same navigation objectives, they are locally
constrained to a specific homotopy class, meaning each local planner attempts a
different evasive maneuver. The robot then executes the feasible trajectory
with the lowest cost in a receding horizon manner. We demonstrate, on a mobile
robot navigating among pedestrians, that our approach leads to faster and safer
trajectories than existing planners.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06030" title="Abstract">arXiv:2401.06030</a> [<a href="/pdf/2401.06030" title="Download PDF">pdf</a>, <a href="/format/2401.06030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can We Trust the Unlabeled Target Data? Towards Backdoor Attack and  Defense on Model Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheng%2C+L">Lijun Sheng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ran He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+T">Tieniu Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Model adaptation tackles the distribution shift problem with a pre-trained
model instead of raw data, becoming a popular paradigm due to its great privacy
protection. Existing methods always assume adapting to a clean target domain,
overlooking the security risks of unlabeled samples. In this paper, we explore
the potential backdoor attacks on model adaptation launched by well-designed
poisoning target data. Concretely, we provide two backdoor triggers with two
poisoning strategies for different prior knowledge owned by attackers. These
attacks achieve a high success rate and keep the normal performance on clean
samples in the test stage. To defend against backdoor embedding, we propose a
plug-and-play method named MixAdapt, combining it with existing adaptation
algorithms. Experiments across commonly used benchmarks and adaptation methods
demonstrate the effectiveness of MixAdapt. We hope this work will shed light on
the safety of learning with unlabeled data.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06031" title="Abstract">arXiv:2401.06031</a> [<a href="/pdf/2401.06031" title="Download PDF">pdf</a>, <a href="/format/2401.06031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GE-AdvGAN: Improving the transferability of adversarial samples by  gradient editing-based adversarial generative model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhiyu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Huaming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiayu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhibo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+K+R">Kim-Kwang Raymond Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIAM International Conference on Data Mining (SDM24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Adversarial generative models, such as Generative Adversarial Networks
(GANs), are widely applied for generating various types of data, i.e., images,
text, and audio. Accordingly, its promising performance has led to the
GAN-based adversarial attack methods in the white-box and black-box attack
scenarios. The importance of transferable black-box attacks lies in their
ability to be effective across different models and settings, more closely
aligning with real-world applications. However, it remains challenging to
retain the performance in terms of transferable adversarial examples for such
methods. Meanwhile, we observe that some enhanced gradient-based transferable
adversarial attack algorithms require prolonged time for adversarial sample
generation. Thus, in this work, we propose a novel algorithm named GE-AdvGAN to
enhance the transferability of adversarial samples whilst improving the
algorithm's efficiency. The main approach is via optimising the training
process of the generator parameters. With the functional and characteristic
similarity analysis, we introduce a novel gradient editing (GE) mechanism and
verify its feasibility in generating transferable samples on various models.
Moreover, by exploring the frequency domain information to determine the
gradient editing direction, GE-AdvGAN can generate highly transferable
adversarial samples while minimizing the execution time in comparison to the
state-of-the-art transferable adversarial attack algorithms. The performance of
GE-AdvGAN is comprehensively evaluated by large-scale experiments on different
datasets, which results demonstrate the superiority of our algorithm. The code
for our algorithm is available at: https://github.com/LMBTough/GE-advGAN
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06034" title="Abstract">arXiv:2401.06034</a> [<a href="/pdf/2401.06034" title="Download PDF">pdf</a>, <a href="/format/2401.06034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinguAlchemy: Fusing Typological and Geographical Elements for Unseen  Language Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adilazuarda%2C+M+F">Muhammad Farid Adilazuarda</a>, 
<a href="/search/cs?searchtype=author&query=Cahyawijaya%2C+S">Samuel Cahyawijaya</a>, 
<a href="/search/cs?searchtype=author&query=Aji%2C+A+F">Alham Fikri Aji</a>, 
<a href="/search/cs?searchtype=author&query=Winata%2C+G+I">Genta Indra Winata</a>, 
<a href="/search/cs?searchtype=author&query=Purwarianti%2C+A">Ayu Purwarianti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Pretrained language models (PLMs) have shown remarkable generalization toward
multiple tasks and languages. Nonetheless, the generalization of PLMs towards
unseen languages is poor, resulting in significantly worse language
performance, or even generating nonsensical responses that are comparable to a
random baseline. This limitation has been a longstanding problem of PLMs
raising the problem of diversity and equal access to language modeling
technology. In this work, we solve this limitation by introducing LinguAlchemy,
a regularization technique that incorporates various aspects of languages
covering typological, geographical, and phylogenetic constraining the resulting
representation of PLMs to better characterize the corresponding linguistics
constraints. LinguAlchemy significantly improves the accuracy performance of
mBERT and XLM-R on unseen languages by ~18% and ~2%, respectively compared to
fully finetuned models and displaying a high degree of unseen language
generalization. We further introduce AlchemyScale and AlchemyTune, extension of
LinguAlchemy which adjusts the linguistic regularization weights automatically,
alleviating the need for hyperparameter search. LinguAlchemy enables better
cross-lingual generalization to unseen languages which is vital for better
inclusivity and accessibility of PLMs.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06035" title="Abstract">arXiv:2401.06035</a> [<a href="/pdf/2401.06035" title="Download PDF">pdf</a>, <a href="/format/2401.06035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAVEN: Rethinking Adversarial Video Generation with Efficient Tri-plane  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+P">Partha Ghosh</a>, 
<a href="/search/cs?searchtype=author&query=Sanyal%2C+S">Soubhik Sanyal</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a novel unconditional video generative model designed to address
long-term spatial and temporal dependencies. To capture these dependencies, our
approach incorporates a hybrid explicit-implicit tri-plane representation
inspired by 3D-aware generative frameworks developed for three-dimensional
object representation and employs a singular latent code to model an entire
video sequence. Individual video frames are then synthesized from an
intermediate tri-plane representation, which itself is derived from the primary
latent code. This novel strategy reduces computational complexity by a factor
of $2$ as measured in FLOPs. Consequently, our approach facilitates the
efficient and temporally coherent generation of videos. Moreover, our joint
frame modeling approach, in contrast to autoregressive methods, mitigates the
generation of visual artifacts. We further enhance the model's capabilities by
integrating an optical flow-based module within our Generative Adversarial
Network (GAN) based generator architecture, thereby compensating for the
constraints imposed by a smaller generator size. As a result, our model is
capable of synthesizing high-fidelity video clips at a resolution of
$256\times256$ pixels, with durations extending to more than $5$ seconds at a
frame rate of 30 fps. The efficacy and versatility of our approach are
empirically validated through qualitative and quantitative assessments across
three different datasets comprising both synthetic and real video clips.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06040" title="Abstract">arXiv:2401.06040</a> [<a href="/pdf/2401.06040" title="Download PDF">pdf</a>, <a href="/format/2401.06040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet-Inspired Multiscale Graph Convolutional Recurrent Network for  Traffic Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+Q">Qipeng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Mallick%2C+T">Tanwi Mallick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Traffic forecasting is the foundation for intelligent transportation systems.
Spatiotemporal graph neural networks have demonstrated state-of-the-art
performance in traffic forecasting. However, these methods do not explicitly
model some of the natural characteristics in traffic data, such as the
multiscale structure that encompasses spatial and temporal variations at
different levels of granularity or scale. To that end, we propose a
Wavelet-Inspired Graph Convolutional Recurrent Network (WavGCRN) which combines
multiscale analysis (MSA)-based method with Deep Learning (DL)-based method. In
WavGCRN, the traffic data is decomposed into time-frequency components with
Discrete Wavelet Transformation (DWT), constructing a multi-stream input
structure; then Graph Convolutional Recurrent networks (GCRNs) are employed as
encoders for each stream, extracting spatiotemporal features in different
scales; and finally the learnable Inversed DWT and GCRN are combined as the
decoder, fusing the information from all streams for traffic metrics
reconstruction and prediction. Furthermore, road-network-informed graphs and
data-driven graph learning are combined to accurately capture spatial
correlation. The proposed method can offer well-defined interpretability,
powerful learning capability, and competitive forecasting performance on
real-world traffic data sets.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06044" title="Abstract">arXiv:2401.06044</a> [<a href="/pdf/2401.06044" title="Download PDF">pdf</a>, <a href="/format/2401.06044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safeguarding DeFi Smart Contracts against Oracle Deviations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+X">Xun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Beillahi%2C+S+M">Sidi Mohamed Beillahi</a>, 
<a href="/search/cs?searchtype=author&query=Minwalla%2C+C">Cyrus Minwalla</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+H">Han Du</a>, 
<a href="/search/cs?searchtype=author&query=Veneris%2C+A">Andreas Veneris</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+F">Fan Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages; extended version of paper accepted in ICSE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper presents OVer, a framework designed to automatically analyze the
behavior of decentralized finance (DeFi) protocols when subjected to a "skewed"
oracle input. OVer firstly performs symbolic analysis on the given contract and
constructs a model of constraints. Then, the framework leverages an SMT solver
to identify parameters that allow its secure operation. Furthermore, guard
statements may be generated for smart contracts that may use the oracle values,
thus effectively preventing oracle manipulation attacks. Empirical results show
that OVer can successfully analyze all 10 benchmarks collected, which encompass
a diverse range of DeFi protocols. Additionally, this paper also illustrates
that current parameters utilized in the majority of benchmarks are inadequate
to ensure safety when confronted with significant oracle deviations.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06047" title="Abstract">arXiv:2401.06047</a> [<a href="/pdf/2401.06047" title="Download PDF">pdf</a>, <a href="/format/2401.06047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Data Distribution from Query Selectivities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+P+K">Pankaj K. Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Raychaudhury%2C+R">Rahul Raychaudhury</a>, 
<a href="/search/cs?searchtype=author&query=Sintos%2C+S">Stavros Sintos</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jun Yang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> ICDT 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Databases (cs.DB)

</div>
<p class="mathjax">We are given a set $\mathcal{Z}=\{(R_1,s_1),\ldots, (R_n,s_n)\}$, where each
$R_i$ is a \emph{range} in $\Re^d$, such as rectangle or ball, and $s_i \in
[0,1]$ denotes its \emph{selectivity}. The goal is to compute a small-size
\emph{discrete data distribution} $\mathcal{D}=\{(q_1,w_1),\ldots,
(q_m,w_m)\}$, where $q_j\in \Re^d$ and $w_j\in [0,1]$ for each $1\leq j\leq m$,
and $\sum_{1\leq j\leq m}w_j= 1$, such that $\mathcal{D}$ is the most
\emph{consistent} with $\mathcal{Z}$, i.e.,
$\mathrm{err}_p(\mathcal{D},\mathcal{Z})=\frac{1}{n}\sum_{i=1}^n\!
\lvert{s_i-\sum_{j=1}^m w_j\cdot 1(q_j\in R_i)}\rvert^p$ is minimized. In a
database setting, $\mathcal{Z}$ corresponds to a workload of range queries over
some table, together with their observed selectivities (i.e., fraction of
tuples returned), and $\mathcal{D}$ can be used as compact model for
approximating the data distribution within the table without accessing the
underlying contents.
<br />In this paper, we obtain both upper and lower bounds for this problem. In
particular, we show that the problem of finding the best data distribution from
selectivity queries is $\mathsf{NP}$-complete. On the positive side, we
describe a Monte Carlo algorithm that constructs, in time
$O((n+\delta^{-d})\delta^{-2}\mathop{\mathrm{polylog}})$, a discrete
distribution $\tilde{\mathcal{D}}$ of size $O(\delta^{-2})$, such that
$\mathrm{err}_p(\tilde{\mathcal{D}},\mathcal{Z})\leq
\min_{\mathcal{D}}\mathrm{err}_p(\mathcal{D},\mathcal{Z})+\delta$ (for
$p=1,2,\infty$) where the minimum is taken over all discrete distributions. We
also establish conditional lower bounds, which strongly indicate the
infeasibility of relative approximations as well as removal of the exponential
dependency on the dimension for additive approximations. This suggests that
significant improvements to our algorithm are unlikely.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06048" title="Abstract">arXiv:2401.06048</a> [<a href="/pdf/2401.06048" title="Download PDF">pdf</a>, <a href="/format/2401.06048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Power of Graph Neural Networks and Feature Augmentation  Strategies to Classify Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guettala%2C+W">Walid Guettala</a>, 
<a href="/search/cs?searchtype=author&query=Guly%C3%A1s%2C+L">L&#xe1;szl&#xf3; Guly&#xe1;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 3 figures, 4 tables, The code for the experiments, together with the datasets used, is available from, <a href="https://github.com/">this https URL</a> walidgeuttala/Synthetic-Benchmark-for-Graph-Classification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper studies four Graph Neural Network architectures (GNNs) for a graph
classification task on a synthetic dataset created using classic generative
models of Network Science. Since the synthetic networks do not contain (node or
edge) features, five different augmentation strategies (artificial feature
types) are applied to nodes. All combinations of the 4 GNNs (GCN with
Hierarchical and Global aggregation, GIN and GATv2) and the 5 feature types
(constant 1, noise, degree, normalized degree and ID -- a vector of the number
of cycles of various lengths) are studied and their performances compared as a
function of the hidden dimension of artificial neural networks used in the
GNNs. The generalisation ability of these models is also analysed using a
second synthetic network dataset (containing networks of different sizes).Our
results point towards the balanced importance of the computational power of the
GNN architecture and the the information level provided by the artificial
features. GNN architectures with higher computational power, like GIN and
GATv2, perform well for most augmentation strategies. On the other hand,
artificial features with higher information content, like ID or degree, not
only consistently outperform other augmentation strategies, but can also help
GNN architectures with lower computational power to achieve good performance.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06052" title="Abstract">arXiv:2401.06052</a> [<a href="/pdf/2401.06052" title="Download PDF">pdf</a>, <a href="/format/2401.06052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast High Dynamic Range Radiance Fields for Dynamic Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanjun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+T">Taoran Yi</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+J">Jiemin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinggang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3DV 2024. Project page: <a href="https://guanjunwu.github.io/HDR-HexPlane">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Neural Radiances Fields (NeRF) and their extensions have shown great success
in representing 3D scenes and synthesizing novel-view images. However, most
NeRF methods take in low-dynamic-range (LDR) images, which may lose details,
especially with nonuniform illumination. Some previous NeRF methods attempt to
introduce high-dynamic-range (HDR) techniques but mainly target static scenes.
To extend HDR NeRF methods to wider applications, we propose a dynamic HDR NeRF
framework, named HDR-HexPlane, which can learn 3D scenes from dynamic 2D images
captured with various exposures. A learnable exposure mapping function is
constructed to obtain adaptive exposure values for each image. Based on the
monotonically increasing prior, a camera response function is designed for
stable learning. With the proposed model, high-quality novel-view images at any
time point can be rendered with any desired exposure. We further construct a
dataset containing multiple dynamic scenes captured with diverse exposures for
evaluation. All the datasets and code are available at
\url{https://guanjunwu.github.io/HDR-HexPlane/}.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06056" title="Abstract">arXiv:2401.06056</a> [<a href="/pdf/2401.06056" title="Download PDF">pdf</a>, <a href="/format/2401.06056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MatSynth: A Modern PBR Materials Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vecchio%2C+G">Giuseppe Vecchio</a>, 
<a href="/search/cs?searchtype=author&query=Deschaintre%2C+V">Valentin Deschaintre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We introduce MatSynth, a dataset of $4,000+$ CC0 ultra-high resolution PBR
materials. Materials are crucial components of virtual relightable assets,
defining the interaction of light at the surface of geometries. Given their
importance, significant research effort was dedicated to their representation,
creation and acquisition. However, in the past 6 years, most research in
material acquisiton or generation relied either on the same unique dataset, or
on company-owned huge library of procedural materials. With this dataset we
propose a significantly larger, more diverse, and higher resolution set of
materials than previously publicly available. We carefully discuss the data
collection process and demonstrate the benefits of this dataset on material
acquisition and generation applications. The complete data further contains
metadata with each material's origin, license, category, tags, creation method
and, when available, descriptions and physical size, as well as 3M+ renderings
of the augmented materials, in 1K, under various environment lightings. The
MatSynth dataset is released through the project page at:
https://www.gvecchio.com/matsynth.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06059" title="Abstract">arXiv:2401.06059</a> [<a href="/pdf/2401.06059" title="Download PDF">pdf</a>, <a href="/format/2401.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Data Contamination for Pre-training Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Minhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K+Z">Ken Ziyu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+M">Ming Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Schaeffer%2C+R">Rylan Schaeffer</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+S">Siru Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiawei Han</a>, 
<a href="/search/cs?searchtype=author&query=Koyejo%2C+S">Sanmi Koyejo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Language models pre-trained on web-scale corpora demonstrate impressive
capabilities on diverse downstream tasks. However, there is increasing concern
whether such capabilities might arise from evaluation datasets being included
in the pre-training corpus -- a phenomenon known as \textit{data contamination}
-- in a manner that artificially increases performance. There has been little
understanding of how this potential contamination might influence LMs'
performance on downstream tasks. In this paper, we explore the impact of data
contamination at the pre-training stage by pre-training a series of GPT-2
models \textit{from scratch}. We highlight the effect of both text
contamination (\textit{i.e.}\ input text of the evaluation samples) and
ground-truth contamination (\textit{i.e.}\ the prompts asked on the input and
the desired outputs) from evaluation data. We also investigate the effects of
repeating contamination for various downstream tasks. Additionally, we examine
the prevailing n-gram-based definitions of contamination within current LLM
reports, pinpointing their limitations and inadequacy. Our findings offer new
insights into data contamination's effects on language model capabilities and
underscore the need for independent, comprehensive contamination assessments in
LLM studies.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06066" title="Abstract">arXiv:2401.06066</a> [<a href="/pdf/2401.06066" title="Download PDF">pdf</a>, <a href="/format/2401.06066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSeekMoE: Towards Ultimate Expert Specialization in  Mixture-of-Experts Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Damai Dai</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+C">Chengqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenggang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R+X">R.X. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Huazuo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiashi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+W">Wangding Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xingkai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Y. Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhenda Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y+K">Y.K. Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Panpan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+F">Fuli Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ruan%2C+C">Chong Ruan</a>, 
<a href="/search/cs?searchtype=author&query=Sui%2C+Z">Zhifang Sui</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+W">Wenfeng Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In the era of large language models, Mixture-of-Experts (MoE) is a promising
architecture for managing computational costs when scaling up model parameters.
However, conventional MoE architectures like GShard, which activate the top-$K$
out of $N$ experts, face challenges in ensuring expert specialization, i.e.
each expert acquires non-overlapping and focused knowledge. In response, we
propose the DeepSeekMoE architecture towards ultimate expert specialization. It
involves two principal strategies: (1) finely segmenting the experts into $mN$
ones and activating $mK$ from them, allowing for a more flexible combination of
activated experts; (2) isolating $K_s$ experts as shared ones, aiming at
capturing common knowledge and mitigating redundancy in routed experts.
Starting from a modest scale with 2B parameters, we demonstrate that
DeepSeekMoE 2B achieves comparable performance with GShard 2.9B, which has 1.5
times the expert parameters and computation. In addition, DeepSeekMoE 2B nearly
approaches the performance of its dense counterpart with the same number of
total parameters, which set the upper bound of MoE models. Subsequently, we
scale up DeepSeekMoE to 16B parameters and show that it achieves comparable
performance with LLaMA2 7B, with only about 40% of computations. Further, our
preliminary efforts to scale up DeepSeekMoE to 145B parameters consistently
validate its substantial advantages over the GShard architecture, and show its
performance comparable with DeepSeek 67B, using only 28.5% (maybe even 18.2%)
of computations.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06071" title="Abstract">arXiv:2401.06071</a> [<a href="/pdf/2401.06071" title="Download PDF">pdf</a>, <a href="/format/2401.06071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEGO:Language Enhanced Multi-modal Grounding Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhaowei Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+H">Hang Song</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqing Cai</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Q">Qi Qi</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+R">Ran Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+J">Junting Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zefeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+V+T">Van Tu Vu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhida Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Multi-modal large language models have demonstrated impressive performance
across various tasks in different modalities. However, existing multi-modal
models primarily emphasize capturing global information within each modality
while neglecting the importance of perceiving local information across
modalities. Consequently, these models lack the ability to effectively
understand the fine-grained details of input data, limiting their performance
in tasks that require a more nuanced understanding. To address this limitation,
there is a compelling need to develop models that enable fine-grained
understanding across multiple modalities, thereby enhancing their applicability
to a wide range of tasks. In this paper, we propose LEGO, a language enhanced
multi-modal grounding model. Beyond capturing global information like other
multi-modal models, our proposed model excels at tasks demanding a detailed
understanding of local information within the input. It demonstrates precise
identification and localization of specific regions in images or moments in
videos. To achieve this objective, we design a diversified dataset construction
pipeline, resulting in a multi-modal, multi-granularity dataset for model
training. The code, dataset, and demo of our model can be found at https:
//github.com/lzw-lzw/LEGO.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06072" title="Abstract">arXiv:2401.06072</a> [<a href="/pdf/2401.06072" title="Download PDF">pdf</a>, <a href="/format/2401.06072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain of History: Learning and Forecasting with LLMs for Temporal  Knowledge Graph Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Ruilin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+T">Tianle Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoling Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junzhe Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zicheng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Temporal Knowledge Graph Completion (TKGC) is a challenging task of
predicting missing event links at future timestamps by leveraging established
temporal structural knowledge. Given the formidable generative capabilities
inherent in LLMs (LLMs), this paper proposes a novel approach to conceptualize
temporal link prediction as an event generation task within the context of a
historical event chain. We employ efficient fine-tuning methods to make LLMs
adapt to specific graph textual information and patterns discovered in temporal
timelines. Furthermore, we introduce structure-based historical data
augmentation and the integration of reverse knowledge to emphasize LLMs'
awareness of structural information, thereby enhancing their reasoning
capabilities. We conduct thorough experiments on multiple widely used datasets
and find that our fine-tuned model outperforms existing embedding-based models
on multiple metrics, achieving SOTA results. We also carry out sufficient
ablation experiments to explore the key influencing factors when LLMs perform
structured temporal knowledge inference tasks.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06080" title="Abstract">arXiv:2401.06080</a> [<a href="/pdf/2401.06080" title="Download PDF">pdf</a>, <a href="/format/2401.06080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secrets of RLHF in Large Language Models Part II: Reward Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binghai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Caishuang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+W">Wei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Senjie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chenyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Songyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Nuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+T">Tao Ji</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+L">Lixing Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zuxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Reinforcement Learning from Human Feedback (RLHF) has become a crucial
technology for aligning language models with human values and intentions,
enabling models to produce more helpful and harmless responses. Reward models
are trained as proxies for human preferences to drive reinforcement learning
optimization. While reward models are often considered central to achieving
high performance, they face the following challenges in practical applications:
(1) Incorrect and ambiguous preference pairs in the dataset may hinder the
reward model from accurately capturing human intent. (2) Reward models trained
on data from a specific distribution often struggle to generalize to examples
outside that distribution and are not suitable for iterative RLHF training.
<br />In this report, we attempt to address these two issues. (1) From a data
perspective, we propose a method to measure the strength of preferences within
the data, based on a voting mechanism of multiple reward models. Experimental
results confirm that data with varying preference strengths have different
impacts on reward model performance. We introduce a series of novel methods to
mitigate the influence of incorrect and ambiguous preferences in the dataset
and fully leverage high-quality preference data. (2) From an algorithmic
standpoint, we introduce contrastive learning to enhance the ability of reward
models to distinguish between chosen and rejected responses, thereby improving
model generalization. Furthermore, we employ meta-learning to enable the reward
model to maintain the ability to differentiate subtle differences in
out-of-distribution samples, and this approach can be utilized for iterative
RLHF optimization.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06081" title="Abstract">arXiv:2401.06081</a> [<a href="/pdf/2401.06081" title="Download PDF">pdf</a>, <a href="/format/2401.06081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Large Language Models via Fine-grained Reinforcement Learning  with Minimum Editing Constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhipeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">Junchen Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fuzheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Di Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, working in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Reinforcement learning (RL) has been widely used in training large language
models~(LLMs) for preventing unexpected outputs, \eg reducing harmfulness and
errors. However, existing RL methods mostly adopt the instance-level reward,
which is unable to provide fine-grained supervision for complex reasoning
tasks, and can not focus on the few key tokens that lead to the incorrectness.
To address it, we propose a new RL method named \textbf{RLMEC} that
incorporates a generative model as the reward model, which is trained by the
erroneous solution rewriting task under the minimum editing constraint, and can
produce token-level rewards for RL training. Based on the generative reward
model, we design the token-level RL objective for training and an
imitation-based regularization for stabilizing RL process. And the both
objectives focus on the learning of the key tokens for the erroneous solution,
reducing the effect of other unimportant tokens. The experiment results on
mathematical tasks and question-answering tasks have demonstrated the
effectiveness of our approach. Our code and data are available at
\url{https://github.com/RUCAIBox/RLMEC}.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06086" title="Abstract">arXiv:2401.06086</a> [<a href="/pdf/2401.06086" title="Download PDF">pdf</a>, <a href="/format/2401.06086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XGBoost Learning of Dynamic Wager Placement for In-Play Betting on an  Agent-Based Model of a Sports Betting Exchange
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Terawong%2C+C">Chawin Terawong</a>, 
<a href="/search/cs?searchtype=author&query=Cliff%2C+D">Dave Cliff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation/publication at the 16th International Conference on Agents and Artificial Intelligence (ICAART2024); Rome, Italy, 24-26 February 2024. 13 pages; 18 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We present first results from the use of XGBoost, a highly effective machine
learning (ML) method, within the Bristol Betting Exchange (BBE), an open-source
agent-based model (ABM) designed to simulate a contemporary sports-betting
exchange with in-play betting during track-racing events such as horse races.
We use the BBE ABM and its array of minimally-simple bettor-agents as a
synthetic data generator which feeds into our XGBoost ML system, with the
intention that XGBoost discovers profitable dynamic betting strategies by
learning from the more profitable bets made by the BBE bettor-agents. After
this XGBoost training, which results in one or more decision trees, a
bettor-agent with a betting strategy determined by the XGBoost-learned decision
tree(s) is added to the BBE ABM and made to bet on a sequence of races under
various conditions and betting-market scenarios, with profitability serving as
the primary metric of comparison and evaluation. Our initial findings presented
here show that XGBoost trained in this way can indeed learn profitable betting
strategies, and can generalise to learn strategies that outperform each of the
set of strategies used for creation of the training data. To foster further
research and enhancements, the complete version of our extended BBE, including
the XGBoost integration, has been made freely available as an open-source
release on GitHub.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06088" title="Abstract">arXiv:2401.06088</a> [<a href="/pdf/2401.06088" title="Download PDF">pdf</a>, <a href="/format/2401.06088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autocompletion of Chief Complaints in the Electronic Health Records  using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+K+M+S">K M Sajjadul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Nipu%2C+A+S">Ayesha Siddika Nipu</a>, 
<a href="/search/cs?searchtype=author&query=Madiraju%2C+P">Praveen Madiraju</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+P">Priya Deshpande</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE BigData 2023 - Sorrento, Italy. 10 Pages, 4 Figures, 5 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Chief Complaint (CC) is a crucial component of a patient's medical record
as it describes the main reason or concern for seeking medical care. It
provides critical information for healthcare providers to make informed
decisions about patient care. However, documenting CCs can be time-consuming
for healthcare providers, especially in busy emergency departments. To address
this issue, an autocompletion tool that suggests accurate and well-formatted
phrases or sentences for clinical notes can be a valuable resource for triage
nurses. In this study, we utilized text generation techniques to develop
machine learning models using CC data. In our proposed work, we train a Long
Short-Term Memory (LSTM) model and fine-tune three different variants of
Biomedical Generative Pretrained Transformers (BioGPT), namely
microsoft/biogpt, microsoft/BioGPT-Large, and microsoft/BioGPT-Large-PubMedQA.
Additionally, we tune a prompt by incorporating exemplar CC sentences,
utilizing the OpenAI API of GPT-4. We evaluate the models' performance based on
the perplexity score, modified BERTScore, and cosine similarity score. The
results show that BioGPT-Large exhibits superior performance compared to the
other models. It consistently achieves a remarkably low perplexity score of
1.65 when generating CC, whereas the baseline LSTM model achieves the best
perplexity score of 170. Further, we evaluate and assess the proposed models'
performance and the outcome of GPT-4.0. Our study demonstrates that utilizing
LLMs such as BioGPT, leads to the development of an effective autocompletion
tool for generating CC documentation in healthcare settings.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06089" title="Abstract">arXiv:2401.06089</a> [<a href="/pdf/2401.06089" title="Download PDF">pdf</a>, <a href="/format/2401.06089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PANDORA: A Parallel Dendrogram Construction Algorithm for Single Linkage  Clustering on GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sao%2C+P">Piyush Sao</a>, 
<a href="/search/cs?searchtype=author&query=Prokopenko%2C+A">Andrey Prokopenko</a>, 
<a href="/search/cs?searchtype=author&query=Lebrun-Grandi%C3%A9%2C+D">Damien Lebrun-Grandi&#xe9;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This paper presents \pandora, a novel parallel algorithm for efficiently
constructing dendrograms for single-linkage hierarchical clustering, including
\hdbscan. Traditional dendrogram construction methods from a minimum spanning
tree (MST), such as agglomerative or divisive techniques, often fail to
efficiently parallelize, especially with skewed dendrograms common in
real-world data.
<br />\pandora addresses these challenges through a unique recursive tree
contraction method, which simplifies the tree for initial dendrogram
construction and then progressively reconstructs the complete dendrogram. This
process makes \pandora asymptotically work-optimal, independent of dendrogram
skewness. All steps in \pandora are fully parallel and suitable for massively
threaded accelerators such as GPUs.
<br />Our implementation is written in Kokkos, providing support for both CPUs and
multi-vendor GPUs (e.g., Nvidia, AMD). The multithreaded version of \pandora is
2.2$\times$ faster than the current best-multithreaded implementation, while
the GPU \pandora implementation achieved 6-20$\times$ on \amdgpu and
10-37$\times$ on \nvidiagpu speed-up over multithreaded \pandora. These
advancements lead to up to a 6-fold speedup for \hdbscan on GPUs over the
current best, which only offload MST construction to GPUs and perform
multithreaded dendrogram construction.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06091" title="Abstract">arXiv:2401.06091</a> [<a href="/pdf/2401.06091" title="Download PDF">pdf</a>, <a href="/format/2401.06091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Closer Look at AUROC and AUPRC under Class Imbalance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McDermott%2C+M+B+A">Matthew B. A. McDermott</a> (1), 
<a href="/search/cs?searchtype=author&query=Hansen%2C+L+H">Lasse Hyldig Hansen</a> (2), 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoran Zhang</a> (3), 
<a href="/search/cs?searchtype=author&query=Angelotti%2C+G">Giovanni Angelotti</a> (4), 
<a href="/search/cs?searchtype=author&query=Gallifant%2C+J">Jack Gallifant</a> (3) ((1) Harvard Medical School, (2) Aarhus University, (3) Massachusetts Institute of Technology, (4) IRCCS Humanitas Research Hospital)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">In machine learning (ML), a widespread adage is that the area under the
precision-recall curve (AUPRC) is a superior metric for model comparison to the
area under the receiver operating characteristic (AUROC) for binary
classification tasks with class imbalance. This paper challenges this notion
through novel mathematical analysis, illustrating that AUROC and AUPRC can be
concisely related in probabilistic terms. We demonstrate that AUPRC, contrary
to popular belief, is not superior in cases of class imbalance and might even
be a harmful metric, given its inclination to unduly favor model improvements
in subpopulations with more frequent positive labels. This bias can
inadvertently heighten algorithmic disparities. Prompted by these insights, a
thorough review of existing ML literature was conducted, utilizing large
language models to analyze over 1.5 million papers from arXiv. Our
investigation focused on the prevalence and substantiation of the purported
AUPRC superiority. The results expose a significant deficit in empirical
backing and a trend of misattributions that have fuelled the widespread
acceptance of AUPRC's supposed advantages. Our findings represent a dual
contribution: a significant technical advancement in understanding metric
behaviors and a stark warning about unchecked assumptions in the ML community.
All experiments are accessible at
https://github.com/mmcdermott/AUC_is_all_you_need.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06102" title="Abstract">arXiv:2401.06102</a> [<a href="/pdf/2401.06102" title="Download PDF">pdf</a>, <a href="/format/2401.06102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Patchscope: A Unifying Framework for Inspecting Hidden Representations  of Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghandeharioun%2C+A">Asma Ghandeharioun</a>, 
<a href="/search/cs?searchtype=author&query=Caciularu%2C+A">Avi Caciularu</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+A">Adam Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Dixon%2C+L">Lucas Dixon</a>, 
<a href="/search/cs?searchtype=author&query=Geva%2C+M">Mor Geva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Inspecting the information encoded in hidden representations of large
language models (LLMs) can explain models' behavior and verify their alignment
with human values. Given the capabilities of LLMs in generating
human-understandable text, we propose leveraging the model itself to explain
its internal representations in natural language. We introduce a framework
called Patchscopes and show how it can be used to answer a wide range of
research questions about an LLM's computation. We show that prior
interpretability methods based on projecting representations into the
vocabulary space and intervening on the LLM computation, can be viewed as
special instances of this framework. Moreover, several of their shortcomings
such as failure in inspecting early layers or lack of expressivity can be
mitigated by a Patchscope. Beyond unifying prior inspection techniques,
Patchscopes also opens up new possibilities such as using a more capable model
to explain the representations of a smaller model, and unlocks new applications
such as self-correction in multi-hop reasoning.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06104" title="Abstract">arXiv:2401.06104</a> [<a href="/pdf/2401.06104" title="Download PDF">pdf</a>, <a href="/format/2401.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformers are Multi-State RNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oren%2C+M">Matanel Oren</a>, 
<a href="/search/cs?searchtype=author&query=Hassid%2C+M">Michael Hassid</a>, 
<a href="/search/cs?searchtype=author&query=Adi%2C+Y">Yossi Adi</a>, 
<a href="/search/cs?searchtype=author&query=Schwartz%2C+R">Roy Schwartz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Transformers are considered conceptually different compared to the previous
generation of state-of-the-art NLP models - recurrent neural networks (RNNs).
In this work, we demonstrate that decoder-only transformers can in fact be
conceptualized as infinite multi-state RNNs - an RNN variant with unlimited
hidden state size. We further show that pretrained transformers can be
converted into $\textit{finite}$ multi-state RNNs by fixing the size of their
hidden state. We observe that several existing transformers cache compression
techniques can be framed as such conversion policies, and introduce a novel
policy, TOVA, which is simpler compared to these policies. Our experiments with
several long range tasks indicate that TOVA outperforms all other baseline
policies, while being nearly on par with the full (infinite) model, and using
in some cases only $\frac{1}{8}$ of the original cache size. Our results
indicate that transformer decoder LLMs often behave in practice as RNNs. They
also lay out the option of mitigating one of their most painful computational
bottlenecks - the size of their cache memory. We publicly release our code at
https://github.com/schwartz-lab-NLP/TOVA.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06105" title="Abstract">arXiv:2401.06105</a> [<a href="/pdf/2401.06105" title="Download PDF">pdf</a>, <a href="/format/2401.06105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PALP: Prompt Aligned Personalization of Text-to-Image Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arar%2C+M">Moab Arar</a>, 
<a href="/search/cs?searchtype=author&query=Voynov%2C+A">Andrey Voynov</a>, 
<a href="/search/cs?searchtype=author&query=Hertz%2C+A">Amir Hertz</a>, 
<a href="/search/cs?searchtype=author&query=Avrahami%2C+O">Omri Avrahami</a>, 
<a href="/search/cs?searchtype=author&query=Fruchter%2C+S">Shlomi Fruchter</a>, 
<a href="/search/cs?searchtype=author&query=Pritch%2C+Y">Yael Pritch</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>, 
<a href="/search/cs?searchtype=author&query=Shamir%2C+A">Ariel Shamir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page available at <a href="https://prompt-aligned.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Content creators often aim to create personalized images using personal
subjects that go beyond the capabilities of conventional text-to-image models.
Additionally, they may want the resulting image to encompass a specific
location, style, ambiance, and more. Existing personalization methods may
compromise personalization ability or the alignment to complex textual prompts.
This trade-off can impede the fulfillment of user prompts and subject fidelity.
We propose a new approach focusing on personalization methods for a
\emph{single} prompt to address this issue. We term our approach prompt-aligned
personalization. While this may seem restrictive, our method excels in
improving text alignment, enabling the creation of images with complex and
intricate prompts, which may pose a challenge for current techniques. In
particular, our method keeps the personalized model aligned with a target
prompt using an additional score distillation sampling term. We demonstrate the
versatility of our method in multi- and single-shot settings and further show
that it can compose multiple subjects or use inspiration from reference images,
such as artworks. We compare our approach quantitatively and qualitatively with
existing baselines and state-of-the-art techniques.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06109" title="Abstract">arXiv:2401.06109</a> [<a href="/pdf/2401.06109" title="Download PDF">pdf</a>, <a href="/ps/2401.06109" title="Download PostScript">ps</a>, <a href="/format/2401.06109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holey graphs: very large Betti numbers are testable
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szab%C3%B3%2C+D">D&#xe1;niel Szab&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=Apers%2C+S">Simon Apers</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 0 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We show that the graph property of having a (very) large $k$-th Betti number
$\beta_k$ for constant $k$ is testable with a constant number of queries in the
dense graph model. More specifically, we consider a clique complex defined by
an underlying graph and prove that for any $\varepsilon&gt;0$, there exists
$\delta(\varepsilon,k)&gt;0$ such that testing whether $\beta_k \geq (1-\delta)
d_k$ for $\delta \leq \delta(\varepsilon,k)$ reduces to tolerantly testing
$(k+2)$-clique-freeness, which is known to be testable. This complements a
result by Elek (2010) showing that Betti numbers are testable in the
bounded-degree model. Our result combines the Euler characteristic, matroid
theory and the graph removal lemma.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06112" title="Abstract">arXiv:2401.06112</a> [<a href="/pdf/2401.06112" title="Download PDF">pdf</a>, <a href="/format/2401.06112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Axis Tour: Word Tour Determines the Order of Axes in ICA-transformed  Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamagiwa%2C+H">Hiroaki Yamagiwa</a>, 
<a href="/search/cs?searchtype=author&query=Takase%2C+Y">Yusuke Takase</a>, 
<a href="/search/cs?searchtype=author&query=Shimodaira%2C+H">Hidetoshi Shimodaira</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Word embedding is one of the most important components in natural language
processing, but interpreting high-dimensional embeddings remains a challenging
problem. To address this problem, Independent Component Analysis (ICA) is
identified as an effective solution. ICA-transformed word embeddings reveal
interpretable semantic axes; however, the order of these axes are arbitrary. In
this study, we focus on this property and propose a novel method, Axis Tour,
which optimizes the order of the axes. Inspired by Word Tour, a one-dimensional
word embedding method, we aim to improve the clarity of the word embedding
space by maximizing the semantic continuity of the axes. Furthermore, we show
through experiments on downstream tasks that Axis Tour constructs better
low-dimensional embeddings compared to both PCA and ICA.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06116" title="Abstract">arXiv:2401.06116</a> [<a href="/pdf/2401.06116" title="Download PDF">pdf</a>, <a href="/format/2401.06116" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Shadow Casting for Neural Characters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bolanos%2C+L">Luis Bolanos</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+S">Shih-Yang Su</a>, 
<a href="/search/cs?searchtype=author&query=Rhodin%2C+H">Helge Rhodin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural character models can now reconstruct detailed geometry and texture
from video, but they lack explicit shadows and shading, leading to artifacts
when generating novel views and poses or during relighting. It is particularly
difficult to include shadows as they are a global effect and the required
casting of secondary rays is costly. We propose a new shadow model using a
Gaussian density proxy that replaces sampling with a simple analytic formula.
It supports dynamic motion and is tailored for shadow computation, thereby
avoiding the affine projection approximation and sorting required by the
closely related Gaussian splatting. Combined with a deferred neural rendering
model, our Gaussian shadows enable Lambertian shading and shadow casting with
minimal overhead. We demonstrate improved reconstructions, with better
separation of albedo, shading, and shadows in challenging outdoor scenes with
direct sun light and hard shadows. Our method is able to optimize the light
direction without any input from the user. As a result, novel poses have fewer
shadow artifacts and relighting in novel scenes is more realistic compared to
the state-of-the-art methods, providing new ways to pose neural characters in
novel environments, increasing their applicability.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06118" title="Abstract">arXiv:2401.06118</a> [<a href="/pdf/2401.06118" title="Download PDF">pdf</a>, <a href="/format/2401.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme Compression of Large Language Models via Additive Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egiazarian%2C+V">Vage Egiazarian</a>, 
<a href="/search/cs?searchtype=author&query=Panferov%2C+A">Andrei Panferov</a>, 
<a href="/search/cs?searchtype=author&query=Kuznedelev%2C+D">Denis Kuznedelev</a>, 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Babenko%2C+A">Artem Babenko</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The emergence of accurate open large language models (LLMs) has led to a race
towards quantization techniques for such models enabling execution on end-user
devices. In this paper, we revisit the problem of "extreme" LLM
compression--defined as targeting extremely low bit counts, such as 2 to 3 bits
per parameter, from the point of view of classic methods in Multi-Codebook
Quantization (MCQ). Our work builds on top of Additive Quantization, a classic
algorithm from the MCQ family, and adapts it to the quantization of language
models. The resulting algorithm advances the state-of-the-art in LLM
compression, outperforming all recently-proposed techniques in terms of
accuracy at a given compression budget. For instance, when compressing Llama 2
models to 2 bits per parameter, our algorithm quantizes the 7B model to 6.93
perplexity (a 1.29 improvement relative to the best prior work, and 1.81 points
from FP16), the 13B model to 5.70 perplexity (a .36 improvement) and the 70B
model to 3.94 perplexity (a .22 improvement) on WikiText2. We release our
implementation of Additive Quantization for Language Models AQLM as a baseline
to facilitate future research in LLM quantization.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06121" title="Abstract">arXiv:2401.06121</a> [<a href="/pdf/2401.06121" title="Download PDF">pdf</a>, <a href="/format/2401.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TOFU: A Task of Fictitious Unlearning for LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maini%2C+P">Pratyush Maini</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhili Feng</a>, 
<a href="/search/cs?searchtype=author&query=Schwarzschild%2C+A">Avi Schwarzschild</a>, 
<a href="/search/cs?searchtype=author&query=Lipton%2C+Z+C">Zachary C. Lipton</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://locuslab.github.io/tofu/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models trained on massive corpora of data from the web can
memorize and reproduce sensitive or private data raising both legal and ethical
concerns. Unlearning, or tuning models to forget information present in their
training data, provides us with a way to protect private data after training.
Although several methods exist for such unlearning, it is unclear to what
extent they result in models equivalent to those where the data to be forgotten
was never learned in the first place. To address this challenge, we present
TOFU, a Task of Fictitious Unlearning, as a benchmark aimed at helping deepen
our understanding of unlearning. We offer a dataset of 200 diverse synthetic
author profiles, each consisting of 20 question-answer pairs, and a subset of
these profiles called the forget set that serves as the target for unlearning.
We compile a suite of metrics that work together to provide a holistic picture
of unlearning efficacy. Finally, we provide a set of baseline results from
existing unlearning algorithms. Importantly, none of the baselines we consider
show effective unlearning motivating continued efforts to develop approaches
for unlearning that effectively tune models so that they truly behave as if
they were never trained on the forget data at all.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06122" title="Abstract">arXiv:2401.06122</a> [<a href="/pdf/2401.06122" title="Download PDF">pdf</a>, <a href="/format/2401.06122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manipulating Feature Visualizations with Gradient Slingshots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bareeva%2C+D">Dilyara Bareeva</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6hne%2C+M+M+-">Marina M.-C. H&#xf6;hne</a>, 
<a href="/search/cs?searchtype=author&query=Warnecke%2C+A">Alexander Warnecke</a>, 
<a href="/search/cs?searchtype=author&query=Pirch%2C+L">Lukas Pirch</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+K">Klaus-Robert M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Rieck%2C+K">Konrad Rieck</a>, 
<a href="/search/cs?searchtype=author&query=Bykov%2C+K">Kirill Bykov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Deep Neural Networks (DNNs) are capable of learning complex and versatile
representations, however, the semantic nature of the learned concepts remains
unknown. A common method used to explain the concepts learned by DNNs is
Activation Maximization (AM), which generates a synthetic input signal that
maximally activates a particular neuron in the network. In this paper, we
investigate the vulnerability of this approach to adversarial model
manipulations and introduce a novel method for manipulating feature
visualization without altering the model architecture or significantly
impacting the model's decision-making process. We evaluate the effectiveness of
our method on several neural network models and demonstrate its capabilities to
hide the functionality of specific neurons by masking the original explanations
of neurons with chosen target explanations during model auditing. As a remedy,
we propose a protective measure against such manipulations and provide
quantitative evidence which substantiates our findings.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06125" title="Abstract">arXiv:2401.06125</a> [<a href="/pdf/2401.06125" title="Download PDF">pdf</a>, <a href="/ps/2401.06125" title="Download PostScript">ps</a>, <a href="/format/2401.06125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Capacity Outer Bound for Private Quadratic Monomial Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%A6hli%2C+K+M">Karen M. D&#xe6;hli</a>, 
<a href="/search/cs?searchtype=author&query=Obead%2C+S+A">Sarah A Obead</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Yin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rosnes%2C+E">Eirik Rosnes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In private computation, a user wishes to retrieve a function evaluation of
messages stored on a set of databases without revealing the function's identity
to the databases. Obead \emph{et al.} introduced a capacity outer bound for
private nonlinear computation, dependent on the order of the candidate
functions. Focusing on private \emph{quadratic monomial} computation, we
propose three methods for ordering candidate functions: a graph edge-coloring
method, a graph-distance method, and an entropy-based greedy method. We
confirm, via an exhaustive search, that all three methods yield an optimal
ordering for $f &lt; 6$ messages. For $6 \leq f \leq 12$ messages, we numerically
evaluate the performance of the proposed methods compared with a directed
random search. For almost all scenarios considered, the entropy-based greedy
method gives the smallest gap to the best-found ordering.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06126" title="Abstract">arXiv:2401.06126</a> [<a href="/pdf/2401.06126" title="Download PDF">pdf</a>, <a href="/format/2401.06126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dubbing for Everyone: Data-Efficient Visual Dubbing using Neural  Rendering Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saunders%2C+J">Jack Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V">Vinay Namboodiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Visual dubbing is the process of generating lip motions of an actor in a
video to synchronise with given audio. Recent advances have made progress
towards this goal but have not been able to produce an approach suitable for
mass adoption. Existing methods are split into either person-generic or
person-specific models. Person-specific models produce results almost
indistinguishable from reality but rely on long training times using large
single-person datasets. Person-generic works have allowed for the visual
dubbing of any video to any audio without further training, but these fail to
capture the person-specific nuances and often suffer from visual artefacts. Our
method, based on data-efficient neural rendering priors, overcomes the
limitations of existing approaches. Our pipeline consists of learning a
deferred neural rendering prior network and actor-specific adaptation using
neural textures. This method allows for $\textbf{high-quality visual dubbing
with just a few seconds of data}$, that enables video dubbing for any actor -
from A-list celebrities to background actors. We show that we achieve
state-of-the-art in terms of $\textbf{visual quality}$ and
$\textbf{recognisability}$ both quantitatively, and qualitatively through two
user studies. Our prior learning and adaptation method $\textbf{generalises to
limited data}$ better and is more $\textbf{scalable}$ than existing
person-specific models. Our experiments on real-world, limited data scenarios
find that our model is preferred over all others. The project page may be found
at https://dubbingforeveryone.github.io/
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06127" title="Abstract">arXiv:2401.06127</a> [<a href="/pdf/2401.06127" title="Download PDF">pdf</a>, <a href="/format/2401.06127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> E$^{2}$GAN: Efficient Training of Efficient GANs for Image-to-Image  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yifan Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Z">Zheng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Q">Qing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Idelbayev%2C+Y">Yerlan Idelbayev</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zharkov%2C+A">Andrey Zharkov</a>, 
<a href="/search/cs?searchtype=author&query=Aberman%2C+K">Kfir Aberman</a>, 
<a href="/search/cs?searchtype=author&query=Tulyakov%2C+S">Sergey Tulyakov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanzhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jian Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">One highly promising direction for enabling flexible real-time on-device
image editing is utilizing data distillation by leveraging large-scale
text-to-image diffusion models, such as Stable Diffusion, to generate paired
datasets used for training generative adversarial networks (GANs). This
approach notably alleviates the stringent requirements typically imposed by
high-end commercial GPUs for performing image editing with diffusion models.
However, unlike text-to-image diffusion models, each distilled GAN is
specialized for a specific image editing task, necessitating costly training
efforts to obtain models for various concepts. In this work, we introduce and
address a novel research direction: can the process of distilling GANs from
diffusion models be made significantly more efficient? To achieve this goal, we
propose a series of innovative techniques. First, we construct a base GAN model
with generalized features, adaptable to different concepts through fine-tuning,
eliminating the need for training from scratch. Second, we identify crucial
layers within the base GAN model and employ Low-Rank Adaptation (LoRA) with a
simple yet effective rank search process, rather than fine-tuning the entire
base model. Third, we investigate the minimal amount of data necessary for
fine-tuning, further reducing the overall training time. Extensive experiments
show that we can efficiently empower GANs with the ability to perform real-time
high-quality image editing on mobile devices with remarkable reduced training
cost and storage for each concept.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06129" title="Abstract">arXiv:2401.06129</a> [<a href="/pdf/2401.06129" title="Download PDF">pdf</a>, <a href="/format/2401.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Vision-Language Models on Millions of Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yue Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Long Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xingyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jialin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+C">Chun-Te Chu</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+H">Hui Miao</a>, 
<a href="/search/cs?searchtype=author&query=Schroff%2C+F">Florian Schroff</a>, 
<a href="/search/cs?searchtype=author&query=Adam%2C+H">Hartwig Adam</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Ting Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>, 
<a href="/search/cs?searchtype=author&query=Kr%C3%A4henb%C3%BChl%2C+P">Philipp Kr&#xe4;henb&#xfc;hl</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Liangzhe Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Tech report. Project page: <a href="https://zhaoyue-zephyrus.github.io/video-instruction-tuning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent advance in vision-language models is largely attributed to the
abundance of image-text data. We aim to replicate this success for
video-language models, but there simply is not enough human-curated video-text
data available. We thus resort to fine-tuning a video-language model from a
strong image-language baseline with synthesized instructional data. The
resulting video-language model is then used to auto-label millions of videos to
generate high-quality captions. We show the adapted video-language model
performs well on a wide range of video-language benchmarks. For instance, it
surpasses the best prior result on open-ended NExT-QA by 2.8%. Besides, our
model generates detailed descriptions for previously unseen videos, which
provide better textual supervision than existing methods. Experiments show that
a video-language dual-encoder model contrastively trained on these
auto-generated captions is 3.8% better than the strongest baseline that also
leverages vision-language models. Our best model outperforms state-of-the-art
methods on MSR-VTT zero-shot text-to-video retrieval by 6%.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Fri, 12 Jan 24</h3>
<dl>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05337" title="Abstract">arXiv:2401.05337</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.05337" title="Download PDF">pdf</a>, <a href="/format/2401.05337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Linear Signal: An Unsupervised Machine Learning Framework to  Optimize PnL with Linear Signals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Renucci%2C+P">Pierre Renucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code of the model and the empiric strategy are available on my GitHub: Cnernc/OptimalLinearSignal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study presents an unsupervised machine learning approach for optimizing
Profit and Loss (PnL) in quantitative finance. Our algorithm, akin to an
unsupervised variant of linear regression, maximizes the Sharpe Ratio of PnL
generated from signals constructed linearly from exogenous variables. The
methodology employs a linear relationship between exogenous variables and the
trading signal, with the objective of maximizing the Sharpe Ratio through
parameter optimization. Empirical application on an ETF representing U.S.
Treasury bonds demonstrates the model's effectiveness, supported by
regularization techniques to mitigate overfitting. The study concludes with
potential avenues for further development, including generalized time steps and
enhanced corrective terms.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05341" title="Abstract">arXiv:2401.05341</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.05341" title="Download PDF">pdf</a>, <a href="/format/2401.05341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stable Online and Offline Reinforcement Learning for Antibody CDRH3  Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Vogt%2C+Y">Yannick Vogt</a>, 
<a href="/search/q-bio?searchtype=author&query=Naouar%2C+M">Mehdi Naouar</a>, 
<a href="/search/q-bio?searchtype=author&query=Kalweit%2C+M">Maria Kalweit</a>, 
<a href="/search/q-bio?searchtype=author&query=Miething%2C+C+C">Christoph Cornelius Miething</a>, 
<a href="/search/q-bio?searchtype=author&query=Duyster%2C+J">Justus Duyster</a>, 
<a href="/search/q-bio?searchtype=author&query=Mertelsmann%2C+R">Roland Mertelsmann</a>, 
<a href="/search/q-bio?searchtype=author&query=Kalweit%2C+G">Gabriel Kalweit</a>, 
<a href="/search/q-bio?searchtype=author&query=Boedecker%2C+J">Joschka Boedecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The field of antibody-based therapeutics has grown significantly in recent
years, with targeted antibodies emerging as a potentially effective approach to
personalized therapies. Such therapies could be particularly beneficial for
complex, highly individual diseases such as cancer. However, progress in this
field is often constrained by the extensive search space of amino acid
sequences that form the foundation of antibody design. In this study, we
introduce a novel reinforcement learning method specifically tailored to
address the unique challenges of this domain. We demonstrate that our method
can learn the design of high-affinity antibodies against multiple targets in
silico, utilizing either online interaction or offline datasets. To the best of
our knowledge, our approach is the first of its kind and outperforms existing
methods on all tested antigens in the Absolut! database.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05342" title="Abstract">arXiv:2401.05342</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.05342" title="Download PDF">pdf</a>, <a href="/format/2401.05342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Most discriminative stimuli for functional cell type identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Burg%2C+M+F">Max F. Burg</a>, 
<a href="/search/q-bio?searchtype=author&query=Zenkel%2C+T">Thomas Zenkel</a>, 
<a href="/search/q-bio?searchtype=author&query=Vystr%C4%8Dilov%C3%A1%2C+M">Michaela Vystr&#x10d;ilov&#xe1;</a>, 
<a href="/search/q-bio?searchtype=author&query=Oesterle%2C+J">Jonathan Oesterle</a>, 
<a href="/search/q-bio?searchtype=author&query=H%C3%B6fling%2C+L">Larissa H&#xf6;fling</a>, 
<a href="/search/q-bio?searchtype=author&query=Willeke%2C+K+F">Konstantin F. Willeke</a>, 
<a href="/search/q-bio?searchtype=author&query=Lause%2C+J">Jan Lause</a>, 
<a href="/search/q-bio?searchtype=author&query=M%C3%BCller%2C+S">Sarah M&#xfc;ller</a>, 
<a href="/search/q-bio?searchtype=author&query=Fahey%2C+P+G">Paul G. Fahey</a>, 
<a href="/search/q-bio?searchtype=author&query=Ding%2C+Z">Zhiwei Ding</a>, 
<a href="/search/q-bio?searchtype=author&query=Restivo%2C+K">Kelli Restivo</a>, 
<a href="/search/q-bio?searchtype=author&query=Sridhar%2C+S">Shashwat Sridhar</a>, 
<a href="/search/q-bio?searchtype=author&query=Gollisch%2C+T">Tim Gollisch</a>, 
<a href="/search/q-bio?searchtype=author&query=Berens%2C+P">Philipp Berens</a>, 
<a href="/search/q-bio?searchtype=author&query=Tolias%2C+A+S">Andreas S. Tolias</a>, 
<a href="/search/q-bio?searchtype=author&query=Euler%2C+T">Thomas Euler</a>, 
<a href="/search/q-bio?searchtype=author&query=Bethge%2C+M">Matthias Bethge</a>, 
<a href="/search/q-bio?searchtype=author&query=Ecker%2C+A+S">Alexander S. Ecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Identifying cell types and understanding their functional properties is
crucial for unraveling the mechanisms underlying perception and cognition. In
the retina, functional types can be identified by carefully selected stimuli,
but this requires expert domain knowledge and biases the procedure towards
previously known cell types. In the visual cortex, it is still unknown what
functional types exist and how to identify them. Thus, for unbiased
identification of the functional cell types in retina and visual cortex, new
approaches are needed. Here we propose an optimization-based clustering
approach using deep predictive models to obtain functional clusters of neurons
using Most Discriminative Stimuli (MDS). Our approach alternates between
stimulus optimization with cluster reassignment akin to an
expectation-maximization algorithm. The algorithm recovers functional clusters
in mouse retina, marmoset retina and macaque visual area V4. This demonstrates
that our approach can successfully find discriminative stimuli across species,
stages of the visual system and recording techniques. The resulting most
discriminative stimuli can be used to assign functional cell types fast and on
the fly, without the need to train complex predictive models or show a large
natural scene dataset, paving the way for experiments that were previously
limited by experimental time. Crucially, MDS are interpretable: they visualize
the distinctive stimulus patterns that most unambiguously identify a specific
type of neuron. We will make our code available online upon publication.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05351" title="Abstract">arXiv:2401.05351</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.05351" title="Download PDF">pdf</a>, <a href="/format/2401.05351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Performance Measures of RNA Secondary Structure Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Runge%2C+F">Frederic Runge</a>, 
<a href="/search/q-bio?searchtype=author&query=Franke%2C+J+K+H">J&#xf6;rg K. H. Franke</a>, 
<a href="/search/q-bio?searchtype=author&query=Fertmann%2C+D">Daniel Fertmann</a>, 
<a href="/search/q-bio?searchtype=author&query=Hutter%2C+F">Frank Hutter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, Accepted at the Machine Learning for Structural Biology Workshop, NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate RNA secondary structure prediction is vital for understanding
cellular regulation and disease mechanisms. Deep learning (DL) methods have
surpassed traditional algorithms by predicting complex features like
pseudoknots and multi-interacting base pairs. However, traditional distance
measures can hardly deal with such tertiary interactions and the currently used
evaluation measures (F1 score, MCC) have limitations. We propose the
Weisfeiler-Lehman graph kernel (WL) as an alternative metric. Embracing
graph-based metrics like WL enables fair and accurate evaluation of RNA
structure prediction algorithms. Further, WL provides informative guidance, as
demonstrated in an RNA design experiment.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05354" title="Abstract">arXiv:2401.05354</a> (cross-list from nlin.AO) [<a href="/pdf/2401.05354" title="Download PDF">pdf</a>, <a href="/format/2401.05354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal coupling functions for fast and global synchronization of weakly  coupled limit-cycle oscillators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Namura%2C+N">Norihisa Namura</a>, 
<a href="/search/nlin?searchtype=author&query=Nakao%2C+H">Hiroya Nakao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Systems and Control (eess.SY); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">We propose a method for optimizing mutual coupling functions to achieve fast
and global synchronization between a pair of weakly coupled limit-cycle
oscillators. Our method is based on phase reduction that provides a concise
low-dimensional representation of the synchronization dynamics of mutually
coupled oscillators, including the case where the coupling depends on past time
series of the oscillators. We first describe a method for a pair of identical
oscillators and then generalize it to the case of slightly nonidentical
oscillators. The coupling function is designed in two optimization steps for
the functional form and amplitude, where the amplitude is numerically optimized
to minimize the average convergence time under a constraint on the total power.
We perform numerical simulations of the synchronization dynamics with the
optimized coupling functions using the FitzHugh-Nagumo and R\"{o}ssler
oscillators as examples. We show that the coupling function optimized by the
proposed method can achieve global synchronization more efficiently than the
previous methods.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05363" title="Abstract">arXiv:2401.05363</a> (cross-list from eess.SP) [<a href="/pdf/2401.05363" title="Download PDF">pdf</a>, <a href="/format/2401.05363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Sleep Staging via Multi-level Domain Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiquan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+S">Sha Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+H">Haiteng Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shijian Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+G">Gang Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automatic sleep staging is essential for sleep assessment and disorder
diagnosis. Most existing methods depend on one specific dataset and are limited
to be generalized to other unseen datasets, for which the training data and
testing data are from the same dataset. In this paper, we introduce domain
generalization into automatic sleep staging and propose the task of
generalizable sleep staging which aims to improve the model generalization
ability to unseen datasets. Inspired by existing domain generalization methods,
we adopt the feature alignment idea and propose a framework called SleepDG to
solve it. Considering both of local salient features and sequential features
are important for sleep staging, we propose a Multi-level Feature Alignment
combining epoch-level and sequence-level feature alignment to learn
domain-invariant feature representations. Specifically, we design an
Epoch-level Feature Alignment to align the feature distribution of each single
sleep epoch among different domains, and a Sequence-level Feature Alignment to
minimize the discrepancy of sequential features among different domains.
SleepDG is validated on five public datasets, achieving the state-of-the-art
performance.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05365" title="Abstract">arXiv:2401.05365</a> (cross-list from eess.SP) [<a href="/pdf/2401.05365" title="Download PDF">pdf</a>, <a href="/format/2401.05365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Action Recognition for Human Risk Prediction with Anticipated  Haptic Alert via Wearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+C">Cheng Guo</a> (1 and 2), 
<a href="/search/eess?searchtype=author&query=Rapetti%2C+L">Lorenzo Rapetti</a> (1), 
<a href="/search/eess?searchtype=author&query=Darvish%2C+K">Kourosh Darvish</a> (3), 
<a href="/search/eess?searchtype=author&query=Grieco%2C+R">Riccardo Grieco</a> (1), 
<a href="/search/eess?searchtype=author&query=Draicchio%2C+F">Francesco Draicchio</a> (4), 
<a href="/search/eess?searchtype=author&query=Pucci%2C+D">Daniele Pucci</a> (1 and 2) ((1) Istituto Italiano di Tecnologia, (2) University of Manchester, (3) University of Toronto, (4) INAIL)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures, accepted at 2023 IEEE-RAS International Conference on Humanoid Robots (Humanoids)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a framework that combines online human state estimation,
action recognition and motion prediction to enable early assessment and
prevention of worker biomechanical risk during lifting tasks. The framework
leverages the NIOSH index to perform online risk assessment, thus fitting
real-time applications. In particular, the human state is retrieved via inverse
kinematics/dynamics algorithms from wearable sensor data. Human action
recognition and motion prediction are achieved by implementing an LSTM-based
Guided Mixture of Experts architecture, which is trained offline and inferred
online. With the recognized actions, a single lifting activity is divided into
a series of continuous movements and the Revised NIOSH Lifting Equation can be
applied for risk assessment. Moreover, the predicted motions enable
anticipation of future risks. A haptic actuator, embedded in the wearable
system, can alert the subject of potential risk, acting as an active prevention
device. The performance of the proposed framework is validated by executing
real lifting tasks, while the subject is equipped with the iFeel wearable
system.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05367" title="Abstract">arXiv:2401.05367</a> (cross-list from eess.SP) [<a href="/pdf/2401.05367" title="Download PDF">pdf</a>, <a href="/format/2401.05367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Context-Aware Stress Monitoring using Wearable and Mobile Technologies  in Everyday Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aqajari%2C+S+A+H">Seyed Amir Hossein Aqajari</a>, 
<a href="/search/eess?searchtype=author&query=Labbaf%2C+S">Sina Labbaf</a>, 
<a href="/search/eess?searchtype=author&query=Tran%2C+P+H">Phuc Hoang Tran</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+B">Brenda Nguyen</a>, 
<a href="/search/eess?searchtype=author&query=Mehrabadi%2C+M+A">Milad Asgari Mehrabadi</a>, 
<a href="/search/eess?searchtype=author&query=Levorato%2C+M">Marco Levorato</a>, 
<a href="/search/eess?searchtype=author&query=Dutt%2C+N">Nikil Dutt</a>, 
<a href="/search/eess?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Daily monitoring of stress is a critical component of maintaining optimal
physical and mental health. Physiological signals and contextual information
have recently emerged as promising indicators for detecting instances of
heightened stress. Nonetheless, developing a real-time monitoring system that
utilizes both physiological and contextual data to anticipate stress levels in
everyday settings while also gathering stress labels from participants
represents a significant challenge. We present a monitoring system that
objectively tracks daily stress levels by utilizing both physiological and
contextual data in a daily-life environment. Additionally, we have integrated a
smart labeling approach to optimize the ecological momentary assessment (EMA)
collection, which is required for building machine learning models for stress
detection. We propose a three-tier Internet-of-Things-based system architecture
to address the challenges. We utilized a cross-validation technique to
accurately estimate the performance of our stress models. We achieved the
F1-score of 70\% with a Random Forest classifier using both PPG and contextual
data, which is considered an acceptable score in models built for everyday
settings. Whereas using PPG data alone, the highest F1-score achieved is
approximately 56\%, emphasizing the significance of incorporating both PPG and
contextual data in stress detection tasks.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05370" title="Abstract">arXiv:2401.05370</a> (cross-list from q-bio.BM) [<a href="/pdf/2401.05370" title="Download PDF">pdf</a>, <a href="/format/2401.05370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autoregressive fragment-based diffusion for pocket-aware ligand design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ghorbani%2C+M">Mahdi Ghorbani</a>, 
<a href="/search/q-bio?searchtype=author&query=Gendelev%2C+L">Leo Gendelev</a>, 
<a href="/search/q-bio?searchtype=author&query=Beroza%2C+P">Paul Beroza</a>, 
<a href="/search/q-bio?searchtype=author&query=Keiser%2C+M+J">Michael J. Keiser</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted, NeurIPS 2023 Generative AI and Biology Workshop. OpenReview: <a href="https://openreview.net/forum?id=E3HN48zjam">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">In this work, we introduce AutoFragDiff, a fragment-based autoregressive
diffusion model for generating 3D molecular structures conditioned on target
protein structures. We employ geometric vector perceptrons to predict atom
types and spatial coordinates of new molecular fragments conditioned on
molecular scaffolds and protein pockets. Our approach improves the local
geometry of the resulting 3D molecules while maintaining high predicted binding
affinity to protein targets. The model can also perform scaffold extension from
user-provided starting molecular scaffold.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05376" title="Abstract">arXiv:2401.05376</a> (cross-list from eess.SP) [<a href="/pdf/2401.05376" title="Download PDF">pdf</a>, <a href="/format/2401.05376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Eating Speed Measurement Using Wrist-Worn IMU Sensors in Free-Living  Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chunzhuo Wang</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+T+S">T. Sunil Kumar</a>, 
<a href="/search/eess?searchtype=author&query=De+Raedt%2C+W">Walter De Raedt</a>, 
<a href="/search/eess?searchtype=author&query=Camps%2C+G">Guido Camps</a>, 
<a href="/search/eess?searchtype=author&query=Hallez%2C+H">Hans Hallez</a>, 
<a href="/search/eess?searchtype=author&query=Vanrumste%2C+B">Bart Vanrumste</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Eating speed is an important indicator that has been widely scrutinized in
nutritional studies. The relationship between eating speed and several
intake-related problems such as obesity, diabetes, and oral health has received
increased attention from researchers. However, existing studies mainly use
self-reported questionnaires to obtain participants' eating speed, where they
choose options from slow, medium, and fast. Such a non-quantitative method is
highly subjective and coarse in individual level. In this study, we propose a
novel approach to measure eating speed in free-living environments
automatically and objectively using wrist-worn inertial measurement unit (IMU)
sensors. Specifically, a temporal convolutional network combined with a
multi-head attention module (TCN-MHA) is developed to detect bites (including
eating and drinking gestures) from free-living IMU data. The predicted bite
sequences are then clustered to eating episodes. Eating speed is calculated by
using the time taken to finish the eating episode to divide the number of
bites. To validate the proposed approach on eating speed measurement, a 7-fold
cross validation is applied to the self-collected fine-annotated full-day-I
(FD-I) dataset, and a hold-out experiment is conducted on the full-day-II
(FD-II) dataset. The two datasets are collected from 61 participants in
free-living environments with a total duration of 513 h, which are publicly
available. Experimental results shows that the proposed approach achieves a
mean absolute percentage error (MAPE) of 0.110 and 0.146 in the FD-I and FD-II
datasets, respectively, showcasing the feasibility of automated eating speed
measurement. To the best of our knowledge, this is the first study
investigating automated eating speed measurement.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05378" title="Abstract">arXiv:2401.05378</a> (cross-list from eess.SP) [<a href="/pdf/2401.05378" title="Download PDF">pdf</a>, <a href="/ps/2401.05378" title="Download PostScript">ps</a>, <a href="/format/2401.05378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting QT prolongation From a Single-lead ECG With Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alam%2C+R">Ridwan Alam</a>, 
<a href="/search/eess?searchtype=author&query=Aguirre%2C+A">Aaron Aguirre</a>, 
<a href="/search/eess?searchtype=author&query=Stultz%2C+C">Collin Stultz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">For a number of antiarrhythmics, drug loading requires a 3 day
hospitalization with monitoring for QT prolongation. Automated QT monitoring
with wearable ECG monitors would facilitate out-of-hospital care. We develop a
deep learning model that infers QT intervals from ECG lead-I - the lead most
often acquired from ambulatory ECG monitors - and to use this model to detect
clinically meaningful QT-prolongation episodes during Dofetilide drug loading.
Using 4.22 million 12-lead ECG recordings from 903.6 thousand patients at the
Massachusetts General Hospital, we develop a deep learning model, QTNet, that
infers QT intervals from lead-I. Over 3 million ECGs from 653 thousand patients
are used to train the model and an internal-test set containing 633 thousand
ECGs from 135 thousand patients was used for testing. QTNet is further
evaluated on an external-validation set containing 3.1 million ECGs from 667
thousand patients at another institution. QTNet was used to detect
Dofetilide-induced QT prolongation in a publicly available database
(ECGRDVQ-dataset) containing ECGs from subjects enrolled in a clinical trial
evaluating the effects of antiarrhythmic drugs. QTNet achieves mean absolute
errors of 12.63ms (internal-test) and 12.30ms (external-validation) for
estimating absolute QT intervals. The associated Pearson correlation
coefficients are 0.91 (internal-test) and 0.92 (external-validation). For the
ECGRDVQ-dataset, QTNet detects Dofetilide-induced QTc prolongation with 87%
sensitivity and 77% specificity. The negative predictive value of the model is
greater than 95% when the pre-test probability of drug-induced QTc prolongation
is below 25%. Drug-induced QT prolongation risk can be tracked from ECG lead-I
using deep learning.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05381" title="Abstract">arXiv:2401.05381</a> (cross-list from eess.SP) [<a href="/pdf/2401.05381" title="Download PDF">pdf</a>, <a href="/format/2401.05381" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ADF &amp; TransApp: A Transformer-Based Framework for Appliance Detection  Using Smart Meter Consumption Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Petralia%2C+A">Adrien Petralia</a>, 
<a href="/search/eess?searchtype=author&query=Charpentier%2C+P">Philippe Charpentier</a>, 
<a href="/search/eess?searchtype=author&query=Palpanas%2C+T">Themis Palpanas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures. This paper appeared in VLDB 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the VLDB Endowment, Volume 17, Issue 3, Pages
  553-562, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past decade, millions of smart meters have been installed by
electricity suppliers worldwide, allowing them to collect a large amount of
electricity consumption data, albeit sampled at a low frequency (one point
every 30min). One of the important challenges these suppliers face is how to
utilize these data to detect the presence/absence of different appliances in
the customers' households. This valuable information can help them provide
personalized offers and recommendations to help customers towards the energy
transition. Appliance detection can be cast as a time series classification
problem. However, the large amount of data combined with the long and variable
length of the consumption series pose challenges when training a classifier. In
this paper, we propose ADF, a framework that uses subsequences of a client
consumption series to detect the presence/absence of appliances. We also
introduce TransApp, a Transformer-based time series classifier that is first
pretrained in a self-supervised way to enhance its performance on appliance
detection tasks. We test our approach on two real datasets, including a
publicly available one. The experimental results with two large real datasets
show that the proposed approach outperforms current solutions, including
state-of-the-art time series classifiers applied to appliance detection. This
paper appeared in VLDB 2024.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05384" title="Abstract">arXiv:2401.05384</a> (cross-list from math.HO) [<a href="/pdf/2401.05384" title="Download PDF">pdf</a>, <a href="/format/2401.05384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Good to Great: Improving Math Reasoning with Tool-Augmented  Interleaf Prompting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+N">Nuo Chen</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+H">Hongguang Li</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+B">Baoyuan Wang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper investigates the performance of Large Language Models (LLMs) and
Tool-augmented LLMs in tackling complex mathematical reasoning tasks. We
introduce IMP-TIP: Improving Math Reasoning with Tool-augmented Interleaf
Prompting, a framework that combines the strengths of both LLMs and
Tool-augmented LLMs. IMP-TIP follows the ``From Good to Great" concept,
collecting multiple potential solutions from both LLMs and their Tool-Augmented
counterparts for the same math problem, and then selecting or re-generating the
most accurate answer after cross-checking these solutions via tool-augmented
interleaf prompting. The framework incorporates two key aspects: self-prompt
and tool-augmented interleaf prompting (TIP). The former allows LLMs to
autonomously refine and improve an initial prompt related to tool usage, while
the latter enables LLMs to derive the final answer by dynamically analyzing the
problem, cross-checking potential solutions, and revising previous reasoning
hints in an interleaved manner. Experimental analysis shows that IMP-TIP
achieves enhanced mathematical capabilities and outperforms traditional LLMs
and tool-augmented LLMs in accuracy and reasoning diversity on math reasoning
tasks. For instance, IMP-TIP can improve Tool-augmented ChatGPT on GSM8K-Hard
from 56.0% to 65.2%.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05385" title="Abstract">arXiv:2401.05385</a> (cross-list from eess.SP) [<a href="/pdf/2401.05385" title="Download PDF">pdf</a>, <a href="/format/2401.05385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Angle-Equivariant Convolutional Neural Networks for Interference  Mitigation in Automotive Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oswald%2C+C">Christian Oswald</a>, 
<a href="/search/eess?searchtype=author&query=Toth%2C+M">Mate Toth</a>, 
<a href="/search/eess?searchtype=author&query=Meissner%2C+P">Paul Meissner</a>, 
<a href="/search/eess?searchtype=author&query=Pernkopf%2C+F">Franz Pernkopf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 20th European Radar Conference (EuRAD) (pp. 135-138). IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In automotive applications, frequency modulated continuous wave (FMCW) radar
is an established technology to determine the distance, velocity and angle of
objects in the vicinity of the vehicle. The quality of predictions might be
seriously impaired if mutual interference between radar sensors occurs.
Previous work processes data from the entire receiver array in parallel to
increase interference mitigation quality using neural networks (NNs). However,
these architectures do not generalize well across different angles of arrival
(AoAs) of interferences and objects. In this paper we introduce fully
convolutional neural network (CNN) with rank-three convolutions which is able
to transfer learned patterns between different AoAs. Our proposed architecture
outperforms previous work while having higher robustness and a lower number of
trainable parameters. We evaluate our network on a diverse data set and
demonstrate its angle equivariance.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05386" title="Abstract">arXiv:2401.05386</a> (cross-list from eess.SP) [<a href="/pdf/2401.05386" title="Download PDF">pdf</a>, <a href="/ps/2401.05386" title="Download PostScript">ps</a>, <a href="/format/2401.05386" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMG subspace alignment and visualization for cross-subject hand gesture  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Colot%2C+M">Martin Colot</a>, 
<a href="/search/eess?searchtype=author&query=Simar%2C+C">C&#xe9;dric Simar</a>, 
<a href="/search/eess?searchtype=author&query=Petieau%2C+M">Mathieu Petieau</a>, 
<a href="/search/eess?searchtype=author&query=Alvarez%2C+A+M+C">Ana Maria Cebolla Alvarez</a>, 
<a href="/search/eess?searchtype=author&query=Cheron%2C+G">Guy Cheron</a>, 
<a href="/search/eess?searchtype=author&query=Bontempi%2C+G">Gianluca Bontempi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages + 1 appendix page 6 figures (one in appendix) Published in the Adapting to Change: Reliable Learning Across Domains workshop from ECML-PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electromyograms (EMG)-based hand gesture recognition systems are a promising
technology for human/machine interfaces. However, one of their main limitations
is the long calibration time that is typically required to handle new users.
The paper discusses and analyses the challenge of cross-subject generalization
thanks to an original dataset containing the EMG signals of 14 human subjects
during hand gestures. The experimental results show that, though an accurate
generalization based on pooling multiple subjects is hardly achievable, it is
possible to improve the cross-subject estimation by identifying a robust
low-dimensional subspace for multiple subjects and aligning it to a target
subject. A visualization of the subspace enables us to provide insights for the
improvement of cross-subject generalization with EMG signals.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05388" title="Abstract">arXiv:2401.05388</a> (cross-list from eess.SP) [<a href="/pdf/2401.05388" title="Download PDF">pdf</a>, <a href="/format/2401.05388" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian ECG reconstruction using denoising diffusion generative models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cardoso%2C+G+V">Gabriel V. Cardoso</a>, 
<a href="/search/eess?searchtype=author&query=Bedin%2C+L">Lisa Bedin</a>, 
<a href="/search/eess?searchtype=author&query=Duchateau%2C+J">Josselin Duchateau</a>, 
<a href="/search/eess?searchtype=author&query=Dubois%2C+R">R&#xe9;mi Dubois</a>, 
<a href="/search/eess?searchtype=author&query=Moulines%2C+E">Eric Moulines</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">In this work, we propose a denoising diffusion generative model (DDGM)
trained with healthy electrocardiogram (ECG) data that focuses on ECG
morphology and inter-lead dependence. Our results show that this innovative
generative model can successfully generate realistic ECG signals. Furthermore,
we explore the application of recent breakthroughs in solving linear inverse
Bayesian problems using DDGM. This approach enables the development of several
important clinical tools. These include the calculation of corrected QT
intervals (QTc), effective noise suppression of ECG signals, recovery of
missing ECG leads, and identification of anomalous readings, enabling
significant advances in cardiac health monitoring and diagnosis.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05394" title="Abstract">arXiv:2401.05394</a> (cross-list from eess.SP) [<a href="/pdf/2401.05394" title="Download PDF">pdf</a>, <a href="/format/2401.05394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Regularization with k-Support Norm: an Important Complement to  Sparse Recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=de+Vazelhes%2C+W">William de Vazelhes</a>, 
<a href="/search/eess?searchtype=author&query=Mukhoty%2C+B">Bhaskar Mukhoty</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+X">Xiao-Tong Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+B">Bin Gu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at AAAI 2024. Code at <a href="https://github.com/wdevazelhes/IRKSN_AAAI2024">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Sparse recovery is ubiquitous in machine learning and signal processing. Due
to the NP-hard nature of sparse recovery, existing methods are known to suffer
either from restrictive (or even unknown) applicability conditions, or high
computational cost. Recently, iterative regularization methods have emerged as
a promising fast approach because they can achieve sparse recovery in one pass
through early stopping, rather than the tedious grid-search used in the
traditional methods. However, most of those iterative methods are based on the
$\ell_1$ norm which requires restrictive applicability conditions and could
fail in many cases. Therefore, achieving sparse recovery with iterative
regularization methods under a wider range of conditions has yet to be further
explored. To address this issue, we propose a novel iterative regularization
algorithm, IRKSN, based on the $k$-support norm regularizer rather than the
$\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and
compare them with traditional conditions for recovery with $\ell_1$ norm
regularizers. Additionally, we give an early stopping bound on the model error
of IRKSN with explicit constants, achieving the standard linear rate for sparse
recovery. Finally, we illustrate the applicability of our algorithm on several
experiments, including a support recovery experiment with a correlated design
matrix.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05395" title="Abstract">arXiv:2401.05395</a> (cross-list from econ.GN) [<a href="/pdf/2401.05395" title="Download PDF">pdf</a>, <a href="/format/2401.05395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SRNI-CAR: A comprehensive dataset for analyzing the Chinese automotive  market
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Ding%2C+R">Ruixin Ding</a>, 
<a href="/search/econ?searchtype=author&query=Chen%2C+B">Bowei Chen</a>, 
<a href="/search/econ?searchtype=author&query=Wilson%2C+J+M">James M. Wilson</a>, 
<a href="/search/econ?searchtype=author&query=Yan%2C+Z">Zhi Yan</a>, 
<a href="/search/econ?searchtype=author&query=Huang%2C+Y">Yufei Huang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of 2023 IEEE International Conference on Big Data
  (BigData), page 3405-3412
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">The automotive industry plays a critical role in the global economy, and
particularly important is the expanding Chinese automobile market due to its
immense scale and influence. However, existing automotive sector datasets are
limited in their coverage, failing to adequately consider the growing demand
for more and diverse variables. This paper aims to bridge this data gap by
introducing a comprehensive dataset spanning the years from 2016 to 2022,
encompassing sales data, online reviews, and a wealth of information related to
the Chinese automotive industry. This dataset serves as a valuable resource,
significantly expanding the available data. Its impact extends to various
dimensions, including improving forecasting accuracy, expanding the scope of
business applications, informing policy development and regulation, and
advancing academic research within the automotive sector. To illustrate the
dataset's potential applications in both business and academic contexts, we
present two application examples. Our developed dataset enhances our
understanding of the Chinese automotive market and offers a valuable tool for
researchers, policymakers, and industry stakeholders worldwide.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05397" title="Abstract">arXiv:2401.05397</a> (cross-list from eess.SP) [<a href="/pdf/2401.05397" title="Download PDF">pdf</a>, <a href="/format/2401.05397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Lightcurve Inversion for Attitude Determination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=da+Gra%C3%A7a+Marto%2C+S">Sim&#xe3;o da Gra&#xe7;a Marto</a>, 
<a href="/search/eess?searchtype=author&query=Vasile%2C+M">Massimiliano Vasile</a>, 
<a href="/search/eess?searchtype=author&query=Campbell%2C+A">Andrew Campbell</a>, 
<a href="/search/eess?searchtype=author&query=Murray%2C+P">Paul Murray</a>, 
<a href="/search/eess?searchtype=author&query=Marshall%2C+S">Stephen Marshall</a>, 
<a href="/search/eess?searchtype=author&query=Savitski%2C+V">Vasili Savitski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 14 figures Accepted for presentation at SciTech 2024 in Orlando, Florida, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Spectral lightcurves consisting of time series single-pixel spectral
measurements of spacecraft are used to infer the spacecraft's attitude and
rotation. Two methods are used. One based on numerical optimisation of a
regularised least squares cost function, and another based on machine learning
with a neural network model. The aim is to work with minimal information, thus
no prior is available on the attitude nor on the inertia tensor. The
theoretical and practical aspects of this task are investigated, and the
methodology is tested on synthetic data. Results are shown based on synthetic
data.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05402" title="Abstract">arXiv:2401.05402</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.05402" title="Download PDF">pdf</a>, <a href="/format/2401.05402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vector Field Oriented Diffusion Model for Crystal Material Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Klipfel%2C+A">Astrid Klipfel</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fregier%2C+Y">Ya&#xeb;l Fregier</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sayede%2C+A">Adlane Sayede</a>, 
<a href="/search/cond-mat?searchtype=author&query=Bouraoui%2C+Z">Zied Bouraoui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Discovering crystal structures with specific chemical properties has become
an increasingly important focus in material science. However, current models
are limited in their ability to generate new crystal lattices, as they only
consider atomic positions or chemical composition. To address this issue, we
propose a probabilistic diffusion model that utilizes a geometrically
equivariant GNN to consider atomic positions and crystal lattices jointly. To
evaluate the effectiveness of our model, we introduce a new generation metric
inspired by Frechet Inception Distance, but based on GNN energy prediction
rather than InceptionV3 used in computer vision. In addition to commonly used
metrics like validity, which assesses the plausibility of a structure, this new
metric offers a more comprehensive evaluation of our model's capabilities. Our
experiments on existing benchmarks show the significance of our diffusion
model. We also show that our method can effectively learn meaningful
representations.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05405" title="Abstract">arXiv:2401.05405</a> (cross-list from eess.SP) [<a href="/pdf/2401.05405" title="Download PDF">pdf</a>, <a href="/format/2401.05405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SelfEEG: A Python library for Self-Supervised Learning in  Electroencephalography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Del+Pup%2C+F">Federico Del Pup</a>, 
<a href="/search/eess?searchtype=author&query=Zanola%2C+A">Andrea Zanola</a>, 
<a href="/search/eess?searchtype=author&query=Tshimanga%2C+L+F">Louis Fabrice Tshimanga</a>, 
<a href="/search/eess?searchtype=author&query=Mazzon%2C+P+E">Paolo Emilio Mazzon</a>, 
<a href="/search/eess?searchtype=author&query=Atzori%2C+M">Manfredo Atzori</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to JOSS for possible publication. GitHub repository: see <a href="https://github.com/MedMaxLab/selfEEG">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">SelfEEG is an open-source Python library developed to assist researchers in
conducting Self-Supervised Learning (SSL) experiments on electroencephalography
(EEG) data. Its primary objective is to offer a user-friendly but highly
customizable environment, enabling users to efficiently design and execute
self-supervised learning tasks on EEG data.
<br />SelfEEG covers all the stages of a typical SSL pipeline, ranging from data
import to model design and training. It includes modules specifically designed
to: split data at various granularity levels (e.g., session-, subject-, or
dataset-based splits); effectively manage data stored with different
configurations (e.g., file extensions, data types) during mini-batch
construction; provide a wide range of standard deep learning models, data
augmentations and SSL baseline methods applied to EEG data.
<br />Most of the functionalities offered by selfEEG can be executed both on GPUs
and CPUs, expanding its usability beyond the self-supervised learning area.
Additionally, these functionalities can be employed for the analysis of other
biomedical signals often coupled with EEGs, such as electromyography or
electrocardiography data.
<br />These features make selfEEG a versatile deep learning tool for biomedical
applications and a useful resource in SSL, one of the currently most active
fields of Artificial Intelligence.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05406" title="Abstract">arXiv:2401.05406</a> (cross-list from eess.SP) [<a href="/pdf/2401.05406" title="Download PDF">pdf</a>, <a href="/format/2401.05406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RFRL Gym: A Reinforcement Learning Testbed for Cognitive Radio  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rosen%2C+D">Daniel Rosen</a> (1), 
<a href="/search/eess?searchtype=author&query=Rochez%2C+I">Illa Rochez</a> (1), 
<a href="/search/eess?searchtype=author&query=McIrvin%2C+C">Caleb McIrvin</a> (1), 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Joshua Lee</a> (1), 
<a href="/search/eess?searchtype=author&query=D%27Alessandro%2C+K">Kevin D&#x27;Alessandro</a> (1), 
<a href="/search/eess?searchtype=author&query=Wiecek%2C+M">Max Wiecek</a> (1), 
<a href="/search/eess?searchtype=author&query=Hoang%2C+N">Nhan Hoang</a> (1), 
<a href="/search/eess?searchtype=author&query=Saffarini%2C+R">Ramzy Saffarini</a> (1), 
<a href="/search/eess?searchtype=author&query=Philips%2C+S">Sam Philips</a> (1), 
<a href="/search/eess?searchtype=author&query=Jones%2C+V">Vanessa Jones</a> (1), 
<a href="/search/eess?searchtype=author&query=Ivey%2C+W">Will Ivey</a> (1), 
<a href="/search/eess?searchtype=author&query=Harris-Smart%2C+Z">Zavier Harris-Smart</a> (2), 
<a href="/search/eess?searchtype=author&query=Harris-Smart%2C+Z">Zavion Harris-Smart</a> (2), 
<a href="/search/eess?searchtype=author&query=Chin%2C+Z">Zayden Chin</a> (2), 
<a href="/search/eess?searchtype=author&query=Johnson%2C+A">Amos Johnson</a> (2), 
<a href="/search/eess?searchtype=author&query=Jones%2C+A+M">Alyse M. Jones</a> (1), 
<a href="/search/eess?searchtype=author&query=Headley%2C+W+C">William C. Headley</a> (1) ((1) Virginia Tech, (2) Morehouse College)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Radio Frequency Reinforcement Learning (RFRL) is anticipated to be a widely
applicable technology in the next generation of wireless communication systems,
particularly 6G and next-gen military communications. Given this, our research
is focused on developing a tool to promote the development of RFRL techniques
that leverage spectrum sensing. In particular, the tool was designed to address
two cognitive radio applications, specifically dynamic spectrum access and
jamming. In order to train and test reinforcement learning (RL) algorithms for
these applications, a simulation environment is necessary to simulate the
conditions that an agent will encounter within the Radio Frequency (RF)
spectrum. In this paper, such an environment has been developed, herein
referred to as the RFRL Gym. Through the RFRL Gym, users can design their own
scenarios to model what an RL agent may encounter within the RF spectrum as
well as experiment with different spectrum sensing techniques. Additionally,
the RFRL Gym is a subclass of OpenAI gym, enabling the use of third-party ML/RL
Libraries. We plan to open-source this codebase to enable other researchers to
utilize the RFRL Gym to test their own scenarios and RL algorithms, ultimately
leading to the advancement of RL research in the wireless communications
domain. This paper describes in further detail the components of the Gym,
results from example scenarios, and plans for future additions.
<br />Index Terms-machine learning, reinforcement learning, wireless
communications, dynamic spectrum access, OpenAI gym
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05407" title="Abstract">arXiv:2401.05407</a> (cross-list from eess.SP) [<a href="/pdf/2401.05407" title="Download PDF">pdf</a>, <a href="/format/2401.05407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning and Feature Ranking for Impact Fall Detection Event  Using Multisensor Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Koffi%2C+T+Y">Tresor Y. Koffi</a>, 
<a href="/search/eess?searchtype=author&query=Mourchid%2C+Y">Youssef Mourchid</a>, 
<a href="/search/eess?searchtype=author&query=Hindawi%2C+M">Mohammed Hindawi</a>, 
<a href="/search/eess?searchtype=author&query=Dupuis%2C+Y">Yohan Dupuis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Falls among individuals, especially the elderly population, can lead to
serious injuries and complications. Detecting impact moments within a fall
event is crucial for providing timely assistance and minimizing the negative
consequences. In this work, we aim to address this challenge by applying
thorough preprocessing techniques to the multisensor dataset, the goal is to
eliminate noise and improve data quality. Furthermore, we employ a feature
selection process to identify the most relevant features derived from the
multisensor UP-FALL dataset, which in turn will enhance the performance and
efficiency of machine learning models. We then evaluate the efficiency of
various machine learning models in detecting the impact moment using the
resulting data information from multiple sensors. Through extensive
experimentation, we assess the accuracy of our approach using various
evaluation metrics. Our results achieve high accuracy rates in impact
detection, showcasing the power of leveraging multisensor data for fall
detection tasks. This highlights the potential of our approach to enhance fall
detection systems and improve the overall safety and well-being of individuals
at risk of falls.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05408" title="Abstract">arXiv:2401.05408</a> (cross-list from eess.SP) [<a href="/pdf/2401.05408" title="Download PDF">pdf</a>, <a href="/format/2401.05408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Emotional Valence from Wearables: Can Our Data Reveal Our True  Feelings?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Grzeszczyk%2C+M+K">Michal K. Grzeszczyk</a>, 
<a href="/search/eess?searchtype=author&query=Lisowska%2C+A">Anna Lisowska</a>, 
<a href="/search/eess?searchtype=author&query=Sitek%2C+A">Arkadiusz Sitek</a>, 
<a href="/search/eess?searchtype=author&query=Lisowska%2C+A">Aneta Lisowska</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for MobileHCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Automatic detection and tracking of emotional states has the potential for
helping individuals with various mental health conditions. While previous
studies have captured physiological signals using wearable devices in
laboratory settings, providing valuable insights into the relationship between
physiological responses and mental states, the transfer of these findings to
real-life scenarios is still in its nascent stages. Our research aims to bridge
the gap between laboratory-based studies and real-life settings by leveraging
consumer-grade wearables and self-report measures. We conducted a preliminary
study involving 15 healthy participants to assess the efficacy of wearables in
capturing user valence in real-world settings. In this paper, we present the
initial analysis of the collected data, focusing primarily on the results of
valence classification. Our findings demonstrate promising results in
distinguishing between high and low positive valence, achieving an F1 score of
0.65. This research opens up avenues for future research in the field of mobile
mental health interventions.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05409" title="Abstract">arXiv:2401.05409</a> (cross-list from eess.SP) [<a href="/pdf/2401.05409" title="Download PDF">pdf</a>, <a href="/format/2401.05409" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Image-based Data Representations of Time Series: A Comparative Analysis  in EEG Artifact Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maiwald%2C+A">Aaron Maiwald</a>, 
<a href="/search/eess?searchtype=author&query=Ackermann%2C+L">Leon Ackermann</a>, 
<a href="/search/eess?searchtype=author&query=Kalcher%2C+M">Maximilian Kalcher</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+D+J">Daniel J. Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Alternative data representations are powerful tools that augment the
performance of downstream models. However, there is an abundance of such
representations within the machine learning toolbox, and the field lacks a
comparative understanding of the suitability of each representation method.
<br />In this paper, we propose artifact detection and classification within EEG
data as a testbed for profiling image-based data representations of time series
data. We then evaluate eleven popular deep learning architectures on each of
six commonly-used representation methods.
<br />We find that, while the choice of representation entails a choice within the
tradeoff between bias and variance, certain representations are practically
more effective in highlighting features which increase the signal-to-noise
ratio of the data. We present our results on EEG data, and open-source our
testing framework to enable future comparative analyses in this vein.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05410" title="Abstract">arXiv:2401.05410</a> (cross-list from eess.SP) [<a href="/pdf/2401.05410" title="Download PDF">pdf</a>, <a href="/format/2401.05410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Device-Free Human State Estimation using UWB Multi-Static Radios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Laham%2C+S+A">Saria Al Laham</a>, 
<a href="/search/eess?searchtype=author&query=Baghi%2C+B+H">Bobak H. Baghi</a>, 
<a href="/search/eess?searchtype=author&query=Lajoie%2C+P">Pierre-Yves Lajoie</a>, 
<a href="/search/eess?searchtype=author&query=Feriani%2C+A">Amal Feriani</a>, 
<a href="/search/eess?searchtype=author&query=Herath%2C+S">Sachini Herath</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Steve Liu</a>, 
<a href="/search/eess?searchtype=author&query=Dudek%2C+G">Gregory Dudek</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">We present a human state estimation framework that allows us to estimate the
location, and even the activities, of people in an indoor environment without
the requirement that they carry a specific devices with them. To achieve this
"device free" localization we use a small number of low-cost Ultra-Wide Band
(UWB) sensors distributed across the environment of interest. To achieve high
quality estimation from the UWB signals merely reflected of people in the
environment, we exploit a deep network that can learn to make inferences. The
hardware setup consists of commercial off-the-shelf (COTS) single antenna UWB
modules for sensing, paired with Raspberry PI units for computational
processing and data transfer. We make use of the channel impulse response (CIR)
measurements from the UWB sensors to estimate the human state - comprised of
location and activity - in a given area. Additionally, we can also estimate the
number of humans that occupy this region of interest. In our approach, first,
we pre-process the CIR data which involves meticulous aggregation of
measurements and extraction of key statistics. Afterwards, we leverage a
convolutional deep neural network to map the CIRs into precise location
estimates with sub-30 cm accuracy. Similarly, we achieve accurate human
activity recognition and occupancy counting results. We show that we can
quickly fine-tune our model for new out-of-distribution users, a process that
requires only a few minutes of data and a few epochs of training. Our results
show that UWB is a promising solution for adaptable smart-home localization and
activity recognition problems.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05411" title="Abstract">arXiv:2401.05411</a> (cross-list from eess.SP) [<a href="/pdf/2401.05411" title="Download PDF">pdf</a>, <a href="/format/2401.05411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RawECGNet: Deep Learning Generalization for Atrial Fibrillation  Detection from the Raw ECG
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ben-Moshe%2C+N">Noam Ben-Moshe</a>, 
<a href="/search/eess?searchtype=author&query=Tsutsui%2C+K">Kenta Tsutsui</a>, 
<a href="/search/eess?searchtype=author&query=Biton%2C+S">Shany Biton</a>, 
<a href="/search/eess?searchtype=author&query=S%C3%B6rnmo%2C+L">Leif S&#xf6;rnmo</a>, 
<a href="/search/eess?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Introduction: Deep learning models for detecting episodes of atrial
fibrillation (AF) using rhythm information in long-term, ambulatory ECG
recordings have shown high performance. However, the rhythm-based approach does
not take advantage of the morphological information conveyed by the different
ECG waveforms, particularly the f-waves. As a result, the performance of such
models may be inherently limited. Methods: To address this limitation, we have
developed a deep learning model, named RawECGNet, to detect episodes of AF and
atrial flutter (AFl) using the raw, single-lead ECG. We compare the
generalization performance of RawECGNet on two external data sets that account
for distribution shifts in geography, ethnicity, and lead position. RawECGNet
is further benchmarked against a state-of-the-art deep learning model, named
ArNet2, which utilizes rhythm information as input. Results: Using RawECGNet,
the results for the different leads in the external test sets in terms of the
F1 score were 0.91--0.94 in RBDB and 0.93 in SHDB, compared to 0.89--0.91 in
RBDB and 0.91 in SHDB for ArNet2. The results highlight RawECGNet as a
high-performance, generalizable algorithm for detection of AF and AFl episodes,
exploiting information on both rhythm and morphology.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05414" title="Abstract">arXiv:2401.05414</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.05414" title="Download PDF">pdf</a>, <a href="/format/2401.05414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Three Demons in Causality in Finance: Time Resolution,  Nonstationarity, and Latent Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Dong%2C+X">Xinshuai Dong</a>, 
<a href="/search/q-fin?searchtype=author&query=Dai%2C+H">Haoyue Dai</a>, 
<a href="/search/q-fin?searchtype=author&query=Fan%2C+Y">Yewen Fan</a>, 
<a href="/search/q-fin?searchtype=author&query=Jin%2C+S">Songyao Jin</a>, 
<a href="/search/q-fin?searchtype=author&query=Rajendran%2C+S">Sathyamoorthy Rajendran</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Financial data is generally time series in essence and thus suffers from
three fundamental issues: the mismatch in time resolution, the time-varying
property of the distribution - nonstationarity, and causal factors that are
important but unknown/unobserved. In this paper, we follow a causal perspective
to systematically look into these three demons in finance. Specifically, we
reexamine these issues in the context of causality, which gives rise to a novel
and inspiring understanding of how the issues can be addressed. Following this
perspective, we provide systematic solutions to these problems, which hopefully
would serve as a foundation for future research in the area.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05416" title="Abstract">arXiv:2401.05416</a> (cross-list from eess.SP) [<a href="/pdf/2401.05416" title="Download PDF">pdf</a>, <a href="/format/2401.05416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wavelet Dynamic Selection Network for Inertial Sensor Signal Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yifeng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yi Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024 - Association for the Advancement of Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As attitude and motion sensing components, inertial sensors are widely used
in various portable devices. But the severe errors of inertial sensors restrain
their function, especially the trajectory recovery and semantic recognition. As
a mainstream signal processing method, wavelet is hailed as the mathematical
microscope of signal due to the plentiful and diverse wavelet basis functions.
However, complicated noise types and application scenarios of inertial sensors
make selecting wavelet basis perplexing. To this end, we propose a wavelet
dynamic selection network (WDSNet), which intelligently selects the appropriate
wavelet basis for variable inertial signals. In addition, existing deep
learning architectures excel at extracting features from input data but neglect
to learn the characteristics of target categories, which is essential to
enhance the category awareness capability, thereby improving the selection of
wavelet basis. Therefore, we propose a category representation mechanism (CRM),
which enables the network to extract and represent category features without
increasing trainable parameters. Furthermore, CRM transforms the common fully
connected network into category representations, which provide closer
supervision to the feature extractor than the far and trivial one-hot
classification labels. We call this process of imposing interpretability on a
network and using it to supervise the feature extractor the feature supervision
mechanism, and its effectiveness is demonstrated experimentally and
theoretically in this paper. The enhanced inertial signal can perform
impracticable tasks with regard to the original signal, such as trajectory
reconstruction. Both quantitative and visual results show that WDSNet
outperforms the existing methods. Remarkably, WDSNet, as a weakly-supervised
method, achieves the state-of-the-art performance of all the compared
fully-supervised methods.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05418" title="Abstract">arXiv:2401.05418</a> (cross-list from eess.SP) [<a href="/pdf/2401.05418" title="Download PDF">pdf</a>, <a href="/ps/2401.05418" title="Download PostScript">ps</a>, <a href="/format/2401.05418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ANALYTiC: Understanding Decision Boundaries and Dimensionality Reduction  in Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Haidri%2C+S">Salman Haidri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Bachelor's thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of compact, handheld devices has given us a pool of tracked
movement data that could be used to infer trends and patterns that can be made
to use. With this flooding of various trajectory data of animals, humans,
vehicles, etc., the idea of ANALYTiC originated, using active learning to infer
semantic annotations from the trajectories by learning from sets of labeled
data. This study explores the application of dimensionality reduction and
decision boundaries in combination with the already present active learning,
highlighting patterns and clusters in data. We test these features with three
different trajectory datasets with objective of exploiting the the already
labeled data and enhance their interpretability. Our experimental analysis
exemplifies the potential of these combined methodologies in improving the
efficiency and accuracy of trajectory labeling. This study serves as a
stepping-stone towards the broader integration of machine learning and visual
methods in context of movement data analysis.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05420" title="Abstract">arXiv:2401.05420</a> (cross-list from eess.SP) [<a href="/pdf/2401.05420" title="Download PDF">pdf</a>, <a href="/format/2401.05420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HoloBeam: Learning Optimal Beamforming in Far-Field Holographic  Metasurface Transceivers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghosh%2C+D">Debamita Ghosh</a>, 
<a href="/search/eess?searchtype=author&query=Hanawal%2C+M+K">Manjesh Kumar Hanawal</a>, 
<a href="/search/eess?searchtype=author&query=Zlatanova%2C+N">Nikola Zlatanova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at INFOCOM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Holographic Metasurface Transceivers (HMTs) are emerging as cost-effective
substitutes to large antenna arrays for beamforming in Millimeter and TeraHertz
wave communication. However, to achieve desired channel gains through
beamforming in HMT, phase-shifts of a large number of elements need to be
appropriately set, which is challenging. Also, these optimal phase-shifts
depend on the location of the receivers, which could be unknown. In this work,
we develop a learning algorithm using a {\it fixed-budget multi-armed bandit
framework} to beamform and maximize received signal strength at the receiver
for far-field regions. Our algorithm, named \Algo exploits the parametric form
of channel gains of the beams, which can be expressed in terms of two {\it
phase-shifting parameters}. Even after parameterization, the problem is still
challenging as phase-shifting parameters take continuous values. To overcome
this, {\it\HB} works with the discrete values of phase-shifting parameters and
exploits their unimodal relations with channel gains to learn the optimal
values faster. We upper bound the probability of {\it\HB} incorrectly
identifying the (discrete) optimal phase-shift parameters in terms of the
number of pilots used in learning. We show that this probability decays
exponentially with the number of pilot signals. We demonstrate that {\it\HB}
outperforms state-of-the-art algorithms through extensive simulations.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05422" title="Abstract">arXiv:2401.05422</a> (cross-list from eess.SP) [<a href="/pdf/2401.05422" title="Download PDF">pdf</a>, <a href="/ps/2401.05422" title="Download PostScript">ps</a>, <a href="/format/2401.05422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning (ML)-assisted Beam Management in millimeter (mm)Wave  Distributed Multiple Input Multiple Output (D-MIMO) systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=M%2C+K+R">Karthik R M</a>, 
<a href="/search/eess?searchtype=author&query=Hegde%2C+D+N">Dhiraj Nagaraja Hegde</a>, 
<a href="/search/eess?searchtype=author&query=Sarajlic%2C+M">Muris Sarajlic</a>, 
<a href="/search/eess?searchtype=author&query=Sarkar%2C+A">Abhishek Sarkar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Beam management (BM) protocols are critical for establishing and maintaining
connectivity between network radio nodes and User Equipments (UEs). In
Distributed Multiple Input Multiple Output systems (D-MIMO), a number of access
points (APs), coordinated by a central processing unit (CPU), serves a number
of UEs. At mmWave frequencies, the problem of finding the best AP and beam to
serve the UEs is challenging due to a large number of beams that need to be
sounded with Downlink (DL) reference signals. The objective of this paper is to
investigate whether the best AP/beam can be reliably inferred from sounding
only a small subset of beams and leveraging AI/ML for inference of best
beam/AP. We use Random Forest (RF), MissForest (MF) and conditional Generative
Adversarial Networks (c-GAN) for demonstrating the performance benefits of
inference.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05425" title="Abstract">arXiv:2401.05425</a> (cross-list from eess.SP) [<a href="/pdf/2401.05425" title="Download PDF">pdf</a>, <a href="/format/2401.05425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Unobtrusive and Lightweight Ear-worn System for Continuous Epileptic  Seizure Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aziz%2C+A">Abdul Aziz</a>, 
<a href="/search/eess?searchtype=author&query=Pham%2C+N">Nhat Pham</a>, 
<a href="/search/eess?searchtype=author&query=Vora%2C+N">Neel Vora</a>, 
<a href="/search/eess?searchtype=author&query=Reynolds%2C+C">Cody Reynolds</a>, 
<a href="/search/eess?searchtype=author&query=Lehnen%2C+J">Jaime Lehnen</a>, 
<a href="/search/eess?searchtype=author&query=Venkatesh%2C+P">Pooja Venkatesh</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zhuoran Yao</a>, 
<a href="/search/eess?searchtype=author&query=Harvey%2C+J">Jay Harvey</a>, 
<a href="/search/eess?searchtype=author&query=Vu%2C+T">Tam Vu</a>, 
<a href="/search/eess?searchtype=author&query=Ding%2C+K">Kan Ding</a>, 
<a href="/search/eess?searchtype=author&query=Nguyen%2C+P">Phuc Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Epilepsy is one of the most common neurological diseases globally, affecting
around 50 million people worldwide. Fortunately, up to 70 percent of people
with epilepsy could live seizure-free if properly diagnosed and treated, and a
reliable technique to monitor the onset of seizures could improve the quality
of life of patients who are constantly facing the fear of random seizure
attacks. The scalp-based EEG test, despite being the gold standard for
diagnosing epilepsy, is costly, necessitates hospitalization, demands skilled
professionals for operation, and is discomforting for users. In this paper, we
propose EarSD, a novel lightweight, unobtrusive, and socially acceptable
ear-worn system to detect epileptic seizure onsets by measuring the
physiological signals from behind the user's ears. EarSD includes an integrated
custom-built sensing, computing, and communication PCB to collect and amplify
the signals of interest, remove the noises caused by motion artifacts and
environmental impacts, and stream the data wirelessly to the computer or mobile
phone nearby, where data are uploaded to the host computer for further
processing. We conducted both in-lab and in-hospital experiments with epileptic
seizure patients who were hospitalized for seizure studies. The preliminary
results confirm that EarSD can detect seizures with up to 95.3 percent accuracy
by just using classical machine learning algorithms.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05426" title="Abstract">arXiv:2401.05426</a> (cross-list from eess.SP) [<a href="/pdf/2401.05426" title="Download PDF">pdf</a>, <a href="/format/2401.05426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoSS: Co-optimizing Sensor and Sampling Rate for Data-Efficient AI in  Human Activity Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengxi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Z">Zimin Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Gei%C3%9Fler%2C+D">Daniel Gei&#xdf;ler</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Suh%2C+S">Sungho Suh</a>, 
<a href="/search/eess?searchtype=author&query=Lukowicz%2C+P">Paul Lukowicz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepeted by the 2nd Workshop on Sustainable AI (AAAI24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in Artificial Neural Networks have significantly improved
human activity recognition using multiple time-series sensors. While employing
numerous sensors with high-frequency sampling rates usually improves the
results, it often leads to data inefficiency and unnecessary expansion of the
ANN, posing a challenge for their practical deployment on edge devices.
Addressing these issues, our work introduces a pragmatic framework for
data-efficient utilization in HAR tasks, considering the optimization of both
sensor modalities and sampling rate simultaneously. Central to our approach are
the designed trainable parameters, termed 'Weight Scores,' which assess the
significance of each sensor modality and sampling rate during the training
phase. These scores guide the sensor modalities and sampling rate selection.
The pruning method allows users to make a trade-off between computational
budgets and performance by selecting the sensor modalities and sampling rates
according to the weight score ranking. We tested our framework's effectiveness
in optimizing sensor modality and sampling rate selection using three public
HAR benchmark datasets. The results show that the sensor and sampling rate
combination selected via CoSS achieves similar classification performance to
configurations using the highest sampling rate with all sensors but at a
reduced hardware cost.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05427" title="Abstract">arXiv:2401.05427</a> (cross-list from eess.SP) [<a href="/pdf/2401.05427" title="Download PDF">pdf</a>, <a href="/format/2401.05427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slide FFT on a homogeneous mesh in wafer-scale computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=van+Putten%2C+M+H+P+M">Maurice H.P.M. van Putten</a> (Sejong Universiy, INAF-OAS), 
<a href="/search/eess?searchtype=author&query=Wilson%2C+L">Leighton Wilson</a> (Cerebras), 
<a href="/search/eess?searchtype=author&query=Lavely%2C+A+W">Adam W. Lavely</a> (LBNL), 
<a href="/search/eess?searchtype=author&query=Hair%2C+M">Mark Hair</a> (Cerebras)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Searches for signals at low signal-to-noise ratios frequently involve the
Fast Fourier Transform (FFT). For high-throughput searches, we here consider
FFT on the homogeneous mesh of Processing Elements (PEs) of a wafer-scale
engine (WSE). To minimize memory overhead in the inherently non-local FFT
algorithm, we introduce a new synchronous slide operation ({\em Slide})
exploiting the fast interconnect between adjacent PEs. Feasibility of
compute-limited performance is demonstrated in linear scaling of Slide
execution times with varying array size in preliminary benchmarks on the CS-2
WSE. The proposed implementation appears opportune to accelerate and open the
full discovery potential of FFT-based signal processing in multi-messenger
astronomy.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05430" title="Abstract">arXiv:2401.05430</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.05430" title="Download PDF">pdf</a>, <a href="/format/2401.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-relational Graph Diffusion Neural Network with Parallel Retention  for Stock Trends Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=You%2C+Z">Zinuo You</a>, 
<a href="/search/q-fin?searchtype=author&query=Zhang%2C+P">Pengju Zhang</a>, 
<a href="/search/q-fin?searchtype=author&query=Zheng%2C+J">Jin Zheng</a>, 
<a href="/search/q-fin?searchtype=author&query=Cartlidge%2C+J">John Cartlidge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures. Author manuscript accepted for ICASSP 2024 (IEEE International Conference on Acoustics, Speech and Signal Processing)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Stock trend classification remains a fundamental yet challenging task, owing
to the intricate time-evolving dynamics between and within stocks. To tackle
these two challenges, we propose a graph-based representation learning approach
aimed at predicting the future movements of multiple stocks. Initially, we
model the complex time-varying relationships between stocks by generating
dynamic multi-relational stock graphs. This is achieved through a novel edge
generation algorithm that leverages information entropy and signal energy to
quantify the intensity and directionality of inter-stock relations on each
trading day. Then, we further refine these initial graphs through a stochastic
multi-relational diffusion process, adaptively learning task-optimal edges.
Subsequently, we implement a decoupled representation learning scheme with
parallel retention to obtain the final graph representation. This strategy
better captures the unique temporal features within individual stocks while
also capturing the overall structure of the stock graph. Comprehensive
experiments conducted on real-world datasets from two US markets (NASDAQ and
NYSE) and one Chinese market (Shanghai Stock Exchange: SSE) validate the
effectiveness of our method. Our approach consistently outperforms
state-of-the-art baselines in forecasting next trading day stock trends across
three test periods spanning seven years. Datasets and code have been released
(https://github.com/pixelhero98/MGDPR).
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05431" title="Abstract">arXiv:2401.05431</a> (cross-list from eess.SP) [<a href="/pdf/2401.05431" title="Download PDF">pdf</a>, <a href="/format/2401.05431" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TRLS: A Time Series Representation Learning Framework via Spectrogram  for Medical Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Luyuan Xie</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C">Cong Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Zhai%2C+S">Shengfang Zhai</a>, 
<a href="/search/eess?searchtype=author&query=Fang%2C+Y">Yuejian Fang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Q">Qingni Shen</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhonghai Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accept by ICASSP 2024. This is a more detailed version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Representation learning frameworks in unlabeled time series have been
proposed for medical signal processing. Despite the numerous excellent
progresses have been made in previous works, we observe the representation
extracted for the time series still does not generalize well. In this paper, we
present a Time series (medical signal) Representation Learning framework via
Spectrogram (TRLS) to get more informative representations. We transform the
input time-domain medical signals into spectrograms and design a time-frequency
encoder named Time Frequency RNN (TFRNN) to capture more robust multi-scale
representations from the augmented spectrograms. Our TRLS takes spectrogram as
input with two types of different data augmentations and maximizes the
similarity between positive ones, which effectively circumvents the problem of
designing negative samples. Our evaluation of four real-world medical signal
datasets focusing on medical signal classification shows that TRLS is superior
to the existing frameworks.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05434" title="Abstract">arXiv:2401.05434</a> (cross-list from eess.SP) [<a href="/pdf/2401.05434" title="Download PDF">pdf</a>, <a href="/ps/2401.05434" title="Download PostScript">ps</a>, <a href="/format/2401.05434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECGformer: Leveraging transformer for ECG heartbeat arrhythmia  classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Akan%2C+T">Taymaz Akan</a>, 
<a href="/search/eess?searchtype=author&query=Alp%2C+S">Sait Alp</a>, 
<a href="/search/eess?searchtype=author&query=Bhuiyan%2C+M+A+N">Mohammad Alfrad Nobel Bhuiyan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">An arrhythmia, also known as a dysrhythmia, refers to an irregular heartbeat.
There are various types of arrhythmias that can originate from different areas
of the heart, resulting in either a rapid, slow, or irregular heartbeat. An
electrocardiogram (ECG) is a vital diagnostic tool used to detect heart
irregularities and abnormalities, allowing experts to analyze the heart's
electrical signals to identify intricate patterns and deviations from the norm.
Over the past few decades, numerous studies have been conducted to develop
automated methods for classifying heartbeats based on ECG data. In recent
years, deep learning has demonstrated exceptional capabilities in tackling
various medical challenges, particularly with transformers as a model
architecture for sequence processing. By leveraging the transformers, we
developed the ECGformer model for the classification of various arrhythmias
present in electrocardiogram data. We assessed the suggested approach using the
MIT-BIH and PTB datasets. ECG heartbeat arrhythmia classification results show
that the proposed method is highly effective.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05436" title="Abstract">arXiv:2401.05436</a> (cross-list from eess.SP) [<a href="/pdf/2401.05436" title="Download PDF">pdf</a>, <a href="/format/2401.05436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep OFDM Channel Estimation: Capturing Frequency Recurrence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jameel%2C+A+S+M+M">Abu Shafin Mohammad Mahdee Jameel</a>, 
<a href="/search/eess?searchtype=author&query=Malhotra%2C+A">Akshay Malhotra</a>, 
<a href="/search/eess?searchtype=author&query=Gamal%2C+A+E">Aly El Gamal</a>, 
<a href="/search/eess?searchtype=author&query=Hamidi-Rad%2C+S">Shahab Hamidi-Rad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In this paper, we propose a deep-learning-based channel estimation scheme in
an orthogonal frequency division multiplexing (OFDM) system. Our proposed
method, named Single Slot Recurrence Along Frequency Network (SisRafNet), is
based on a novel study of recurrent models for exploiting sequential behavior
of channels across frequencies. Utilizing the fact that wireless channels have
a high degree of correlation across frequencies, we employ recurrent neural
network techniques within a single OFDM slot, thus overcoming the latency and
memory constraints typically associated with recurrence based methods. The
proposed SisRafNet delivers superior estimation performance compared to
existing deep-learning-based channel estimation techniques and the performance
has been validated on a wide range of 3rd Generation Partnership Project (3GPP)
compliant channel scenarios at multiple signal-to-noise ratios.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05437" title="Abstract">arXiv:2401.05437</a> (cross-list from eess.SP) [<a href="/pdf/2401.05437" title="Download PDF">pdf</a>, <a href="/format/2401.05437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representation Learning for Wearable-Based Applications in the Case of  Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jungo%2C+J">Janosch Jungo</a>, 
<a href="/search/eess?searchtype=author&query=Xiang%2C+Y">Yutong Xiang</a>, 
<a href="/search/eess?searchtype=author&query=Gashi%2C+S">Shkurta Gashi</a>, 
<a href="/search/eess?searchtype=author&query=Holz%2C+C">Christian Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted in Human-Centric Representation Learning workshop at AAAI 2024 (<a href="https://hcrl-workshop.github.io/2024/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Wearable devices continuously collect sensor data and use it to infer an
individual's behavior, such as sleep, physical activity, and emotions. Despite
the significant interest and advancements in this field, modeling multimodal
sensor data in real-world environments is still challenging due to low data
quality and limited data annotations. In this work, we investigate
representation learning for imputing missing wearable data and compare it with
state-of-the-art statistical approaches. We investigate the performance of the
transformer model on 10 physiological and behavioral signals with different
masking ratios. Our results show that transformers outperform baselines for
missing data imputation of signals that change more frequently, but not for
monotonic signals. We further investigate the impact of imputation strategies
and masking rations on downstream classification tasks. Our study provides
insights for the design and development of masking-based self-supervised
learning tasks and advocates the adoption of hybrid-based imputation strategies
to address the challenge of missing data in wearable devices.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05440" title="Abstract">arXiv:2401.05440</a> (cross-list from eess.SP) [<a href="/pdf/2401.05440" title="Download PDF">pdf</a>, <a href="/format/2401.05440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autosen: improving automatic wifi human sensing through cross-modal  autoencoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gao%2C+Q">Qian Gao</a>, 
<a href="/search/eess?searchtype=author&query=Hao%2C+Y">Yanling Hao</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">WiFi human sensing is highly regarded for its low-cost and privacy advantages
in recognizing human activities. However, its effectiveness is largely confined
to controlled, single-user, line-of-sight settings, limited by data collection
complexities and the scarcity of labeled datasets. Traditional cross-modal
methods, aimed at mitigating these limitations by enabling self-supervised
learning without labeled data, struggle to extract meaningful features from
amplitude-phase combinations. In response, we introduce AutoSen, an innovative
automatic WiFi sensing solution that departs from conventional approaches.
AutoSen establishes a direct link between amplitude and phase through automated
cross-modal autoencoder learning. This autoencoder efficiently extracts
valuable features from unlabeled CSI data, encompassing amplitude and phase
information while eliminating their respective unique noises. These features
are then leveraged for specific tasks using few-shot learning techniques.
AutoSen's performance is rigorously evaluated on a publicly accessible
benchmark dataset, demonstrating its exceptional capabilities in automatic WiFi
sensing through the extraction of comprehensive cross-modal features.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05441" title="Abstract">arXiv:2401.05441</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.05441" title="Download PDF">pdf</a>, <a href="/ps/2401.05441" title="Download PostScript">ps</a>, <a href="/format/2401.05441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive network-based approach for advanced forecasting of  cryptocurrency values
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Mehrban%2C+A">Ali Mehrban</a>, 
<a href="/search/q-fin?searchtype=author&query=Ahadian%2C+P">Pegah Ahadian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Science and Information
  Technology (IJCSIT), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper describes an architecture for predicting the price of
cryptocurrencies for the next seven days using the Adaptive Network Based Fuzzy
Inference System (ANFIS). Historical data of cryptocurrencies and indexes that
are considered are Bitcoin (BTC), Ethereum (ETH), Bitcoin Dominance (BTC.D),
and Ethereum Dominance (ETH.D) in a daily timeframe. The methods used to teach
the data are hybrid and backpropagation algorithms, as well as grid partition,
subtractive clustering, and Fuzzy C-means clustering (FCM) algorithms, which
are used in data clustering. The architectural performance designed in this
paper has been compared with different inputs and neural network models in
terms of statistical evaluation criteria. Finally, the proposed method can
predict the price of digital currencies in a short time.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05446" title="Abstract">arXiv:2401.05446</a> (cross-list from eess.SP) [<a href="/pdf/2401.05446" title="Download PDF">pdf</a>, <a href="/format/2401.05446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Learning for Electroencephalogram: A Systematic Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Weng%2C+W">Weining Weng</a>, 
<a href="/search/eess?searchtype=author&query=Gu%2C+Y">Yang Gu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+S">Shuai Guo</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Y">Yuan Ma</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Z">Zhaohua Yang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yuchen Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Y">Yiqiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Electroencephalogram (EEG) is a non-invasive technique to record
bioelectrical signals. Integrating supervised deep learning techniques with EEG
signals has recently facilitated automatic analysis across diverse EEG-based
tasks. However, the label issues of EEG signals have constrained the
development of EEG-based deep models. Obtaining EEG annotations is difficult
that requires domain experts to guide collection and labeling, and the
variability of EEG signals among different subjects causes significant label
shifts. To solve the above challenges, self-supervised learning (SSL) has been
proposed to extract representations from unlabeled samples through
well-designed pretext tasks. This paper concentrates on integrating SSL
frameworks with temporal EEG signals to achieve efficient representation and
proposes a systematic review of the SSL for EEG signals. In this paper, 1) we
introduce the concept and theory of self-supervised learning and typical SSL
frameworks. 2) We provide a comprehensive review of SSL for EEG analysis,
including taxonomy, methodology, and technique details of the existing
EEG-based SSL frameworks, and discuss the difference between these methods. 3)
We investigate the adaptation of the SSL approach to various downstream tasks,
including the task description and related benchmark datasets. 4) Finally, we
discuss the potential directions for future SSL-EEG research.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05447" title="Abstract">arXiv:2401.05447</a> (cross-list from q-fin.ST) [<a href="/pdf/2401.05447" title="Download PDF">pdf</a>, <a href="/format/2401.05447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market  Wraps?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Lefort%2C+B">Baptiste Lefort</a>, 
<a href="/search/q-fin?searchtype=author&query=Benhamou%2C+E">Eric Benhamou</a>, 
<a href="/search/q-fin?searchtype=author&query=Ohana%2C+J">Jean-Jacques Ohana</a>, 
<a href="/search/q-fin?searchtype=author&query=Saltiel%2C+D">David Saltiel</a>, 
<a href="/search/q-fin?searchtype=author&query=Guez%2C+B">Beatrice Guez</a>, 
<a href="/search/q-fin?searchtype=author&query=Challet%2C+D">Damien Challet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to
2023, reposted on large financial media, to determine how global news headlines
may affect stock market movements using ChatGPT and a two-stage prompt
approach. We document a statistically significant positive correlation between
the sentiment score and future equity market returns over short to medium term,
which reverts to a negative correlation over longer horizons. Validation of
this correlation pattern across multiple equity markets indicates its
robustness across equity regions and resilience to non-linearity, evidenced by
comparison of Pearson and Spearman correlations. Finally, we provide an
estimate of the optimal horizon that strikes a balance between reactivity to
new information and correlation.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05452" title="Abstract">arXiv:2401.05452</a> (cross-list from eess.SP) [<a href="/pdf/2401.05452" title="Download PDF">pdf</a>, <a href="/format/2401.05452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cuff-less Arterial Blood Pressure Waveform Synthesis from Single-site  PPG using Transformer &amp; Frequency-domain Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tahir%2C+M+A">Muhammad Ahmad Tahir</a>, 
<a href="/search/eess?searchtype=author&query=Mehmood%2C+A">Ahsan Mehmood</a>, 
<a href="/search/eess?searchtype=author&query=Rahman%2C+M+M+U">Muhammad Mahboob Ur Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Nawaz%2C+M+W">Muhammad Wasim Nawaz</a>, 
<a href="/search/eess?searchtype=author&query=Riaz%2C+K">Kashif Riaz</a>, 
<a href="/search/eess?searchtype=author&query=Abbasi%2C+Q+H">Qammer H. Abbasi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 3 tables, submitted for review and potential publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose two novel purpose-built deep learning (DL) models for synthesis of
the arterial blood pressure (ABP) waveform in a cuff-less manner, using a
single-site photoplethysmography (PPG) signal. We utilize the public UCI
dataset on cuff-less blood pressure (CLBP) estimation to train and evaluate our
DL models. Firstly, we implement a transformer model that incorporates
positional encoding, multi-head attention, layer normalization, and dropout
techniques, and synthesizes the ABP waveform with a mean absolute error (MAE)
of 14. Secondly, we implement a frequency-domain (FD) learning approach where
we first obtain the discrete cosine transform (DCT) coefficients of the PPG and
ABP signals corresponding to two cardiac cycles, and then learn a
linear/non-linear (L/NL) regression between them. We learn that the FD L/NL
regression model outperforms the transformer model by achieving an MAE of 11.87
and 8.01, for diastolic blood pressure (DBP) and systolic blood pressure (SBP),
respectively. Our FD L/NL regression model also fulfills the AAMI criterion of
utilizing data from more than 85 subjects, and achieves grade B by the BHS
criterion.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05469" title="Abstract">arXiv:2401.05469</a> (cross-list from eess.SP) [<a href="/pdf/2401.05469" title="Download PDF">pdf</a>, <a href="/format/2401.05469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust CNN-based Respiration Rate Estimation for Smartwatch PPG and IMU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kazemi%2C+K">Kianoosh Kazemi</a>, 
<a href="/search/eess?searchtype=author&query=Azimi%2C+I">Iman Azimi</a>, 
<a href="/search/eess?searchtype=author&query=Liljeberg%2C+P">Pasi Liljeberg</a>, 
<a href="/search/eess?searchtype=author&query=Rahmani%2C+A+M">Amir M. Rahmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Respiratory rate (RR) serves as an indicator of various medical conditions,
such as cardiovascular diseases and sleep disorders. These RR estimation
methods were mostly designed for finger-based PPG collected from subjects in
stationary situations (e.g., in hospitals). In contrast to finger-based PPG
signals, wrist-based PPG are more susceptible to noise, particularly in their
low frequency range, which includes respiratory information. Therefore, the
existing methods struggle to accurately extract RR when PPG data are collected
from wrist area under free-living conditions. The increasing popularity of
smartwatches, equipped with various sensors including PPG, has prompted the
need for a robust RR estimation method. In this paper, we propose a
convolutional neural network-based approach to extract RR from PPG,
accelerometer, and gyroscope signals captured via smartwatches. Our method,
including a dilated residual inception module and 1D convolutions, extract the
temporal information from the signals, enabling RR estimation. Our method is
trained and tested using data collected from 36 subjects under free-living
conditions for one day using Samsung Gear Sport watches. For evaluation, we
compare the proposed method with four state-of-the-art RR estimation methods.
The RR estimates are compared with RR references obtained from a chest-band
device. The results show that our method outperforms the existing methods with
the Mean-Absolute-Error and Root-Mean-Square-Error of 1.85 and 2.34, while the
best results obtained by the other methods are 2.41 and 3.29, respectively.
Moreover, compared to the other methods, the absolute error distribution of our
method was narrow (with the lowest median), indicating a higher level of
agreement between the estimated and reference RR values.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05470" title="Abstract">arXiv:2401.05470</a> (cross-list from q-bio.PE) [<a href="/pdf/2401.05470" title="Download PDF">pdf</a>, <a href="/format/2401.05470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling Species Distributions with Deep Learning to Predict Plant  Extinction Risk and Assess Climate Change Impacts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Estopinan%2C+J">Joaquim Estopinan</a>, 
<a href="/search/q-bio?searchtype=author&query=Bonnet%2C+P">Pierre Bonnet</a>, 
<a href="/search/q-bio?searchtype=author&query=Servajean%2C+M">Maximilien Servajean</a>, 
<a href="/search/q-bio?searchtype=author&query=Munoz%2C+F">Fran&#xe7;ois Munoz</a>, 
<a href="/search/q-bio?searchtype=author&query=Joly%2C+A">Alexis Joly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures. Coda and data: <a href="https://github.com/estopinj/IUCN_classification">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Machine Learning (cs.LG); Applications (stat.AP)

</div>
<p class="mathjax">The post-2020 global biodiversity framework needs ambitious, research-based
targets. Estimating the accelerated extinction risk due to climate change is
critical. The International Union for Conservation of Nature (IUCN) measures
the extinction risk of species. Automatic methods have been developed to
provide information on the IUCN status of under-assessed taxa. However, these
compensatory methods are based on current species characteristics, mainly
geographical, which precludes their use in future projections. Here, we
evaluate a novel method for classifying the IUCN status of species benefiting
from the generalisation power of species distribution models based on deep
learning. Our method matches state-of-the-art classification performance while
relying on flexible SDM-based features that capture species' environmental
preferences. Cross-validation yields average accuracies of 0.61 for status
classification and 0.78 for binary classification. Climate change will reshape
future species distributions. Under the species-environment equilibrium
hypothesis, SDM projections approximate plausible future outcomes. Two extremes
of species dispersal capacity are considered: unlimited or null. The projected
species distributions are translated into features feeding our IUCN
classification method. Finally, trends in threatened species are analysed over
time and i) by continent and as a function of average ii) latitude or iii)
altitude. The proportion of threatened species is increasing globally, with
critical rates in Africa, Asia and South America. Furthermore, the proportion
of threatened species is predicted to peak around the two Tropics, at the
Equator, in the lowlands and at altitudes of 800-1,500 m.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05480" title="Abstract">arXiv:2401.05480</a> (cross-list from eess.SP) [<a href="/pdf/2401.05480" title="Download PDF">pdf</a>, <a href="/ps/2401.05480" title="Download PostScript">ps</a>, <a href="/format/2401.05480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PulsatioMech: An Open-Source MATLAB Toolbox for Seismocardiography  Signal Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zavanelli%2C+N">Nathan Zavanelli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Human-Computer Interaction (cs.HC); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">This paper summarizes and presents PulsatioMech: an open-source MATLAB
toolbox for seismocardiography (SCG) signal processing. The toolbox may be
found here: https://github.com/nzavanelli/SCG_master_toolbox PulsatioMech is
currently under development as a common tool to promote new studies and
discoveries in the use of cardiac mechanical signal for wearable health
monitoring. This toolbox is designed to assist users in analyzing SCG signals
without the need to devote significant effort into signal processing and coding
tasks. Simultaneously, it provides a uniform basis to assess the
reproducibility of works based on this toolbox, including those cited here
[1-6]. The referenced works contain a great deal more detail regarding the
specific algorithms implemented here, whereas this paper will present a short
overview of the PulsatioMech Toolbox.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05481" title="Abstract">arXiv:2401.05481</a> (cross-list from eess.IV) [<a href="/pdf/2401.05481" title="Download PDF">pdf</a>, <a href="/format/2401.05481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-CNN Fused Architecture for Enhanced Skin Lesion Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tiwari%2C+S">Siddharth Tiwari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The segmentation of medical images is important for the improvement and
creation of healthcare systems, particularly for early disease detection and
treatment planning. In recent years, the use of convolutional neural networks
(CNNs) and other state-of-the-art methods has greatly advanced medical image
segmentation. However, CNNs have been found to struggle with learning
long-range dependencies and capturing global context due to the limitations of
convolution operations. In this paper, we explore the use of transformers and
CNNs for medical image segmentation and propose a hybrid architecture that
combines the ability of transformers to capture global dependencies with the
ability of CNNs to capture low-level spatial details. We compare various
architectures and configurations and conduct multiple experiments to evaluate
their effectiveness.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05523" title="Abstract">arXiv:2401.05523</a> (cross-list from math.CO) [<a href="/pdf/2401.05523" title="Download PDF">pdf</a>, <a href="/ps/2401.05523" title="Download PostScript">ps</a>, <a href="/format/2401.05523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Number of Vertices/Edges whose Deletion Preserves the  Konig-Egervary Property
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Levit%2C+V+E">Vadim E. Levit</a>, 
<a href="/search/math?searchtype=author&query=Mandrescu%2C+E">Eugen Mandrescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">The graph G=(V,E) is called Konig-Egervary if the sum of its independence
number and its matching number equals its order. Let RV(G) denote the number of
vertices v such that G-v is Konig-Egervary, and let RE(G) denote the number of
edges e such that G-e is Konig-Egervary. Clearly, RV(G) = |V| and RE(G) = |E|
for bipartite graphs. Unlike the bipartiteness, the property of being a
Konig-Egervary graph is not hereditary. In this paper, we present an equality
expressing RV(G) in terms of some graph parameters, and a tight inequality
bounding RE(G) in terms of the same parameters, when G is Konig-Egervary.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05535" title="Abstract">arXiv:2401.05535</a> (cross-list from stat.ML) [<a href="/pdf/2401.05535" title="Download PDF">pdf</a>, <a href="/format/2401.05535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving the Accuracy and Interpretability of Random Forests via Forest  Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dorador%2C+A">Albert Dorador</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">Decades after their inception, random forests continue to provide
state-of-the-art accuracy in a variety of learning problems, outperforming in
this respect alternative machine learning algorithms such as decision trees or
even neural networks. However, being an ensemble method, the one aspect where
random forests tend to severely underperform decision trees is
interpretability. In the present work, we propose a post-hoc approach that aims
to have the best of both worlds: the accuracy of random forests and the
interpretability of decision trees. To this end, we present two forest-pruning
methods to find an optimal sub-forest within a given random forest, and then,
when applicable, combine the selected trees into one. Our first method relies
on constrained exhaustive search, while our second method is based on an
adaptation of the LASSO methodology. Extensive experiments over synthetic and
real world datasets show that, in the majority of scenarios, at least one of
the two methods proposed is more accurate than the original random forest,
while just using a small fraction of the trees, aiding result interpretability.
Compared to current state-of-the-art forestpruning methods, namely sequential
forward selection and (a variation of) sequential backward selection, our
methods tend to outperform both of them, whether in terms of accuracy, number
of trees employed, or both.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05568" title="Abstract">arXiv:2401.05568</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.05568" title="Download PDF">pdf</a>, <a href="/format/2401.05568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase discovery with active learning: Application to structural phase  transitions in equiatomic NiTi
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Vandermause%2C+J">Jonathan Vandermause</a>, 
<a href="/search/cond-mat?searchtype=author&query=Johansson%2C+A">Anders Johansson</a>, 
<a href="/search/cond-mat?searchtype=author&query=Miao%2C+Y">Yucong Miao</a>, 
<a href="/search/cond-mat?searchtype=author&query=Vlassak%2C+J+J">Joost J. Vlassak</a>, 
<a href="/search/cond-mat?searchtype=author&query=Kozinsky%2C+B">Boris Kozinsky</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Nickel titanium (NiTi) is a protypical shape-memory alloy used in a range of
biomedical and engineering devices, but direct molecular dynamics simulations
of the martensitic B19' -&gt; B2 phase transition driving its shape-memory
behavior are rare and have relied on classical force fields with limited
accuracy. Here, we train four machine-learned force fields for equiatomic NiTi
based on the LDA, PBE, PBEsol, and SCAN DFT functionals. The models are trained
on the fly during NPT molecular dynamics, with DFT calculations and model
updates performed automatically whenever the uncertainty of a local energy
prediction exceeds a chosen threshold. The models achieve accuracies of 1-2
meV/atom during training and are shown to closely track DFT predictions of B2
and B19' elastic constants and phonon frequencies. Surprisingly, in large-scale
molecular dynamics simulations, only the SCAN model predicts a reversible B19'
-&gt; B2 phase transition, with the LDA, PBE, and PBEsol models predicting a
reversible transition to a previously uncharacterized low-volume phase, which
we hypothesize to be a new stable high-pressure phase. We examine the structure
of the new phase and estimate its stability on the temperature-pressure phase
diagram. This work establishes an automated active learning protocol for
studying displacive transformations, reveals important differences between DFT
functionals that can only be detected in large-scale simulations, provides an
accurate force field for NiTi, and identifies a new phase.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05571" title="Abstract">arXiv:2401.05571</a> (cross-list from quant-ph) [<a href="/pdf/2401.05571" title="Download PDF">pdf</a>, <a href="/format/2401.05571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuantumSEA: In-Time Sparse Exploration for Noise Adaptive Quantum  Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+T">Tianlong Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+J">Jiaqi Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zirui Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pan%2C+D+Z">David Z. Pan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Han%2C+S">Song Han</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE International Conference on Quantum Computing and Engineering (QCE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Parameterized Quantum Circuits (PQC) have obtained increasing popularity
thanks to their great potential for near-term Noisy Intermediate-Scale Quantum
(NISQ) computers. Achieving quantum advantages usually requires a large number
of qubits and quantum circuits with enough capacity. However, limited coherence
time and massive quantum noises severely constrain the size of quantum circuits
that can be executed reliably on real machines. To address these two pain
points, we propose QuantumSEA, an in-time sparse exploration for noise-adaptive
quantum circuits, aiming to achieve two key objectives: (1) implicit circuits
capacity during training - by dynamically exploring the circuit's sparse
connectivity and sticking a fixed small number of quantum gates throughout the
training which satisfies the coherence time and enjoy light noises, enabling
feasible executions on real quantum devices; (2) noise robustness - by jointly
optimizing the topology and parameters of quantum circuits under real device
noise models. In each update step of sparsity, we leverage the moving average
of historical gradients to grow necessary gates and utilize salience-based
pruning to eliminate insignificant gates. Extensive experiments are conducted
with 7 Quantum Machine Learning (QML) and Variational Quantum Eigensolver (VQE)
benchmarks on 6 simulated or real quantum computers, where QuantumSEA
consistently surpasses noise-aware search, human-designed, and randomly
generated quantum circuit baselines by a clear performance margin. For example,
even in the most challenging on-chip training regime, our method establishes
state-of-the-art results with only half the number of quantum gates and ~2x
time saving of circuit executions. Codes are available at
https://github.com/VITA-Group/QuantumSEA.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05611" title="Abstract">arXiv:2401.05611</a> (cross-list from q-bio.PE) [<a href="/pdf/2401.05611" title="Download PDF">pdf</a>, <a href="/format/2401.05611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the existence of funneled orientations for classes of unrooted  phylogenetic networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=D%C3%B6cker%2C+J">Janosch D&#xf6;cker</a>, 
<a href="/search/q-bio?searchtype=author&query=Linz%2C+S">Simone Linz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Populations and Evolution (q-bio.PE)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Recently, there has been a growing interest in the relationships between
unrooted and rooted phylogenetic networks. In this context, a natural question
to ask is if an unrooted phylogenetic network U can be oriented as a rooted
phylogenetic network such that the latter satisfies certain structural
properties. In a recent preprint, Bulteau et al. claim that it is computational
hard to decide if U has a funneled (resp. funneled tree-child) orientation, for
when the internal vertices of U have degree at most 5. Unfortunately, the proof
of their funneled tree-child result appears to be incorrect. In this paper, we
present a corrected proof and show that hardness remains for other popular
classes of rooted phylogenetic networks such as funneled normal and funneled
reticulation-visible. Additionally, our results hold regardless of whether U is
rooted at an existing vertex or by subdividing an edge with the root.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05648" title="Abstract">arXiv:2401.05648</a> (cross-list from math.CO) [<a href="/pdf/2401.05648" title="Download PDF">pdf</a>, <a href="/ps/2401.05648" title="Download PostScript">ps</a>, <a href="/format/2401.05648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the on-line coloring of proper interval graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Curbelo%2C+I+R">Israel R. Curbelo</a>, 
<a href="/search/math?searchtype=author&query=Malko%2C+H+R">Hannah R. Malko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> On the on-line chain partitioning of semi-orders with proper interval representation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">We consider the on-line coloring problem restricted to proper interval graphs
with known interval representation. Chrobak and \'{S}lusarek (1981) showed that
the greedy $\textrm{First-Fit}$ algorithm has a strict competitive ratio of
$2$. It remains open whether there is an on-line algorithm that performs better
than $\textrm{First-Fit}$. Piotr (2008) showed that if the representation is
not known, there is no better on-line algorithm. Epstein and Levy (2005) showed
that no on-line algorithm has a strict competitive ratio less than $1.5$ when a
unit-interval representation is known, which was later improved to
$1.\overline{3}$. In this paper, we show that there is no on-line algorithm
with strict competitive ratio less than $1.75$ by presenting a strategy that
can force any on-line algorithm to use $7$ colors on a proper interval graph
$G$ with chromatic number $\chi(G)\leq 4$ and known interval representation.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05657" title="Abstract">arXiv:2401.05657</a> (cross-list from econ.TH) [<a href="/pdf/2401.05657" title="Download PDF">pdf</a>, <a href="/ps/2401.05657" title="Download PostScript">ps</a>, <a href="/format/2401.05657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The defensible set and a new impossibility theorem in voting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Holliday%2C+W+H">Wesley H. Holliday</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 table, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In the context of social choice theory with ordinal preferences, we say that
the defensible set is the set of alternatives $x$ such that for any alternative
$y$, if $y$ beats $x$ in a head-to-head majority comparison, then there is an
alternative $z$ that beats $y$ in a head-to-head majority comparison by a
margin at least as large as the margin by which $y$ beat $x$. We show that any
ordinal voting method satisfying two well-known axioms from voting
theory--positive involvement and the Condorcet winner criterion--refines the
defensible set. Using this lemma, we prove an impossibility theorem: there is
no such voting method that also satisfies the Condorcet loser criterion,
resolvability, and a common invariance property for Condorcet methods, namely
that the choice of winners depends only on the relative sizes of majority
margins.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05684" title="Abstract">arXiv:2401.05684</a> (cross-list from math.OC) [<a href="/pdf/2401.05684" title="Download PDF">pdf</a>, <a href="/format/2401.05684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Stirring Strategies for Passive Scalars in a Domain with a  General Shape and No-Flux Boundary Condition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhu%2C+S">Sirui Zhu</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Z">Zhi Lin</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+L">Liang Li</a>, 
<a href="/search/math?searchtype=author&query=Ding%2C+L">Lingyun Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Numerical Analysis (math.NA); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Multiscale metrics such as negative Sobolev norms are effective for
quantifying the degree of mixedness of a passive scalar field advected by an
incompressible flow in the absence of diffusion. In this paper we introduce a
mix norm that is motivated by Sobolev norm $H^{-1}$ for a general domain with a
no-flux boundary. We then derive an explicit expression for the optimal flow
that maximizes the instantaneous decay rate of the mix norm under fixed energy
and enstrophy constraints. Numerical simulations indicate that the mix norm
decays exponentially or faster for various initial conditions and geometries
and the rate is closely related to the smallest non-zero eigenvalue of the
Laplace operator. These results generalize previous findings restricted for a
periodic domain for its analytical and numerical simplicity. Additionally, we
observe that periodic boundaries tend to induce a faster decay in mix norm
compared to no-flux conditions under the fixed energy constraint, while the
comparison is reversed for the fixed enstrophy constraint. In the special case
of even initial distributions, two types of boundary conditions yield the same
optimal flow and mix norm decay.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05717" title="Abstract">arXiv:2401.05717</a> (cross-list from eess.AS) [<a href="/pdf/2401.05717" title="Download PDF">pdf</a>, <a href="/format/2401.05717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Boundary Detection via Class Entropy Measurements in  Connectionist Phoneme Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Salvi%2C+G">Giampiero Salvi</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Speech Communication Volume 48, Issue 12, December 2006, Pages
  1666-1676
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This article investigates the possibility to use the class entropy of the
output of a connectionist phoneme recogniser to predict time boundaries between
phonetic classes. The rationale is that the value of the entropy should
increase in proximity of a transition between two segments that are well
modelled (known) by the recognition network since it is a measure of
uncertainty. The advantage of this measure is its simplicity as the posterior
probabilities of each class are available in connectionist phoneme recognition.
The entropy and a number of measures based on differentiation of the entropy
are used in isolation and in combination. The decision methods for predicting
the boundaries range from simple thresholds to neural network based procedure.
The different methods are compared with respect to their precision, measured in
terms of the ratio between the number C of predicted boundaries within 10 or 20
msec of the reference and the total number of predicted boundaries, and recall,
measured as the ratio between C and the total number of reference boundaries.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05722" title="Abstract">arXiv:2401.05722</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2401.05722" title="Download PDF">pdf</a>, <a href="/format/2401.05722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Micromagnetic simulations of the size dependence of the Curie  temperature in ferromagnetic nanowires and nanolayers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Court%C3%A8s%2C+C">Cl&#xe9;mentine Court&#xe8;s</a>, 
<a href="/search/cond-mat?searchtype=author&query=Boileau%2C+M">Matthieu Boileau</a>, 
<a href="/search/cond-mat?searchtype=author&query=C%C3%B4te%2C+R">Rapha&#xeb;l C&#xf4;te</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hervieux%2C+P">Paul-Antoine Hervieux</a>, 
<a href="/search/cond-mat?searchtype=author&query=Manfredi%2C+G">Giovanni Manfredi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We solve the Landau-Lifshitz-Gilbert equation in the finite-temperature
regime, where thermal fluctuations are modeled by a random magnetic field whose
variance is proportional to the temperature. By rescaling the temperature
proportionally to the computational cell size $\Delta x$ ($T \to T\,\Delta
x/a_{\text{eff}}$, where $a_{\text{eff}}$ is the lattice constant) [M. B. Hahn,
J. Phys. Comm., 3:075009, 2019], we obtain Curie temperatures $T_{\text{C}}$
that are in line with the experimental values for cobalt, iron and nickel. For
finite-sized objects such as nanowires (1D) and nanolayers (2D), the Curie
temperature varies with the smallest size $d$ of the system. We show that the
difference between the computed finite-size $T_{\text{C}}$ and the bulk
$T_{\text{C}}$ follows a power-law of the type: $(\xi_0/d)^\lambda$, where
$\xi_0$ is the correlation length at zero temperature, and $\lambda$ is a
critical exponent. We obtain values of $\xi_0$ in the nanometer range, also in
accordance with other simulations and experiments. The computed critical
exponent is close to $\lambda=2$ for all considered materials and geometries.
This is the expected result for a mean-field approach, but slightly larger than
the values observed experimentally.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05765" title="Abstract">arXiv:2401.05765</a> (cross-list from stat.ML) [<a href="/pdf/2401.05765" title="Download PDF">pdf</a>, <a href="/format/2401.05765" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Selection for Functional Data Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Boschi%2C+T">Tobia Boschi</a>, 
<a href="/search/stat?searchtype=author&query=Bonin%2C+F">Francesca Bonin</a>, 
<a href="/search/stat?searchtype=author&query=Epperlein%2C+J">Jonathan Epperlein</a>, 
<a href="/search/stat?searchtype=author&query=Ordonez-Hurtado%2C+R">Rodrigo Ordonez-Hurtado</a>, 
<a href="/search/stat?searchtype=author&query=Pascale%2C+A">Alessandra Pascale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Functional data analysis has emerged as a crucial tool in many contemporary
scientific domains that require the integration and interpretation of complex
data. Moreover, the advent of new technologies has facilitated the collection
of a large number of longitudinal variables, making feature selection pivotal
for avoiding overfitting and improving prediction performance. This paper
introduces a novel methodology called FSFC (Feature Selection for Functional
Classification), that addresses the challenge of jointly performing feature
selection and classification of functional data in scenarios with categorical
responses and longitudinal features. Our approach tackles a newly defined
optimization problem that integrates logistic loss and functional features to
identify the most crucial features for classification. To address the
minimization procedure, we employ functional principal components and develop a
new adaptive version of the Dual Augmented Lagrangian algorithm that leverages
the sparsity structure of the problem for dimensionality reduction. The
computational efficiency of FSFC enables handling high-dimensional scenarios
where the number of features may considerably exceed the number of statistical
units. Simulation experiments demonstrate that FSFC outperforms other machine
learning and deep learning methods in computational time and classification
accuracy. Furthermore, the FSFC feature selection capability can be leveraged
to significantly reduce the problem's dimensionality and enhance the
performances of other classification algorithms. The efficacy of FSFC is also
demonstrated through a real data application, analyzing relationships between
four chronic diseases and other health and socio-demographic factors.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05809" title="Abstract">arXiv:2401.05809</a> (cross-list from eess.AS) [<a href="/pdf/2401.05809" title="Download PDF">pdf</a>, <a href="/ps/2401.05809" title="Download PostScript">ps</a>, <a href="/format/2401.05809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localizing Acoustic Energy in Sound Field Synthesis by Directionally  Weighted Exterior Radiation Suppression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tomita%2C+Y">Yoshihide Tomita</a>, 
<a href="/search/eess?searchtype=author&query=Koyama%2C+S">Shoichi Koyama</a>, 
<a href="/search/eess?searchtype=author&query=Saruwatari%2C+H">Hiroshi Saruwatari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">A method for synthesizing the desired sound field while suppressing the
exterior radiation power with directional weighting is proposed. The exterior
radiation from the loudspeakers in sound field synthesis systems can be
problematic in practical situations. Although several methods to suppress the
exterior radiation have been proposed, suppression in all outward directions is
generally difficult, especially when the number of loudspeakers is not
sufficiently large. We propose the directionally weighted exterior radiation
representation to prioritize the suppression directions by incorporating it
into the optimization problem of sound field synthesis. By using the proposed
representation, the exterior radiation in the prioritized directions can be
significantly reduced while maintaining high interior synthesis accuracy, owing
to the relaxed constraint on the exterior radiation. Its performance is
evaluated with the application of the proposed representation to amplitude
matching in numerical experiments.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05815" title="Abstract">arXiv:2401.05815</a> (cross-list from physics.acc-ph) [<a href="/pdf/2401.05815" title="Download PDF">pdf</a>, <a href="/format/2401.05815" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cheetah: Bridging the Gap Between Machine Learning and Particle  Accelerator Physics with High-Speed, Differentiable Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kaiser%2C+J">Jan Kaiser</a>, 
<a href="/search/physics?searchtype=author&query=Xu%2C+C">Chenran Xu</a>, 
<a href="/search/physics?searchtype=author&query=Eichler%2C+A">Annika Eichler</a>, 
<a href="/search/physics?searchtype=author&query=Garcia%2C+A+S">Andrea Santamaria Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 9 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Accelerator Physics (physics.acc-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Machine learning has emerged as a powerful solution to the modern challenges
in accelerator physics. However, the limited availability of beam time, the
computational cost of simulations, and the high-dimensionality of optimisation
problems pose significant challenges in generating the required data for
training state-of-the-art machine learning models. In this work, we introduce
Cheetah, a PyTorch-based high-speed differentiable linear-beam dynamics code.
Cheetah enables the fast collection of large data sets by reducing computation
times by multiple orders of magnitude and facilitates efficient gradient-based
optimisation for accelerator tuning and system identification. This positions
Cheetah as a user-friendly, readily extensible tool that integrates seamlessly
with widely adopted machine learning tools. We showcase the utility of Cheetah
through five examples, including reinforcement learning training,
gradient-based beamline tuning, gradient-based system identification,
physics-informed Bayesian optimisation priors, and modular neural network
surrogate modelling of space charge effects. The use of such a high-speed
differentiable simulation code will simplify the development of machine
learning-based methods for particle accelerators and fast-track their
integration into everyday operations of accelerator facilities.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05819" title="Abstract">arXiv:2401.05819</a> (cross-list from eess.SP) [<a href="/pdf/2401.05819" title="Download PDF">pdf</a>, <a href="/ps/2401.05819" title="Download PostScript">ps</a>, <a href="/format/2401.05819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAnet: A New Temporal Attention Network for EEG-based Auditory Spatial  Attention Decoding with a Short Decision Window
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ding%2C+Y">Yuting Ding</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+F">Fei Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Auditory spatial attention detection (ASAD) is used to determine the
direction of a listener's attention to a speaker by analyzing her/his
electroencephalographic (EEG) signals. This study aimed to further improve the
performance of ASAD with a short decision window (i.e., &lt;1 s) rather than with
long decision windows in previous studies. An end-to-end temporal attention
network (i.e., TAnet) was introduced in this work. TAnet employs a multi-head
attention (MHA) mechanism, which can more effectively capture the interactions
among time steps in collected EEG signals and efficiently assign corresponding
weights to those EEG time steps. Experiments demonstrated that, compared with
the CNN-based method and recent ASAD methods, TAnet provided improved decoding
performance in the KUL dataset, with decoding accuracies of 92.4% (decision
window 0.1 s), 94.9% (0.25 s), 95.1% (0.3 s), 95.4% (0.4 s), and 95.5% (0.5 s)
with short decision windows (i.e., &lt;1 s). As a new ASAD model with a short
decision window, TAnet can potentially facilitate the design of EEG-controlled
intelligent hearing aids and sound recognition systems.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05848" title="Abstract">arXiv:2401.05848</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.05848" title="Download PDF">pdf</a>, <a href="/format/2401.05848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pushing the Pareto front of band gap and permittivity: ML-guided search  for dielectric materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Riebesell%2C+J">Janosh Riebesell</a>, 
<a href="/search/cond-mat?searchtype=author&query=Surta%2C+T+W">T. Wesley Surta</a>, 
<a href="/search/cond-mat?searchtype=author&query=Goodall%2C+R">Rhys Goodall</a>, 
<a href="/search/cond-mat?searchtype=author&query=Gaultois%2C+M">Michael Gaultois</a>, 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+A+A">Alpha A Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 11 figures, 5 authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Chemical Physics (physics.chem-ph)

</div>
<p class="mathjax">Materials with high-dielectric constant easily polarize under external
electric fields, allowing them to perform essential functions in many modern
electronic devices. Their practical utility is determined by two conflicting
properties: high dielectric constants tend to occur in materials with narrow
band gaps, limiting the operating voltage before dielectric breakdown. We
present a high-throughput workflow that combines element substitution, ML
pre-screening, ab initio simulation and human expert intuition to efficiently
explore the vast space of unknown materials for potential dielectrics, leading
to the synthesis and characterization of two novel dielectric materials,
CsTaTeO6 and Bi2Zr2O7. Our key idea is to deploy ML in a multi-objective
optimization setting with concave Pareto front. While usually considered more
challenging than single-objective optimization, we argue and show preliminary
evidence that the $1/x$-correlation between band gap and permittivity in fact
makes the task more amenable to ML methods by allowing separate models for band
gap and permittivity to each operate in regions of good training support while
still predicting materials of exceptional merit. To our knowledge, this is the
first instance of successful ML-guided multi-objective materials optimization
achieving experimental synthesis and characterization. CsTaTeO6 is a structure
generated via element substitution not present in our reference data sources,
thus exemplifying successful de-novo materials design. Meanwhile, we report the
first high-purity synthesis and dielectric characterization of Bi2Zr2O7 with a
band gap of 2.27 eV and a permittivity of 20.5, meeting all target metrics of
our multi-objective search.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05916" title="Abstract">arXiv:2401.05916</a> (cross-list from eess.AS) [<a href="/pdf/2401.05916" title="Download PDF">pdf</a>, <a href="/format/2401.05916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Ambisonics encoding for compact irregular microphone arrays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Heikkinen%2C+M">Mikko Heikkinen</a>, 
<a href="/search/eess?searchtype=author&query=Politis%2C+A">Archontis Politis</a>, 
<a href="/search/eess?searchtype=author&query=Virtanen%2C+T">Tuomas Virtanen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Proceedings of the 2024 IEEE International Conference on Acoustics, Speech and Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Ambisonics encoding of microphone array signals can enable various spatial
audio applications, such as virtual reality or telepresence, but it is
typically designed for uniformly-spaced spherical microphone arrays. This paper
proposes a method for Ambisonics encoding that uses a deep neural network (DNN)
to estimate a signal transform from microphone inputs to Ambisonics signals.
The approach uses a DNN consisting of a U-Net structure with a learnable
preprocessing as well as a loss function consisting of mean average error,
spatial correlation, and energy preservation components. The method is
validated on two microphone arrays with regular and irregular shapes having
four microphones, on simulated reverberant scenes with multiple sources. The
results of the validation show that the proposed method can meet or exceed the
performance of a conventional signal-independent Ambisonics encoder on a number
of error metrics.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05918" title="Abstract">arXiv:2401.05918</a> (cross-list from math.DS) [<a href="/pdf/2401.05918" title="Download PDF">pdf</a>, <a href="/format/2401.05918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Embedding Approach to Multiple Games and Multiple  Populations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boll%2C+B">Bastian Boll</a>, 
<a href="/search/math?searchtype=author&query=Cassel%2C+J">Jonas Cassel</a>, 
<a href="/search/math?searchtype=author&query=Albers%2C+P">Peter Albers</a>, 
<a href="/search/math?searchtype=author&query=Petra%2C+S">Stefania Petra</a>, 
<a href="/search/math?searchtype=author&query=Schn%C3%B6rr%2C+C">Christoph Schn&#xf6;rr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Computer Science and Game Theory (cs.GT); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">This paper studies a meta-simplex concept and geometric embedding framework
for multi-population replicator dynamics. Central results are two embedding
theorems which constitute a formal reduction of multi-population replicator
dynamics to single-population ones. In conjunction with a robust mathematical
formalism, this provides a toolset for analyzing complex multi-population
models. Our framework provides a unifying perspective on different population
dynamics in the literature which in particular enables to establish a formal
link between multi-population and multi-game dynamics.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05938" title="Abstract">arXiv:2401.05938</a> (cross-list from math.CO) [<a href="/pdf/2401.05938" title="Download PDF">pdf</a>, <a href="/ps/2401.05938" title="Download PostScript">ps</a>, <a href="/format/2401.05938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subdivisions in dicritical digraphs with large order or digirth
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Picasarri-Arrieta%2C+L">Lucas Picasarri-Arrieta</a>, 
<a href="/search/math?searchtype=author&query=Rambaud%2C+C">Cl&#xe9;ment Rambaud</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">Aboulker et al. proved that a digraph with large enough dichromatic number
contains any fixed digraph as a subdivision. The dichromatic number of a
digraph is the smallest order of a partition of its vertex set into acyclic
induced subdigraphs. A digraph is dicritical if the removal of any arc or
vertex decreases its dichromatic number. In this paper we give sufficient
conditions on a dicritical digraph of large order or large directed girth to
contain a given digraph as a subdivision. In particular, we prove that (i) for
every integers $k,\ell$, large enough dicritical digraphs with dichromatic
number $k$ contain an orientation of a cycle with at least $\ell$ vertices;
(ii) there are functions $f,g$ such that for every subdivision $F^*$ of a
digraph $F$, digraphs with directed girth at least $f(F^*)$ and dichromatic
number at least $g(F)$ contain a subdivision of $F^*$, and if $F$ is a tree,
then $g(F)=|V(F)|$; (iii) there is a function $f$ such that for every
subdivision $F^*$ of $TT_3$ (the transitive tournament on three vertices),
digraphs with directed girth at least $f(F^*)$ and minimum out-degree at least
$2$ contain $F^*$ as a subdivision.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05972" title="Abstract">arXiv:2401.05972</a> (cross-list from physics.comp-ph) [<a href="/pdf/2401.05972" title="Download PDF">pdf</a>, <a href="/format/2401.05972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning physics-based reduced models from data for the  Hasegawa-Wakatani equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Gahr%2C+C">Constatin Gahr</a>, 
<a href="/search/physics?searchtype=author&query=Farcas%2C+I">Ionut-Gabriel Farcas</a>, 
<a href="/search/physics?searchtype=author&query=Jenko%2C+F">Frank Jenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 9 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG); Plasma Physics (physics.plasm-ph)

</div>
<p class="mathjax">This paper focuses on the construction of non-intrusive Scientific Machine
Learning (SciML) Reduced-Order Models (ROMs) for nonlinear, chaotic plasma
turbulence simulations. In particular, we propose using Operator Inference
(OpInf) to build low-cost physics-based ROMs from data for such simulations. As
a representative example, we focus on the Hasegawa-Wakatani (HW) equations used
for modeling two-dimensional electrostatic drift-wave plasma turbulence. For a
comprehensive perspective of the potential of OpInf to construct accurate ROMs
for this model, we consider a setup for the HW equations that leads to the
formation of complex, nonlinear, and self-driven dynamics, and perform two sets
of experiments. We first use the data obtained via a direct numerical
simulation of the HW equations starting from a specific initial condition and
train OpInf ROMs for predictions beyond the training time horizon. In the
second, more challenging set of experiments, we train ROMs using the same
dataset as before but this time perform predictions for six other initial
conditions. Our results show that the OpInf ROMs capture the important features
of the turbulent dynamics and generalize to new and unseen initial conditions
while reducing the evaluation time of the high-fidelity model by up to five
orders of magnitude in single-core performance. In the broader context of
fusion research, this shows that non-intrusive SciML ROMs have the potential to
drastically accelerate numerical studies, which can ultimately enable tasks
such as the design and real-time control of optimized fusion devices.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05982" title="Abstract">arXiv:2401.05982</a> (cross-list from stat.ML) [<a href="/pdf/2401.05982" title="Download PDF">pdf</a>, <a href="/ps/2401.05982" title="Download PostScript">ps</a>, <a href="/format/2401.05982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A tree-based varying coefficient model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zakrisson%2C+H">Henning Zakrisson</a>, 
<a href="/search/stat?searchtype=author&query=Lindholm%2C+M">Mathias Lindholm</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The paper introduces a tree-based varying coefficient model (VCM) where the
varying coefficients are modelled using the cyclic gradient boosting machine
(CGBM) from Delong et al. (2023). Modelling the coefficient functions using a
CGBM allows for dimension-wise early stopping and feature importance scores.
The dimension-wise early stopping not only reduces the risk of
dimension-specific overfitting, but also reveals differences in model
complexity across dimensions. The use of feature importance scores allows for
simple feature selection and easy model interpretation. The model is evaluated
on the same simulated and real data examples as those used in Richman and
W\"uthrich (2023), and the results show that it produces results in terms of
out of sample loss that are comparable to those of their neural network-based
VCM called LocalGLMnet.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06000" title="Abstract">arXiv:2401.06000</a> (cross-list from eess.SP) [<a href="/pdf/2401.06000" title="Download PDF">pdf</a>, <a href="/format/2401.06000" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Body-Area Capacitive or Electric Field Sensing for Human Activity  Recognition and Human-Computer Interaction: A Comprehensive Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bian%2C+S">Sizhen Bian</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengxi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+B">Bo Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lukowicz%2C+P">Paul Lukowicz</a>, 
<a href="/search/eess?searchtype=author&query=Magno%2C+M">Michele Magno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Due to the fact that roughly sixty percent of the human body is essentially
composed of water, the human body is inherently a conductive object, being able
to, firstly, form an inherent electric field from the body to the surroundings
and secondly, deform the distribution of an existing electric field near the
body. Body-area capacitive sensing, also called body-area electric field
sensing, is becoming a promising alternative for wearable devices to accomplish
certain tasks in human activity recognition and human-computer interaction.
Over the last decade, researchers have explored plentiful novel sensing systems
backed by the body-area electric field. On the other hand, despite the
pervasive exploration of the body-area electric field, a comprehensive survey
does not exist for an enlightening guideline. Moreover, the various hardware
implementations, applied algorithms, and targeted applications result in a
challenging task to achieve a systematic overview of the subject. This paper
aims to fill in the gap by comprehensively summarizing the existing works on
body-area capacitive sensing so that researchers can have a better view of the
current exploration status. To this end, we first sorted the explorations into
three domains according to the involved body forms: body-part electric field,
whole-body electric field, and body-to-body electric field, and enumerated the
state-of-art works in the domains with a detailed survey of the backed sensing
tricks and targeted applications. We then summarized the three types of sensing
frontends in circuit design, which is the most critical part in body-area
capacitive sensing, and analyzed the data processing pipeline categorized into
three kinds of approaches. Finally, we described the challenges and outlooks of
body-area electric sensing.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06005" title="Abstract">arXiv:2401.06005</a> (cross-list from q-bio.NC) [<a href="/pdf/2401.06005" title="Download PDF">pdf</a>, <a href="/format/2401.06005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How does the primate brain combine generative and discriminative  computations in vision?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Peters%2C+B">Benjamin Peters</a>, 
<a href="/search/q-bio?searchtype=author&query=DiCarlo%2C+J+J">James J. DiCarlo</a>, 
<a href="/search/q-bio?searchtype=author&query=Gureckis%2C+T">Todd Gureckis</a>, 
<a href="/search/q-bio?searchtype=author&query=Haefner%2C+R">Ralf Haefner</a>, 
<a href="/search/q-bio?searchtype=author&query=Isik%2C+L">Leyla Isik</a>, 
<a href="/search/q-bio?searchtype=author&query=Tenenbaum%2C+J">Joshua Tenenbaum</a>, 
<a href="/search/q-bio?searchtype=author&query=Konkle%2C+T">Talia Konkle</a>, 
<a href="/search/q-bio?searchtype=author&query=Naselaris%2C+T">Thomas Naselaris</a>, 
<a href="/search/q-bio?searchtype=author&query=Stachenfeld%2C+K">Kimberly Stachenfeld</a>, 
<a href="/search/q-bio?searchtype=author&query=Tavares%2C+Z">Zenna Tavares</a>, 
<a href="/search/q-bio?searchtype=author&query=Tsao%2C+D">Doris Tsao</a>, 
<a href="/search/q-bio?searchtype=author&query=Yildirim%2C+I">Ilker Yildirim</a>, 
<a href="/search/q-bio?searchtype=author&query=Kriegeskorte%2C+N">Nikolaus Kriegeskorte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Vision is widely understood as an inference problem. However, two contrasting
conceptions of the inference process have each been influential in research on
biological vision as well as the engineering of machine vision. The first
emphasizes bottom-up signal flow, describing vision as a largely feedforward,
discriminative inference process that filters and transforms the visual
information to remove irrelevant variation and represent behaviorally relevant
information in a format suitable for downstream functions of cognition and
behavioral control. In this conception, vision is driven by the sensory data,
and perception is direct because the processing proceeds from the data to the
latent variables of interest. The notion of "inference" in this conception is
that of the engineering literature on neural networks, where feedforward
convolutional neural networks processing images are said to perform inference.
The alternative conception is that of vision as an inference process in
Helmholtz's sense, where the sensory evidence is evaluated in the context of a
generative model of the causal processes giving rise to it. In this conception,
vision inverts a generative model through an interrogation of the evidence in a
process often thought to involve top-down predictions of sensory data to
evaluate the likelihood of alternative hypotheses. The authors include
scientists rooted in roughly equal numbers in each of the conceptions and
motivated to overcome what might be a false dichotomy between them and engage
the other perspective in the realm of theory and experiment. The primate brain
employs an unknown algorithm that may combine the advantages of both
conceptions. We explain and clarify the terminology, review the key empirical
evidence, and propose an empirical research program that transcends the
dichotomy and sets the stage for revealing the mysterious hybrid algorithm of
primate vision.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06070" title="Abstract">arXiv:2401.06070</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2401.06070" title="Download PDF">pdf</a>, <a href="/format/2401.06070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Peridynamic Neural Operators: A Data-Driven Nonlocal Constitutive Model  for Complex Material Responses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Jafarzadeh%2C+S">Siavash Jafarzadeh</a>, 
<a href="/search/cond-mat?searchtype=author&query=Silling%2C+S">Stewart Silling</a>, 
<a href="/search/cond-mat?searchtype=author&query=Liu%2C+N">Ning Liu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+Z">Zhongqiang Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yu%2C+Y">Yue Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural operators, which can act as implicit solution operators of hidden
governing equations, have recently become popular tools for learning the
responses of complex real-world physical systems. Nevertheless, most neural
operator applications have thus far been data-driven and neglect the intrinsic
preservation of fundamental physical laws in data. In this work, we introduce a
novel integral neural operator architecture called the Peridynamic Neural
Operator (PNO) that learns a nonlocal constitutive law from data. This neural
operator provides a forward model in the form of state-based peridynamics, with
objectivity and momentum balance laws automatically guaranteed. As
applications, we demonstrate the expressivity and efficacy of our model in
learning complex material behaviors from both synthetic and experimental data
sets. We show that, owing to its ability to capture complex responses, our
learned neural operator achieves improved accuracy and efficiency compared to
baseline models that use predefined constitutive laws. Moreover, by preserving
the essential physical laws within the neural network architecture, the PNO is
robust in treating noisy data. The method shows generalizability to different
domain configurations, external loadings, and discretizations.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06085" title="Abstract">arXiv:2401.06085</a> (cross-list from math.CO) [<a href="/pdf/2401.06085" title="Download PDF">pdf</a>, <a href="/ps/2401.06085" title="Download PostScript">ps</a>, <a href="/format/2401.06085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the stabilizer of the graph of linear functions over finite fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Smaldore%2C+V">Valentino Smaldore</a>, 
<a href="/search/math?searchtype=author&query=Zanella%2C+C">Corrado Zanella</a>, 
<a href="/search/math?searchtype=author&query=Zullo%2C+F">Ferdinando Zullo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper we will study the action of $\mathbb{F}_{q^n}^{2 \times 2}$ on
the graph of an $\mathbb{F}_q$-linear function of $\mathbb{F}_{q^n}$ into
itself. In particular we will see that, under certain combinatorial
assumptions, its stabilizer (together with the sum and product of matrices) is
a field. We will also see some examples for which this does not happen.
Moreover, we will establish a connection between such a stabilizer and the
right idealizer of the rank-metric code defined by the linear function and give
some structural results in the case in which the polynomials are partially
scattered.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.06098" title="Abstract">arXiv:2401.06098</a> (cross-list from math.OC) [<a href="/pdf/2401.06098" title="Download PDF">pdf</a>, <a href="/format/2401.06098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proximal observers for secure state estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bako%2C+L">Laurent Bako</a>, 
<a href="/search/math?searchtype=author&query=Nadri%2C+M">Madiha Nadri</a>, 
<a href="/search/math?searchtype=author&query=Andrieu%2C+V">Vincent Andrieu</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Q">Qinghua Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper discusses a general framework for designing robust state
estimators for a class of discrete-time nonlinear systems. We consider systems
that may be impacted by impulsive (sparse but otherwise arbitrary) measurement
noise sequences. We show that a family of state estimators, robust to this type
of undesired signal, can be obtained by minimizing a class of nonsmooth convex
functions at each time step. The resulting state observers are defined through
proximal operators. We obtain a nonlinear implicit dynamical system in term of
estimation error and prove, in the noise-free setting, that it vanishes
asymptotically when the minimized loss function and the to-beobserved system
enjoy appropriate properties. From a computational perspective, even though the
proposed observers can be implemented via efficient numerical procedures, they
do not admit closed-form expressions. The paper argues that by adopting
appropriate relaxations, simple and fast analytic expressions can be derived.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Fri, 12 Jan 24</h3>
<dl>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1701.08338" title="Abstract">arXiv:1701.08338</a> (replaced) [<a href="/pdf/1701.08338" title="Download PDF">pdf</a>, <a href="/ps/1701.08338" title="Download PostScript">ps</a>, <a href="/format/1701.08338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parameter and State Estimation in Queues and Related Stochastic Models:  A Bibliography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Asanjarani%2C+A">Azam Asanjarani</a>, 
<a href="/search/math?searchtype=author&query=Nazarathy%2C+Y">Yoni Nazarathy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1804.02917" title="Abstract">arXiv:1804.02917</a> (replaced) [<a href="/pdf/1804.02917" title="Download PDF">pdf</a>, <a href="/ps/1804.02917" title="Download PostScript">ps</a>, <a href="/format/1804.02917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sublinear-Time Quantum Computation of the Diameter in CONGEST Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gall%2C+F+L">Fran&#xe7;ois Le Gall</a>, 
<a href="/search/cs?searchtype=author&query=Magniez%2C+F">Fr&#xe9;d&#xe9;ric Magniez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages; preliminary version in PODC 2018. Minor typos in the previous version: $\log(1/\delta)$ should not appear within a square root in Theorem 6, Corollary 1, and Theorem 7
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 37th ACM Symposium on Principles of Distributed
  Computing (PODC 2018), pp. 337-346, 2018
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Data Structures and Algorithms (cs.DS); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.00911" title="Abstract">arXiv:2010.00911</a> (replaced) [<a href="/pdf/2010.00911" title="Download PDF">pdf</a>, <a href="/format/2010.00911" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proving Highly-Concurrent Traversals Correct
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feldman%2C+Y+M+Y">Yotam M. Y. Feldman</a>, 
<a href="/search/cs?searchtype=author&query=Khyzha%2C+A">Artem Khyzha</a>, 
<a href="/search/cs?searchtype=author&query=Enea%2C+C">Constantin Enea</a>, 
<a href="/search/cs?searchtype=author&query=Morrison%2C+A">Adam Morrison</a>, 
<a href="/search/cs?searchtype=author&query=Nanevski%2C+A">Aleksandar Nanevski</a>, 
<a href="/search/cs?searchtype=author&query=Rinetzky%2C+N">Noam Rinetzky</a>, 
<a href="/search/cs?searchtype=author&query=Shoham%2C+S">Sharon Shoham</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of a paper appearing in OOPSLA'20
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.10394" title="Abstract">arXiv:2101.10394</a> (replaced) [<a href="/pdf/2101.10394" title="Download PDF">pdf</a>, <a href="/format/2101.10394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Network Topology of Multi-Agent Systems subject to Computation  and Communication Latency (with proofs)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ballotta%2C+L">Luca Ballotta</a>, 
<a href="/search/eess?searchtype=author&query=Jovanovi%C4%87%2C+M+R">Mihailo R. Jovanovi&#x107;</a>, 
<a href="/search/eess?searchtype=author&query=Schenato%2C+L">Luca Schenato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures; MED 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.04856" title="Abstract">arXiv:2106.04856</a> (replaced) [<a href="/pdf/2106.04856" title="Download PDF">pdf</a>, <a href="/format/2106.04856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strongly Sublinear Algorithms for Testing Pattern Freeness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Newman%2C+I">Ilan Newman</a>, 
<a href="/search/cs?searchtype=author&query=Varma%2C+N">Nithin Varma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 2 figures; We thank anonymous reviewers for comments that helped us significantly improve the presentation
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TheoretiCS, Volume 3 (2024), Article 1, 1-39
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.09820" title="Abstract">arXiv:2112.09820</a> (replaced) [<a href="/pdf/2112.09820" title="Download PDF">pdf</a>, <a href="/ps/2112.09820" title="Download PostScript">ps</a>, <a href="/format/2112.09820" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPEX, A Framework For Interpreting Artificial Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akbarnejad%2C+A">Amir Akbarnejad</a>, 
<a href="/search/cs?searchtype=author&query=Bigras%2C+G">Gilbert Bigras</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+N">Nilanjan Ray</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09123" title="Abstract">arXiv:2202.09123</a> (replaced) [<a href="/pdf/2202.09123" title="Download PDF">pdf</a>, <a href="/format/2202.09123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Every Word Count: Adaptive BA with Fewer Words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cohen%2C+S">Shir Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Keidar%2C+I">Idit Keidar</a>, 
<a href="/search/cs?searchtype=author&query=Spiegelman%2C+A">Alexander Spiegelman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.09438" title="Abstract">arXiv:2203.09438</a> (replaced) [<a href="/pdf/2203.09438" title="Download PDF">pdf</a>, <a href="/format/2203.09438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable Stacked Ensemble Model for Static Route-Free Estimation  of Time of Arrival
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schleibaum%2C+S">S&#xf6;ren Schleibaum</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+J+P">J&#xf6;rg P. M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Sester%2C+M">Monika Sester</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.16810" title="Abstract">arXiv:2203.16810</a> (replaced) [<a href="/pdf/2203.16810" title="Download PDF">pdf</a>, <a href="/format/2203.16810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Estimation of Random Vectors with Bandit Feedback: A  mean-squared error viewpoint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+D">Dipayan Sen</a>, 
<a href="/search/cs?searchtype=author&query=Prashanth%2C+L+A">L.A. Prashanth</a>, 
<a href="/search/cs?searchtype=author&query=Gopalan%2C+A">Aditya Gopalan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.12926" title="Abstract">arXiv:2204.12926</a> (replaced) [<a href="/pdf/2204.12926" title="Download PDF">pdf</a>, <a href="/ps/2204.12926" title="Download PostScript">ps</a>, <a href="/format/2204.12926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong rate of convergence of the Euler scheme for SDEs with irregular  drift driven by Levy noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Butkovsky%2C+O">Oleg Butkovsky</a>, 
<a href="/search/math?searchtype=author&query=Dareiotis%2C+K">Konstantinos Dareiotis</a>, 
<a href="/search/math?searchtype=author&query=Gerencs%C3%A9r%2C+M">M&#xe1;t&#xe9; Gerencs&#xe9;r</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.13538" title="Abstract">arXiv:2204.13538</a> (replaced) [<a href="/pdf/2204.13538" title="Download PDF">pdf</a>, <a href="/format/2204.13538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Correlation Bound and Construction of Quasi-Complementary Code Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+P">Palash Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunlei Li</a>, 
<a href="/search/cs?searchtype=author&query=Majhi%2C+S">Sudhan Majhi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zilong Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.02692" title="Abstract">arXiv:2205.02692</a> (replaced) [<a href="/pdf/2205.02692" title="Download PDF">pdf</a>, <a href="/format/2205.02692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gait Recognition in the Wild: A Large-scale Benchmark and NAS-based  Baseline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xianda Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+B">Beibei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junjie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiankang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of our ICCV 2021 work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.03449" title="Abstract">arXiv:2206.03449</a> (replaced) [<a href="/pdf/2206.03449" title="Download PDF">pdf</a>, <a href="/format/2206.03449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The virtual element method on polygonal pixel-based tessellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bertoluzza%2C+S">Silvia Bertoluzza</a>, 
<a href="/search/math?searchtype=author&query=Montardini%2C+M">Monica Montardini</a>, 
<a href="/search/math?searchtype=author&query=Pennacchio%2C+M">Micol Pennacchio</a>, 
<a href="/search/math?searchtype=author&query=Prada%2C+D">Daniele Prada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.05289" title="Abstract">arXiv:2206.05289</a> (replaced) [<a href="/pdf/2206.05289" title="Download PDF">pdf</a>, <a href="/format/2206.05289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Localized adversarial artifacts for compressed sensing MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Alaifari%2C+R">Rima Alaifari</a>, 
<a href="/search/eess?searchtype=author&query=Alberti%2C+G+S">Giovanni S. Alberti</a>, 
<a href="/search/eess?searchtype=author&query=Gauksson%2C+T">Tandri Gauksson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIAM Journal on Imaging Sciences, 16(4):SC14-SC26, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.07210" title="Abstract">arXiv:2206.07210</a> (replaced) [<a href="/pdf/2206.07210" title="Download PDF">pdf</a>, <a href="/format/2206.07210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Words: An Experimental Study of Signaling in Crowdfunding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dambanemuya%2C+H+K">Henry K. Dambanemuya</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+E">Eunseo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Gergle%2C+D">Darren Gergle</a>, 
<a href="/search/cs?searchtype=author&query=Horv%C3%A1t%2C+E">Em&#x151;ke-&#xc1;gnes Horv&#xe1;t</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06488" title="Abstract">arXiv:2208.06488</a> (replaced) [<a href="/pdf/2208.06488" title="Download PDF">pdf</a>, <a href="/format/2208.06488" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The planted XY model: thermodynamics and inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Chen%2C+S">Siyu Chen</a>, 
<a href="/search/cond-mat?searchtype=author&query=Huang%2C+G">Guanhao Huang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Piccioli%2C+G">Giovanni Piccioli</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zdeborov%C3%A1%2C+L">Lenka Zdeborov&#xe1;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. E 106, 054115 (2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Information Retrieval (cs.IR); Probability (math.PR); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08626" title="Abstract">arXiv:2208.08626</a> (replaced) [<a href="/pdf/2208.08626" title="Download PDF">pdf</a>, <a href="/format/2208.08626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural  Networks with Total-Variation Penalty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dong%2C+Z">Zhikang Dong</a>, 
<a href="/search/stat?searchtype=author&query=Polak%2C+P">Pawel Polak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14919" title="Abstract">arXiv:2208.14919</a> (replaced) [<a href="/pdf/2208.14919" title="Download PDF">pdf</a>, <a href="/format/2208.14919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ARMA Cell: A Modular and Effective Approach for Neural Autoregressive  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schiele%2C+P">Philipp Schiele</a>, 
<a href="/search/cs?searchtype=author&query=Berninger%2C+C">Christoph Berninger</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCgamer%2C+D">David R&#xfc;gamer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.04847" title="Abstract">arXiv:2209.04847</a> (replaced) [<a href="/pdf/2209.04847" title="Download PDF">pdf</a>, <a href="/format/2209.04847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Lossy Plus Residual Coding for Lossless and Near-lossless Image  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bai%2C+Y">Yuanchao Bai</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xianming Liu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+K">Kai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+X">Xiangyang Ji</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xiaolin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+W">Wen Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> manuscript accepted by TPAMI, source code:<a href="https://github.com/BYchao100/Deep-Lossy-Plus-Residual-Coding">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05758" title="Abstract">arXiv:2209.05758</a> (replaced) [<a href="/pdf/2209.05758" title="Download PDF">pdf</a>, <a href="/format/2209.05758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A stochastic approach to delays optimization for narrowband transmit  beam pattern in medical ultrasound
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Razzetta%2C+C">Chiara Razzetta</a>, 
<a href="/search/math?searchtype=author&query=Candiani%2C+V">Valentina Candiani</a>, 
<a href="/search/math?searchtype=author&query=Crocco%2C+M">Marco Crocco</a>, 
<a href="/search/math?searchtype=author&query=Benvenuto%2C+F">Federico Benvenuto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Signal Processing (eess.SP); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08159" title="Abstract">arXiv:2210.08159</a> (replaced) [<a href="/pdf/2210.08159" title="Download PDF">pdf</a>, <a href="/format/2210.08159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamics-aware Adversarial Attack of Adaptive Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+A">An Tao</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yueqi Duan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yingqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiwen Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jie Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2112.09428">arXiv:2112.09428</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Circuits and Systems for Video Technology,
  2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05494" title="Abstract">arXiv:2211.05494</a> (replaced) [<a href="/pdf/2211.05494" title="Download PDF">pdf</a>, <a href="/format/2211.05494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two conjectures on the Stokes complex in three dimensions on Freudenthal  meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Farrell%2C+P+E">Patrick E. Farrell</a>, 
<a href="/search/math?searchtype=author&query=Mitchell%2C+L">Lawrence Mitchell</a>, 
<a href="/search/math?searchtype=author&query=Scott%2C+L+R">L. Ridgway Scott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16162" title="Abstract">arXiv:2211.16162</a> (replaced) [<a href="/pdf/2211.16162" title="Download PDF">pdf</a>, <a href="/format/2211.16162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Hierarchical Over-the-Air Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azimi-Abarghouyi%2C+S+M">Seyed Mohammad Azimi-Abarghouyi</a>, 
<a href="/search/cs?searchtype=author&query=Fodor%2C+V">Viktoria Fodor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE Transactions on Wireless Communications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01354" title="Abstract">arXiv:2212.01354</a> (replaced) [<a href="/pdf/2212.01354" title="Download PDF">pdf</a>, <a href="/format/2212.01354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Ecosystems of Intelligence from First Principles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Friston%2C+K+J">Karl J Friston</a>, 
<a href="/search/cs?searchtype=author&query=Ramstead%2C+M+J+D">Maxwell J D Ramstead</a>, 
<a href="/search/cs?searchtype=author&query=Kiefer%2C+A+B">Alex B Kiefer</a>, 
<a href="/search/cs?searchtype=author&query=Tschantz%2C+A">Alexander Tschantz</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+C+L">Christopher L Buckley</a>, 
<a href="/search/cs?searchtype=author&query=Albarracin%2C+M">Mahault Albarracin</a>, 
<a href="/search/cs?searchtype=author&query=Pitliya%2C+R+J">Riddhi J Pitliya</a>, 
<a href="/search/cs?searchtype=author&query=Heins%2C+C">Conor Heins</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+B">Brennan Klein</a>, 
<a href="/search/cs?searchtype=author&query=Millidge%2C+B">Beren Millidge</a>, 
<a href="/search/cs?searchtype=author&query=Sakthivadivel%2C+D+A+R">Dalton A R Sakthivadivel</a>, 
<a href="/search/cs?searchtype=author&query=Smithe%2C+T+S+C">Toby St Clere Smithe</a>, 
<a href="/search/cs?searchtype=author&query=Koudahl%2C+M">Magnus Koudahl</a>, 
<a href="/search/cs?searchtype=author&query=Tremblay%2C+S+E">Safae Essafi Tremblay</a>, 
<a href="/search/cs?searchtype=author&query=Petersen%2C+C">Capm Petersen</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+K">Kaiser Fung</a>, 
<a href="/search/cs?searchtype=author&query=Fox%2C+J+G">Jason G Fox</a>, 
<a href="/search/cs?searchtype=author&query=Swanson%2C+S">Steven Swanson</a>, 
<a href="/search/cs?searchtype=author&query=Mapes%2C+D">Dan Mapes</a>, 
<a href="/search/cs?searchtype=author&query=Ren%C3%A9%2C+G">Gabriel Ren&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23+18 pages, one figure, one six page appendix
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Collective Intelligence, 3(1), 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Multiagent Systems (cs.MA); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08674" title="Abstract">arXiv:2212.08674</a> (replaced) [<a href="/pdf/2212.08674" title="Download PDF">pdf</a>, <a href="/format/2212.08674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An unfolding method based on conditional Invertible Neural Networks  (cINN) using iterative training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Backes%2C+M">Mathias Backes</a>, 
<a href="/search/hep-ph?searchtype=author&query=Butter%2C+A">Anja Butter</a>, 
<a href="/search/hep-ph?searchtype=author&query=Dunford%2C+M">Monica Dunford</a>, 
<a href="/search/hep-ph?searchtype=author&query=Malaescu%2C+B">Bogdan Malaescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08839" title="Abstract">arXiv:2212.08839</a> (replaced) [<a href="/pdf/2212.08839" title="Download PDF">pdf</a>, <a href="/ps/2212.08839" title="Download PostScript">ps</a>, <a href="/format/2212.08839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of the tamed-Euler-Maruyama method for SDEs with  discontinuous and polynomially growing drift
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Spendier%2C+K">Kathrin Spendier</a>, 
<a href="/search/math?searchtype=author&query=Sz%C3%B6lgyenyi%2C+M">Michaela Sz&#xf6;lgyenyi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.09260" title="Abstract">arXiv:2212.09260</a> (replaced) [<a href="/pdf/2212.09260" title="Download PDF">pdf</a>, <a href="/format/2212.09260" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Marginal Probability-Based Integer Handling for CMA-ES Tackling  Single-and Multi-Objective Mixed-Integer Black-Box Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamano%2C+R">Ryoki Hamano</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+S">Shota Saito</a>, 
<a href="/search/cs?searchtype=author&query=Nomura%2C+M">Masahiro Nomura</a>, 
<a href="/search/cs?searchtype=author&query=Shirakawa%2C+S">Shinichi Shirakawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera-ready version for ACM Transactions on Evolutionary Learning and Optimization (TELO). This paper is an extended version of the work presented in <a href="/abs/2205.13482">arXiv:2205.13482</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.13023" title="Abstract">arXiv:2212.13023</a> (replaced) [<a href="/pdf/2212.13023" title="Download PDF">pdf</a>, <a href="/format/2212.13023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Continuous Sign Language Recognition with Consistency  Constraints and Signer Removal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zuo%2C+R">Ronglai Zuo</a>, 
<a href="/search/cs?searchtype=author&query=Mak%2C+B">Brian Mak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM TOMM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08898" title="Abstract">arXiv:2301.08898</a> (replaced) [<a href="/pdf/2301.08898" title="Download PDF">pdf</a>, <a href="/format/2301.08898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recurrent Generic Contour-based Instance Segmentation with Progressive  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+H">Hao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Keyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wengang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Y">Yufei Yin</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jiajun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Houqiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10642" title="Abstract">arXiv:2301.10642</a> (replaced) [<a href="/pdf/2301.10642" title="Download PDF">pdf</a>, <a href="/format/2301.10642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Group fairness in dynamic refugee assignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freund%2C+D">Daniel Freund</a>, 
<a href="/search/cs?searchtype=author&query=Lykouris%2C+T">Thodoris Lykouris</a>, 
<a href="/search/cs?searchtype=author&query=Paulson%2C+E">Elisabeth Paulson</a>, 
<a href="/search/cs?searchtype=author&query=Sturt%2C+B">Bradley Sturt</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+W">Wentao Weng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13148" title="Abstract">arXiv:2301.13148</a> (replaced) [<a href="/pdf/2301.13148" title="Download PDF">pdf</a>, <a href="/format/2301.13148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realistic pattern formations on surfaces by adding arbitrary roughness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+S">Siqing Li</a>, 
<a href="/search/math?searchtype=author&query=Ling%2C+L">Leevan Ling</a>, 
<a href="/search/math?searchtype=author&query=Ruuth%2C+S+J">Steven J. Ruuth</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xuemeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.13330" title="Abstract">arXiv:2301.13330</a> (replaced) [<a href="/pdf/2301.13330" title="Download PDF">pdf</a>, <a href="/format/2301.13330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and Effective Methods for Mixed Precision Neural Network  Quantization for Faster, Energy-efficient Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bablani%2C+D">Deepika Bablani</a>, 
<a href="/search/cs?searchtype=author&query=Mckinstry%2C+J+L">Jeffrey L. Mckinstry</a>, 
<a href="/search/cs?searchtype=author&query=Esser%2C+S+K">Steven K. Esser</a>, 
<a href="/search/cs?searchtype=author&query=Appuswamy%2C+R">Rathinakumar Appuswamy</a>, 
<a href="/search/cs?searchtype=author&query=Modha%2C+D+S">Dharmendra S. Modha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03350" title="Abstract">arXiv:2302.03350</a> (replaced) [<a href="/pdf/2302.03350" title="Download PDF">pdf</a>, <a href="/format/2302.03350" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Be Forgotten or To Be Fair: Unveiling Fairness Implications of  Machine Unlearning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI Spring Symposium on AI Trustworthiness Assessment 2023. Published in AI and Ethics Journal <a href="https://link.springer.com/article/10.1007/s43681-023-00398-y">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06506" title="Abstract">arXiv:2302.06506</a> (replaced) [<a href="/pdf/2302.06506" title="Download PDF">pdf</a>, <a href="/format/2302.06506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Myhill-Nerode Theorem for Generalized Automata, with Applications to  Pattern Matching and Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cotumaccio%2C+N">Nicola Cotumaccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08985" title="Abstract">arXiv:2302.08985</a> (replaced) [<a href="/pdf/2302.08985" title="Download PDF">pdf</a>, <a href="/format/2302.08985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Theory of coupled neuronal-synaptic dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Clark%2C+D+G">David G. Clark</a>, 
<a href="/search/q-bio?searchtype=author&query=Abbott%2C+L+F">L.F. Abbott</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.10580" title="Abstract">arXiv:2302.10580</a> (replaced) [<a href="/pdf/2302.10580" title="Download PDF">pdf</a>, <a href="/ps/2302.10580" title="Download PostScript">ps</a>, <a href="/format/2302.10580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Classy Ensemble: A Novel Ensemble Algorithm for Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sipper%2C+M">Moshe Sipper</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14383" title="Abstract">arXiv:2302.14383</a> (replaced) [<a href="/pdf/2302.14383" title="Download PDF">pdf</a>, <a href="/format/2302.14383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linear Spaces of Meanings: Compositional Structures in Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trager%2C+M">Matthew Trager</a>, 
<a href="/search/cs?searchtype=author&query=Perera%2C+P">Pramuditha Perera</a>, 
<a href="/search/cs?searchtype=author&query=Zancato%2C+L">Luca Zancato</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Bhatia%2C+P">Parminder Bhatia</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 9 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE/CVF International Conference on Computer
  Vision 2023 (pp. 15395-15404)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06471" title="Abstract">arXiv:2303.06471</a> (replaced) [<a href="/pdf/2303.06471" title="Download PDF">pdf</a>, <a href="/format/2303.06471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multimodal Data Integration for Oncology in the Era of Deep Neural  Networks: A Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waqas%2C+A">Asim Waqas</a>, 
<a href="/search/cs?searchtype=author&query=Tripathi%2C+A">Aakash Tripathi</a>, 
<a href="/search/cs?searchtype=author&query=Ramachandran%2C+R+P">Ravi P. Ramachandran</a>, 
<a href="/search/cs?searchtype=author&query=Stewart%2C+P">Paul Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Rasool%2C+G">Ghulam Rasool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06982" title="Abstract">arXiv:2303.06982</a> (replaced) [<a href="/pdf/2303.06982" title="Download PDF">pdf</a>, <a href="/format/2303.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysing the Masked predictive coding training criterion for  pre-training a Speech Representation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yadav%2C+H">Hemant Yadav</a>, 
<a href="/search/cs?searchtype=author&query=Sitaram%2C+S">Sunayana Sitaram</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+R+R">Rajiv Ratn Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08115" title="Abstract">arXiv:2303.08115</a> (replaced) [<a href="/pdf/2303.08115" title="Download PDF">pdf</a>, <a href="/format/2303.08115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Inspired Framework to Accelerate Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beikmohammadi%2C+A">Ali Beikmohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Magn%C3%BAsson%2C+S">Sindri Magn&#xfa;sson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.08500" title="Abstract">arXiv:2303.08500</a> (replaced) [<a href="/pdf/2303.08500" title="Download PDF">pdf</a>, <a href="/format/2303.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Devil&#x27;s Advocate: Shattering the Illusion of Unexploitable Data  using Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dolatabadi%2C+H+M">Hadi M. Dolatabadi</a>, 
<a href="/search/cs?searchtype=author&query=Erfani%2C+S">Sarah Erfani</a>, 
<a href="/search/cs?searchtype=author&query=Leckie%2C+C">Christopher Leckie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2024 IEEE Conference on Secure and Trustworthy Machine Learning (SatML)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03567" title="Abstract">arXiv:2304.03567</a> (replaced) [<a href="/pdf/2304.03567" title="Download PDF">pdf</a>, <a href="/format/2304.03567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporalizing digraphs via linear-size balanced bi-trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bessy%2C+S">St&#xe9;phane Bessy</a>, 
<a href="/search/math?searchtype=author&query=Thomass%C3%A9%2C+S">St&#xe9;phan Thomass&#xe9;</a>, 
<a href="/search/math?searchtype=author&query=Viennot%2C+L">Laurent Viennot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08929" title="Abstract">arXiv:2304.08929</a> (replaced) [<a href="/pdf/2304.08929" title="Download PDF">pdf</a>, <a href="/format/2304.08929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SDFReg: Learning Signed Distance Functions for Point Cloud Registration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Leida Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhengda Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kai Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yiqun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03582" title="Abstract">arXiv:2305.03582</a> (replaced) [<a href="/pdf/2305.03582" title="Download PDF">pdf</a>, <a href="/format/2305.03582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A multimodal dynamical variational autoencoder for audiovisual speech  representation learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadok%2C+S">Samir Sadok</a>, 
<a href="/search/cs?searchtype=author&query=Leglaive%2C+S">Simon Leglaive</a>, 
<a href="/search/cs?searchtype=author&query=Girin%2C+L">Laurent Girin</a>, 
<a href="/search/cs?searchtype=author&query=Alameda-Pineda%2C+X">Xavier Alameda-Pineda</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A9guier%2C+R">Renaud S&#xe9;guier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 figures, <a href="https://samsad35.github.io/site-mdvae/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04665" title="Abstract">arXiv:2305.04665</a> (replaced) [<a href="/pdf/2305.04665" title="Download PDF">pdf</a>, <a href="/format/2305.04665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riesz networks: scale invariant neural networks in a single forward pass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barisin%2C+T">Tin Barisin</a>, 
<a href="/search/cs?searchtype=author&query=Schladitz%2C+K">Katja Schladitz</a>, 
<a href="/search/cs?searchtype=author&query=Redenbach%2C+C">Claudia Redenbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05352" title="Abstract">arXiv:2305.05352</a> (replaced) [<a href="/pdf/2305.05352" title="Download PDF">pdf</a>, <a href="/format/2305.05352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Taxonomy of Foundation Model based Systems through the Lens of  Software Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Whittle%2C+J">Jon Whittle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06822" title="Abstract">arXiv:2305.06822</a> (replaced) [<a href="/pdf/2305.06822" title="Download PDF">pdf</a>, <a href="/format/2305.06822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Networks with Fourier-Feature Inputs for Free-breathing  Cardiac MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kunz%2C+J+F">Johannes F. Kunz</a>, 
<a href="/search/eess?searchtype=author&query=Ruschke%2C+S">Stefan Ruschke</a>, 
<a href="/search/eess?searchtype=author&query=Heckel%2C+R">Reinhard Heckel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08489" title="Abstract">arXiv:2305.08489</a> (replaced) [<a href="/pdf/2305.08489" title="Download PDF">pdf</a>, <a href="/format/2305.08489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extensional Taylor Expansion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blondeau-Patissier%2C+L">Lison Blondeau-Patissier</a>, 
<a href="/search/cs?searchtype=author&query=Clairambault%2C+P">Pierre Clairambault</a>, 
<a href="/search/cs?searchtype=author&query=Auclair%2C+L+V">Lionel Vaux Auclair</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11731" title="Abstract">arXiv:2305.11731</a> (replaced) [<a href="/pdf/2305.11731" title="Download PDF">pdf</a>, <a href="/ps/2305.11731" title="Download PostScript">ps</a>, <a href="/format/2305.11731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Persian Typographical Error Type Detection Using Deep Neural Networks on  Algorithmically-Generated Misspellings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dehghani%2C+M">Mohammad Dehghani</a>, 
<a href="/search/cs?searchtype=author&query=Faili%2C+H">Heshaam Faili</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13118" title="Abstract">arXiv:2305.13118</a> (replaced) [<a href="/pdf/2305.13118" title="Download PDF">pdf</a>, <a href="/format/2305.13118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis of eigenvalue condition numbers for a class of randomized  numerical methods for singular matrix pencils
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kressner%2C+D">Daniel Kressner</a>, 
<a href="/search/math?searchtype=author&query=Plestenjak%2C+B">Bor Plestenjak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14062" title="Abstract">arXiv:2305.14062</a> (replaced) [<a href="/pdf/2305.14062" title="Download PDF">pdf</a>, <a href="/format/2305.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Amplitude-Independent Machine Learning for PPG through Visibility Graphs  and Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Miao%2C+Y">Yuyang Miao</a>, 
<a href="/search/eess?searchtype=author&query=Davies%2C+H+J">Harry J. Davies</a>, 
<a href="/search/eess?searchtype=author&query=Mandic%2C+D+P">Danilo P. Mandic</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15349" title="Abstract">arXiv:2305.15349</a> (replaced) [<a href="/pdf/2305.15349" title="Download PDF">pdf</a>, <a href="/format/2305.15349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence of Black-Box Variational Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyurae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jisu Oh</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaiwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS'23; previous title: "Black-Box Variational Inference Converges"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16297" title="Abstract">arXiv:2305.16297</a> (replaced) [<a href="/pdf/2305.16297" title="Download PDF">pdf</a>, <a href="/format/2305.16297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unbiased Compression Saves Communication in Distributed Optimization:  When and How Much?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yutong He</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinmeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+K">Kun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16829" title="Abstract">arXiv:2305.16829</a> (replaced) [<a href="/pdf/2305.16829" title="Download PDF">pdf</a>, <a href="/format/2305.16829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEV-IO: Enhancing Bird&#x27;s-Eye-View 3D Detection with Instance Occupancy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zaibin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuanhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lijun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17147" title="Abstract">arXiv:2305.17147</a> (replaced) [<a href="/pdf/2305.17147" title="Download PDF">pdf</a>, <a href="/format/2305.17147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Value Alignment Evaluation for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ceyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Siyuan Qi</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+Z">Ziqi Rong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+S">Shuguang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3 is the camera-ready version for AAAI-24 Workshop on Public Sector LLMs: Algorithmic and Sociotechnical Design. 7 pages of main content, 1 page of references, 3 pages of appendices, and 7 figures. Our full prompts are released in the repo: <a href="https://github.com/zowiezhang/HVAE">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17333" title="Abstract">arXiv:2305.17333</a> (replaced) [<a href="/pdf/2305.17333" title="Download PDF">pdf</a>, <a href="/format/2305.17333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Tuning Language Models with Just Forward Passes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malladi%2C+S">Sadhika Malladi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Tianyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Nichani%2C+E">Eshaan Nichani</a>, 
<a href="/search/cs?searchtype=author&query=Damian%2C+A">Alex Damian</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+D">Jason D. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Danqi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Sanjeev Arora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 (oral). Code available at <a href="https://github.com/princeton-nlp/MeZO">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18211" title="Abstract">arXiv:2305.18211</a> (replaced) [<a href="/pdf/2305.18211" title="Download PDF">pdf</a>, <a href="/ps/2305.18211" title="Download PostScript">ps</a>, <a href="/format/2305.18211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WiFi-TCN: Temporal Convolution for Human Interaction Recognition based  on WiFi signal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+C">Chih-Yang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+C">Chia-Yu Lin</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yu-Tso Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shih%2C+T+K">Timothy K. Shih</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper is currently under review at IEEE Access
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19604" title="Abstract">arXiv:2305.19604</a> (replaced) [<a href="/pdf/2305.19604" title="Download PDF">pdf</a>, <a href="/format/2305.19604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Medication Recommendation via Domain Knowledge Informed Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sicen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaolong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xianbing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01424" title="Abstract">arXiv:2306.01424</a> (replaced) [<a href="/pdf/2306.01424" title="Download PDF">pdf</a>, <a href="/format/2306.01424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Partial Counterfactual Identification of Continuous Outcomes with a  Curvature Sensitivity Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Melnychuk%2C+V">Valentyn Melnychuk</a>, 
<a href="/search/stat?searchtype=author&query=Frauen%2C+D">Dennis Frauen</a>, 
<a href="/search/stat?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 37th Conference on Neural Information
  Processing Systems (NeurIPS 2023), New Orleans, Louisiana, USA, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01684" title="Abstract">arXiv:2306.01684</a> (replaced) [<a href="/pdf/2306.01684" title="Download PDF">pdf</a>, <a href="/format/2306.01684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing large-language models to generate private synthetic text
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurakin%2C+A">Alexey Kurakin</a>, 
<a href="/search/cs?searchtype=author&query=Ponomareva%2C+N">Natalia Ponomareva</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+U">Umar Syed</a>, 
<a href="/search/cs?searchtype=author&query=MacDermed%2C+L">Liam MacDermed</a>, 
<a href="/search/cs?searchtype=author&query=Terzis%2C+A">Andreas Terzis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages; 7 figures; compared to previous version added result of LoRa-finetuning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02426" title="Abstract">arXiv:2306.02426</a> (replaced) [<a href="/pdf/2306.02426" title="Download PDF">pdf</a>, <a href="/format/2306.02426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient Constrained Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hounie%2C+I">Ignacio Hounie</a>, 
<a href="/search/cs?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>, 
<a href="/search/cs?searchtype=author&query=Chamon%2C+L+F+O">Luiz F. O. Chamon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02729" title="Abstract">arXiv:2306.02729</a> (replaced) [<a href="/pdf/2306.02729" title="Download PDF">pdf</a>, <a href="/format/2306.02729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gibbs Sampling the Posterior of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Piccioli%2C+G">Giovanni Piccioli</a>, 
<a href="/search/cs?searchtype=author&query=Troiani%2C+E">Emanuele Troiani</a>, 
<a href="/search/cs?searchtype=author&query=Zdeborov%C3%A1%2C+L">Lenka Zdeborov&#xe1;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08836" title="Abstract">arXiv:2306.08836</a> (replaced) [<a href="/pdf/2306.08836" title="Download PDF">pdf</a>, <a href="/format/2306.08836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic-based Feature Embedding of 4-D Light Fields for  Compressive Imaging and Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lyu%2C+X">Xianqiang Lyu</a>, 
<a href="/search/eess?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Vision (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09086" title="Abstract">arXiv:2306.09086</a> (replaced) [<a href="/pdf/2306.09086" title="Download PDF">pdf</a>, <a href="/format/2306.09086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation-Aware Diffusion Model for Controllable Poster Layout Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fengheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">An Liu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Honghe Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yaoyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jingjing Lv</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Junjie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhangang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jingping Shao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13853" title="Abstract">arXiv:2306.13853</a> (replaced) [<a href="/pdf/2306.13853" title="Download PDF">pdf</a>, <a href="/format/2306.13853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Approach to Controlling Implicit Regularization via Mirror  Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Haoyuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gatmiry%2C+K">Khashayar Gatmiry</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+K">Kwangjun Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Azizan%2C+N">Navid Azizan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2205.12808">arXiv:2205.12808</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17061" title="Abstract">arXiv:2306.17061</a> (replaced) [<a href="/pdf/2306.17061" title="Download PDF">pdf</a>, <a href="/format/2306.17061" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RowPress: Amplifying Read Disturbance in Modern DRAM Chips
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haocong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Olgun%2C+A">Ataberk Olgun</a>, 
<a href="/search/cs?searchtype=author&query=Ya%C4%9Fl%C4%B1k%C3%A7%C4%B1%2C+A+G">A. Giray Ya&#x11f;l&#x131;k&#xe7;&#x131;</a>, 
<a href="/search/cs?searchtype=author&query=Tu%C4%9Frul%2C+Y+C">Yahya Can Tu&#x11f;rul</a>, 
<a href="/search/cs?searchtype=author&query=Rhyner%2C+S">Steve Rhyner</a>, 
<a href="/search/cs?searchtype=author&query=Cavlak%2C+M+B">Meryem Banu Cavlak</a>, 
<a href="/search/cs?searchtype=author&query=Lindegger%2C+J">Jo&#xeb;l Lindegger</a>, 
<a href="/search/cs?searchtype=author&query=Sadrosadati%2C+M">Mohammad Sadrosadati</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper "RowPress: Amplifying Read Disturbance in Modern DRAM Chips" at the 50th Annual International Symposium on Computer Architecture (ISCA), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01849" title="Abstract">arXiv:2307.01849</a> (replaced) [<a href="/pdf/2307.01849" title="Download PDF">pdf</a>, <a href="/format/2307.01849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crossway Diffusion: Improving Diffusion-based Visuomotor Policy via  Self-supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Belagali%2C+V">Varun Belagali</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+J">Jinghuan Shang</a>, 
<a href="/search/cs?searchtype=author&query=Ryoo%2C+M+S">Michael S. Ryoo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 13 figures. Code, pretrained checkpoints, and datasets are available at <a href="https://github.com/LostXine/crossway_diffusion">this https URL</a> Video demo is at <a href="https://youtu.be/9deKHueZBuk">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02717" title="Abstract">arXiv:2307.02717</a> (replaced) [<a href="/pdf/2307.02717" title="Download PDF">pdf</a>, <a href="/ps/2307.02717" title="Download PostScript">ps</a>, <a href="/format/2307.02717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted  Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dengfeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liukai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Songyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Weifeng He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xueqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yanan Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02730" title="Abstract">arXiv:2307.02730</a> (replaced) [<a href="/pdf/2307.02730" title="Download PDF">pdf</a>, <a href="/format/2307.02730" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of  Figure Skating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng-Lan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yu-Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+G">Gang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Si-Fan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin-Rong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wen-Yue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+N">Ning Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xue-Hai Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.05638" title="Abstract">arXiv:2307.05638</a> (replaced) [<a href="/pdf/2307.05638" title="Download PDF">pdf</a>, <a href="/format/2307.05638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection  in Industrial Time Series: Methods, Applications, and Directions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+P">Peng Yan</a>, 
<a href="/search/cs?searchtype=author&query=Abdulkadir%2C+A">Ahmed Abdulkadir</a>, 
<a href="/search/cs?searchtype=author&query=Luley%2C+P">Paul-Philipp Luley</a>, 
<a href="/search/cs?searchtype=author&query=Rosenthal%2C+M">Matthias Rosenthal</a>, 
<a href="/search/cs?searchtype=author&query=Schatte%2C+G+A">Gerrit A. Schatte</a>, 
<a href="/search/cs?searchtype=author&query=Grewe%2C+B+F">Benjamin F. Grewe</a>, 
<a href="/search/cs?searchtype=author&query=Stadelmann%2C+T">Thilo Stadelmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages, 8 figures, 2 tables, published in IEEE Acess
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Acess 12 (2024) 3768-3789
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07643" title="Abstract">arXiv:2307.07643</a> (replaced) [<a href="/pdf/2307.07643" title="Download PDF">pdf</a>, <a href="/format/2307.07643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Enhanced Co-Interactive Fusion Network (AECIF-Net) for  Automated Structural Condition Assessment in Visual Inspection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhaozheng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Ruwen Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Automation in Construction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08467" title="Abstract">arXiv:2307.08467</a> (replaced) [<a href="/pdf/2307.08467" title="Download PDF">pdf</a>, <a href="/format/2307.08467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Riesz feature representation: scale equivariant scattering network for  classification tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barisin%2C+T">Tin Barisin</a>, 
<a href="/search/cs?searchtype=author&query=Angulo%2C+J">Jesus Angulo</a>, 
<a href="/search/cs?searchtype=author&query=Schladitz%2C+K">Katja Schladitz</a>, 
<a href="/search/cs?searchtype=author&query=Redenbach%2C+C">Claudia Redenbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.08994" title="Abstract">arXiv:2307.08994</a> (replaced) [<a href="/pdf/2307.08994" title="Download PDF">pdf</a>, <a href="/format/2307.08994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Action Recognition in Still Images Using ConViT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hosseyni%2C+S+R">Seyed Rohollah Hosseyni</a>, 
<a href="/search/cs?searchtype=author&query=Seyedin%2C+S">Sanaz Seyedin</a>, 
<a href="/search/cs?searchtype=author&query=Taheri%2C+H">Hasan Taheri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12089" title="Abstract">arXiv:2307.12089</a> (replaced) [<a href="/pdf/2307.12089" title="Download PDF">pdf</a>, <a href="/format/2307.12089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order entropy stable schemes for the quasi-one-dimensional shallow  water and compressible Euler equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chan%2C+J">Jesse Chan</a>, 
<a href="/search/math?searchtype=author&query=Shukla%2C+K">Khemraj Shukla</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+X">Xinhui Wu</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+R">Ruofeng Liu</a>, 
<a href="/search/math?searchtype=author&query=Nalluri%2C+P">Prani Nalluri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13080" title="Abstract">arXiv:2307.13080</a> (replaced) [<a href="/pdf/2307.13080" title="Download PDF">pdf</a>, <a href="/ps/2307.13080" title="Download PostScript">ps</a>, <a href="/format/2307.13080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tolerance to Asynchrony of an Algorithm for Gathering Myopic Robots on  an Infinite Triangular Grid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A+T">Arya Tanmay Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+S+S">Sandeep S Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13621" title="Abstract">arXiv:2307.13621</a> (replaced) [<a href="/pdf/2307.13621" title="Download PDF">pdf</a>, <a href="/format/2307.13621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling up machine learning-based chemical plant simulation: A method  for fine-tuning a model to induce stable fixed points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esders%2C+M">Malte Esders</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez%2C+G+A+F">Gimmy Alex Fernandez Ramirez</a>, 
<a href="/search/cs?searchtype=author&query=Gastegger%2C+M">Michael Gastegger</a>, 
<a href="/search/cs?searchtype=author&query=Samal%2C+S+S">Satya Swarup Samal</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers &amp; Chemical Engineering Volume 182, March 2024, 108574
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Engineering, Finance, and Science (cs.CE); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00031" title="Abstract">arXiv:2308.00031</a> (replaced) [<a href="/pdf/2308.00031" title="Download PDF">pdf</a>, <a href="/format/2308.00031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement Learning for Generative AI: State of the Art,  Opportunities and Open Research Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Franceschelli%2C+G">Giorgio Franceschelli</a>, 
<a href="/search/cs?searchtype=author&query=Musolesi%2C+M">Mirco Musolesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in JAIR
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03234" title="Abstract">arXiv:2308.03234</a> (replaced) [<a href="/pdf/2308.03234" title="Download PDF">pdf</a>, <a href="/format/2308.03234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Distractor and Feedback Generation for Math Multiple-choice  Questions via In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McNichols%2C+H">Hunter McNichols</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Wanyong Feng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaewook Lee</a>, 
<a href="/search/cs?searchtype=author&query=Scarlatos%2C+A">Alexander Scarlatos</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+D">Digory Smith</a>, 
<a href="/search/cs?searchtype=author&query=Woodhead%2C+S">Simon Woodhead</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+A">Andrew Lan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurlIPS 2023 GAIED Workshop Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03853" title="Abstract">arXiv:2308.03853</a> (replaced) [<a href="/pdf/2308.03853" title="Download PDF">pdf</a>, <a href="/ps/2308.03853" title="Download PostScript">ps</a>, <a href="/format/2308.03853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CORAL: Expert-Curated medical Oncology Reports to Advance Language Model  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sushil%2C+M">Madhumita Sushil</a>, 
<a href="/search/cs?searchtype=author&query=Kennedy%2C+V+E">Vanessa E. Kennedy</a>, 
<a href="/search/cs?searchtype=author&query=Mandair%2C+D">Divneet Mandair</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+B+Y">Brenda Y. Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zack%2C+T">Travis Zack</a>, 
<a href="/search/cs?searchtype=author&query=Butte%2C+A+J">Atul J. Butte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code available at: <a href="https://github.com/MadhumitaSushil/OncLLMExtraction">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05087" title="Abstract">arXiv:2308.05087</a> (replaced) [<a href="/pdf/2308.05087" title="Download PDF">pdf</a>, <a href="/format/2308.05087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mean-Biased Processes for Balanced Allocations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Los%2C+D">Dimitrios Los</a>, 
<a href="/search/math?searchtype=author&query=Sauerwald%2C+T">Thomas Sauerwald</a>, 
<a href="/search/math?searchtype=author&query=Sylvester%2C+J">John Sylvester</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper refines and extends the content on non-filling processes in <a href="/abs/2110.10759">arXiv:2110.10759</a>. It consists of 65 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09510" title="Abstract">arXiv:2308.09510</a> (replaced) [<a href="/pdf/2308.09510" title="Download PDF">pdf</a>, <a href="/ps/2308.09510" title="Download PostScript">ps</a>, <a href="/format/2308.09510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forward and Backward Constrained Bisimulations for Quantum Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jim%C3%A9nez-Pastor%2C+A">Antonio Jim&#xe9;nez-Pastor</a>, 
<a href="/search/quant-ph?searchtype=author&query=Larsen%2C+K+G">Kim G. Larsen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tribastone%2C+M">Mirco Tribastone</a>, 
<a href="/search/quant-ph?searchtype=author&query=Tschaikowski%2C+M">Max Tschaikowski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11339" title="Abstract">arXiv:2308.11339</a> (replaced) [<a href="/pdf/2308.11339" title="Download PDF">pdf</a>, <a href="/format/2308.11339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProAgent: Building Proactive Cooperative Agents with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Ceyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaijie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Siyi Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guanghe Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yihang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Cheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaowei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anji Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-Chun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaojun Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junge Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yitao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yaodong Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> v3 is the AAAI'24 camera ready version, which polished abstract and introduction based on the reviewers' comments, and enriched related works. 7 pages of main content, 2 pages of references, 2 figures and 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13981" title="Abstract">arXiv:2308.13981</a> (replaced) [<a href="/pdf/2308.13981" title="Download PDF">pdf</a>, <a href="/format/2308.13981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Codes for CRYSTALS-Kyber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuiyin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sakzad%2C+A">Amin Sakzad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14647" title="Abstract">arXiv:2308.14647</a> (replaced) [<a href="/pdf/2308.14647" title="Download PDF">pdf</a>, <a href="/format/2308.14647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Generation Scheduling for DAG Tasks Using Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+B">Binqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Theile%2C+M">Mirco Theile</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Ziyuan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Bernardini%2C+D">Daniele Bernardini</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+D">Debayan Roy</a>, 
<a href="/search/cs?searchtype=author&query=Bastoni%2C+A">Andrea Bastoni</a>, 
<a href="/search/cs?searchtype=author&query=Caccamo%2C+M">Marco Caccamo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEEE Transactions on Computers
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Discrete Mathematics (cs.DM); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16518" title="Abstract">arXiv:2308.16518</a> (replaced) [<a href="/pdf/2308.16518" title="Download PDF">pdf</a>, <a href="/format/2308.16518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MS23D: : A 3D Object Detection Method Using Multi-Scale Semantic Feature  Points to Construct 3D Feature Layer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yongxin Shao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+A">Aihong Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Binrui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+T">Tianhong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhetao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaxin Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16875" title="Abstract">arXiv:2308.16875</a> (replaced) [<a href="/pdf/2308.16875" title="Download PDF">pdf</a>, <a href="/format/2308.16875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Holistic Processing of Colour Images Using Novel Quaternion-Valued  Wavelets on the Plane
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dizon%2C+N+D">Neil D. Dizon</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+J+A">Jeffrey A. Hogan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01036" title="Abstract">arXiv:2309.01036</a> (replaced) [<a href="/pdf/2309.01036" title="Download PDF">pdf</a>, <a href="/format/2309.01036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEPAL: Spatial Gene Expression Prediction from Local Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mejia%2C+G">Gabriel Mejia</a>, 
<a href="/search/cs?searchtype=author&query=C%C3%A1rdenas%2C+P">Paula C&#xe1;rdenas</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+D">Daniela Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Castillo%2C+A">Angela Castillo</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%C3%A1ez%2C+P">Pablo Arbel&#xe1;ez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03561" title="Abstract">arXiv:2309.03561</a> (replaced) [<a href="/pdf/2309.03561" title="Download PDF">pdf</a>, <a href="/ps/2309.03561" title="Download PostScript">ps</a>, <a href="/format/2309.03561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trinary Decision Trees for handling missing data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zakrisson%2C+H">Henning Zakrisson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03581" title="Abstract">arXiv:2309.03581</a> (replaced) [<a href="/pdf/2309.03581" title="Download PDF">pdf</a>, <a href="/format/2309.03581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Hyperparameter Optimization in Multi-Objective Problems via  Preference Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giovanelli%2C+J">Joseph Giovanelli</a>, 
<a href="/search/cs?searchtype=author&query=Tornede%2C+A">Alexander Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Tornede%2C+T">Tanja Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04941" title="Abstract">arXiv:2309.04941</a> (replaced) [<a href="/pdf/2309.04941" title="Download PDF">pdf</a>, <a href="/ps/2309.04941" title="Download PostScript">ps</a>, <a href="/format/2309.04941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle  Counting Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junru Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiarui Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Muhan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07156" title="Abstract">arXiv:2309.07156</a> (replaced) [<a href="/pdf/2309.07156" title="Download PDF">pdf</a>, <a href="/format/2309.07156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparency in Sleep Staging: Deep Learning Method for EEG Sleep Stage  Classification with Model Interpretability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sharma%2C+S">Shivam Sharma</a>, 
<a href="/search/eess?searchtype=author&query=Maiti%2C+S">Suvadeep Maiti</a>, 
<a href="/search/eess?searchtype=author&query=Mythirayee%2C+S">S. Mythirayee</a>, 
<a href="/search/eess?searchtype=author&query=Rajendran%2C+S">Srijithesh Rajendran</a>, 
<a href="/search/eess?searchtype=author&query=Bapi%2C+R+S">Raju Surampudi Bapi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 9 figures, Under review at IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07207" title="Abstract">arXiv:2309.07207</a> (replaced) [<a href="/pdf/2309.07207" title="Download PDF">pdf</a>, <a href="/format/2309.07207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EarthPT: a time series foundation model for Earth Observation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+M+J">Michael J. Smith</a>, 
<a href="/search/cs?searchtype=author&query=Fleming%2C+L">Luke Fleming</a>, 
<a href="/search/cs?searchtype=author&query=Geach%2C+J+E">James E. Geach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, accepted to NeurIPS CCAI workshop at <a href="https://www.climatechange.ai/papers/neurips2023/2">this https URL</a> . Code available at <a href="https://github.com/aspiaspace/EarthPT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08704" title="Abstract">arXiv:2309.08704</a> (replaced) [<a href="/pdf/2309.08704" title="Download PDF">pdf</a>, <a href="/format/2309.08704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Optimization of Damage Assessment and Restoration: A  Resilience-Driven Dynamic Crew Allocation for Power Distribution Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jalilian%2C+A">Ali Jalilian</a>, 
<a href="/search/eess?searchtype=author&query=Taheri%2C+B">Babak Taheri</a>, 
<a href="/search/eess?searchtype=author&query=Molzahn%2C+D+K">Daniel K. Molzahn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09182" title="Abstract">arXiv:2309.09182</a> (replaced) [<a href="/pdf/2309.09182" title="Download PDF">pdf</a>, <a href="/format/2309.09182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Scene Graph Planning with Large Language Model Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhirui Dai</a>, 
<a href="/search/cs?searchtype=author&query=Asgharivaskasi%2C+A">Arash Asgharivaskasi</a>, 
<a href="/search/cs?searchtype=author&query=Duong%2C+T">Thai Duong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shusen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Tzes%2C+M">Maria-Elizabeth Tzes</a>, 
<a href="/search/cs?searchtype=author&query=Pappas%2C+G">George Pappas</a>, 
<a href="/search/cs?searchtype=author&query=Atanasov%2C+N">Nikolay Atanasov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09571" title="Abstract">arXiv:2309.09571</a> (replaced) [<a href="/pdf/2309.09571" title="Download PDF">pdf</a>, <a href="/format/2309.09571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Generative Knowledge Distillation with Masked Image  Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Ziming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shumin Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaodi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jing Hao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xianbin Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09832" title="Abstract">arXiv:2309.09832</a> (replaced) [<a href="/pdf/2309.09832" title="Download PDF">pdf</a>, <a href="/format/2309.09832" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task Selection and Assignment for Multi-modal Multi-task Dialogue Act  Classification with Non-stationary Multi-armed Bandits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangheng He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11526" title="Abstract">arXiv:2309.11526</a> (replaced) [<a href="/pdf/2309.11526" title="Download PDF">pdf</a>, <a href="/format/2309.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Likelihood-based Sensor Calibration using Affine Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Machhamer%2C+R">R&#xfc;diger Machhamer</a>, 
<a href="/search/cs?searchtype=author&query=Fazlic%2C+L+B">Lejla Begic Fazlic</a>, 
<a href="/search/cs?searchtype=author&query=Guven%2C+E">Eray Guven</a>, 
<a href="/search/cs?searchtype=author&query=Junk%2C+D">David Junk</a>, 
<a href="/search/cs?searchtype=author&query=Kurt%2C+G+K">Gunes Karabulut Kurt</a>, 
<a href="/search/cs?searchtype=author&query=Naumann%2C+S">Stefan Naumann</a>, 
<a href="/search/cs?searchtype=author&query=Didas%2C+S">Stephan Didas</a>, 
<a href="/search/cs?searchtype=author&query=Gollmer%2C+K">Klaus-Uwe Gollmer</a>, 
<a href="/search/cs?searchtype=author&query=Bergmann%2C+R">Ralph Bergmann</a>, 
<a href="/search/cs?searchtype=author&query=Timm%2C+I+J">Ingo J. Timm</a>, 
<a href="/search/cs?searchtype=author&query=Dartmann%2C+G">Guido Dartmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11872" title="Abstract">arXiv:2309.11872</a> (replaced) [<a href="/pdf/2309.11872" title="Download PDF">pdf</a>, <a href="/format/2309.11872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-Field Beam Training: Joint Angle and Range Estimation with DFT  Codebook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xun Wu</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+C">Changsheng You</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiapeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunpu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work is submitted to IEEE for possible publication. Our other works on near-field beam training include: 1) two-phase near-field beam training (<a href="/abs/2209.14798">arXiv:2209.14798</a>), 2) hierarchical near-field beam training (<a href="/abs/2302.12511">arXiv:2302.12511</a>), and 3) near-field beam management (<a href="/abs/2306.16206">arXiv:2306.16206</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12009" title="Abstract">arXiv:2309.12009</a> (replaced) [<a href="/pdf/2309.12009" title="Download PDF">pdf</a>, <a href="/format/2309.12009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elevating Skeleton-Based Action Recognition with Efficient  Multi-Modality Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yiping Wei</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+K">Kunyu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Roitberg%2C+A">Alina Roitberg</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junwei Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruiping Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yufan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024. The source code will be made publicly available at <a href="https://github.com/desehuileng0o0/IKEM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Robotics (cs.RO); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12613" title="Abstract">arXiv:2309.12613</a> (replaced) [<a href="/pdf/2309.12613" title="Download PDF">pdf</a>, <a href="/format/2309.12613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Migration across Multiple Social Media Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+U">Ujun Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Nirmal%2C+A">Ayushi Nirmal</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+K">Kritshekhar Jha</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S+X">Susan Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Bernard%2C+H+R">H. Russell Bernard</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SDM 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.16874" title="Abstract">arXiv:2309.16874</a> (replaced) [<a href="/pdf/2309.16874" title="Download PDF">pdf</a>, <a href="/format/2309.16874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sandwich Approach for Motion Planning and Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramezani%2C+M">Mohamadreza Ramezani</a>, 
<a href="/search/cs?searchtype=author&query=Rastgoftar%2C+H">Hossein Rastgoftar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00530" title="Abstract">arXiv:2310.00530</a> (replaced) [<a href="/pdf/2310.00530" title="Download PDF">pdf</a>, <a href="/ps/2310.00530" title="Download PostScript">ps</a>, <a href="/format/2310.00530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-tiling Neural Radiance Field (NeRF) -- Geometric Assessment on  Large-scale Aerial Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Ningli Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+R">Rongjun Qin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Debao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Remondino%2C+F">Fabio Remondino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 Figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.00723" title="Abstract">arXiv:2310.00723</a> (replaced) [<a href="/pdf/2310.00723" title="Download PDF">pdf</a>, <a href="/format/2310.00723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HOH: Markerless Multimodal Human-Object-Human Handover Dataset with  Large Object Count
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiederhold%2C+N">Noah Wiederhold</a>, 
<a href="/search/cs?searchtype=author&query=Megyeri%2C+A">Ava Megyeri</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+D">DiMaggio Paris</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sean Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+N+K">Natasha Kholgade Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01213" title="Abstract">arXiv:2310.01213</a> (replaced) [<a href="/pdf/2310.01213" title="Download PDF">pdf</a>, <a href="/format/2310.01213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure and growth of $\mathbb{R}$-bonacci words
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dovgal%2C+S">Sergey Dovgal</a>, 
<a href="/search/math?searchtype=author&query=Kirgizov%2C+S">Sergey Kirgizov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.01376" title="Abstract">arXiv:2310.01376</a> (replaced) [<a href="/pdf/2310.01376" title="Download PDF">pdf</a>, <a href="/format/2310.01376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Distribution-Agnostic Generalized Category Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jianhong Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuozhu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hualiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruizhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+L">Lianrui Mu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaomeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J+T">Joey Tianyi Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Haoji Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.04986" title="Abstract">arXiv:2310.04986</a> (replaced) [<a href="/pdf/2310.04986" title="Download PDF">pdf</a>, <a href="/format/2310.04986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new economic and financial theory of money
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Glinsky%2C+M+E">Michael E. Glinsky</a>, 
<a href="/search/econ?searchtype=author&query=Sievert%2C+S">Sharon Sievert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 35 figures, 158 equations, to be submitted to Journal of Economic Affairs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI); Classical Physics (physics.class-ph)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.05012" title="Abstract">arXiv:2310.05012</a> (replaced) [<a href="/pdf/2310.05012" title="Download PDF">pdf</a>, <a href="/format/2310.05012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting Abnormal Health Conditions in Smart Home Using a Drone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barman%2C+P+K">Pronob Kumar Barman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06059" title="Abstract">arXiv:2310.06059</a> (replaced) [<a href="/pdf/2310.06059" title="Download PDF">pdf</a>, <a href="/format/2310.06059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Warning Prediction with Automatic Labeling in Epilepsy Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+T">Ting Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinqiao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Nikolenko%2C+S">Sergey Nikolenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages,4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.06266" title="Abstract">arXiv:2310.06266</a> (replaced) [<a href="/pdf/2310.06266" title="Download PDF">pdf</a>, <a href="/format/2310.06266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CodeFuse-13B: A Pretrained Multi-lingual Code Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di%2C+P">Peng Di</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianguo Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenting Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Y">Yang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaoyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongwei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+G">Gang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jie Gong</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zi Gong</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wen Hu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Tingting Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhichao Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Ting Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+M">Ming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+C">Cong Liao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bingchang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shaojun Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+M">Min Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangpei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaogui Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiawei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Q">Qing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gehao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zelin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xunjin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hailian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lifu Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xianying Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICSE-SEIP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.10898" title="Abstract">arXiv:2310.10898</a> (replaced) [<a href="/pdf/2310.10898" title="Download PDF">pdf</a>, <a href="/format/2310.10898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analyzing Modularity Maximization in Approximation, Heuristic, and Graph  Neural Network Algorithms for Community Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aref%2C+S">Samin Aref</a>, 
<a href="/search/cs?searchtype=author&query=Mostajabdaveh%2C+M">Mahdi Mostajabdaveh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article is an extended version of <a href="/abs/2302.14698">arXiv:2302.14698</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.11526" title="Abstract">arXiv:2310.11526</a> (replaced) [<a href="/pdf/2310.11526" title="Download PDF">pdf</a>, <a href="/ps/2310.11526" title="Download PostScript">ps</a>, <a href="/format/2310.11526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commitments from Quantum One-Wayness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Khurana%2C+D">Dakshita Khurana</a> (UIUC), 
<a href="/search/quant-ph?searchtype=author&query=Tomer%2C+K">Kabir Tomer</a> (UIUC)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 68 pages; Minor edits
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.12551" title="Abstract">arXiv:2310.12551</a> (replaced) [<a href="/pdf/2310.12551" title="Download PDF">pdf</a>, <a href="/format/2310.12551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative PnP and its application in 3D-2D vascular image registration  for robot navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingwei Song</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Keke Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Meng Li</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+T">Tuoyu Cao</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024 Errors in Eq. 4 and Eq. 6 have been corrected. Updates include some minor improvements in Section II
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13183" title="Abstract">arXiv:2310.13183</a> (replaced) [<a href="/pdf/2310.13183" title="Download PDF">pdf</a>, <a href="/format/2310.13183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking through Deterministic Barriers: Randomized Pruning Mask  Generation and Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weizhi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13191" title="Abstract">arXiv:2310.13191</a> (replaced) [<a href="/pdf/2310.13191" title="Download PDF">pdf</a>, <a href="/format/2310.13191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy  for Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wei Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.13413" title="Abstract">arXiv:2310.13413</a> (replaced) [<a href="/pdf/2310.13413" title="Download PDF">pdf</a>, <a href="/ps/2310.13413" title="Download PostScript">ps</a>, <a href="/format/2310.13413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scoped and Typed Staging by Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allais%2C+G">Guillaume Allais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> As accepted for publication at PEPM 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15043" title="Abstract">arXiv:2310.15043</a> (replaced) [<a href="/pdf/2310.15043" title="Download PDF">pdf</a>, <a href="/format/2310.15043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CalibrationPhys: Self-supervised Video-based Heart and Respiratory Rate  Measurements by Calibrating Between Multiple Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Akamatsu%2C+Y">Yusuke Akamatsu</a>, 
<a href="/search/eess?searchtype=author&query=Umematsu%2C+T">Terumi Umematsu</a>, 
<a href="/search/eess?searchtype=author&query=Imaoka%2C+H">Hitoshi Imaoka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Journal of Biomedical and Health Informatics (J-BHI)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE.J.Biomed.Health.Inf. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.15152" title="Abstract">arXiv:2310.15152</a> (replaced) [<a href="/pdf/2310.15152" title="Download PDF">pdf</a>, <a href="/format/2310.15152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling Balanced Forests of Grids in Polynomial Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cannon%2C+S">Sarah Cannon</a>, 
<a href="/search/cs?searchtype=author&query=Pegden%2C+W">Wesley Pegden</a>, 
<a href="/search/cs?searchtype=author&query=Tucker-Foltz%2C+J">Jamie Tucker-Foltz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2310.18716" title="Abstract">arXiv:2310.18716</a> (replaced) [<a href="/pdf/2310.18716" title="Download PDF">pdf</a>, <a href="/format/2310.18716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laplacian Canonization: A Minimalist Approach to Sign and Basis  Invariant Spectral Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jiangyan Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yisen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Thirty-seventh Conference on Neural Information Processing Systems (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00541" title="Abstract">arXiv:2311.00541</a> (replaced) [<a href="/pdf/2311.00541" title="Download PDF">pdf</a>, <a href="/format/2311.00541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Embedded Diachronic Sense Change Model with a Case Study from Ancient  Greek
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zafar%2C+S">Schyan Zafar</a>, 
<a href="/search/cs?searchtype=author&query=Nicholls%2C+G+K">Geoff K. Nicholls</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.00636" title="Abstract">arXiv:2311.00636</a> (replaced) [<a href="/pdf/2311.00636" title="Download PDF">pdf</a>, <a href="/format/2311.00636" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kronecker-Factored Approximate Curvature for Modern Neural Network  Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eschenhagen%2C+R">Runa Eschenhagen</a>, 
<a href="/search/cs?searchtype=author&query=Immer%2C+A">Alexander Immer</a>, 
<a href="/search/cs?searchtype=author&query=Turner%2C+R+E">Richard E. Turner</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+F">Frank Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Hennig%2C+P">Philipp Hennig</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01433" title="Abstract">arXiv:2311.01433</a> (replaced) [<a href="/pdf/2311.01433" title="Download PDF">pdf</a>, <a href="/format/2311.01433" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study of Governance Issues in Decentralized Finance  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+W">Wei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chenguang Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.01459" title="Abstract">arXiv:2311.01459</a> (replaced) [<a href="/pdf/2311.01459" title="Download PDF">pdf</a>, <a href="/format/2311.01459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Align Your Prompts: Test-Time Prompting with Distribution Alignment for  Zero-Shot Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hassan%2C+J">Jameel Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Gani%2C+H">Hanan Gani</a>, 
<a href="/search/cs?searchtype=author&query=Hussein%2C+N">Noor Hussein</a>, 
<a href="/search/cs?searchtype=author&query=Khattak%2C+M+U">Muhammad Uzair Khattak</a>, 
<a href="/search/cs?searchtype=author&query=Naseer%2C+M">Muzammal Naseer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F+S">Fahad Shahbaz Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.02790" title="Abstract">arXiv:2311.02790</a> (replaced) [<a href="/pdf/2311.02790" title="Download PDF">pdf</a>, <a href="/format/2311.02790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CausalCite: A Causal Formulation of Paper Citations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+I">Ishan Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhijing Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mokhtarian%2C+E">Ehsan Mokhtarian</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+S">Siyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sachan%2C+M">Mrinmaya Sachan</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03220" title="Abstract">arXiv:2311.03220</a> (replaced) [<a href="/pdf/2311.03220" title="Download PDF">pdf</a>, <a href="/format/2311.03220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALYMPICS: Language Agents Meet Game Theory -- Exploring Strategic  Decision-Making with AI Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mao%2C+S">Shaoguang Mao</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yuzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fengyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+T">Tao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.03774" title="Abstract">arXiv:2311.03774</a> (replaced) [<a href="/pdf/2311.03774" title="Download PDF">pdf</a>, <a href="/format/2311.03774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Meta-Adapter: An Online Few-shot Learner for Vision-Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+C">Cheng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+L">Lin Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+R">Ruoyi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hongbin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+Y">Yixiao Ge</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+Y">Ying Shan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.07102" title="Abstract">arXiv:2311.07102</a> (replaced) [<a href="/pdf/2311.07102" title="Download PDF">pdf</a>, <a href="/format/2311.07102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fovea Transformer: Efficient Long-Context Modeling with Structured  Fine-to-Coarse Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Ziwei He</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jian Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Le Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Leng%2C+J">Jingwen Leng</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bo Jiang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.08038" title="Abstract">arXiv:2311.08038</a> (replaced) [<a href="/pdf/2311.08038" title="Download PDF">pdf</a>, <a href="/format/2311.08038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linking QKD testbeds across Europe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brauer%2C+M">Max Brauer</a>, 
<a href="/search/cs?searchtype=author&query=Vicente%2C+R+J">Rafael J. Vicente</a>, 
<a href="/search/cs?searchtype=author&query=Buruaga%2C+J+S">Jaime S. Buruaga</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+R+B">Ruben B. Mendez</a>, 
<a href="/search/cs?searchtype=author&query=Braun%2C+R">Ralf-Peter Braun</a>, 
<a href="/search/cs?searchtype=author&query=Geitz%2C+M">Marc Geitz</a>, 
<a href="/search/cs?searchtype=author&query=Rydlichkowski%2C+P">Piotr Rydlichkowski</a>, 
<a href="/search/cs?searchtype=author&query=Brunner%2C+H+H">Hans H. Brunner</a>, 
<a href="/search/cs?searchtype=author&query=Fung%2C+F">Fred Fung</a>, 
<a href="/search/cs?searchtype=author&query=Peev%2C+M">Momtchil Peev</a>, 
<a href="/search/cs?searchtype=author&query=Pastor%2C+A">Antonio Pastor</a>, 
<a href="/search/cs?searchtype=author&query=Lopez%2C+D">Diego Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+V">Vicente Martin</a>, 
<a href="/search/cs?searchtype=author&query=Brito%2C+J+P">Juan P. Brito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.09229" title="Abstract">arXiv:2311.09229</a> (replaced) [<a href="/pdf/2311.09229" title="Download PDF">pdf</a>, <a href="/format/2311.09229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Novel Holistic, Personalized Dementia Risk Prediction Model  via Integration of Machine Learning and Network Systems Biology Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mamidala%2C+S">Srilekha Mamidala</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.11340" title="Abstract">arXiv:2311.11340</a> (replaced) [<a href="/pdf/2311.11340" title="Download PDF">pdf</a>, <a href="/format/2311.11340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RflyMAD: A Dataset for Multicopter Fault Detection and Health Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+X">Xiangli Le</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+B">Bo Jin</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+G">Gen Cui</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xunhua Dai</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+Q">Quan Quan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.13326" title="Abstract">arXiv:2311.13326</a> (replaced) [<a href="/pdf/2311.13326" title="Download PDF">pdf</a>, <a href="/format/2311.13326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Curriculum Learning and Imitation Learning for Model-free Control on  Financial Time-series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koh%2C+W">Woosung Koh</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+I">Insu Choi</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+Y">Yuntae Jang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+G">Gimin Kang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W+C">Woo Chang Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AAAI 2024 AI4TS Workshop Oral
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Portfolio Management (q-fin.PM)

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15816" title="Abstract">arXiv:2311.15816</a> (replaced) [<a href="/pdf/2311.15816" title="Download PDF">pdf</a>, <a href="/format/2311.15816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scale-Dropout: Estimating Uncertainty in Deep Neural Networks Using  Stochastic Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S+T">Soyed Tuhin Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Danouchi%2C+K">Kamal Danouchi</a>, 
<a href="/search/cs?searchtype=author&query=Hefenbrock%2C+M">Michael Hefenbrock</a>, 
<a href="/search/cs?searchtype=author&query=Prenat%2C+G">Guillaume Prenat</a>, 
<a href="/search/cs?searchtype=author&query=Anghel%2C+L">Lorena Anghel</a>, 
<a href="/search/cs?searchtype=author&query=Tahoori%2C+M+B">Mehdi B. Tahoori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.15830" title="Abstract">arXiv:2311.15830</a> (replaced) [<a href="/pdf/2311.15830" title="Download PDF">pdf</a>, <a href="/format/2311.15830" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A-JEPA: Joint-Embedding Predictive Architecture Can Listen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fei%2C+Z">Zhengcong Fei</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+M">Mingyuan Fan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Junshi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.06405">arXiv:2207.06405</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16163" title="Abstract">arXiv:2311.16163</a> (replaced) [<a href="/pdf/2311.16163" title="Download PDF">pdf</a>, <a href="/format/2311.16163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IODeep: an IOD for the introduction of deep learning in the DICOM  standard
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Contino%2C+S">Salvatore Contino</a>, 
<a href="/search/eess?searchtype=author&query=Cruciata%2C+L">Luca Cruciata</a>, 
<a href="/search/eess?searchtype=author&query=Gambino%2C+O">Orazio Gambino</a>, 
<a href="/search/eess?searchtype=author&query=Pirrone%2C+R">Roberto Pirrone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.16751" title="Abstract">arXiv:2311.16751</a> (replaced) [<a href="/pdf/2311.16751" title="Download PDF">pdf</a>, <a href="/format/2311.16751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yunshan Ma</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yingzhi He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yinwei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiaoyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yuyangzi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> TOIS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17262" title="Abstract">arXiv:2311.17262</a> (replaced) [<a href="/pdf/2311.17262" title="Download PDF">pdf</a>, <a href="/ps/2311.17262" title="Download PostScript">ps</a>, <a href="/format/2311.17262" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parity-check Codes from Disjunct Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haymaker%2C+K">Kathryn Haymaker</a>, 
<a href="/search/cs?searchtype=author&query=McMillon%2C+E">Emily McMillon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.17929" title="Abstract">arXiv:2311.17929</a> (replaced) [<a href="/pdf/2311.17929" title="Download PDF">pdf</a>, <a href="/format/2311.17929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Online Communities: Graph Deep Learning on Anonymous Voting Networks  to Identify Sybils in Polycentric Governance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=DuPont%2C+Q">Quinn DuPont</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2311.18252" title="Abstract">arXiv:2311.18252</a> (replaced) [<a href="/pdf/2311.18252" title="Download PDF">pdf</a>, <a href="/format/2311.18252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigating Privacy and Copyright Challenges Across the Data Lifecycle of  Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Boming Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yue Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T">Thong Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Q">Qinghua Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 2024 IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.00840" title="Abstract">arXiv:2312.00840</a> (replaced) [<a href="/pdf/2312.00840" title="Download PDF">pdf</a>, <a href="/format/2312.00840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Redundancy-Free Sub-networks in Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">LianLi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H+T">Heng Tao Shen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02080" title="Abstract">arXiv:2312.02080</a> (replaced) [<a href="/pdf/2312.02080" title="Download PDF">pdf</a>, <a href="/ps/2312.02080" title="Download PostScript">ps</a>, <a href="/format/2312.02080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fixed-point methods for long-term power control and beamforming design  in large-scale MIMO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miretti%2C+L">Lorenzo Miretti</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcante%2C+R+L+G">Renato L. G. Cavalcante</a>, 
<a href="/search/cs?searchtype=author&query=Sta%C5%84czak%2C+S">S&#x142;awomir Sta&#x144;czak</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.02133" title="Abstract">arXiv:2312.02133</a> (replaced) [<a href="/pdf/2312.02133" title="Download PDF">pdf</a>, <a href="/format/2312.02133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Style Aligned Image Generation via Shared Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hertz%2C+A">Amir Hertz</a>, 
<a href="/search/cs?searchtype=author&query=Voynov%2C+A">Andrey Voynov</a>, 
<a href="/search/cs?searchtype=author&query=Fruchter%2C+S">Shlomi Fruchter</a>, 
<a href="/search/cs?searchtype=author&query=Cohen-Or%2C+D">Daniel Cohen-Or</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at style-aligned-gen.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.03919" title="Abstract">arXiv:2312.03919</a> (replaced) [<a href="/pdf/2312.03919" title="Download PDF">pdf</a>, <a href="/ps/2312.03919" title="Download PostScript">ps</a>, <a href="/format/2312.03919" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Indivisibility and uniform computational strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gill%2C+K">Kenneth Gill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 4 figures. This work extends the results of Sections 1.2 and 1.3 of the author's Ph.D. thesis at Penn State University. Version 4: add Example 3.4 and discussion of recent related work of Dzhafarov, Solomon, and Valenti (<a href="/abs/1312.10535">1312.10535</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic (math.LO)</span>; Logic in Computer Science (cs.LO); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.04018" title="Abstract">arXiv:2312.04018</a> (replaced) [<a href="/pdf/2312.04018" title="Download PDF">pdf</a>, <a href="/format/2312.04018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ricci-Notation Tensor Framework for Model-Based Approaches to Imaging
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joseph%2C+D">Dileepan Joseph</a> (Electrical and Computer Engineering, University of Alberta)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mathematical Software (cs.MS)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.05720" title="Abstract">arXiv:2312.05720</a> (replaced) [<a href="/pdf/2312.05720" title="Download PDF">pdf</a>, <a href="/format/2312.05720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer  Inputs of Language Models in Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Q">Qi Lei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.06499" title="Abstract">arXiv:2312.06499</a> (replaced) [<a href="/pdf/2312.06499" title="Download PDF">pdf</a>, <a href="/format/2312.06499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TaCo: Targeted Concept Removal in Output Embeddings for NLP via  Information Theory and Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jourdan%2C+F">Fanny Jourdan</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%A9thune%2C+L">Louis B&#xe9;thune</a>, 
<a href="/search/cs?searchtype=author&query=Picard%2C+A">Agustin Picard</a>, 
<a href="/search/cs?searchtype=author&query=Risser%2C+L">Laurent Risser</a>, 
<a href="/search/cs?searchtype=author&query=Asher%2C+N">Nicholas Asher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.07941" title="Abstract">arXiv:2312.07941</a> (replaced) [<a href="/pdf/2312.07941" title="Download PDF">pdf</a>, <a href="/ps/2312.07941" title="Download PostScript">ps</a>, <a href="/format/2312.07941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An efficient algorithm for multiuser sum-rate maximization of  large-scale active RIS-aided MIMO system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingjie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08048" title="Abstract">arXiv:2312.08048</a> (replaced) [<a href="/pdf/2312.08048" title="Download PDF">pdf</a>, <a href="/format/2312.08048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Inversion for Stable Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xulu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiao-Yong Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jinlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper was accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08079" title="Abstract">arXiv:2312.08079</a> (replaced) [<a href="/pdf/2312.08079" title="Download PDF">pdf</a>, <a href="/format/2312.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Whisper with prompt tuning to target-speaker ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Z">Zhiyuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+M">Mingjie Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jing Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Ju Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08567" title="Abstract">arXiv:2312.08567</a> (replaced) [<a href="/pdf/2312.08567" title="Download PDF">pdf</a>, <a href="/format/2312.08567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConFormer: A Novel Collection of Deep Learning Models to Assist  Cardiologists in the Assessment of Cardiac Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Thomas%2C+E">Ethan Thomas</a>, 
<a href="/search/eess?searchtype=author&query=Aslam%2C+S">Salman Aslam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08736" title="Abstract">arXiv:2312.08736</a> (replaced) [<a href="/pdf/2312.08736" title="Download PDF">pdf</a>, <a href="/format/2312.08736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank solver for conforming multipatch Isogeometric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Montardini%2C+M">Monica Montardini</a>, 
<a href="/search/math?searchtype=author&query=Sangalli%2C+G">Giancarlo Sangalli</a>, 
<a href="/search/math?searchtype=author&query=Tani%2C+M">Mattia Tani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.08952" title="Abstract">arXiv:2312.08952</a> (replaced) [<a href="/pdf/2312.08952" title="Download PDF">pdf</a>, <a href="/format/2312.08952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCMCTrack: Multi-Object Tracking with Uniform Camera Motion Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kefu Yi</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+K">Kai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiaolei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiangui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Rongdong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+W">Wei Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09075" title="Abstract">arXiv:2312.09075</a> (replaced) [<a href="/pdf/2312.09075" title="Download PDF">pdf</a>, <a href="/format/2312.09075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Verifiable Text Generation with Evolving Memory and  Self-Reflection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hengyi Cai</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yingyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xiaochi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaiqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dawei Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09507" title="Abstract">arXiv:2312.09507</a> (replaced) [<a href="/pdf/2312.09507" title="Download PDF">pdf</a>, <a href="/format/2312.09507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WAVER: Writing-style Agnostic Text-Video Retrieval via Distilling  Vision-Language Models Through Open-Vocabulary Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Huy Le</a>, 
<a href="/search/cs?searchtype=author&query=Kieu%2C+T">Tung Kieu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.09654" title="Abstract">arXiv:2312.09654</a> (replaced) [<a href="/pdf/2312.09654" title="Download PDF">pdf</a>, <a href="/format/2312.09654" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The cost of artificial latency in the PBS context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Natale%2C+U">Umberto Natale</a>, 
<a href="/search/cs?searchtype=author&query=Moser%2C+M">Michael Moser</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Statistical Finance (q-fin.ST)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.10813" title="Abstract">arXiv:2312.10813</a> (replaced) [<a href="/pdf/2312.10813" title="Download PDF">pdf</a>, <a href="/format/2312.10813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model  within 0.5K Parameters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hao%2C+T">Tianxiang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M">Mengyao Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jungong Han</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+G">Guiguang Ding</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.11747" title="Abstract">arXiv:2312.11747</a> (replaced) [<a href="/pdf/2312.11747" title="Download PDF">pdf</a>, <a href="/format/2312.11747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Stochastic Graph Generator for Counterfactual Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prado-Romero%2C+M+A">Mario Alfonso Prado-Romero</a>, 
<a href="/search/cs?searchtype=author&query=Prenkaj%2C+B">Bardh Prenkaj</a>, 
<a href="/search/cs?searchtype=author&query=Stilo%2C+G">Giovanni Stilo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in AAAI'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.12269" title="Abstract">arXiv:2312.12269</a> (replaced) [<a href="/pdf/2312.12269" title="Download PDF">pdf</a>, <a href="/ps/2312.12269" title="Download PostScript">ps</a>, <a href="/format/2312.12269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated speech audiometry: Can it work using open-source pre-trained  Kaldi-NL automatic speech recognition?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Araiza-Illan%2C+G">Gloria Araiza-Illan</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+L">Luke Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Truong%2C+K+P">Khiet P. Truong</a>, 
<a href="/search/cs?searchtype=author&query=Baskent%2C+D">Deniz Baskent</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages (double spaced), 5 figures, 3 tables, 54 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13784" title="Abstract">arXiv:2312.13784</a> (replaced) [<a href="/pdf/2312.13784" title="Download PDF">pdf</a>, <a href="/format/2312.13784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Evolutionary Community Detection Algorithms in Dynamic  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paoletti%2C+G">Giordano Paoletti</a>, 
<a href="/search/cs?searchtype=author&query=Gioacchini%2C+L">Luca Gioacchini</a>, 
<a href="/search/cs?searchtype=author&query=Mellia%2C+M">Marco Mellia</a>, 
<a href="/search/cs?searchtype=author&query=Vassio%2C+L">Luca Vassio</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+J+M">Jussara M. Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 4th Workshop on Graphs and more Complex structures for Learning and Reasoning (GCLR) at AAAI 2024
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 4th Workshop on Graphs and more Complex structures for Learning
  and Reasoning (GCLR) at AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13788" title="Abstract">arXiv:2312.13788</a> (replaced) [<a href="/pdf/2312.13788" title="Download PDF">pdf</a>, <a href="/format/2312.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-Source Reinforcement Learning Environments Implemented in MuJoCo  with Franka Manipulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zichun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuntao Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xiaohang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+L">Lei Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingdong Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.13941" title="Abstract">arXiv:2312.13941</a> (replaced) [<a href="/pdf/2312.13941" title="Download PDF">pdf</a>, <a href="/format/2312.13941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable 3D Face Generation with Conditional Style Code Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaolong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+J">Jianxin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14187" title="Abstract">arXiv:2312.14187</a> (replaced) [<a href="/pdf/2312.14187" title="Download PDF">pdf</a>, <a href="/format/2312.14187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with  Refined Data Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhaojian Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+N">Ning Shang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yangyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Can Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yishujie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wenxiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Q">Qiufeng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.14430" title="Abstract">arXiv:2312.14430</a> (replaced) [<a href="/html/2312.14430" title="Download HTML">html</a>, <a href="/format/2312.14430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Higashinaka%2C+R">Ryuichiro Higashinaka</a>, 
<a href="/search/cs?searchtype=author&query=Minato%2C+T">Takashi Minato</a>, 
<a href="/search/cs?searchtype=author&query=Nishizaki%2C+H">Hiromitsu Nishizaki</a>, 
<a href="/search/cs?searchtype=author&query=Nagai%2C+T">Takayuki Nagai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a proceedings of the Dialogue Robot Competition 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15567" title="Abstract">arXiv:2312.15567</a> (replaced) [<a href="/pdf/2312.15567" title="Download PDF">pdf</a>, <a href="/format/2312.15567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conversational Co-Speech Gesture Generation via Modeling Dialog  Intention, Emotion, and Context with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+H">Haiwei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zonghong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+H">Helen Meng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,2 figures, Accepted for publication at the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15948" title="Abstract">arXiv:2312.15948</a> (replaced) [<a href="/pdf/2312.15948" title="Download PDF">pdf</a>, <a href="/format/2312.15948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How digital will the future be? Analysis of prospective scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bugeau%2C+A">Aur&#xe9;lie Bugeau</a> (IUF, LaBRI, UB), 
<a href="/search/cs?searchtype=author&query=Ligozat%2C+A">Anne-Laure Ligozat</a> (ENSIIE, LISN, STL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.15987" title="Abstract">arXiv:2312.15987</a> (replaced) [<a href="/pdf/2312.15987" title="Download PDF">pdf</a>, <a href="/ps/2312.15987" title="Download PostScript">ps</a>, <a href="/format/2312.15987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Full-Stack End-to-End Sub-THz Simulations at 140 GHz using NYUSIM  Channel Model in ns-3
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poddar%2C+H">Hitesh Poddar</a>, 
<a href="/search/cs?searchtype=author&query=Chowdary%2C+A">Akhileswar Chowdary</a>, 
<a href="/search/cs?searchtype=author&query=Rappaport%2C+T+S">Theodore S. Rappaport</a>, 
<a href="/search/cs?searchtype=author&query=Chafii%2C+M">Marwa Chafii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16148" title="Abstract">arXiv:2312.16148</a> (replaced) [<a href="/pdf/2312.16148" title="Download PDF">pdf</a>, <a href="/format/2312.16148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Media Bias Taxonomy: A Systematic Literature Review on the Forms and  Automated Detection of Media Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinde%2C+T">Timo Spinde</a>, 
<a href="/search/cs?searchtype=author&query=Hinterreiter%2C+S">Smi Hinterreiter</a>, 
<a href="/search/cs?searchtype=author&query=Haak%2C+F">Fabian Haak</a>, 
<a href="/search/cs?searchtype=author&query=Ruas%2C+T">Terry Ruas</a>, 
<a href="/search/cs?searchtype=author&query=Giese%2C+H">Helge Giese</a>, 
<a href="/search/cs?searchtype=author&query=Meuschke%2C+N">Norman Meuschke</a>, 
<a href="/search/cs?searchtype=author&query=Gipp%2C+B">Bela Gipp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2312.16483" title="Abstract">arXiv:2312.16483</a> (replaced) [<a href="/pdf/2312.16483" title="Download PDF">pdf</a>, <a href="/ps/2312.16483" title="Download PostScript">ps</a>, <a href="/format/2312.16483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressivity and Approximation Properties of Deep Neural Networks with  ReLU$^k$ Activation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+J">Juncai He</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+T">Tong Mao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinchao Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.01527" title="Abstract">arXiv:2401.01527</a> (replaced) [<a href="/pdf/2401.01527" title="Download PDF">pdf</a>, <a href="/format/2401.01527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poisoning Attacks Against Recommender Systems: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Min Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Junliang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+H">Hao Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+S">Shazia Sadiq</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02130" title="Abstract">arXiv:2401.02130</a> (replaced) [<a href="/pdf/2401.02130" title="Download PDF">pdf</a>, <a href="/format/2401.02130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral-based Graph Neural Networks for Complementary Item  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haitong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xuying Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Suhang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hanyun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weiyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yequan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yujun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02501" title="Abstract">arXiv:2401.02501</a> (replaced) [<a href="/pdf/2401.02501" title="Download PDF">pdf</a>, <a href="/format/2401.02501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The cell signaling structure function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aho%2C+L">Layton Aho</a>, 
<a href="/search/cs?searchtype=author&query=Winter%2C+M">Mark Winter</a>, 
<a href="/search/cs?searchtype=author&query=DeCarlo%2C+M">Marc DeCarlo</a>, 
<a href="/search/cs?searchtype=author&query=Frismantiene%2C+A">Agne Frismantiene</a>, 
<a href="/search/cs?searchtype=author&query=Blum%2C+Y">Yannick Blum</a>, 
<a href="/search/cs?searchtype=author&query=Gagliardi%2C+P+A">Paolo Armando Gagliardi</a>, 
<a href="/search/cs?searchtype=author&query=Pertz%2C+O">Olivier Pertz</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A+R">Andrew R. Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.02873" title="Abstract">arXiv:2401.02873</a> (replaced) [<a href="/pdf/2401.02873" title="Download PDF">pdf</a>, <a href="/format/2401.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Chaining of Vehicle Plans with Time Windows
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Fiedler%2C+D">David Fiedler</a>, 
<a href="/search/math?searchtype=author&query=Difonzo%2C+F+V">Fabio V. Difonzo</a>, 
<a href="/search/math?searchtype=author&query=Mrkos%2C+J">Jan Mrkos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures, submitted to "Expert Systems with Applications" journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03144" title="Abstract">arXiv:2401.03144</a> (replaced) [<a href="/pdf/2401.03144" title="Download PDF">pdf</a>, <a href="/format/2401.03144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating Personalized Parsons Problems with Multi-Level Textual  Explanations to Scaffold Code Writing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinying Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+B+J">Barbara J. Ericson</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-Reviewed, Accepted for publication in Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2 (SIGCSE 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03200" title="Abstract">arXiv:2401.03200</a> (replaced) [<a href="/pdf/2401.03200" title="Download PDF">pdf</a>, <a href="/format/2401.03200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Coexistence of Infection Spread Patterns in the Global Dynamics of  COVID-19 Dissemination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+H">Hiroyasu Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Souma%2C+W">Wataru Souma</a>, 
<a href="/search/cs?searchtype=author&query=Fujiwara%2C+Y">Yoshi Fujiwara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03302" title="Abstract">arXiv:2401.03302</a> (replaced) [<a href="/pdf/2401.03302" title="Download PDF">pdf</a>, <a href="/format/2401.03302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical  Images Using YOLOv8 and DeiT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hashemi%2C+S+M+H">Seyed Mohammad Hossein Hashemi</a>, 
<a href="/search/eess?searchtype=author&query=Safari%2C+L">Leila Safari</a>, 
<a href="/search/eess?searchtype=author&query=Taromi%2C+A+D">Amirhossein Dadashzade Taromi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03621" title="Abstract">arXiv:2401.03621</a> (replaced) [<a href="/pdf/2401.03621" title="Download PDF">pdf</a>, <a href="/ps/2401.03621" title="Download PostScript">ps</a>, <a href="/format/2401.03621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Applications in Traumatic Brain Injury: A Spotlight on  Mild TBI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ellethy%2C+H">Hanem Ellethy</a>, 
<a href="/search/eess?searchtype=author&query=Chandra%2C+S+S">Shekhar S. Chandra</a>, 
<a href="/search/eess?searchtype=author&query=Vegh%2C+V">Viktor Vegh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has 34 pages, 3 figures, and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03786" title="Abstract">arXiv:2401.03786</a> (replaced) [<a href="/pdf/2401.03786" title="Download PDF">pdf</a>, <a href="/format/2401.03786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Long-term Safe Reinforcement Learning with Binary Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wachi%2C+A">Akifumi Wachi</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+W">Wataru Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+K">Kazumune Hashimoto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AAAI-24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03854" title="Abstract">arXiv:2401.03854</a> (replaced) [<a href="/pdf/2401.03854" title="Download PDF">pdf</a>, <a href="/format/2401.03854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIER: Text-Image Encoder-based Regression for AIGC Image Quality  Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiquan Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xinyan Cao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+J">Jinming Che</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Sen Liang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+W">Wei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jinlong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xixin Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures. arXiv admin note: text overlap with <a href="/abs/2312.05897">arXiv:2312.05897</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.03955" title="Abstract">arXiv:2401.03955</a> (replaced) [<a href="/pdf/2401.03955" title="Download PDF">pdf</a>, <a href="/format/2401.03955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiny Time Mixers (TTMs): Fast Pretrained Models for Enhanced  Zero/Few-Shot Forecasting of Multivariate Time Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ekambaram%2C+V">Vijay Ekambaram</a>, 
<a href="/search/cs?searchtype=author&query=Jati%2C+A">Arindam Jati</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+N+H">Nam H. Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Dayama%2C+P">Pankaj Dayama</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+C">Chandra Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Gifford%2C+W+M">Wesley M. Gifford</a>, 
<a href="/search/cs?searchtype=author&query=Kalagnanam%2C+J">Jayant Kalagnanam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04098" title="Abstract">arXiv:2401.04098</a> (replaced) [<a href="/pdf/2401.04098" title="Download PDF">pdf</a>, <a href="/format/2401.04098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling AoII in Push- and Pull-Based Sampling of Continuous Time Markov  Chains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosandal%2C+I">Ismail Cosandal</a>, 
<a href="/search/cs?searchtype=author&query=Akar%2C+N">Nail Akar</a>, 
<a href="/search/cs?searchtype=author&query=Ulukus%2C+S">Sennur Ulukus</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04126" title="Abstract">arXiv:2401.04126</a> (replaced) [<a href="/e-print/2401.04126" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Concept of the Tactile Signature System for Individuals with Visual  Impairments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kremenchutskiy%2C+A">Anatoliy Kremenchutskiy</a>, 
<a href="/search/cs?searchtype=author&query=Gabdreshov%2C+G">Galymzhan Gabdreshov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The principles of connection between the interaction of a blind individual with the tactile field, when he uses touch, drawing various figures and forms, and the resulting prompts to the user to create a valid signature, have not been disclosed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04206" title="Abstract">arXiv:2401.04206</a> (replaced) [<a href="/pdf/2401.04206" title="Download PDF">pdf</a>, <a href="/format/2401.04206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Racing From an AI Coach: Effects of Multimodal Autonomous  Driving Explanations on Driving Performance, Cognitive Load, Expertise, and  Trust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaufman%2C+R">Robert Kaufman</a>, 
<a href="/search/cs?searchtype=author&query=Costa%2C+J">Jean Costa</a>, 
<a href="/search/cs?searchtype=author&query=Kimani%2C+E">Everlyne Kimani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04308" title="Abstract">arXiv:2401.04308</a> (replaced) [<a href="/pdf/2401.04308" title="Download PDF">pdf</a>, <a href="/format/2401.04308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Remotely Verifiable Software Integrity in Resource-Constrained  IoT Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=De+Oliveira+Nunes%2C+I">Ivan De Oliveira Nunes</a>, 
<a href="/search/cs?searchtype=author&query=Jakkamsetti%2C+S">Sashidhar Jakkamsetti</a>, 
<a href="/search/cs?searchtype=author&query=Rattanavipanon%2C+N">Norrathep Rattanavipanon</a>, 
<a href="/search/cs?searchtype=author&query=Tsudik%2C+G">Gene Tsudik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04543" title="Abstract">arXiv:2401.04543</a> (replaced) [<a href="/pdf/2401.04543" title="Download PDF">pdf</a>, <a href="/format/2401.04543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Healthcare Voice AI Assistants: Factors Influencing Trust and Intention  to Use
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhan%2C+X">Xiao Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Abdi%2C+N">Noura Abdi</a>, 
<a href="/search/cs?searchtype=author&query=Seymour%2C+W">William Seymour</a>, 
<a href="/search/cs?searchtype=author&query=Such%2C+J">Jose Such</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages. This is a preprint of the paper accepted for the 27th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW'24)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04621" title="Abstract">arXiv:2401.04621</a> (replaced) [<a href="/pdf/2401.04621" title="Download PDF">pdf</a>, <a href="/format/2401.04621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DebugBench: Evaluating Debugging Capability of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tian%2C+R">Runchu Tian</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yining Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yujia Qin</a>, 
<a href="/search/cs?searchtype=author&query=Cong%2C+X">Xin Cong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yinxu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yesai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04679" title="Abstract">arXiv:2401.04679</a> (replaced) [<a href="/pdf/2401.04679" title="Download PDF">pdf</a>, <a href="/format/2401.04679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nikdan%2C+M">Mahdi Nikdan</a>, 
<a href="/search/cs?searchtype=author&query=Tabesh%2C+S">Soroush Tabesh</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04718" title="Abstract">arXiv:2401.04718</a> (replaced) [<a href="/pdf/2401.04718" title="Download PDF">pdf</a>, <a href="/format/2401.04718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Jump Cut Smoothing for Talking Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+T">Taesung Park</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shechtman%2C+E">Eli Shechtman</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richard Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Correct typos in the caption of Figure 1; Change the project website address. Project page: <a href="https://jeanne-wang.github.io/jumpcutsmoothing/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.04847" title="Abstract">arXiv:2401.04847</a> (replaced) [<a href="/pdf/2401.04847" title="Download PDF">pdf</a>, <a href="/format/2401.04847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Correctness of the Generalized Isotonic Recursive Partitioning  Algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Won%2C+J">Joong-Ho Won</a>, 
<a href="/search/stat?searchtype=author&query=Jung%2C+J">Jihan Jung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05042" title="Abstract">arXiv:2401.05042</a> (replaced) [<a href="/pdf/2401.05042" title="Download PDF">pdf</a>, <a href="/format/2401.05042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DRL-based Latency-Aware Network Slicing in O-RAN with Time-Varying SLAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raftopoulos%2C+R">Raoul Raftopoulos</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oro%2C+S">Salvatore D&#x27;Oro</a>, 
<a href="/search/cs?searchtype=author&query=Melodia%2C+T">Tommaso Melodia</a>, 
<a href="/search/cs?searchtype=author&query=Schembra%2C+G">Giovanni Schembra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05102" title="Abstract">arXiv:2401.05102</a> (replaced) [<a href="/pdf/2401.05102" title="Download PDF">pdf</a>, <a href="/ps/2401.05102" title="Download PostScript">ps</a>, <a href="/format/2401.05102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Duality Upper Bound for Finite-State Channels with Feedback
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huleihel%2C+B">Bashar Huleihel</a>, 
<a href="/search/cs?searchtype=author&query=Sabag%2C+O">Oron Sabag</a>, 
<a href="/search/cs?searchtype=author&query=Aharoni%2C+Z">Ziv Aharoni</a>, 
<a href="/search/cs?searchtype=author&query=Permuter%2C+H+H">Haim H. Permuter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05167" title="Abstract">arXiv:2401.05167</a> (replaced) [<a href="/pdf/2401.05167" title="Download PDF">pdf</a>, <a href="/format/2401.05167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Watermark Text Pattern Spotting in Document Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krubi%C5%84ski%2C+M">Mateusz Krubi&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Matcovici%2C+S">Stefan Matcovici</a>, 
<a href="/search/cs?searchtype=author&query=Grigore%2C+D">Diana Grigore</a>, 
<a href="/search/cs?searchtype=author&query=Voinea%2C+D">Daniel Voinea</a>, 
<a href="/search/cs?searchtype=author&query=Popa%2C+A">Alin-Ionut Popa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05171" title="Abstract">arXiv:2401.05171</a> (replaced) [<a href="/pdf/2401.05171" title="Download PDF">pdf</a>, <a href="/ps/2401.05171" title="Download PostScript">ps</a>, <a href="/format/2401.05171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Extreme Value Theory Based Rate Selection for  Ultra-Reliable Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehrnia%2C+N">Niloofar Mehrnia</a>, 
<a href="/search/cs?searchtype=author&query=Coleri%2C+S">Sinem Coleri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 6 figures, submitted to the IEEE Transactions on Vehicular Technology (TVT)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05239" title="Abstract">arXiv:2401.05239</a> (replaced) [<a href="/pdf/2401.05239" title="Download PDF">pdf</a>, <a href="/ps/2401.05239" title="Download PostScript">ps</a>, <a href="/format/2401.05239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Failures of public key infrastructure: 53 year survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dumitrescu%2C+A">Adrian-Tudor Dumitrescu</a>, 
<a href="/search/cs?searchtype=author&query=Pouwelse%2C+J">Johan Pouwelse</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 table, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2401.05254" title="Abstract">arXiv:2401.05254</a> (replaced) [<a href="/pdf/2401.05254" title="Download PDF">pdf</a>, <a href="/format/2401.05254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-based Valence and Arousal Expressions between the United States  and China: a Cross-Cultural Examination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cho%2C+Y">Young-Min Cho</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+D">Dandan Pang</a>, 
<a href="/search/cs?searchtype=author&query=Thapa%2C+S">Stuti Thapa</a>, 
<a href="/search/cs?searchtype=author&query=Sherman%2C+G">Garrick Sherman</a>, 
<a href="/search/cs?searchtype=author&query=Ungar%2C+L">Lyle Ungar</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+L">Louis Tay</a>, 
<a href="/search/cs?searchtype=author&query=Guntuku%2C+S+C">Sharath Chandra Guntuku</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item311">Cross-lists</a></li>
<li><a href="#item385">Replacements</a></li>
</ul>
<small>[ total of 576 entries:  <b>1-576</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2401">2401</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
