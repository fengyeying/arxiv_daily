<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Tue 12 Sep 23  to  Wed 13 Sep 23, announced Thu, 14 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item268">Cross-lists</a></li>
<li><a href="#item308">Replacements</a></li>
</ul>
<small>[ total of 505 entries:  <b>1-505</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Thu, 14 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06444" title="Abstract">arXiv:2309.06444</a> [<a href="/pdf/2309.06444" title="Download PDF">pdf</a>, <a href="/format/2309.06444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting Everyday Objects with the Metaverse: A Unified Recognition  Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Towey%2C+D">Dave Towey</a>, 
<a href="/search/cs?searchtype=author&query=French%2C+A+P">Andrew P. French</a>, 
<a href="/search/cs?searchtype=author&query=Benford%2C+S">Steve Benford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper includes 6 pages, 4 figures, and 1 table, and has been accepted to be published by the 2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC), Los Alamitos, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The recent Facebook rebranding to Meta has drawn renewed attention to the
metaverse. Technology giants, amongst others, are increasingly embracing the
vision and opportunities of a hybrid social experience that mixes physical and
virtual interactions. As the metaverse gains in traction, it is expected that
everyday objects may soon connect more closely with virtual elements. However,
discovering this "hidden" virtual world will be a crucial first step to
interacting with it in this new augmented world. In this paper, we address the
problem of connecting physical objects with their virtual counterparts,
especially through connections built upon visual markers. We propose a unified
recognition framework that guides approaches to the metaverse access points. We
illustrate the use of the framework through experimental studies under
different conditions, in which an interactive and visually attractive
decoration pattern, an Artcode, is used as the approach to enable the
connection. This paper will be of interest to, amongst others, researchers
working in Interaction Design or Augmented Reality who are seeking techniques
or guidelines for augmenting physical objects in an unobtrusive, complementary
manner.
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06453" title="Abstract">arXiv:2309.06453</a> [<a href="/pdf/2309.06453" title="Download PDF">pdf</a>, <a href="/format/2309.06453" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrowing the Gap between Supervised and Unsupervised Sentence  Representation Learning with Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Richong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Z">Zhijie Nie</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+Y">Yongyi Mao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Sentence Representation Learning (SRL) is a fundamental task in Natural
Language Processing (NLP), with Contrastive learning of Sentence Embeddings
(CSE) as the mainstream technique due to its superior performance. An
intriguing phenomenon in CSE is the significant performance gap between
supervised and unsupervised methods, even when their sentence encoder and loss
function are the same. Previous works attribute this performance gap to
differences in two representation properties (alignment and uniformity).
However, alignment and uniformity only measure the results, which means they
cannot answer "What happens during the training process that leads to the
performance gap?" and "How can the performance gap be narrowed?". In this
paper, we conduct empirical experiments to answer these "What" and "How"
questions. We first answer the "What" question by thoroughly comparing the
behavior of supervised and unsupervised CSE during their respective training
processes. From the comparison, We observe a significant difference in fitting
difficulty. Thus, we introduce a metric, called Fitting Difficulty Increment
(FDI), to measure the fitting difficulty gap between the evaluation dataset and
the held-out training dataset, and use the metric to answer the "What"
question. Then, based on the insights gained from the "What" question, we
tackle the "How" question by increasing the fitting difficulty of the training
dataset. We achieve this by leveraging the In-Context Learning (ICL) capability
of the Large Language Model (LLM) to generate data that simulates complex
patterns. By utilizing the hierarchical patterns in the LLM-generated data, we
effectively narrow the gap between supervised and unsupervised CSE.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06457" title="Abstract">arXiv:2309.06457</a> [<a href="/pdf/2309.06457" title="Download PDF">pdf</a>, <a href="/format/2309.06457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Opportunistic Reflection in Reconfigurable Intelligent Surface-Assisted  Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+W">Wei Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE PIMRC 2023, Toronto, Canada. arXiv admin note: text overlap with <a href="/abs/2303.09183">arXiv:2303.09183</a>. text overlap with <a href="/abs/2309.06326">arXiv:2309.06326</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper focuses on multiple-access protocol design in a wireless network
assisted by multiple reconfigurable intelligent surfaces (RISs). By extending
the existing approaches in single-user or single-RIS cases, we present two
benchmark schemes for this multi-user multi-RIS scenario. Inspecting their
shortcomings, a simple but efficient method coined opportunistic multi-user
reflection (OMUR) is proposed. The key idea is to opportunistically select the
best user as the anchor for optimizing the RISs, and non-orthogonally
transmitting all users' signals simultaneously. A simplified version of OMUR
exploiting random phase shifts is also proposed to avoid the complexity of RIS
channel estimation.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06460" title="Abstract">arXiv:2309.06460</a> [<a href="/pdf/2309.06460" title="Download PDF">pdf</a>, <a href="/format/2309.06460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Widely Interpretable Semantic Representation: Frameless Meaning  Representation for Broader Applicability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+L">Lydia Feng</a>, 
<a href="/search/cs?searchtype=author&query=Williamson%2C+G">Gregor Williamson</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Han He</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+D">Jinho D. Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper presents a novel semantic representation, WISeR, that overcomes
challenges for Abstract Meaning Representation (AMR). Despite its strengths,
AMR is not easily applied to languages or domains without predefined semantic
frames, and its use of numbered arguments results in semantic role labels,
which are not directly interpretable and are semantically overloaded for
parsers. We examine the numbered arguments of predicates in AMR and convert
them to thematic roles that do not require reference to semantic frames. We
create a new corpus of 1K English dialogue sentences annotated in both WISeR
and AMR. WISeR shows stronger inter-annotator agreement for beginner and
experienced annotators, with beginners becoming proficient in WISeR annotation
more quickly. Finally, we train a state-of-the-art parser on the AMR 3.0 corpus
and a WISeR corpus converted from AMR 3.0. The parser is evaluated on these
corpora and our dialogue corpus. The WISeR model exhibits higher accuracy than
its AMR counterpart across the board, demonstrating that WISeR is easier for
parsers to learn.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06462" title="Abstract">arXiv:2309.06462</a> [<a href="/pdf/2309.06462" title="Download PDF">pdf</a>, <a href="/format/2309.06462" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Segmentation Using 2D Skeleton Heatmaps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyder%2C+S+W">Syed Waleed Hyder</a>, 
<a href="/search/cs?searchtype=author&query=Usama%2C+M">Muhammad Usama</a>, 
<a href="/search/cs?searchtype=author&query=Zafar%2C+A">Anas Zafar</a>, 
<a href="/search/cs?searchtype=author&query=Naufil%2C+M">Muhammad Naufil</a>, 
<a href="/search/cs?searchtype=author&query=Konin%2C+A">Andrey Konin</a>, 
<a href="/search/cs?searchtype=author&query=Zia%2C+M+Z">M. Zeeshan Zia</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+Q">Quoc-Huy Tran</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents a 2D skeleton-based action segmentation method with
applications in fine-grained human activity recognition. In contrast with
state-of-the-art methods which directly take sequences of 3D skeleton
coordinates as inputs and apply Graph Convolutional Networks (GCNs) for
spatiotemporal feature learning, our main idea is to use sequences of 2D
skeleton heatmaps as inputs and employ Temporal Convolutional Networks (TCNs)
to extract spatiotemporal features. Despite lacking 3D information, our
approach yields comparable/superior performances and better robustness against
missing keypoints than previous methods on action segmentation datasets.
Moreover, we improve the performances further by using both 2D skeleton
heatmaps and RGB videos as inputs. To our best knowledge, this is the first
work to utilize 2D skeleton heatmap inputs and the first work to explore 2D
skeleton+RGB fusion for action segmentation.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06484" title="Abstract">arXiv:2309.06484</a> [<a href="/pdf/2309.06484" title="Download PDF">pdf</a>, <a href="/format/2309.06484" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning topological operations on meshes with application to block  decomposition of polygons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A">Arjun Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yulong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Persson%2C+P">Per-Olof Persson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Computer-Aided Design Journal. Presented at 17th US National Conference on Computational Mechanics, Albuquerque, NM
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a learning based framework for mesh quality improvement on
unstructured triangular and quadrilateral meshes. Our model learns to improve
mesh quality according to a prescribed objective function purely via self-play
reinforcement learning with no prior heuristics. The actions performed on the
mesh are standard local and global element operations. The goal is to minimize
the deviation of the node degrees from their ideal values, which in the case of
interior vertices leads to a minimization of irregular nodes.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06490" title="Abstract">arXiv:2309.06490</a> [<a href="/pdf/2309.06490" title="Download PDF">pdf</a>, <a href="/format/2309.06490" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models for Automated Dialogue Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finch%2C+S+E">Sarah E. Finch</a>, 
<a href="/search/cs?searchtype=author&query=Paek%2C+E+S">Ellie S. Paek</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+D">Jinho D. Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGDIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Developing high-performing dialogue systems benefits from the automatic
identification of undesirable behaviors in system responses. However, detecting
such behaviors remains challenging, as it draws on a breadth of general
knowledge and understanding of conversational practices. Although recent
research has focused on building specialized classifiers for detecting specific
dialogue behaviors, the behavior coverage is still incomplete and there is a
lack of testing on real-world human-bot interactions. This paper investigates
the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to
perform dialogue behavior detection for nine categories in real human-bot
dialogues. We aim to assess whether ChatGPT can match specialized models and
approximate human performance, thereby reducing the cost of behavior detection
tasks. Our findings reveal that neither specialized models nor ChatGPT have yet
achieved satisfactory results for this task, falling short of human
performance. Nevertheless, ChatGPT shows promising potential and often
outperforms specialized detection models. We conclude with an in-depth
examination of the prevalent shortcomings of ChatGPT, offering guidance for
future research to enhance LLM capabilities.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06494" title="Abstract">arXiv:2309.06494</a> [<a href="/pdf/2309.06494" title="Download PDF">pdf</a>, <a href="/format/2309.06494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-smooth Control Barrier Functions for Stochastic Dynamical Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahs%2C+M">Matti Vahs</a>, 
<a href="/search/cs?searchtype=author&query=Tumova%2C+J">Jana Tumova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Uncertainties arising in various control systems, such as robots that are
subject to unknown disturbances or environmental variations, pose significant
challenges for ensuring system safety, such as collision avoidance. At the same
time, safety specifications are getting more and more complex, e.g., by
composing multiple safety objectives through Boolean operators resulting in
non-smooth descriptions of safe sets. Control Barrier Functions (CBFs) have
emerged as a control technique to provably guarantee system safety. In most
settings, they rely on an assumption of having deterministic dynamics and
smooth safe sets. This paper relaxes these two assumptions by extending CBFs to
encompass control systems with stochastic dynamics and safe sets defined by
non-smooth functions. By explicitly considering the stochastic nature of system
dynamics and accommodating complex safety specifications, our method enables
the design of safe control strategies in uncertain and complex systems. We
provide formal guarantees on the safety of the system by leveraging the
theoretical foundations of stochastic CBFs and non-smooth safe sets. Numerical
simulations demonstrate the effectiveness of the approach in various scenarios.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06495" title="Abstract">arXiv:2309.06495</a> [<a href="/pdf/2309.06495" title="Download PDF">pdf</a>, <a href="/format/2309.06495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AGIBench: A Multi-granularity, Multimodal, Human-referenced,  Auto-scoring Benchmark for Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fei Tang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wanling Gao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+L">Luzhou Peng</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jianfeng Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Performance (cs.PF)

</div>
<p class="mathjax">Large language models (LLMs) like ChatGPT have revealed amazing intelligence.
How to evaluate the question-solving abilities of LLMs and their degrees of
intelligence is a hot-spot but challenging issue. First, the question-solving
abilities are interlaced with different ability branches like understanding and
massive knowledge categories like mathematics. Second, the inputs of questions
are multimodal that may involve text and images. Third, the response format of
LLMs is diverse and thus poses great challenges for result extraction and
evaluation. In this paper, we propose AGIBench -- a multi-granularity,
multimodal, human-referenced, and auto-scoring benchmarking methodology for
LLMs. Instead of a collection of blended questions, AGIBench focuses on three
typical ability branches and adopts a four-tuple &lt;ability branch, knowledge,
difficulty, modal&gt; to label the attributes of each question. First, it supports
multi-granularity benchmarking, e.g., per-question, per-ability branch,
per-knowledge, per-modal, per-dataset, and per-difficulty level granularities.
Second, it contains multimodal input, including text and images. Third, it
classifies all the questions into five degrees of difficulty according to the
average accuracy rate of abundant educated humans (human-referenced). Fourth,
it adopts zero-shot learning to avoid introducing additional unpredictability
and provides an auto-scoring method to extract and judge the result. Finally,
it defines multi-dimensional metrics, including accuracy under the average,
worst, best, and majority voting cases, and repeatability. AGIBench is
publically available from \url{https://www.benchcouncil.org/agibench}.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06496" title="Abstract">arXiv:2309.06496</a> [<a href="/pdf/2309.06496" title="Download PDF">pdf</a>, <a href="/format/2309.06496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Level Up: Private Non-Interactive Decision Tree Evaluation using  Levelled Homomorphic Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahdavi%2C+R+A">Rasoul Akhavan Mahdavi</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+H">Haoyan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Linkov%2C+D">Dimitry Linkov</a>, 
<a href="/search/cs?searchtype=author&query=Kerschbaum%2C+F">Florian Kerschbaum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">As machine learning as a service continues gaining popularity, concerns about
privacy and intellectual property arise. Users often hesitate to disclose their
private information to obtain a service, while service providers aim to protect
their proprietary models. Decision trees, a widely used machine learning model,
are favoured for their simplicity, interpretability, and ease of training. In
this context, Private Decision Tree Evaluation (PDTE) enables a server holding
a private decision tree to provide predictions based on a client's private
attributes. The protocol is such that the server learns nothing about the
client's private attributes. Similarly, the client learns nothing about the
server's model besides the prediction and some hyperparameters.
<br />In this paper, we propose two novel non-interactive PDTE protocols,
XXCMP-PDTE and RCC-PDTE, based on two new non-interactive comparison protocols,
XXCMP and RCC. Our evaluation of these comparison operators demonstrates that
our proposed constructions can efficiently evaluate high-precision numbers.
Specifically, RCC can compare 32-bit numbers in under 10 milliseconds.
<br />We assess our proposed PDTE protocols on decision trees trained over UCI
datasets and compare our results with existing work in the field. Moreover, we
evaluate synthetic decision trees to showcase scalability, revealing that
RCC-PDTE can evaluate a decision tree with over 1000 nodes and 16 bits of
precision in under 2 seconds. In contrast, the current state-of-the-art
requires over 10 seconds to evaluate such a tree with only 11 bits of
precision.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06497" title="Abstract">arXiv:2309.06497</a> [<a href="/pdf/2309.06497" title="Download PDF">pdf</a>, <a href="/format/2309.06497" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Distributed Data-Parallel PyTorch Implementation of the Distributed  Shampoo Optimizer for Training Neural Networks At-Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+H+M">Hao-Jun Michael Shi</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T">Tsung-Hsien Lee</a>, 
<a href="/search/cs?searchtype=author&query=Iwasaki%2C+S">Shintaro Iwasaki</a>, 
<a href="/search/cs?searchtype=author&query=Gallego-Posada%2C+J">Jose Gallego-Posada</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhijing Li</a>, 
<a href="/search/cs?searchtype=author&query=Rangadurai%2C+K">Kaushik Rangadurai</a>, 
<a href="/search/cs?searchtype=author&query=Mudigere%2C+D">Dheevatsa Mudigere</a>, 
<a href="/search/cs?searchtype=author&query=Rabbat%2C+M">Michael Rabbat</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 8 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Mathematical Software (cs.MS); Optimization and Control (math.OC)

</div>
<p class="mathjax">Shampoo is an online and stochastic optimization algorithm belonging to the
AdaGrad family of methods for training neural networks. It constructs a
block-diagonal preconditioner where each block consists of a coarse Kronecker
product approximation to full-matrix AdaGrad for each parameter of the neural
network. In this work, we provide a complete description of the algorithm as
well as the performance optimizations that our implementation leverages to
train deep networks at-scale in PyTorch. Our implementation enables fast
multi-GPU distributed data-parallel training by distributing the memory and
computation associated with blocks of each parameter via PyTorch's DTensor data
structure and performing an AllGather primitive on the computed search
directions at each iteration. This major performance enhancement enables us to
achieve at most a 10% performance reduction in per-step wall-clock time
compared against standard diagonal-scaling-based adaptive gradient methods. We
validate our implementation by performing an ablation study on training
ImageNet ResNet50, demonstrating Shampoo's superiority over standard training
recipes with minimal hyperparameter tuning.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06499" title="Abstract">arXiv:2309.06499</a> [<a href="/pdf/2309.06499" title="Download PDF">pdf</a>, <a href="/format/2309.06499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Belief Control Barrier Functions for Risk-aware Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vahs%2C+M">Matti Vahs</a>, 
<a href="/search/cs?searchtype=author&query=Pek%2C+C">Christian Pek</a>, 
<a href="/search/cs?searchtype=author&query=Tumova%2C+J">Jana Tumova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ensuring safety in real-world robotic systems is often challenging due to
unmodeled disturbances and noisy sensor measurements. To account for such
stochastic uncertainties, many robotic systems leverage probabilistic state
estimators such as Kalman filters to obtain a robot's belief, i.e. a
probability distribution over possible states. We propose belief control
barrier functions (BCBFs) to enable risk-aware control synthesis, leveraging
all information provided by state estimators. This allows robots to stay in
predefined safety regions with desired confidence under these stochastic
uncertainties. BCBFs are general and can be applied to a variety of robotic
systems that use extended Kalman filters as state estimator. We demonstrate
BCBFs on a quadrotor that is exposed to external disturbances and varying
sensing conditions. Our results show improved safety compared to traditional
state-based approaches while allowing control frequencies of up to 1kHz.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06503" title="Abstract">arXiv:2309.06503</a> [<a href="/pdf/2309.06503" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models and Weak Supervision for Social Media  data annotation: an evaluation using COVID-19 self-reported vaccination  tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tekumalla%2C+R">Ramya Tekumalla</a>, 
<a href="/search/cs?searchtype=author&query=Banda%2C+J+M">Juan M. Banda</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The COVID-19 pandemic has presented significant challenges to the healthcare
industry and society as a whole. With the rapid development of COVID-19
vaccines, social media platforms have become a popular medium for discussions
on vaccine-related topics. Identifying vaccine-related tweets and analyzing
them can provide valuable insights for public health research-ers and
policymakers. However, manual annotation of a large number of tweets is
time-consuming and expensive. In this study, we evaluate the usage of Large
Language Models, in this case GPT-4 (March 23 version), and weak supervision,
to identify COVID-19 vaccine-related tweets, with the purpose of comparing
performance against human annotators. We leveraged a manu-ally curated
gold-standard dataset and used GPT-4 to provide labels without any additional
fine-tuning or instructing, in a single-shot mode (no additional prompting).
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06504" title="Abstract">arXiv:2309.06504</a> [<a href="/pdf/2309.06504" title="Download PDF">pdf</a>, <a href="/format/2309.06504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Bitrate Neuromorphic Encoding for Continuous-Time Gauss-Markov  Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cuvelier%2C+T">Travis Cuvelier</a>, 
<a href="/search/cs?searchtype=author&query=Ogden%2C+R">Ronald Ogden</a>, 
<a href="/search/cs?searchtype=author&query=Tanaka%2C+T">Takashi Tanaka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In this work, we study minimum data rate tracking of a dynamical system under
a neuromorphic event-based sensing paradigm. We begin by bridging the gap
between continuous-time (CT) system dynamics and information theory's causal
rate distortion theory. We motivate the use of non-singular source codes to
quantify bitrates in event-based sampling schemes. This permits an analysis of
minimum bitrate event-based tracking using tools already established in the
control and information theory literature. We derive novel, nontrivial lower
bounds to event-based sensing, and compare the lower bound with the performance
of well-known schemes in the established literature.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06511" title="Abstract">arXiv:2309.06511</a> [<a href="/pdf/2309.06511" title="Download PDF">pdf</a>, <a href="/format/2309.06511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DF-TransFusion: Multimodal Deepfake Detection via Lip-Audio  Cross-Attention and Facial Self-Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharel%2C+A">Aaditya Kharel</a>, 
<a href="/search/cs?searchtype=author&query=Paranjape%2C+M">Manas Paranjape</a>, 
<a href="/search/cs?searchtype=author&query=Bera%2C+A">Aniket Bera</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">With the rise in manipulated media, deepfake detection has become an
imperative task for preserving the authenticity of digital content. In this
paper, we present a novel multi-modal audio-video framework designed to
concurrently process audio and video inputs for deepfake detection tasks. Our
model capitalizes on lip synchronization with input audio through a
cross-attention mechanism while extracting visual cues via a fine-tuned VGG-16
network. Subsequently, a transformer encoder network is employed to perform
facial self-attention. We conduct multiple ablation studies highlighting
different strengths of our approach. Our multi-modal methodology outperforms
state-of-the-art multi-modal deepfake detection techniques in terms of F-1 and
per-video AUC scores.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06513" title="Abstract">arXiv:2309.06513</a> [<a href="/pdf/2309.06513" title="Download PDF">pdf</a>, <a href="/format/2309.06513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RackBlox: A Software-Defined Rack-Scale Storage System with  Network-Storage Co-Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reidys%2C+B">Benjamin Reidys</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yuqi Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+D">Daixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sukhwani%2C+B">Bharat Sukhwani</a>, 
<a href="/search/cs?searchtype=author&query=Hwu%2C+W">Wen-mei Hwu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Deming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Asaad%2C+S">Sameh Asaad</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jian Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages. Published in published in ACM SIGOPS 29th Symposium on Operating Systems Principles (SOSP'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Operating Systems (cs.OS)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Software-defined networking (SDN) and software-defined flash (SDF) have been
serving as the backbone of modern data centers. They are managed separately to
handle I/O requests. At first glance, this is a reasonable design by following
the rack-scale hierarchical design principles. However, it suffers from
suboptimal end-to-end performance, due to the lack of coordination between SDN
and SDF.
<br />In this paper, we co-design the SDN and SDF stack by redefining the functions
of their control plane and data plane, and splitting up them within a new
architecture named RackBlox. RackBlox decouples the storage management
functions of flash-based solid-state drives (SSDs), and allow the SDN to track
and manage the states of SSDs in a rack. Therefore, we can enable the state
sharing between SDN and SDF, and facilitate global storage resource management.
RackBlox has three major components: (1) coordinated I/O scheduling, in which
it dynamically adjusts the I/O scheduling in the storage stack with the
measured and predicted network latency, such that it can coordinate the effort
of I/O scheduling across the network and storage stack for achieving
predictable end-to-end performance; (2) coordinated garbage collection (GC), in
which it will coordinate the GC activities across the SSDs in a rack to
minimize their impact on incoming I/O requests; (3) rack-scale wear leveling,
in which it enables global wear leveling among SSDs in a rack by periodically
swapping data, for achieving improved device lifetime for the entire rack. We
implement RackBlox using programmable SSDs and switch. Our experiments
demonstrate that RackBlox can reduce the tail latency of I/O requests by up to
5.8x over state-of-the-art rack-scale storage systems.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06517" title="Abstract">arXiv:2309.06517</a> [<a href="/pdf/2309.06517" title="Download PDF">pdf</a>, <a href="/format/2309.06517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed  Hinglish Memes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shreyash Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Suryavardan%2C+S">S Suryavardan</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+M">Megha Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Patwa%2C+P">Parth Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Rani%2C+A">Anku Rani</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Reganti%2C+A">Aishwarya Reganti</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amitava Das</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Chinnakotla%2C+M">Manoj Chinnakotla</a>, 
<a href="/search/cs?searchtype=author&query=Ekbal%2C+A">Asif Ekbal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Srijan Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Defactify2 @AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Analyzing memes on the internet has emerged as a crucial endeavor due to the
impact this multi-modal form of content wields in shaping online discourse.
Memes have become a powerful tool for expressing emotions and sentiments,
possibly even spreading hate and misinformation, through humor and sarcasm. In
this paper, we present the overview of the Memotion 3 shared task, as part of
the DeFactify 2 workshop at AAAI-23. The task released an annotated dataset of
Hindi-English code-mixed memes based on their Sentiment (Task A), Emotion (Task
B), and Emotion intensity (Task C). Each of these is defined as an individual
task and the participants are ranked separately for each task. Over 50 teams
registered for the shared task and 5 made final submissions to the test set of
the Memotion 3 dataset. CLIP, BERT modifications, ViT etc. were the most
popular models among the participants along with approaches such as
Student-Teacher model, Fusion, and Ensembling. The best final F1 score for Task
A is 34.41, Task B is 79.77 and Task C is 59.82.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06519" title="Abstract">arXiv:2309.06519</a> [<a href="/pdf/2309.06519" title="Download PDF">pdf</a>, <a href="/format/2309.06519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Q-learning Approach for Adherence-Aware Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Faros%2C+I">Ioannis Faros</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+A">Aditya Dave</a>, 
<a href="/search/cs?searchtype=author&query=Malikopoulos%2C+A+A">Andreas A. Malikopoulos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">In many real-world scenarios involving high-stakes and safety implications, a
human decision-maker (HDM) may receive recommendations from an artificial
intelligence while holding the ultimate responsibility of making decisions. In
this letter, we develop an "adherence-aware Q-learning" algorithm to address
this problem. The algorithm learns the "adherence level" that captures the
frequency with which an HDM follows the recommended actions and derives the
best recommendation policy in real time. We prove the convergence of the
proposed Q-learning algorithm to the optimal value and evaluate its performance
across various scenarios.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06520" title="Abstract">arXiv:2309.06520</a> [<a href="/pdf/2309.06520" title="Download PDF">pdf</a>, <a href="/format/2309.06520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Minimum Bayes&#x27; Risk Decoding for System Combination of Grammatical Error  Correction Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raina%2C+V">Vyas Raina</a>, 
<a href="/search/cs?searchtype=author&query=Gales%2C+M">Mark Gales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">For sequence-to-sequence tasks it is challenging to combine individual system
outputs. Further, there is also often a mismatch between the decoding criterion
and the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used
to combine system outputs in a manner that encourages better alignment with the
final assessment criterion. This paper examines MBR decoding for Grammatical
Error Correction (GEC) systems, where performance is usually evaluated in terms
of edits and an associated F-score. Hence, we propose a novel MBR loss function
directly linked to this form of criterion. Furthermore, an approach to expand
the possible set of candidate sentences is described. This builds on a current
max-voting combination scheme, as well as individual edit-level selection.
Experiments on three popular GEC datasets and with state-of-the-art GEC systems
demonstrate the efficacy of the proposed MBR approach. Additionally, the paper
highlights how varying reward metrics within the MBR decoding framework can
provide control over precision, recall, and the F-score in combined GEC
systems.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06521" title="Abstract">arXiv:2309.06521</a> [<a href="/pdf/2309.06521" title="Download PDF">pdf</a>, <a href="/format/2309.06521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethnicity and Biometric Uniqueness: Iris Pattern Individuality in a West  African Database
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daugman%2C+J">John Daugman</a>, 
<a href="/search/cs?searchtype=author&query=Downing%2C+C">Cathryn Downing</a>, 
<a href="/search/cs?searchtype=author&query=Akande%2C+O+N">Oluwatobi Noah Akande</a>, 
<a href="/search/cs?searchtype=author&query=Abikoye%2C+O+C">Oluwakemi Christiana Abikoye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 8 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We conducted more than 1.3 million comparisons of iris patterns encoded from
images collected at two Nigerian universities, which constitute the newly
available African Human Iris (AFHIRIS) database. The purpose was to discover
whether ethnic differences in iris structure and appearance such as the
textural feature size, as contrasted with an all-Chinese image database or an
American database in which only 1.53% were of African-American heritage, made a
material difference for iris discrimination. We measured a reduction in entropy
for the AFHIRIS database due to the coarser iris features created by the thick
anterior layer of melanocytes, and we found stochastic parameters that
accurately model the relevant empirical distributions. Quantile-Quantile
analysis revealed that a very small change in operational decision thresholds
for the African database would compensate for the reduced entropy and generate
the same performance in terms of resistance to False Matches. We conclude that
despite demographic difference, individuality can be robustly discerned by
comparison of iris patterns in this West African population.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06525" title="Abstract">arXiv:2309.06525</a> [<a href="/pdf/2309.06525" title="Download PDF">pdf</a>, <a href="/format/2309.06525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SocioHub: An Interactive Tool for Cross-Platform Social Media Data  Collection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nirmal%2C+A">Ayushi Nirmal</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bohan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Social media is inherently about connecting and interacting with others.
Different social media platforms have unique characteristics and user bases.
Moreover, people use different platforms for various social and entertainment
purposes. Analyzing cross-platform user behavior can provide insights into the
preferences and expectations of users on each platform. By understanding how
users behave and interact across platforms, we can build an understanding of
content consumption patterns, enhance communication and social interactions,
and tailor platform-specific strategies. We can further gather insights into
how users navigate and engage with their platforms on different devices. In
this work, we develop a tool SocioHub, which enables users to gather data on
multiple social media platforms in one place. This tool can help researchers
gain insights into different data attributes for users across social media
platforms such as Twitter, Instagram, and Mastodon. Keywords: Social Media
Platforms, Twitter, Instagram, Mastodon.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06526" title="Abstract">arXiv:2309.06526</a> [<a href="/pdf/2309.06526" title="Download PDF">pdf</a>, <a href="/format/2309.06526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Benefits of Differentially Private Pre-training and  Parameter-Efficient Fine-tuning for Table Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xilong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chia-Mu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Pin-Yu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">For machine learning with tabular data, Table Transformer (TabTransformer) is
a state-of-the-art neural network model, while Differential Privacy (DP) is an
essential component to ensure data privacy. In this paper, we explore the
benefits of combining these two aspects together in the scenario of transfer
learning -- differentially private pre-training and fine-tuning of
TabTransformers with a variety of parameter-efficient fine-tuning (PEFT)
methods, including Adapter, LoRA, and Prompt Tuning. Our extensive experiments
on the ACSIncome dataset show that these PEFT methods outperform traditional
approaches in terms of the accuracy of the downstream task and the number of
trainable parameters, thus achieving an improved trade-off among parameter
efficiency, privacy, and accuracy. Our code is available at
github.com/IBM/DP-TabTransformer.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06527" title="Abstract">arXiv:2309.06527</a> [<a href="/pdf/2309.06527" title="Download PDF">pdf</a>, <a href="/format/2309.06527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Translation Models Stand Strong in the Face of Adversarial  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burnyshev%2C+P">Pavel Burnyshev</a>, 
<a href="/search/cs?searchtype=author&query=Kostenok%2C+E">Elizaveta Kostenok</a>, 
<a href="/search/cs?searchtype=author&query=Zaytsev%2C+A">Alexey Zaytsev</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AIST-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Adversarial attacks expose vulnerabilities of deep learning models by
introducing minor perturbations to the input, which lead to substantial
alterations in the output. Our research focuses on the impact of such
adversarial attacks on sequence-to-sequence (seq2seq) models, specifically
machine translation models. We introduce algorithms that incorporate basic text
perturbation heuristics and more advanced strategies, such as the
gradient-based attack, which utilizes a differentiable approximation of the
inherently non-differentiable translation metric. Through our investigation, we
provide evidence that machine translation models display robustness displayed
robustness against best performed known adversarial attacks, as the degree of
perturbation in the output is directly proportional to the perturbation in the
input. However, among underdogs, our attacks outperform alternatives, providing
the best relative performance. Another strong candidate is an attack based on
mixing of individual characters.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06528" title="Abstract">arXiv:2309.06528</a> [<a href="/pdf/2309.06528" title="Download PDF">pdf</a>, <a href="/format/2309.06528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong-Weak Integrated Semi-supervision for Unsupervised Single and  Multi Target Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaohu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Radha%2C+H">Hayder Radha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised domain adaptation (UDA) focuses on transferring knowledge
learned in the labeled source domain to the unlabeled target domain. Despite
significant progress that has been achieved in single-target domain adaptation
for image classification in recent years, the extension from single-target to
multi-target domain adaptation is still a largely unexplored problem area. In
general, unsupervised domain adaptation faces a major challenge when attempting
to learn reliable information from a single unlabeled target domain. Increasing
the number of unlabeled target domains further exacerbate the problem rather
significantly. In this paper, we propose a novel strong-weak integrated
semi-supervision (SWISS) learning strategy for image classification using
unsupervised domain adaptation that works well for both single-target and
multi-target scenarios. Under the proposed SWISS-UDA framework, a strong
representative set with high confidence but low diversity target domain samples
and a weak representative set with low confidence but high diversity target
domain samples are updated constantly during the training process. Both sets
are fused to generate an augmented strong-weak training batch with
pseudo-labels to train the network during every iteration. The extension from
single-target to multi-target domain adaptation is accomplished by exploring
the class-wise distance relationship between domains and replacing the strong
representative set with much stronger samples from peer domains via peer
scaffolding. Moreover, a novel adversarial logit loss is proposed to reduce the
intra-class divergence between source and target domains, which is
back-propagated adversarially with a gradient reverse layer between the
classifier and the rest of the network. Experimental results based on three
benchmarks, Office-31, Office-Home, and DomainNet, show the effectiveness of
the proposed SWISS framework.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06530" title="Abstract">arXiv:2309.06530</a> [<a href="/pdf/2309.06530" title="Download PDF">pdf</a>, <a href="/format/2309.06530" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating HPX and Kokkos on RISC-V using an Astrophysics Application  Octo-Tiger
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diehl%2C+P">Parick Diehl</a>, 
<a href="/search/cs?searchtype=author&query=Daiss%2C+G">Gregor Daiss</a>, 
<a href="/search/cs?searchtype=author&query=Brandt%2C+S+R">Steven R. Brandt</a>, 
<a href="/search/cs?searchtype=author&query=Kheirkhahan%2C+A">Alireza Kheirkhahan</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+H">Hartmut Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Taylor%2C+C">Christopher Taylor</a>, 
<a href="/search/cs?searchtype=author&query=Leidel%2C+J">John Leidel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In recent years, computers based on the RISC-V architecture have raised broad
interest in the high-performance computing (HPC) community. As the RISC-V
community develops the core instruction set architecture (ISA) along with ISA
extensions, the HPC community has been actively ensuring HPC applications and
environments are supported. In this context, assessing the performance of
asynchronous many-task runtime systems (AMT) is essential. In this paper, we
describe our experience with porting of a full 3D adaptive mesh-refinement,
multi-scale, multi-model, and multi-physics application, Octo-Tiger, that is
based on the HPX AMT, and we explore its performance characteristics on
different RISC-V systems. Considering the (limited) capabilities of the RISC-V
test systems we used, Octo-Tiger already shows promising results and good
scaling. We, however, expect that exceptional hardware support based on
dedicated ISA extensions (such as single-cycle context switches, extended
atomic operations, and direct support for HPX's global address space) would
allow for even better performance results.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06533" title="Abstract">arXiv:2309.06533</a> [<a href="/pdf/2309.06533" title="Download PDF">pdf</a>, <a href="/format/2309.06533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Multi-Task Learning Framework for Session-based  Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Oh%2C+S">Sejoon Oh</a>, 
<a href="/search/cs?searchtype=author&query=Shalaby%2C+W">Walid Shalaby</a>, 
<a href="/search/cs?searchtype=author&query=Afsharinejad%2C+A">Amir Afsharinejad</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+X">Xiquan Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 6th Workshop on Online Recommender Systems and User Modeling @ ACM RecSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">While session-based recommender systems (SBRSs) have shown superior
recommendation performance, multi-task learning (MTL) has been adopted by SBRSs
to enhance their prediction accuracy and generalizability further. Hierarchical
MTL (H-MTL) sets a hierarchical structure between prediction tasks and feeds
outputs from auxiliary tasks to main tasks. This hierarchy leads to richer
input features for main tasks and higher interpretability of predictions,
compared to existing MTL frameworks. However, the H-MTL framework has not been
investigated in SBRSs yet. In this paper, we propose HierSRec which
incorporates the H-MTL architecture into SBRSs. HierSRec encodes a given
session with a metadata-aware Transformer and performs next-category prediction
(i.e., auxiliary task) with the session encoding. Next, HierSRec conducts
next-item prediction (i.e., main task) with the category prediction result and
session encoding. For scalable inference, HierSRec creates a compact set of
candidate items (e.g., 4% of total items) per test example using the category
prediction. Experiments show that HierSRec outperforms existing SBRSs as per
next-item prediction accuracy on two session-based recommendation datasets. The
accuracy of HierSRec measured with the carefully-curated candidate items aligns
with the accuracy of HierSRec calculated with all items, which validates the
usefulness of our candidate generation scheme via H-MTL.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06534" title="Abstract">arXiv:2309.06534</a> [<a href="/pdf/2309.06534" title="Download PDF">pdf</a>, <a href="/format/2309.06534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributionally Robust Transfer Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xin Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zijian Guo</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Tianxi Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Many existing transfer learning methods rely on leveraging information from
source data that closely resembles the target data. However, this approach
often overlooks valuable knowledge that may be present in different yet
potentially related auxiliary samples. When dealing with a limited amount of
target data and a diverse range of source models, our paper introduces a novel
approach, Distributionally Robust Optimization for Transfer Learning
(TransDRO), that breaks free from strict similarity constraints. TransDRO is
designed to optimize the most adversarial loss within an uncertainty set,
defined as a collection of target populations generated as a convex combination
of source distributions that guarantee excellent prediction performances for
the target data. TransDRO effectively bridges the realms of transfer learning
and distributional robustness prediction models. We establish the
identifiability of TransDRO and its interpretation as a weighted average of
source models closest to the baseline model. We also show that TransDRO
achieves a faster convergence rate than the model fitted with the target data.
Our comprehensive numerical studies and analysis of multi-institutional
electronic health records data using TransDRO further substantiate the
robustness and accuracy of TransDRO, highlighting its potential as a powerful
tool in transfer learning applications.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06541" title="Abstract">arXiv:2309.06541</a> [<a href="/pdf/2309.06541" title="Download PDF">pdf</a>, <a href="/format/2309.06541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Encoders Lack Knowledge: Leveraging Generative LLMs for  Domain-Specific Semantic Textual Similarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gatto%2C+J">Joseph Gatto</a>, 
<a href="/search/cs?searchtype=author&query=Sharif%2C+O">Omar Sharif</a>, 
<a href="/search/cs?searchtype=author&query=Seegmiller%2C+P">Parker Seegmiller</a>, 
<a href="/search/cs?searchtype=author&query=Bohlman%2C+P">Philip Bohlman</a>, 
<a href="/search/cs?searchtype=author&query=Preum%2C+S+M">Sarah Masud Preum</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review GEM@EMNLP-2023, 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Amidst the sharp rise in the evaluation of large language models (LLMs) on
various tasks, we find that semantic textual similarity (STS) has been
under-explored. In this study, we show that STS can be cast as a text
generation problem while maintaining strong performance on multiple STS
benchmarks. Additionally, we show generative LLMs significantly outperform
existing encoder-based STS models when characterizing the semantic similarity
between two texts with complex semantic relationships dependent on world
knowledge. We validate this claim by evaluating both generative LLMs and
existing encoder-based STS models on three newly collected STS challenge sets
which require world knowledge in the domains of Health, Politics, and Sports.
All newly collected data is sourced from social media content posted after May
2023 to ensure the performance of closed-source models like ChatGPT cannot be
credited to memorization. Our results show that, on average, generative LLMs
outperform the best encoder-only baselines by an average of 22.3% on STS tasks
requiring world knowledge. Our results suggest generative language models with
STS-specific prompting strategies achieve state-of-the-art performance in
complex, domain-specific STS tasks.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06545" title="Abstract">arXiv:2309.06545</a> [<a href="/pdf/2309.06545" title="Download PDF">pdf</a>, <a href="/format/2309.06545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Homomorphic Operations on a Real-World Processing-In-Memory  System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+H">Harshita Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Kabra%2C+M">Mayank Kabra</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Luna%2C+J">Juan G&#xf3;mez-Luna</a>, 
<a href="/search/cs?searchtype=author&query=Kanellopoulos%2C+K">Konstantinos Kanellopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Mutlu%2C+O">Onur Mutlu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work will be presented at IISWC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Computing on encrypted data is a promising approach to reduce data security
and privacy risks, with homomorphic encryption serving as a facilitator in
achieving this goal. In this work, we accelerate homomorphic operations using
the Processing-in- Memory (PIM) paradigm to mitigate the large memory capacity
and frequent data movement requirements. Using a real-world PIM system, we
accelerate the Brakerski-Fan-Vercauteren (BFV) scheme for homomorphic addition
and multiplication. We evaluate the PIM implementations of these homomorphic
operations with statistical workloads (arithmetic mean, variance, linear
regression) and compare to CPU and GPU implementations. Our results demonstrate
50-100x speedup with a real PIM system (UPMEM) over the CPU and 2-15x over the
GPU in vector addition. For vector multiplication, the real PIM system
outperforms the CPU by 40-50x. However, it lags 10-15x behind the GPU due to
the lack of native sufficiently wide multiplication support in the evaluated
first-generation real PIM system. For mean, variance, and linear regression,
the real PIM system performance improvements vary between 30x and 300x over the
CPU and between 10x and 30x over the GPU, uncovering real PIM system trade-offs
in terms of scalability of homomorphic operations for varying amounts of data.
We plan to make our implementation open-source in the future.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06547" title="Abstract">arXiv:2309.06547</a> [<a href="/pdf/2309.06547" title="Download PDF">pdf</a>, <a href="/format/2309.06547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmodalSynthDrive: A Synthetic Amodal Perception Dataset for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sekkat%2C+A+R">Ahmed Rida Sekkat</a>, 
<a href="/search/cs?searchtype=author&query=Mohan%2C+R">Rohit Mohan</a>, 
<a href="/search/cs?searchtype=author&query=Sawade%2C+O">Oliver Sawade</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+E">Elmar Matthes</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unlike humans, who can effortlessly estimate the entirety of objects even
when partially occluded, modern computer vision algorithms still find this
aspect extremely challenging. Leveraging this amodal perception for autonomous
driving remains largely untapped due to the lack of suitable datasets. The
curation of these datasets is primarily hindered by significant annotation
costs and mitigating annotator subjectivity in accurately labeling occluded
regions. To address these limitations, we introduce AmodalSynthDrive, a
synthetic multi-task multi-modal amodal perception dataset. The dataset
provides multi-view camera images, 3D bounding boxes, LiDAR data, and odometry
for 150 driving sequences with over 1M object annotations in diverse traffic,
weather, and lighting conditions. AmodalSynthDrive supports multiple amodal
scene understanding tasks including the introduced amodal depth estimation for
enhanced spatial understanding. We evaluate several baselines for each of these
tasks to illustrate the challenges and set up public benchmarking servers. The
dataset is available at <a href="http://amodalsynthdrive.cs.uni-freiburg.de.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06550" title="Abstract">arXiv:2309.06550</a> [<a href="/pdf/2309.06550" title="Download PDF">pdf</a>, <a href="/format/2309.06550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synthetic Text Generation using Hypergraph Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raman%2C+N">Natraj Raman</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S">Sameena Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Generating synthetic variants of a document is often posed as text-to-text
transformation. We propose an alternate LLM based method that first decomposes
a document into semantic frames and then generates text using this interim
sparse format. The frames are modeled using a hypergraph, which allows
perturbing the frame contents in a principled manner. Specifically, new
hyperedges are mined through topological analysis and complex polyadic
relationships including hierarchy and temporal dynamics are accommodated. We
show that our solution generates documents that are diverse, coherent and vary
in style, sentiment, format, composition and facts.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06551" title="Abstract">arXiv:2309.06551</a> [<a href="/pdf/2309.06551" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Commands as AI Conversations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Spinellis%2C+D">Diomidis Spinellis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Developers and data scientists often struggle to write command-line inputs,
even though graphical interfaces or tools like ChatGPT can assist. The
solution? "ai-cli," an open-source system inspired by GitHub Copilot that
converts natural language prompts into executable commands for various Linux
command-line tools. By tapping into OpenAI's API, which allows interaction
through JSON HTTP requests, "ai-cli" transforms user queries into actionable
command-line instructions. However, integrating AI assistance across multiple
command-line tools, especially in open source settings, can be complex.
Historically, operating systems could mediate, but individual tool
functionality and the lack of a unified approach have made centralized
integration challenging. The "ai-cli" tool, by bridging this gap through
dynamic loading and linking with each program's Readline library API, makes
command-line interfaces smarter and more user-friendly, opening avenues for
further enhancement and cross-platform applicability.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06553" title="Abstract">arXiv:2309.06553</a> [<a href="/pdf/2309.06553" title="Download PDF">pdf</a>, <a href="/format/2309.06553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Offline Prompt Evaluation and Optimization with Inverse Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">The recent advances in the development of Large Language Models (LLMs) like
ChatGPT have achieved remarkable performance by leveraging human expertise.
Yet, fully eliciting LLMs' potential for complex tasks requires navigating the
vast search space of natural language prompts. While prompt engineering has
shown promise, the requisite human-crafted prompts in trial-and-error attempts
and the associated costs pose significant challenges. Crucially, the efficiency
of prompt optimization hinges on the costly procedure of prompt evaluation.
This work introduces Prompt-OIRL, an approach rooted in offline inverse
reinforcement learning that seeks to bridge the gap between effective prompt
evaluation and affordability. Our method draws on offline datasets from expert
evaluations, employing Inverse-RL to derive a reward model for offline,
query-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold:
it predicts prompt performance, is cost-efficient, produces human-readable
results, and efficiently navigates the prompt space. We validate our method
across four LLMs and three arithmetic datasets, highlighting its potential as a
robust and effective tool for offline prompt evaluation and optimization. Our
code as well as the offline datasets are released, and we highlight the
Prompt-OIRL can be reproduced within a few hours using a single laptop using
CPU
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06554" title="Abstract">arXiv:2309.06554</a> [<a href="/pdf/2309.06554" title="Download PDF">pdf</a>, <a href="/ps/2309.06554" title="Download PostScript">ps</a>, <a href="/format/2309.06554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An improved protocol for ExactlyN with more than 3 players
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hambardzumyan%2C+L">Lianna Hambardzumyan</a>, 
<a href="/search/cs?searchtype=author&query=Pitassi%2C+T">Toniann Pitassi</a>, 
<a href="/search/cs?searchtype=author&query=Sherif%2C+S">Suhail Sherif</a>, 
<a href="/search/cs?searchtype=author&query=Shirley%2C+M">Morgan Shirley</a>, 
<a href="/search/cs?searchtype=author&query=Shraibman%2C+A">Adi Shraibman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The ExactlyN problem in the number-on-forehead (NOF) communication setting
asks $k$ players, each of whom can see every input but their own, if the $k$
input numbers add up to $N$. Introduced by Chandra, Furst and Lipton in 1983,
ExactlyN is important for its role in understanding the strength of randomness
in communication complexity with many players. It is also tightly connected to
the field of combinatorics: its $k$-party NOF communication complexity is
related to the size of the largest corner-free subset in $[N]^{k-1}$.
<br />In 2021, Linial and Shraibman gave more efficient protocols for ExactlyN for
3 players. As an immediate consequence, this also gave a new construction of
larger corner-free subsets in $[N]^2$. Later that year Green gave a further
refinement to their argument. These results represent the first improvements to
the highest-order term for $k=3$ since the famous work of Behrend in 1946. In
this paper we give a corresponding improvement to the highest-order term for
all $k&gt;3$, the first since Rankin in 1961. That is, we give a more efficient
protocol for ExactlyN as well as larger corner-free sets in higher dimensions.
<br />Nearly all previous results in this line of research approached the problem
from the combinatorics perspective, implicitly resulting in non-constructive
protocols for ExactlyN. Approaching the problem from the communication
complexity point of view and constructing explicit protocols for ExactlyN was
key to the improvements in the $k=3$ setting. As a further contribution we
provide explicit protocols for ExactlyN for any number of players which serves
as a base for our improvement.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06555" title="Abstract">arXiv:2309.06555</a> [<a href="/pdf/2309.06555" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An overview of VANET vehicular networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hozouri%2C+A">Ali Hozouri</a>, 
<a href="/search/cs?searchtype=author&query=Mirzaei%2C+A">Abbas Mirzaei</a>, 
<a href="/search/cs?searchtype=author&query=RazaghZadeh%2C+S">Shiva RazaghZadeh</a>, 
<a href="/search/cs?searchtype=author&query=Yousefi%2C+D">Davoud Yousefi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Today, with the development of intercity and metropolitan roadways and with
various cars moving in various directions, there is a greater need than ever
for a network to coordinate commutes. Nowadays, people spend a lot of time in
their vehicles. Smart automobiles have developed to make that time safer, more
effective, more fun, pollution-free, and affordable. However, maintaining the
optimum use of resources and addressing rising needs continues to be a
challenge given the popularity of vehicle users and the growing diversity of
requests for various services. As a result, VANET will require modernized
working practices in the future. Modern intelligent transportation management
and driver assistance systems are created using cutting-edge communication
technology. Vehicular Ad-hoc networks promise to increase transportation
effectiveness, accident prevention, and pedestrian comfort by allowing
automobiles and road infrastructure to communicate entertainment and traffic
information. By constructing thorough frameworks, workflow patterns, and update
procedures, including block-chain, artificial intelligence, and SDN (Software
Defined Networking), this paper addresses VANET-related technologies, future
advances, and related challenges. An overview of the VANET upgrade solution is
given in this document in order to handle potential future problems.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06557" title="Abstract">arXiv:2309.06557</a> [<a href="/pdf/2309.06557" title="Download PDF">pdf</a>, <a href="/format/2309.06557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Bias Detection in College Student Newspapers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lehavi%2C+A+M">Adam M. Lehavi</a>, 
<a href="/search/cs?searchtype=author&query=McCormack%2C+W">William McCormack</a>, 
<a href="/search/cs?searchtype=author&query=Kornfeld%2C+N">Noah Kornfeld</a>, 
<a href="/search/cs?searchtype=author&query=Glazer%2C+S">Solomon Glazer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 3 tables, submitted to AAAI2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper presents a pipeline with minimal human influence for scraping and
detecting bias on college newspaper archives. This paper introduces a framework
for scraping complex archive sites that automated tools fail to grab data from,
and subsequently generates a dataset of 14 student papers with 23,154 entries.
This data can also then be queried by keyword to calculate bias by comparing
the sentiment of a large language model summary to the original article. The
advantages of this approach are that it is less comparative than reconstruction
bias and requires less labelled data than generating keyword sentiment. Results
are calculated on politically charged words as well as control words to show
how conclusions can be drawn. The complete method facilitates the extraction of
nuanced insights with minimal assumptions and categorizations, paving the way
for a more objective understanding of bias within student newspaper sources.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06558" title="Abstract">arXiv:2309.06558</a> [<a href="/pdf/2309.06558" title="Download PDF">pdf</a>, <a href="/format/2309.06558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High Fidelity Fast Simulation of Human in the Loop Human in the Plant  (HIL-HIP) Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Banerjee%2C+A">Ayan Banerjee</a>, 
<a href="/search/eess?searchtype=author&query=Kamboj%2C+P">Payal Kamboj</a>, 
<a href="/search/eess?searchtype=author&query=Maity%2C+A">Aranyak Maity</a>, 
<a href="/search/eess?searchtype=author&query=Salian%2C+R+S">Riya Sudhakar Salian</a>, 
<a href="/search/eess?searchtype=author&query=Gupta%2C+S+K+S">Sandeep K.S. Gupta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ACM MSWIM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">Non-linearities in simulation arise from the time variance in wireless mobile
networks when integrated with human in the loop, human in the plant (HIL-HIP)
physical systems under dynamic contexts, leading to simulation slowdown. Time
variance is handled by deriving a series of piece wise linear time invariant
simulations (PLIS) in intervals, which are then concatenated in time domain. In
this paper, we conduct a formal analysis of the impact of discretizing
time-varying components in wireless network-controlled HIL-HIP systems on
simulation accuracy and speedup, and evaluate trade-offs with reliable
guarantees. We develop an accurate simulation framework for an artificial
pancreas wireless network system that controls blood glucose in Type 1 Diabetes
patients with time varying properties such as physiological changes associated
with psychological stress and meal patterns. PLIS approach achieves accurate
simulation with greater than 2.1 times speedup than a non-linear system
simulation for the given dataset.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06565" title="Abstract">arXiv:2309.06565</a> [<a href="/pdf/2309.06565" title="Download PDF">pdf</a>, <a href="/format/2309.06565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> METICULOUS: An FPGA-based Main Memory Emulator for System Software  Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hirofuchi%2C+T">Takahiro Hirofuchi</a>, 
<a href="/search/cs?searchtype=author&query=Fukai%2C+T">Takaaki Fukai</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A+B">Akram Ben Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Takano%2C+R">Ryousei Takano</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+K">Kento Sato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Performance (cs.PF)

</div>
<p class="mathjax">Due to the scaling problem of the DRAM technology, non-volatile memory
devices, which are based on different principle of operation than DRAM, are now
being intensively developed to expand the main memory of computers.
Disaggregated memory is also drawing attention as an emerging technology to
scale up the main memory. Although system software studies need to discuss
management mechanisms for the new main memory designs incorporating such
emerging memory systems, there are no feasible memory emulation mechanisms that
efficiently work for large-scale, privileged programs such as operating systems
and hypervisors. In this paper, we propose an FPGA-based main memory emulator
for system software studies on new main memory systems. It can emulate the main
memory incorporating multiple memory regions with different performance
characteristics. For the address region of each memory device, it emulates the
latencies, bandwidths and bit-flip error rates of read/write operations,
respectively. The emulator is implemented at the hardware module of an
off-the-self FPGA System-on-Chip board. Any privileged/unprivileged software
programs running on its powerful 64-bit CPU cores can access emulated main
memory devices at a practical speed through the exactly same interface as
normal DRAM main memory. We confirmed that the emulator transparently worked
for CPU cores and successfully changed the performance of a memory region
according to given emulation parameters; for example, the latencies measured by
CPU cores were exactly proportional to the latencies inserted by the emulator,
involving the minimum overhead of approximately 240 ns. As a preliminary use
case, we confirmed that the emulator allows us to change the bandwidth limit
and the inserted latency individually for unmodified software programs, making
discussions on latency sensitivity much easier.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06569" title="Abstract">arXiv:2309.06569</a> [<a href="/pdf/2309.06569" title="Download PDF">pdf</a>, <a href="/format/2309.06569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Promises of Deep Kernel Learning for Control Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Reed%2C+R">Robert Reed</a>, 
<a href="/search/eess?searchtype=author&query=Laurenti%2C+L">Luca Laurenti</a>, 
<a href="/search/eess?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep Kernel Learning (DKL) combines the representational power of neural
networks with the uncertainty quantification of Gaussian Processes. Hence, it
is potentially a promising tool to learn and control complex dynamical systems.
In this work, we develop a scalable abstraction-based framework that enables
the use of DKL for control synthesis of stochastic dynamical systems against
complex specifications. Specifically, we consider temporal logic specifications
and create an end-to-end framework that uses DKL to learn an unknown system
from data and formally abstracts the DKL model into an Interval Markov Decision
Process (IMDP) to perform control synthesis with correctness guarantees.
Furthermore, we identify a deep architecture that enables accurate learning and
efficient abstraction computation. The effectiveness of our approach is
illustrated on various benchmarks, including a 5-D nonlinear stochastic system,
showing how control synthesis with DKL can substantially outperform
state-of-the-art competitive methods.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06573" title="Abstract">arXiv:2309.06573</a> [<a href="/pdf/2309.06573" title="Download PDF">pdf</a>, <a href="/format/2309.06573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-proximal null-space networks for inverse problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%B6ppel%2C+S">Simon G&#xf6;ppel</a>, 
<a href="/search/math?searchtype=author&query=Frikel%2C+J">J&#xfc;rgen Frikel</a>, 
<a href="/search/math?searchtype=author&query=Haltmeier%2C+M">Markus Haltmeier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Inverse problems are inherently ill-posed and therefore require
regularization techniques to achieve a stable solution. While traditional
variational methods have well-established theoretical foundations, recent
advances in machine learning based approaches have shown remarkable practical
performance. However, the theoretical foundations of learning-based methods in
the context of regularization are still underexplored. In this paper, we
propose a general framework that addresses the current gap between
learning-based methods and regularization strategies. In particular, our
approach emphasizes the crucial role of data consistency in the solution of
inverse problems and introduces the concept of data-proximal null-space
networks as a key component for their solution. We provide a complete
convergence analysis by extending the concept of regularizing null-space
networks with data proximity in the visual part. We present numerical results
for limited-view computed tomography to illustrate the validity of our
framework.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06574" title="Abstract">arXiv:2309.06574</a> [<a href="/pdf/2309.06574" title="Download PDF">pdf</a>, <a href="/format/2309.06574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Circle Feature Graphormer: Can Circle Features Stimulate Graph  Transformer?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lv%2C+J">Jingsong Lv</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yao Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lei Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 pages, 2 figures, 1 table, 31 references, manuscript in preparation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we introduce two local graph features for missing link
prediction tasks on ogbl-citation2. We define the features as Circle Features,
which are borrowed from the concept of circle of friends. We propose the
detailed computing formulas for the above features. Firstly, we define the
first circle feature as modified swing for common graph, which comes from
bipartite graph. Secondly, we define the second circle feature as bridge, which
indicates the importance of two nodes for different circle of friends. In
addition, we firstly propose the above features as bias to enhance graph
transformer neural network, such that graph self-attention mechanism can be
improved. We implement a Circled Feature aware Graph transformer (CFG) model
based on SIEG network, which utilizes a double tower structure to capture both
global and local structure features. Experimental results show that CFG
achieves the state-of-the-art performance on dataset ogbl-citation2.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06577" title="Abstract">arXiv:2309.06577</a> [<a href="/pdf/2309.06577" title="Download PDF">pdf</a>, <a href="/format/2309.06577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Finite Initialization for Tensorized Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+M">Alejandro Mata Ali</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+I+P">I&#xf1;igo Perez Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Roura%2C+M+R">Marina Ristol Roura</a>, 
<a href="/search/cs?searchtype=author&query=de+Leceta%2C+A+M+F">Aitor Moreno Fdez. de Leceta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantum Physics (quant-ph)

</div>
<p class="mathjax">We present a novel method for initializing layers of tensorized neural
networks in a way that avoids the explosion of the parameters of the matrix it
emulates. The method is intended for layers with a high number of nodes in
which there is a connection to the input or output of all or most of the nodes.
The core of this method is the use of the Frobenius norm of this layer in an
iterative partial form, so that it has to be finite and within a certain range.
This norm is efficient to compute, fully or partially for most cases of
interest. We apply the method to different layers and check its performance. We
create a Python function to run it on an arbitrary layer, available in a
Jupyter Notebook in the i3BQuantum repository:
https://github.com/i3BQuantumTeam/Q4Real/blob/e07c827651ef16bcf74590ab965ea3985143f891/Quantum-Inspired%20Variational%20Methods/Normalization_process.ipynb
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06578" title="Abstract">arXiv:2309.06578</a> [<a href="/pdf/2309.06578" title="Download PDF">pdf</a>, <a href="/format/2309.06578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Large Language Models Discern Evidence for Scientific Hypotheses?  Case Studies in the Social Sciences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Koneru%2C+S">Sai Koneru</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Rajtmajer%2C+S">Sarah Rajtmajer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Hypothesis formulation and testing are central to empirical research. A
strong hypothesis is a best guess based on existing evidence and informed by a
comprehensive view of relevant literature. However, with exponential increase
in the number of scientific articles published annually, manual aggregation and
synthesis of evidence related to a given hypothesis is a challenge. Our work
explores the ability of current large language models (LLMs) to discern
evidence in support or refute of specific hypotheses based on the text of
scientific abstracts. We share a novel dataset for the task of scientific
hypothesis evidencing using community-driven annotations of studies in the
social sciences. We compare the performance of LLMs to several state-of-the-art
benchmarks and highlight opportunities for future research in this area. The
dataset is available at
https://github.com/Sai90000/ScientificHypothesisEvidencing.git
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06579" title="Abstract">arXiv:2309.06579</a> [<a href="/pdf/2309.06579" title="Download PDF">pdf</a>, <a href="/format/2309.06579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compact and Low-Loss PCM-based Silicon Photonic MZIs for Photonic Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+A">Amin Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Sanmitra Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Charbonnier%2C+B">Benoit Charbonnier</a>, 
<a href="/search/cs?searchtype=author&query=Pasricha%2C+S">Sudeep Pasricha</a>, 
<a href="/search/cs?searchtype=author&query=Nikdast%2C+M">Mahdi Nikdast</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted at IEEE Photonics Conference (IPC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Applied Physics (physics.app-ph)

</div>
<p class="mathjax">We present an optimized Mach-Zehnder Interferometer (MZI) with phase change
materials for photonic neural networks (PNNs). With 0.2 dB loss, -38 dB
crosstalk, and length of 52 micrometer, the designed MZI significantly improves
the scalability and accuracy of PNNs under loss and crosstalk.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06580" title="Abstract">arXiv:2309.06580</a> [<a href="/pdf/2309.06580" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can humans help BERT gain &quot;confidence&quot;?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Piyush Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Masters thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advancements in artificial intelligence over the last decade have opened
a multitude of avenues for interdisciplinary research. Since the idea of
artificial intelligence was inspired by the working of neurons in the brain, it
seems pretty practical to combine the two fields and take the help of cognitive
data to train AI models. Not only it will help to get a deeper understanding of
the technology, but of the brain as well. In this thesis, I conduct novel
experiments to integrate cognitive features from the Zurich Cognitive Corpus
(ZuCo) (Hollenstein et al., 2018) with a transformer-based encoder model called
BERT. I show how EEG and eye-tracking features from ZuCo can help to increase
the performance of the NLP model. I confirm the performance increase with the
help of a robustness-checking pipeline and derive a word-EEG lexicon to use in
benchmarking on an external dataset that does not have any cognitive features
associated with it. Further, I analyze the internal working mechanism of BERT
and explore a potential method for model explainability by correlating it with
a popular model-agnostic explainability framework called LIME (Ribeiro et al.,
2016). Finally, I discuss the possible directions to take this research
forward.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06581" title="Abstract">arXiv:2309.06581</a> [<a href="/pdf/2309.06581" title="Download PDF">pdf</a>, <a href="/format/2309.06581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Visual Classification with Guided Cropping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saranrittichai%2C+P">Piyapat Saranrittichai</a>, 
<a href="/search/cs?searchtype=author&query=Munoz%2C+M">Mauricio Munoz</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+V">Volker Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Mummadi%2C+C+K">Chaithanya Kumar Mummadi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Pretrained vision-language models, such as CLIP, show promising zero-shot
performance across a wide variety of datasets. For closed-set classification
tasks, however, there is an inherent limitation: CLIP image encoders are
typically designed to extract generic image-level features that summarize
superfluous or confounding information for the target tasks. This results in
degradation of classification performance, especially when objects of interest
cover small areas of input images. In this work, we propose CLIP with Guided
Cropping (GC-CLIP), where we use an off-the-shelf zero-shot object detection
model in a preprocessing step to increase focus of zero-shot classifier to the
object of interest and minimize influence of extraneous image regions. We
empirically show that our approach improves zero-shot classification results
across architectures and datasets, favorably for small objects.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06584" title="Abstract">arXiv:2309.06584</a> [<a href="/pdf/2309.06584" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Graph Neural Network for Alzheimer&#x27;s Disease And Related  Dementias Risk Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinyue Hu</a> (1), 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zenan Sun</a> (1), 
<a href="/search/cs?searchtype=author&query=Nian%2C+Y">Yi Nian</a> (1), 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yifang Dang</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fang Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jingna Feng</a> (1), 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">Evan Yu</a> (1), 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Cui Tao</a> (1) ((1) McWilliams School of Biomedical Informatics, The University of Texas Health Science Center at Houston, Houston, TX, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Alzheimer's disease and related dementias (ADRD) ranks as the sixth leading
cause of death in the US, underlining the importance of accurate ADRD risk
prediction. While recent advancement in ADRD risk prediction have primarily
relied on imaging analysis, yet not all patients undergo medical imaging before
an ADRD diagnosis. Merging machine learning with claims data can reveal
additional risk factors and uncover interconnections among diverse medical
codes. Our goal is to utilize Graph Neural Networks (GNNs) with claims data for
ADRD risk prediction. Addressing the lack of human-interpretable reasons behind
these predictions, we introduce an innovative method to evaluate relationship
importance and its influence on ADRD risk prediction, ensuring comprehensive
interpretation.
<br />We employed Variationally Regularized Encoder-decoder Graph Neural Network
(VGNN) for estimating ADRD likelihood. We created three scenarios to assess the
model's efficiency, using Random Forest and Light Gradient Boost Machine as
baselines. We further used our relation importance method to clarify the key
relationships for ADRD risk prediction. VGNN surpassed other baseline models by
10% in the area under the receiver operating characteristic. The integration of
the GNN model and relation importance interpretation could potentially play an
essential role in providing valuable insight into factors that may contribute
to or delay ADRD progression.
<br />Employing a GNN approach with claims data enhances ADRD risk prediction and
provides insights into the impact of interconnected medical code relationships.
This methodology not only enables ADRD risk modeling but also shows potential
for other image analysis predictions using claims data.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06588" title="Abstract">arXiv:2309.06588</a> [<a href="/pdf/2309.06588" title="Download PDF">pdf</a>, <a href="/format/2309.06588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Gradient-based MAML in LQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Musavi%2C+N">Negin Musavi</a>, 
<a href="/search/eess?searchtype=author&query=Dullerud%2C+G+E">Geir E. Dullerud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The main objective of this research paper is to investigate the local
convergence characteristics of Model-agnostic Meta-learning (MAML) when applied
to linear system quadratic optimal control (LQR). MAML and its variations have
become popular techniques for quickly adapting to new tasks by leveraging
previous learning knowledge in areas like regression, classification, and
reinforcement learning. However, its theoretical guarantees remain unknown due
to non-convexity and its structure, making it even more challenging to ensure
stability in the dynamic system setting. This study focuses on exploring MAML
in the LQR setting, providing its local convergence guarantees while
maintaining the stability of the dynamical system. The paper also presents
simple numerical results to demonstrate the convergence properties of MAML in
LQR tasks.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06589" title="Abstract">arXiv:2309.06589</a> [<a href="/pdf/2309.06589" title="Download PDF">pdf</a>, <a href="/ps/2309.06589" title="Download PostScript">ps</a>, <a href="/format/2309.06589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Generative Large Language Models need billions of parameters?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gholami%2C+S">Sia Gholami</a>, 
<a href="/search/cs?searchtype=author&query=Omar%2C+M">Marwan Omar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents novel systems and methodologies for the development of
efficient large language models (LLMs). It explores the trade-offs between
model size, performance, and computational resources, with the aim of
maximizing the efficiency of these AI systems. The research explores novel
methods that allow different parts of the model to share parameters, reducing
the total number of unique parameters required. This approach ensures that the
model remains compact without sacrificing its ability to learn and represent
complex language structures. This study provides valuable insights and tools
for creating more efficient and effective LLMs, contributing to a more
sustainable and accessible future for AI language modeling.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06597" title="Abstract">arXiv:2309.06597</a> [<a href="/pdf/2309.06597" title="Download PDF">pdf</a>, <a href="/format/2309.06597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rank2Tell: A Multimodal Driving Dataset for Joint Importance Ranking and  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+E">Enna Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Nakul Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Chundi%2C+S">Suhas Chundi</a>, 
<a href="/search/cs?searchtype=author&query=Roelofs%2C+S">Sean Roelofs</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Dariush%2C+B">Behzad Dariush</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+C">Chiho Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M">Mykel Kochenderfer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">The widespread adoption of commercial autonomous vehicles (AVs) and advanced
driver assistance systems (ADAS) may largely depend on their acceptance by
society, for which their perceived trustworthiness and interpretability to
riders are crucial. In general, this task is challenging because modern
autonomous systems software relies heavily on black-box artificial intelligence
models. Towards this goal, this paper introduces a novel dataset, Rank2Tell, a
multi-modal ego-centric dataset for Ranking the importance level and Telling
the reason for the importance. Using various close and open-ended visual
question answering, the dataset provides dense annotations of various semantic,
spatial, temporal, and relational attributes of various important objects in
complex traffic scenarios. The dense annotations and unique attributes of the
dataset make it a valuable resource for researchers working on visual scene
understanding and related fields. Further, we introduce a joint model for joint
importance level ranking and natural language captions generation to benchmark
our dataset and demonstrate performance with quantitative evaluations.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06599" title="Abstract">arXiv:2309.06599</a> [<a href="/pdf/2309.06599" title="Download PDF">pdf</a>, <a href="/format/2309.06599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reasoning with Latent Diffusion in Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venkatraman%2C+S">Siddarth Venkatraman</a>, 
<a href="/search/cs?searchtype=author&query=Khaitan%2C+S">Shivesh Khaitan</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+R+T">Ravi Tej Akella</a>, 
<a href="/search/cs?searchtype=author&query=Dolan%2C+J">John Dolan</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jeff Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Berseth%2C+G">Glen Berseth</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Offline reinforcement learning (RL) holds promise as a means to learn
high-reward policies from a static dataset, without the need for further
environment interactions. However, a key challenge in offline RL lies in
effectively stitching portions of suboptimal trajectories from the static
dataset while avoiding extrapolation errors arising due to a lack of support in
the dataset. Existing approaches use conservative methods that are tricky to
tune and struggle with multi-modal data (as we show) or rely on noisy Monte
Carlo return-to-go samples for reward conditioning. In this work, we propose a
novel approach that leverages the expressiveness of latent diffusion to model
in-support trajectory sequences as compressed latent skills. This facilitates
learning a Q-function while avoiding extrapolation error via
batch-constraining. The latent space is also expressive and gracefully copes
with multi-modal data. We show that the learned temporally-abstract latent
space encodes richer task-specific information for offline RL tasks as compared
to raw state-actions. This improves credit assignment and facilitates faster
reward propagation during Q-learning. Our method demonstrates state-of-the-art
performance on the D4RL benchmarks, particularly excelling in long-horizon,
sparse-reward tasks.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06600" title="Abstract">arXiv:2309.06600</a> [<a href="/pdf/2309.06600" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narrative as a Dynamical System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doxas%2C+I">Isidoros Doxas</a> (1 and 2), 
<a href="/search/cs?searchtype=author&query=Meiss%2C+J">James Meiss</a> (3), 
<a href="/search/cs?searchtype=author&query=Bottone%2C+S">Steven Bottone</a> (1), 
<a href="/search/cs?searchtype=author&query=Strelich%2C+T">Tom Strelich</a> (4 and 5), 
<a href="/search/cs?searchtype=author&query=Plummer%2C+A">Andrew Plummer</a> (5 and 6), 
<a href="/search/cs?searchtype=author&query=Breland%2C+A">Adrienne Breland</a> (5 and 7), 
<a href="/search/cs?searchtype=author&query=Dennis%2C+S">Simon Dennis</a> (8 and 9), 
<a href="/search/cs?searchtype=author&query=Garvin-Doxas%2C+K">Kathy Garvin-Doxas</a> (9 and 10), 
<a href="/search/cs?searchtype=author&query=Klymkowsky%2C+M">Michael Klymkowsky</a> (3) ( (1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">There is increasing evidence that human activity in general, and narrative in
particular, can be treated as a dynamical system in the physics sense; a system
whose evolution is described by an action integral, such that the average of
all possible paths from point A to point B is given by the extremum of the
action. We create by construction three such paths by averaging about 500
different narratives, and we show that the average path is consistent with an
action principle.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06604" title="Abstract">arXiv:2309.06604</a> [<a href="/pdf/2309.06604" title="Download PDF">pdf</a>, <a href="/format/2309.06604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hybrid Algorithm Selection and Hyperparameter Tuning on Distributed  Machine Learning Resources: A Hierarchical Agent-based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Esmaeili%2C+A">Ahmad Esmaeili</a>, 
<a href="/search/cs?searchtype=author&query=Matson%2C+E+T">Eric T. Matson</a>, 
<a href="/search/cs?searchtype=author&query=Rayz%2C+J+T">Julia T. Rayz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Algorithm selection and hyperparameter tuning are critical steps in both
academic and applied machine learning. On the other hand, these steps are
becoming ever increasingly delicate due to the extensive rise in the number,
diversity, and distributedness of machine learning resources. Multi-agent
systems, when applied to the design of machine learning platforms, bring about
several distinctive characteristics such as scalability, flexibility, and
robustness, just to name a few. This paper proposes a fully automatic and
collaborative agent-based mechanism for selecting distributedly organized
machine learning algorithms and simultaneously tuning their hyperparameters.
Our method builds upon an existing agent-based hierarchical machine-learning
platform and augments its query structure to support the aforementioned
functionalities without being limited to specific learning, selection, and
tuning mechanisms. We have conducted theoretical assessments, formal
verification, and analytical study to demonstrate the correctness, resource
utilization, and computational efficiency of our technique. According to the
results, our solution is totally correct and exhibits linear time and space
complexity in relation to the size of available resources. To provide concrete
examples of how the proposed methodologies can effectively adapt and perform
across a range of algorithmic options and datasets, we have also conducted a
series of experiments using a system comprised of 24 algorithms and 9 datasets.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06606" title="Abstract">arXiv:2309.06606</a> [<a href="/pdf/2309.06606" title="Download PDF">pdf</a>, <a href="/format/2309.06606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Differentiable Filters Enable Ubiquitous Robot Control  with Smartwatches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weigend%2C+F+C">Fabian C Weigend</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Amor%2C+H+B">Heni Ben Amor</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DiffPropRob IROS 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Ubiquitous robot control and human-robot collaboration using smart devices
poses a challenging problem primarily due to strict accuracy requirements and
sparse information. This paper presents a novel approach that incorporates a
probabilistic differentiable filter, specifically the Differentiable Ensemble
Kalman Filter (DEnKF), to facilitate robot control solely using Inertial
Measurement Units (IMUs) observations from a smartwatch and a smartphone. The
implemented system achieves accurate estimation of human pose state with a
reduction of 30.2% compared to the baseline using the Mean Per Joint Vertex
Error (MPJVE). Our results foster smartwatches and smartphones as a
cost-effective alternative human-pose state estimation. Furthermore, experiment
results from human-robot handover tasks underscore that smart devices allow for
low-cost, versatile and ubiquitous robot control.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06607" title="Abstract">arXiv:2309.06607</a> [<a href="/pdf/2309.06607" title="Download PDF">pdf</a>, <a href="/format/2309.06607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Analysis of Racial Categories in the Algorithmic Fairness  Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdu%2C+A+A">Amina A. Abdu</a>, 
<a href="/search/cs?searchtype=author&query=Pasquetto%2C+I+V">Irene V. Pasquetto</a>, 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+A+Z">Abigail Z. Jacobs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 2 figures, FAccT '23
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 2023 ACM Conference on Fairness,
  Accountability, and Transparency (pp. 1324-1333)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Recent work in algorithmic fairness has highlighted the challenge of defining
racial categories for the purposes of anti-discrimination. These challenges are
not new but have previously fallen to the state, which enacts race through
government statistics, policies, and evidentiary standards in
anti-discrimination law. Drawing on the history of state race-making, we
examine how longstanding questions about the nature of race and discrimination
appear within the algorithmic fairness literature. Through a content analysis
of 60 papers published at FAccT between 2018 and 2020, we analyze how race is
conceptualized and formalized in algorithmic fairness frameworks. We note that
differing notions of race are adopted inconsistently, at times even within a
single analysis. We also explore the institutional influences and values
associated with these choices. While we find that categories used in
algorithmic fairness work often echo legal frameworks, we demonstrate that
values from academic computer science play an equally important role in the
construction of racial categories. Finally, we examine the reasoning behind
different operationalizations of race, finding that few papers explicitly
describe their choices and even fewer justify them. We argue that the
construction of racial categories is a value-laden process with significant
social and political consequences for the project of algorithmic fairness. The
widespread lack of justification around the operationalization of race reflects
institutional norms that allow these political decisions to remain obscured
within the backstage of knowledge production.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06608" title="Abstract">arXiv:2309.06608</a> [<a href="/pdf/2309.06608" title="Download PDF">pdf</a>, <a href="/format/2309.06608" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pump, Dump, and then What? The Long-Term Impact of Cryptocurrency  Pump-and-Dump Schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Clough%2C+J">Joshua Clough</a>, 
<a href="/search/cs?searchtype=author&query=Edwards%2C+M">Matthew Edwards</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The pump and dump scheme is a form of market manipulation attack in which
coordinated actors drive up the price of an asset in order to sell at a higher
price. Due in part to a lack of enforcement, these schemes are widespread
within the cryptocurrency marketplace, but the negative impact of these events
on the coins they target is not yet fully understood. Drawing upon a novel
dataset of pump events extracted from Telegram channels, an order of magnitude
larger than the nearest comparable dataset in the literature, we explore the
differing tactics of pumping channels and the long-term impact of pump and dump
schemes across 765 coins. We find that, despite a short-term positive impact in
some cases, the long-term impact of pump and dump schemes on the targeted
assets is negative, amounting to an average 30% relative drop in price a year
after the pump event.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06611" title="Abstract">arXiv:2309.06611</a> [<a href="/pdf/2309.06611" title="Download PDF">pdf</a>, <a href="/format/2309.06611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling the Deployment of Any-Scale Robotic Applications in  Microservice-Based Service-Oriented Architectures through Automated  Containerization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busch%2C+J">Jean-Pierre Busch</a>, 
<a href="/search/cs?searchtype=author&query=Reiher%2C+L">Lennart Reiher</a>, 
<a href="/search/cs?searchtype=author&query=Eckstein%2C+L">Lutz Eckstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In an increasingly automated world -- from warehouse robots to self-driving
cars -- streamlining the development and deployment process and operations of
robotic applications becomes ever more important. Automated DevOps processes
and microservice-based architectures have already proven successful in other
domains such as large-scale customer-oriented web services (e.g., Netflix). We
recommend to employ similar microservice-based service-oriented architectures
for the deployment of small- to large-scale robotic applications in order to
accelerate development cycles, loosen functional dependence, and improve
resiliency and elasticity. In order to facilitate involved DevOps processes, we
present and release a tooling suite for automating the microservice-based
development and build of robotic applications based on the Robot Operating
System (ROS). Our tooling suite covers the automated minimal containerization
of ROS applications, a collection of useful machine learning-enabled base
container images, as well as a handy CLI tool for simplified interaction with
container images during the development phase. Within the scope of this paper,
we embed our tooling suite into the overall context of streamlined robotics
deployment and compare it to alternative solutions. We publicly release our
tools as free and open-source software at
https://github.com/ika-rwth-aachen/dorotos.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06612" title="Abstract">arXiv:2309.06612</a> [<a href="/pdf/2309.06612" title="Download PDF">pdf</a>, <a href="/format/2309.06612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harmonic-NAS: Hardware-Aware Multimodal Neural Architecture Search on  Resource-constrained Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghebriout%2C+M+I+E">Mohamed Imed Eddine Ghebriout</a>, 
<a href="/search/cs?searchtype=author&query=Bouzidi%2C+H">Halima Bouzidi</a>, 
<a href="/search/cs?searchtype=author&query=Niar%2C+S">Smail Niar</a>, 
<a href="/search/cs?searchtype=author&query=Ouarnoughi%2C+H">Hamza Ouarnoughi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 15th Asian Conference on Machine Learning (ACML 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The recent surge of interest surrounding Multimodal Neural Networks (MM-NN)
is attributed to their ability to effectively process and integrate information
from diverse data sources. In MM-NN, features are extracted and fused from
multiple modalities using adequate unimodal backbones and specific fusion
networks. Although this helps strengthen the multimodal information
representation, designing such networks is labor-intensive. It requires tuning
the architectural parameters of the unimodal backbones, choosing the fusing
point, and selecting the operations for fusion. Furthermore, multimodality AI
is emerging as a cutting-edge option in Internet of Things (IoT) systems where
inference latency and energy consumption are critical metrics in addition to
accuracy. In this paper, we propose Harmonic-NAS, a framework for the joint
optimization of unimodal backbones and multimodal fusion networks with hardware
awareness on resource-constrained devices. Harmonic-NAS involves a two-tier
optimization approach for the unimodal backbone architectures and fusion
strategy and operators. By incorporating the hardware dimension into the
optimization, evaluation results on various devices and multimodal datasets
have demonstrated the superiority of Harmonic-NAS over state-of-the-art
approaches achieving up to 10.9% accuracy improvement, 1.91x latency reduction,
and 2.14x energy efficiency gain.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06613" title="Abstract">arXiv:2309.06613</a> [<a href="/pdf/2309.06613" title="Download PDF">pdf</a>, <a href="/format/2309.06613" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Learning of Nanoindentation Data to Infer Microstructural  Details of Complex Materials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bos%2C+C">Cl&#xe9;mence Bos</a>, 
<a href="/search/cs?searchtype=author&query=Sandfeld%2C+S">Stefan Sandfeld</a>, 
<a href="/search/cs?searchtype=author&query=Schwaiger%2C+R">Ruth Schwaiger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">In this study, Cu-Cr composites were studied by nanoindentation. Arrays of
indents were placed over large areas of the samples resulting in datasets
consisting of several hundred measurements of Young's modulus and hardness at
varying indentation depths. The unsupervised learning technique, Gaussian
mixture model, was employed to analyze the data, which helped to determine the
number of "mechanical phases" and the respective mechanical properties.
Additionally, a cross-validation approach was introduced to infer whether the
data quantity was adequate and to suggest the amount of data required for
reliable predictions -- one of the often encountered but difficult to resolve
issues in machine learning of materials science problems.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06615" title="Abstract">arXiv:2309.06615</a> [<a href="/pdf/2309.06615" title="Download PDF">pdf</a>, <a href="/format/2309.06615" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Differential Privacy of Online Algorithms with Multiple  Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chadha%2C+R">Rohit Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Sistla%2C+A+P">A. Prasad Sistla</a>, 
<a href="/search/cs?searchtype=author&query=Viswanathan%2C+M">Mahesh Viswanathan</a>, 
<a href="/search/cs?searchtype=author&query=Bhusal%2C+B">Bishnu Bhusal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO); Programming Languages (cs.PL)

</div>
<p class="mathjax">We consider the problem of checking the differential privacy of online
randomized algorithms that process a stream of inputs and produce outputs
corresponding to each input. This paper generalizes an automaton model called
DiP automata (See <a href="/abs/2104.14519">arXiv:2104.14519</a>) to describe such algorithms by allowing
multiple real-valued storage variables. A DiP automaton is a parametric
automaton whose behavior depends on the privacy budget $\epsilon$. An automaton
$A$ will be said to be differentially private if, for some $\mathfrak{D}$, the
automaton is $\mathfrak{D}\epsilon$-differentially private for all values of
$\epsilon&gt;0$. We identify a precise characterization of the class of all
differentially private DiP automata. We show that the problem of determining if
a given DiP automaton belongs to this class is PSPACE-complete. Our PSPACE
algorithm also computes a value for $\mathfrak{D}$ when the given automaton is
differentially private. The algorithm has been implemented, and experiments
demonstrating its effectiveness are presented.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06617" title="Abstract">arXiv:2309.06617</a> [<a href="/pdf/2309.06617" title="Download PDF">pdf</a>, <a href="/format/2309.06617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating model evaluations in uncertainty propagation on tensor  grids using computational graph transformations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sperry%2C+M">Mark Sperry</a>, 
<a href="/search/cs?searchtype=author&query=Gandarillas%2C+V+E">Victor E. Gandarillas</a>, 
<a href="/search/cs?searchtype=author&query=Hwang%2C+J+T">John T. Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Methods such as non-intrusive polynomial chaos (NIPC), and stochastic
collocation are frequently used for uncertainty propagation problems.
Particularly for low-dimensional problems, these methods often use a
tensor-product grid for sampling the space of uncertain inputs. A limitation of
this approach is that it encounters a significant challenge: the number of
sample points grows exponentially with the increase of uncertain inputs.
Current strategies to mitigate computational costs abandon the tensor structure
of sampling points, with the aim of reducing their overall count.
Contrastingly, our investigation reveals that preserving the tensor structure
of sample points can offer distinct advantages in specific scenarios. Notably,
by manipulating the computational graph of the targeted model, it is feasible
to avoid redundant evaluations at the operation level to significantly reduce
the model evaluation cost on tensor-grid inputs. This paper presents a
pioneering method: Accelerated Model Evaluations on Tensor grids using
Computational graph transformations (AMTC). The core premise of AMTC lies in
the strategic modification of the computational graph of the target model to
algorithmically remove the repeated evaluations on the operation level. We
implemented the AMTC method within the compiler of a new modeling language
called the Computational System Design Language (CSDL). We demonstrate the
effectiveness of AMTC by using it with the full-grid NIPC method to solve three
low-dimensional UQ problems involving an analytical piston model, a
multidisciplinary unmanned aerial vehicle design model, and a multi-point air
taxi mission analysis model, respectively. For all of the test problems, AMTC
reduces the model evaluation cost by between 50% and 90%, making the full-grid
NIPC the most efficacious method to use among the UQ methods implemented.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06618" title="Abstract">arXiv:2309.06618</a> [<a href="/pdf/2309.06618" title="Download PDF">pdf</a>, <a href="/format/2309.06618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-dimensional Fusion and Consistency for Semi-supervised Medical  Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yixing Lu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Min Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Tissues and Organs (q-bio.TO)

</div>
<p class="mathjax">In this paper, we introduce a novel semi-supervised learning framework
tailored for medical image segmentation. Central to our approach is the
innovative Multi-scale Text-aware ViT-CNN Fusion scheme. This scheme adeptly
combines the strengths of both ViTs and CNNs, capitalizing on the unique
advantages of both architectures as well as the complementary information in
vision-language modalities. Further enriching our framework, we propose the
Multi-Axis Consistency framework for generating robust pseudo labels, thereby
enhancing the semi-supervised learning process. Our extensive experiments on
several widely-used datasets unequivocally demonstrate the efficacy of our
approach.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06619" title="Abstract">arXiv:2309.06619</a> [<a href="/pdf/2309.06619" title="Download PDF">pdf</a>, <a href="/format/2309.06619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wei Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RTSS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Systems and Control (eess.SY)

</div>
<p class="mathjax">Recent advancements in language models (LMs) have gained substantial
attentions on their capability to generate human-like responses. Though
exhibiting a promising future for various applications such as conversation AI,
these LMs face deployment challenges on various devices due to their extreme
computational cost and unpredictable inference latency. Such varied inference
latency, identified as a consequence of uncertainty intrinsic to the nature of
language, can lead to computational inefficiency and degrade the overall
performance of LMs, especially under high-traffic workloads. Unfortunately, the
bandwidth of these uncertainty sources is extensive, complicating the
prediction of latency and the effects emanating from such uncertainties. To
understand and mitigate the impact of uncertainty on real-time
response-demanding systems, we take the first step to comprehend, quantify and
optimize these uncertainty-induced latency performance variations in LMs.
Specifically, we present RT-LM, an uncertainty-aware resource management
ecosystem for real-time inference of LMs. RT-LM innovatively quantifies how
specific input uncertainties, adversely affect latency, often leading to an
increased output length. Exploiting these insights, we devise a lightweight yet
effective method to dynamically correlate input text uncertainties with output
length at runtime. Utilizing this quantification as a latency heuristic, we
integrate the uncertainty information into a system-level scheduler which
explores several uncertainty-induced optimization opportunities, including
uncertainty-aware prioritization, dynamic consolidation, and strategic CPU
offloading. Quantitative experiments across five state-of-the-art LMs on two
hardware platforms demonstrates that RT-LM can significantly reduce the average
response time and improve throughput while incurring a rather small runtime
overhead.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06620" title="Abstract">arXiv:2309.06620</a> [<a href="/pdf/2309.06620" title="Download PDF">pdf</a>, <a href="/format/2309.06620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Games and Argumentation: Time for a Family Reunion!
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lud%C3%A4scher%2C+B">Bertram Lud&#xe4;scher</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yilin Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fourth Workshop on Explainable Logic-Based Knowledge Representation (XLoKR), Sept 2, 2023. Rhodes, Greece
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The rule "defeated(X) $\leftarrow$ attacks(Y,X), $\neg$ defeated(Y)" states
that an argument is defeated if it is attacked by an argument that is not
defeated. The rule "win(X) $\leftarrow$ move(X,Y), $\neg$ win(Y)" states that
in a game a position is won if there is a move to a position that is not won.
Both logic rules can be seen as close relatives (even identical twins) and both
rules have been at the center of attention at various times in different
communities: The first rule lies at the core of argumentation frameworks and
has spawned a large family of models and semantics of abstract argumentation.
The second rule has played a key role in the quest to find the "right"
semantics for logic programs with recursion through negation, and has given
rise to the stable and well-founded semantics. Both semantics have been widely
studied by the logic programming and nonmonotonic reasoning community. The
second rule has also received much attention by the database and finite model
theory community, e.g., when studying the expressive power of query languages
and fixpoint logics. Although close connections between argumentation
frameworks, logic programming, and dialogue games have been known for a long
time, the overlap and cross-fertilization between the communities appears to be
smaller than one might expect. To this end, we recall some of the key results
from database theory in which the win-move query has played a central role,
e.g., on normal forms and expressive power of query languages. We introduce
some notions that naturally emerge from games and that may provide new
perspectives and research opportunities for argumentation frameworks. We
discuss how solved query evaluation games reveal how- and why-not provenance of
query answers. These techniques can be used to explain how results were derived
via the given query, game, or argumentation framework.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06621" title="Abstract">arXiv:2309.06621</a> [<a href="/pdf/2309.06621" title="Download PDF">pdf</a>, <a href="/format/2309.06621" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Reinforcement Learning Approach for Robotic Unloading from Visual  Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giammarino%2C+V">Vittorio Giammarino</a>, 
<a href="/search/cs?searchtype=author&query=Giammarino%2C+A">Alberto Giammarino</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+M">Matthew Pearce</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
<p class="mathjax">In this work, we focus on a robotic unloading problem from visual
observations, where robots are required to autonomously unload stacks of
parcels using RGB-D images as their primary input source. While supervised and
imitation learning have accomplished good results in these types of tasks, they
heavily rely on labeled data, which are challenging to obtain in realistic
scenarios. Our study aims to develop a sample efficient controller framework
that can learn unloading tasks without the need for labeled data during the
learning process. To tackle this challenge, we propose a hierarchical
controller structure that combines a high-level decision-making module with
classical motion control. The high-level module is trained using Deep
Reinforcement Learning (DRL), wherein we incorporate a safety bias mechanism
and design a reward function tailored to this task. Our experiments demonstrate
that both these elements play a crucial role in achieving improved learning
performance. Furthermore, to ensure reproducibility and establish a benchmark
for future research, we provide free access to our code and simulation.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06626" title="Abstract">arXiv:2309.06626</a> [<a href="/pdf/2309.06626" title="Download PDF">pdf</a>, <a href="/format/2309.06626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Deep Neural Networks via Semi-Structured Activation  Sparsity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grimaldi%2C+M">Matteo Grimaldi</a>, 
<a href="/search/cs?searchtype=author&query=Ganji%2C+D+C">Darshan C. Ganji</a>, 
<a href="/search/cs?searchtype=author&query=Lazarevich%2C+I">Ivan Lazarevich</a>, 
<a href="/search/cs?searchtype=author&query=Sah%2C+S">Sudhakar Sah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="http://github.com/Deeplite/activ-sparse">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The demand for efficient processing of deep neural networks (DNNs) on
embedded devices is a significant challenge limiting their deployment.
Exploiting sparsity in the network's feature maps is one of the ways to reduce
its inference latency. It is known that unstructured sparsity results in lower
accuracy degradation with respect to structured sparsity but the former needs
extensive inference engine changes to get latency benefits. To tackle this
challenge, we propose a solution to induce semi-structured activation sparsity
exploitable through minor runtime modifications. To attain high speedup levels
at inference time, we design a sparse training procedure with awareness of the
final position of the activations while computing the General Matrix
Multiplication (GEMM). We extensively evaluate the proposed solution across
various models for image classification and object detection tasks. Remarkably,
our approach yields a speed improvement of $1.25 \times$ with a minimal
accuracy drop of $1.1\%$ for the ResNet18 model on the ImageNet dataset.
Furthermore, when combined with a state-of-the-art structured pruning method,
the resulting models provide a good latency-accuracy trade-off, outperforming
models that solely employ structured pruning techniques.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06628" title="Abstract">arXiv:2309.06628</a> [<a href="/pdf/2309.06628" title="Download PDF">pdf</a>, <a href="/format/2309.06628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Epistemic Modeling Uncertainty of Rapid Neural Network Ensembles for  Adaptive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beachy%2C+A">Atticus Beachy</a> (1), 
<a href="/search/cs?searchtype=author&query=Bae%2C+H">Harok Bae</a> (1), 
<a href="/search/cs?searchtype=author&query=Camberos%2C+J">Jose Camberos</a> (2), 
<a href="/search/cs?searchtype=author&query=Grandhi%2C+R">Ramana Grandhi</a> (2) ((1) Wright State University, Dayton, OH, USA (2) Air Force Institute of Technology, Wright-Patterson AFB, OH, USA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Emulator embedded neural networks, which are a type of physics informed
neural network, leverage multi-fidelity data sources for efficient design
exploration of aerospace engineering systems. Multiple realizations of the
neural network models are trained with different random initializations. The
ensemble of model realizations is used to assess epistemic modeling uncertainty
caused due to lack of training samples. This uncertainty estimation is crucial
information for successful goal-oriented adaptive learning in an aerospace
system design exploration. However, the costs of training the ensemble models
often become prohibitive and pose a computational challenge, especially when
the models are not trained in parallel during adaptive learning. In this work,
a new type of emulator embedded neural network is presented using the rapid
neural network paradigm. Unlike the conventional neural network training that
optimizes the weights and biases of all the network layers by using
gradient-based backpropagation, rapid neural network training adjusts only the
last layer connection weights by applying a linear regression technique. It is
found that the proposed emulator embedded neural network trains
near-instantaneously, typically without loss of prediction accuracy. The
proposed method is demonstrated on multiple analytical examples, as well as an
aerospace flight parameter study of a generic hypersonic vehicle.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06629" title="Abstract">arXiv:2309.06629</a> [<a href="/pdf/2309.06629" title="Download PDF">pdf</a>, <a href="/format/2309.06629" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Relational Bottleneck as an Inductive Bias for Efficient Abstraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Webb%2C+T+W">Taylor W. Webb</a>, 
<a href="/search/cs?searchtype=author&query=Frankland%2C+S+M">Steven M. Frankland</a>, 
<a href="/search/cs?searchtype=author&query=Altabaa%2C+A">Awni Altabaa</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+K">Kamesh Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Campbell%2C+D">Declan Campbell</a>, 
<a href="/search/cs?searchtype=author&query=Russin%2C+J">Jacob Russin</a>, 
<a href="/search/cs?searchtype=author&query=O%27Reilly%2C+R">Randall O&#x27;Reilly</a>, 
<a href="/search/cs?searchtype=author&query=Lafferty%2C+J">John Lafferty</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+J+D">Jonathan D. Cohen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">A central challenge for cognitive science is to explain how abstract concepts
are acquired from limited experience. This effort has often been framed in
terms of a dichotomy between empiricist and nativist approaches, most recently
embodied by debates concerning deep neural networks and symbolic cognitive
models. Here, we highlight a recently emerging line of work that suggests a
novel reconciliation of these approaches, by exploiting an inductive bias that
we term the relational bottleneck. We review a family of models that employ
this approach to induce abstractions in a data-efficient manner, emphasizing
their potential as candidate models for the acquisition of abstract concepts in
the human mind and brain.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06633" title="Abstract">arXiv:2309.06633</a> [<a href="/pdf/2309.06633" title="Download PDF">pdf</a>, <a href="/format/2309.06633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCQUIC: Multicast and unicast in a single transport protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarre%2C+L">Louis Navarre</a>, 
<a href="/search/cs?searchtype=author&query=Pereira%2C+O">Olivier Pereira</a>, 
<a href="/search/cs?searchtype=author&query=Bonaventure%2C+O">Olivier Bonaventure</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Multicast enables efficient one-to-many communications. Several applications
benefit from its scalability properties, e.g., live-streaming and large-scale
software updates. Historically, multicast applications have used specialized
transport protocols. The flexibility of the recently standardized QUIC protocol
opens the possibility of providing both unicast and multicast services to
applications with a single transport protocol. We present MCQUIC, an extended
version of the QUIC protocol that supports multicast communications. We show
how QUIC features and built-in security can be leveraged for multicast
transport. We present the design of MCQUIC and implement it in Cloudflare
quiche. We assess its performance through benchmarks and in emulated networks
under realistic scenarios. We also demonstrate MCQUIC in a campus network. By
coupling QUIC with our multicast extension, applications can rely on multicast
for efficiency with the possibility to fall back on unicast in case of
incompatible network conditions.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06634" title="Abstract">arXiv:2309.06634</a> [<a href="/pdf/2309.06634" title="Download PDF">pdf</a>, <a href="/format/2309.06634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> $G$-Mapper: Learning a Cover in the Mapper Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alvarado%2C+E">Enrique Alvarado</a>, 
<a href="/search/cs?searchtype=author&query=Belton%2C+R">Robin Belton</a>, 
<a href="/search/cs?searchtype=author&query=Fischer%2C+E">Emily Fischer</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kang-Ju Lee</a>, 
<a href="/search/cs?searchtype=author&query=Palande%2C+S">Sourabh Palande</a>, 
<a href="/search/cs?searchtype=author&query=Percival%2C+S">Sarah Percival</a>, 
<a href="/search/cs?searchtype=author&query=Purvine%2C+E">Emilie Purvine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT); Machine Learning (stat.ML)

</div>
<p class="mathjax">The Mapper algorithm is a visualization technique in topological data
analysis (TDA) that outputs a graph reflecting the structure of a given
dataset. The Mapper algorithm requires tuning several parameters in order to
generate a "nice" Mapper graph. The paper focuses on selecting the cover
parameter. We present an algorithm that optimizes the cover of a Mapper graph
by splitting a cover repeatedly according to a statistical test for normality.
Our algorithm is based on $G$-means clustering which searches for the optimal
number of clusters in $k$-means by conducting iteratively the Anderson-Darling
test. Our splitting procedure employs a Gaussian mixture model in order to
choose carefully the cover based on the distribution of a given data.
Experiments for synthetic and real-world datasets demonstrate that our
algorithm generates covers so that the Mapper graphs retain the essence of the
datasets.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06635" title="Abstract">arXiv:2309.06635</a> [<a href="/pdf/2309.06635" title="Download PDF">pdf</a>, <a href="/format/2309.06635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Dynamic 3D Scene Graphs for Automated Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greve%2C+E">Elias Greve</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchner%2C+M">Martin B&#xfc;chner</a>, 
<a href="/search/cs?searchtype=author&query=V%C3%B6disch%2C+N">Niclas V&#xf6;disch</a>, 
<a href="/search/cs?searchtype=author&query=Burgard%2C+W">Wolfram Burgard</a>, 
<a href="/search/cs?searchtype=author&query=Valada%2C+A">Abhinav Valada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Maps have played an indispensable role in enabling safe and automated
driving. Although there have been many advances on different fronts ranging
from SLAM to semantics, building an actionable hierarchical semantic
representation of urban dynamic scenes from multiple agents is still a
challenging problem. In this work, we present collaborative urban scene graphs
(CURB-SG) that enable higher-order reasoning and efficient querying for many
functions of automated driving. CURB-SG leverages panoptic LiDAR data from
multiple agents to build large-scale maps using an effective graph-based
collaborative SLAM approach that detects inter-agent loop closures. To
semantically decompose the obtained 3D map, we build a lane graph from the
paths of ego agents and their panoptic observations of other vehicles. Based on
the connectivity of the lane graph, we segregate the environment into
intersecting and non-intersecting road areas. Subsequently, we construct a
multi-layered scene graph that includes lane information, the position of
static landmarks and their assignment to certain map sections, other vehicles
observed by the ego agents, and the pose graph from SLAM including 3D panoptic
point clouds. We extensively evaluate CURB-SG in urban scenarios using a
photorealistic simulator and release our code at
<a href="http://curb.cs.uni-freiburg.de.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06640" title="Abstract">arXiv:2309.06640</a> [<a href="/pdf/2309.06640" title="Download PDF">pdf</a>, <a href="/format/2309.06640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REVIS: An Error Visualization Tool for Rust
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruochen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Maclaren%2C+M">Molly Maclaren</a>, 
<a href="/search/cs?searchtype=author&query=Coblenz%2C+M">Michael Coblenz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at HATRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Rust is a programming language that uses a concept of ownership to guarantee
memory safety without the use of a garbage collector. However, some error
messages related to ownership can be difficult to understand and fix,
particularly those that depend on value lifetimes. To help developers fix
lifetime-related errors, we developed REVIS, a VSCode extension that visualizes
lifetime-related Rust compiler errors. We describe the design and
implementation of the VSCode extension, along with a preliminary evaluation of
its efficacy for student learners of Rust. Although the number of participants
was too low to enable evaluation of the efficacy of REVIS, we gathered data
regarding the prevalence and time to fix the compiler errors that the
participants encountered.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06643" title="Abstract">arXiv:2309.06643</a> [<a href="/pdf/2309.06643" title="Download PDF">pdf</a>, <a href="/format/2309.06643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Classification of Malware Families Under Extreme Class  Imbalance via Hierarchical Non-Negative Matrix Factorization with Automatic  Model Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eren%2C+M+E">Maksim E. Eren</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+M">Manish Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Joyce%2C+R+J">Robert J. Joyce</a>, 
<a href="/search/cs?searchtype=author&query=Raff%2C+E">Edward Raff</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+C">Charles Nicholas</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B+S">Boian S. Alexandrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ACM TOPS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Identification of the family to which a malware specimen belongs is essential
in understanding the behavior of the malware and developing mitigation
strategies. Solutions proposed by prior work, however, are often not
practicable due to the lack of realistic evaluation factors. These factors
include learning under class imbalance, the ability to identify new malware,
and the cost of production-quality labeled data. In practice, deployed models
face prominent, rare, and new malware families. At the same time, obtaining a
large quantity of up-to-date labeled malware for training a model can be
expensive. In this paper, we address these problems and propose a novel
hierarchical semi-supervised algorithm, which we call the HNMFk Classifier,
that can be used in the early stages of the malware family labeling process.
Our method is based on non-negative matrix factorization with automatic model
selection, that is, with an estimation of the number of clusters. With HNMFk
Classifier, we exploit the hierarchical structure of the malware data together
with a semi-supervised setup, which enables us to classify malware families
under conditions of extreme class imbalance. Our solution can perform
abstaining predictions, or rejection option, which yields promising results in
the identification of novel malware families and helps with maintaining the
performance of the model when a low quantity of labeled data is used. We
perform bulk classification of nearly 2,900 both rare and prominent malware
families, through static analysis, using nearly 388,000 samples from the
EMBER-2018 corpus. In our experiments, we surpass both supervised and
semi-supervised baseline models with an F1 score of 0.80.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06645" title="Abstract">arXiv:2309.06645</a> [<a href="/pdf/2309.06645" title="Download PDF">pdf</a>, <a href="/format/2309.06645" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bregman Graph Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+J">Jiayu Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lequan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Numerous recent research on graph neural networks (GNNs) has focused on
formulating GNN architectures as an optimization problem with the smoothness
assumption. However, in node classification tasks, the smoothing effect induced
by GNNs tends to assimilate representations and over-homogenize labels of
connected nodes, leading to adverse effects such as over-smoothing and
misclassification. In this paper, we propose a novel bilevel optimization
framework for GNNs inspired by the notion of Bregman distance. We demonstrate
that the GNN layer proposed accordingly can effectively mitigate the
over-smoothing issue by introducing a mechanism reminiscent of the "skip
connection". We validate our theoretical results through comprehensive
empirical studies in which Bregman-enhanced GNNs outperform their original
counterparts in both homophilic and heterophilic graphs. Furthermore, our
experiments also show that Bregman GNNs can produce more robust learning
accuracy even when the number of layers is high, suggesting the effectiveness
of the proposed method in alleviating the over-smoothing issue.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06647" title="Abstract">arXiv:2309.06647</a> [<a href="/pdf/2309.06647" title="Download PDF">pdf</a>, <a href="/format/2309.06647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Composing Control Barrier Functions for Complex Safety Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/eess?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the IEEE Control System Letters (L-CSS) and the 2024 American Control Conference (ACC). 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Dynamical Systems (math.DS)

</div>
<p class="mathjax">The increasing complexity of control systems necessitates control laws that
guarantee safety w.r.t. complex combinations of constraints. In this letter, we
propose a framework to describe compositional safety specifications with
control barrier functions (CBFs). The specifications are formulated as Boolean
compositions of state constraints, and we propose an algorithmic way to create
a single continuously differentiable CBF that captures these constraints and
enables safety-critical control. We describe the properties of the proposed
CBF, and we demonstrate its efficacy by numerical simulations.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06648" title="Abstract">arXiv:2309.06648</a> [<a href="/pdf/2309.06648" title="Download PDF">pdf</a>, <a href="/format/2309.06648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exp[licit]-A Robot modeling Software based on Exponential Maps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lachner%2C+J">Johannes Lachner</a>, 
<a href="/search/cs?searchtype=author&query=Nah%2C+M+C">Moses C. Nah</a>, 
<a href="/search/cs?searchtype=author&query=Stramigioli%2C+S">Stefano Stramigioli</a>, 
<a href="/search/cs?searchtype=author&query=Hogan%2C+N">Neville Hogan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">$ $Deriving a robot's equation of motion typically requires placing multiple
coordinate frames, commonly using the Denavit-Hartenberg convention to express
the kinematic and dynamic relationships between segments. This paper presents
an alternative using the differential geometric method of Exponential Maps,
which reduces the number of coordinate frame choices to two. The traditional
and differential geometric methods are compared, and the conceptual and
practical differences are detailed. The open-source software, Exp[licit], based
on the differential geometric method, is introduced. It is intended for use by
researchers and engineers with basic knowledge of geometry and robotics. Code
snippets and an example application are provided to demonstrate the benefits of
the differential geometric method and assist users to get started with the
software.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06649" title="Abstract">arXiv:2309.06649</a> [<a href="/pdf/2309.06649" title="Download PDF">pdf</a>, <a href="/format/2309.06649" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Modelling of Percussive Audio with Transient and Spectral  Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shier%2C+J">Jordie Shier</a>, 
<a href="/search/cs?searchtype=author&query=Caspe%2C+F">Franco Caspe</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+A">Andrew Robertson</a>, 
<a href="/search/cs?searchtype=author&query=Sandler%2C+M">Mark Sandler</a>, 
<a href="/search/cs?searchtype=author&query=Saitis%2C+C">Charalampos Saitis</a>, 
<a href="/search/cs?searchtype=author&query=McPherson%2C+A">Andrew McPherson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in The Proceedings of Forum Acusticum, Sep 2023, Turin, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Differentiable digital signal processing (DDSP) techniques, including methods
for audio synthesis, have gained attention in recent years and lend themselves
to interpretability in the parameter space. However, current differentiable
synthesis methods have not explicitly sought to model the transient portion of
signals, which is important for percussive sounds. In this work, we present a
unified synthesis framework aiming to address transient generation and
percussive synthesis within a DDSP framework. To this end, we propose a model
for percussive synthesis that builds on sinusoidal modeling synthesis and
incorporates a modulated temporal convolutional network for transient
generation. We use a modified sinusoidal peak picking algorithm to generate
time-varying non-harmonic sinusoids and pair it with differentiable noise and
transient encoders that are jointly trained to reconstruct drumset sounds. We
compute a set of reconstruction metrics using a large dataset of acoustic and
electronic percussion samples that show that our method leads to improved onset
signal reconstruction for membranophone percussion instruments.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06651" title="Abstract">arXiv:2309.06651</a> [<a href="/pdf/2309.06651" title="Download PDF">pdf</a>, <a href="/format/2309.06651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ConR: Contrastive Regularizer for Deep Imbalanced Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keramati%2C+M">Mahsa Keramati</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Lili Meng</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+R+D">R. David Evans</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Imbalanced distributions are ubiquitous in real-world data. They create
constraints on Deep Neural Networks to represent the minority labels and avoid
bias towards majority labels. The extensive body of imbalanced approaches
address categorical label spaces but fail to effectively extend to regression
problems where the label space is continuous. Conversely, local and global
correlations among continuous labels provide valuable insights towards
effectively modelling relationships in feature space. In this work, we propose
ConR, a contrastive regularizer that models global and local label similarities
in feature space and prevents the features of minority samples from being
collapsed into their majority neighbours. Serving the similarities of the
predictions as an indicator of feature similarities, ConR discerns the
dissagreements between the label space and feature space and imposes a penalty
on these disagreements. ConR minds the continuous nature of label space with
two main strategies in a contrastive manner: incorrect proximities are
penalized proportionate to the label similarities and the correct ones are
encouraged to model local similarities. ConR consolidates essential
considerations into a generic, easy-to-integrate, and efficient method that
effectively addresses deep imbalanced regression. Moreover, ConR is orthogonal
to existing approaches and smoothly extends to uni- and multi-dimensional label
spaces. Our comprehensive experiments show that ConR significantly boosts the
performance of all the state-of-the-art methods on three large-scale deep
imbalanced regression benchmarks. Our code is publicly available in
https://github.com/BorealisAI/ConR.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06652" title="Abstract">arXiv:2309.06652</a> [<a href="/pdf/2309.06652" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-Driven Imaging in Turbid Media: A Confluence of Optoelectronics  and Neuromorphic Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+N">Ning Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shea%2C+T">Timothy Shea</a>, 
<a href="/search/cs?searchtype=author&query=Nurmikko%2C+A">Arto Nurmikko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In this paper a new optical-computational method is introduced to unveil
images of targets whose visibility is severely obscured by light scattering in
dense, turbid media. The targets of interest are taken to be dynamic in that
their optical properties are time-varying whether stationary in space or
moving. The scheme, to our knowledge the first of its kind, is human vision
inspired whereby diffuse photons collected from the turbid medium are first
transformed to spike trains by a dynamic vision sensor as in the retina, and
image reconstruction is then performed by a neuromorphic computing approach
mimicking the brain. We combine benchtop experimental data in both reflection
(backscattering) and transmission geometries with support from physics-based
simulations to develop a neuromorphic computational model and then apply this
for image reconstruction of different MNIST characters and image sets by a
dedicated deep spiking neural network algorithm. Image reconstruction is
achieved under conditions of turbidity where an original image is
unintelligible to the human eye or a digital video camera, yet clearly and
quantifiable identifiable when using the new neuromorphic computational
approach.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06655" title="Abstract">arXiv:2309.06655</a> [<a href="/pdf/2309.06655" title="Download PDF">pdf</a>, <a href="/format/2309.06655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Out of Distribution Detection via Domain-Informed Gaussian Process State  Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marco%2C+A">Alonso Marco</a>, 
<a href="/search/cs?searchtype=author&query=Morley%2C+E">Elias Morley</a>, 
<a href="/search/cs?searchtype=author&query=Tomlin%2C+C+J">Claire J. Tomlin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In order for robots to safely navigate in unseen scenarios using
learning-based methods, it is important to accurately detect
out-of-training-distribution (OoD) situations online. Recently, Gaussian
process state-space models (GPSSMs) have proven useful to discriminate
unexpected observations by comparing them against probabilistic predictions.
However, the capability for the model to correctly distinguish between in- and
out-of-training distribution observations hinges on the accuracy of these
predictions, primarily affected by the class of functions the GPSSM kernel can
represent. In this paper, we propose (i) a novel approach to embed existing
domain knowledge in the kernel and (ii) an OoD online runtime monitor, based on
receding-horizon predictions. Domain knowledge is assumed given as a dataset
collected either in simulation or using a nominal model. Numerical results show
that the informed kernel yields better regression quality with smaller
datasets, as compared to standard kernel choices. We demonstrate the
effectiveness of the OoD monitor on a real quadruped navigating an indoor
setting, which reliably classifies previously unseen terrains.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06657" title="Abstract">arXiv:2309.06657</a> [<a href="/pdf/2309.06657" title="Download PDF">pdf</a>, <a href="/format/2309.06657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Rejection Sampling Improves Preference Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Joshi%2C+R">Rishabh Joshi</a>, 
<a href="/search/cs?searchtype=author&query=Khalman%2C+M">Misha Khalman</a>, 
<a href="/search/cs?searchtype=author&query=Saleh%2C+M">Mohammad Saleh</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Improving the alignment of language models with human preferences remains an
active research challenge. Previous approaches have primarily utilized
Reinforcement Learning from Human Feedback (RLHF) via online RL methods such as
Proximal Policy Optimization (PPO). Recently, offline methods such as Sequence
Likelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have
emerged as attractive alternatives, offering improvements in stability and
scalability while maintaining competitive performance. SLiC refines its loss
function using sequence pairs sampled from a supervised fine-tuned (SFT)
policy, while DPO directly optimizes language models based on preference data,
foregoing the need for a separate reward model. However, the maximum likelihood
estimator (MLE) of the target optimal policy requires labeled preference pairs
sampled from that policy. DPO's lack of a reward model constrains its ability
to sample preference pairs from the optimal policy, and SLiC is restricted to
sampling preference pairs only from the SFT policy. To address these
limitations, we introduce a novel approach called Statistical Rejection
Sampling Optimization (RSO) that aims to source preference data from the target
optimal policy using rejection sampling, enabling a more accurate estimation of
the optimal policy. We also propose a unified framework that enhances the loss
functions used in both SLiC and DPO from a preference modeling standpoint.
Through extensive experiments across three diverse tasks, we demonstrate that
RSO consistently outperforms both SLiC and DPO on evaluations from both Large
Language Model (LLM) and human raters.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06658" title="Abstract">arXiv:2309.06658</a> [<a href="/pdf/2309.06658" title="Download PDF">pdf</a>, <a href="/ps/2309.06658" title="Download PostScript">ps</a>, <a href="/format/2309.06658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dissipative Imitation Learning for Discrete Dynamic Output Feedback  Control with Sparse Data Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Strong%2C+A+K">Amy K. Strong</a>, 
<a href="/search/eess?searchtype=author&query=LoCicero%2C+E+J">Ethan J. LoCicero</a>, 
<a href="/search/eess?searchtype=author&query=Bridgeman%2C+L+J">Leila J. Bridgeman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Imitation learning enables the synthesis of controllers for complex
objectives and highly uncertain plant models. However, methods to provide
stability guarantees to imitation learned controllers often rely on large
amounts of data and/or known plant models. In this paper, we explore an
input-output (IO) stability approach to dissipative imitation learning, which
achieves stability with sparse data sets and with little known about the plant
model. A closed-loop stable dynamic output feedback controller is learned using
expert data, a coarse IO plant model, and a new constraint to enforce
dissipativity on the learned controller. While the learning objective is
nonconvex, iterative convex overbounding (ICO) and projected gradient descent
(PGD) are explored as methods to successfully learn the controller. This new
imitation learning method is applied to two unknown plants and compared to
traditionally learned dynamic output feedback controller and neural network
controller. With little knowledge of the plant model and a small data set, the
dissipativity constrained learned controller achieves closed loop stability and
successfully mimics the behavior of the expert controller, while other methods
often fail to maintain stability and achieve good performance.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06659" title="Abstract">arXiv:2309.06659</a> [<a href="/pdf/2309.06659" title="Download PDF">pdf</a>, <a href="/format/2309.06659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond English: Centering Multilingualism in Data Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakotondravony%2C+N">No&#xeb;lle Rakotondravony</a>, 
<a href="/search/cs?searchtype=author&query=Dhawka%2C+P">Priya Dhawka</a>, 
<a href="/search/cs?searchtype=author&query=Bancilhon%2C+M">Melanie Bancilhon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, Visualization for Social Good @VIS23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Information visualization and natural language are intricately linked.
However, the majority of research and relevant work in information and data
visualization (and human-computer interaction) involve English-speaking
populations as both researchers and participants, are published in English, and
are presented predominantly at English-speaking venues. Although several
solutions can be proposed such as translating English texts in visualization to
other languages, there is little research that looks at the intersection of
data visualization and different languages, and the implications that current
visualization practices have on non-English speaking communities. In this
position paper, we argue that linguistically diverse communities abound beyond
the English-speaking world and offer a richness of experiences for the
visualization research community to engage with. Through a case study of how
two non-English languages interplay with data visualization reasoning in
Madagascar, we describe how monolingualism in data visualization impacts the
experiences of underrepresented populations and emphasize potential harm to
these communities. Lastly, we raise several questions towards advocating for
more inclusive visualization practices that center the diverse experiences of
linguistically underrepresented populations.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06660" title="Abstract">arXiv:2309.06660</a> [<a href="/pdf/2309.06660" title="Download PDF">pdf</a>, <a href="/format/2309.06660" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable Neural Fields as Partially Observed Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jeffrey Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuan-Chieh Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Neural fields, which represent signals as a function parameterized by a
neural network, are a promising alternative to traditional discrete vector or
grid-based representations. Compared to discrete representations, neural
representations both scale well with increasing resolution, are continuous, and
can be many-times differentiable. However, given a dataset of signals that we
would like to represent, having to optimize a separate neural field for each
signal is inefficient, and cannot capitalize on shared information or
structures among signals. Existing generalization methods view this as a
meta-learning problem and employ gradient-based meta-learning to learn an
initialization which is then fine-tuned with test-time optimization, or learn
hypernetworks to produce the weights of a neural field. We instead propose a
new paradigm that views the large-scale training of neural representations as a
part of a partially-observed neural process framework, and leverage neural
process algorithms to solve this task. We demonstrate that this approach
outperforms both state-of-the-art gradient-based meta-learning approaches and
hypernetwork approaches.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06664" title="Abstract">arXiv:2309.06664</a> [<a href="/pdf/2309.06664" title="Download PDF">pdf</a>, <a href="/ps/2309.06664" title="Download PostScript">ps</a>, <a href="/format/2309.06664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fixed-parameter tractable algorithm for combinatorial filter reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shell%2C+D+A">Dylan A. Shell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">What is the minimal information that a robot must retain to achieve its task?
To design economical robots, the literature dealing with reduction of
combinatorial filters approaches this problem algorithmically.As lossless state
compression is NP-hard, prior work has examined, along with minimization
algorithms, a variety of special cases in which specific properties enable
efficient solution. Complementing those findings, this paper refines the
present understanding from the perspective of parameterized complexity. We give
a fixed-parameter tractable algorithm for the general reduction problem by
exploiting a transformation into minimal clique covering. The transformation
introduces new constraints that arise from sequential dependencies encoded
within the input filter -- some of these constraints can be repaired, others
are treated through enumeration. Through this approach, we identify parameters
affecting filter reduction that are based upon inter-constraint couplings
(expressed as a notion of their height and width), which add to the structural
parameters present in the unconstrained problem of minimal clique covering.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06670" title="Abstract">arXiv:2309.06670</a> [<a href="/pdf/2309.06670" title="Download PDF">pdf</a>, <a href="/format/2309.06670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ShaDocFormer: A Shadow-attentive Threshold Detector with Cascaded Fusion  Refiner for document shadow removal&#x27; to the ICASSP 2024 online submission  system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weiwen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+S">Shenghong Luo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zinuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pun%2C+C">Chi-Man Pun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Document shadow is a common issue that arise when capturing documents using
mobile devices, which significantly impacts the readability. Current methods
encounter various challenges including inaccurate detection of shadow masks and
estimation of illumination. In this paper, we propose ShaDocFormer, a
Transformer-based architecture that integrates traditional methodologies and
deep learning techniques to tackle the problem of document shadow removal. The
ShaDocFormer architecture comprises two components: the Shadow-attentive
Threshold Detector (STD) and the Cascaded Fusion Refiner (CFR). The STD module
employs a traditional thresholding technique and leverages the attention
mechanism of the Transformer to gather global information, thereby enabling
precise detection of shadow masks. The cascaded and aggregative structure of
the CFR module facilitates a coarse-to-fine restoration process for the entire
image. As a result, ShaDocFormer excels in accurately detecting and capturing
variations in both shadow and illumination, thereby enabling effective removal
of shadows. Extensive experiments demonstrate that ShaDocFormer outperforms
current state-of-the-art methods in both qualitative and quantitative
measurements.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06672" title="Abstract">arXiv:2309.06672</a> [<a href="/pdf/2309.06672" title="Download PDF">pdf</a>, <a href="/format/2309.06672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-based Encoder-Decoder End-to-End Neural Diarization with  Embedding Enhancer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhengyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bing Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/ACM Transactions on Audio Speech and Language Processing Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deep neural network-based systems have significantly improved the performance
of speaker diarization tasks. However, end-to-end neural diarization (EEND)
systems often struggle to generalize to scenarios with an unseen number of
speakers, while target speaker voice activity detection (TS-VAD) systems tend
to be overly complex. In this paper, we propose a simple attention-based
encoder-decoder network for end-to-end neural diarization (AED-EEND). In our
training process, we introduce a teacher-forcing strategy to address the
speaker permutation problem, leading to faster model convergence. For
evaluation, we propose an iterative decoding method that outputs diarization
results for each speaker sequentially. Additionally, we propose an Enhancer
module to enhance the frame-level speaker embeddings, enabling the model to
handle scenarios with an unseen number of speakers. We also explore replacing
the transformer encoder with a Conformer architecture, which better models
local information. Furthermore, we discovered that commonly used simulation
datasets for speaker diarization have a much higher overlap ratio compared to
real data. We found that using simulated training data that is more consistent
with real data can achieve an improvement in consistency. Extensive
experimental validation demonstrates the effectiveness of our proposed
methodologies. Our best system achieved a new state-of-the-art diarization
error rate (DER) performance on all the CALLHOME (10.08%), DIHARD II (24.64%),
and AMI (13.00%) evaluation benchmarks, when no oracle voice activity detection
(VAD) is used. Beyond speaker diarization, our AED-EEND system also shows
remarkable competitiveness as a speech type detection model.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06673" title="Abstract">arXiv:2309.06673</a> [<a href="/pdf/2309.06673" title="Download PDF">pdf</a>, <a href="/format/2309.06673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ridge detection for nonstationary multicomponent signals with  time-varying wave-shape functions and its applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Su%2C+Y">Yan-Wei Su</a>, 
<a href="/search/math?searchtype=author&query=Liu%2C+G">Gi-Ren Liu</a>, 
<a href="/search/math?searchtype=author&query=Sheu%2C+Y">Yuan-Chung Sheu</a>, 
<a href="/search/math?searchtype=author&query=Wu%2C+H">Hau-Tieng Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">We introduce a novel ridge detection algorithm for time-frequency (TF)
analysis, particularly tailored for intricate nonstationary time series
encompassing multiple non-sinusoidal oscillatory components. The algorithm is
rooted in the distinctive geometric patterns that emerge in the TF domain due
to such non-sinusoidal oscillations. We term this method \textit{shape-adaptive
mode decomposition-based multiple harmonic ridge detection}
(\textsf{SAMD-MHRD}). A swift implementation is available when supplementary
information is at hand. We demonstrate the practical utility of
\textsf{SAMD-MHRD} through its application to a real-world challenge. We employ
it to devise a cutting-edge walking activity detection algorithm, leveraging
accelerometer signals from an inertial measurement unit across diverse body
locations of a moving subject.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06677" title="Abstract">arXiv:2309.06677</a> [<a href="/pdf/2309.06677" title="Download PDF">pdf</a>, <a href="/format/2309.06677" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SHARM: Segmented Head Anatomical Reference Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashed%2C+E+A">Essam A. Rashed</a>, 
<a href="/search/cs?searchtype=author&query=al-Shatouri%2C+M">Mohammad al-Shatouri</a>, 
<a href="/search/cs?searchtype=author&query=Laakso%2C+I">Ilkka Laakso</a>, 
<a href="/search/cs?searchtype=author&query=Hirata%2C+A">Akimasa Hirata</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reliable segmentation of anatomical tissues of human head is a major step in
several clinical applications such as brain mapping, surgery planning and
associated computational simulation studies. Segmentation is based on
identifying different anatomical structures through labeling different tissues
through medical imaging modalities. The segmentation of brain structures is
commonly feasible with several remarkable contributions mainly for medical
perspective; however, non-brain tissues are of less interest due to anatomical
complexity and difficulties to be observed using standard medical imaging
protocols. The lack of whole head segmentation methods and unavailability of
large human head segmented datasets limiting the variability studies,
especially in the computational evaluation of electrical brain stimulation
(neuromodulation), human protection from electromagnetic field, and
electroencephalography where non-brain tissues are of great importance.
<br />To fill this gap, this study provides an open-access Segmented Head
Anatomical Reference Models (SHARM) that consists of 196 subjects. These models
are segmented into 15 different tissues; skin, fat, muscle, skull cancellous
bone, skull cortical bone, brain white matter, brain gray matter, cerebellum
white matter, cerebellum gray matter, cerebrospinal fluid, dura, vitreous
humor, lens, mucous tissue and blood vessels. The segmented head models are
generated using open-access IXI MRI dataset through convolutional neural
network structure named ForkNet+. Results indicate a high consistency in
statistical characteristics of different tissue distribution in age scale with
real measurements. SHARM is expected to be a useful benchmark not only for
electromagnetic dosimetry studies but also for different human head
segmentation applications.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06680" title="Abstract">arXiv:2309.06680</a> [<a href="/pdf/2309.06680" title="Download PDF">pdf</a>, <a href="/format/2309.06680" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STUPD: A Synthetic Dataset for Spatial and Temporal Relation Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Palaash Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Azaman%2C+H">Haidi Azaman</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheston Tan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Neurips Dataset track. 24 pages including citations and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Understanding relations between objects is crucial for understanding the
semantics of a visual scene. It is also an essential step in order to bridge
visual and language models. However, current state-of-the-art computer vision
models still lack the ability to perform spatial reasoning well. Existing
datasets mostly cover a relatively small number of spatial relations, all of
which are static relations that do not intrinsically involve motion. In this
paper, we propose the Spatial and Temporal Understanding of Prepositions
Dataset (STUPD) -- a large-scale video dataset for understanding static and
dynamic spatial relationships derived from prepositions of the English
language. The dataset contains 150K visual depictions (videos and images),
consisting of 30 distinct spatial prepositional senses, in the form of object
interaction simulations generated synthetically using Unity3D. In addition to
spatial relations, we also propose 50K visual depictions across 10 temporal
relations, consisting of videos depicting event/time-point interactions. To our
knowledge, no dataset exists that represents temporal relations through visual
settings. In this dataset, we also provide 3D information about object
interactions such as frame-wise coordinates, and descriptions of the objects
used. The goal of this synthetic dataset is to help models perform better in
visual relationship detection in real-world settings. We demonstrate an
increase in the performance of various models over 2 real-world datasets
(ImageNet-VidVRD and Spatial Senses) when pretrained on the STUPD dataset, in
comparison to other pretraining datasets.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06682" title="Abstract">arXiv:2309.06682</a> [<a href="/pdf/2309.06682" title="Download PDF">pdf</a>, <a href="/format/2309.06682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Low-Cost, Recyclable, Easy-to-Build Robot Blimp For Transporting  Supplies in Hard-to-Reach Locations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Karen Li</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shuhang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Negash%2C+M">Matyas Negash</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jiawei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jeffs%2C+E">Edward Jeffs</a>, 
<a href="/search/cs?searchtype=author&query=D%27Antonio%2C+D+S">Diego S. D&#x27;Antonio</a>, 
<a href="/search/cs?searchtype=author&query=Salda%C3%B1a%2C+D">David Salda&#xf1;a</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Global Humanitarian Technology Conference (GHTC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Rural communities in remote areas often encounter significant challenges when
it comes to accessing emergency healthcare services and essential supplies due
to a lack of adequate transportation infrastructure. The situation is further
exacerbated by poorly maintained, damaged, or flooded roads, making it arduous
for rural residents to obtain the necessary aid in critical situations. Limited
budgets and technological constraints pose additional obstacles, hindering the
prompt response of local rescue teams during emergencies. The transportation of
crucial resources, such as medical supplies and food, plays a vital role in
saving lives in these situations. In light of these obstacles, our objective is
to improve accessibility and alleviate the suffering of vulnerable populations
by automating transportation tasks using low-cost robotic systems. We propose a
low-cost, easy-to-build blimp robot (UAVs), that can significantly enhance the
efficiency and effectiveness of local emergency responses.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06683" title="Abstract">arXiv:2309.06683</a> [<a href="/pdf/2309.06683" title="Download PDF">pdf</a>, <a href="/format/2309.06683" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated PAC-Bayesian Learning on Non-IID data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zihao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wenbo Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao-Ping Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Existing research has either adapted the Probably Approximately Correct (PAC)
Bayesian framework for federated learning (FL) or used information-theoretic
PAC-Bayesian bounds while introducing their theorems, but few considering the
non-IID challenges in FL. Our work presents the first non-vacuous federated
PAC-Bayesian bound tailored for non-IID local data. This bound assumes unique
prior knowledge for each client and variable aggregation weights. We also
introduce an objective function and an innovative Gibbs-based algorithm for the
optimization of the derived bound. The results are validated on real-world
datasets.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06684" title="Abstract">arXiv:2309.06684</a> [<a href="/pdf/2309.06684" title="Download PDF">pdf</a>, <a href="/format/2309.06684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Loss Adjusted Prioritized Experience Replay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huiping Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rizhong Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Prioritized Experience Replay (PER) is a technical means of deep
reinforcement learning by selecting experience samples with more knowledge
quantity to improve the training rate of neural network. However, the
non-uniform sampling used in PER inevitably shifts the state-action space
distribution and brings the estimation error of Q-value function. In this
paper, an Attention Loss Adjusted Prioritized (ALAP) Experience Replay
algorithm is proposed, which integrates the improved Self-Attention network
with Double-Sampling mechanism to fit the hyperparameter that can regulate the
importance sampling weights to eliminate the estimation error caused by PER. In
order to verify the effectiveness and generality of the algorithm, the ALAP is
tested with value-function based, policy-gradient based and multi-agent
reinforcement learning algorithms in OPENAI gym, and comparison studies verify
the advantage and efficiency of the proposed training framework.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06687" title="Abstract">arXiv:2309.06687</a> [<a href="/pdf/2309.06687" title="Download PDF">pdf</a>, <a href="/format/2309.06687" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Refined Large Language Model as Automated Reward Function Designer  for Deep Reinforcement Learning in Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiayang Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhehua Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiawei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+Z">Zhan Shu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although Deep Reinforcement Learning (DRL) has achieved notable success in
numerous robotic applications, designing a high-performing reward function
remains a challenging task that often requires substantial manual input.
Recently, Large Language Models (LLMs) have been extensively adopted to address
tasks demanding in-depth common-sense knowledge, such as reasoning and
planning. Recognizing that reward function design is also inherently linked to
such knowledge, LLM offers a promising potential in this context. Motivated by
this, we propose in this work a novel LLM framework with a self-refinement
mechanism for automated reward function design. The framework commences with
the LLM formulating an initial reward function based on natural language
inputs. Then, the performance of the reward function is assessed, and the
results are presented back to the LLM for guiding its self-refinement process.
We examine the performance of our proposed framework through a variety of
continuous robotic control tasks across three diverse robotic systems. The
results indicate that our LLM-designed reward functions are able to rival or
even surpass manually designed reward functions, highlighting the efficacy and
applicability of our approach.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06688" title="Abstract">arXiv:2309.06688</a> [<a href="/pdf/2309.06688" title="Download PDF">pdf</a>, <a href="/format/2309.06688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cleaning Up the Streets: Understanding Motivations, Mental Models, and  Concerns of Users Flagging Social Media Posts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A+Q">Alice Qian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Montague%2C+K">Kaitlin Montague</a>, 
<a href="/search/cs?searchtype=author&query=Jhaver%2C+S">Shagun Jhaver</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review at ACM CSCW
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Social media platforms offer flagging, a technical feature that empowers
users to report inappropriate posts or bad actors, to reduce online harms.
While flags are often presented as flimsy icons, their simple interface
disguises complex underlying interactions among users, algorithms, and
moderators. Through semi-structured interviews with 22 active social media
users who had recently flagged, we examine their understanding of flagging
procedures, explore the factors that motivate and demotivate them from engaging
in flagging, and surface their emotional, cognitive, and privacy concerns. Our
findings show that a belief in generalized reciprocity motivates flag
submissions, but deficiencies in procedural transparency create gaps in users'
mental models of how platforms process flags. We highlight how flags raise
questions about the distribution of labor and responsibility between platforms
and users for addressing online harm. We recommend innovations in the flagging
design space that assist user comprehension and facilitate granular status
checks while aligning with their privacy and security expectations.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06690" title="Abstract">arXiv:2309.06690</a> [<a href="/pdf/2309.06690" title="Download PDF">pdf</a>, <a href="/format/2309.06690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Scheduling for Industrial Time-Sensitive Networking: A  Hyper-flow Graph Based Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanzhou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cailian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Q">Qimin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shouliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+X">Xinping Guan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Industrial Time-Sensitive Networking (TSN) provides deterministic mechanisms
for real-time and reliable flow transmission. Increasing attention has been
paid to efficient scheduling for time-sensitive flows with stringent
requirements such as ultra-low latency and jitter. In TSN, the fine-grained
traffic shaping protocol, cyclic queuing and forwarding (CQF), eliminates
uncertain delay and frame loss by cyclic traffic forwarding and queuing.
However, it inevitably causes high scheduling complexity. Moreover, complexity
is quite sensitive to flow attributes and network scale. The problem stems in
part from the lack of an attribute mining mechanism in existing frame-based
scheduling. For time-critical industrial networks with large-scale complex
flows, a so-called hyper-flow graph based scheduling scheme is proposed to
improve the scheduling scalability in terms of schedulability, scheduling
efficiency and latency &amp; jitter. The hyper-flow graph is built by aggregating
similar flow sets as hyper-flow nodes and designing a hierarchical scheduling
framework. The flow attribute-sensitive scheduling information is embedded into
the condensed maximal cliques, and reverse maps them precisely to congestion
flow portions for re-scheduling. Its parallel scheduling reduces network scale
induced complexity. Further, this scheme is designed in its entirety as a
comprehensive scheduling algorithm GH^2. It improves the three criteria of
scalability along a Pareto front. Extensive simulation studies demonstrate its
superiority. Notably, GH^2 is verified its scheduling stability with a runtime
of less than 100 ms for 1000 flows and near 1/430 of the SOTA FITS method for
2000 flows.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06692" title="Abstract">arXiv:2309.06692</a> [<a href="/pdf/2309.06692" title="Download PDF">pdf</a>, <a href="/format/2309.06692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Non-IID Issue in Heterogeneous Federated Learning by  Gradient Harmonization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Ying Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Federated learning (FL) is a privacy-preserving paradigm for collaboratively
training a global model from decentralized clients. However, the performance of
FL is hindered by non-independent and identically distributed (non-IID) data
and device heterogeneity. In this work, we revisit this key challenge through
the lens of gradient conflicts on the server side. Specifically, we first
investigate the gradient conflict phenomenon among multiple clients and reveal
that stronger heterogeneity leads to more severe gradient conflicts. To tackle
this issue, we propose FedGH, a simple yet effective method that mitigates
local drifts through Gradient Harmonization. This technique projects one
gradient vector onto the orthogonal plane of the other within conflicting
client pairs. Extensive experiments demonstrate that FedGH consistently
enhances multiple state-of-the-art FL baselines across diverse benchmarks and
non-IID scenarios. Notably, FedGH yields more significant improvements in
scenarios with stronger heterogeneity. As a plug-and-play module, FedGH can be
seamlessly integrated into any FL framework without requiring hyperparameter
tuning.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06696" title="Abstract">arXiv:2309.06696</a> [<a href="/pdf/2309.06696" title="Download PDF">pdf</a>, <a href="/ps/2309.06696" title="Download PostScript">ps</a>, <a href="/format/2309.06696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fault-Tolerant Spanners against Bounded-Degree Edge Failures: Linearly  More Faults, Almost For Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Haeupler%2C+B">Bernhard Haeupler</a>, 
<a href="/search/cs?searchtype=author&query=Parter%2C+M">Merav Parter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study a new and stronger notion of fault-tolerant graph structures whose
size bounds depend on the degree of the failing edge set, rather than the total
number of faults. For a subset of faulty edges $F \subseteq G$, the
faulty-degree $\deg(F)$ is the largest number of faults in $F$ incident to any
given vertex. We design new fault-tolerant structures with size comparable to
previous constructions, but which tolerate every fault set of small
faulty-degree $\deg(F)$, rather than only fault sets of small size $|F|$. Our
main results are:
<br />- New FT-Certificates: For every $n$-vertex graph $G$ and degree threshold
$f$, one can compute a connectivity certificate $H \subseteq G$ with $|E(H)| =
\widetilde{O}(fn)$ edges that has the following guarantee: for any edge set $F$
with faulty-degree $\deg(F)\leq f$ and every vertex pair $u,v$, it holds that
$u$ and $v$ are connected in $H \setminus F$ iff they are connected in $G
\setminus F$. This bound on $|E(H)|$ is nearly tight. Since our certificates
handle some fault sets of size up to $|F|=O(fn)$, prior work did not imply any
nontrivial upper bound for this problem, even when $f=1$.
<br />- New FT-Spanners: We show that every $n$-vertex graph $G$ admits a
$(2k-1)$-spanner $H$ with $|E(H)| = O_k(f^{1-1/k} n^{1+1/k})$ edges, which
tolerates any fault set $F$ of faulty-degree at most $f$. This bound on
$|E(H)|$ optimal up to its hidden dependence on $k$, and it is close to the
bound of $O_k(|F|^{1/2} n^{1+1/k} + |F|n)$ that is known for the case where the
total number of faults is $|F|$ [Bodwin, Dinitz, Robelle SODA '22]. Our proof
of this theorem is non-constructive, but by following a proof strategy of
Dinitz and Robelle [PODC '20], we show that the runtime can be made polynomial
by paying an additional $\text{polylog } n$ factor in spanner size.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06697" title="Abstract">arXiv:2309.06697</a> [<a href="/pdf/2309.06697" title="Download PDF">pdf</a>, <a href="/format/2309.06697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing Voice Interfaces to Support Mindfulness-Based Pain Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mendu%2C+S">Sanjana Mendu</a>, 
<a href="/search/cs?searchtype=author&query=Fosco%2C+S+L+D">Sebrina L. Doyle Fosco</a>, 
<a href="/search/cs?searchtype=author&query=Lanza%2C+S+T">Stephanie T. Lanza</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+S">Saeed Abdullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 1 figure, 1 table, under review at SAGE Digital Health
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Objective: Chronic pain is a critical public health issue affecting
approximately 20% of the adult population in the United States. Given the
opioid crisis, there has been an urgent focus on non-addictive pain management
methods including Mindfulness-Based Stress Reduction (MBSR). Prior work has
successfully used MBSR for pain management. However, ensuring longitudinal
engagement to MBSR practices remains a serious challenge. In this work, we
explore the utility of a voice interface to support MBSR home practice.
<br />Methods: We interviewed ten mindfulness program facilitators to understand
how such a technology might fit in the context of the MBSR class and identify
potential usability issues with our prototype. We then used directed content
analysis to identify key themes and sub-themes within the interview data.
<br />Results: Our findings show that facilitators supported the use of the voice
interface for MBSR, particularly for individuals with limited motor function.
Facilitators also highlighted unique affordances of voice interfaces, including
perceived social presence, to support sustained engagement.
<br />Conclusion: We demonstrate the acceptability of a voice interface to support
home practice for MBSR participants among trained mindfulness facilitators.
Based on our findings, we outline design recommendations for technologies
aiming to provide longitudinal support for mindfulness-based interventions.
Future work should further these efforts towards making non-addictive pain
management interventions accessible and efficacious for a wide audience of
users.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06698" title="Abstract">arXiv:2309.06698</a> [<a href="/pdf/2309.06698" title="Download PDF">pdf</a>, <a href="/format/2309.06698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Procedural Language Understanding for Low-Resource  Languages: A Case Study on Turkish
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Uzuno%C4%9Flu%2C+A">Arda Uzuno&#x11f;lu</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eahin%2C+G+G">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Understanding procedural natural language (e.g., step-by-step instructions)
is a crucial step to execution and planning. However, while there are ample
corpora and downstream tasks available in English, the field lacks such
resources for most languages. To address this gap, we conduct a case study on
Turkish procedural texts. We first expand the number of tutorials in Turkish
wikiHow from 2,000 to 52,000 using automated translation tools, where the
translation quality and loyalty to the original meaning are validated by a team
of experts on a random set. Then, we generate several downstream tasks on the
corpus, such as linking actions, goal inference, and summarization. To tackle
these tasks, we implement strong baseline models via fine-tuning large
language-specific models such as TR-BART and BERTurk, as well as multilingual
models such as mBART, mT5, and XLM. We find that language-specific models
consistently outperform their multilingual models by a significant margin
across most procedural language understanding (PLU) tasks. We release our
corpus, downstream tasks and the baseline models with https://github.com/
GGLAB-KU/turkish-plu.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06701" title="Abstract">arXiv:2309.06701</a> [<a href="/pdf/2309.06701" title="Download PDF">pdf</a>, <a href="/ps/2309.06701" title="Download PostScript">ps</a>, <a href="/format/2309.06701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transparent Object Tracking with Enhanced Fusion Module
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garigapati%2C+K">Kalyan Garigapati</a>, 
<a href="/search/cs?searchtype=author&query=Blasch%2C+E">Erik Blasch</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jie Wei</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Accurate tracking of transparent objects, such as glasses, plays a critical
role in many robotic tasks such as robot-assisted living. Due to the adaptive
and often reflective texture of such objects, traditional tracking algorithms
that rely on general-purpose learned features suffer from reduced performance.
Recent research has proposed to instill transparency awareness into existing
general object trackers by fusing purpose-built features. However, with the
existing fusion techniques, the addition of new features causes a change in the
latent space making it impossible to incorporate transparency awareness on
trackers with fixed latent spaces. For example, many of the current days
transformer-based trackers are fully pre-trained and are sensitive to any
latent space perturbations. In this paper, we present a new feature fusion
technique that integrates transparency information into a fixed feature space,
enabling its use in a broader range of trackers. Our proposed fusion module,
composed of a transformer encoder and an MLP module, leverages key query-based
transformations to embed the transparency information into the tracking
pipeline. We also present a new two-step training strategy for our fusion
module to effectively merge transparency features. We propose a new tracker
architecture that uses our fusion techniques to achieve superior results for
transparent object tracking. Our proposed method achieves competitive results
with state-of-the-art trackers on TOTB, which is the largest transparent object
tracking benchmark recently released. Our results and the implementation of
code will be made publicly available at https://github.com/kalyan0510/TOTEM.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06702" title="Abstract">arXiv:2309.06702</a> [<a href="/pdf/2309.06702" title="Download PDF">pdf</a>, <a href="/ps/2309.06702" title="Download PostScript">ps</a>, <a href="/format/2309.06702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Encryption in the Bounded Storage Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barhoush%2C+M">Mohammed Barhoush</a>, 
<a href="/search/cs?searchtype=author&query=Salvail%2C+L">Louis Salvail</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Functional encryption is a powerful paradigm for public-key encryption which
allows for controlled access to encrypted data. This primitive is generally
impossible in the standard setting so we investigate possibilities in the
bounded quantum storage model (BQSM) and the bounded classical storage model
(BCSM). In these models, ciphertexts potentially disappear which nullifies
impossibility results and allows us to obtain positive outcomes.
<br />Firstly, in the BQSM, we construct information-theoretically secure
functional encryption with $\texttt{q}=O(\sqrt{\texttt{s}/\texttt{r}})$ where
$\texttt{r}$ can be set to any value less than $\texttt{s}$. Here $\texttt{r}$
denotes the number of times that an adversary is restricted to
$\texttt{s}$--qubits of quantum memory in the protocol and $\texttt{q}$ denotes
the required quantum memory to run the protocol honestly. We then show that our
scheme is optimal by proving that it is impossible to attain
information-theoretically secure functional encryption with $\texttt{q} &lt;
\sqrt{\texttt{s}/\texttt{r}}$. However, by assuming the existence of
post-quantum one-way functions, we can do far better and achieve functional
encryption with classical keys and with $\texttt{q}=0$ and $\texttt{r}=1$.
<br />Secondly, in the BCSM, we construct $(O(\texttt{n}),\texttt{n}^2)$ functional
encryption assuming the existence of $(\texttt{n},\texttt{n}^2)$ virtual weak
grey-box obfuscation. Here, the pair $(\texttt{n},\texttt{n}^2)$ indicates the
required memory to run honestly and the needed memory to break security,
respectively. This memory gap is optimal and the assumption is minimal. In
particular, we also construct $(O(\texttt{n}),\texttt{n}^2)$ virtual weak
grey-box obfuscation assuming $(\texttt{n},\texttt{n}^2)$ functional
encryption.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06703" title="Abstract">arXiv:2309.06703</a> [<a href="/pdf/2309.06703" title="Download PDF">pdf</a>, <a href="/format/2309.06703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VLSlice: Interactive Vision-and-Language Slice Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Slyman%2C+E">Eric Slyman</a>, 
<a href="/search/cs?searchtype=author&query=Kahng%2C+M">Minsuk Kahng</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Stefan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper at ICCV 2023. 17 pages, 11 figures. <a href="https://ericslyman.com/vlslice/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent work in vision-and-language demonstrates that large-scale pretraining
can learn generalizable models that are efficiently transferable to downstream
tasks. While this may improve dataset-scale aggregate metrics, analyzing
performance around hand-crafted subgroups targeting specific bias dimensions
reveals systemic undesirable behaviors. However, this subgroup analysis is
frequently stalled by annotation efforts, which require extensive time and
resources to collect the necessary data. Prior art attempts to automatically
discover subgroups to circumvent these constraints but typically leverages
model behavior on existing task-specific annotations and rapidly degrades on
more complex inputs beyond "tabular" data, none of which study
vision-and-language models. This paper presents VLSlice, an interactive system
enabling user-guided discovery of coherent representation-level subgroups with
consistent visiolinguistic behavior, denoted as vision-and-language slices,
from unlabeled image sets. We show that VLSlice enables users to quickly
generate diverse high-coherency slices in a user study (n=22) and release the
tool publicly.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06705" title="Abstract">arXiv:2309.06705</a> [<a href="/pdf/2309.06705" title="Download PDF">pdf</a>, <a href="/format/2309.06705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Learning Dynamics for Coalitional Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+A">Aya Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Shamma%2C+J+S">Jeff S. Shamma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures; accepted for CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">In the framework of transferable utility coalitional games, a scoring
(characteristic) function determines the value of any subset/coalition of
agents. Agents decide on both which coalitions to form and the allocations of
the values of the formed coalitions among their members. An important concept
in coalitional games is that of a core solution, which is a partitioning of
agents into coalitions and an associated allocation to each agent under which
no group of agents can get a higher allocation by forming an alternative
coalition. We present distributed learning dynamics for coalitional games that
converge to a core solution whenever one exists. In these dynamics, an agent
maintains a state consisting of (i) an aspiration level for its allocation and
(ii) the coalition, if any, to which it belongs. In each stage, a randomly
activated agent proposes to form a new coalition and changes its aspiration
based on the success or failure of its proposal. The coalition membership
structure is changed, accordingly, whenever the proposal succeeds. Required
communications are that: (i) agents in the proposed new coalition need to
reveal their current aspirations to the proposing agent, and (ii) agents are
informed if they are joining the proposed coalition or if their existing
coalition is broken. The proposing agent computes the feasibility of forming
the coalition. We show that the dynamics hit an absorbing state whenever a core
solution is reached. We further illustrate the distributed learning dynamics on
a multi-agent task allocation setting.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06706" title="Abstract">arXiv:2309.06706</a> [<a href="/pdf/2309.06706" title="Download PDF">pdf</a>, <a href="/format/2309.06706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simultaneous Machine Translation with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Minghan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinming Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Thuy-Trang Vu</a>, 
<a href="/search/cs?searchtype=author&query=Shiri%2C+F">Fatemeh Shiri</a>, 
<a href="/search/cs?searchtype=author&query=Shareghi%2C+E">Ehsan Shareghi</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLM) have demonstrated their abilities to solve
various natural language processing tasks through dialogue-based interactions.
For instance, research indicates that LLMs can achieve competitive performance
in offline machine translation tasks for high-resource languages. However,
applying LLMs to simultaneous machine translation (SimulMT) poses many
challenges, including issues related to the training-inference mismatch arising
from different decoding patterns. In this paper, we explore the feasibility of
utilizing LLMs for SimulMT. Building upon conventional approaches, we introduce
a simple yet effective mixture policy that enables LLMs to engage in SimulMT
without requiring additional training. Furthermore, after Supervised
Fine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits
significant performance improvements. Our experiments, conducted with
Llama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that
LLM can achieve translation quality and latency comparable to dedicated SimulMT
models.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06708" title="Abstract">arXiv:2309.06708</a> [<a href="/pdf/2309.06708" title="Download PDF">pdf</a>, <a href="/format/2309.06708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Fatigue Crack Growth via Path Slicing and Re-Weighting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yingjie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhiping Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predicting potential risks associated with the fatigue of key structural
components is crucial in engineering design. However, fatigue often involves
entangled complexities of material microstructures and service conditions,
making diagnosis and prognosis of fatigue damage challenging. We report a
statistical learning framework to predict the growth of fatigue cracks and the
life-to-failure of the components under loading conditions with uncertainties.
Digital libraries of fatigue crack patterns and the remaining life are
constructed by high-fidelity physical simulations. Dimensionality reduction and
neural network architectures are then used to learn the history dependence and
nonlinearity of fatigue crack growth. Path-slicing and re-weighting techniques
are introduced to handle the statistical noises and rare events. The predicted
fatigue crack patterns are self-updated and self-corrected by the evolving
crack patterns. The end-to-end approach is validated by representative examples
with fatigue cracks in plates, which showcase the digital-twin scenario in
real-time structural health monitoring and fatigue life prediction for
maintenance management decision-making.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06714" title="Abstract">arXiv:2309.06714</a> [<a href="/pdf/2309.06714" title="Download PDF">pdf</a>, <a href="/format/2309.06714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPI-Flow: Learning Realistic Optical Flow with Multiplane Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yingping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Debing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Ying Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The accuracy of learning-based optical flow estimation models heavily relies
on the realism of the training datasets. Current approaches for generating such
datasets either employ synthetic data or generate images with limited realism.
However, the domain gap of these data with real-world scenes constrains the
generalization of the trained model to real-world applications. To address this
issue, we investigate generating realistic optical flow datasets from
real-world images. Firstly, to generate highly realistic new images, we
construct a layered depth representation, known as multiplane images (MPI),
from single-view images. This allows us to generate novel view images that are
highly realistic. To generate optical flow maps that correspond accurately to
the new image, we calculate the optical flows of each plane using the camera
matrix and plane depths. We then project these layered optical flows into the
output optical flow map with volume rendering. Secondly, to ensure the realism
of motion, we present an independent object motion module that can separate the
camera and dynamic object motion in MPI. This module addresses the deficiency
in MPI-based single-view methods, where optical flow is generated only by
camera motion and does not account for any object movement. We additionally
devise a depth-aware inpainting module to merge new images with dynamic objects
and address unnatural motion occlusions. We show the superior performance of
our method through extensive experiments on real-world datasets. Moreover, our
approach achieves state-of-the-art performance in both unsupervised and
supervised training of learning-based models. The code will be made publicly
available at: \url{https://github.com/Sharpiless/MPI-Flow}.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06715" title="Abstract">arXiv:2309.06715</a> [<a href="/pdf/2309.06715" title="Download PDF">pdf</a>, <a href="/ps/2309.06715" title="Download PostScript">ps</a>, <a href="/format/2309.06715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On correlation distribution of Niho-type decimation $d=3(p^m-1)+1$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+M">Maosheng Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Haode Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The cross-correlation problem is a classic problem in sequence design. In
this paper we compute the cross-correlation distribution of the Niho-type
decimation $d=3(p^m-1)+1$ over $\mathrm{GF}(p^{2m})$ for any prime $p \ge 5$.
Previously this problem was solved by Xia et al. only for $p=2$ and $p=3$ in a
series of papers. The main difficulty of this problem for $p \ge 5$, as pointed
out by Xia et al., is to count the number of codewords of "pure weight" 5 in
$p$-ary Zetterberg codes. It turns out this counting problem can be transformed
by the MacWilliams identity into counting codewords of weight at most 5 in
$p$-ary Melas codes, the most difficult of which is related to a K3 surface
well studied in the literature and can be computed. When $p \ge 7$, the theory
of elliptic curves over finite fields also plays an important role in the
resolution of this problem.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06717" title="Abstract">arXiv:2309.06717</a> [<a href="/pdf/2309.06717" title="Download PDF">pdf</a>, <a href="/format/2309.06717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bias Amplification Enhances Minority Group Performance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gaotang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiarui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+W">Wei Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Neural networks produced by standard training are known to suffer from poor
accuracy on rare subgroups despite achieving high accuracy on average, due to
the correlations between certain spurious features and labels. Previous
approaches based on worst-group loss minimization (e.g. Group-DRO) are
effective in improving worse-group accuracy but require expensive group
annotations for all the training samples. In this paper, we focus on the more
challenging and realistic setting where group annotations are only available on
a small validation set or are not available at all. We propose BAM, a novel
two-stage training algorithm: in the first stage, the model is trained using a
bias amplification scheme via introducing a learnable auxiliary variable for
each training sample; in the second stage, we upweight the samples that the
bias-amplified model misclassifies, and then continue training the same model
on the reweighted dataset. Empirically, BAM achieves competitive performance
compared with existing methods evaluated on spurious correlation benchmarks in
computer vision and natural language processing. Moreover, we find a simple
stopping criterion based on minimum class accuracy difference that can remove
the need for group annotations, with little or no loss in worst-group accuracy.
We perform extensive analyses and ablations to verify the effectiveness and
robustness of our algorithm in varying class and group imbalance ratios.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06718" title="Abstract">arXiv:2309.06718</a> [<a href="/pdf/2309.06718" title="Download PDF">pdf</a>, <a href="/format/2309.06718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Immersion and Invariance-based Disturbance Observer and Its Application  to Safe Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yujie Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+X">Xiangru Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">When the disturbance input matrix is nonlinear, existing disturbance observer
design methods rely on the solvability of a partial differential equation or
the existence of an output function with a uniformly well-defined disturbance
relative degree, which can pose significant limitations. This note introduces a
systematic approach for designing an Immersion and Invariance-based Disturbance
Observer (IIDOB) that circumvents these strong assumptions. The proposed IIDOB
ensures the disturbance estimation error is globally uniformly ultimately
bounded by approximately solving a partial differential equation while
compensating for the approximation error. Furthermore, by integrating IIDOB
into the framework of control barrier functions, a filter-based safe control
design method for control-affine systems with disturbances is established where
the filter is used to generate an alternative disturbance estimation signal
with a known derivative. Sufficient conditions are established to guarantee the
safety of the disturbed systems. Simulation results demonstrate the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06719" title="Abstract">arXiv:2309.06719</a> [<a href="/pdf/2309.06719" title="Download PDF">pdf</a>, <a href="/format/2309.06719" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TrafficGPT: Viewing, Processing and Interacting with Traffic Foundation  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Siyao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Daocheng Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bin Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+P">Pinlong Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the promotion of chatgpt to the public, Large language models indeed
showcase remarkable common sense, reasoning, and planning skills, frequently
providing insightful guidance. These capabilities hold significant promise for
their application in urban traffic management and control. However, LLMs
struggle with addressing traffic issues, especially processing numerical data
and interacting with simulations, limiting their potential in solving
traffic-related challenges. In parallel, specialized traffic foundation models
exist but are typically designed for specific tasks with limited input-output
interactions. Combining these models with LLMs presents an opportunity to
enhance their capacity for tackling complex traffic-related problems and
providing insightful suggestions. To bridge this gap, we present TrafficGPT, a
fusion of ChatGPT and traffic foundation models. This integration yields the
following key enhancements: 1) empowering ChatGPT with the capacity to view,
analyze, process traffic data, and provide insightful decision support for
urban transportation system management; 2) facilitating the intelligent
deconstruction of broad and complex tasks and sequential utilization of traffic
foundation models for their gradual completion; 3) aiding human decision-making
in traffic control through natural language dialogues; and 4) enabling
interactive feedback and solicitation of revised outcomes. By seamlessly
intertwining large language model and traffic expertise, TrafficGPT not only
advances traffic management but also offers a novel approach to leveraging AI
capabilities in this domain. The TrafficGPT demo can be found in
https://github.com/lijlansg/TrafficGPT.git.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06720" title="Abstract">arXiv:2309.06720</a> [<a href="/pdf/2309.06720" title="Download PDF">pdf</a>, <a href="/format/2309.06720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Attentive Time Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matsuo%2C+S">Shinnosuke Matsuo</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaomeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Atarsaikhan%2C+G">Gantugs Atarsaikhan</a>, 
<a href="/search/cs?searchtype=author&query=Kimura%2C+A">Akisato Kimura</a>, 
<a href="/search/cs?searchtype=author&query=Kashino%2C+K">Kunio Kashino</a>, 
<a href="/search/cs?searchtype=author&query=Iwana%2C+B+K">Brian Kenji Iwana</a>, 
<a href="/search/cs?searchtype=author&query=Uchida%2C+S">Seiichi Uchida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Pattern Recognition
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Similarity measures for time series are important problems for time series
classification. To handle the nonlinear time distortions, Dynamic Time Warping
(DTW) has been widely used. However, DTW is not learnable and suffers from a
trade-off between robustness against time distortion and discriminative power.
In this paper, we propose a neural network model for task-adaptive time
warping. Specifically, we use the attention model, called the bipartite
attention model, to develop an explicit time warping mechanism with greater
distortion invariance. Unlike other learnable models using DTW for warping, our
model predicts all local correspondences between two time series and is trained
based on metric learning, which enables it to learn the optimal data-dependent
warping for the target task. We also propose to induce pre-training of our
model by DTW to improve the discriminative power. Extensive experiments
demonstrate the superior effectiveness of our model over DTW and its
state-of-the-art performance in online signature verification.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06721" title="Abstract">arXiv:2309.06721</a> [<a href="/pdf/2309.06721" title="Download PDF">pdf</a>, <a href="/format/2309.06721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Spectrum Mixer for Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiqiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, MLP-based vision backbones have achieved promising performance in
several visual recognition tasks. However, the existing MLP-based methods
directly aggregate tokens with static weights, leaving the adaptability to
different images untouched. Moreover, Recent research demonstrates that
MLP-Transformer is great at creating long-range dependencies but ineffective at
catching high frequencies that primarily transmit local information, which
prevents it from applying to the downstream dense prediction tasks, such as
semantic segmentation. To address these challenges, we propose a
content-adaptive yet computationally efficient structure, dubbed Dynamic
Spectrum Mixer (DSM). The DSM represents token interactions in the frequency
domain by employing the Discrete Cosine Transform, which can learn long-term
spatial dependencies with log-linear complexity. Furthermore, a dynamic
spectrum weight generation layer is proposed as the spectrum bands selector,
which could emphasize the informative frequency bands while diminishing others.
To this end, the technique can efficiently learn detailed features from visual
input that contains both high- and low-frequency information. Extensive
experiments show that DSM is a powerful and adaptable backbone for a range of
visual recognition tasks. Particularly, DSM outperforms previous
transformer-based and MLP-based models, on image classification, object
detection, and semantic segmentation tasks, such as 83.8 \% top-1 accuracy on
ImageNet, and 49.9 \% mIoU on ADE20K.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06723" title="Abstract">arXiv:2309.06723</a> [<a href="/pdf/2309.06723" title="Download PDF">pdf</a>, <a href="/format/2309.06723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PIAVE: A Pose-Invariant Audio-Visual Speaker Extraction Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qinghua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+M">Meng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhizheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Interspeech 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proc. INTERSPEECH 2023, 3719-3723
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">It is common in everyday spoken communication that we look at the turning
head of a talker to listen to his/her voice. Humans see the talker to listen
better, so do machines. However, previous studies on audio-visual speaker
extraction have not effectively handled the varying talking face. This paper
studies how to take full advantage of the varying talking face. We propose a
Pose-Invariant Audio-Visual Speaker Extraction Network (PIAVE) that
incorporates an additional pose-invariant view to improve audio-visual speaker
extraction. Specifically, we generate the pose-invariant view from each
original pose orientation, which enables the model to receive a consistent
frontal view of the talker regardless of his/her head pose, therefore, forming
a multi-view visual input for the speaker. Experiments on the multi-view MEAD
and in-the-wild LRS3 dataset demonstrate that PIAVE outperforms the
state-of-the-art and is more robust to pose variations.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06724" title="Abstract">arXiv:2309.06724</a> [<a href="/pdf/2309.06724" title="Download PDF">pdf</a>, <a href="/format/2309.06724" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Nonparametric Convexified Filtering for Computational Photography,  Image Synthesis and Adversarial Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wangni%2C+J">Jianqiao Wangni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">We aim to provide a general framework of for computational photography that
recovers the real scene from imperfect images, via the Deep Nonparametric
Convexified Filtering (DNCF). It is consists of a nonparametric deep network to
resemble the physical equations behind the image formation, such as denoising,
super-resolution, inpainting, and flash. DNCF has no parameterization dependent
on training data, therefore has a strong generalization and robustness to
adversarial image manipulation. During inference, we also encourage the network
parameters to be nonnegative and create a bi-convex function on the input and
parameters, and this adapts to second-order optimization algorithms with
insufficient running time, having 10X acceleration over Deep Image Prior. With
these tools, we empirically verify its capability to defend image
classification deep networks against adversary attack algorithms in real-time.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06725" title="Abstract">arXiv:2309.06725</a> [<a href="/pdf/2309.06725" title="Download PDF">pdf</a>, <a href="/format/2309.06725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solar-powered shape-changing origami microfliers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Johnson%2C+K">Kyle Johnson</a>, 
<a href="/search/cs?searchtype=author&query=Arroyos%2C+V">Vicente Arroyos</a>, 
<a href="/search/cs?searchtype=author&query=Ferran%2C+A">Am&#xe9;lie Ferran</a>, 
<a href="/search/cs?searchtype=author&query=Elberier%2C+T">Tilboon Elberier</a>, 
<a href="/search/cs?searchtype=author&query=Villanueva%2C+R">Raul Villanueva</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+D">Dennis Yin</a>, 
<a href="/search/cs?searchtype=author&query=Aliseda%2C+A">Alberto Aliseda</a>, 
<a href="/search/cs?searchtype=author&query=Fuller%2C+S">Sawyer Fuller</a>, 
<a href="/search/cs?searchtype=author&query=Iyer%2C+V">Vikram Iyer</a>, 
<a href="/search/cs?searchtype=author&query=Gollakota%2C+S">Shyamnath Gollakota</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the author's version of the work. It is posted here by permission of the AAAS for personal use, not for redistribution. The definitive version was published in Science Robotics on September 13, 2023. DOI: 10.1126/scirobotics.adg4276
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Using wind to disperse microfliers that fall like seeds and leaves can help
automate large-scale sensor deployments. Here, we present battery-free
microfliers that can change shape in mid-air to vary their dispersal distance.
We design origami microfliers using bi-stable leaf-out structures and uncover
an important property: a simple change in the shape of these origami structures
causes two dramatically different falling behaviors. When unfolded and flat,
the microfliers exhibit a tumbling behavior that increases lateral displacement
in the wind. When folded inward, their orientation is stabilized, resulting in
a downward descent that is less influenced by wind. To electronically
transition between these two shapes, we designed a low-power electromagnetic
actuator that produces peak forces of up to 200 millinewtons within 25
milliseconds while powered by solar cells. We fabricated a circuit directly on
the folded origami structure that includes a programmable microcontroller,
Bluetooth radio, solar power harvesting circuit, a pressure sensor to estimate
altitude and a temperature sensor. Outdoor evaluations show that our 414
milligram origami microfliers are able to electronically change their shape
mid-air, travel up to 98 meters in a light breeze, and wirelessly transmit data
via Bluetooth up to 60 meters away, using only power collected from the sun.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06726" title="Abstract">arXiv:2309.06726</a> [<a href="/pdf/2309.06726" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Keyphrase Generation by BART Finetuning with Splitting and  Shuffling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Iwaihara%2C+M">Mizuho Iwaihara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Keyphrase generation is a task of identifying a set of phrases that best
repre-sent the main topics or themes of a given text. Keyphrases are dividend
int pre-sent and absent keyphrases. Recent approaches utilizing
sequence-to-sequence models show effectiveness on absent keyphrase generation.
However, the per-formance is still limited due to the hardness of finding
absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which
exploits the differ-ences between present and absent keyphrase generations, and
performs fine-tuning of two separate BART models for present and absent
keyphrases. We further show effective approaches of shuffling keyphrases and
candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART
achieved new state-of-the-art score on F1@5 in two out of five keyphrase
gen-eration benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06728" title="Abstract">arXiv:2309.06728</a> [<a href="/pdf/2309.06728" title="Download PDF">pdf</a>, <a href="/format/2309.06728" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Foundation models for Unsupervised Audio-Visual Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhosale%2C+S">Swapnil Bhosale</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haosen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kanojia%2C+D">Diptesh Kanojia</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiatian Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio-Visual Segmentation (AVS) aims to precisely outline audible objects in
a visual scene at the pixel level. Existing AVS methods require fine-grained
annotations of audio-mask pairs in supervised learning fashion. This limits
their scalability since it is time consuming and tedious to acquire such
cross-modality pixel level labels. To overcome this obstacle, in this work we
introduce unsupervised audio-visual segmentation with no need for task-specific
data annotations and model training. For tackling this newly proposed problem,
we formulate a novel Cross-Modality Semantic Filtering (CMSF) approach to
accurately associate the underlying audio-mask pairs by leveraging the
off-the-shelf multi-modal foundation models (e.g., detection [1], open-world
segmentation [2] and multi-modal alignment [3]). Guiding the proposal
generation by either audio or visual cues, we design two training-free
variants: AT-GDINO-SAM and OWOD-BIND. Extensive experiments on the AVS-Bench
dataset show that our unsupervised approach can perform well in comparison to
prior art supervised counterparts across complex scenarios with multiple
auditory objects. Particularly, in situations where existing supervised AVS
methods struggle with overlapping foreground objects, our models still excel in
accurately segmenting overlapped auditory objects. Our code will be publicly
released.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06735" title="Abstract">arXiv:2309.06735</a> [<a href="/pdf/2309.06735" title="Download PDF">pdf</a>, <a href="/format/2309.06735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GelFlow: Self-supervised Learning of Optical Flow for Vision-Based  Tactile Sensor Displacement Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhiyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhouping Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-resolution multi-modality information acquired by vision-based tactile
sensors can support more dexterous manipulations for robot fingers. Optical
flow is low-level information directly obtained by vision-based tactile
sensors, which can be transformed into other modalities like force, geometry
and depth. Current vision-tactile sensors employ optical flow methods from
OpenCV to estimate the deformation of markers in gels. However, these methods
need to be more precise for accurately measuring the displacement of markers
during large elastic deformation of the gel, as this can significantly impact
the accuracy of downstream tasks. This study proposes a self-supervised optical
flow method based on deep learning to achieve high accuracy in displacement
measurement for vision-based tactile sensors. The proposed method employs a
coarse-to-fine strategy to handle large deformations by constructing a
multi-scale feature pyramid from the input image. To better deal with the
elastic deformation caused by the gel, the Helmholtz velocity decomposition
constraint combined with the elastic deformation constraint are adopted to
address the distortion rate and area change rate, respectively. A local flow
fusion module is designed to smooth the optical flow, taking into account the
prior knowledge of the blurred effect of gel deformation. We trained the
proposed self-supervised network using an open-source dataset and compared it
with traditional and deep learning-based optical flow methods. The results show
that the proposed method achieved the highest displacement measurement
accuracy, thereby demonstrating its potential for enabling more precise
measurement of downstream tasks using vision-based tactile sensors.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06739" title="Abstract">arXiv:2309.06739</a> [<a href="/pdf/2309.06739" title="Download PDF">pdf</a>, <a href="/format/2309.06739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MCNS: Mining Causal Natural Structures Inside Time Series via A Novel  Internal Causality Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanhao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+D">Dehui Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zihan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+A">Anyan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiyang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Causal inference permits us to discover covert relationships of various
variables in time series. However, in most existing works, the variables
mentioned above are the dimensions. The causality between dimensions could be
cursory, which hinders the comprehension of the internal relationship and the
benefit of the causal graph to the neural networks (NNs). In this paper, we
find that causality exists not only outside but also inside the time series
because it reflects a succession of events in the real world. It inspires us to
seek the relationship between internal subsequences. However, the challenges
are the hardship of discovering causality from subsequences and utilizing the
causal natural structures to improve NNs. To address these challenges, we
propose a novel framework called Mining Causal Natural Structure (MCNS), which
is automatic and domain-agnostic and helps to find the causal natural
structures inside time series via the internal causality scheme. We evaluate
the MCNS framework and impregnation NN with MCNS on time series classification
tasks. Experimental results illustrate that our impregnation, by refining
attention, shape selection classification, and pruning datasets, drives NN,
even the data itself preferable accuracy and interpretability. Besides, MCNS
provides an in-depth, solid summary of the time series and datasets.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06741" title="Abstract">arXiv:2309.06741</a> [<a href="/pdf/2309.06741" title="Download PDF">pdf</a>, <a href="/format/2309.06741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Multi-task Learning Framework for Drone State Identification and  Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Palamas%2C+A">Antreas Palamas</a>, 
<a href="/search/eess?searchtype=author&query=Souli%2C+N">Nicolas Souli</a>, 
<a href="/search/eess?searchtype=author&query=Panayiotou%2C+T">Tania Panayiotou</a>, 
<a href="/search/eess?searchtype=author&query=Kolios%2C+P">Panayiotis Kolios</a>, 
<a href="/search/eess?searchtype=author&query=Ellinas%2C+G">Georgios Ellinas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The rise of unmanned aerial vehicle (UAV) operations, as well as the
vulnerability of the UAVs' sensors, has led to the need for proper monitoring
systems for detecting any abnormal behavior of the UAV. This work addresses
this problem by proposing an innovative multi-task learning framework (MLF-ST)
for UAV state identification and trajectory prediction, that aims to optimize
the performance of both tasks simultaneously. A deep neural network with shared
layers to extract features from the input data is employed, utilizing drone
sensor measurements and historical trajectory information. Moreover, a novel
loss function is proposed that combines the two objectives, encouraging the
network to jointly learn the features that are most useful for both tasks. The
proposed MLF-ST framework is evaluated on a large dataset of UAV flights,
illustrating that it is able to outperform various state-of-the-art baseline
techniques in terms of both state identification and trajectory prediction. The
evaluation of the proposed framework, using real-world data, demonstrates that
it can enable applications such as UAV-based surveillance and monitoring, while
also improving the safety and efficiency of UAV operations.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06742" title="Abstract">arXiv:2309.06742</a> [<a href="/pdf/2309.06742" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTD: Multi-Timestep Detector for Delayed Streaming Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yihui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Ningjiang Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, accepted by PRCV 2023 (The 6th Chinese Conference on Pattern Recognition and Computer Vision)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Autonomous driving systems require real-time environmental perception to
ensure user safety and experience. Streaming perception is a task of reporting
the current state of the world, which is used to evaluate the delay and
accuracy of autonomous driving systems. In real-world applications, factors
such as hardware limitations and high temperatures inevitably cause delays in
autonomous driving systems, resulting in the offset between the model output
and the world state. In order to solve this problem, this paper propose the
Multi- Timestep Detector (MTD), an end-to-end detector which uses dynamic
routing for multi-branch future prediction, giving model the ability to resist
delay fluctuations. A Delay Analysis Module (DAM) is proposed to optimize the
existing delay sensing method, continuously monitoring the model inference
stack and calculating the delay trend. Moreover, a novel Timestep Branch Module
(TBM) is constructed, which includes static flow and adaptive flow to
adaptively predict specific timesteps according to the delay trend. The
proposed method has been evaluated on the Argoverse-HD dataset, and the
experimental results show that it has achieved state-of-the-art performance
across various delay settings.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06743" title="Abstract">arXiv:2309.06743</a> [<a href="/pdf/2309.06743" title="Download PDF">pdf</a>, <a href="/format/2309.06743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Effects of Japanese Font Designs on Impression Formation  and Decision-Making in Text-Based Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chujo%2C+R">Rintaro Chujo</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+A">Atsunobu Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Hautasaari%2C+A">Ari Hautasaari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Text-based communication, such as text chat, is commonly employed in various
contexts, both professional and personal. However, it lacks the rich emotional
cues present in verbal and visual forms of communication, such as facial
expressions and tone of voice, making it more challenging to convey emotions
and increasing the likelihood of misunderstandings. In this study, we focused
on typefaces as emotional cues employed in text-based communication and
investigated the influence of font design on impression formation and
decision-making through two experiments. The results of the experiments
revealed the relationship between Japanese typeface design and impression
formation, and indicated that advice presented in a font evoking an impression
of high confidence was more likely to be accepted than advice presented in a
font evoking an impression of low confidence.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06745" title="Abstract">arXiv:2309.06745</a> [<a href="/pdf/2309.06745" title="Download PDF">pdf</a>, <a href="/format/2309.06745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEATIC: Video-based Emotion and Affect Tracking in Context Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhihang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+J">Jefferson Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Whitney%2C+D">David Whitney</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
<p class="mathjax">Human affect recognition has been a significant topic in psychophysics and
computer vision. However, the currently published datasets have many
limitations. For example, most datasets contain frames that contain only
information about facial expressions. Due to the limitations of previous
datasets, it is very hard to either understand the mechanisms for affect
recognition of humans or generalize well on common cases for computer vision
models trained on those datasets. In this work, we introduce a brand new large
dataset, the Video-based Emotion and Affect Tracking in Context Dataset
(VEATIC), that can conquer the limitations of the previous datasets. VEATIC has
124 video clips from Hollywood movies, documentaries, and home videos with
continuous valence and arousal ratings of each frame via real-time annotation.
Along with the dataset, we propose a new computer vision task to infer the
affect of the selected character via both context and character information in
each video frame. Additionally, we propose a simple model to benchmark this new
computer vision task. We also compare the performance of the pretrained model
using our dataset with other similar datasets. Experiments show the competing
results of our pretrained model via VEATIC, indicating the generalizability of
VEATIC. Our dataset is available at https://veatic.github.io.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06746" title="Abstract">arXiv:2309.06746</a> [<a href="/pdf/2309.06746" title="Download PDF">pdf</a>, <a href="/format/2309.06746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-Forward: Fine-tuning and Inference on Language Models with  Differential Privacy in Forward Pass
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Minxin Du</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+X">Xiang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chow%2C+S+S+M">Sherman S. M. Chow</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Huan Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ACM CCS '23. This is the full version. The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Differentially private stochastic gradient descent (DP-SGD) adds noise to
gradients in back-propagation, safeguarding training data from privacy leakage,
particularly membership inference. It fails to cover (inference-time) threats
like embedding inversion and sensitive attribute inference. It is also costly
in storage and computation when used to fine-tune large pre-trained language
models (LMs).
<br />We propose DP-Forward, which directly perturbs embedding matrices in the
forward pass of LMs. It satisfies stringent local DP requirements for training
and inference data. To instantiate it using the smallest matrix-valued noise,
we devise an analytic matrix Gaussian~mechanism (aMGM) by drawing possibly
non-i.i.d. noise from a matrix Gaussian distribution. We then investigate
perturbing outputs from different hidden (sub-)layers of LMs with aMGM noises.
Its utility on three typical tasks almost hits the non-private baseline and
outperforms DP-SGD by up to 7.7pp at a moderate privacy level. It saves
3$\times$ time and memory costs compared to DP-SGD with the latest high-speed
library. It also reduces the average success rates of embedding inversion and
sensitive attribute inference by up to 88pp and 41pp, respectively, whereas
DP-SGD fails.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06747" title="Abstract">arXiv:2309.06747</a> [<a href="/pdf/2309.06747" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrating GAN and Texture Synthesis for Enhanced Road Damage Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tengyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiangtao Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, 2 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the domain of traffic safety and road maintenance, precise detection of
road damage is crucial for ensuring safe driving and prolonging road
durability. However, current methods often fall short due to limited data.
Prior attempts have used Generative Adversarial Networks to generate damage
with diverse shapes and manually integrate it into appropriate positions.
However, the problem has not been well explored and is faced with two
challenges. First, they only enrich the location and shape of damage while
neglect the diversity of severity levels, and the realism still needs further
improvement. Second, they require a significant amount of manual effort. To
address these challenges, we propose an innovative approach. In addition to
using GAN to generate damage with various shapes, we further employ texture
synthesis techniques to extract road textures. These two elements are then
mixed with different weights, allowing us to control the severity of the
synthesized damage, which are then embedded back into the original images via
Poisson blending. Our method ensures both richness of damage severity and a
better alignment with the background. To save labor costs, we leverage
structural similarity for automated sample selection during embedding. Each
augmented data of an original image contains versions with varying severity
levels. We implement a straightforward screening strategy to mitigate
distribution drift. Experiments are conducted on a public road damage dataset.
The proposed method not only eliminates the need for manual labor but also
achieves remarkable enhancements, improving the mAP by 4.1% and the F1-score by
4.5%.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06748" title="Abstract">arXiv:2309.06748</a> [<a href="/pdf/2309.06748" title="Download PDF">pdf</a>, <a href="/format/2309.06748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao-Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chen-Yu Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+T">Tsu-Yuan Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen-An Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yun-Nung Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to SIGDIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Conversational search provides a natural interface for information retrieval
(IR). Recent approaches have demonstrated promising results in applying dense
retrieval to conversational IR. However, training dense retrievers requires
large amounts of in-domain paired data. This hinders the development of
conversational dense retrievers, as abundant in-domain conversations are
expensive to collect. In this paper, we propose CONVERSER, a framework for
training conversational dense retrievers with at most 6 examples of in-domain
dialogues. Specifically, we utilize the in-context learning capability of large
language models to generate conversational queries given a passage in the
retrieval corpus. Experimental results on conversational retrieval benchmarks
OR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable
performance to fully-supervised models, demonstrating the effectiveness of our
proposed framework in few-shot conversational dense retrieval. All source code
and generated datasets are available at https://github.com/MiuLab/CONVERSER
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06750" title="Abstract">arXiv:2309.06750</a> [<a href="/pdf/2309.06750" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MFL-YOLO: An Object Detection Model for Damaged Traffic Signs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tengyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jiangtao Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traffic signs are important facilities to ensure traffic safety and smooth
flow, but may be damaged due to many reasons, which poses a great safety
hazard. Therefore, it is important to study a method to detect damaged traffic
signs. Existing object detection techniques for damaged traffic signs are still
absent. Since damaged traffic signs are closer in appearance to normal ones, it
is difficult to capture the detailed local damage features of damaged traffic
signs using traditional object detection methods. In this paper, we propose an
improved object detection method based on YOLOv5s, namely MFL-YOLO (Mutual
Feature Levels Loss enhanced YOLO). We designed a simple cross-level loss
function so that each level of the model has its own role, which is beneficial
for the model to be able to learn more diverse features and improve the fine
granularity. The method can be applied as a plug-and-play module and it does
not increase the structural complexity or the computational complexity while
improving the accuracy. We also replaced the traditional convolution and CSP
with the GSConv and VoVGSCSP in the neck of YOLOv5s to reduce the scale and
computational complexity. Compared with YOLOv5s, our MFL-YOLO improves 4.3 and
5.1 in F1 scores and mAP, while reducing the FLOPs by 8.9%. The Grad-CAM heat
map visualization shows that our model can better focus on the local details of
the damaged traffic signs. In addition, we also conducted experiments on
CCTSDB2021 and TT100K to further validate the generalization of our model.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06751" title="Abstract">arXiv:2309.06751</a> [<a href="/pdf/2309.06751" title="Download PDF">pdf</a>, <a href="/format/2309.06751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remote Sensing Object Detection Meets Deep Learning: A Meta-review of  Challenges and Advances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiangrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guanchun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+P">Peng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+X">Xiuping Jia</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted with IEEE Geoscience and Remote Sensing Magazine. More than 300 papers relevant to the RSOD filed were reviewed in this survey
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Remote sensing object detection (RSOD), one of the most fundamental and
challenging tasks in the remote sensing field, has received longstanding
attention. In recent years, deep learning techniques have demonstrated robust
feature representation capabilities and led to a big leap in the development of
RSOD techniques. In this era of rapid technical evolution, this review aims to
present a comprehensive review of the recent achievements in deep learning
based RSOD methods. More than 300 papers are covered in this review. We
identify five main challenges in RSOD, including multi-scale object detection,
rotated object detection, weak object detection, tiny object detection, and
object detection with limited supervision, and systematically review the
corresponding methods developed in a hierarchical division manner. We also
review the widely used benchmark datasets and evaluation metrics within the
field of RSOD, as well as the application scenarios for RSOD. Future research
directions are provided for further promoting the research in RSOD.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06759" title="Abstract">arXiv:2309.06759</a> [<a href="/pdf/2309.06759" title="Download PDF">pdf</a>, <a href="/format/2309.06759" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaled Prompt-Tuning for Few-Shot Natural Language Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+T">Ting Hu</a>, 
<a href="/search/cs?searchtype=author&query=Meinel%2C+C">Christoph Meinel</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Haojin Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The increasingly Large Language Models (LLMs) demonstrate stronger language
understanding and generation capabilities, while the memory demand and
computation cost of fine-tuning LLMs on downstream tasks are non-negligible.
Besides, fine-tuning generally requires a certain amount of data from
individual tasks whilst data collection cost is another issue to consider in
real-world applications. In this work, we focus on Parameter-Efficient
Fine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG),
which freeze most parameters in LLMs and tune a small subset of parameters in
few-shot cases so that memory footprint, training cost, and labeling cost are
reduced while maintaining or even improving the performance. We propose a
Scaled Prompt-Tuning (SPT) method which surpasses conventional PT with better
performance and generalization ability but without an obvious increase in
training cost. Further study on intermediate SPT suggests the superior
transferability of SPT in few-shot scenarios, providing a recipe for
data-deficient and computation-limited circumstances. Moreover, a comprehensive
comparison of existing PEFT methods reveals that certain approaches exhibiting
decent performance with modest training cost such as Prefix-Tuning in prior
study could struggle in few-shot NLG tasks, especially on challenging datasets.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06764" title="Abstract">arXiv:2309.06764</a> [<a href="/pdf/2309.06764" title="Download PDF">pdf</a>, <a href="/format/2309.06764" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adding an Implication to Logics of Perfect Paradefinite Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greati%2C+V">Vitor Greati</a>, 
<a href="/search/cs?searchtype=author&query=Marcelino%2C+S">S&#xe9;rgio Marcelino</a>, 
<a href="/search/cs?searchtype=author&query=Marcos%2C+J">Jo&#xe3;o Marcos</a>, 
<a href="/search/cs?searchtype=author&query=Rivieccio%2C+U">Umberto Rivieccio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Perfect paradefinite algebras are De Morgan algebras expanded with a
perfection (or classicality) operation. They form a variety that is
term-equivalent to the variety of involutive Stone algebras. Their associated
multiple-conclusion (Set-Set) and single-conclusion (Set-Fmla) order-preserving
logics are non-algebraizable self-extensional logics of formal inconsistency
and undeterminedness determined by a six-valued matrix, studied in depth by
Gomes et al. (2022) from both the algebraic and the proof-theoretical
perspectives. We continue hereby that study by investigating directions for
conservatively expanding these logics with an implication connective
(essentially, one that admits the deduction-detachment theorem). We first
consider logics given by very simple and manageable non-deterministic semantics
whose implication (in isolation) is classical. These, nevertheless, fail to be
self-extensional. We then consider the implication realized by the relative
pseudo-complement over the six-valued perfect paradefinite algebra. Our
strategy is to expand such algebra with this connective and study the
(self-extensional) Set-Set and Set-Fmla order-preserving logics, as well as the
T-assertional logics of the variety induced by the new algebra. We provide
axiomatizations for such new variety and for such logics, drawing parallels
with the class of symmetric Heyting algebras and with Moisil's `symmetric modal
logic'. For the Set-Set logic, in particular, the axiomatization we obtain is
analytic. We close by studying interpolation properties for these logics and
concluding that the new variety has the Maehara amalgamation property.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06768" title="Abstract">arXiv:2309.06768</a> [<a href="/pdf/2309.06768" title="Download PDF">pdf</a>, <a href="/format/2309.06768" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Time-Optimal Planning for Multi-Vehicle Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jank%2C+G">Georg Jank</a>, 
<a href="/search/cs?searchtype=author&query=Rowold%2C+M">Matthias Rowold</a>, 
<a href="/search/cs?searchtype=author&query=Lohmann%2C+B">Boris Lohmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, accepted to be published as part of the 26th IEEE International Conference on Intelligent Transportation Systems (ITSC 2023), Bilbao, Bizkaia, Spain, September 24-28, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a hierarchical planning algorithm for racing with
multiple opponents. The two-stage approach consists of a high-level behavioral
planning step and a low-level optimization step. By combining discrete and
continuous planning methods, our algorithm encourages global time optimality
without being limited by coarse discretization. In the behavioral planning
step, the fastest behavior is determined with a low-resolution spatio-temporal
visibility graph. Based on the selected behavior, we calculate maneuver
envelopes that are subsequently applied as constraints in a time-optimal
control problem. The performance of our method is comparable to a parallel
approach that selects the fastest trajectory from multiple optimizations with
different behavior classes. However, our algorithm can be executed on a single
core. This significantly reduces computational requirements, especially when
multiple opponents are involved. Therefore, the proposed method is an efficient
and practical solution for real-time multi-vehicle racing scenarios.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06769" title="Abstract">arXiv:2309.06769</a> [<a href="/pdf/2309.06769" title="Download PDF">pdf</a>, <a href="/format/2309.06769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reliability-Latency-Rate Tradeoff in Low-Latency Communications with  Finite-Blocklength Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lintao Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Letaief%2C+K+B">Khaled B. Letaief</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE Trans. Inf. Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Low-latency communication plays an increasingly important role in
delay-sensitive applications by ensuring the real-time exchange of information.
However, due to the constraints on the maximum instantaneous power, bounded
latency is hard to be guaranteed. In this paper, we investigate the
reliability-latency-rate tradeoff in low-latency communications with
finite-blocklength coding (FBC). More specifically, we are interested in the
fundamental tradeoff between error probability, delay-violation probability
(DVP), and service rate. Based on the effective capacity (EC) and normal
approximation, we present several gain-conservation inequalities to bound the
reliability-latency-rate tradeoffs. In particular, we investigate the
low-latency transmissions over an additive white Gaussian noise (AWGN) channel,
over a Rayleigh fading channel, with frequency or spatial diversity, and over a
Nakagami-$m$ fading channel. To analytically evaluate the
quality-of-service-constrained low-latency communications with FBC, an
EC-approximation method is further conceived to derive the closed-form
expression of quality-of-service-constrained throughput. For delay-sensitive
transmissions in which the latency threshold is greater than the channel
coherence time, we find an asymptotic form of the tradeoff between the error
probability and DVP over the AWGN and Rayleigh fading channels. Our results may
provide some insights into the efficient scheduling of low-latency wireless
communications in which statistical latency and reliability metrics are
adopted.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06771" title="Abstract">arXiv:2309.06771</a> [<a href="/pdf/2309.06771" title="Download PDF">pdf</a>, <a href="/format/2309.06771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OrdinalFix: Fixing Compilation Errors via Shortest-Path CFL Reachability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wenjie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guancheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junjie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Y">Yingfei Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The development of correct and efficient software can be hindered by
compilation errors, which must be fixed to ensure the code's syntactic
correctness and program language constraints. Neural network-based approaches
have been used to tackle this problem, but they lack guarantees of output
correctness and can require an unlimited number of modifications. Fixing
compilation errors within a given number of modifications is a challenging
task. We demonstrate that finding the minimum number of modifications to fix a
compilation error is NP-hard. To address compilation error fixing problem, we
propose OrdinalFix, a complete algorithm based on shortest-path CFL
(context-free language) reachability with attribute checking that is guaranteed
to output a program with the minimum number of modifications required.
Specifically, OrdinalFix searches possible fixes from the smallest to the
largest number of modifications. By incorporating merged attribute checking to
enhance efficiency, the time complexity of OrdinalFix is acceptable for
application. We evaluate OrdinalFix on two datasets and demonstrate its ability
to fix compilation errors within reasonable time limit. Comparing with existing
approaches, OrdinalFix achieves a success rate of 83.5%, surpassing all
existing approaches (71.7%).
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06774" title="Abstract">arXiv:2309.06774</a> [<a href="/pdf/2309.06774" title="Download PDF">pdf</a>, <a href="/format/2309.06774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fundamental Limits of Deep Learning-Based Binary Classifiers Trained  with Hinge Loss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Getu%2C+T+M">Tilahun M. Getu</a>, 
<a href="/search/cs?searchtype=author&query=Kaddoum%2C+G">Georges Kaddoum</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Although deep learning (DL) has led to several breakthroughs in many
disciplines as diverse as chemistry, computer science, electrical engineering,
mathematics, medicine, neuroscience, and physics, a comprehensive understanding
of why and how DL is empirically successful remains fundamentally elusive. To
attack this fundamental problem and unravel the mysteries behind DL's empirical
successes, significant innovations toward a unified theory of DL have been
made. These innovations encompass nearly fundamental advances in optimization,
generalization, and approximation. Despite these advances, however, no work to
date has offered a way to quantify the testing performance of a DL-based
algorithm employed to solve a pattern classification problem. To overcome this
fundamental challenge in part, this paper exposes the fundamental testing
performance limits of DL-based binary classifiers trained with hinge loss. For
binary classifiers that are based on deep rectified linear unit (ReLU)
feedforward neural networks (FNNs) and ones that are based on deep FNNs with
ReLU and Tanh activation, we derive their respective novel asymptotic testing
performance limits. The derived testing performance limits are validated by
extensive computer experiments.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06779" title="Abstract">arXiv:2309.06779</a> [<a href="/pdf/2309.06779" title="Download PDF">pdf</a>, <a href="/format/2309.06779" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZKROWNN: Zero Knowledge Right of Ownership for Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sheybani%2C+N">Nojan Sheybani</a>, 
<a href="/search/cs?searchtype=author&query=Ghodsi%2C+Z">Zahra Ghodsi</a>, 
<a href="/search/cs?searchtype=author&query=Kapila%2C+R">Ritvik Kapila</a>, 
<a href="/search/cs?searchtype=author&query=Koushanfar%2C+F">Farinaz Koushanfar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published and presented at DAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Training contemporary AI models requires investment in procuring learning
data and computing resources, making the models intellectual property of the
owners. Popular model watermarking solutions rely on key input triggers for
detection; the keys have to be kept private to prevent discovery, forging, and
removal of the hidden signatures. We present ZKROWNN, the first automated
end-to-end framework utilizing Zero-Knowledge Proofs (ZKP) that enable an
entity to validate their ownership of a model, while preserving the privacy of
the watermarks. ZKROWNN permits a third party client to verify model ownership
in less than a second, requiring as little as a few KBs of communication.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06780" title="Abstract">arXiv:2309.06780</a> [<a href="/pdf/2309.06780" title="Download PDF">pdf</a>, <a href="/format/2309.06780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distinguishing Neural Speech Synthesis Models Through Fingerprints in  Speech Waveforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C+Y">Chu Yuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xinrui Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent strides in neural speech synthesis technologies, while enjoying
widespread applications, have nonetheless introduced a series of challenges,
spurring interest in the defence against the threat of misuse and abuse.
Notably, source attribution of synthesized speech has value in forensics and
intellectual property protection, but prior work in this area has certain
limitations in scope. To address the gaps, we present our findings concerning
the identification of the sources of synthesized speech in this paper. We
investigate the existence of speech synthesis model fingerprints in the
generated speech waveforms, with a focus on the acoustic model and the vocoder,
and study the influence of each component on the fingerprint in the overall
speech waveforms. Our research, conducted using the multi-speaker LibriTTS
dataset, demonstrates two key insights: (1) vocoders and acoustic models impart
distinct, model-specific fingerprints on the waveforms they generate, and (2)
vocoder fingerprints are the more dominant of the two, and may mask the
fingerprints from the acoustic model. These findings strongly suggest the
existence of model-specific fingerprints for both the acoustic model and the
vocoder, highlighting their potential utility in source identification
applications.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06783" title="Abstract">arXiv:2309.06783</a> [<a href="/pdf/2309.06783" title="Download PDF">pdf</a>, <a href="/format/2309.06783" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ungar $\unicode{x2013}$ A C++ Framework for Real-Time Optimal Control  Using Template Metaprogramming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=De+Vincenti%2C+F">Flavio De Vincenti</a>, 
<a href="/search/eess?searchtype=author&query=Coros%2C+S">Stelian Coros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 7 pages, 2 figures. Library available at <a href="https://github.com/fdevinc/ungar">this https URL</a> . Presentation available at <a href="https://www.youtube.com/watch?v=iKQ6felf45k">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We present Ungar, an open-source library to aid the implementation of
high-dimensional optimal control problems (OCPs). We adopt modern template
metaprogramming techniques to enable the compile-time modeling of complex
systems while retaining maximum runtime efficiency. Our framework provides
syntactic sugar to allow for expressive formulations of a rich set of
structured dynamical systems. While the core modules depend only on the
header-only Eigen and Boost.Hana libraries, we bundle our codebase with
optional packages and custom wrappers for automatic differentiation, code
generation, and nonlinear programming. Finally, we demonstrate the versatility
of Ungar in various model predictive control applications, namely, four-legged
locomotion and collaborative loco-manipulation with multiple one-armed
quadruped robots. Ungar is available under the Apache License 2.0 at
https://github.com/fdevinc/ungar.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06787" title="Abstract">arXiv:2309.06787</a> [<a href="/pdf/2309.06787" title="Download PDF">pdf</a>, <a href="/format/2309.06787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCTTS: Discrete Diffusion Model with Contrastive Learning for  Text-to-speech Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhichao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiulin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Sixing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, submitted to ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In the Text-to-speech(TTS) task, the latent diffusion model has excellent
fidelity and generalization, but its expensive resource consumption and slow
inference speed have always been a challenging. This paper proposes Discrete
Diffusion Model with Contrastive Learning for Text-to-Speech Generation(DCTTS).
The following contributions are made by DCTTS: 1) The TTS diffusion model based
on discrete space significantly lowers the computational consumption of the
diffusion model and improves sampling speed; 2) The contrastive learning method
based on discrete space is used to enhance the alignment connection between
speech and text and improve sampling quality; and 3) It uses an efficient text
encoder to simplify the model's parameters and increase computational
efficiency. The experimental results demonstrate that the approach proposed in
this paper has outstanding speech synthesis quality and sampling speed while
significantly reducing the resource consumption of diffusion model. The
synthesized samples are available at https://github.com/lawtherWu/DCTTS.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06789" title="Abstract">arXiv:2309.06789</a> [<a href="/pdf/2309.06789" title="Download PDF">pdf</a>, <a href="/format/2309.06789" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Image Dataset for Benchmarking Recommender Systems with Raw Pixels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Y">Yu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yunzhu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+Y">Yongxin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Aixin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+F">Fajie Yuan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Recommender systems (RS) have achieved significant success by leveraging
explicit identification (ID) features. However, the full potential of content
features, especially the pure image pixel features, remains relatively
unexplored. The limited availability of large, diverse, and content-driven
image recommendation datasets has hindered the use of raw images as item
representations. In this regard, we present PixelRec, a massive image-centric
recommendation dataset that includes approximately 200 million user-image
interactions, 30 million users, and 400,000 high-quality cover images. By
providing direct access to raw image pixels, PixelRec enables recommendation
models to learn item representation directly from them. To demonstrate its
utility, we begin by presenting the results of several classical pure ID-based
baseline models, termed IDNet, trained on PixelRec. Then, to show the
effectiveness of the dataset's image features, we substitute the itemID
embeddings (from IDNet) with a powerful vision encoder that represents items
using their raw image pixels. This new model is dubbed PixelNet.Our findings
indicate that even in standard, non-cold start recommendation settings where
IDNet is recognized as highly effective, PixelNet can already perform equally
well or even better than IDNet. Moreover, PixelNet has several other notable
advantages over IDNet, such as being more effective in cold-start and
cross-domain recommendation scenarios. These results underscore the importance
of visual features in PixelRec. We believe that PixelRec can serve as a
critical resource and testing ground for research on recommendation models that
emphasize image pixel content. The dataset, code, and leaderboard will be
available at https://github.com/website-pixelrec/PixelRec.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06792" title="Abstract">arXiv:2309.06792</a> [<a href="/pdf/2309.06792" title="Download PDF">pdf</a>, <a href="/format/2309.06792" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion-Bias-Free Feature-Based SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fontan%2C+A">Alejandro Fontan</a>, 
<a href="/search/cs?searchtype=author&query=Civera%2C+J">Javier Civera</a>, 
<a href="/search/cs?searchtype=author&query=Milford%2C+M">Michael Milford</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">For SLAM to be safely deployed in unstructured real world environments, it
must possess several key properties that are not encompassed by conventional
benchmarks. In this paper we show that SLAM commutativity, that is, consistency
in trajectory estimates on forward and reverse traverses of the same route, is
a significant issue for the state of the art. Current pipelines show a
significant bias between forward and reverse directions of travel, that is in
addition inconsistent regarding which direction of travel exhibits better
performance. In this paper we propose several contributions to feature-based
SLAM pipelines that remedies the motion bias problem. In a comprehensive
evaluation across four datasets, we show that our contributions implemented in
ORB-SLAM2 substantially reduce the bias between forward and backward motion and
additionally improve the aggregated trajectory error. Removing the SLAM motion
bias has significant relevance for the wide range of robotics and computer
vision applications where performance consistency is important.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06793" title="Abstract">arXiv:2309.06793</a> [<a href="/pdf/2309.06793" title="Download PDF">pdf</a>, <a href="/format/2309.06793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electricity Demand Forecasting through Natural Language Processing with  Long Short-Term Memory Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yun Bai</a>, 
<a href="/search/cs?searchtype=author&query=Camal%2C+S">Simon Camal</a>, 
<a href="/search/cs?searchtype=author&query=Michiorri%2C+A">Andrea Michiorri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, 2023 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Electricity demand forecasting is a well established research field. Usually
this task is performed considering historical loads, weather forecasts,
calendar information and known major events. Recently attention has been given
on the possible use of new sources of information from textual news in order to
improve the performance of these predictions. This paper proposes a Long and
Short-Term Memory (LSTM) network incorporating textual news features that
successfully predicts the deterministic and probabilistic tasks of the UK
national electricity demand. The study finds that public sentiment and word
vector representations related to transport and geopolitics have
time-continuity effects on electricity demand. The experimental results show
that the LSTM with textual features improves by more than 3% compared to the
pure LSTM benchmark and by close to 10% over the official benchmark.
Furthermore, the proposed model effectively reduces forecasting uncertainty by
narrowing the confidence interval and bringing the forecast distribution closer
to the truth.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06794" title="Abstract">arXiv:2309.06794</a> [<a href="/pdf/2309.06794" title="Download PDF">pdf</a>, <a href="/format/2309.06794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cognitive Mirage: A Review of Hallucinations in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Hongbin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Aijia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wei Hua</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+W">Weiqiang Jia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As large language models continue to develop in the field of AI, text
generation systems are susceptible to a worrisome phenomenon known as
hallucination. In this study, we summarize recent compelling insights into
hallucinations in LLMs. We present a novel taxonomy of hallucinations from
various text generation tasks, thus provide theoretical insights, detection
methods and improvement approaches. Based on this, future research directions
are proposed. Our contribution are threefold: (1) We provide a detailed and
complete taxonomy for hallucinations appearing in text generation tasks; (2) We
provide theoretical analyses of hallucinations in LLMs and provide existing
detection and improvement methods; (3) We propose several research directions
that can be developed in the future. As hallucinations garner significant
attention from the community, we will maintain updates on relevant research
progress.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06797" title="Abstract">arXiv:2309.06797</a> [<a href="/pdf/2309.06797" title="Download PDF">pdf</a>, <a href="/format/2309.06797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced Lagrange multiplier approach for non-matching coupled problems  in multiscale elasticity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Belponer%2C+C">Camilla Belponer</a>, 
<a href="/search/math?searchtype=author&query=Caiazz%2C+A">Alfonso Caiazz</a>, 
<a href="/search/math?searchtype=author&query=Heltai%2C+L">Luca Heltai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper presents a numerical method for the simulation of elastic solid
materials coupled to fluid inclusions. The application is motivated by the
modeling of vascularized tissues and by problems in medical imaging which
target the estimation of effective (i.e., macroscale) material properties,
taking into account the influence of microscale dynamics, such as fluid flow in
the microvasculature. The method is based on the recently proposed Reduced
Lagrange Multipliers framework. In particular, the interface between solid and
fluid domains is not resolved within the computational mesh for the elastic
material but discretized independently, imposing the coupling condition via
non-matching Lagrange multipliers. Exploiting the multiscale properties of the
problem, the resulting Lagrange multipliers space is reduced to a
lower-dimensional characteristic set. We present the details of the stability
analysis of the resulting method considering a non-standard boundary condition
that enforces a local deformation on the solid-fluid boundary. The method is
validated with several numerical examples.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06799" title="Abstract">arXiv:2309.06799</a> [<a href="/pdf/2309.06799" title="Download PDF">pdf</a>, <a href="/format/2309.06799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When Geoscience Meets Foundation Models: Towards General Geoscience  Artificial Intelligence System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jin-Jian Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Geophysics (physics.geo-ph)

</div>
<p class="mathjax">Geoscience foundation models represent a revolutionary approach in the field
of Earth sciences by integrating massive cross-disciplinary data to simulate
and understand the Earth systems dynamics. As a data-centric artificial
intelligence (AI) paradigm, they uncover insights from petabytes of structured
and unstructured data. Flexible task specification, diverse inputs and outputs
and multi-modal knowledge representation enable comprehensive analysis
infeasible with individual data sources. Critically, the scalability and
generalizability of geoscience models allow for tackling diverse prediction,
simulation, and decision challenges related to Earth systems interactions.
Collaboration between domain experts and computer scientists leads to
innovations in these invaluable tools for understanding the past, present, and
future of our planet. However, challenges remain in validation and
verification, scale, interpretability, knowledge representation, and social
bias. Going forward, enhancing model integration, resolution, accuracy, and
equity through cross-disciplinary teamwork is key. Despite current limitations,
geoscience foundation models show promise for providing critical insights into
pressing issues including climate change, natural hazards, and sustainability
through their ability to probe scenarios and quantify uncertainties. Their
continued evolution toward integrated, data-driven modeling holds
paradigm-shifting potential for Earth science.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06800" title="Abstract">arXiv:2309.06800</a> [<a href="/pdf/2309.06800" title="Download PDF">pdf</a>, <a href="/format/2309.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Traffic Prediction under Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhiming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, Accepted as a short paper of IEEE International Conference on Data Mining (ICDM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic prediction is a crucial topic because of its broad scope of
applications in the transportation domain. Recently, various studies have
achieved promising results. However, most studies assume the prediction
locations have complete or at least partial historical records and cannot be
extended to non-historical recorded locations. In real-life scenarios, the
deployment of sensors could be limited due to budget limitations and
installation availability, which makes most current models not applicable.
Though few pieces of literature tried to impute traffic states at the missing
locations, these methods need the data simultaneously observed at the locations
with sensors, making them not applicable to prediction tasks. Another drawback
is the lack of measurement of uncertainty in prediction, making prior works
unsuitable for risk-sensitive tasks or involving decision-making. To fill the
gap, inspired by the previous inductive graph neural network, this work
proposed an uncertainty-aware framework with the ability to 1) extend
prediction to missing locations with no historical records and significantly
extend spatial coverage of prediction locations while reducing deployment of
sensors and 2) generate probabilistic prediction with uncertainty
quantification to help the management of risk and decision making in the
down-stream tasks. Through extensive experiments on real-life datasets, the
result shows our method achieved promising results on prediction tasks, and the
uncertainty quantification gives consistent results which highly correlated
with the locations with and without historical data. We also show that our
model could help support sensor deployment tasks in the transportation field to
achieve higher accuracy with a limited sensor deployment budget.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06801" title="Abstract">arXiv:2309.06801</a> [<a href="/pdf/2309.06801" title="Download PDF">pdf</a>, <a href="/ps/2309.06801" title="Download PostScript">ps</a>, <a href="/format/2309.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defensive Alliances in Signed Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arrighi%2C+E">Emmanuel Arrighi</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhidan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+X">Xingqin Qi</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+P">Petra Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The analysis of (social) networks and multi-agent systems is a central theme
in Artificial Intelligence. Some line of research deals with finding groups of
agents that could work together to achieve a certain goal. To this end,
different notions of so-called clusters or communities have been introduced in
the literature of graphs and networks. Among these, defensive alliance is a
kind of quantitative group structure. However, all studies on the alliance so
for have ignored one aspect that is central to the formation of alliances on a
very intuitive level, assuming that the agents are preconditioned concerning
their attitude towards other agents: they prefer to be in some group (alliance)
together with the agents they like, so that they are happy to help each other
towards their common aim, possibly then working against the agents outside of
their group that they dislike. Signed networks were introduced in the
psychology literature to model liking and disliking between agents,
generalizing graphs in a natural way. Hence, we propose the novel notion of a
defensive alliance in the context of signed networks. We then investigate
several natural algorithmic questions related to this notion. These, and also
combinatorial findings, connect our notion to that of correlation clustering,
which is a well-established idea of finding groups of agents within a signed
network. Also, we introduce a new structural parameter for signed graphs,
signed neighborhood diversity snd, and exhibit a parameterized algorithm that
finds a smallest defensive alliance in a signed graph.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06802" title="Abstract">arXiv:2309.06802</a> [<a href="/pdf/2309.06802" title="Download PDF">pdf</a>, <a href="/format/2309.06802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic NeRFs for Soccer Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewin%2C+S">Sacha Lewin</a>, 
<a href="/search/cs?searchtype=author&query=Vandegar%2C+M">Maxime Vandegar</a>, 
<a href="/search/cs?searchtype=author&query=Hoyoux%2C+T">Thomas Hoyoux</a>, 
<a href="/search/cs?searchtype=author&query=Barnich%2C+O">Olivier Barnich</a>, 
<a href="/search/cs?searchtype=author&query=Louppe%2C+G">Gilles Louppe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the 6th International ACM Workshop on Multimedia Content Analysis in Sports. 8 pages, 9 figures. Project page: <a href="https://soccernerfs.isach.be">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The long-standing problem of novel view synthesis has many applications,
notably in sports broadcasting. Photorealistic novel view synthesis of soccer
actions, in particular, is of enormous interest to the broadcast industry. Yet
only a few industrial solutions have been proposed, and even fewer that achieve
near-broadcast quality of the synthetic replays. Except for their setup of
multiple static cameras around the playfield, the best proprietary systems
disclose close to no information about their inner workings. Leveraging
multiple static cameras for such a task indeed presents a challenge rarely
tackled in the literature, for a lack of public datasets: the reconstruction of
a large-scale, mostly static environment, with small, fast-moving elements.
Recently, the emergence of neural radiance fields has induced stunning progress
in many novel view synthesis applications, leveraging deep learning principles
to produce photorealistic results in the most challenging settings. In this
work, we investigate the feasibility of basing a solution to the task on
dynamic NeRFs, i.e., neural models purposed to reconstruct general dynamic
content. We compose synthetic soccer environments and conduct multiple
experiments using them, identifying key components that help reconstruct soccer
scenes with dynamic NeRFs. We show that, although this approach cannot fully
meet the quality requirements for the target application, it suggests promising
avenues toward a cost-efficient, automatic solution. We also make our work
dataset and code publicly available, with the goal to encourage further efforts
from the research community on the task of novel view synthesis for dynamic
soccer scenes. For code, data, and video results, please see
https://soccernerfs.isach.be.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06803" title="Abstract">arXiv:2309.06803</a> [<a href="/pdf/2309.06803" title="Download PDF">pdf</a>, <a href="/format/2309.06803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Critical Escape Probability Formulation for Enhancing the Transient  Stability of Power Systems with System Parameter Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+X">Xian Wu</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+K">Kaihua Xi</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+A">Aijie Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chenghui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+H+X">Hai Xiang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">For the enhancement of the transient stability of power systems, the key is
to define a quantitative optimization formulation with system parameters as
decision variables. In this paper, we model the disturbances by Gaussian noise
and define a metric named Critical Escape Probability (CREP) based on the
invariant probability measure of a linearised stochastic processes. CREP
characterizes the probability of the state escaping from a critical set. CREP
involves all the system parameters and reflects the size of the basin of
attraction of the nonlinear systems. An optimization framework that minimizes
CREP with the system parameters as decision variablesis is presented.
Simulations show that the mean first hitting time when the state hits the
boundary of the critical set, that is often used to describe the stability of
nonlinear systems, is dramatically increased by minimizing CREP. This indicates
that the transient stability of the system is effectively enhanced. It also
shown that suppressing the state fluctuations only is insufficient for
enhancing the transient stability. In addition, the famous Braess' paradox
which also exists in power systems is revisited. Surprisingly, it turned out
that the paradoxes identified by the traditional metric may not exist according
to CREP. This new metric opens a new avenue for the transient stability
analysis of future power systems integrated with large amounts of renewable
energy.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06805" title="Abstract">arXiv:2309.06805</a> [<a href="/pdf/2309.06805" title="Download PDF">pdf</a>, <a href="/format/2309.06805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDIP: Federated Learning with Extreme Dynamic Pruning and Incremental  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Q">Qianyu Long</a>, 
<a href="/search/cs?searchtype=author&query=Anagnostopoulos%2C+C">Christos Anagnostopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Parambath%2C+S+P">Shameem Puthiya Parambath</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+D">Daning Bi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at ICDM 2023 (Full version in arxiv). The associated code is available at <a href="https://github.com/EricLoong/feddip">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Federated Learning (FL) has been successfully adopted for distributed
training and inference of large-scale Deep Neural Networks (DNNs). However,
DNNs are characterized by an extremely large number of parameters, thus,
yielding significant challenges in exchanging these parameters among
distributed nodes and managing the memory. Although recent DNN compression
methods (e.g., sparsification, pruning) tackle such challenges, they do not
holistically consider an adaptively controlled reduction of parameter exchange
while maintaining high accuracy levels. We, therefore, contribute with a novel
FL framework (coined FedDIP), which combines (i) dynamic model pruning with
error feedback to eliminate redundant information exchange, which contributes
to significant performance improvement, with (ii) incremental regularization
that can achieve \textit{extreme} sparsity of models. We provide convergence
analysis of FedDIP and report on a comprehensive performance and comparative
assessment against state-of-the-art methods using benchmark data sets and DNN
models. Our results showcase that FedDIP not only controls the model sparsity
but efficiently achieves similar or better performance compared to other model
pruning methods adopting incremental regularization during distributed model
training. The code is available at: https://github.com/EricLoong/feddip.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06806" title="Abstract">arXiv:2309.06806</a> [<a href="/pdf/2309.06806" title="Download PDF">pdf</a>, <a href="/ps/2309.06806" title="Download PostScript">ps</a>, <a href="/format/2309.06806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bounds and Constructions for Generalized Batch Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kong%2C+X">Xiangliang Kong</a>, 
<a href="/search/cs?searchtype=author&query=Elishco%2C+O">Ohad Elishco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Private information retrieval (PIR) codes and batch codes are two important
types of codes that are designed for coded distributed storage systems and
private information retrieval protocols. These codes have been the focus of
much attention in recent years, as they enable efficient and secure storage and
retrieval of data in distributed systems.
<br />In this paper, we introduce a new class of codes called \emph{$(s,t)$-batch
codes}. These codes are a type of storage codes that can handle any multi-set
of $t$ requests, comprised of $s$ distinct information symbols. Importantly,
PIR codes and batch codes are special cases of $(s,t)$-batch codes.
<br />The main goal of this paper is to explore the relationship between the number
of redundancy symbols and the $(s,t)$-batch code property. Specifically, we
establish a lower bound on the number of redundancy symbols required and
present several constructions of $(s,t)$-batch codes. Furthermore, we extend
this property to the case where each request is a linear combination of
information symbols, which we refer to as \emph{functional $(s,t)$-batch
codes}. Specifically, we demonstrate that simplex codes are asymptotically
optimal functional $(s,t)$-batch codes, in terms of the number of redundancy
symbols required, under certain parameter regime.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06807" title="Abstract">arXiv:2309.06807</a> [<a href="/pdf/2309.06807" title="Download PDF">pdf</a>, <a href="/format/2309.06807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian uncertainty-weighted loss for improved generalisability on  polyp segmentation task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stone%2C+R+S">Rebecca S. Stone</a>, 
<a href="/search/cs?searchtype=author&query=Chavarrias-Solano%2C+P+E">Pedro E. Chavarrias-Solano</a>, 
<a href="/search/cs?searchtype=author&query=Bulpitt%2C+A+J">Andrew J. Bulpitt</a>, 
<a href="/search/cs?searchtype=author&query=Hogg%2C+D+C">David C. Hogg</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Sharib Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at the Fairness of AI in Medical Imaging (FAIMI) MICCAI 2023 Workshop and published in volumes of the Springer Lecture Notes Computer Science (LNCS) series
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">While several previous studies have devised methods for segmentation of
polyps, most of these methods are not rigorously assessed on multi-center
datasets. Variability due to appearance of polyps from one center to another,
difference in endoscopic instrument grades, and acquisition quality result in
methods with good performance on in-distribution test data, and poor
performance on out-of-distribution or underrepresented samples. Unfair models
have serious implications and pose a critical challenge to clinical
applications. We adapt an implicit bias mitigation method which leverages
Bayesian epistemic uncertainties during training to encourage the model to
focus on underrepresented sample regions. We demonstrate the potential of this
approach to improve generalisability without sacrificing state-of-the-art
performance on a challenging multi-center polyp segmentation dataset (PolypGen)
with different centers and image modalities.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06809" title="Abstract">arXiv:2309.06809</a> [<a href="/pdf/2309.06809" title="Download PDF">pdf</a>, <a href="/format/2309.06809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TAP: Targeted Prompting for Task Adaptive Generation of Textual Training  Instances for Visual Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mirza%2C+M+J">M. Jehanzeb Mirza</a>, 
<a href="/search/cs?searchtype=author&query=Karlinsky%2C+L">Leonid Karlinsky</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Possegger%2C+H">Horst Possegger</a>, 
<a href="/search/cs?searchtype=author&query=Feris%2C+R">Rogerio Feris</a>, 
<a href="/search/cs?searchtype=author&query=Bischof%2C+H">Horst Bischof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at: <a href="https://github.com/jmiemirza/TAP">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision and Language Models (VLMs), such as CLIP, have enabled visual
recognition of a potentially unlimited set of categories described by text
prompts. However, for the best visual recognition performance, these models
still require tuning to better fit the data distributions of the downstream
tasks, in order to overcome the domain shift from the web-based pre-training
data. Recently, it has been shown that it is possible to effectively tune VLMs
without any paired data, and in particular to effectively improve VLMs visual
recognition performance using text-only training data generated by Large
Language Models (LLMs). In this paper, we dive deeper into this exciting
text-only VLM training approach and explore ways it can be significantly
further improved taking the specifics of the downstream task into account when
sampling text data from LLMs. In particular, compared to the SOTA text-only VLM
training approach, we demonstrate up to 8.4% performance improvement in (cross)
domain-specific adaptation, up to 8.7% improvement in fine-grained recognition,
and 3.1% overall average improvement in zero-shot classification compared to
strong baselines.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06810" title="Abstract">arXiv:2309.06810</a> [<a href="/pdf/2309.06810" title="Download PDF">pdf</a>, <a href="/format/2309.06810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging SE(3) Equivariance for Learning 3D Geometric Shape Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruihai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tie%2C+C">Chenrui Tie</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yushi Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023, Project page: <a href="https://crtie.github.io/SE-3-part-assembly/">this https URL</a> , Code: <a href="https://github.com/crtie/Leveraging-SE-3-Equivariance-for-Learning-3D-Geometric-Shape-Assembly">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Shape assembly aims to reassemble parts (or fragments) into a complete
object, which is a common task in our daily life. Different from the semantic
part assembly (e.g., assembling a chair's semantic parts like legs into a whole
chair), geometric part assembly (e.g., assembling bowl fragments into a
complete bowl) is an emerging task in computer vision and robotics. Instead of
semantic information, this task focuses on geometric information of parts. As
the both geometric and pose space of fractured parts are exceptionally large,
shape pose disentanglement of part representations is beneficial to geometric
shape assembly. In our paper, we propose to leverage SE(3) equivariance for
such shape pose disentanglement. Moreover, while previous works in vision and
robotics only consider SE(3) equivariance for the representations of single
objects, we move a step forward and propose leveraging SE(3) equivariance for
representations considering multi-part correlations, which further boosts the
performance of the multi-part assembly. Experiments demonstrate the
significance of SE(3) equivariance and our proposed method for geometric shape
assembly. Project page: https://crtie.github.io/SE-3-part-assembly/
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06814" title="Abstract">arXiv:2309.06814</a> [<a href="/pdf/2309.06814" title="Download PDF">pdf</a>, <a href="/format/2309.06814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Analysis of Contextual Relation Extraction based on Deep  Learning Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Priyadharshini%2C+R">R.Priyadharshini</a>, 
<a href="/search/cs?searchtype=author&query=Jeyakodi%2C+G">G.Jeyakodi</a>, 
<a href="/search/cs?searchtype=author&query=Bala%2C+P+S">P.Shanthi Bala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This Paper Presented in the International Conference on FOSS Approaches towards Computational Intelligence and Language TTechnolog on February 2023, Thiruvananthapuram
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> An International Journal of Engineering Science, March 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Contextual Relation Extraction (CRE) is mainly used for constructing a
knowledge graph with a help of ontology. It performs various tasks such as
semantic search, query answering, and textual entailment. Relation extraction
identifies the entities from raw texts and the relations among them. An
efficient and accurate CRE system is essential for creating domain knowledge in
the biomedical industry. Existing Machine Learning and Natural Language
Processing (NLP) techniques are not suitable to predict complex relations from
sentences that consist of more than two relations and unspecified entities
efficiently. In this work, deep learning techniques have been used to identify
the appropriate semantic relation based on the context from multiple sentences.
Even though various machine learning models have been used for relation
extraction, they provide better results only for binary relations, i.e.,
relations occurred exactly between the two entities in a sentence. Machine
learning models are not suited for complex sentences that consist of the words
that have various meanings. To address these issues, hybrid deep learning
models have been used to extract the relations from complex sentence
effectively. This paper explores the analysis of various deep learning models
that are used for relation extraction.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06819" title="Abstract">arXiv:2309.06819</a> [<a href="/pdf/2309.06819" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Particles Ejected From Active Asteroid Bennu With Event-Based  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azzalini%2C+L+J">Lo&#xef;c J. Azzalini</a>, 
<a href="/search/cs?searchtype=author&query=Izzo%2C+D">Dario Izzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, presented at the XXVII Italian Association of Aeronautics and Astronautics (AIDAA) Congress, 4-7 September 2023, Padova Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Early detection and tracking of ejecta in the vicinity of small solar system
bodies is crucial to guarantee spacecraft safety and support scientific
observation. During the visit of active asteroid Bennu, the OSIRIS-REx
spacecraft relied on the analysis of images captured by onboard navigation
cameras to detect particle ejection events, which ultimately became one of the
mission's scientific highlights. To increase the scientific return of similar
time-constrained missions, this work proposes an event-based solution that is
dedicated to the detection and tracking of centimetre-sized particles. Unlike a
standard frame-based camera, the pixels of an event-based camera independently
trigger events indicating whether the scene brightness has increased or
decreased at that time and location in the sensor plane. As a result of the
sparse and asynchronous spatiotemporal output, event cameras combine very high
dynamic range and temporal resolution with low-power consumption, which could
complement existing onboard imaging techniques. This paper motivates the use of
a scientific event camera by reconstructing the particle ejection episodes
reported by the OSIRIS-REx mission in a photorealistic scene generator and in
turn, simulating event-based observations. The resulting streams of
spatiotemporal data support future work on event-based multi-object tracking.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06824" title="Abstract">arXiv:2309.06824</a> [<a href="/pdf/2309.06824" title="Download PDF">pdf</a>, <a href="/format/2309.06824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMUS: Adapting Segment Anything Model for Clinically-Friendly and  Generalizable Ultrasound Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+Y">Yangyang Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zengqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Li Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Segment anything model (SAM), an eminent universal image segmentation model,
has recently gathered considerable attention within the domain of medical image
segmentation. Despite the remarkable performance of SAM on natural images, it
grapples with significant performance degradation and limited generalization
when confronted with medical images, particularly with those involving objects
of low contrast, faint boundaries, intricate shapes, and diminutive sizes. In
this paper, we propose SAMUS, a universal model tailored for ultrasound image
segmentation. In contrast to previous SAM-based universal models, SAMUS pursues
not only better generalization but also lower deployment cost, rendering it
more suitable for clinical applications. Specifically, based on SAM, a parallel
CNN branch is introduced to inject local features into the ViT encoder through
cross-branch attention for better medical image segmentation. Then, a position
adapter and a feature adapter are developed to adapt SAM from natural to
medical domains and from requiring large-size inputs (1024x1024) to small-size
inputs (256x256) for more clinical-friendly deployment. A comprehensive
ultrasound dataset, comprising about 30k images and 69k masks and covering six
object categories, is collected for verification. Extensive comparison
experiments demonstrate SAMUS's superiority against the state-of-the-art
task-specific models and universal foundation models under both task-specific
evaluation and generalization evaluation. Moreover, SAMUS is deployable on
entry-level GPUs, as it has been liberated from the constraints of long
sequence encoding. The code, data, and models will be released at
https://github.com/xianlin7/SAMUS.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06828" title="Abstract">arXiv:2309.06828</a> [<a href="/pdf/2309.06828" title="Download PDF">pdf</a>, <a href="/format/2309.06828" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniBrain: Universal Brain MRI Diagnosis with Hierarchical  Knowledge-enhanced Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiayu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+L">Lisong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Haoyun Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chaoyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoman Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+J">Jiangchao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanyong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuehua Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Magnetic resonance imaging~(MRI) have played a crucial role in brain disease
diagnosis, with which a range of computer-aided artificial intelligence methods
have been proposed. However, the early explorations usually focus on the
limited types of brain diseases in one study and train the model on the data in
a small scale, yielding the bottleneck of generalization. Towards a more
effective and scalable paradigm, we propose a hierarchical knowledge-enhanced
pre-training framework for the universal brain MRI diagnosis, termed as
UniBrain. Specifically, UniBrain leverages a large-scale dataset of 24,770
imaging-report pairs from routine diagnostics. Different from previous
pre-training techniques for the unitary vision or textual feature, or with the
brute-force alignment between vision and language information, we leverage the
unique characteristic of report information in different granularity to build a
hierarchical alignment mechanism, which strengthens the efficiency in feature
learning. Our UniBrain is validated on three real world datasets with severe
class imbalance and the public BraTS2019 dataset. It not only consistently
outperforms all state-of-the-art diagnostic methods by a large margin and
provides a superior grounding performance but also shows comparable performance
compared to expert radiologists on certain disease types.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06835" title="Abstract">arXiv:2309.06835</a> [<a href="/pdf/2309.06835" title="Download PDF">pdf</a>, <a href="/format/2309.06835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe Reinforcement Learning with Dual Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zeyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chuxiong Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+E">Shengbo Eben Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning (RL) agents are vulnerable to adversarial
disturbances, which can deteriorate task performance or compromise safety
specifications. Existing methods either address safety requirements under the
assumption of no adversary (e.g., safe RL) or only focus on robustness against
performance adversaries (e.g., robust RL). Learning one policy that is both
safe and robust remains a challenging open problem. The difficulty is how to
tackle two intertwined aspects in the worst cases: feasibility and optimality.
Optimality is only valid inside a feasible region, while identification of
maximal feasible region must rely on learning the optimal policy. To address
this issue, we propose a systematic framework to unify safe RL and robust RL,
including problem formulation, iteration scheme, convergence analysis and
practical algorithm design. This unification is built upon constrained
two-player zero-sum Markov games. A dual policy iteration scheme is proposed,
which simultaneously optimizes a task policy and a safety policy. The
convergence of this iteration scheme is proved. Furthermore, we design a deep
RL algorithm for practical implementation, called dually robust actor-critic
(DRAC). The evaluations with safety-critical benchmarks demonstrate that DRAC
achieves high performance and persistent safety under all scenarios (no
adversary, safety adversary, performance adversary), outperforming all
baselines significantly.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06837" title="Abstract">arXiv:2309.06837</a> [<a href="/pdf/2309.06837" title="Download PDF">pdf</a>, <a href="/format/2309.06837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Optimal Gate-Traversing Planner for Autonomous Drone Racing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+C">Chao Qin</a>, 
<a href="/search/cs?searchtype=author&query=Michet%2C+M+S+J">Maxime S.J. Michet</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H+H+-">Hugh H.-T. Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Time-minimum trajectories through race tracks are determined by the drone's
capability as well as the configuration of all gates (e.g., their shapes,
sizes, and orientations). However, prior works neglect the impact of the gate
configuration and formulate drone racing as a waypoint flight task, leading to
conservative waypoint selection through each gate. We present a novel
time-optimal planner that can account for gate constraints explicitly, enabling
quadrotors to follow the most time-efficient waypoints at their
single-rotor-thrust limits in tracks with hybrid gate types. Our approach
provides comparable solution quality to the state-of-the-art but with a
computation time orders of magnitude faster. Furthermore, the proposed
framework allows users to customize gate constraints such as tunnels by
concatenating existing gate classes, enabling high-fidelity race track
modeling. Owing to the superior computation efficiency and flexibility, we can
generate optimal racing trajectories for complex race tracks with tens or even
hundreds of gates with distinct shapes. We validate our method in real-world
flights and demonstrate that faster lap times can be produced by using gate
constraints instead of waypoint constraints.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06838" title="Abstract">arXiv:2309.06838</a> [<a href="/pdf/2309.06838" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Machine Learning and Physics based Machine Learning approach  for prediction of peak temperature distribution in Additive Friction Stir  Deposition of Aluminium Alloy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+A">Akshansh Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Additive friction stir deposition (AFSD) is a novel solid-state additive
manufacturing technique that circumvents issues of porosity, cracking, and
properties anisotropy that plague traditional powder bed fusion and directed
energy deposition approaches. However, correlations between process parameters,
thermal profiles, and resulting microstructure in AFSD remain poorly
understood. This hinders process optimization for properties. This work employs
a cutting-edge framework combining supervised machine learning (SML) and
physics-informed neural networks (PINNs) to predict peak temperature
distribution in AFSD from process parameters. Eight regression algorithms were
implemented for SML modeling, while four PINNs leveraged governing equations
for transport, wave propagation, heat transfer, and quantum mechanics. Across
multiple statistical measures, ensemble techniques like gradient boosting
proved superior for SML, with lowest MSE of 165.78. The integrated ML approach
was also applied to classify deposition quality from process factors, with
logistic regression delivering robust accuracy. By fusing data-driven learning
and fundamental physics, this dual methodology provides comprehensive insights
into tailoring microstructure through thermal management in AFSD. The work
demonstrates the power of bridging statistical and physics-based modeling for
elucidating AM process-property relationships.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06840" title="Abstract">arXiv:2309.06840</a> [<a href="/pdf/2309.06840" title="Download PDF">pdf</a>, <a href="/ps/2309.06840" title="Download PostScript">ps</a>, <a href="/format/2309.06840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolic Path-guided Test Cases for Models with Data and Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bannour%2C+B">Boutheina Bannour</a>, 
<a href="/search/cs?searchtype=author&query=Lapitre%2C+A">Arnault Lapitre</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+P+L">Pascale Le Gall</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Thang Nguyen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">This paper focuses on generating test cases from timed symbolic transition
systems. At the heart of the generation process are symbolic execution
techniques on data and time. Test cases look like finite symbolic trees with
verdicts on their leaves and are based on a user-specified finite symbolic path
playing the role of a test purpose. Generated test cases handle data involved
in time constraints and uninitialized parameters, leveraging the advantages of
symbolic execution techniques.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06841" title="Abstract">arXiv:2309.06841</a> [<a href="/pdf/2309.06841" title="Download PDF">pdf</a>, <a href="/ps/2309.06841" title="Download PostScript">ps</a>, <a href="/format/2309.06841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Local Quadratic Stability of T-S Fuzzy Systems in the Vicinity of  the Origin
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Donghwan Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+D+W">Do Wan Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The main goal of this paper is to introduce new local stability conditions
for continuous-time Takagi-Sugeno (T-S) fuzzy systems. These stability
conditions are based on linear matrix inequalities (LMIs) in combination with
quadratic Lyapunov functions. Moreover, they integrate information on the
membership functions at the origin and effectively leverage the linear
structure of the underlying nonlinear system in the vicinity of the origin. As
a result, the proposed conditions are proved to be less conservative compared
to existing methods using fuzzy Lyapunov functions in the literature. Moreover,
we establish that the proposed methods offer necessary and sufficient
conditions for the local exponential stability of T-S fuzzy systems. The paper
also includes discussions on the inherent limitations associated with fuzzy
Lyapunov approaches. To demonstrate the theoretical results, we provide
comprehensive examples that elucidate the core concepts and validate the
efficacy of the proposed conditions.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06843" title="Abstract">arXiv:2309.06843</a> [<a href="/pdf/2309.06843" title="Download PDF">pdf</a>, <a href="/format/2309.06843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stepwise Model Reconstruction of Robotic Manipulator Based on  Data-Driven Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dingxu Guo</a>, 
<a href="/search/cs?searchtype=author&query=xu%2C+J">Jian xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Research on dynamics of robotic manipulators provides promising support for
model-based control. In general, rigorous first-principles-based dynamics
modeling and accurate identification of mechanism parameters are critical to
achieving high precision in model-based control, while data-driven model
reconstruction provides alternative approaches of the above process. Taking the
level of activation of data as an indicator, this paper classifies the
collected robotic manipulator data by means of K-means clustering algorithm.
With the fundamental prior knowledge, we find the corresponding dynamical
properties behind the classified data separately. Afterwards, the sparse
identification of nonlinear dynamics (SINDy) method is used to reconstruct the
dynamics model of the robotic manipulator step by step according to the
activation level of the classified data. The simulation results show that the
proposed method not only reduces the complexity of the basis function library,
enabling the application of SINDy method to multi-degree-of-freedom robotic
manipulators, but also decreases the influence of data noise on the regression
results. Finally, the dynamic control based on the reconfigured model is
deployed on the experimental platform, and the experimental results prove the
effectiveness of the proposed method.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06844" title="Abstract">arXiv:2309.06844</a> [<a href="/pdf/2309.06844" title="Download PDF">pdf</a>, <a href="/format/2309.06844" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for  Subjectivity Detection in News Articles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pachov%2C+G">Georgi Pachov</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrov%2C+D">Dimitar Dimitrov</a>, 
<a href="/search/cs?searchtype=author&query=Koychev%2C+I">Ivan Koychev</a>, 
<a href="/search/cs?searchtype=author&query=Nakov%2C+P">Preslav Nakov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The wide-spread use of social networks has given rise to subjective,
misleading, and even false information on the Internet. Thus, subjectivity
detection can play an important role in ensuring the objectiveness and the
quality of a piece of information. This paper presents the solution built by
the Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity
detection. Three different research directions are explored. The first one is
based on fine-tuning a sentence embeddings encoder model and dimensionality
reduction. The second one explores a sample-efficient few-shot learning model.
The third one evaluates fine-tuning a multilingual transformer on an altered
dataset, using data from multiple languages. Finally, the three approaches are
combined in a simple majority voting ensemble, resulting in 0.77 macro F1 on
the test set and achieving 2nd place on the English subtask.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06847" title="Abstract">arXiv:2309.06847</a> [<a href="/pdf/2309.06847" title="Download PDF">pdf</a>, <a href="/ps/2309.06847" title="Download PostScript">ps</a>, <a href="/format/2309.06847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undetectable Selfish Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahrani%2C+M">Maryam Bahrani</a>, 
<a href="/search/cs?searchtype=author&query=Weinberg%2C+S+M">S. Matthew Weinberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Seminal work of Eyal and Sirer (2014) establishes that a strategic Bitcoin
miner may strictly profit by deviating from the intended Bitcoin protocol,
using a strategy now termed *selfish mining*. More specifically, any miner with
$&gt;1/3$ of the total hashrate can earn bitcoin at a faster rate by selfish
mining than by following the intended protocol (depending on network
conditions, a lower fraction of hashrate may also suffice).
<br />One convincing critique of selfish mining in practice is that the presence of
a selfish miner is *statistically detectable*: the pattern of orphaned blocks
created by the presence of a selfish miner cannot be explained by natural
network delays. Therefore, if an attacker chooses to selfish mine, users can
detect this, and this may (significantly) negatively impact the value of BTC.
So while the attacker may get slightly more bitcoin by selfish mining, these
bitcoin may be worth significantly less USD.
<br />We develop a selfish mining variant that is provably *statistically
undetectable*: the pattern of orphaned blocks is statistically identical to a
world with only honest miners but higher network delay. Specifically, we
consider a stylized model where honest miners with network delay produce
orphaned blocks at each height independently with probability $\beta'$. We
propose a selfish mining strategy that instead produces orphaned blocks at each
height independently with probability $\beta &gt; \beta'$. We further show that
our strategy is strictly profitable for attackers with $38.2\% \ll 50\%$ of the
total hashrate (and this holds for all natural orphan rates $\beta'$).
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06849" title="Abstract">arXiv:2309.06849</a> [<a href="/pdf/2309.06849" title="Download PDF">pdf</a>, <a href="/format/2309.06849" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiplexed Streaming Codes for Messages With Different Decoding Delays  in Channel with Burst and Random Erasures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+D">Dingli Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiquan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhongyi Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In a real-time transmission scenario, messages are transmitted through a
channel that is subject to packet loss. The destination must recover the
messages within the required deadline. In this paper, we consider a setup where
two different types of messages with distinct decoding deadlines are
transmitted through a channel that can introduce burst erasures of a length at
most $B$, or $N$ random erasures. The message with a short decoding deadline
$T_u$ is referred to as an urgent message, while the other one with a decoding
deadline $T_v$ ($T_v &gt; T_u$) is referred to as a less urgent message.
<br />We propose a merging method to encode two message streams of different
urgency levels into a single flow. We consider the scenario where $T_v &gt; T_u +
B$. We establish that any coding strategy based on this merging approach has a
closed-form upper limit on its achievable sum rate. Moreover, we present
explicit constructions within a finite field that scales quadratically with the
imposed delay, ensuring adherence to the upper bound. In a given parameter
configuration, we rigorously demonstrate that the sum rate of our proposed
streaming codes consistently surpasses that of separate encoding, which serves
as a baseline for comparison.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06851" title="Abstract">arXiv:2309.06851</a> [<a href="/pdf/2309.06851" title="Download PDF">pdf</a>, <a href="/format/2309.06851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Wearable Ultra-Low-Power sEMG-Triggered Ultrasound System for  Long-Term Muscle Activity Monitoring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Frey%2C+S">Sebastian Frey</a>, 
<a href="/search/eess?searchtype=author&query=Kartsch%2C+V">Victor Kartsch</a>, 
<a href="/search/eess?searchtype=author&query=Leitner%2C+C">Christoph Leitner</a>, 
<a href="/search/eess?searchtype=author&query=Cossettini%2C+A">Andrea Cossettini</a>, 
<a href="/search/eess?searchtype=author&query=Vostrikov%2C+S">Sergei Vostrikov</a>, 
<a href="/search/eess?searchtype=author&query=Benatti%2C+S">Simone Benatti</a>, 
<a href="/search/eess?searchtype=author&query=Benini%2C+L">Luca Benini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 5 figures, 1 table, 2023 IEEE International Ultrasonics Symposium
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Wearable biosignal processing applications are driving significant progress
toward miniaturized, energy-efficient Internet-of-Things solutions for both
clinical and consumer applications. However, scaling toward high-density
multi-channel front-ends is only feasible by performing data processing and
\ac{ML} near-sensor through energy-efficient edge processing. To tackle these
challenges, we introduce BioGAP, a novel, compact, modular, and lightweight
(6g) medical-grade biosignal acquisition and processing platform powered by
GAP9, a ten-core ultra-low-power SoC designed for efficient multi-precision
(from FP to aggressively quantized integer) processing, as required for
advanced ML and DSP. BioGAP's form factor is 16x21x14~mm$^3$ and comprises two
stacked PCBs: a baseboard integrating the GAP9 SoC, a wireless \ac{BLE} capable
SoC, a power management circuit, and an accelerometer; and a shield including
an \ac{AFE} for ExG acquisition. Finally, the system also includes a flexibly
placeable \ac{PPG} PCB with a size of 9x7x3~mm$^3$ and a rechargeable battery
($\phi$ 12x5~mm$^2$). We demonstrate BioGAP on a \ac{SSVEP}-based \ac{BCI}
application. We achieve 3.6~$\mu J/sample$ in streaming and 2.2~$\mu J/sample$
in onboard processing mode, thanks to an efficiency on the FFT computation task
of 16.7~Mflops/s/mW with wireless bandwidth reduction of 97\%, within a power
budget of just 18.2~mW allowing for an operation time of 15~h.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06858" title="Abstract">arXiv:2309.06858</a> [<a href="/pdf/2309.06858" title="Download PDF">pdf</a>, <a href="/format/2309.06858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EMALG: An Enhanced Mandarin Lombard Grid Corpus with Meaningful  Sentences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baifeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qingmu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuhong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+W">Weiping Tu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Song Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This study investigates the Lombard effect, where individuals adapt their
speech in noisy environments. We introduce an enhanced Mandarin Lombard grid
(EMALG) corpus with meaningful sentences , enhancing the Mandarin Lombard grid
(MALG) corpus. EMALG features 34 speakers and improves recording setups,
addressing challenges faced by MALG with nonsense sentences. Our findings
reveal that in Mandarin, female exhibit a more pronounced Lombard effect than
male, particularly when uttering meaningful sentences. Additionally, we uncover
that nonsense sentences negatively impact Lombard effect analysis. Moreover,
our results reaffirm the consistency in the Lombard effect comparison between
English and Mandarin found in previous research.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06859" title="Abstract">arXiv:2309.06859</a> [<a href="/pdf/2309.06859" title="Download PDF">pdf</a>, <a href="/format/2309.06859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal information in Bayesian routing games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cianfanelli%2C+L">Leonardo Cianfanelli</a>, 
<a href="/search/cs?searchtype=author&query=Ambrogio%2C+A">Alexia Ambrogio</a>, 
<a href="/search/cs?searchtype=author&query=Como%2C+G">Giacomo Como</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures. Full version of accepted paper for the 2023 62th IEEE Conference on Decision and Control (CDC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">We study optimal information provision in transportation networks when users
are strategic and the network state is uncertain. An omniscient planner
observes the network state and discloses information to the users with the goal
of minimizing the expected travel time at the user equilibrium. Public signal
policies, including full-information disclosure, are known to be inefficient in
achieving optimality. For this reason, we focus on private signals and restrict
without loss of generality the analysis to signals that coincide with path
recommendations that satisfy obedience constraints, namely users have no
incentive in deviating from the received recommendation according to their
posterior belief. We first formulate the general problem and analyze its
properties for arbitrary network topologies and delay functions. Then, we
consider the case of two parallel links with affine delay functions, and
provide sufficient conditions under which optimality can be achieved by
information design. Interestingly, we observe that the system benefits from
uncertainty, namely it is easier for the planner to achieve optimality when the
variance of the uncertain parameters is large. We then provide an example where
optimality can be achieved even if the sufficient conditions for optimality are
not met.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06861" title="Abstract">arXiv:2309.06861</a> [<a href="/pdf/2309.06861" title="Download PDF">pdf</a>, <a href="/format/2309.06861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TTD Configurations for Near-Field Beamforming: Parallel, Serial, or  Hybrid?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaolin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+X">Xidong Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuanwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Schober%2C+R">Robert Schober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">True-time delayers (TTDs) are popular components for hybrid beamforming
architectures to combat the spatial-wideband effect in wideband near-field
communications. A serial and a hybrid serial-parallel TTD configuration are
investigated for hybrid beamforming architectures. Compared to the conventional
parallel configuration, the serial configuration exhibits a cumulative time
delay through multiple TTDs, which potentially alleviates the maximum delay
requirements on the TTDs. However, independent control of individual TTDs
becomes impossible in the serial configuration. In this context, a hybrid TTD
configuration is proposed as a compromise solution. Furthermore, a power
equalization approach is proposed to address the cumulative insertion loss of
the serial and hybrid TTD configurations. Moreover, the wideband near-field
beamforming design for different configurations is studied for maximizing the
spectral efficiency in both single-user and multiple-user systems. 1) For
single-user systems, a closed-form solution for the beamforming design is
derived. The preferred user locations and the required maximum time delay of
each TTD configuration are characterized. 2) For multi-user systems, a
penalty-based iterative algorithm is developed to obtain a stationary point of
the spectral efficiency maximization problem for each TTD configuration. In
addition, a mixed-forward-and-backward (MFB) implementation is proposed to
enhance the performance of the serial configuration. Our numerical results
confirm the effectiveness of the proposed designs and unveil that i) compared
to the conventional parallel configuration, both the serial and hybrid
configurations can significantly reduce the maximum time delays required for
the TTDs and ii) the hybrid configuration excels in single-user systems, while
the serial configuration is preferred in multi-user systems.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06862" title="Abstract">arXiv:2309.06862</a> [<a href="/pdf/2309.06862" title="Download PDF">pdf</a>, <a href="/format/2309.06862" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain decomposition method for Poisson--Boltzmann equations based on  Solvent Excluded Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jha%2C+A">Abhinav Jha</a>, 
<a href="/search/math?searchtype=author&query=Stamm%2C+B">Benjamin Stamm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Number Theory (math.NT)

</div>
<p class="mathjax">In this paper, we develop a domain-decomposition method for the generalized
Poisson-Boltzmann equation based on a solvent-excluded surface which is widely
used in computational chemistry. The solver requires to solve a generalized
screened Poisson (GSP) equation defined in $\mathbb{R}^3$ with a
space-dependent dielectric permittivity and an ion-exclusion function that
accounts for Steric effects. Potential theory arguments transform the GSP
equation into two-coupled equations defined in a bounded domain. Then, the
Schwarz decomposition method is used to formulate local problems by decomposing
the cavity into overlapping balls and only solving a set of coupled
sub-equations in each ball in which, the spherical harmonics and the Legendre
polynomials are used as basis functions in the angular and radial directions. A
series of numerical experiments are presented to test the method.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06863" title="Abstract">arXiv:2309.06863</a> [<a href="/pdf/2309.06863" title="Download PDF">pdf</a>, <a href="/format/2309.06863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lavender Autonomous Navigation with Semantic Segmentation at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navone%2C+A">Alessandro Navone</a>, 
<a href="/search/cs?searchtype=author&query=Romanelli%2C+F">Fabrizio Romanelli</a>, 
<a href="/search/cs?searchtype=author&query=Ambrosio%2C+M">Marco Ambrosio</a>, 
<a href="/search/cs?searchtype=author&query=Martini%2C+M">Mauro Martini</a>, 
<a href="/search/cs?searchtype=author&query=Angarano%2C+S">Simone Angarano</a>, 
<a href="/search/cs?searchtype=author&query=Chiaberge%2C+M">Marcello Chiaberge</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Achieving success in agricultural activities heavily relies on precise
navigation in row crop fields. Recently, segmentation-based navigation has
emerged as a reliable technique when GPS-based localization is unavailable or
higher accuracy is needed due to vegetation or unfavorable weather conditions.
It also comes in handy when plants are growing rapidly and require an online
adaptation of the navigation algorithm. This work applies a segmentation-based
visual agnostic navigation algorithm to lavender fields, considering both
simulation and real-world scenarios. The effectiveness of this approach is
validated through a wide set of experimental tests, which show the capability
of the proposed solution to generalize over different scenarios and provide
highly-reliable results.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06865" title="Abstract">arXiv:2309.06865</a> [<a href="/pdf/2309.06865" title="Download PDF">pdf</a>, <a href="/format/2309.06865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Short reasons for long vectors in HPC CPUs: a study based on RISC-V
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vizcaino%2C+P">Pablo Vizcaino</a>, 
<a href="/search/cs?searchtype=author&query=Ieronymakis%2C+G">Georgios Ieronymakis</a>, 
<a href="/search/cs?searchtype=author&query=Dimou%2C+N">Nikolaos Dimou</a>, 
<a href="/search/cs?searchtype=author&query=Papaefstathiou%2C+V">Vassilis Papaefstathiou</a>, 
<a href="/search/cs?searchtype=author&query=Labarta%2C+J">Jesus Labarta</a>, 
<a href="/search/cs?searchtype=author&query=Mantovani%2C+F">Filippo Mantovani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as paper at the Second RISC-V Workshops at SC23 - Denver
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">For years, SIMD/vector units have enhanced the capabilities of modern CPUs in
High-Performance Computing (HPC) and mobile technology. Typical
commercially-available SIMD units process up to 8 double-precision elements
with one instruction. The optimal vector width and its impact on CPU throughput
due to memory latency and bandwidth remain challenging research areas. This
study examines the behavior of four computational kernels on a RISC-V core
connected to a customizable vector unit, capable of operating up to 256 double
precision elements per instruction. The four codes have been purposefully
selected to represent non-dense workloads: SpMV, BFS, PageRank, FFT. The
experimental setup allows us to measure their performance while varying the
vector length, the memory latency, and bandwidth. Our results not only show
that larger vector lengths allow for better tolerance of limitations in the
memory subsystem but also offer hope to code developers beyond dense linear
algebra.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06867" title="Abstract">arXiv:2309.06867</a> [<a href="/pdf/2309.06867" title="Download PDF">pdf</a>, <a href="/format/2309.06867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness for Spectral Clustering of General Graphs under Local  Differential Privacy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+S">Sayan Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Suppakitpaisarn%2C+V">Vorapong Suppakitpaisarn</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Spectral clustering is a widely used algorithm to find clusters in networks.
Several researchers have studied the stability of spectral clustering under
local differential privacy with the additional assumption that the underlying
networks are generated from the stochastic block model (SBM). However, we argue
that this assumption is too restrictive since social networks do not originate
from the SBM. Thus, delve into an analysis for general graphs in this work. Our
primary focus is the edge flipping method -- a common technique for protecting
local differential privacy. On a positive side, our findings suggest that even
when the edges of an $n$-vertex graph satisfying some reasonable
well-clustering assumptions are flipped with a probability of $O(\log n/n)$,
the clustering outcomes are largely consistent. Empirical tests further
corroborate these theoretical findings. Conversely, although clustering
outcomes have been stable for dense and well-clustered graphs produced from the
SBM, we show that in general, spectral clustering may yield highly erratic
results on certain dense and well-clustered graphs when the flipping
probability is $\omega(\log n/n)$. This indicates that the best privacy budget
obtainable for general graphs is $\Theta(\log n)$.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06873" title="Abstract">arXiv:2309.06873</a> [<a href="/pdf/2309.06873" title="Download PDF">pdf</a>, <a href="/format/2309.06873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Connecting Control to Perception: High-Performance Whole-Body  Collision Avoidance Using Control-Compatible Obstacles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eckhoff%2C+M">Moritz Eckhoff</a>, 
<a href="/search/cs?searchtype=author&query=Knobbe%2C+D">Dennis Knobbe</a>, 
<a href="/search/cs?searchtype=author&query=Zwirnmann%2C+H">Henning Zwirnmann</a>, 
<a href="/search/cs?searchtype=author&query=Swikir%2C+A">Abdalla Swikir</a>, 
<a href="/search/cs?searchtype=author&query=Haddadin%2C+S">Sami Haddadin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">One of the most important aspects of autonomous systems is safety. This
includes ensuring safe human-robot and safe robot-environment interaction when
autonomously performing complex tasks or in collaborative scenarios. Although
several methods have been introduced to tackle this, most are unsuitable for
real-time applications and require carefully hand-crafted obstacle
descriptions. In this work, we propose a method combining high-frequency and
real-time self and environment collision avoidance of a robotic manipulator
with low-frequency, multimodal, and high-resolution environmental perceptions
accumulated in a digital twin system. Our method is based on geometric
primitives, so-called primitive skeletons. These, in turn, are
information-compressed and real-time compatible digital representations of the
robot's body and environment, automatically generated from ultra-realistic
virtual replicas of the real world provided by the digital twin. Our approach
is a key enabler for closing the loop between environment perception and robot
control by providing the millisecond real-time control stage with a current and
accurate world description, empowering it to react to environmental changes. We
evaluate our whole-body collision avoidance on a 9-DOFs robot system through
five experiments, demonstrating the functionality and efficiency of our
framework.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06877" title="Abstract">arXiv:2309.06877</a> [<a href="/pdf/2309.06877" title="Download PDF">pdf</a>, <a href="/format/2309.06877" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Infringement Detection via Feature Disentanglement and Mutual  Information Maximization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhenguang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinyang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Ruili Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuai Ye</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Zhe Ma</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jianfeng Dong</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Sifeng He</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+F">Feng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaobo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Lei Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is accepted by ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">The self-media era provides us tremendous high quality videos. Unfortunately,
frequent video copyright infringements are now seriously damaging the interests
and enthusiasm of video creators. Identifying infringing videos is therefore a
compelling task. Current state-of-the-art methods tend to simply feed
high-dimensional mixed video features into deep neural networks and count on
the networks to extract useful representations. Despite its simplicity, this
paradigm heavily relies on the original entangled features and lacks
constraints guaranteeing that useful task-relevant semantics are extracted from
the features.
<br />In this paper, we seek to tackle the above challenges from two aspects: (1)
We propose to disentangle an original high-dimensional feature into multiple
sub-features, explicitly disentangling the feature into exclusive
lower-dimensional components. We expect the sub-features to encode
non-overlapping semantics of the original feature and remove redundant
information.
<br />(2) On top of the disentangled sub-features, we further learn an auxiliary
feature to enhance the sub-features. We theoretically analyzed the mutual
information between the label and the disentangled features, arriving at a loss
that maximizes the extraction of task-relevant information from the original
feature.
<br />Extensive experiments on two large-scale benchmark datasets (i.e., SVD and
VCSL) demonstrate that our method achieves 90.1% TOP-100 mAP on the large-scale
SVD dataset and also sets the new state-of-the-art on the VCSL benchmark
dataset. Our code and model have been released at
https://github.com/yyyooooo/DMI/, hoping to contribute to the community.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06882" title="Abstract">arXiv:2309.06882</a> [<a href="/pdf/2309.06882" title="Download PDF">pdf</a>, <a href="/format/2309.06882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ProMap: Datasets for Product Mapping in E-commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mackov%C3%A1%2C+K">Kate&#x159;ina Mackov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Pil%C3%A1t%2C+M">Martin Pil&#xe1;t</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)

</div>
<p class="mathjax">The goal of product mapping is to decide, whether two listings from two
different e-shops describe the same products. Existing datasets of matching and
non-matching pairs of products, however, often suffer from incomplete product
information or contain only very distant non-matching products. Therefore,
while predictive models trained on these datasets achieve good results on them,
in practice, they are unusable as they cannot distinguish very similar but
non-matching pairs of products. This paper introduces two new datasets for
product mapping: ProMapCz consisting of 1,495 Czech product pairs and ProMapEn
consisting of 1,555 English product pairs of matching and non-matching products
manually scraped from two pairs of e-shops. The datasets contain both images
and textual descriptions of the products, including their specifications,
making them one of the most complete datasets for product mapping.
Additionally, the non-matching products were selected in two phases, creating
two types of non-matches -- close non-matches and medium non-matches. Even the
medium non-matches are pairs of products that are much more similar than
non-matches in other datasets -- for example, they still need to have the same
brand and similar name and price. After simple data preprocessing, several
machine learning algorithms were trained on these and two the other datasets to
demonstrate the complexity and completeness of ProMap datasets. ProMap datasets
are presented as a golden standard for further research of product mapping
filling the gaps in existing ones.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06884" title="Abstract">arXiv:2309.06884</a> [<a href="/pdf/2309.06884" title="Download PDF">pdf</a>, <a href="/format/2309.06884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Manufacturing Quality Control with Autoencoder-Based Defect Localization  and Unsupervised Class Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mehta%2C+D">Devang Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Klarmann%2C+N">Noah Klarmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Manufacturing industries require efficient and voluminous production of
high-quality finished goods. In the context of Industry 4.0, visual anomaly
detection poses an optimistic solution for automatically controlling product
quality with high precision. Automation based on computer vision poses a
promising solution to prevent bottlenecks at the product quality checkpoint. We
considered recent advancements in machine learning to improve visual defect
localization, but challenges persist in obtaining a balanced feature set and
database of the wide variety of defects occurring in the production line. This
paper proposes a defect localizing autoencoder with unsupervised class
selection by clustering with k-means the features extracted from a pre-trained
VGG-16 network. The selected classes of defects are augmented with natural wild
textures to simulate artificial defects. The study demonstrates the
effectiveness of the defect localizing autoencoder with unsupervised class
selection for improving defect detection in manufacturing industries. The
proposed methodology shows promising results with precise and accurate
localization of quality defects on melamine-faced boards for the furniture
industry. Incorporating artificial defects into the training data shows
significant potential for practical implementation in real-world quality
control scenarios.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06887" title="Abstract">arXiv:2309.06887</a> [<a href="/pdf/2309.06887" title="Download PDF">pdf</a>, <a href="/format/2309.06887" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utilizing Hybrid Trajectory Prediction Models to Recognize Highly  Interactive Traffic Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zipfl%2C+M">Maximilian Zipfl</a>, 
<a href="/search/cs?searchtype=author&query=Spickermann%2C+S">Sven Spickermann</a>, 
<a href="/search/cs?searchtype=author&query=Z%C3%B6llner%2C+J+M">J. Marius Z&#xf6;llner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous vehicles hold great promise in improving the future of
transportation. The driving models used in these vehicles are based on neural
networks, which can be difficult to validate. However, ensuring the safety of
these models is crucial. Traditional field tests can be costly, time-consuming,
and dangerous. To address these issues, scenario-based closed-loop simulations
can simulate many hours of vehicle operation in a shorter amount of time and
allow for specific investigation of important situations. Nonetheless, the
detection of relevant traffic scenarios that also offer substantial testing
benefits remains a significant challenge. To address this need, in this paper
we build an imitation learning based trajectory prediction for traffic
participants. We combine an image-based (CNN) approach to represent spatial
environmental factors and a graph-based (GNN) approach to specifically
represent relations between traffic participants. In our understanding, traffic
scenes that are highly interactive due to the network's significant utilization
of the social component are more pertinent for a validation process. Therefore,
we propose to use the activity of such sub networks as a measure of
interactivity of a traffic scene. We evaluate our model using a motion dataset
and discuss the value of the relationship information with respect to different
traffic situations.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06888" title="Abstract">arXiv:2309.06888</a> [<a href="/pdf/2309.06888" title="Download PDF">pdf</a>, <a href="/format/2309.06888" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OWL Reasoners still useable in 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abicht%2C+K">Konrad Abicht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">In a systematic literature and software review over 100 OWL reasoners/systems
were analyzed to see if they would still be usable in 2023. This has never been
done in this capacity. OWL reasoners still play an important role in knowledge
organisation and management, but the last comprehensive surveys/studies are
more than 8 years old. The result of this work is a comprehensive list of 95
standalone OWL reasoners and systems using an OWL reasoner. For each item,
information on project pages, source code repositories and related
documentation was gathered. The raw research data is provided in a Github
repository for anyone to use.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06891" title="Abstract">arXiv:2309.06891</a> [<a href="/pdf/2309.06891" title="Download PDF">pdf</a>, <a href="/format/2309.06891" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep It SimPool: Who Said Supervised Transformers Suffer from Attention  Deficit?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psomas%2C+B">Bill Psomas</a>, 
<a href="/search/cs?searchtype=author&query=Kakogeorgiou%2C+I">Ioannis Kakogeorgiou</a>, 
<a href="/search/cs?searchtype=author&query=Karantzalos%2C+K">Konstantinos Karantzalos</a>, 
<a href="/search/cs?searchtype=author&query=Avrithis%2C+Y">Yannis Avrithis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Code and models: <a href="https://github.com/billpsomas/simpool">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Conference on Computer Vision (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Convolutional networks and vision transformers have different forms of
pairwise interactions, pooling across layers and pooling at the end of the
network. Does the latter really need to be different? As a by-product of
pooling, vision transformers provide spatial attention for free, but this is
most often of low quality unless self-supervised, which is not well studied. Is
supervision really the problem?
<br />In this work, we develop a generic pooling framework and then we formulate a
number of existing methods as instantiations. By discussing the properties of
each group of methods, we derive SimPool, a simple attention-based pooling
mechanism as a replacement of the default one for both convolutional and
transformer encoders. We find that, whether supervised or self-supervised, this
improves performance on pre-training and downstream tasks and provides
attention maps delineating object boundaries in all cases. One could thus call
SimPool universal. To our knowledge, we are the first to obtain attention maps
in supervised transformers of at least as good quality as self-supervised,
without explicit losses or modifying the architecture. Code at:
https://github.com/billpsomas/simpool.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06895" title="Abstract">arXiv:2309.06895</a> [<a href="/pdf/2309.06895" title="Download PDF">pdf</a>, <a href="/format/2309.06895" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MagiCapture: High-Resolution Multi-Concept Portrait Customization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hyung%2C+J">Junha Hyung</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jaeyo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large-scale text-to-image models including Stable Diffusion are capable of
generating high-fidelity photorealistic portrait images. There is an active
research area dedicated to personalizing these models, aiming to synthesize
specific subjects or styles using provided sets of reference images. However,
despite the plausible results from these personalization methods, they tend to
produce images that often fall short of realism and are not yet on a
commercially viable level. This is particularly noticeable in portrait image
generation, where any unnatural artifact in human faces is easily discernible
due to our inherent human bias. To address this, we introduce MagiCapture, a
personalization method for integrating subject and style concepts to generate
high-resolution portrait images using just a few subject and style references.
For instance, given a handful of random selfies, our fine-tuned model can
generate high-quality portrait images in specific styles, such as passport or
profile photos. The main challenge with this task is the absence of ground
truth for the composed concepts, leading to a reduction in the quality of the
final output and an identity shift of the source subject. To address these
issues, we present a novel Attention Refocusing loss coupled with auxiliary
priors, both of which facilitate robust learning within this weakly supervised
learning setting. Our pipeline also includes additional post-processing steps
to ensure the creation of highly realistic outputs. MagiCapture outperforms
other baselines in both quantitative and qualitative evaluations and can also
be generalized to other non-human objects.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06896" title="Abstract">arXiv:2309.06896</a> [<a href="/pdf/2309.06896" title="Download PDF">pdf</a>, <a href="/format/2309.06896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Domain-Aware Augmentations for Unsupervised Online General Continual  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Michel%2C+N">Nicolas Michel</a>, 
<a href="/search/cs?searchtype=author&query=Negrel%2C+R">Romain Negrel</a>, 
<a href="/search/cs?searchtype=author&query=Chierchia%2C+G">Giovanni Chierchia</a>, 
<a href="/search/cs?searchtype=author&query=Bercher%2C+J">Jean-Fran&#xe7;ois Bercher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Continual Learning has been challenging, especially when dealing with
unsupervised scenarios such as Unsupervised Online General Continual Learning
(UOGCL), where the learning agent has no prior knowledge of class boundaries or
task change information. While previous research has focused on reducing
forgetting in supervised setups, recent studies have shown that self-supervised
learners are more resilient to forgetting. This paper proposes a novel approach
that enhances memory usage for contrastive learning in UOGCL by defining and
using stream-dependent data augmentations together with some implementation
tricks. Our proposed method is simple yet effective, achieves state-of-the-art
results compared to other unsupervised approaches in all considered setups, and
reduces the gap between supervised and unsupervised continual learning. Our
domain-aware augmentation procedure can be adapted to other replay-based
methods, making it a promising strategy for continual learning.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06902" title="Abstract">arXiv:2309.06902</a> [<a href="/pdf/2309.06902" title="Download PDF">pdf</a>, <a href="/format/2309.06902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCSPNet-Joint: Efficient Joint Training Method for Traffic Sihn  Detection Under Extreme Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Haoqin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+X">Xiangyu Shu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiangfang Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Traffic sign detection is an important research direction in intelligent
driving. Unfortunately, existing methods often overlook extreme conditions such
as fog, rain, and motion blur. Moreover, the end-to-end training strategy for
image denoising and object detection models fails to utilize inter-model
information effectively. To address these issues, we propose CCSPNet, an
efficient feature extraction module based on Transformers and CNNs, which
effectively leverages contextual information, achieves faster inference speed
and provides stronger feature enhancement capabilities. Furthermore, we
establish the correlation between object detection and image denoising tasks
and propose a joint training model, CCSPNet-Joint, to improve data efficiency
and generalization. Finally, to validate our approach, we create the CCTSDB-AUG
dataset for traffic sign detection in extreme scenarios. Extensive experiments
have shown that CCSPNet achieves state-of-the-art performance in traffic sign
detection under extreme conditions. Compared to end-to-end methods,
CCSPNet-Joint achieves a 5.32% improvement in precision and an 18.09%
improvement in mAP@.5.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06908" title="Abstract">arXiv:2309.06908</a> [<a href="/pdf/2309.06908" title="Download PDF">pdf</a>, <a href="/format/2309.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards the TopMost: A Topic Modeling System Toolkit
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaobao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+F">Fengjun Pan</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Topic models have been proposed for decades with various applications and
recently refreshed by the neural variational inference. However, these topic
models adopt totally distinct dataset, implementation, and evaluation settings,
which hinders their quick utilization and fair comparisons. This greatly
hinders the research progress of topic models. To address these issues, in this
paper we propose a Topic Modeling System Toolkit (TopMost). Compared to
existing toolkits, TopMost stands out by covering a wider range of topic
modeling scenarios including complete lifecycles with dataset pre-processing,
model training, testing, and evaluations. The highly cohesive and decoupled
modular design of TopMost enables quick utilization, fair comparisons, and
flexible extensions of different topic models. This can facilitate the research
and applications of topic models. Our code, tutorials, and documentation are
available at https://github.com/bobxwu/topmost.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06912" title="Abstract">arXiv:2309.06912</a> [<a href="/pdf/2309.06912" title="Download PDF">pdf</a>, <a href="/format/2309.06912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-behavior Recommendation with SVD Graph Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+S">Shengxi Fu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Q">Qianqian Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Graph Neural Networks (GNNs) has been extensively employed in the field of
recommender systems, offering users personalized recommendations and yielding
remarkable outcomes. Recently, GNNs incorporating contrastive learning have
demonstrated promising performance in handling sparse data problem of
recommendation system. However, existing contrastive learning methods still
have limitations in addressing the cold-start problem and resisting noise
interference especially for multi-behavior recommendation. To mitigate the
aforementioned issues, the present research posits a GNNs based multi-behavior
recommendation model MB-SVD that utilizes Singular Value Decomposition (SVD)
graphs to enhance model performance. In particular, MB-SVD considers user
preferences under different behaviors, improving recommendation effectiveness
while better addressing the cold-start problem. Our model introduces an
innovative methodology, which subsume multi-behavior contrastive learning
paradigm to proficiently discern the intricate interconnections among
heterogeneous manifestations of user behavior and generates SVD graphs to
automate the distillation of crucial multi-behavior self-supervised information
for robust graph augmentation. Furthermore, the SVD based framework reduces the
embedding dimensions and computational load. Thorough experimentation showcases
the remarkable performance of our proposed MB-SVD approach in multi-behavior
recommendation endeavors across diverse real-world datasets.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06913" title="Abstract">arXiv:2309.06913</a> [<a href="/pdf/2309.06913" title="Download PDF">pdf</a>, <a href="/ps/2309.06913" title="Download PostScript">ps</a>, <a href="/format/2309.06913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Distributions in Probabilistic Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kozen%2C+D">Dexter Kozen</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+A">Alexandra Silva</a>, 
<a href="/search/cs?searchtype=author&query=Voogd%2C+E">Erik Voogd</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, MFPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Various categories have been proposed as targets for the denotational
semantics of higher-order probabilistic programming languages. One such
proposal involves joint probability distributions (couplings) used in Bayesian
statistical models with conditioning. In previous treatments, composition of
joint measures was performed by disintegrating to obtain Markov kernels,
composing the kernels, then reintegrating to obtain a joint measure.
Disintegrations exist only under certain restrictions on the underlying spaces.
In this paper we propose a category whose morphisms are joint finite measures
in which composition is defined without reference to disintegration, allowing
its application to a broader class of spaces. The category is symmetric
monoidal with a pleasing symmetry in which the dagger structure is a simple
transpose.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06917" title="Abstract">arXiv:2309.06917</a> [<a href="/pdf/2309.06917" title="Download PDF">pdf</a>, <a href="/format/2309.06917" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Dirichlet Generative-based Rehearsal
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+M">Min Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recent advancements in data-driven task-oriented dialogue systems (ToDs)
struggle with incremental learning due to computational constraints and
time-consuming issues. Continual Learning (CL) attempts to solve this by
avoiding intensive pre-training, but it faces the problem of catastrophic
forgetting (CF). While generative-based rehearsal CL methods have made
significant strides, generating pseudo samples that accurately reflect the
underlying task-specific distribution is still a challenge. In this paper, we
present Dirichlet Continual Learning (DCL), a novel generative-based rehearsal
strategy for CL. Unlike the traditionally used Gaussian latent variable in the
Conditional Variational Autoencoder (CVAE), DCL leverages the flexibility and
versatility of the Dirichlet distribution to model the latent prior variable.
This enables it to efficiently capture sentence-level features of previous
tasks and effectively guide the generation of pseudo samples. In addition, we
introduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based
knowledge distillation method that enhances knowledge transfer during pseudo
sample generation. Our experiments confirm the efficacy of our approach in both
intent detection and slot-filling tasks, outperforming state-of-the-art
methods.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06918" title="Abstract">arXiv:2309.06918</a> [<a href="/pdf/2309.06918" title="Download PDF">pdf</a>, <a href="/format/2309.06918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lotaru: Locally Predicting Workflow Task Runtimes for Resource  Management on Heterogeneous Infrastructures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bader%2C+J">Jonathan Bader</a>, 
<a href="/search/cs?searchtype=author&query=Lehmann%2C+F">Fabian Lehmann</a>, 
<a href="/search/cs?searchtype=author&query=Thamsen%2C+L">Lauritz Thamsen</a>, 
<a href="/search/cs?searchtype=author&query=Leser%2C+U">Ulf Leser</a>, 
<a href="/search/cs?searchtype=author&query=Kao%2C+O">Odej Kao</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Future Generation Computer Systems, Volume 150, January 2024,
  Pages 171-185
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Many resource management techniques for task scheduling, energy and carbon
efficiency, and cost optimization in workflows rely on a-priori task runtime
knowledge. Building runtime prediction models on historical data is often not
feasible in practice as workflows, their input data, and the cluster
infrastructure change. Online methods, on the other hand, which estimate task
runtimes on specific machines while the workflow is running, have to cope with
a lack of measurements during start-up. Frequently, scientific workflows are
executed on heterogeneous infrastructures consisting of machines with different
CPU, I/O, and memory configurations, further complicating predicting runtimes
due to different task runtimes on different machine types.
<br />This paper presents Lotaru, a method for locally predicting the runtimes of
scientific workflow tasks before they are executed on heterogeneous compute
clusters. Crucially, our approach does not rely on historical data and copes
with a lack of training data during the start-up. To this end, we use
microbenchmarks, reduce the input data to quickly profile the workflow locally,
and predict a task's runtime with a Bayesian linear regression based on the
gathered data points from the local workflow execution and the microbenchmarks.
Due to its Bayesian approach, Lotaru provides uncertainty estimates that can be
used for advanced scheduling methods on distributed cluster infrastructures.
<br />In our evaluation with five real-world scientific workflows, our method
outperforms two state-of-the-art runtime prediction baselines and decreases the
absolute prediction error by more than 12.5%. In a second set of experiments,
the prediction performance of our method, using the predicted runtimes for
state-of-the-art scheduling, carbon reduction, and cost prediction, enables
results close to those achieved with perfect prior knowledge of runtimes.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06921" title="Abstract">arXiv:2309.06921</a> [<a href="/pdf/2309.06921" title="Download PDF">pdf</a>, <a href="/format/2309.06921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Impact of Action Representations in Policy Gradient  Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+J">Jan Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Schumacher%2C+P">Pierre Schumacher</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%A4ufle%2C+D">Daniel H&#xe4;ufle</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%B6lkopf%2C+B">Bernhard Sch&#xf6;lkopf</a>, 
<a href="/search/cs?searchtype=author&query=B%C3%BCchler%2C+D">Dieter B&#xfc;chler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the Workshop on effective Representations, Abstractions, and Priors for Robot Learning (RAP4Robots) at ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Reinforcement learning~(RL) is a versatile framework for learning to solve
complex real-world tasks. However, influences on the learning performance of RL
algorithms are often poorly understood in practice. We discuss different
analysis techniques and assess their effectiveness for investigating the impact
of action representations in RL. Our experiments demonstrate that the action
representation can significantly influence the learning performance on popular
RL benchmark tasks. The analysis results indicate that some of the performance
differences can be attributed to changes in the complexity of the optimization
landscape. Finally, we discuss open challenges of analysis techniques for RL
algorithms.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06922" title="Abstract">arXiv:2309.06922</a> [<a href="/pdf/2309.06922" title="Download PDF">pdf</a>, <a href="/format/2309.06922" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hydra: Multi-head Low-rank Adaptation for Parameter Efficient  Fine-tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sanghyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hyunmo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Younghyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+Y">Youngjoon Hong</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+E">Eunbyung Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The recent surge in large-scale foundation models has spurred the development
of efficient methods for adapting these models to various downstream tasks.
Low-rank adaptation methods, such as LoRA, have gained significant attention
due to their outstanding parameter efficiency and no additional inference
latency. This paper investigates a more general form of adapter module based on
the analysis that parallel and sequential adaptation branches learn novel and
general features during fine-tuning, respectively. The proposed method, named
Hydra, due to its multi-head computational branches, combines parallel and
sequential branch to integrate capabilities, which is more expressive than
existing single branch methods and enables the exploration of a broader range
of optimal points in the fine-tuning process. In addition, the proposed
adaptation method explicitly leverages the pre-trained weights by performing a
linear combination of the pre-trained features. It allows the learned features
to have better generalization performance across diverse downstream tasks.
Furthermore, we perform a comprehensive analysis of the characteristics of each
adaptation branch with empirical evidence. Through an extensive range of
experiments, encompassing comparisons and ablation studies, we substantiate the
efficiency and demonstrate the superior performance of Hydra. This
comprehensive evaluation underscores the potential impact and effectiveness of
Hydra in a variety of applications. Our code is available on
\url{https://github.com/extremebird/Hydra}
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06923" title="Abstract">arXiv:2309.06923</a> [<a href="/pdf/2309.06923" title="Download PDF">pdf</a>, <a href="/ps/2309.06923" title="Download PostScript">ps</a>, <a href="/format/2309.06923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Native Language Identification with Big Bird Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kramp%2C+S">Sergey Kramp</a>, 
<a href="/search/cs?searchtype=author&query=Cassani%2C+G">Giovanni Cassani</a>, 
<a href="/search/cs?searchtype=author&query=Emmery%2C+C">Chris Emmery</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Native Language Identification (NLI) intends to classify an author's native
language based on their writing in another language. Historically, the task has
heavily relied on time-consuming linguistic feature engineering, and
transformer-based NLI models have thus far failed to offer effective, practical
alternatives. The current work investigates if input size is a limiting factor,
and shows that classifiers trained using Big Bird embeddings outperform
linguistic feature engineering models by a large margin on the Reddit-L2
dataset. Additionally, we provide further insight into input length
dependencies, show consistent out-of-sample performance, and qualitatively
analyze the embedding space. Given the effectiveness and computational
efficiency of this method, we believe it offers a promising avenue for future
NLI work.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06924" title="Abstract">arXiv:2309.06924</a> [<a href="/pdf/2309.06924" title="Download PDF">pdf</a>, <a href="/format/2309.06924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrast-Phys+: Unsupervised and Weakly-supervised Video-based Remote  Physiological Measurement via Spatiotemporal Contrast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhaodong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaobai Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video-based remote physiological measurement utilizes facial videos to
measure the blood volume change signal, which is also called remote
photoplethysmography (rPPG). Supervised methods for rPPG measurements have been
shown to achieve good performance. However, the drawback of these methods is
that they require facial videos with ground truth (GT) physiological signals,
which are often costly and difficult to obtain. In this paper, we propose
Contrast-Phys+, a method that can be trained in both unsupervised and
weakly-supervised settings. We employ a 3DCNN model to generate multiple
spatiotemporal rPPG signals and incorporate prior knowledge of rPPG into a
contrastive loss function. We further incorporate the GT signals into
contrastive learning to adapt to partial or misaligned labels. The contrastive
loss encourages rPPG/GT signals from the same video to be grouped together,
while pushing those from different videos apart. We evaluate our methods on
five publicly available datasets that include both RGB and Near-infrared
videos. Contrast-Phys+ outperforms the state-of-the-art supervised methods,
even when using partially available or misaligned GT signals, or no labels at
all. Additionally, we highlight the advantages of our methods in terms of
computational efficiency, noise robustness, and generalization.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06926" title="Abstract">arXiv:2309.06926</a> [<a href="/pdf/2309.06926" title="Download PDF">pdf</a>, <a href="/ps/2309.06926" title="Download PostScript">ps</a>, <a href="/format/2309.06926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regular Representations of Uniform TC^0
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hella%2C+L">Lauri Hella</a>, 
<a href="/search/cs?searchtype=author&query=Kontinen%2C+J">Juha Kontinen</a>, 
<a href="/search/cs?searchtype=author&query=Luosto%2C+K">Kerkko Luosto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
<p class="mathjax">The circuit complexity class DLOGTIME-uniform AC^0 is known to be a modest
subclass of DLOGTIME-uniform TC^0. The weakness of AC^0 is caused by the fact
that AC^0 is not closed under restricting AC^0-computable queries into simple
subsequences of the input. Analogously, in descriptive complexity, the logics
corresponding to DLOGTIME-uniform AC^0 do not have the relativization property
and hence they are not regular. This weakness of DLOGTIME-uniform AC^0 has been
elaborated in the line of research on the Crane Beach Conjecture. The
conjecture (which was refuted by Barrington, Immerman, Lautemann, Schweikardt
and Th{\'e}rien) was that if a language L has a neutral letter, then L can be
defined in first-order logic with the collection of all numerical built-in
relations, if and only if L can be already defined in FO with order.
<br />In the first part of this article we consider logics in the range of AC^0 and
TC^0. First we formulate a combinatorial criterion for a cardinality quantifier
C_S implying that all languages in DLOGTIME-uniform TC^0 can be defined in
FO(C_S). For instance, this criterion is satisfied by C_S if S is the range of
some polynomial with positive integer coefficients of degree at least two. In
the second part of the paper we first adapt the key properties of abstract
logics to accommodate built-in relations. Then we define the regular interior
R-int(L) and regular closure R-cl(L), of a logic L, and show that the Crane
Beach Conjecture can be interpreted as a statement concerning the regular
interior of first-order logic with built-in relations B. We show that if B={+},
or B contains only unary relations besides the order, then R-int(FO_B)
collapses to FO with order. In contrast, our results imply that if B contains
the order and the range of a polynomial of degree at least two, then R-cl(FO_B)
includes all languages in DLOGTIME-uniform TC^0.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06927" title="Abstract">arXiv:2309.06927</a> [<a href="/pdf/2309.06927" title="Download PDF">pdf</a>, <a href="/format/2309.06927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OMOD: An open-source tool for creating disaggregated mobility demand  based on OpenStreetMap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strobel%2C+L">Leo Strobel</a>, 
<a href="/search/cs?searchtype=author&query=Pruckner%2C+M">Marco Pruckner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">In this paper, we introduce the OpenStreetMap Mobility Demand Generator
(OMOD), a new open-source activity-based mobility demand generation tool. OMOD
creates a population of agents and detailed daily activity schedules that state
what activities each agent plans to conduct, where, and for how long. The
temporal aspect of the output is wholly disaggregated, while the spatial aspect
is given on the level of individual buildings. In contrast to other existing
models, OMOD is freely available, open-source, works out-of-the-box, can be
applied to any region on earth, and only requires freely available
OpenStreetMap (OSM) data from the user. With OMOD, it is easy for non-experts
to create realistic mobility demand, which can be used in transportation
studies, energy system modeling, communications system research, et cetera.
OMOD uses a data-driven approach to generate mobility demand that has been
calibrated with household travel survey data. This paper describes OMOD's
architecture and validates the model for three cities ranging from 200,000 to
2.5 million inhabitants.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06928" title="Abstract">arXiv:2309.06928</a> [<a href="/pdf/2309.06928" title="Download PDF">pdf</a>, <a href="/format/2309.06928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Causal Disentanglement Model for Dialogue Emotion Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuting Su</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yichen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+W">Weizhi Nie</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Sicheng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Anan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Emotion detection is a critical technology extensively employed in diverse
fields. While the incorporation of commonsense knowledge has proven beneficial
for existing emotion detection methods, dialogue-based emotion detection
encounters numerous difficulties and challenges due to human agency and the
variability of dialogue content.In dialogues, human emotions tend to accumulate
in bursts. However, they are often implicitly expressed. This implies that many
genuine emotions remain concealed within a plethora of unrelated words and
dialogues.In this paper, we propose a Dynamic Causal Disentanglement Model
based on hidden variable separation, which is founded on the separation of
hidden variables. This model effectively decomposes the content of dialogues
and investigates the temporal accumulation of emotions, thereby enabling more
precise emotion recognition. First, we introduce a novel Causal Directed
Acyclic Graph (DAG) to establish the correlation between hidden emotional
information and other observed elements. Subsequently, our approach utilizes
pre-extracted personal attributes and utterance topics as guiding factors for
the distribution of hidden variables, aiming to separate irrelevant ones.
Specifically, we propose a dynamic temporal disentanglement model to infer the
propagation of utterances and hidden variables, enabling the accumulation of
emotion-related information throughout the conversation. To guide this
disentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to
extract utterance topics and personal attributes as observed
information.Finally, we test our approach on two popular datasets in dialogue
emotion detection and relevant experimental results verified the model's
superiority.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06933" title="Abstract">arXiv:2309.06933</a> [<a href="/pdf/2309.06933" title="Download PDF">pdf</a>, <a href="/format/2309.06933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DreamStyler: Paint by Style Inversion with Text-to-Image Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahn%2C+N">Namhyuk Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Junsoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+C">Chunggi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kunhee Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daesik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+S">Seung-Hun Nam</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+K">Kibeom Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent progresses in large-scale text-to-image models have yielded remarkable
accomplishments, finding various applications in art domain. However,
expressing unique characteristics of an artwork (e.g. brushwork, colortone, or
composition) with text prompts alone may encounter limitations due to the
inherent constraints of verbal description. To this end, we introduce
DreamStyler, a novel framework designed for artistic image synthesis,
proficient in both text-to-image synthesis and style transfer. DreamStyler
optimizes a multi-stage textual embedding with a context-aware text prompt,
resulting in prominent image quality. In addition, with content and style
guidance, DreamStyler exhibits flexibility to accommodate a range of style
references. Experimental results demonstrate its superior performance across
multiple scenarios, suggesting its promising potential in artistic product
creation.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06938" title="Abstract">arXiv:2309.06938</a> [<a href="/pdf/2309.06938" title="Download PDF">pdf</a>, <a href="/format/2309.06938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collectionless Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>, 
<a href="/search/cs?searchtype=author&query=Melacci%2C+S">Stefano Melacci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">By and large, the professional handling of huge data collections is regarded
as a fundamental ingredient of the progress of machine learning and of its
spectacular results in related disciplines, with a growing agreement on risks
connected to the centralization of such data collections. This paper sustains
the position that the time has come for thinking of new learning protocols
where machines conquer cognitive skills in a truly human-like context centered
on environmental interactions. This comes with specific restrictions on the
learning protocol according to the collectionless principle, which states that,
at each time instant, data acquired from the environment is processed with the
purpose of contributing to update the current internal representation of the
environment, and that the agent is not given the privilege of recording the
temporal stream. Basically, there is neither permission to store the temporal
information coming from the sensors, thus promoting the development of
self-organized memorization skills at a more abstract level, instead of relying
on bare storage to simulate learning dynamics that are typical of offline
learning algorithms. This purposely extreme position is intended to stimulate
the development of machines that learn to dynamically organize the information
by following human-based schemes. The proposition of this challenge suggests
developing new foundations on computational processes of learning and reasoning
that might open the doors to a truly orthogonal competitive track on AI
technologies that avoid data accumulation by design, thus offering a framework
which is better suited concerning privacy issues, control and customizability.
Finally, pushing towards massively distributed computation, the collectionless
approach to AI will likely reduce the concentration of power in companies and
governments, thus better facing geopolitical issues.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06940" title="Abstract">arXiv:2309.06940</a> [<a href="/pdf/2309.06940" title="Download PDF">pdf</a>, <a href="/format/2309.06940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing the Performance of Multi-Agent Reinforcement Learning for  Controlling HVAC Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bayer%2C+D">Daniel Bayer</a>, 
<a href="/search/cs?searchtype=author&query=Pruckner%2C+M">Marco Pruckner</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 IEEE Conference on Technologies for Sustainability (SusTech)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
<p class="mathjax">Systems for heating, ventilation and air-conditioning (HVAC) of buildings are
traditionally controlled by a rule-based approach. In order to reduce the
energy consumption and the environmental impact of HVAC systems more advanced
control methods such as reinforcement learning are promising. Reinforcement
learning (RL) strategies offer a good alternative, as user feedback can be
integrated more easily and presence can also be incorporated. Moreover,
multi-agent RL approaches scale well and can be generalized. In this paper, we
propose a multi-agent RL framework based on existing work that learns reducing
on one hand energy consumption by optimizing HVAC control and on the other hand
user feedback by occupants about uncomfortable room temperatures. Second, we
show how to reduce training time required for proper RL-agent-training by using
parameter sharing between the multiple agents and apply different pretraining
techniques. Results show that our framework is capable of reducing the energy
by around 6% when controlling a complete building or 8% for a single room zone.
The occupants complaints are acceptable or even better compared to a rule-based
baseline. Additionally, our performance analysis show that the training time
can be drastically reduced by using parameter sharing.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06941" title="Abstract">arXiv:2309.06941</a> [<a href="/pdf/2309.06941" title="Download PDF">pdf</a>, <a href="/format/2309.06941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEFormer: DCT-driven Enhancement Transformer for Low-light Image and  Dark Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xiangchen Yin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhenda Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xin Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+R">Ran Ju</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submit to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The goal of low-light image enhancement is to restore the color and details
of the image and is of great significance for high-level visual tasks in
autonomous driving. However, it is difficult to restore the lost details in the
dark area by relying only on the RGB domain. In this paper we introduce
frequency as a new clue into the network and propose a novel DCT-driven
enhancement transformer (DEFormer). First, we propose a learnable frequency
branch (LFB) for frequency enhancement contains DCT processing and
curvature-based frequency enhancement (CFE). CFE calculates the curvature of
each channel to represent the detail richness of different frequency bands,
then we divides the frequency features, which focuses on frequency bands with
richer textures. In addition, we propose a cross domain fusion (CDF) for
reducing the differences between the RGB domain and the frequency domain. We
also adopt DEFormer as a preprocessing in dark detection, DEFormer effectively
improves the performance of the detector, bringing 2.1% and 3.4% improvement in
ExDark and DARK FACE datasets on mAP respectively.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06950" title="Abstract">arXiv:2309.06950</a> [<a href="/pdf/2309.06950" title="Download PDF">pdf</a>, <a href="/format/2309.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Active Metric-Semantic SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yuezhan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/cs?searchtype=author&query=Agarwa%2C+S">Saurav Agarwa</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to RA-L for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this letter, we address the problem of exploration and metric-semantic
mapping of multi-floor GPS-denied indoor environments using Size Weight and
Power (SWaP) constrained aerial robots. Most previous work in exploration
assumes that robot localization is solved. However, neglecting the state
uncertainty of the agent can ultimately lead to cascading errors both in the
resulting map and in the state of the agent itself. Furthermore, actions that
reduce localization errors may be at direct odds with the exploration task. We
propose a framework that balances the efficiency of exploration with actions
that reduce the state uncertainty of the agent. In particular, our algorithmic
approach for active metric-semantic SLAM is built upon sparse information
abstracted from raw problem data, to make it suitable for SWaP-constrained
robots. Furthermore, we integrate this framework within a fully autonomous
aerial robotic system that achieves autonomous exploration in cluttered, 3D
environments. From extensive real-world experiments, we showed that by
including Semantic Loop Closure (SLC), we can reduce the robot pose estimation
errors by over 90% in translation and approximately 75% in yaw, and the
uncertainties in pose estimates and semantic maps by over 70% and 65%,
respectively. Although discussed in the context of indoor multi-floor
exploration, our system can be used for various other applications, such as
infrastructure inspection and precision agriculture where reliable GPS data may
not be available.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06951" title="Abstract">arXiv:2309.06951</a> [<a href="/pdf/2309.06951" title="Download PDF">pdf</a>, <a href="/format/2309.06951" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TransNet: A Transfer Learning-Based Network for Human Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alomar%2C+K">K. Alomar</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">X. Cai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Human action recognition (HAR) is a high-level and significant research area
in computer vision due to its ubiquitous applications. The main limitations of
the current HAR models are their complex structures and lengthy training time.
In this paper, we propose a simple yet versatile and effective end-to-end deep
learning architecture, coined as TransNet, for HAR. TransNet decomposes the
complex 3D-CNNs into 2D- and 1D-CNNs, where the 2D- and 1D-CNN components
extract spatial features and temporal patterns in videos, respectively.
Benefiting from its concise architecture, TransNet is ideally compatible with
any pretrained state-of-the-art 2D-CNN models in other fields, being
transferred to serve the HAR task. In other words, it naturally leverages the
power and success of transfer learning for HAR, bringing huge advantages in
terms of efficiency and effectiveness. Extensive experimental results and the
comparison with the state-of-the-art models demonstrate the superior
performance of the proposed TransNet in HAR in terms of flexibility, model
complexity, training speed and classification accuracy.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06955" title="Abstract">arXiv:2309.06955</a> [<a href="/pdf/2309.06955" title="Download PDF">pdf</a>, <a href="/format/2309.06955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Motion Planning for In-Hand Manipulation with a Multi-Fingered  Hand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiao Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Kunpeng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Khadivar%2C+F">Farshad Khadivar</a>, 
<a href="/search/cs?searchtype=author&query=Billard%2C+A">Aude Billard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Dexterous manipulation of objects once held in hand remains a challenge. Such
skills are, however, necessary for robotics to move beyond gripper-based
manipulation and use all the dexterity offered by anthropomorphic robotic
hands. One major challenge when manipulating an object within the hand is that
fingers must move around the object while avoiding collision with other fingers
or the object. Such collision-free paths must be computed in real-time, as the
smallest deviation from the original plan can easily lead to collisions. We
present a real-time approach to computing collision-free paths in a
high-dimensional space. To guide the exploration, we learn an explicit
representation of the free space, retrievable in real-time. We further combine
this representation with closed-loop control via dynamical systems and
sampling-based motion planning and show that the combination increases
performance compared to alternatives, offering efficient search of feasible
paths and real-time obstacle avoidance in a multi-fingered robotic hand.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06957" title="Abstract">arXiv:2309.06957</a> [<a href="/pdf/2309.06957" title="Download PDF">pdf</a>, <a href="/format/2309.06957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harvesting Brownian Motion: Zero Energy Computational Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doty%2C+D">David Doty</a>, 
<a href="/search/cs?searchtype=author&query=Kornerup%2C+N">Niels Kornerup</a>, 
<a href="/search/cs?searchtype=author&query=Luchsinger%2C+A">Austin Luchsinger</a>, 
<a href="/search/cs?searchtype=author&query=Orshansky%2C+L">Leo Orshansky</a>, 
<a href="/search/cs?searchtype=author&query=Soloveichik%2C+D">David Soloveichik</a>, 
<a href="/search/cs?searchtype=author&query=Woods%2C+D">Damien Woods</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 6 figures, submitted to ITCS 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">The key factor currently limiting the advancement of computational power of
electronic computation is no longer the manufacturing density and speed of
components, but rather their high energy consumption. While it has been widely
argued that reversible computation can escape the fundamental Landauer limit of
$k_B T\ln(2)$ Joules per irreversible computational step, there is disagreement
around whether indefinitely reusable computation can be achieved without energy
dissipation. Here we focus on the relatively simpler context of sampling
problems, which take no input, so avoids modeling the energy costs of the
observer perturbing the machine to change its input. Given an algorithm $A$ for
generating samples from a distribution, we desire a device that can perpetually
generate samples from that distribution driven entirely by Brownian motion. We
show that such a device can efficiently execute algorithm $A$ in the sense that
we must wait only $O(\text{time}(A)^2)$ between samples. We consider two output
models: Las Vegas, which samples from the exact probability distribution every
$4$ tries in expectation, and Monte Carlo, in which every try succeeds but the
distribution is only approximated. We base our model on continuous-time random
walks over the state space graph of a general computational machine, with a
space-bounded Turing machine as one instantiation. The problem of sampling a
computationally complex probability distribution with no energy dissipation
informs our understanding of the energy requirements of computation, and may
lead to more energy efficient randomized algorithms.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06958" title="Abstract">arXiv:2309.06958</a> [<a href="/pdf/2309.06958" title="Download PDF">pdf</a>, <a href="/format/2309.06958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural network-based coronary dominance classification of RCA angiograms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruzhilov%2C+I">Ivan Kruzhilov</a>, 
<a href="/search/cs?searchtype=author&query=Ikryannikov%2C+E">Egor Ikryannikov</a>, 
<a href="/search/cs?searchtype=author&query=Shadrin%2C+A">Artem Shadrin</a>, 
<a href="/search/cs?searchtype=author&query=Utegenov%2C+R">Ruslan Utegenov</a>, 
<a href="/search/cs?searchtype=author&query=Zubkova%2C+G">Galina Zubkova</a>, 
<a href="/search/cs?searchtype=author&query=Bessonov%2C+I">Ivan Bessonov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Background. Cardiac dominance classification is essential for SYNTAX score
estimation, which is a tool used to determine the complexity of coronary artery
disease and guide patient selection toward optimal revascularization strategy.
Objectives. Cardiac dominance classification algorithm based on the analysis of
right coronary artery (RCA) angiograms using neural network Method. We employed
convolutional neural network ConvNext and Swin transformer for 2D image
(frames) classification, along with a majority vote for cardio angiographic
view classification. An auxiliary network was also used to detect irrelevant
images which were then excluded from the data set. Our data set consisted of
828 angiographic studies, 192 of them being patients with left dominance.
Results. 5-fold cross validation gave the following dominance classification
metrics (p=95%): macro recall=93.1%, accuracy=93.5%, macro F1=89.2%. The most
common case in which the model regularly failed was RCA occlusion, as it
requires utilization of LCA information. Another cause for false prediction is
a small diameter combined with poor quality cardio angiographic view. In such
cases, cardiac dominance classification can be complex and may require
discussion among specialists to reach an accurate conclusion. Conclusion. The
use of machine learning approaches to classify cardiac dominance based on RCA
alone has been shown to be successful with satisfactory accuracy. However, for
higher accuracy, it is necessary to utilize LCA information in the case of an
occluded RCA and detect cases where there is high uncertainty.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06960" title="Abstract">arXiv:2309.06960</a> [<a href="/pdf/2309.06960" title="Download PDF">pdf</a>, <a href="/format/2309.06960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PhantomSound: Black-Box, Query-Efficient Audio Adversarial Attack via  Split-Second Phoneme Injection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Guangjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuanda Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bocheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiben Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Li Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RAID 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In this paper, we propose PhantomSound, a query-efficient black-box attack
toward voice assistants. Existing black-box adversarial attacks on voice
assistants either apply substitution models or leverage the intermediate model
output to estimate the gradients for crafting adversarial audio samples.
However, these attack approaches require a significant amount of queries with a
lengthy training stage. PhantomSound leverages the decision-based attack to
produce effective adversarial audios, and reduces the number of queries by
optimizing the gradient estimation. In the experiments, we perform our attack
against 4 different speech-to-text APIs under 3 real-world scenarios to
demonstrate the real-time attack impact. The results show that PhantomSound is
practical and robust in attacking 5 popular commercial voice controllable
devices over the air, and is able to bypass 3 liveness detection mechanisms
with &gt;95% success rate. The benchmark result shows that PhantomSound can
generate adversarial examples and launch the attack in a few minutes. We
significantly enhance the query efficiency and reduce the cost of a successful
untargeted and targeted adversarial attack by 93.1% and 65.5% compared with the
state-of-the-art black-box attacks, using merely ~300 queries (~5 minutes) and
~1,500 queries (~25 minutes), respectively.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06961" title="Abstract">arXiv:2309.06961</a> [<a href="/pdf/2309.06961" title="Download PDF">pdf</a>, <a href="/format/2309.06961" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Reliable Dermatology Evaluation Benchmarks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6ger%2C+F">Fabian Gr&#xf6;ger</a>, 
<a href="/search/cs?searchtype=author&query=Lionetti%2C+S">Simone Lionetti</a>, 
<a href="/search/cs?searchtype=author&query=Gottfrois%2C+P">Philippe Gottfrois</a>, 
<a href="/search/cs?searchtype=author&query=Gonzalez-Jimenez%2C+A">Alvaro Gonzalez-Jimenez</a>, 
<a href="/search/cs?searchtype=author&query=Groh%2C+M">Matthew Groh</a>, 
<a href="/search/cs?searchtype=author&query=Daneshjou%2C+R">Roxana Daneshjou</a>, 
<a href="/search/cs?searchtype=author&query=Consortium%2C+L">Labelling Consortium</a>, 
<a href="/search/cs?searchtype=author&query=Navarini%2C+A+A">Alexander A. Navarini</a>, 
<a href="/search/cs?searchtype=author&query=Pouly%2C+M">Marc Pouly</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Link to the revised file lists: <a href="https://github.com/Digital-Dermatology/SelfClean-Revised-Benchmarks">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Benchmark datasets for digital dermatology unwittingly contain inaccuracies
that reduce trust in model performance estimates. We propose a
resource-efficient data cleaning protocol to identify issues that escaped
previous curation. The protocol leverages an existing algorithmic cleaning
strategy and is followed by a confirmation process terminated by an intuitive
stopping criterion. Based on confirmation by multiple dermatologists, we remove
irrelevant samples and near duplicates and estimate the percentage of label
errors in six dermatology image datasets for model evaluation promoted by the
International Skin Imaging Collaboration. Along with this paper, we publish
revised file lists for each dataset which should be used for model evaluation.
Our work paves the way for more trustworthy performance assessment in digital
dermatology.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06968" title="Abstract">arXiv:2309.06968</a> [<a href="/pdf/2309.06968" title="Download PDF">pdf</a>, <a href="/format/2309.06968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness in Metric Spaces over Continuous Quantales and the  Hausdorff-Smyth Monad
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dagnino%2C+F">Francesco Dagnino</a>, 
<a href="/search/cs?searchtype=author&query=Farjudian%2C+A">Amin Farjudian</a>, 
<a href="/search/cs?searchtype=author&query=Moggi%2C+E">Eugenio Moggi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Category Theory (math.CT)

</div>
<p class="mathjax">Generalized metric spaces are obtained by weakening the requirements (e.g.,
symmetry) on the distance function and by allowing it to take values in
structures (e.g., quantales) that are more general than the set of non-negative
real numbers. Quantale-valued metric spaces have gained prominence due to their
use in quantitative reasoning on programs/systems, and for defining various
notions of behavioral metrics.
<br />We investigate imprecision and robustness in the framework of quantale-valued
metric spaces, when the quantale is continuous. In particular, we study the
relation between the robust topology, which captures robustness of analyses,
and the Hausdorff-Smyth hemi-metric. To this end, we define a preorder-enriched
monad $\mathsf{P}_S$, called the Hausdorff-Smyth monad, and when $Q$ is a
continuous quantale and $X$ is a $Q$-metric space, we relate the topology
induced by the metric on $\mathsf{P}_S(X)$ with the robust topology on the
powerset $\mathsf{P}(X)$ defined in terms of the metric on $X$.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06969" title="Abstract">arXiv:2309.06969</a> [<a href="/pdf/2309.06969" title="Download PDF">pdf</a>, <a href="/format/2309.06969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Setting the Right Expectations: Algorithmic Recourse Over Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fonseca%2C+J">Joao Fonseca</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+A">Andrew Bell</a>, 
<a href="/search/cs?searchtype=author&query=Abrate%2C+C">Carlo Abrate</a>, 
<a href="/search/cs?searchtype=author&query=Bonchi%2C+F">Francesco Bonchi</a>, 
<a href="/search/cs?searchtype=author&query=Stoyanovich%2C+J">Julia Stoyanovich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Algorithmic systems are often called upon to assist in high-stakes decision
making. In light of this, algorithmic recourse, the principle wherein
individuals should be able to take action against an undesirable outcome made
by an algorithmic system, is receiving growing attention. The bulk of the
literature on algorithmic recourse to-date focuses primarily on how to provide
recourse to a single individual, overlooking a critical element: the effects of
a continuously changing context. Disregarding these effects on recourse is a
significant oversight, since, in almost all cases, recourse consists of an
individual making a first, unfavorable attempt, and then being given an
opportunity to make one or several attempts at a later date - when the context
might have changed. This can create false expectations, as initial recourse
recommendations may become less reliable over time due to model drift and
competition for access to the favorable outcome between individuals.
<br />In this work we propose an agent-based simulation framework for studying the
effects of a continuously changing environment on algorithmic recourse. In
particular, we identify two main effects that can alter the reliability of
recourse for individuals represented by the agents: (1) competition with other
agents acting upon recourse, and (2) competition with new agents entering the
environment. Our findings highlight that only a small set of specific
parameterizations result in algorithmic recourse that is reliable for agents
over time. Consequently, we argue that substantial additional work is needed to
understand recourse reliability over time, and to develop recourse methods that
reward agents' effort.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06973" title="Abstract">arXiv:2309.06973</a> [<a href="/pdf/2309.06973" title="Download PDF">pdf</a>, <a href="/ps/2309.06973" title="Download PostScript">ps</a>, <a href="/format/2309.06973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DNNShifter: An Efficient DNN Pruning System for Edge Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eccles%2C+B+J">Bailey J. Eccles</a>, 
<a href="/search/cs?searchtype=author&query=Rodgers%2C+P">Philip Rodgers</a>, 
<a href="/search/cs?searchtype=author&query=Kilpatrick%2C+P">Peter Kilpatrick</a>, 
<a href="/search/cs?searchtype=author&query=Spence%2C+I">Ivor Spence</a>, 
<a href="/search/cs?searchtype=author&query=Varghese%2C+B">Blesson Varghese</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 7 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Deep neural networks (DNNs) underpin many machine learning applications.
Production quality DNN models achieve high inference accuracy by training
millions of DNN parameters which has a significant resource footprint. This
presents a challenge for resources operating at the extreme edge of the
network, such as mobile and embedded devices that have limited computational
and memory resources. To address this, models are pruned to create lightweight,
more suitable variants for these devices. Existing pruning methods are unable
to provide similar quality models compared to their unpruned counterparts
without significant time costs and overheads or are limited to offline use
cases. Our work rapidly derives suitable model variants while maintaining the
accuracy of the original model. The model variants can be swapped quickly when
system and network conditions change to match workload demand. This paper
presents DNNShifter, an end-to-end DNN training, spatial pruning, and model
switching system that addresses the challenges mentioned above. At the heart of
DNNShifter is a novel methodology that prunes sparse models using structured
pruning. The pruned model variants generated by DNNShifter are smaller in size
and thus faster than dense and sparse model predecessors, making them suitable
for inference at the edge while retaining near similar accuracy as of the
original dense model. DNNShifter generates a portfolio of model variants that
can be swiftly interchanged depending on operational conditions. DNNShifter
produces pruned model variants up to 93x faster than conventional training
methods. Compared to sparse models, the pruned model variants are up to 5.14x
smaller and have a 1.67x inference latency speedup, with no compromise to
sparse model accuracy. In addition, DNNShifter has up to 11.9x lower overhead
for switching models and up to 3.8x lower memory utilisation than existing
approaches.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06978" title="Abstract">arXiv:2309.06978</a> [<a href="/pdf/2309.06978" title="Download PDF">pdf</a>, <a href="/format/2309.06978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable JPEG: The Devil is in the Details
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reich%2C+C">Christoph Reich</a>, 
<a href="/search/cs?searchtype=author&query=Debnath%2C+B">Biplob Debnath</a>, 
<a href="/search/cs?searchtype=author&query=Patel%2C+D">Deep Patel</a>, 
<a href="/search/cs?searchtype=author&query=Chakradhar%2C+S">Srimat Chakradhar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at WACV 2024. Project page: <a href="https://christophreich1996.github.io/differentiable_jpeg/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">JPEG remains one of the most widespread lossy image coding methods. However,
the non-differentiable nature of JPEG restricts the application in deep
learning pipelines. Several differentiable approximations of JPEG have recently
been proposed to address this issue. This paper conducts a comprehensive review
of existing diff. JPEG approaches and identifies critical details that have
been missed by previous methods. To this end, we propose a novel diff. JPEG
approach, overcoming previous limitations. Our approach is differentiable
w.r.t. the input image, the JPEG quality, the quantization tables, and the
color conversion parameters. We evaluate the forward and backward performance
of our diff. JPEG approach against existing methods. Additionally, extensive
ablations are performed to evaluate crucial design choices. Our proposed diff.
JPEG resembles the (non-diff.) reference implementation best, significantly
surpassing the recent-best diff. approach by $3.47$dB (PSNR) on average. For
strong compression rates, we can even improve PSNR by $9.51$dB. Strong
adversarial attack results are yielded by our diff. JPEG, demonstrating the
effective gradient approximation. Our code is available at
https://github.com/necla-ml/Diff-JPEG.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06979" title="Abstract">arXiv:2309.06979</a> [<a href="/pdf/2309.06979" title="Download PDF">pdf</a>, <a href="/format/2309.06979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Auto-Regressive Next-Token Predictors are Universal Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malach%2C+E">Eran Malach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models display remarkable capabilities in logical and
mathematical reasoning, allowing them to solve complex tasks. Interestingly,
these abilities emerge in networks trained on the simple task of next-token
prediction. In this work, we present a theoretical framework for studying
auto-regressive next-token predictors. We demonstrate that even simple models
such as linear next-token predictors, trained on Chain-of-Thought (CoT) data,
can approximate any function efficiently computed by a Turing machine. We
introduce a new complexity measure -- length complexity -- which measures the
number of intermediate tokens in a CoT sequence required to approximate some
target function, and analyze the interplay between length complexity and other
notions of complexity. Finally, we show experimentally that simple next-token
predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs),
display non-trivial performance on text generation and arithmetic tasks. Our
results demonstrate that the power of language models can be attributed, to a
great extent, to the auto-regressive next-token training scheme, and not
necessarily to a particular choice of architecture.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06981" title="Abstract">arXiv:2309.06981</a> [<a href="/pdf/2309.06981" title="Download PDF">pdf</a>, <a href="/format/2309.06981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASTERKEY: Practical Backdoor Attack Against Speaker Verification  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+H">Hanqing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junfeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Li Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiben Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Mobicom 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speaker Verification (SV) is widely deployed in mobile systems to
authenticate legitimate users by using their voice traits. In this work, we
propose a backdoor attack MASTERKEY, to compromise the SV models. Different
from previous attacks, we focus on a real-world practical setting where the
attacker possesses no knowledge of the intended victim. To design MASTERKEY, we
investigate the limitation of existing poisoning attacks against unseen
targets. Then, we optimize a universal backdoor that is capable of attacking
arbitrary targets. Next, we embed the speaker's characteristics and semantics
information into the backdoor, making it imperceptible. Finally, we estimate
the channel distortion and integrate it into the backdoor. We validate our
attack on 6 popular SV models. Specifically, we poison a total of 53 models and
use our trigger to attack 16,430 enrolled speakers, composed of 310 target
speakers enrolled in 53 poisoned models. Our attack achieves 100% attack
success rate with a 15% poison rate. By decreasing the poison rate to 3%, the
attack success rate remains around 50%. We validate our attack in 3 real-world
scenarios and successfully demonstrate the attack through both over-the-air and
over-the-telephony-line scenarios.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06982" title="Abstract">arXiv:2309.06982</a> [<a href="/pdf/2309.06982" title="Download PDF">pdf</a>, <a href="/format/2309.06982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Efficient Laplace Mechanism for Differential Privacy via  Random Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahmiri%2C+A+M">Ali Moradi Shahmiri</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C+W">Chih Wei Ling</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C+T">Cheuk Ting Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, short version to be submitted at 2024 IEEE International Conference on Acoustics, Speech and Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">We propose the first method that realizes the Laplace mechanism exactly
(i.e., a Laplace noise is added to the data) that requires only a finite amount
of communication (whereas the original Laplace mechanism requires the
transmission of a real number) while guaranteeing privacy against the server
and database. Our mechanism can serve as a drop-in replacement for local or
centralized differential privacy applications where the Laplace mechanism is
used. Our mechanism is constructed using a random quantization technique.
Unlike the simple and prevalent Laplace-mechanism-then-quantize approach, the
quantization in our mechanism does not result in any distortion or degradation
of utility. Unlike existing dithered quantization and channel simulation
schemes for simulating additive Laplacian noise, our mechanism guarantees
privacy not only against the database and downstream, but also against the
honest but curious server which attempts to decode the data using the dither
signals.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06986" title="Abstract">arXiv:2309.06986</a> [<a href="/pdf/2309.06986" title="Download PDF">pdf</a>, <a href="/format/2309.06986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Explore Indoor Environments using Autonomous Micro Aerial  Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+Y">Yuezhan Tao</a>, 
<a href="/search/cs?searchtype=author&query=Iceland%2C+E">Eran Iceland</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Beiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zwecher%2C+E">Elchanan Zwecher</a>, 
<a href="/search/cs?searchtype=author&query=Heinemann%2C+U">Uri Heinemann</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Avraham Cohen</a>, 
<a href="/search/cs?searchtype=author&query=Avni%2C+A">Amir Avni</a>, 
<a href="/search/cs?searchtype=author&query=Gal%2C+O">Oren Gal</a>, 
<a href="/search/cs?searchtype=author&query=Barel%2C+A">Ariel Barel</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we address the challenge of exploring unknown indoor aerial
environments using autonomous aerial robots with Size Weight and Power (SWaP)
constraints. The SWaP constraints induce limits on mission time requiring
efficiency in exploration. We present a novel exploration framework that uses
Deep Learning (DL) to predict the most likely indoor map given the previous
observations, and Deep Reinforcement Learning (DRL) for exploration, designed
to run on modern SWaP constraints neural processors. The DL-based map predictor
provides a prediction of the occupancy of the unseen environment while the
DRL-based planner determines the best navigation goals that can be safely
reached to provide the most information. The two modules are tightly coupled
and run onboard allowing the vehicle to safely map an unknown environment.
Extensive experimental and simulation results show that our approach surpasses
state-of-the-art methods by 50-60% in efficiency, which we measure by the
fraction of the explored space as a function of the length of the trajectory
traveled.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06987" title="Abstract">arXiv:2309.06987</a> [<a href="/pdf/2309.06987" title="Download PDF">pdf</a>, <a href="/format/2309.06987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Instance Adaptive Prototypical Contrastive Embedding for Generalized  Zero Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Paul%2C+R">Riti Paul</a>, 
<a href="/search/cs?searchtype=author&query=Vora%2C+S">Sahil Vora</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Baoxin Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures. Accepted in IJCAI 2023 Workshop on Generalizing from Limited Resources in the Open World
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generalized zero-shot learning(GZSL) aims to classify samples from seen and
unseen labels, assuming unseen labels are not accessible during training.
Recent advancements in GZSL have been expedited by incorporating
contrastive-learning-based (instance-based) embedding in generative networks
and leveraging the semantic relationship between data points. However, existing
embedding architectures suffer from two limitations: (1) limited
discriminability of synthetic features' embedding without considering
fine-grained cluster structures; (2) inflexible optimization due to restricted
scaling mechanisms on existing contrastive embedding networks, leading to
overlapped representations in the embedding space. To enhance the quality of
representations in the embedding space, as mentioned in (1), we propose a
margin-based prototypical contrastive learning embedding network that reaps the
benefits of prototype-data (cluster quality enhancement) and implicit data-data
(fine-grained representations) interaction while providing substantial cluster
supervision to the embedding network and the generator. To tackle (2), we
propose an instance adaptive contrastive loss that leads to generalized
representations for unseen labels with increased inter-class margin. Through
comprehensive experimental evaluation, we show that our method can outperform
the current state-of-the-art on three benchmark datasets. Our approach also
consistently achieves the best unseen performance in the GZSL setting.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06989" title="Abstract">arXiv:2309.06989</a> [<a href="/pdf/2309.06989" title="Download PDF">pdf</a>, <a href="/format/2309.06989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remote Inference of Cognitive Scores in ALS Patients Using a Picture  Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agurto%2C+C">Carla Agurto</a>, 
<a href="/search/cs?searchtype=author&query=Cecchi%2C+G">Guillermo Cecchi</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+B">Bo Wen</a>, 
<a href="/search/cs?searchtype=author&query=Fraenkel%2C+E">Ernest Fraenkel</a>, 
<a href="/search/cs?searchtype=author&query=Berry%2C+J">James Berry</a>, 
<a href="/search/cs?searchtype=author&query=Navar%2C+I">Indu Navar</a>, 
<a href="/search/cs?searchtype=author&query=Norel%2C+R">Raquel Norel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Amyotrophic lateral sclerosis is a fatal disease that not only affects
movement, speech, and breath but also cognition. Recent studies have focused on
the use of language analysis techniques to detect ALS and infer scales for
monitoring functional progression. In this paper, we focused on another
important aspect, cognitive impairment, which affects 35-50% of the ALS
population. In an effort to reach the ALS population, which frequently exhibits
mobility limitations, we implemented the digital version of the Edinburgh
Cognitive and Behavioral ALS Screen (ECAS) test for the first time. This test
which is designed to measure cognitive impairment was remotely performed by 56
participants from the EverythingALS Speech Study. As part of the study,
participants (ALS and non-ALS) were asked to describe weekly one picture from a
pool of many pictures with complex scenes displayed on their computer at home.
We analyze the descriptions performed within +/- 60 days from the day the ECAS
test was administered and extract different types of linguistic and acoustic
features. We input those features into linear regression models to infer 5 ECAS
sub-scores and the total score. Speech samples from the picture description are
reliable enough to predict the ECAS subs-scores, achieving statistically
significant Spearman correlation values between 0.32 and 0.51 for the model's
performance using 10-fold cross-validation.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06991" title="Abstract">arXiv:2309.06991</a> [<a href="/pdf/2309.06991" title="Download PDF">pdf</a>, <a href="/format/2309.06991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Contrast-Consistent Ranking with Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stoehr%2C+N">Niklas Stoehr</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengxiang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Preotiuc-Pietro%2C+D">Daniel Preotiuc-Pietro</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+R">Rajarshi Bhowmik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Machine Learning (stat.ML)

</div>
<p class="mathjax">Language models contain ranking-based knowledge and are powerful solvers of
in-context ranking tasks. For instance, they may have parametric knowledge
about the ordering of countries by size or may be able to rank reviews by
sentiment. Recent work focuses on pairwise, pointwise, and listwise prompting
techniques to elicit a language model's ranking knowledge. However, we find
that even with careful calibration and constrained decoding, prompting-based
techniques may not always be self-consistent in the rankings they produce. This
motivates us to explore an alternative approach that is inspired by an
unsupervised probing method called Contrast-Consistent Search (CCS). The idea
is to train a probing model guided by a logical constraint: a model's
representation of a statement and its negation must be mapped to contrastive
true-false poles consistently across multiple statements. We hypothesize that
similar constraints apply to ranking tasks where all items are related via
consistent pairwise or listwise comparisons. To this end, we extend the binary
CCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking
methods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression
objective. Our results confirm that, for the same language model, CCR probing
outperforms prompting and even performs on a par with prompting much larger
language models.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06998" title="Abstract">arXiv:2309.06998</a> [<a href="/pdf/2309.06998" title="Download PDF">pdf</a>, <a href="/ps/2309.06998" title="Download PostScript">ps</a>, <a href="/format/2309.06998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Synthesis of Configuration-Constrained Robust Invariant Sets  for Linear Parameter-Varying Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Mejari%2C+M">Manas Mejari</a>, 
<a href="/search/eess?searchtype=author&query=Mulagaleti%2C+S+K">Sampath Kumar Mulagaleti</a>, 
<a href="/search/eess?searchtype=author&query=Bemporad%2C+A">Alberto Bemporad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We present a data-driven method to synthesize robust control invariant (RCI)
sets for linear parameter-varying (LPV) systems subject to unknown but bounded
disturbances. A finite-length data set consisting of state, input, and
scheduling signal measurements is used to compute an RCI set and
invariance-inducing controller, without identifying an LPV model of the system.
We parameterize the RCI set as a configuration-constrained polytope whose
facets have a fixed orientation and variable offset. This allows us to define
the vertices of the polytopic set in terms of its offset. By exploiting this
property, an RCI set and associated vertex control inputs are computed by
solving a single linear programming (LP) problem, formulated based on a
data-based invariance condition and system constraints. We illustrate the
effectiveness of our approach via two numerical examples. The proposed method
can generate RCI sets that are of comparable size to those obtained by a
model-based method in which exact knowledge of the system matrices is assumed.
We show that RCI sets can be synthesized even with a relatively small number of
data samples, if the gathered data satisfy certain excitation conditions.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07001" title="Abstract">arXiv:2309.07001</a> [<a href="/pdf/2309.07001" title="Download PDF">pdf</a>, <a href="/format/2309.07001" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Analysis of Corporate ESG Reports: A Model of Evolutionary  Trends
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Ziyuan Xia</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+A">Anchen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xiaodong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Saixing Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Artificial Intelligence (cs.AI); Applications (stat.AP)

</div>
<p class="mathjax">Environmental, social, and governance (ESG) reports are globally recognized
as a keystone in sustainable enterprise development. This study aims to map the
changing landscape of ESG topics within firms in the global market. A dynamic
framework is developed to analyze ESG strategic management for individual
classes, across multiple classes, and in alignment with a specific
sustainability index. The output of these analytical processes forms the
foundation of an ESG strategic model. Utilizing a rich collection of
21st-century ESG reports from technology companies, our experiment elucidates
the changes in ESG perspectives by incorporating analytical keywords into the
proposed framework. This work thus provides an empirical method that reveals
the concurrent evolution of ESG topics over recent years.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07002" title="Abstract">arXiv:2309.07002</a> [<a href="/pdf/2309.07002" title="Download PDF">pdf</a>, <a href="/format/2309.07002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Morton-Like Layouts for Multi-Dimensional Arrays Using  Evolutionary Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swatman%2C+S+N">Stephen Nicholas Swatman</a>, 
<a href="/search/cs?searchtype=author&query=Varbanescu%2C+A">Ana-Lucia Varbanescu</a>, 
<a href="/search/cs?searchtype=author&query=Pimentel%2C+A+D">Andy D. Pimentel</a>, 
<a href="/search/cs?searchtype=author&query=Salzburger%2C+A">Andreas Salzburger</a>, 
<a href="/search/cs?searchtype=author&query=Krasznahorkay%2C+A">Attila Krasznahorkay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Performance (cs.PF)

</div>
<p class="mathjax">The layout of multi-dimensional data can have a significant impact on the
efficacy of hardware caches and, by extension, the performance of applications.
Common multi-dimensional layouts include the canonical row-major and
column-major layouts as well as the Morton curve layout. In this paper, we
describe how the Morton layout can be generalized to a very large family of
multi-dimensional data layouts with widely varying performance characteristics.
We posit that this design space can be efficiently explored using a
combinatorial evolutionary methodology based on genetic algorithms. To this
end, we propose a chromosomal representation for such layouts as well as a
methodology for estimating the fitness of array layouts using cache simulation.
We show that our fitness function correlates to kernel running time in real
hardware, and that our evolutionary strategy allows us to find candidates with
favorable simulated cache properties in four out of the eight real-world
applications under consideration in a small number of generations. Finally, we
demonstrate that the array layouts found using our evolutionary method perform
well not only in simulated environments but that they can effect significant
performance gains -- up to a factor ten in extreme cases -- in real hardware.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07009" title="Abstract">arXiv:2309.07009</a> [<a href="/pdf/2309.07009" title="Download PDF">pdf</a>, <a href="/format/2309.07009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OYXOY: A Modern NLP Test Suite for Modern Greek
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kogkalidis%2C+K">Konstantinos Kogkalidis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzikyriakidis%2C+S">Stergios Chatzikyriakidis</a>, 
<a href="/search/cs?searchtype=author&query=Giannikouri%2C+E+C">Eirini Chrysovalantou Giannikouri</a>, 
<a href="/search/cs?searchtype=author&query=Katsouli%2C+V">Vassiliki Katsouli</a>, 
<a href="/search/cs?searchtype=author&query=Klironomou%2C+C">Christina Klironomou</a>, 
<a href="/search/cs?searchtype=author&query=Koula%2C+C">Christina Koula</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+D">Dimitris Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Pasparaki%2C+T">Thelka Pasparaki</a>, 
<a href="/search/cs?searchtype=author&query=Psaltaki%2C+E">Erofili Psaltaki</a>, 
<a href="/search/cs?searchtype=author&query=Sakellariou%2C+E">Efthymia Sakellariou</a>, 
<a href="/search/cs?searchtype=author&query=Soupiona%2C+H">Hara Soupiona</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This paper serves as a foundational step towards the development of a
linguistically motivated and technically relevant evaluation suite for Greek
NLP. We initiate this endeavor by introducing four expert-verified evaluation
tasks, specifically targeted at natural language inference, word sense
disambiguation (through example comparison or sense selection) and metaphor
detection. More than language-adapted replicas of existing tasks, we contribute
two innovations which will resonate with the broader resource and evaluation
community. Firstly, our inference dataset is the first of its kind, marking not
just \textit{one}, but rather \textit{all} possible inference labels,
accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we
demonstrate a cost-efficient method to obtain datasets for under-resourced
languages. Using ChatGPT as a language-neutral parser, we transform the
Dictionary of Standard Modern Greek into a structured format, from which we
derive the other three tasks through simple projections. Alongside each task,
we conduct experiments using currently available state of the art machinery.
Our experimental baselines affirm the challenging nature of our tasks and
highlight the need for expedited progress in order for the Greek NLP ecosystem
to keep pace with contemporary mainstream research.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07011" title="Abstract">arXiv:2309.07011</a> [<a href="/pdf/2309.07011" title="Download PDF">pdf</a>, <a href="/format/2309.07011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Collective Tree Exploration by Tree-Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cosson%2C+R">Romain Cosson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">We investigate the problem of collaborative tree exploration with complete
communication introduced by [FGKP06], in which a group of $k$ agents is
assigned to collectively go through all edges of an unknown tree in an
efficient manner and then return to the origin. The agents have unrestricted
communication and computation capabilities. The algorithm's runtime is
typically compared to the cost of offline traversal, which is at least
$\max\{2n/k,2D\}$ where $n$ is the number of nodes and $D$ is the tree depth.
Since its introduction, two types of guarantee have emerged on the topic: the
first is of the form $r(k)(n/k+D)$, where $r(k)$ is called the competitive
ratio, and the other is of the form $2n/k+f(k,D)$, where $f(k,D)$ is called the
competitive overhead. In this paper, we present the first algorithm with
linear-in-$D$ competitive overhead, thereby reconciling both approaches.
Specifically, our bound is in $2n/k + O(k^{\log_2 k} D)$ and thus leads to a
competitive ratio in $O(k/\exp(0.8\sqrt{\ln k}))$. This is the first
improvement over the $O(k/\ln k)$-competitive algorithm known since the
introduction of the problem in 2004. Our algorithm is obtained for an
asynchronous generalization of collective tree exploration (ACTE). It is an
instance of a general class of locally-greedy exploration algorithms that we
define. We show that the additive overhead analysis of locally-greedy
algorithms can be seen through the lens of a 2-player game that we call the
tree-mining game and that could be of independent interest.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07014" title="Abstract">arXiv:2309.07014</a> [<a href="/pdf/2309.07014" title="Download PDF">pdf</a>, <a href="/format/2309.07014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Lidar Intensity for Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Weerakoon%2C+K">Kasun Weerakoon</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present Multi-Layer Intensity Map, a novel 3D object representation for
robot perception and autonomous navigation. They consist of multiple stacked
layers of 2D grid maps each derived from reflected point cloud intensities
corresponding to a certain height interval. The different layers of the
intensity maps can be used to simultaneously estimate obstacles' height,
solidity/density, and opacity. We demonstrate that they can help accurately
differentiate obstacles that are safe to navigate through (e.g. beaded/string
curtains, pliable tall grass), from ones that must be avoided (e.g. transparent
surfaces such as glass walls, bushes, trees, etc.) in indoor and outdoor
environments. Further, to handle narrow passages, and navigate through
non-solid obstacles in dense environments, we propose an approach to adaptively
inflate or enlarge the obstacles detected on intensity maps based on their
solidity, and the robot's preferred velocity direction. We demonstrate these
improved navigation capabilities in real-world narrow, dense environments using
a real Turtlebot and Boston Dynamics Spot. We observe significant increases in
success rates (up to 50%), a 9.55% decrease in trajectory length, and up to a
10.9% increase in the F-score compared to current navigation methods using
other sensor modalities.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07015" title="Abstract">arXiv:2309.07015</a> [<a href="/pdf/2309.07015" title="Download PDF">pdf</a>, <a href="/format/2309.07015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R&#xe9;sum&#xe9; Parsing as Hierarchical Sequence Labeling: An Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Retyk%2C+F">Federico Retyk</a>, 
<a href="/search/cs?searchtype=author&query=Fabregat%2C+H">Hermenegildo Fabregat</a>, 
<a href="/search/cs?searchtype=author&query=Aizpuru%2C+J">Juan Aizpuru</a>, 
<a href="/search/cs?searchtype=author&query=Taglio%2C+M">Mariana Taglio</a>, 
<a href="/search/cs?searchtype=author&query=Zbib%2C+R">Rabih Zbib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> RecSys in HR'23: The 3rd Workshop on Recommender Systems for Human Resources, in conjunction with the 17th ACM Conference on Recommender Systems, September 18--22, 2023, Singapore, Singapore
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">Extracting information from r\'esum\'es is typically formulated as a
two-stage problem, where the document is first segmented into sections and then
each section is processed individually to extract the target entities. Instead,
we cast the whole problem as sequence labeling in two levels -- lines and
tokens -- and study model architectures for solving both tasks simultaneously.
We build high-quality r\'esum\'e parsing corpora in English, French, Chinese,
Spanish, German, Portuguese, and Swedish. Based on these corpora, we present
experimental results that demonstrate the effectiveness of the proposed models
for the information extraction task, outperforming approaches introduced in
previous work. We conduct an ablation study of the proposed architectures. We
also analyze both model performance and resource efficiency, and describe the
trade-offs for model deployment in the context of a production environment.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07018" title="Abstract">arXiv:2309.07018</a> [<a href="/pdf/2309.07018" title="Download PDF">pdf</a>, <a href="/ps/2309.07018" title="Download PostScript">ps</a>, <a href="/format/2309.07018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perfect Roman Domination and Unique Response Roman Domination
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernau%2C+H">Henning Fernau</a>, 
<a href="/search/cs?searchtype=author&query=Mann%2C+K">Kevin Mann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Combinatorics (math.CO)

</div>
<p class="mathjax">The idea of enumeration algorithms with polynomial delay is to polynomially
bound the running time between any two subsequent solutions output by the
enumeration algorithm. While it is open for more than four decades if all
minimal dominating sets of a graph can be enumerated in output-polynomial time,
it has recently been proven that pointwise-minimal Roman dominating functions
can be enumerated even with polynomial delay. The idea of the enumeration
algorithm was to use polynomial-time solvable extension problems. We use this
as a motivation to prove that also two variants of Roman dominating functions
studied in the literature, named perfect and unique response, can be enumerated
with polynomial delay. This is interesting since Extension Perfect Roman
Domination is W[1]-complete if parameterized by the weight of the given
function and even W[2]-complete if parameterized by the number vertices
assigned 0 in the pre-solution, as we prove. Otherwise, efficient solvability
of extension problems and enumerability with polynomial delay tend to go
hand-in-hand. We achieve our enumeration result by constructing a bijection to
Roman dominating functions, where the corresponding extension problem is
polynomimaltime solvable. Furthermore, we show that Unique Response Roman
Domination is solvable in polynomial time on split graphs, while Perfect Roman
Domination is NP-complete on this graph class, which proves that both
variations, albeit coming with a very similar definition, do differ in some
complexity aspects. This way, we also solve an open problem from the
literature.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07020" title="Abstract">arXiv:2309.07020</a> [<a href="/pdf/2309.07020" title="Download PDF">pdf</a>, <a href="/format/2309.07020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond original Research Articles Categorization via NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turrisi%2C+R">Rosanna Turrisi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Workshop on Human-in-the-Loop Applied Machine Learning (HITLAML), 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> CEUR Workshop Proceedings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">This work proposes a novel approach to text categorization -- for unknown
categories -- in the context of scientific literature, using Natural Language
Processing techniques. The study leverages the power of pre-trained language
models, specifically SciBERT, to extract meaningful representations of
abstracts from the ArXiv dataset. Text categorization is performed using the
K-Means algorithm, and the optimal number of clusters is determined based on
the Silhouette score. The results demonstrate that the proposed approach
captures subject information more effectively than the traditional arXiv
labeling system, leading to improved text categorization. The approach offers
potential for better navigation and recommendation systems in the rapidly
growing landscape of scientific research literature.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07021" title="Abstract">arXiv:2309.07021</a> [<a href="/pdf/2309.07021" title="Download PDF">pdf</a>, <a href="/format/2309.07021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Multiple Priors for Neural 3D Indoor Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lincetto%2C+F">Federico Lincetto</a>, 
<a href="/search/cs?searchtype=author&query=Agresti%2C+G">Gianluca Agresti</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+M">Mattia Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Zanuttigh%2C+P">Pietro Zanuttigh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the British Machine Vision Conference (BMVC) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Neural implicit modeling permits to achieve impressive 3D reconstruction
results on small objects, while it exhibits significant limitations in large
indoor scenes. In this work, we propose a novel neural implicit modeling method
that leverages multiple regularization strategies to achieve better
reconstructions of large indoor environments, while relying only on images. A
sparse but accurate depth prior is used to anchor the scene to the initial
model. A dense but less accurate depth prior is also introduced, flexible
enough to still let the model diverge from it to improve the estimated
geometry. Then, a novel self-supervised strategy to regularize the estimated
surface normals is presented. Finally, a learnable exposure compensation scheme
permits to cope with challenging lighting conditions. Experimental results show
that our approach produces state-of-the-art 3D reconstructions in challenging
indoor scenarios.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07022" title="Abstract">arXiv:2309.07022</a> [<a href="/pdf/2309.07022" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptography: Against AI and QAI Odds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harris%2C+S">Sheetal Harris</a>, 
<a href="/search/cs?searchtype=author&query=Hadi%2C+H+J">Hassan Jalil Hadi</a>, 
<a href="/search/cs?searchtype=author&query=Zukaib%2C+U">Umer Zukaib</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Artificial Intelligence (AI) presents prodigious technological prospects for
development, however, all that glitters is not gold! The cyber-world faces the
worst nightmare with the advent of AI and quantum computers. Together with
Quantum Artificial Intelligence (QAI), they pose a catastrophic threat to
modern cryptography. It would also increase the capability of cryptanalysts
manifold, with its built-in persistent and extensive predictive intelligence.
This prediction ability incapacitates the constrained message space in device
cryptography. With the comparison of these assumptions and the intercepted
ciphertext, the code-cracking process will considerably accelerate. Before the
vigorous and robust developments in AI, we have never faced and never had to
prepare for such a plaintext-originating attack. The supremacy of AI can be
challenged by creating ciphertexts that would give the AI attacker erroneous
responses stymied by randomness and misdirect them. AI threat is deterred by
deviating from the conventional use of small, known-size keys and
pattern-loaded ciphers. The strategy is vested in implementing larger secret
size keys, supplemented by ad-hoc unilateral randomness of unbound limitations
and a pattern-devoid technique. The very large key size can be handled with low
processing and computational burden to achieve desired unicity distances. The
strategy against AI odds is feasible by implementing non-algorithmic
randomness, large and inexpensive memory chips, and wide-area communication
networks. The strength of AI, i.e., randomness and pattern detection can be
used to generate highly optimized ciphers and algorithms. These pattern-devoid,
randomness-rich ciphers also provide a timely and plausible solution for NIST's
proactive approach toward the quantum challenge.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07026" title="Abstract">arXiv:2309.07026</a> [<a href="/pdf/2309.07026" title="Download PDF">pdf</a>, <a href="/format/2309.07026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> APICom: Automatic API Completion via Prompt Learning and Adversarial  Training-based Data Augmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Y">Yafeng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yiheng Shen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shaoyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yiling Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhixiang Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in Internetware 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Based on developer needs and usage scenarios, API (Application Programming
Interface) recommendation is the process of assisting developers in finding the
required API among numerous candidate APIs. Previous studies mainly modeled API
recommendation as the recommendation task, which can recommend multiple
candidate APIs for the given query, and developers may not yet be able to find
what they need. Motivated by the neural machine translation research domain, we
can model this problem as the generation task, which aims to directly generate
the required API for the developer query. After our preliminary investigation,
we find the performance of this intuitive approach is not promising. The reason
is that there exists an error when generating the prefixes of the API. However,
developers may know certain API prefix information during actual development in
most cases. Therefore, we model this problem as the automatic completion task
and propose a novel approach APICom based on prompt learning, which can
generate API related to the query according to the prompts (i.e., API prefix
information). Moreover, the effectiveness of APICom highly depends on the
quality of the training dataset. In this study, we further design a novel
gradient-based adversarial training method {\atpart} for data augmentation,
which can improve the normalized stability when generating adversarial
examples. To evaluate the effectiveness of APICom, we consider a corpus of 33k
developer queries and corresponding APIs. Compared with the state-of-the-art
baselines, our experimental results show that APICom can outperform all
baselines by at least 40.02\%, 13.20\%, and 16.31\% in terms of the performance
measures EM@1, MRR, and MAP. Finally, our ablation studies confirm the
effectiveness of our component setting (such as our designed adversarial
training method, our used pre-trained model, and prompt learning) in APICom.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07028" title="Abstract">arXiv:2309.07028</a> [<a href="/pdf/2309.07028" title="Download PDF">pdf</a>, <a href="/ps/2309.07028" title="Download PostScript">ps</a>, <a href="/format/2309.07028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Machine Co-Creativity with Older Adults -- A Learning Community to  Study Explainable Dialogues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bossema%2C+M">Marianne Bossema</a>, 
<a href="/search/cs?searchtype=author&query=Saunders%2C+R">Rob Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Allouch%2C+S+B">Somaya Ben Allouch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This position paper is part of a long-term research project on human-machine
co-creativity with older adults. The goal is to investigate how robots and
AI-generated content can contribute to older adults' creative experiences, with
a focus on collaborative drawing and painting. The research has recently
started, and current activities are centred around literature studies,
interviews with seniors and artists, and developing initial prototypes. In
addition, a course "Drawing with Robots", is being developed to establish
collaboration between human and machine learners: older adults, artists,
students, researchers, and artificial agents. We present this course as a
learning community and as an opportunity for studying how explainable AI and
creative dialogues can be intertwined in human-machine co-creativity with older
adults.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07030" title="Abstract">arXiv:2309.07030</a> [<a href="/pdf/2309.07030" title="Download PDF">pdf</a>, <a href="/format/2309.07030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal transport distances for directed, weighted graphs: a case study  with cell-cell communication networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagai%2C+J+S">James S. Nagai</a> (1), 
<a href="/search/cs?searchtype=author&query=Costa%2C+I+G">Ivan G. Costa</a> (1), 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a> (2) ((1) Institute for Computational Genomics, RWTH Aachen Medical Faculty, Germany, (2) Department of Computer Science, RWTH Aachen University, Germany)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Systems and Control (eess.SY); Genomics (q-bio.GN); Molecular Networks (q-bio.MN)

</div>
<p class="mathjax">Comparing graphs of optimal transport has recently gained significant
attention, as the distances induced by optimal transport provide both a
principled metric between graphs as well as an interpretable description of the
associated changes between graphs in terms of a transport plan. As the lack of
symmetry introduces challenges in the typically considered formulations,
optimal transport distances for graphs have mostly been developed for
undirected graphs. Here, we propose two distance measures to compare directed
graphs based on variants of optimal transport: (i) an earth movers distance
(Wasserstein) and (ii) a Gromov-Wasserstein (GW) distance. We evaluate these
two distances and discuss their relative performance for both simulated graph
data and real-world directed cell-cell communication graphs, inferred from
single-cell RNA-seq data.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07033" title="Abstract">arXiv:2309.07033</a> [<a href="/pdf/2309.07033" title="Download PDF">pdf</a>, <a href="/format/2309.07033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Robot Co-creativity: A Scoping Review -- Informing a Research  Agenda for Human-Robot Co-Creativity with Older Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bossema%2C+M">Marianne Bossema</a>, 
<a href="/search/cs?searchtype=author&query=Allouch%2C+S+B">Somaya Ben Allouch</a>, 
<a href="/search/cs?searchtype=author&query=Plaat%2C+A">Aske Plaat</a>, 
<a href="/search/cs?searchtype=author&query=Saunders%2C+R">Rob Saunders</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">This review is the first step in a long-term research project exploring how
social robotics and AI-generated content can contribute to the creative
experiences of older adults, with a focus on collaborative drawing and
painting. We systematically searched and selected literature on human-robot
co-creativity, and analyzed articles to identify methods and strategies for
researching co-creative robotics. We found that none of the studies involved
older adults, which shows the gap in the literature for this often involved
participant group in robotics research. The analyzed literature provides
valuable insights into the design of human-robot co-creativity and informs a
research agenda to further investigate the topic with older adults. We argue
that future research should focus on ecological and developmental perspectives
on creativity, on how system behavior can be aligned with the values of older
adults, and on the system structures that support this best.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07034" title="Abstract">arXiv:2309.07034</a> [<a href="/pdf/2309.07034" title="Download PDF">pdf</a>, <a href="/format/2309.07034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How (Not) to Use Sociodemographic Information for Subjective NLP Tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beck%2C+T">Tilman Beck</a>, 
<a href="/search/cs?searchtype=author&query=Schuff%2C+H">Hendrik Schuff</a>, 
<a href="/search/cs?searchtype=author&query=Lauscher%2C+A">Anne Lauscher</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Annotators' sociodemographic backgrounds (i.e., the individual compositions
of their gender, age, educational background, etc.) have a strong impact on
their decisions when working on subjective NLP tasks, such as hate speech
detection. Often, heterogeneous backgrounds result in high disagreements. To
model this variation, recent work has explored sociodemographic prompting, a
technique, which steers the output of prompt-based models towards answers that
humans with specific sociodemographic profiles would give. However, the
available NLP literature disagrees on the efficacy of this technique -- it
remains unclear, for which tasks and scenarios it can help and evaluations are
limited to specific tasks only. We address this research gap by presenting the
largest and most comprehensive study of sociodemographic prompting today.
Concretely, we evaluate several prompt formulations across seven datasets and
six instruction-tuned model families. We find that (1) while sociodemographic
prompting can be beneficial for improving zero-shot learning in subjective NLP
tasks, (2) its outcomes largely vary for different model types, sizes, and
datasets, (3) are subject to large variance with regards to prompt
formulations. Thus, sociodemographic prompting is not a reliable proxy for
traditional data annotation with a sociodemographically heterogeneous group of
annotators. Instead, we propose (4) to use it for identifying ambiguous
instances resulting in more informed annotation efforts.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07038" title="Abstract">arXiv:2309.07038</a> [<a href="/pdf/2309.07038" title="Download PDF">pdf</a>, <a href="/format/2309.07038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Reinforcement Learning for Jumping Monopods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bussola%2C+R">Riccardo Bussola</a>, 
<a href="/search/cs?searchtype=author&query=Focchi%2C+M">Michele Focchi</a>, 
<a href="/search/cs?searchtype=author&query=Del+Prete%2C+A">Andrea Del Prete</a>, 
<a href="/search/cs?searchtype=author&query=Fontanelli%2C+D">Daniele Fontanelli</a>, 
<a href="/search/cs?searchtype=author&query=Palopoli%2C+L">Luigi Palopoli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we consider the complex control problem of making a monopod
reach a target with a jump. The monopod can jump in any direction and the
terrain underneath its foot can be uneven. This is a template of a much larger
class of problems, which are extremely challenging and computationally
expensive to solve using standard optimisation-based techniques. Reinforcement
Learning (RL) could be an interesting alternative, but the application of an
end-to-end approach in which the controller must learn everything from scratch,
is impractical. The solution advocated in this paper is to guide the learning
process within an RL framework by injecting physical knowledge. This expedient
brings to widespread benefits, such as a drastic reduction of the learning
time, and the ability to learn and compensate for possible errors in the
low-level controller executing the motion. We demonstrate the advantage of our
approach with respect to both optimization-based and end-to-end RL approaches.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07045" title="Abstract">arXiv:2309.07045</a> [<a href="/pdf/2309.07045" title="Download PDF">pdf</a>, <a href="/format/2309.07045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SafetyBench: Evaluating the Safety of Large Language Models with  Multiple Choice Questions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhexin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+L">Leqi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Lindong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Rui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yongkang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+C">Chong Long</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+X">Xuanyu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+J">Jie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+M">Minlie Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the rapid development of Large Language Models (LLMs), increasing
attention has been paid to their safety concerns. Consequently, evaluating the
safety of LLMs has become an essential task for facilitating the broad
applications of LLMs. Nevertheless, the absence of comprehensive safety
evaluation benchmarks poses a significant impediment to effectively assess and
enhance the safety of LLMs. In this work, we present SafetyBench, a
comprehensive benchmark for evaluating the safety of LLMs, which comprises
11,435 diverse multiple choice questions spanning across 7 distinct categories
of safety concerns. Notably, SafetyBench also incorporates both Chinese and
English data, facilitating the evaluation in both languages. Our extensive
tests over 25 popular Chinese and English LLMs in both zero-shot and few-shot
settings reveal a substantial performance advantage for GPT-4 over its
counterparts, and there is still significant room for improving the safety of
current LLMs. We believe SafetyBench will enable fast and comprehensive
evaluation of LLMs' safety, and foster the development of safer LLMs. Data and
evaluation guidelines are available at https://github.com/thu-coai/SafetyBench.
Submission entrance and leaderboard are available at
https://llmbench.ai/safety.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07049" title="Abstract">arXiv:2309.07049</a> [<a href="/pdf/2309.07049" title="Download PDF">pdf</a>, <a href="/format/2309.07049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Extreme Learning Machine-Based Method for Computational PDEs in  Higher Dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yiran Wang</a>, 
<a href="/search/math?searchtype=author&query=Dong%2C+S">Suchuan Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 17 tables, 25 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">We present two effective methods for solving high-dimensional partial
differential equations (PDE) based on randomized neural networks. Motivated by
the universal approximation property of this type of networks, both methods
extend the extreme learning machine (ELM) approach from low to high dimensions.
With the first method the unknown solution field in $d$ dimensions is
represented by a randomized feed-forward neural network, in which the
hidden-layer parameters are randomly assigned and fixed while the output-layer
parameters are trained. The PDE and the boundary/initial conditions, as well as
the continuity conditions (for the local variant of the method), are enforced
on a set of random interior/boundary collocation points. The resultant linear
or nonlinear algebraic system, through its least squares solution, provides the
trained values for the network parameters. With the second method the
high-dimensional PDE problem is reformulated through a constrained expression
based on an Approximate variant of the Theory of Functional Connections
(A-TFC), which avoids the exponential growth in the number of terms of TFC as
the dimension increases. The free field function in the A-TFC constrained
expression is represented by a randomized neural network and is trained by a
procedure analogous to the first method. We present ample numerical simulations
for a number of high-dimensional linear/nonlinear stationary/dynamic PDEs to
demonstrate their performance. These methods can produce accurate solutions to
high-dimensional PDEs, in particular with their errors reaching levels not far
from the machine accuracy for relatively lower dimensions. Compared with the
physics-informed neural network (PINN) method, the current method is both
cost-effective and more accurate for high-dimensional PDEs.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07050" title="Abstract">arXiv:2309.07050</a> [<a href="/pdf/2309.07050" title="Download PDF">pdf</a>, <a href="/format/2309.07050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Robot Informative Path Planning from Regression with Sparse  Gaussian Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakkala%2C+K">Kalvik Jakkala</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+S">Srinivas Akella</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper addresses multi-robot informative path planning (IPP) for
environmental monitoring. The problem involves determining informative regions
in the environment that should be visited by robots in order to gather the most
information about the environment. We propose an efficient sparse Gaussian
process-based approach that uses gradient descent to optimize paths in
continuous environments. Our approach efficiently scales to both spatially and
spatio-temporally correlated environments. Moreover, our approach can
simultaneously optimize the informative paths while accounting for routing
constraints, such as a distance budget and limits on the robot's velocity and
acceleration. Our approach can be used for IPP with both discrete and
continuous sensing robots, with point and non-point field-of-view sensing
shapes, and for multi-robot IPP. The proposed approach is demonstrated to be
fast and accurate on real-world data.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07051" title="Abstract">arXiv:2309.07051</a> [<a href="/pdf/2309.07051" title="Download PDF">pdf</a>, <a href="/format/2309.07051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnifiedGesture: A Unified Gesture Synthesis Model for Multiple Skeletons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sicheng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zilin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhiyong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Minglei Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhensong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiaochu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+L">Lei Hao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Songcen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaofei Wu</a>, 
<a href="/search/cs?searchtype=author&query=yang%2C+c">changpeng yang</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zonghong Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 11 figures, ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The automatic co-speech gesture generation draws much attention in computer
animation. Previous works designed network structures on individual datasets,
which resulted in a lack of data volume and generalizability across different
motion capture standards. In addition, it is a challenging task due to the weak
correlation between speech and gestures. To address these problems, we present
UnifiedGesture, a novel diffusion model-based speech-driven gesture synthesis
approach, trained on multiple gesture datasets with different skeletons.
Specifically, we first present a retargeting network to learn latent
homeomorphic graphs for different motion capture standards, unifying the
representations of various gestures while extending the dataset. We then
capture the correlation between speech and gestures based on a diffusion model
architecture using cross-local attention and self-attention to generate better
speech-matched and realistic gestures. To further align speech and gesture and
increase diversity, we incorporate reinforcement learning on the discrete
gesture units with a learned reward function. Extensive experiments show that
UnifiedGesture outperforms recent approaches on speech-driven gesture
generation in terms of CCA, FGD, and human-likeness. All code, pre-trained
models, databases, and demos are available to the public at
https://github.com/YoungSeng/UnifiedGesture.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07053" title="Abstract">arXiv:2309.07053</a> [<a href="/pdf/2309.07053" title="Download PDF">pdf</a>, <a href="/format/2309.07053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pearl&#x27;s and Jeffrey&#x27;s Update as Modes of Learning in Probabilistic  Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jacobs%2C+B">Bart Jacobs</a>, 
<a href="/search/cs?searchtype=author&query=Stein%2C+D">Dario Stein</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> MFPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The concept of updating a probability distribution in the light of new
evidence lies at the heart of statistics and machine learning. Pearl's and
Jeffrey's rule are two natural update mechanisms which lead to different
outcomes, yet the similarities and differences remain mysterious. This paper
clarifies their relationship in several ways: via separate descriptions of the
two update mechanisms in terms of probabilistic programs and sampling
semantics, and via different notions of likelihood (for Pearl and for Jeffrey).
Moreover, it is shown that Jeffrey's update rule arises via variational
inference. In terms of categorical probability theory, this amounts to an
analysis of the situation in terms of the behaviour of the multiset functor,
extended to the Kleisli category of the distribution monad.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07054" title="Abstract">arXiv:2309.07054</a> [<a href="/pdf/2309.07054" title="Download PDF">pdf</a>, <a href="/format/2309.07054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Aggregating Long-term Sharp Features via Hybrid Transformers for Video  Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+D">Dongwei Ren</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+W">Wei Shang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, and the code is available at <a href="https://github.com/shangwei5/STGTN">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video deblurring methods, aiming at recovering consecutive sharp frames from
a given blurry video, usually assume that the input video suffers from
consecutively blurry frames. However, in real-world blurry videos taken by
modern imaging devices, sharp frames usually appear in the given video, thus
making temporal long-term sharp features available for facilitating the
restoration of a blurry frame. In this work, we propose a video deblurring
method that leverages both neighboring frames and present sharp frames using
hybrid Transformers for feature aggregation. Specifically, we first train a
blur-aware detector to distinguish between sharp and blurry frames. Then, a
window-based local Transformer is employed for exploiting features from
neighboring frames, where cross attention is beneficial for aggregating
features from neighboring frames without explicit spatial alignment. To
aggregate long-term sharp features from detected sharp frames, we utilize a
global Transformer with multi-scale matching capability. Moreover, our method
can easily be extended to event-driven video deblurring by incorporating an
event fusion module into the global Transformer. Extensive experiments on
benchmark datasets demonstrate that our proposed method outperforms
state-of-the-art video deblurring methods as well as event-driven video
deblurring methods in terms of quantitative metrics and visual quality. The
source code and trained models are available at
https://github.com/shangwei5/STGTN.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07055" title="Abstract">arXiv:2309.07055</a> [<a href="/pdf/2309.07055" title="Download PDF">pdf</a>, <a href="/format/2309.07055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geospatial Tessellation in the Agent-In-Cell Model: A Framework for  Agent-Based Modeling of Pandemic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sikaroudi%2C+A+M+E">Amir Mohammad Esmaieeli Sikaroudi</a>, 
<a href="/search/cs?searchtype=author&query=Efrat%2C+A">Alon Efrat</a>, 
<a href="/search/cs?searchtype=author&query=Chertkov%2C+M">Michael Chertkov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Agent-based simulation is a versatile and potent computational modeling
technique employed to analyze intricate systems and phenomena spanning diverse
fields. However, due to their computational intensity, agent-based models
become more resource-demanding when geographic considerations are introduced.
This study delves into diverse strategies for crafting a series of Agent-Based
Models, named "agent-in-the-cell," which emulate a city. These models,
incorporating geographical attributes of the city and employing real-world
open-source mobility data from Safegraph's publicly available dataset, simulate
the dynamics of COVID spread under varying scenarios. The "agent-in-the-cell"
concept designates that our representative agents, called meta-agents, are
linked to specific home cells in the city's tessellation. We scrutinize
tessellations of the mobility map with varying complexities and experiment with
the agent density, ranging from matching the actual population to reducing the
number of (meta-) agents for computational efficiency. Our findings demonstrate
that tessellations constructed according to the Voronoi Diagram of specific
location types on the street network better preserve dynamics compared to
Census Block Group tessellations and better than Euclidean-based tessellations.
Furthermore, the Voronoi Diagram tessellation and also a hybrid -- Voronoi
Diagram - and Census Block Group - based -- tessellation require fewer
meta-agents to adequately approximate full-scale dynamics. Our analysis spans a
range of city sizes in the United States, encompassing small (Santa Fe, NM),
medium (Seattle, WA), and large (Chicago, IL) urban areas. This examination
also provides valuable insights into the effects of agent count reduction,
varying sensitivity metrics, and the influence of city-specific factors.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07062" title="Abstract">arXiv:2309.07062</a> [<a href="/pdf/2309.07062" title="Download PDF">pdf</a>, <a href="/format/2309.07062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Compiler Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cummins%2C+C">Chris Cummins</a>, 
<a href="/search/cs?searchtype=author&query=Seeker%2C+V">Volker Seeker</a>, 
<a href="/search/cs?searchtype=author&query=Grubisic%2C+D">Dejan Grubisic</a>, 
<a href="/search/cs?searchtype=author&query=Elhoushi%2C+M">Mostafa Elhoushi</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Youwei Liang</a>, 
<a href="/search/cs?searchtype=author&query=Roziere%2C+B">Baptiste Roziere</a>, 
<a href="/search/cs?searchtype=author&query=Gehring%2C+J">Jonas Gehring</a>, 
<a href="/search/cs?searchtype=author&query=Gloeckle%2C+F">Fabian Gloeckle</a>, 
<a href="/search/cs?searchtype=author&query=Hazelwood%2C+K">Kim Hazelwood</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Leather%2C+H">Hugh Leather</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">We explore the novel application of Large Language Models to code
optimization. We present a 7B-parameter transformer model trained from scratch
to optimize LLVM assembly for code size. The model takes as input unoptimized
assembly and outputs a list of compiler options to best optimize the program.
Crucially, during training, we ask the model to predict the instruction counts
before and after optimization, and the optimized code itself. These auxiliary
learning tasks significantly improve the optimization performance of the model
and improve the model's depth of understanding.
<br />We evaluate on a large suite of test programs. Our approach achieves a 3.0%
improvement in reducing instruction counts over the compiler, outperforming two
state-of-the-art baselines that require thousands of compilations. Furthermore,
the model shows surprisingly strong code reasoning abilities, generating
compilable code 91% of the time and perfectly emulating the output of the
compiler 70% of the time.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07064" title="Abstract">arXiv:2309.07064</a> [<a href="/pdf/2309.07064" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Analysis of the Role of Artificial Intelligence and  Machine Learning in Modern Digital Forensics and Incident Response
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dunsin%2C+D">Dipo Dunsin</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+M+C">Mohamed C. Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Ouazzane%2C+K">Karim Ouazzane</a>, 
<a href="/search/cs?searchtype=author&query=Vassilev%2C+V">Vassil Vassilev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">In the dynamic landscape of digital forensics, the integration of Artificial
Intelligence (AI) and Machine Learning (ML) stands as a transformative
technology, poised to amplify the efficiency and precision of digital forensics
investigations. However, the use of ML and AI in digital forensics is still in
its nascent stages. As a result, this paper gives a thorough and in-depth
analysis that goes beyond a simple survey and review. The goal is to look
closely at how AI and ML techniques are used in digital forensics and incident
response. This research explores cutting-edge research initiatives that cross
domains such as data collection and recovery, the intricate reconstruction of
cybercrime timelines, robust big data analysis, pattern recognition,
safeguarding the chain of custody, and orchestrating responsive strategies to
hacking incidents. This endeavour digs far beneath the surface to unearth the
intricate ways AI-driven methodologies are shaping these crucial facets of
digital forensics practice. While the promise of AI in digital forensics is
evident, the challenges arising from increasing database sizes and evolving
criminal tactics necessitate ongoing collaborative research and refinement
within the digital forensics profession. This study examines the contributions,
limitations, and gaps in the existing research, shedding light on the potential
and limitations of AI and ML techniques. By exploring these different research
areas, we highlight the critical need for strategic planning, continual
research, and development to unlock AI's full potential in digital forensics
and incident response. Ultimately, this paper underscores the significance of
AI and ML integration in digital forensics, offering insights into their
benefits, drawbacks, and broader implications for tackling modern cyber
threats.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07066" title="Abstract">arXiv:2309.07066</a> [<a href="/pdf/2309.07066" title="Download PDF">pdf</a>, <a href="/format/2309.07066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLiFF-LHMP: Using Spatial Dynamics Patterns for Long-Term Human Motion  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yufei Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Rudenko%2C+A">Andrey Rudenko</a>, 
<a href="/search/cs?searchtype=author&query=Kucner%2C+T+P">Tomasz P. Kucner</a>, 
<a href="/search/cs?searchtype=author&query=Palmieri%2C+L">Luigi Palmieri</a>, 
<a href="/search/cs?searchtype=author&query=Arras%2C+K+O">Kai O. Arras</a>, 
<a href="/search/cs?searchtype=author&query=Lilienthal%2C+A+J">Achim J. Lilienthal</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+M">Martin Magnusson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Human motion prediction is important for mobile service robots and
intelligent vehicles to operate safely and smoothly around people. The more
accurate predictions are, particularly over extended periods of time, the
better a system can, e.g., assess collision risks and plan ahead. In this
paper, we propose to exploit maps of dynamics (MoDs, a class of general
representations of place-dependent spatial motion patterns, learned from prior
observations) for long-term human motion prediction (LHMP). We present a new
MoD-informed human motion prediction approach, named CLiFF-LHMP, which is data
efficient, explainable, and insensitive to errors from an upstream tracking
system. Our approach uses CLiFF-map, a specific MoD trained with human motion
data recorded in the same environment. We bias a constant velocity prediction
with samples from the CLiFF-map to generate multi-modal trajectory predictions.
In two public datasets we show that this algorithm outperforms the state of the
art for predictions over very extended periods of time, achieving 45% more
accurate prediction performance at 50s compared to the baseline.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07067" title="Abstract">arXiv:2309.07067</a> [<a href="/pdf/2309.07067" title="Download PDF">pdf</a>, <a href="/format/2309.07067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Pipeline Quality: Influencing Factors, Root Causes of Data-related  Issues, and Processing Problem Areas for Developers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foidl%2C+H">Harald Foidl</a>, 
<a href="/search/cs?searchtype=author&query=Golendukhina%2C+V">Valentina Golendukhina</a>, 
<a href="/search/cs?searchtype=author&query=Ramler%2C+R">Rudolf Ramler</a>, 
<a href="/search/cs?searchtype=author&query=Felderer%2C+M">Michael Felderer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published by The Journal of Systems &amp; Software
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Databases (cs.DB)

</div>
<p class="mathjax">Data pipelines are an integral part of various modern data-driven systems.
However, despite their importance, they are often unreliable and deliver
poor-quality data. A critical step toward improving this situation is a solid
understanding of the aspects contributing to the quality of data pipelines.
Therefore, this article first introduces a taxonomy of 41 factors that
influence the ability of data pipelines to provide quality data. The taxonomy
is based on a multivocal literature review and validated by eight interviews
with experts from the data engineering domain. Data, infrastructure, life cycle
management, development &amp; deployment, and processing were found to be the main
influencing themes. Second, we investigate the root causes of data-related
issues, their location in data pipelines, and the main topics of data pipeline
processing issues for developers by mining GitHub projects and Stack Overflow
posts. We found data-related issues to be primarily caused by incorrect data
types (33%), mainly occurring in the data cleaning stage of pipelines (35%).
Data integration and ingestion tasks were found to be the most asked topics of
developers, accounting for nearly half (47%) of all questions. Compatibility
issues were found to be a separate problem area in addition to issues
corresponding to the usual data pipeline processing areas (i.e., data loading,
ingestion, integration, cleaning, and transformation). These findings suggest
that future research efforts should focus on analyzing compatibility and data
type issues in more depth and assisting developers in data integration and
ingestion tasks. The proposed taxonomy is valuable to practitioners in the
context of quality assurance activities and fosters future research into data
pipeline quality.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07068" title="Abstract">arXiv:2309.07068</a> [<a href="/pdf/2309.07068" title="Download PDF">pdf</a>, <a href="/format/2309.07068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FAIR: Frequency-aware Image Restoration for Industrial Visual Anomaly  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tongkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xiao Du</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+B">Bingke Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+L">Leqi Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Feiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image reconstruction-based anomaly detection models are widely explored in
industrial visual inspection. However, existing models usually suffer from the
trade-off between normal reconstruction fidelity and abnormal reconstruction
distinguishability, which damages the performance. In this paper, we find that
the above trade-off can be better mitigated by leveraging the distinct
frequency biases between normal and abnormal reconstruction errors. To this
end, we propose Frequency-aware Image Restoration (FAIR), a novel
self-supervised image restoration task that restores images from their
high-frequency components. It enables precise reconstruction of normal patterns
while mitigating unfavorable generalization to anomalies. Using only a simple
vanilla UNet, FAIR achieves state-of-the-art performance with higher efficiency
on various defect detection datasets. Code: https://github.com/liutongkun/FAIR.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07072" title="Abstract">arXiv:2309.07072</a> [<a href="/pdf/2309.07072" title="Download PDF">pdf</a>, <a href="/ps/2309.07072" title="Download PostScript">ps</a>, <a href="/format/2309.07072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Boundaries of Verifiable Accuracy, Robustness, and Generalisation in  Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastounis%2C+A">Alexander Bastounis</a>, 
<a href="/search/cs?searchtype=author&query=Gorban%2C+A+N">Alexander N. Gorban</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+A+C">Anders C. Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Higham%2C+D+J">Desmond J. Higham</a>, 
<a href="/search/cs?searchtype=author&query=Prokhorov%2C+D">Danil Prokhorov</a>, 
<a href="/search/cs?searchtype=author&query=Sutton%2C+O">Oliver Sutton</a>, 
<a href="/search/cs?searchtype=author&query=Tyukin%2C+I+Y">Ivan Y. Tyukin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Q">Qinghua Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this work, we assess the theoretical limitations of determining guaranteed
stability and accuracy of neural networks in classification tasks. We consider
classical distribution-agnostic framework and algorithms minimising empirical
risks and potentially subjected to some weights regularisation. We show that
there is a large family of tasks for which computing and verifying ideal stable
and accurate neural networks in the above settings is extremely challenging, if
at all possible, even when such ideal solutions exist within the given class of
neural architectures.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07075" title="Abstract">arXiv:2309.07075</a> [<a href="/pdf/2309.07075" title="Download PDF">pdf</a>, <a href="/format/2309.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chained-DP: Can We Recycle Privacy Budget?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J+L+G">Jingyi Li Guangjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Liekang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=and%2C+L+C">Lin Chen and</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper was accepted by IEEE/ACM IWQoS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
<p class="mathjax">Privacy-preserving vector mean estimation is a crucial primitive in federated
analytics. Existing practices usually resort to Local Differentiated Privacy
(LDP) mechanisms that inject random noise into users' vectors when
communicating with users and the central server. Due to the privacy-utility
trade-off, the privacy budget has been widely recognized as the bottleneck
resource that requires well-provisioning. In this paper, we explore the
possibility of privacy budget recycling and propose a novel Chained-DP
framework enabling users to carry out data aggregation sequentially to recycle
the privacy budget. We establish a sequential game to model the user
interactions in our framework. We theoretically show the mathematical nature of
the sequential game, solve its Nash Equilibrium, and design an incentive
mechanism with provable economic properties. We further derive a differentially
privacy-guaranteed protocol to alleviate potential privacy collusion attacks to
avoid holistic exposure. Our numerical simulation validates the effectiveness
of Chained-DP, showing that it can significantly save privacy budget and lower
estimation error compared to the traditional LDP mechanism.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07077" title="Abstract">arXiv:2309.07077</a> [<a href="/pdf/2309.07077" title="Download PDF">pdf</a>, <a href="/format/2309.07077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimized Implementation of Neuromorphic HATS Algorithm on FPGA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sethi%2C+K">Khushal Sethi</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+M">Manan Suri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">In this paper, we present first-ever optimized hardware implementation of a
state-of-the-art neuromorphic approach Histogram of Averaged Time Surfaces
(HATS) algorithm to event-based object classification in FPGA for asynchronous
time-based image sensors (ATIS). Our Implementation achieves latency of 3.3 ms
for the N-CARS dataset samples and is capable of processing 2.94 Mevts/s.
Speed-up is achieved by using parallelism in the design and multiple Processing
Elements can be added. As development platform, Zynq-7000 SoC from Xilinx is
used. The tradeoff between Average Absolute Error and Resource Utilization for
fixed precision implementation is analyzed and presented. The proposed FPGA
implementation is $\sim$ 32 x power efficient compared to software
implementation.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07084" title="Abstract">arXiv:2309.07084</a> [<a href="/pdf/2309.07084" title="Download PDF">pdf</a>, <a href="/format/2309.07084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yiran Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoqun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Z">Zijian Kang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+N">Ningning Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruimao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we propose a novel training strategy called SupFusion, which
provides an auxiliary feature level supervision for effective LiDAR-Camera
fusion and significantly boosts detection performance. Our strategy involves a
data enhancement method named Polar Sampling, which densifies sparse objects
and trains an assistant model to generate high-quality features as the
supervision. These features are then used to train the LiDAR-Camera fusion
model, where the fusion feature is optimized to simulate the generated
high-quality features. Furthermore, we propose a simple yet effective deep
fusion module, which contiguously gains superior performance compared with
previous fusion methods with SupFusion strategy. In such a manner, our proposal
shares the following advantages. Firstly, SupFusion introduces auxiliary
feature-level supervision which could boost LiDAR-Camera detection performance
without introducing extra inference costs. Secondly, the proposed deep fusion
could continuously improve the detector's abilities. Our proposed SupFusion and
deep fusion module is plug-and-play, we make extensive experiments to
demonstrate its effectiveness. Specifically, we gain around 2% 3D mAP
improvements on KITTI benchmark based on multiple LiDAR-Camera 3D detectors.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07085" title="Abstract">arXiv:2309.07085</a> [<a href="/pdf/2309.07085" title="Download PDF">pdf</a>, <a href="/format/2309.07085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Group Bias in Federated Learning for Heterogeneous Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Selialia%2C+K">Khotso Selialia</a>, 
<a href="/search/cs?searchtype=author&query=Chandio%2C+Y">Yasra Chandio</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+F+M">Fatima M. Anwar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Federated Learning is emerging as a privacy-preserving model training
approach in distributed edge applications. As such, most edge deployments are
heterogeneous in nature i.e., their sensing capabilities and environments vary
across deployments. This edge heterogeneity violates the independence and
identical distribution (IID) property of local data across clients and produces
biased global models i.e. models that contribute to unfair decision-making and
discrimination against a particular community or a group. Existing bias
mitigation techniques only focus on bias generated from label heterogeneity in
non-IID data without accounting for domain variations due to feature
heterogeneity and do not address global group-fairness property.
<br />Our work proposes a group-fair FL framework that minimizes group-bias while
preserving privacy and without resource utilization overhead. Our main idea is
to leverage average conditional probabilities to compute a cross-domain group
\textit{importance weights} derived from heterogeneous training data to
optimize the performance of the worst-performing group using a modified
multiplicative weights update method. Additionally, we propose regularization
techniques to minimize the difference between the worst and best-performing
groups while making sure through our thresholding mechanism to strike a balance
between bias reduction and group performance degradation. Our evaluation of
human emotion recognition and image classification benchmarks assesses the fair
decision-making of our framework in real-world heterogeneous settings.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07087" title="Abstract">arXiv:2309.07087</a> [<a href="/pdf/2309.07087" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Developing a Novel Image Marker to Predict the Responses of Neoadjuvant  Chemotherapy (NACT) for Ovarian Cancer Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Ke Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Abdoli%2C+N">Neman Abdoli</a>, 
<a href="/search/cs?searchtype=author&query=Gilley%2C+P">Patrik Gilley</a>, 
<a href="/search/cs?searchtype=author&query=Sadri%2C+Y">Youkabed Sadri</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Thai%2C+T+C">Theresa C. Thai</a>, 
<a href="/search/cs?searchtype=author&query=Dockery%2C+L">Lauren Dockery</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+K">Kathleen Moore</a>, 
<a href="/search/cs?searchtype=author&query=Mannel%2C+R+S">Robert S. Mannel</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yuchen Qiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Data Analysis, Statistics and Probability (physics.data-an); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Objective: Neoadjuvant chemotherapy (NACT) is one kind of treatment for
advanced stage ovarian cancer patients. However, due to the nature of tumor
heterogeneity, the patients' responses to NACT varies significantly among
different subgroups. To address this clinical challenge, the purpose of this
study is to develop a novel image marker to achieve high accuracy response
prediction of the NACT at an early stage. Methods: For this purpose, we first
computed a total of 1373 radiomics features to quantify the tumor
characteristics, which can be grouped into three categories: geometric,
intensity, and texture features. Second, all these features were optimized by
principal component analysis algorithm to generate a compact and informative
feature cluster. Using this cluster as the input, an SVM based classifier was
developed and optimized to create a final marker, indicating the likelihood of
the patient being responsive to the NACT treatment. To validate this scheme, a
total of 42 ovarian cancer patients were retrospectively collected. A nested
leave-one-out cross-validation was adopted for model performance assessment.
Results: The results demonstrate that the new method yielded an AUC (area under
the ROC [receiver characteristic operation] curve) of 0.745. Meanwhile, the
model achieved overall accuracy of 76.2%, positive predictive value of 70%, and
negative predictive value of 78.1%. Conclusion: This study provides meaningful
information for the development of radiomics based image markers in NACT
response prediction.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07094" title="Abstract">arXiv:2309.07094</a> [<a href="/pdf/2309.07094" title="Download PDF">pdf</a>, <a href="/format/2309.07094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RadarLCD: Learnable Radar-based Loop Closure Detection Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Usuelli%2C+M">Mirko Usuelli</a>, 
<a href="/search/cs?searchtype=author&query=Frosi%2C+M">Matteo Frosi</a>, 
<a href="/search/cs?searchtype=author&query=Cudrano%2C+P">Paolo Cudrano</a>, 
<a href="/search/cs?searchtype=author&query=Mentasti%2C+S">Simone Mentasti</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Loop Closure Detection (LCD) is an essential task in robotics and computer
vision, serving as a fundamental component for various applications across
diverse domains. These applications encompass object recognition, image
retrieval, and video analysis. LCD consists in identifying whether a robot has
returned to a previously visited location, referred to as a loop, and then
estimating the related roto-translation with respect to the analyzed location.
Despite the numerous advantages of radar sensors, such as their ability to
operate under diverse weather conditions and provide a wider range of view
compared to other commonly used sensors (e.g., cameras or LiDARs), integrating
radar data remains an arduous task due to intrinsic noise and distortion. To
address this challenge, this research introduces RadarLCD, a novel supervised
deep learning pipeline specifically designed for Loop Closure Detection using
the FMCW Radar (Frequency Modulated Continuous Wave) sensor. RadarLCD, a
learning-based LCD methodology explicitly designed for radar systems, makes a
significant contribution by leveraging the pre-trained HERO (Hybrid Estimation
Radar Odometry) model. Being originally developed for radar odometry, HERO's
features are used to select key points crucial for LCD tasks. The methodology
undergoes evaluation across a variety of FMCW Radar dataset scenes, and it is
compared to state-of-the-art systems such as Scan Context for Place Recognition
and ICP for Loop Closure. The results demonstrate that RadarLCD surpasses the
alternatives in multiple aspects of Loop Closure Detection.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07098" title="Abstract">arXiv:2309.07098</a> [<a href="/pdf/2309.07098" title="Download PDF">pdf</a>, <a href="/format/2309.07098" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitigating Hallucinations and Off-target Machine Translation with  Source-Contrastive and Language-Contrastive Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sennrich%2C+R">Rico Sennrich</a>, 
<a href="/search/cs?searchtype=author&query=Vamvas%2C+J">Jannis Vamvas</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadshahi%2C+A">Alireza Mohammadshahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Hallucinations and off-target translation remain unsolved problems in machine
translation, especially for low-resource languages and massively multilingual
models. In this paper, we introduce methods to mitigate both failure cases with
a modified decoding objective, without requiring retraining or external models.
In source-contrastive decoding, we search for a translation that is probable
given the correct input, but improbable given a random input segment,
hypothesising that hallucinations will be similarly probable given either. In
language-contrastive decoding, we search for a translation that is probable,
but improbable given the wrong language indicator token. In experiments on
M2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress
hallucinations and off-target translations, improving chrF2 by 1.7 and 1.4
points on average across 57 tested translation directions. In a proof of
concept on English--German, we also show that we can suppress off-target
translations with the Llama 2 chat models, demonstrating the applicability of
the method to machine translation with LLMs. We release our source code at
https://github.com/ZurichNLP/ContraDecode.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07103" title="Abstract">arXiv:2309.07103</a> [<a href="/pdf/2309.07103" title="Download PDF">pdf</a>, <a href="/format/2309.07103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparing Llama-2 and GPT-3 LLMs for HPC kernels generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Valero-Lara%2C+P">Pedro Valero-Lara</a>, 
<a href="/search/cs?searchtype=author&query=Huante%2C+A">Alexis Huante</a>, 
<a href="/search/cs?searchtype=author&query=Lail%2C+M+A">Mustafa Al Lail</a>, 
<a href="/search/cs?searchtype=author&query=Godoy%2C+W+F">William F. Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Teranishi%2C+K">Keita Teranishi</a>, 
<a href="/search/cs?searchtype=author&query=Balaprakash%2C+P">Prasanna Balaprakash</a>, 
<a href="/search/cs?searchtype=author&query=Vetter%2C+J+S">Jeffrey S. Vetter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at LCPC 2023, The 36th International Workshop on Languages and Compilers for Parallel Computing <a href="http://www.lcpcworkshop.org/LCPC23/">this http URL</a> . 13 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Programming Languages (cs.PL)

</div>
<p class="mathjax">We evaluate the use of the open-source Llama-2 model for generating
well-known, high-performance computing kernels (e.g., AXPY, GEMV, GEMM) on
different parallel programming models and languages (e.g., C++: OpenMP, OpenMP
Offload, OpenACC, CUDA, HIP; Fortran: OpenMP, OpenMP Offload, OpenACC; Python:
numpy, Numba, pyCUDA, cuPy; and Julia: Threads, CUDA.jl, AMDGPU.jl). We built
upon our previous work that is based on the OpenAI Codex, which is a descendant
of GPT-3, to generate similar kernels with simple prompts via GitHub Copilot.
Our goal is to compare the accuracy of Llama-2 and our original GPT-3 baseline
by using a similar metric. Llama-2 has a simplified model that shows
competitive or even superior accuracy. We also report on the differences
between these foundational large language models as generative AI continues to
redefine human-computer interactions. Overall, Copilot generates codes that are
more reliable but less optimized, whereas codes generated by Llama-2 are less
reliable but more optimized when correct.
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07104" title="Abstract">arXiv:2309.07104</a> [<a href="/pdf/2309.07104" title="Download PDF">pdf</a>, <a href="/format/2309.07104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polygon Intersection-over-Union Loss for Viewpoint-Agnostic Monocular 3D  Vehicle Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gloudemans%2C+D">Derek Gloudemans</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xinxuan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+S">Shepard Xia</a>, 
<a href="/search/cs?searchtype=author&query=Work%2C+D+B">Daniel B. Work</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular 3D object detection is a challenging task because depth information
is difficult to obtain from 2D images. A subset of viewpoint-agnostic monocular
3D detection methods also do not explicitly leverage scene homography or
geometry during training, meaning that a model trained thusly can detect
objects in images from arbitrary viewpoints. Such works predict the projections
of the 3D bounding boxes on the image plane to estimate the location of the 3D
boxes, but these projections are not rectangular so the calculation of IoU
between these projected polygons is not straightforward. This work proposes an
efficient, fully differentiable algorithm for the calculation of IoU between
two convex polygons, which can be utilized to compute the IoU between two 3D
bounding box footprints viewed from an arbitrary angle. We test the performance
of the proposed polygon IoU loss (PIoU loss) on three state-of-the-art
viewpoint-agnostic 3D detection models. Experiments demonstrate that the
proposed PIoU loss converges faster than L1 loss and that in 3D detection
models, a combination of PIoU loss and L1 loss gives better results than L1
loss alone (+1.64% AP70 for MonoCon on cars, +0.18% AP70 for RTM3D on cars, and
+0.83%/+2.46% AP50/AP25 for MonoRCNN on cyclists).
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07106" title="Abstract">arXiv:2309.07106</a> [<a href="/pdf/2309.07106" title="Download PDF">pdf</a>, <a href="/format/2309.07106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hardening RGB-D Object Recognition Systems against Adversarial Patch  Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Demetrio%2C+L">Luca Demetrio</a>, 
<a href="/search/cs?searchtype=author&query=Cin%C3%A0%2C+A+E">Antonio Emanuele Cin&#xe0;</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaoyi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Z">Zhaoqiang Xia</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xiaoyue Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Demontis%2C+A">Ambra Demontis</a>, 
<a href="/search/cs?searchtype=author&query=Biggio%2C+B">Battista Biggio</a>, 
<a href="/search/cs?searchtype=author&query=Roli%2C+F">Fabio Roli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in the Information Sciences journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">RGB-D object recognition systems improve their predictive performances by
fusing color and depth information, outperforming neural network architectures
that rely solely on colors. While RGB-D systems are expected to be more robust
to adversarial examples than RGB-only systems, they have also been proven to be
highly vulnerable. Their robustness is similar even when the adversarial
examples are generated by altering only the original images' colors. Different
works highlighted the vulnerability of RGB-D systems; however, there is a
lacking of technical explanations for this weakness. Hence, in our work, we
bridge this gap by investigating the learned deep representation of RGB-D
systems, discovering that color features make the function learned by the
network more complex and, thus, more sensitive to small perturbations. To
mitigate this problem, we propose a defense based on a detection mechanism that
makes RGB-D systems more robust against adversarial examples. We empirically
show that this defense improves the performances of RGB-D systems against
adversarial examples even when they are computed ad-hoc to circumvent this
detection mechanism, and that is also more effective than adversarial training.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07108" title="Abstract">arXiv:2309.07108</a> [<a href="/pdf/2309.07108" title="Download PDF">pdf</a>, <a href="/format/2309.07108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing Speed Performance of Multi-Agent Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiggins%2C+S">Samuel Wiggins</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yuan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V">Viktor Prasanna</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 12th International Conference on Data
  Science, Technology and Applications - DATA (2023) 327-334
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">Multi-Agent Reinforcement Learning (MARL) has achieved significant success in
large-scale AI systems and big-data applications such as smart grids,
surveillance, etc. Existing advancements in MARL algorithms focus on improving
the rewards obtained by introducing various mechanisms for inter-agent
cooperation. However, these optimizations are usually compute- and
memory-intensive, thus leading to suboptimal speed performance in end-to-end
training time. In this work, we analyze the speed performance (i.e.,
latency-bounded throughput) as the key metric in MARL implementations.
Specifically, we first introduce a taxonomy of MARL algorithms from an
acceleration perspective categorized by (1) training scheme and (2)
communication method. Using our taxonomy, we identify three state-of-the-art
MARL algorithms - Multi-Agent Deep Deterministic Policy Gradient (MADDPG),
Target-oriented Multi-agent Communication and Cooperation (ToM2C), and
Networked Multi-Agent RL (NeurComm) - as target benchmark algorithms, and
provide a systematic analysis of their performance bottlenecks on a homogeneous
multi-core CPU platform. We justify the need for MARL latency-bounded
throughput to be a key performance metric in future literature while also
addressing opportunities for parallelization and acceleration.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07113" title="Abstract">arXiv:2309.07113</a> [<a href="/pdf/2309.07113" title="Download PDF">pdf</a>, <a href="/format/2309.07113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Deep Encoding Enables Uncertainty-aware  Machine-learning-assisted Histopathology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivaroopan%2C+N">Nirhoshan Sivaroopan</a>, 
<a href="/search/cs?searchtype=author&query=Jayanga%2C+C">Chamuditha Jayanga</a>, 
<a href="/search/cs?searchtype=author&query=Ekanayake%2C+C">Chalani Ekanayake</a>, 
<a href="/search/cs?searchtype=author&query=Watawana%2C+H">Hasindri Watawana</a>, 
<a href="/search/cs?searchtype=author&query=Pradeepkumar%2C+J">Jathurshan Pradeepkumar</a>, 
<a href="/search/cs?searchtype=author&query=Anandakumar%2C+M">Mithunjha Anandakumar</a>, 
<a href="/search/cs?searchtype=author&query=Rodrigo%2C+R">Ranga Rodrigo</a>, 
<a href="/search/cs?searchtype=author&query=Edussooriya%2C+C+U+S">Chamira U. S. Edussooriya</a>, 
<a href="/search/cs?searchtype=author&query=Wadduwage%2C+D+N">Dushan N. Wadduwage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep neural network models can learn clinically relevant features from
millions of histopathology images. However generating high-quality annotations
to train such models for each hospital, each cancer type, and each diagnostic
task is prohibitively laborious. On the other hand, terabytes of training data
-- while lacking reliable annotations -- are readily available in the public
domain in some cases. In this work, we explore how these large datasets can be
consciously utilized to pre-train deep networks to encode informative
representations. We then fine-tune our pre-trained models on a fraction of
annotated training data to perform specific downstream tasks. We show that our
approach can reach the state-of-the-art (SOTA) for patch-level classification
with only 1-10% randomly selected annotations compared to other SOTA
approaches. Moreover, we propose an uncertainty-aware loss function, to
quantify the model confidence during inference. Quantified uncertainty helps
experts select the best instances to label for further training. Our
uncertainty-aware labeling reaches the SOTA with significantly fewer
annotations compared to random labeling. Last, we demonstrate how our
pre-trained encoders can surpass current SOTA for whole-slide image
classification with weak supervision. Our work lays the foundation for data and
task-agnostic pre-trained deep networks with quantified uncertainty.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07115" title="Abstract">arXiv:2309.07115</a> [<a href="/pdf/2309.07115" title="Download PDF">pdf</a>, <a href="/format/2309.07115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly-Supervised Multi-Task Learning for Audio-Visual Speaker  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Selvakumar%2C+A">Anith Selvakumar</a>, 
<a href="/search/cs?searchtype=author&query=Fashandi%2C+H">Homa Fashandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In this paper, we present a methodology for achieving robust multimodal
person representations optimized for open-set audio-visual speaker
verification. Distance Metric Learning (DML) approaches have typically
dominated this problem space, owing to strong performance on new and unseen
classes. In our work, we explored multitask learning techniques to further
boost performance of the DML approach and show that an auxiliary task with weak
labels can increase the compactness of the learned speaker representation. We
also extend the Generalized end-to-end loss (GE2E) to multimodal inputs and
demonstrate that it can achieve competitive performance in an audio-visual
space. Finally, we introduce a non-synchronous audio-visual sampling random
strategy during training time that has shown to improve generalization. Our
network achieves state of the art performance for speaker verification,
reporting 0.244%, 0.252%, 0.441% Equal Error Rate (EER) on the three official
trial lists of VoxCeleb1-O/E/H, which is to our knowledge, the best published
results on VoxCeleb1-E and VoxCeleb1-H.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07117" title="Abstract">arXiv:2309.07117</a> [<a href="/pdf/2309.07117" title="Download PDF">pdf</a>, <a href="/format/2309.07117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PILOT: A Pre-Trained Model-Based Continual Learning Toolbox
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hai-Long Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+D">Da-Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Han-Jia Ye</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+D">De-Chuan Zhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code is available at <a href="https://github.com/sun-hailong/LAMDA-PILOT">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">While traditional machine learning can effectively tackle a wide range of
problems, it primarily operates within a closed-world setting, which presents
limitations when dealing with streaming data. As a solution, incremental
learning emerges to address real-world scenarios involving new data's arrival.
Recently, pre-training has made significant advancements and garnered the
attention of numerous researchers. The strong performance of these pre-trained
models (PTMs) presents a promising avenue for developing continual learning
algorithms that can effectively adapt to real-world scenarios. Consequently,
exploring the utilization of PTMs in incremental learning has become essential.
This paper introduces a pre-trained model-based continual learning toolbox
known as PILOT. On the one hand, PILOT implements some state-of-the-art
class-incremental learning algorithms based on pre-trained models, such as L2P,
DualPrompt, and CODA-Prompt. On the other hand, PILOT also fits typical
class-incremental learning algorithms (e.g., DER, FOSTER, and MEMO) within the
context of pre-trained models to evaluate their effectiveness.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07120" title="Abstract">arXiv:2309.07120</a> [<a href="/pdf/2309.07120" title="Download PDF">pdf</a>, <a href="/format/2309.07120" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness  and Ethics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+H">Haoqin Tu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+B">Bingchen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+C">Chen Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Cihang Xie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-modal large language models (MLLMs) are trained based on large language
models (LLM), with an enhanced capability to comprehend multi-modal inputs and
generate textual responses. While they excel in multi-modal tasks, the pure NLP
abilities of MLLMs are often underestimated and left untested. In this study,
we get out of the box and unveil an intriguing characteristic of MLLMs -- our
preliminary results suggest that visual instruction tuning, a prevailing
strategy for transitioning LLMs into MLLMs, unexpectedly and interestingly
helps models attain both improved truthfulness and ethical alignment in the
pure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model
surpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one
million human annotations, on TruthfulQA-mc and Ethics benchmarks. Further
analysis reveals that the improved alignment can be attributed to the superior
instruction quality inherent to visual-text data. In releasing our code at
github.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration
into the intrinsic value of visual-text synergies and, in a broader scope,
multi-modal interactions in alignment research.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07122" title="Abstract">arXiv:2309.07122</a> [<a href="/pdf/2309.07122" title="Download PDF">pdf</a>, <a href="/format/2309.07122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-Structured Shading Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+C">Chen Geng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hong-Xing Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Sharon Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Agrawala%2C+M">Maneesh Agrawala</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiajun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023. Project website: <a href="https://chen-geng.com/inv-shade-trees">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We study inferring a tree-structured representation from a single image for
object shading. Prior work typically uses the parametric or measured
representation to model shading, which is neither interpretable nor easily
editable. We propose using the shade tree representation, which combines basic
shading nodes and compositing methods to factorize object surface shading. The
shade tree representation enables novice users who are unfamiliar with the
physical shading process to edit object shading in an efficient and intuitive
manner. A main challenge in inferring the shade tree is that the inference
problem involves both the discrete tree structure and the continuous parameters
of the tree nodes. We propose a hybrid approach to address this issue. We
introduce an auto-regressive inference model to generate a rough estimation of
the tree structure and node parameters, and then we fine-tune the inferred
shade tree through an optimization algorithm. We show experiments on synthetic
images, captured reflectance, real images, and non-realistic vector drawings,
allowing downstream applications such as material editing, vectorized shading,
and relighting. Project website: https://chen-geng.com/inv-shade-trees
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07124" title="Abstract">arXiv:2309.07124</a> [<a href="/pdf/2309.07124" title="Download PDF">pdf</a>, <a href="/format/2309.07124" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RAIN: Your Language Models Can Align Themselves without Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuhui Li</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Fangyun Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jinjing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) often demonstrate inconsistencies with human
preferences. Previous research gathered human preference data and then aligned
the pre-trained models using reinforcement learning or instruction tuning, the
so-called finetuning step. In contrast, aligning frozen LLMs without any extra
data is more appealing. This work explores the potential of the latter setting.
We discover that by integrating self-evaluation and rewind mechanisms,
unaligned LLMs can directly produce responses consistent with human preferences
via self-boosting. We introduce a novel inference method, Rewindable
Auto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate
their own generation and use the evaluation results to guide backward rewind
and forward generation for AI safety. Notably, RAIN operates without the need
of extra data for model alignment and abstains from any training, gradient
computation, or parameter updates; during the self-evaluation phase, the model
receives guidance on which human preference to align with through a
fixed-template prompt, eliminating the need to modify the initial prompt.
Experimental results evaluated by GPT-4 and humans demonstrate the
effectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate
of LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the
helpfulness rate. Under the leading adversarial attack llm-attacks on Vicuna
33B, RAIN establishes a new defense baseline by reducing the attack success
rate from 94% to 19%.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07125" title="Abstract">arXiv:2309.07125</a> [<a href="/pdf/2309.07125" title="Download PDF">pdf</a>, <a href="/format/2309.07125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Guided Generation and Editing of Compositional 3D Avatars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yao Feng</a>, 
<a href="/search/cs?searchtype=author&query=Kulits%2C+P">Peter Kulits</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yandong Wen</a>, 
<a href="/search/cs?searchtype=author&query=Thies%2C+J">Justus Thies</a>, 
<a href="/search/cs?searchtype=author&query=Black%2C+M+J">Michael J. Black</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Home page: <a href="https://yfeng95.github.io/teca">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our goal is to create a realistic 3D facial avatar with hair and accessories
using only a text description. While this challenge has attracted significant
recent interest, existing methods either lack realism, produce unrealistic
shapes, or do not support editing, such as modifications to the hairstyle. We
argue that existing methods are limited because they employ a monolithic
modeling approach, using a single representation for the head, face, hair, and
accessories. Our observation is that the hair and face, for example, have very
different structural qualities that benefit from different representations.
Building on this insight, we generate avatars with a compositional model, in
which the head, face, and upper body are represented with traditional 3D
meshes, and the hair, clothing, and accessories with neural radiance fields
(NeRF). The model-based mesh representation provides a strong geometric prior
for the face region, improving realism while enabling editing of the person's
appearance. By using NeRFs to represent the remaining components, our method is
able to model and synthesize parts with complex geometry and appearance, such
as curly hair and fluffy scarves. Our novel system synthesizes these
high-quality compositional avatars from text descriptions. The experimental
results demonstrate that our method, Text-guided generation and Editing of
Compositional Avatars (TECA), produces avatars that are more realistic than
those of recent methods while being editable because of their compositional
nature. For example, our TECA enables the seamless transfer of compositional
features like hairstyles, scarves, and other accessories between avatars. This
capability supports applications such as virtual try-on.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Thu, 14 Sep 23</h3>
<dl>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11846" title="Abstract">arXiv:2308.11846</a> (cross-list from nlin.PS) [<a href="/pdf/2308.11846" title="Download PDF">pdf</a>, <a href="/format/2308.11846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data-Driven Approach to Morphogenesis under Structural Instability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Zhao%2C+Y">Yingjie Zhao</a>, 
<a href="/search/nlin?searchtype=author&query=Xu%2C+Z">Zhiping Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Pattern Formation and Solitons (nlin.PS)</span>; Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM); Machine Learning (stat.ML)

</div>
<p class="mathjax">Morphological development into evolutionary patterns under structural
instability is ubiquitous in living systems and often of vital importance for
engineering structures. Here we propose a data-driven approach to understand
and predict their spatiotemporal complexities. A machine-learning framework is
proposed based on the physical modeling of morphogenesis triggered by internal
or external forcing. Digital libraries of structural patterns are constructed
from the simulation data, which are then used to recognize the abnormalities,
predict their development, and assist in risk assessment and prognosis. The
capabilities to identify the key bifurcation characteristics and predict the
history-dependent development from the global and local features are
demonstrated by examples of brain growth and aerospace structural design, which
offer guidelines for disease diagnosis/prognosis and instability-tolerant
design.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06449" title="Abstract">arXiv:2309.06449</a> (cross-list from cond-mat.mes-hall) [<a href="/pdf/2309.06449" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantized Non-Volatile Nanomagnetic Synapse based Autoencoder for  Efficient Unsupervised Network Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Alam%2C+M+S">Muhammad Sabbir Alam</a>, 
<a href="/search/cond-mat?searchtype=author&query=Misba%2C+W+A">Walid Al Misba</a>, 
<a href="/search/cond-mat?searchtype=author&query=Atulasimha%2C+J">Jayasimha Atulasimha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Mesoscale and Nanoscale Physics (cond-mat.mes-hall)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">In the autoencoder based anomaly detection paradigm, implementing the
autoencoder in edge devices capable of learning in real-time is exceedingly
challenging due to limited hardware, energy, and computational resources. We
show that these limitations can be addressed by designing an autoencoder with
low-resolution non-volatile memory-based synapses and employing an effective
quantized neural network learning algorithm. We propose a ferromagnetic
racetrack with engineered notches hosting a magnetic domain wall (DW) as the
autoencoder synapses, where limited state (5-state) synaptic weights are
manipulated by spin orbit torque (SOT) current pulses. The performance of
anomaly detection of the proposed autoencoder model is evaluated on the NSL-KDD
dataset. Limited resolution and DW device stochasticity aware training of the
autoencoder is performed, which yields comparable anomaly detection performance
to the autoencoder having floating-point precision weights. While the limited
number of quantized states and the inherent stochastic nature of DW synaptic
weights in nanoscale devices are known to negatively impact the performance,
our hardware-aware training algorithm is shown to leverage these imperfect
device characteristics to generate an improvement in anomaly detection accuracy
(90.98%) compared to accuracy obtained with floating-point trained weights.
Furthermore, our DW-based approach demonstrates a remarkable reduction of at
least three orders of magnitude in weight updates during training compared to
the floating-point approach, implying substantial energy savings for our
method. This work could stimulate the development of extremely energy efficient
non-volatile multi-state synapse-based processors that can perform real-time
training and inference on the edge with unsupervised data.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06472" title="Abstract">arXiv:2309.06472</a> (cross-list from hep-ph) [<a href="/pdf/2309.06472" title="Download PDF">pdf</a>, <a href="/format/2309.06472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flows for Flows: Morphing one Dataset into another with Maximum  Likelihood Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Golling%2C+T">Tobias Golling</a>, 
<a href="/search/hep-ph?searchtype=author&query=Klein%2C+S">Samuel Klein</a>, 
<a href="/search/hep-ph?searchtype=author&query=Mastandrea%2C+R">Radha Mastandrea</a>, 
<a href="/search/hep-ph?searchtype=author&query=Nachman%2C+B">Benjamin Nachman</a>, 
<a href="/search/hep-ph?searchtype=author&query=Raine%2C+J+A">John Andrew Raine</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 17 figures. This work is a merger of <a href="/abs/2211.02487">arXiv:2211.02487</a> and <a href="/abs/2212.06155">arXiv:2212.06155</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Many components of data analysis in high energy physics and beyond require
morphing one dataset into another. This is commonly solved via reweighting, but
there are many advantages of preserving weights and shifting the data points
instead. Normalizing flows are machine learning models with impressive
precision on a variety of particle physics tasks. Naively, normalizing flows
cannot be used for morphing because they require knowledge of the probability
density of the starting dataset. In most cases in particle physics, we can
generate more examples, but we do not know densities explicitly. We propose a
protocol called flows for flows for training normalizing flows to morph one
dataset into another even if the underlying probability density of neither
dataset is known explicitly. This enables a morphing strategy trained with
maximum likelihood estimation, a setup that has been shown to be highly
effective in related tasks. We study variations on this protocol to explore how
far the data points are moved to statistically match the two datasets.
Furthermore, we show how to condition the learned flows on particular features
in order to create a morphing function for every value of the conditioning
feature. For illustration, we demonstrate flows for flows for toy examples as
well as a collider physics example involving dijet events
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06507" title="Abstract">arXiv:2309.06507</a> (cross-list from math.CO) [<a href="/pdf/2309.06507" title="Download PDF">pdf</a>, <a href="/format/2309.06507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The maximum size of adjacency-crossing graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ackerman%2C+E">Eyal Ackerman</a>, 
<a href="/search/math?searchtype=author&query=Keszegh%2C+B">Bal&#xe1;zs Keszegh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">An adjacency-crossing graph is a graph that can be drawn such that every two
edges that cross the same edge share a common endpoint. We show that the number
of edges in an $n$-vertex adjacency-crossing graph is at most $5n-10$. If we
require the edges to be drawn as straight-line segments, then this upper bound
becomes $5n-11$. Both of these bounds are tight. The former result also follows
from a very recent and independent work of Cheong et al.\cite{cheong2023weakly}
who showed that the maximum size of weakly and strongly fan-planar graphs
coincide. By combining this result with the bound of Kaufmann and
Ueckerdt\cite{KU22} on the size of strongly fan-planar graphs and results of
Brandenburg\cite{Br20} by which the maximum size of adjacency-crossing graphs
equals the maximum size of fan-crossing graphs which in turn equals the maximum
size of weakly fan-planar graphs, one obtains the same bound on the size of
adjacency-crossing graphs. However, the proof presented here is different,
simpler and direct.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06531" title="Abstract">arXiv:2309.06531</a> (cross-list from eess.AS) [<a href="/pdf/2309.06531" title="Download PDF">pdf</a>, <a href="/format/2309.06531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ASPED: An Audio Dataset for Detecting Pedestrians
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Seshadri%2C+P">Pavan Seshadri</a>, 
<a href="/search/eess?searchtype=author&query=Han%2C+C">Chaeyeon Han</a>, 
<a href="/search/eess?searchtype=author&query=Koo%2C+B">Bon-Woo Koo</a>, 
<a href="/search/eess?searchtype=author&query=Posner%2C+N">Noah Posner</a>, 
<a href="/search/eess?searchtype=author&query=Guhathakurta%2C+S">Subhrajit Guhathakurta</a>, 
<a href="/search/eess?searchtype=author&query=Lerch%2C+A">Alexander Lerch</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4+1 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">We introduce the new audio analysis task of pedestrian detection and present
a new large-scale dataset for this task. While the preliminary results prove
the viability of using audio approaches for pedestrian detection, they also
show that this challenging task cannot be easily solved with standard
approaches.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06538" title="Abstract">arXiv:2309.06538</a> (cross-list from q-fin.ST) [<a href="/pdf/2309.06538" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Desenvolvimento de modelo para predi&#xe7;&#xe3;o de cota&#xe7;&#xf5;es de  a&#xe7;&#xe3;o baseada em an&#xe1;lise de sentimentos de tweets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Akita%2C+M+M">Mario Mitsuo Akita</a>, 
<a href="/search/q-fin?searchtype=author&query=da+Silva%2C+E+J">Everton Josue da Silva</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Portuguese language, Presented at: 1o Semin\'ario de Ci\^encia de Dados do IFSP. Campinas: 2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Anais do 1o Semin\'ario de Ci\^encia de Dados do IFSP. Campinas:
  2023. p. 51 - 58
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Training machine learning models for predicting stock market share prices is
an active area of research since the automatization of trading such papers was
available in real time. While most of the work in this field of research is
done by training Neural networks based on past prices of stock shares, in this
work, we use iFeel 2.0 platform to extract 19 sentiment features from posts
obtained from microblog platform Twitter that mention the company Petrobras.
Then, we used those features to train XBoot models to predict future stock
prices for the referred company. Later, we simulated the trading of Petrobras'
shares based on the model's outputs and determined the gain of R$88,82 (net) in
a 250-day period when compared to a 100 random models' average performance.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06548" title="Abstract">arXiv:2309.06548</a> (cross-list from stat.ML) [<a href="/pdf/2309.06548" title="Download PDF">pdf</a>, <a href="/ps/2309.06548" title="Download PostScript">ps</a>, <a href="/format/2309.06548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Infinite-Dimensional Regression: Learning Linear Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Raman%2C+V">Vinod Raman</a>, 
<a href="/search/stat?searchtype=author&query=Subedi%2C+U">Unique Subedi</a>, 
<a href="/search/stat?searchtype=author&query=Tewari%2C+A">Ambuj Tewari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We consider the problem of learning linear operators under squared loss
between two infinite-dimensional Hilbert spaces in the online setting. We show
that the class of linear operators with uniformly bounded $p$-Schatten norm is
online learnable for any $p \in [1, \infty)$. On the other hand, we prove an
impossibility result by showing that the class of uniformly bounded linear
operators with respect to the operator norm is \textit{not} online learnable.
Moreover, we show a separation between online uniform convergence and online
learnability by identifying a class of bounded linear operators that is online
learnable but uniform convergence does not hold. Finally, we prove that the
impossibility result and the separation between uniform convergence and
learnability also hold in the agnostic PAC setting.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06559" title="Abstract">arXiv:2309.06559</a> (cross-list from q-fin.ST) [<a href="/pdf/2309.06559" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Media Moments and Corporate Connections: A Deep Learning Approach to  Stock Movement Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sanborn%2C+L">Luke Sanborn</a>, 
<a href="/search/q-fin?searchtype=author&query=Sahagun%2C+M">Matthew Sahagun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistical Finance (q-fin.ST)</span>; Social and Information Networks (cs.SI); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">The financial industry poses great challenges with risk modeling and profit
generation. These entities are intricately tied to the sophisticated prediction
of stock movements. A stock forecaster must untangle the randomness and
ever-changing behaviors of the stock market. Stock movements are influenced by
a myriad of factors, including company history, performance, and
economic-industry connections. However, there are other factors that aren't
traditionally included, such as social media and correlations between stocks.
Social platforms such as Reddit, Facebook, and X (Twitter) create opportunities
for niche communities to share their sentiment on financial assets. By
aggregating these opinions from social media in various mediums such as posts,
interviews, and news updates, we propose a more holistic approach to include
these "media moments" within stock market movement prediction. We introduce a
method that combines financial data, social media, and correlated stock
relationships via a graph neural network in a hierarchical temporal fashion.
Through numerous trials on current S&amp;P 500 index data, with results showing an
improvement in cumulative returns by 28%, we provide empirical evidence of our
tool's applicability for use in investment decisions.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06572" title="Abstract">arXiv:2309.06572</a> (cross-list from eess.AS) [<a href="/pdf/2309.06572" title="Download PDF">pdf</a>, <a href="/format/2309.06572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Addressing the Blind Spots in Spoken Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moryossef%2C+A">Amit Moryossef</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">This paper explores the critical but often overlooked role of non-verbal
cues, including co-speech gestures and facial expressions, in human
communication and their implications for Natural Language Processing (NLP). We
argue that understanding human communication requires a more holistic approach
that goes beyond textual or spoken words to include non-verbal elements.
Borrowing from advances in sign language processing, we propose the development
of universal automatic gesture segmentation and transcription models to
transcribe these non-verbal cues into textual form. Such a methodology aims to
bridge the blind spots in spoken language understanding, enhancing the scope
and applicability of NLP models. Through motivating examples, we demonstrate
the limitations of relying solely on text-based models. We propose a
computationally efficient and flexible approach for incorporating non-verbal
cues, which can seamlessly integrate with existing NLP pipelines. We conclude
by calling upon the research community to contribute to the development of
universal transcription methods and to validate their effectiveness in
capturing the complexities of real-world, multi-modal interactions.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06582" title="Abstract">arXiv:2309.06582</a> (cross-list from hep-ex) [<a href="/pdf/2309.06582" title="Download PDF">pdf</a>, <a href="/format/2309.06582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Electron Energy Regression in the CMS High-Granularity Calorimeter  Prototype
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Rusack%2C+R">Roger Rusack</a>, 
<a href="/search/hep-ex?searchtype=author&query=Joshi%2C+B">Bhargav Joshi</a>, 
<a href="/search/hep-ex?searchtype=author&query=Alpana%2C+A">Alpana Alpana</a>, 
<a href="/search/hep-ex?searchtype=author&query=Sharma%2C+S">Seema Sharma</a>, 
<a href="/search/hep-ex?searchtype=author&query=Vadnais%2C+T">Thomas Vadnais</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">We present a new publicly available dataset that contains simulated data of a
novel calorimeter to be installed at the CERN Large Hadron Collider. This
detector will have more than six-million channels with each channel capable of
position, ionisation and precision time measurement. Reconstructing these
events in an efficient way poses an immense challenge which is being addressed
with the latest machine learning techniques. As part of this development a
large prototype with 12,000 channels was built and a beam of high-energy
electrons incident on it. Using machine learning methods we have reconstructed
the energy of incident electrons from the energies of three-dimensional hits,
which is known to some precision. By releasing this data publicly we hope to
encourage experts in the application of machine learning to develop efficient
and accurate image reconstruction of these electrons.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06591" title="Abstract">arXiv:2309.06591</a> (cross-list from math.OC) [<a href="/pdf/2309.06591" title="Download PDF">pdf</a>, <a href="/format/2309.06591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homothetic tube model predictive control with multi-step predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Saccani%2C+D">Danilo Saccani</a>, 
<a href="/search/math?searchtype=author&query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>, 
<a href="/search/math?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>, 
<a href="/search/math?searchtype=author&query=K%C3%B6hler%2C+J">Johannes K&#xf6;hler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a robust model predictive control (MPC) framework for linear
systems facing bounded parametric uncertainty and bounded disturbances. Our
approach deviates from standard MPC formulations by integrating multi-step
predictors, which provide reduced error bounds. These bounds, derived from
multi-step predictors, are utilized in a homothetic tube formulation to
mitigate conservatism. Lastly, a multi-rate formulation is adopted to handle
the incompatibilities of multi-step predictors. We provide a theoretical
analysis, guaranteeing robust recursive feasibility, constraint satisfaction,
and (practical) stability of the desired setpoint. We use a simulation example
to compare it to existing literature and demonstrate advantages in terms of
conservatism and computational complexity.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06622" title="Abstract">arXiv:2309.06622</a> (cross-list from math.OC) [<a href="/pdf/2309.06622" title="Download PDF">pdf</a>, <a href="/format/2309.06622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Contraction Coefficient of the Schr&#xf6;dinger Bridge for  Stochastic Linear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Teter%2C+A+M+H">Alexis M.H. Teter</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+Y">Yongxin Chen</a>, 
<a href="/search/math?searchtype=author&query=Halder%2C+A">Abhishek Halder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG); Systems and Control (eess.SY); Machine Learning (stat.ML)

</div>
<p class="mathjax">Schr\"{o}dinger bridge is a stochastic optimal control problem to steer a
given initial state density to another, subject to controlled diffusion and
deadline constraints. A popular method to numerically solve the Schr\"{o}dinger
bridge problems, in both classical and in the linear system settings, is via
contractive fixed point recursions. These recursions can be seen as dynamic
versions of the well-known Sinkhorn iterations, and under mild assumptions,
they solve the so-called Schr\"{o}dinger systems with guaranteed linear
convergence. In this work, we study a priori estimates for the contraction
coefficients associated with the convergence of respective Schr\"{o}dinger
systems. We provide new geometric and control-theoretic interpretations for the
same. Building on these newfound interpretations, we point out the possibility
of improved computation for the worst-case contraction coefficients of linear
SBPs by preconditioning the endpoint support sets.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06627" title="Abstract">arXiv:2309.06627</a> (cross-list from stat.ML) [<a href="/pdf/2309.06627" title="Download PDF">pdf</a>, <a href="/format/2309.06627" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Sequentially Fair Mechanism for Multiple Sensitive Attributes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hu%2C+F">Fran&#xe7;ois Hu</a>, 
<a href="/search/stat?searchtype=author&query=Ratz%2C+P">Philipp Ratz</a>, 
<a href="/search/stat?searchtype=author&query=Charpentier%2C+A">Arthur Charpentier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
<p class="mathjax">In the standard use case of Algorithmic Fairness, the goal is to eliminate
the relationship between a sensitive variable and a corresponding score.
Throughout recent years, the scientific community has developed a host of
definitions and tools to solve this task, which work well in many practical
applications. However, the applicability and effectivity of these tools and
definitions becomes less straightfoward in the case of multiple sensitive
attributes. To tackle this issue, we propose a sequential framework, which
allows to progressively achieve fairness across a set of sensitive features. We
accomplish this by leveraging multi-marginal Wasserstein barycenters, which
extends the standard notion of Strong Demographic Parity to the case with
multiple sensitive characteristics. This method also provides a closed-form
solution for the optimal, sequentially fair predictor, permitting a clear
interpretation of inter-sensitive feature correlations. Our approach seamlessly
extends to approximate fairness, enveloping a framework accommodating the
trade-off between risk and unfairness. This extension permits a targeted
prioritization of fairness improvements for a specific attribute within a set
of sensitive attributes, allowing for a case specific adaptation. A data-driven
estimation procedure for the derived solution is developed, and comprehensive
numerical experiments are conducted on both synthetic and real datasets. Our
empirical findings decisively underscore the practical efficacy of our
post-processing approach in fostering fair decision-making.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06641" title="Abstract">arXiv:2309.06641</a> (cross-list from quant-ph) [<a href="/pdf/2309.06641" title="Download PDF">pdf</a>, <a href="/format/2309.06641" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Data Center: Perspectives
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, many figures. This is a perspective papers introducing the ideas and impacts of quantum data centers in <a href="/abs/2207.14336">arXiv:2207.14336</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">A quantum version of data centers might be significant in the quantum era. In
this paper, we introduce Quantum Data Center (QDC), a quantum version of
existing classical data centers, with a specific emphasis on combining Quantum
Random Access Memory (QRAM) and quantum networks. We argue that QDC will
provide significant benefits to customers in terms of efficiency, security, and
precision, and will be helpful for quantum computing, communication, and
sensing. We investigate potential scientific and business opportunities along
this novel research direction through hardware realization and possible
specific applications. We show the possible impacts of QDCs in business and
science, especially the machine learning and big data industries.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06642" title="Abstract">arXiv:2309.06642</a> (cross-list from eess.IV) [<a href="/pdf/2309.06642" title="Download PDF">pdf</a>, <a href="/format/2309.06642" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fabian%2C+Z">Zalan Fabian</a>, 
<a href="/search/eess?searchtype=author&query=Tinaz%2C+B">Berk Tinaz</a>, 
<a href="/search/eess?searchtype=author&query=Soltanolkotabi%2C+M">Mahdi Soltanolkotabi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, preliminary version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Inverse problems arise in a multitude of applications, where the goal is to
recover a clean signal from noisy and possibly (non)linear observations. The
difficulty of a reconstruction problem depends on multiple factors, such as the
structure of the ground truth signal, the severity of the degradation, the
implicit bias of the reconstruction model and the complex interactions between
the above factors. This results in natural sample-by-sample variation in the
difficulty of a reconstruction task, which is often overlooked by contemporary
techniques. Recently, diffusion-based inverse problem solvers have established
new state-of-the-art in various reconstruction tasks. However, they have the
drawback of being computationally prohibitive. Our key observation in this
paper is that most existing solvers lack the ability to adapt their compute
power to the difficulty of the reconstruction task, resulting in long inference
times, subpar performance and wasteful resource allocation. We propose a novel
method that we call severity encoding, to estimate the degradation severity of
noisy, degraded signals in the latent space of an autoencoder. We show that the
estimated severity has strong correlation with the true corruption level and
can give useful hints at the difficulty of reconstruction problems on a
sample-by-sample basis. Furthermore, we propose a reconstruction method based
on latent diffusion models that leverages the predicted degradation severities
to fine-tune the reverse diffusion sampling trajectory and thus achieve
sample-adaptive inference times. We utilize latent diffusion posterior sampling
to maintain data consistency with observations. We perform experiments on both
linear and nonlinear inverse problems and demonstrate that our technique
achieves performance comparable to state-of-the-art diffusion-based techniques,
with significant improvements in computational efficiency.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06661" title="Abstract">arXiv:2309.06661</a> (cross-list from eess.AS) [<a href="/pdf/2309.06661" title="Download PDF">pdf</a>, <a href="/ps/2309.06661" title="Download PostScript">ps</a>, <a href="/format/2309.06661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound field decomposition based on two-stage neural networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Matsuda%2C+R">Ryo Matsuda</a>, 
<a href="/search/eess?searchtype=author&query=Otani%2C+M">Makoto Otani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 16 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">A method for sound field decomposition based on neural networks is proposed.
The method comprises two stages: a sound field separation stage and a
single-source localization stage. In the first stage, the sound pressure at
microphones synthesized by multiple sources is separated into one excited by
each sound source. In the second stage, the source location is obtained as a
regression from the sound pressure at microphones consisting of a single sound
source. The estimated location is not affected by discretization because the
second stage is designed as a regression rather than a classification. Datasets
are generated by simulation using Green's function, and the neural network is
trained for each frequency. Numerical experiments reveal that, compared with
conventional methods, the proposed method can achieve higher
source-localization accuracy and higher sound-field-reconstruction accuracy.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06662" title="Abstract">arXiv:2309.06662</a> (cross-list from physics.ao-ph) [<a href="/pdf/2309.06662" title="Download PDF">pdf</a>, <a href="/format/2309.06662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oceananigans.jl: A model that achieves breakthrough resolution, memory  and energy efficiency in global ocean simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Silvestri%2C+S">Simone Silvestri</a>, 
<a href="/search/physics?searchtype=author&query=Wagner%2C+G">Gregory Wagner</a>, 
<a href="/search/physics?searchtype=author&query=Hill%2C+C">Christopher Hill</a>, 
<a href="/search/physics?searchtype=author&query=Ardakani%2C+M+R">Matin Raayai Ardakani</a>, 
<a href="/search/physics?searchtype=author&query=Blaschke%2C+J">Johannes Blaschke</a>, 
<a href="/search/physics?searchtype=author&query=Campin%2C+J">Jean-Michel Campin</a>, 
<a href="/search/physics?searchtype=author&query=Churavy%2C+V">Valentin Churavy</a>, 
<a href="/search/physics?searchtype=author&query=Constantinou%2C+N">Navid Constantinou</a>, 
<a href="/search/physics?searchtype=author&query=Edelman%2C+A">Alan Edelman</a>, 
<a href="/search/physics?searchtype=author&query=Marshall%2C+J">John Marshall</a>, 
<a href="/search/physics?searchtype=author&query=Ramadhan%2C+A">Ali Ramadhan</a>, 
<a href="/search/physics?searchtype=author&query=Souza%2C+A">Andre Souza</a>, 
<a href="/search/physics?searchtype=author&query=Ferrari%2C+R">Raffaele Ferrari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Climate models must simulate hundreds of future scenarios for hundreds of
years at coarse resolutions, and a handful of high-resolution decadal
simulations to resolve localized extreme events. Using Oceananigans.jl, written
from scratch in Julia, we report several achievements: First, a global ocean
simulation with breakthrough horizontal resolution -- 488m -- reaching 15
simulated days per day (0.04 simulated years per day; SYPD). Second,
Oceananigans simulates the global ocean at 488m with breakthrough memory
efficiency on just 768 Nvidia A100 GPUs, a fraction of the resources available
on current and upcoming exascale supercomputers. Third, and arguably most
significant for climate modeling, Oceananigans achieves breakthrough energy
efficiency reaching 0.95 SYPD at 1.7 km on 576 A100s and 9.9 SYPD at 10 km on
68 A100s -- the latter representing the highest horizontal resolutions employed
by current IPCC-class ocean models. Routine climate simulations with 10 km
ocean components are within reach.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06679" title="Abstract">arXiv:2309.06679</a> (cross-list from physics.flu-dyn) [<a href="/pdf/2309.06679" title="Download PDF">pdf</a>, <a href="/format/2309.06679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalizable improvement of the Spalart-Allmaras model through  assimilation of experimental data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Aulakh%2C+D+J+S">Deepinder Jot Singh Aulakh</a>, 
<a href="/search/physics?searchtype=author&query=Maulik%2C+R">Romit Maulik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Fluid Dynamics (physics.flu-dyn)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">This study focuses on the use of model and data fusion for improving the
Spalart-Allmaras (SA) closure model for Reynolds-averaged Navier-Stokes
solutions of separated flows. In particular, our goal is to develop of models
that not-only assimilate sparse experimental data to improve performance in
computational models, but also generalize to unseen cases by recovering
classical SA behavior. We achieve our goals using data assimilation, namely the
Ensemble Kalman Filtering approach (EnKF), to calibrate the coefficients of the
SA model for separated flows. A holistic calibration strategy is implemented
via a parameterization of the production, diffusion, and destruction terms.
This calibration relies on the assimilation of experimental data collected
velocity profiles, skin friction, and pressure coefficients for separated
flows. Despite using of observational data from a single flow condition around
a backward-facing step (BFS), the recalibrated SA model demonstrates
generalization to other separated flows, including cases such as the 2D-bump
and modified BFS. Significant improvement is observed in the quantities of
interest, i.e., skin friction coefficient ($C_f$) and pressure coefficient
($C_p$) for each flow tested. Finally, it is also demonstrated that the newly
proposed model recovers SA proficiency for external, unseparated flows, such as
flow around a NACA-0012 airfoil without any danger of extrapolation, and that
the individually calibrated terms in the SA model are targeted towards specific
flow-physics wherein the calibrated production term improves the re-circulation
zone while destruction improves the recovery zone.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06681" title="Abstract">arXiv:2309.06681</a> (cross-list from eess.IV) [<a href="/pdf/2309.06681" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A plug-and-play synthetic data deep learning for undersampled magnetic  resonance image reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xiao%2C+M">Min Xiao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+J">Jiefeng Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qu%2C+X">Xiaobo Qu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Magnetic resonance imaging (MRI) plays an important role in modern medical
diagnostic but suffers from prolonged scan time. Current deep learning methods
for undersampled MRI reconstruction exhibit good performance in image
de-aliasing which can be tailored to the specific kspace undersampling
scenario. But it is very troublesome to configure different deep networks when
the sampling setting changes. In this work, we propose a deep plug-and-play
method for undersampled MRI reconstruction, which effectively adapts to
different sampling settings. Specifically, the image de-aliasing prior is first
learned by a deep denoiser trained to remove general white Gaussian noise from
synthetic data. Then the learned deep denoiser is plugged into an iterative
algorithm for image reconstruction. Results on in vivo data demonstrate that
the proposed method provides nice and robust accelerated image reconstruction
performance under different undersampling patterns and sampling rates, both
visually and quantitatively.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06710" title="Abstract">arXiv:2309.06710</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.06710" title="Download PDF">pdf</a>, <a href="/format/2309.06710" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crystal structure prediction using neural network potential and  age-fitness Pareto genetic algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Omee%2C+S+S">Sadman Sadeed Omee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wei%2C+L">Lai Wei</a>, 
<a href="/search/cond-mat?searchtype=author&query=Hu%2C+J">Jianjun Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">While crystal structure prediction (CSP) remains a longstanding challenge, we
introduce ParetoCSP, a novel algorithm for CSP, which combines a
multi-objective genetic algorithm (MOGA) with a neural network inter-atomic
potential (IAP) model to find energetically optimal crystal structures given
chemical compositions. We enhance the NSGA-III algorithm by incorporating the
genotypic age as an independent optimization criterion and employ the M3GNet
universal IAP to guide the GA search. Compared to GN-OA, a state-of-the-art
neural potential based CSP algorithm, ParetoCSP demonstrated significantly
better predictive capabilities, outperforming by a factor of $2.562$ across
$55$ diverse benchmark structures, as evaluated by seven performance metrics.
Trajectory analysis of the traversed structures of all algorithms shows that
ParetoCSP generated more valid structures than other algorithms, which helped
guide the GA to search more effectively for the optimal structures
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06763" title="Abstract">arXiv:2309.06763</a> (cross-list from quant-ph) [<a href="/pdf/2309.06763" title="Download PDF">pdf</a>, <a href="/format/2309.06763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of a Hybrid Algorithm Based on Quantum Annealing to Solve a  Metropolitan Scale Railway Dispatching Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Koniorczyk%2C+M">M&#xe1;ty&#xe1;s Koniorczyk</a>, 
<a href="/search/quant-ph?searchtype=author&query=Krawiec%2C+K">Krzysztof Krawiec</a>, 
<a href="/search/quant-ph?searchtype=author&query=Botelho%2C+L">Ludmila Botelho</a>, 
<a href="/search/quant-ph?searchtype=author&query=Be%C5%A1inovi%C4%87%2C+N">Nikola Be&#x161;inovi&#x107;</a>, 
<a href="/search/quant-ph?searchtype=author&query=Domino%2C+K">Krzysztof Domino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">We address the applicability of quantum-classical hybrid solvers for
practical railway dispatching/conflict management problems, with a
demonstration on real-life metropolitan-scale network traffic. The railway
network includes both single-and double segments and covers all the
requirements posed by the operator of the network. We build a linear integer
model for the problem and solve it with D-Wave's quantum-classical hybrid
solver as well as with CPLEX for comparison. The computational results
demonstrate the readiness for application and benefits of quantum-classical
hybrid solvers in the a realistic railway scenario: they yield acceptable
solutions on time; a critical requirement in a dispatching situation. Though
they are heuristic they offer a valid alternative and outperform classical
solvers in some cases.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06770" title="Abstract">arXiv:2309.06770</a> (cross-list from eess.IV) [<a href="/pdf/2309.06770" title="Download PDF">pdf</a>, <a href="/format/2309.06770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-based Synthetic High-Resolution In-Depth Imaging Using an  Attachable Dual-element Endoscopic Ultrasound Probe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lew%2C+H+M">Hah Min Lew</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J+S">Jae Seong Kim</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+M+H">Moon Hwan Lee</a>, 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jaegeun Park</a>, 
<a href="/search/eess?searchtype=author&query=Youn%2C+S">Sangyeon Youn</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+H+M">Hee Man Kim</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Jihun Kim</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+J+Y">Jae Youn Hwang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Endoscopic ultrasound (EUS) imaging has a trade-off between resolution and
penetration depth. By considering the in-vivo characteristics of human organs,
it is necessary to provide clinicians with appropriate hardware specifications
for precise diagnosis. Recently, super-resolution (SR) ultrasound imaging
studies, including the SR task in deep learning fields, have been reported for
enhancing ultrasound images. However, most of those studies did not consider
ultrasound imaging natures, but rather they were conventional SR techniques
based on downsampling of ultrasound images. In this study, we propose a novel
deep learning-based high-resolution in-depth imaging probe capable of offering
low- and high-frequency ultrasound image pairs. We developed an attachable
dual-element EUS probe with customized low- and high-frequency ultrasound
transducers under small hardware constraints. We also designed a special geared
structure to enable the same image plane. The proposed system was evaluated
with a wire phantom and a tissue-mimicking phantom. After the evaluation, 442
ultrasound image pairs from the tissue-mimicking phantom were acquired. We then
applied several deep learning models to obtain synthetic high-resolution
in-depth images, thus demonstrating the feasibility of our approach for
clinical unmet needs. Furthermore, we quantitatively and qualitatively analyzed
the results to find a suitable deep-learning model for our task. The obtained
results demonstrate that our proposed dual-element EUS probe with an
image-to-image translation network has the potential to provide synthetic
high-frequency ultrasound images deep inside tissues.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06782" title="Abstract">arXiv:2309.06782</a> (cross-list from physics.data-an) [<a href="/pdf/2309.06782" title="Download PDF">pdf</a>, <a href="/format/2309.06782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable neural network models and terascale datasets for particle-flow  reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Pata%2C+J">Joosep Pata</a>, 
<a href="/search/physics?searchtype=author&query=Wulff%2C+E">Eric Wulff</a>, 
<a href="/search/physics?searchtype=author&query=Mokhtar%2C+F">Farouk Mokhtar</a>, 
<a href="/search/physics?searchtype=author&query=Southwick%2C+D">David Southwick</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+M">Mengke Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Girone%2C+M">Maria Girone</a>, 
<a href="/search/physics?searchtype=author&query=Duarte%2C+J">Javier Duarte</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Analysis, Statistics and Probability (physics.data-an)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Instrumentation and Detectors (physics.ins-det); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study scalable machine learning models for full event reconstruction in
high-energy electron-positron collisions based on a highly granular detector
simulation. Particle-flow (PF) reconstruction can be formulated as a supervised
learning task using tracks and calorimeter clusters or hits. We compare a graph
neural network and kernel-based transformer and demonstrate that both avoid
quadratic memory allocation and computational cost while achieving realistic PF
reconstruction. We show that hyperparameter tuning on a supercomputer
significantly improves the physics performance of the models. We also
demonstrate that the resulting model is highly portable across hardware
processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we
demonstrate that the model can be trained on highly granular inputs consisting
of tracks and calorimeter hits, resulting in a competitive physics performance
with the baseline. Datasets and software to reproduce the studies are published
following the findable, accessible, interoperable, and reusable (FAIR)
principles.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06798" title="Abstract">arXiv:2309.06798</a> (cross-list from math.AP) [<a href="/pdf/2309.06798" title="Download PDF">pdf</a>, <a href="/format/2309.06798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial boundary conditions for random ellitpic systems with  correlated coefficient field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Clozeau%2C+N">Nicolas Clozeau</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+L">Lihan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA); Probability (math.PR)

</div>
<p class="mathjax">We are interested in numerical algorithms for computing the electrical field
generated by a charge distribution localized on scale $l$ in an infinite
heterogeneous correlated random medium, in a situation where the medium is only
known in a box of diameter $L\gg l$ around the support of the charge. We show
that the algorithm of Lu, Otto and Wang, suggesting optimal Dirichlet boundary
conditions motivated by the multipole expansion of Bella, Giunti and Otto,
still performs well in correlated media. With overwhelming probability, we
obtain a convergence rate in terms of $l$, $L$ and the size of the correlations
for which optimality is supported with numerical simulations. These estimates
are provided for ensembles which satisfy a multi-scale logarithmic Sobolev
inequality, where our main tool is an extension of the semi-group estimates
established by the first author. As part of our strategy, we construct
sub-linear second-order correctors in this correlated setting which is of
independent interest.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06825" title="Abstract">arXiv:2309.06825</a> (cross-list from eess.IV) [<a href="/pdf/2309.06825" title="Download PDF">pdf</a>, <a href="/format/2309.06825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-inspired Cross-domain Network for Developmental Cervical  Stenosis Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhenxi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yanyang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yao Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+W">Weifei Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Developmental Canal Stenosis (DCS) quantification is crucial in cervical
spondylosis screening. Compared with quantifying DCS manually, a more efficient
and time-saving manner is provided by deep keypoint localization networks,
which can be implemented in either the coordinate or the image domain. However,
the vertebral visualization features often lead to abnormal topological
structures during keypoint localization, including keypoint distortion with
edges and weakly connected structures, which cannot be fully suppressed in
either the coordinate or image domain alone. To overcome this limitation, a
keypoint-edge and a reparameterization modules are utilized to restrict these
abnormal structures in a cross-domain manner. The keypoint-edge constraint
module restricts the keypoints on the edges of vertebrae, which ensures that
the distribution pattern of keypoint coordinates is consistent with those for
DCS quantification. And the reparameterization module constrains the weakly
connected structures in image-domain heatmaps with coordinates combined.
Moreover, the cross-domain network improves spatial generalization by utilizing
heatmaps and incorporating coordinates for accurate localization, which avoids
the trade-off between these two properties in an individual domain.
Comprehensive results of distinct quantification tasks show the superiority and
generability of the proposed Topology-inspired Cross-domain Network (TCN)
compared with other competing localization methods.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06854" title="Abstract">arXiv:2309.06854</a> (cross-list from math.OC) [<a href="/pdf/2309.06854" title="Download PDF">pdf</a>, <a href="/ps/2309.06854" title="Download PostScript">ps</a>, <a href="/format/2309.06854" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear network identifiability: The static case
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Vizuete%2C+R">Renato Vizuete</a>, 
<a href="/search/math?searchtype=author&query=Hendrickx%2C+J+M">Julien M. Hendrickx</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, to appear in IEEE Conference on Decision and Control (CDC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We analyze the problem of network identifiability with nonlinear functions
associated with the edges. We consider a static model for the output of each
node and by assuming a perfect identification of the function associated with
the measurement of a node, we provide conditions for the identifiability of the
edges in a specific class of functions. First, we analyze the identifiability
conditions in the class of all nonlinear functions and show that even for a
path graph, it is necessary to measure all the nodes except by the source.
Then, we consider analytic functions satisfying $f(0)=0$ and we provide
conditions for the identifiability of paths and trees. Finally, by restricting
the problem to a smaller class of functions where none of the functions is
linear, we derive conditions for the identifiability of directed acyclic
graphs. Some examples are presented to illustrate the results.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06869" title="Abstract">arXiv:2309.06869</a> (cross-list from cond-mat.soft) [<a href="/pdf/2309.06869" title="Download PDF">pdf</a>, <a href="/format/2309.06869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic control of self-assembly of quasicrystalline structures through  reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lieu%2C+U+T">Uyen Tu Lieu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yoshinaga%2C+N">Natsuhiko Yoshinaga</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Soft Condensed Matter (cond-mat.soft)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We propose reinforcement learning to control the dynamical self-assembly of
the dodecagonal quasicrystal (DDQC) from patchy particles. The patchy particles
have anisotropic interactions with other particles and form DDQC. However,
their structures at steady states are significantly influenced by the kinetic
pathways of their structural formation. We estimate the best policy of
temperature control trained by the Q-learning method and demonstrate that we
can generate DDQC with few defects using the estimated policy. The temperature
schedule obtained by reinforcement learning can reproduce the desired structure
more efficiently than the conventional pre-fixed temperature schedule, such as
annealing. To clarify the success of the learning, we also analyse a simple
model describing the kinetics of structural changes through the motion in a
triple-well potential. We have found that reinforcement learning autonomously
discovers the critical temperature at which structural fluctuations enhance the
chance of forming a globally stable state. The estimated policy guides the
system toward the critical temperature to assist the formation of DDQC.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06930" title="Abstract">arXiv:2309.06930</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.06930" title="Download PDF">pdf</a>, <a href="/format/2309.06930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Dislocation Dynamics Data Using Semantic Web Technologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ihsan%2C+A+Z">Ahmad Zainul Ihsan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fathalla%2C+S">Said Fathalla</a>, 
<a href="/search/cond-mat?searchtype=author&query=Sandfeld%2C+S">Stefan Sandfeld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Research in the field of Materials Science and Engineering focuses on the
design, synthesis, properties, and performance of materials. An important class
of materials that is widely investigated are crystalline materials, including
metals and semiconductors. Crystalline material typically contains a distinct
type of defect called "dislocation". This defect significantly affects various
material properties, including strength, fracture toughness, and ductility.
Researchers have devoted a significant effort in recent years to understanding
dislocation behavior through experimental characterization techniques and
simulations, e.g., dislocation dynamics simulations. This paper presents how
data from dislocation dynamics simulations can be modeled using semantic web
technologies through annotating data with ontologies. We extend the already
existing Dislocation Ontology by adding missing concepts and aligning it with
two other domain-related ontologies (i.e., the Elementary Multi-perspective
Material Ontology and the Materials Design Ontology) allowing for representing
the dislocation simulation data efficiently. Moreover, we show a real-world use
case by representing the discrete dislocation dynamics data as a knowledge
graph (DisLocKG) that illustrates the relationship between them. We also
developed a SPARQL endpoint that brings extensive flexibility to query
DisLocKG.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06934" title="Abstract">arXiv:2309.06934</a> (cross-list from eess.AS) [<a href="/pdf/2309.06934" title="Download PDF">pdf</a>, <a href="/format/2309.06934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VRDMG: Vocal Restoration via Diffusion Posterior Sampling with Multiple  Guidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hernandez-Olivan%2C+C">Carlos Hernandez-Olivan</a>, 
<a href="/search/eess?searchtype=author&query=Saito%2C+K">Koichi Saito</a>, 
<a href="/search/eess?searchtype=author&query=Murata%2C+N">Naoki Murata</a>, 
<a href="/search/eess?searchtype=author&query=Lai%2C+C">Chieh-Hsin Lai</a>, 
<a href="/search/eess?searchtype=author&query=Mart%C3%ADnez-Ramirez%2C+M+A">Marco A. Mart&#xed;nez-Ramirez</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+W">Wei-Hsiang Liao</a>, 
<a href="/search/eess?searchtype=author&query=Mitsufuji%2C+Y">Yuki Mitsufuji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Restoring degraded music signals is essential to enhance audio quality for
downstream music manipulation. Recent diffusion-based music restoration methods
have demonstrated impressive performance, and among them, diffusion posterior
sampling (DPS) stands out given its intrinsic properties, making it versatile
across various restoration tasks. In this paper, we identify that there are
potential issues which will degrade current DPS-based methods' performance and
introduce the way to mitigate the issues inspired by diverse diffusion guidance
techniques including the RePaint (RP) strategy and the Pseudoinverse-Guided
Diffusion Models ($\Pi$GDM). We demonstrate our methods for the vocal
declipping and bandwidth extension tasks under various levels of distortion and
cutoff frequency, respectively. In both tasks, our methods outperform the
current DPS-based music restoration benchmarks. We refer to
\url{<a href="http://carlosholivan.github.io/demos/audio-restoration-2023.html">this http URL</a>} for
examples of the restored audio samples.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06943" title="Abstract">arXiv:2309.06943</a> (cross-list from stat.ML) [<a href="/pdf/2309.06943" title="Download PDF">pdf</a>, <a href="/format/2309.06943" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effect of hyperparameters on variable selection in random forests
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fouodo%2C+C+J+K">Cesaire J. K. Fouodo</a>, 
<a href="/search/stat?searchtype=author&query=Kronziel%2C+L+L">Lea L. Kronziel</a>, 
<a href="/search/stat?searchtype=author&query=K%C3%B6nig%2C+I+R">Inke R. K&#xf6;nig</a>, 
<a href="/search/stat?searchtype=author&query=Szymczak%2C+S">Silke Szymczak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures + 2 figures in appendix, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Random forests (RFs) are well suited for prediction modeling and variable
selection in high-dimensional omics studies. The effect of hyperparameters of
the RF algorithm on prediction performance and variable importance estimation
have previously been investigated. However, how hyperparameters impact RF-based
variable selection remains unclear. We evaluate the effects on the Vita and the
Boruta variable selection procedures based on two simulation studies utilizing
theoretical distributions and empirical gene expression data. We assess the
ability of the procedures to select important variables (sensitivity) while
controlling the false discovery rate (FDR). Our results show that the
proportion of splitting candidate variables (mtry.prop) and the sample fraction
(sample.fraction) for the training dataset influence the selection procedures
more than the drawing strategy of the training datasets and the minimal
terminal node size. A suitable setting of the RF hyperparameters depends on the
correlation structure in the data. For weakly correlated predictor variables,
the default value of mtry is optimal, but smaller values of sample.fraction
result in larger sensitivity. In contrast, the difference in sensitivity of the
optimal compared to the default value of sample.fraction is negligible for
strongly correlated predictor variables, whereas smaller values than the
default are better in the other settings. In conclusion, the default values of
the hyperparameters will not always be suitable for identifying important
variables. Thus, adequate values differ depending on whether the aim of the
study is optimizing prediction performance or variable selection.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06946" title="Abstract">arXiv:2309.06946</a> (cross-list from eess.AS) [<a href="/pdf/2309.06946" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reorganization of the auditory-perceptual space across the human vocal  range
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Friedrichs%2C+D">Daniel Friedrichs</a>, 
<a href="/search/eess?searchtype=author&query=Dellwo%2C+V">Volker Dellwo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 20th International Congress of Phonetic
  Sciences (2023) 560-564
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">We analyzed the auditory-perceptual space across a substantial portion of the
human vocal range (220-1046 Hz) using multidimensional scaling analysis of
cochlea-scaled spectra from 250-ms vowel segments, initially studied in
Friedrichs et al. (2017) J. Acoust. Soc. Am. 142 1025-1033. The dataset
comprised the vowels /i y e {\o} {\epsilon} a o u/ (N=240) produced by three
native German female speakers, encompassing a broad range of their respective
voice frequency ranges. The initial study demonstrated that, during a
closed-set identification task involving 21 listeners, the point vowels /i a u/
were significantly recognized at fundamental frequencies (fo) nearing 1 kHz,
whereas the recognition of other vowels decreased at higher pitches. Building
on these findings, our study revealed systematic spectral shifts associated
with vowel height and frontness as fo increased, with a notable clustering
around /i a u/ above 523 Hz. These observations underscore the pivotal role of
spectral shape in vowel perception, illustrating the reliance on acoustic
anchors at higher pitches. Furthermore, this study sheds light on the quantal
nature of these vowels and their potential impact on language evolution,
offering a plausible explanation for their widespread presence in the world's
languages.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06948" title="Abstract">arXiv:2309.06948</a> (cross-list from eess.IV) [<a href="/pdf/2309.06948" title="Download PDF">pdf</a>, <a href="/format/2309.06948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limited-Angle Tomography Reconstruction via Deep End-To-End Learning on  Synthetic Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Germer%2C+T">Thomas Germer</a>, 
<a href="/search/eess?searchtype=author&query=Robine%2C+J">Jan Robine</a>, 
<a href="/search/eess?searchtype=author&query=Konietzny%2C+S">Sebastian Konietzny</a>, 
<a href="/search/eess?searchtype=author&query=Harmeling%2C+S">Stefan Harmeling</a>, 
<a href="/search/eess?searchtype=author&query=Uelwer%2C+T">Tobias Uelwer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Computed tomography (CT) has become an essential part of modern science and
medicine. A CT scanner consists of an X-ray source that is spun around an
object of interest. On the opposite end of the X-ray source, a detector
captures X-rays that are not absorbed by the object. The reconstruction of an
image is a linear inverse problem, which is usually solved by filtered back
projection. However, when the number of measurements is small, the
reconstruction problem is ill-posed. This is for example the case when the
X-ray source is not spun completely around the object, but rather irradiates
the object only from a limited angle. To tackle this problem, we present a deep
neural network that is trained on a large amount of carefully-crafted synthetic
data and can perform limited-angle tomography reconstruction even for only
30{\deg} or 40{\deg} sinograms. With our approach we won the first place in the
Helsinki Tomography Challenge 2022.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06956" title="Abstract">arXiv:2309.06956</a> (cross-list from eess.IV) [<a href="/pdf/2309.06956" title="Download PDF">pdf</a>, <a href="/format/2309.06956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Neural Multiple Description for DNA-based data storage
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Le%2C+T+H">Trung Hieu Le</a>, 
<a href="/search/eess?searchtype=author&query=Pic%2C+X">Xavier Pic</a>, 
<a href="/search/eess?searchtype=author&query=Mateos%2C+J">Jeremy Mateos</a>, 
<a href="/search/eess?searchtype=author&query=Antonini%2C+M">Marc Antonini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Xavier Pic and Trung Hieu Le are both equal contributors and primary authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">DNA exhibits remarkable potential as a data storage solution due to its
impressive storage density and long-term stability, stemming from its inherent
biomolecular structure. However, developing this novel medium comes with its
own set of challenges, particularly in addressing errors arising from storage
and biological manipulations. These challenges are further conditioned by the
structural constraints of DNA sequences and cost considerations. In response to
these limitations, we have pioneered a novel compression scheme and a
cutting-edge Multiple Description Coding (MDC) technique utilizing neural
networks for DNA data storage. Our MDC method introduces an innovative approach
to encoding data into DNA, specifically designed to withstand errors
effectively. Notably, our new compression scheme overperforms classic image
compression methods for DNA-data storage. Furthermore, our approach exhibits
superiority over conventional MDC methods reliant on auto-encoders. Its
distinctive strengths lie in its ability to bypass the need for extensive model
training and its enhanced adaptability for fine-tuning redundancy levels.
Experimental results demonstrate that our solution competes favorably with the
latest DNA data storage methods in the field, offering superior compression
rates and robust noise resilience.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07043" title="Abstract">arXiv:2309.07043</a> (cross-list from eess.AS) [<a href="/pdf/2309.07043" title="Download PDF">pdf</a>, <a href="/format/2309.07043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Flexible Online Framework for Projection-Based STFT Phase Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peer%2C+T">Tal Peer</a>, 
<a href="/search/eess?searchtype=author&query=Welker%2C+S">Simon Welker</a>, 
<a href="/search/eess?searchtype=author&query=Kolhoff%2C+J">Johannes Kolhoff</a>, 
<a href="/search/eess?searchtype=author&query=Gerkmann%2C+T">Timo Gerkmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Several recent contributions in the field of iterative STFT phase retrieval
have demonstrated that the performance of the classical Griffin-Lim method can
be considerably improved upon. By using the same projection operators as
Griffin-Lim, but combining them in innovative ways, these approaches achieve
better results in terms of both reconstruction quality and required number of
iterations, while retaining a similar computational complexity per iteration.
However, like Griffin-Lim, these algorithms operate in an offline manner and
thus require an entire spectrogram as input, which is an unrealistic
requirement for many real-world speech communication applications. We propose
to extend RTISI -- an existing online (frame-by-frame) variant of the
Griffin-Lim algorithm -- into a flexible framework that enables straightforward
online implementation of any algorithm based on iterative projections. We
further employ this framework to implement online variants of the fast
Griffin-Lim algorithm, the accelerated Griffin-Lim algorithm, and two
algorithms from the optics domain. Evaluation results on speech signals show
that, similarly to the offline case, these algorithms can achieve a
considerable performance gain compared to RTISI.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07056" title="Abstract">arXiv:2309.07056</a> (cross-list from quant-ph) [<a href="/pdf/2309.07056" title="Download PDF">pdf</a>, <a href="/format/2309.07056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Quantum Graph Dreaming: Deciphering Neural Network Insights into  Quantum Experiments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jaouni%2C+T">Tareq Jaouni</a>, 
<a href="/search/quant-ph?searchtype=author&query=Arlt%2C+S">S&#xf6;ren Arlt</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ruiz-Gonzalez%2C+C">Carlos Ruiz-Gonzalez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Karimi%2C+E">Ebrahim Karimi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gu%2C+X">Xuemei Gu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Krenn%2C+M">Mario Krenn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures. Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite their promise to facilitate new scientific discoveries, the
opaqueness of neural networks presents a challenge in interpreting the logic
behind their findings. Here, we use a eXplainable-AI (XAI) technique called
$inception$ or $deep$ $dreaming$, which has been invented in machine learning
for computer vision. We use this techniques to explore what neural networks
learn about quantum optics experiments. Our story begins by training a deep
neural networks on the properties of quantum systems. Once trained, we "invert"
the neural network -- effectively asking how it imagines a quantum system with
a specific property, and how it would continuously modify the quantum system to
change a property. We find that the network can shift the initial distribution
of properties of the quantum system, and we can conceptualize the learned
strategies of the neural network. Interestingly, we find that, in the first
layers, the neural network identifies simple properties, while in the deeper
ones, it can identify complex quantum structures and even quantum entanglement.
This is in reminiscence of long-understood properties known in computer vision,
which we now identify in a complex natural science task. Our approach could be
useful in a more interpretable way to develop new advanced AI-based scientific
discovery techniques in quantum physics.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07079" title="Abstract">arXiv:2309.07079</a> (cross-list from math.OC) [<a href="/pdf/2309.07079" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Simulation of Three-Phase Induction Machines Under Eccentricity  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ardekani%2C+I">Iman Ardekani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Farsi, Master Thesis, Tehran University
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
<p class="mathjax">This thesis propose an a computationally efficient method for dynamic
simulation and mathematical modelling of three-phase induction machines under
eccentricity conditions.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07080" title="Abstract">arXiv:2309.07080</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.07080" title="Download PDF">pdf</a>, <a href="/format/2309.07080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Dynamic DAG Learning: Application in Discovering Dynamic  Effective Connectome of Brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Bagheri%2C+A">Abdolmahdi Bagheri</a>, 
<a href="/search/q-bio?searchtype=author&query=Pasande%2C+M">Mohammad Pasande</a>, 
<a href="/search/q-bio?searchtype=author&query=Bello%2C+K">Kevin Bello</a>, 
<a href="/search/q-bio?searchtype=author&query=Akhondi-Asl%2C+A">Alireza Akhondi-Asl</a>, 
<a href="/search/q-bio?searchtype=author&query=Araabi%2C+B+N">Babak Nadjar Araabi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Understanding the complex mechanisms of the brain can be unraveled by
extracting the Dynamic Effective Connectome (DEC). Recently, score-based
Directed Acyclic Graph (DAG) discovery methods have shown significant
improvements in extracting the causal structure and inferring effective
connectivity. However, learning DEC through these methods still faces two main
challenges: one with the fundamental impotence of high-dimensional dynamic DAG
discovery methods and the other with the low quality of fMRI data. In this
paper, we introduce Bayesian Dynamic DAG learning with M-matrices Acyclicity
characterization \textbf{(BDyMA)} method to address the challenges in
discovering DEC. The presented dynamic causal model enables us to discover
bidirected edges as well. Leveraging an unconstrained framework in the BDyMA
method leads to more accurate results in detecting high-dimensional networks,
achieving sparser outcomes, making it particularly suitable for extracting DEC.
Additionally, the score function of the BDyMA method allows the incorporation
of prior knowledge into the process of dynamic causal discovery which further
enhances the accuracy of results. Comprehensive simulations on synthetic data
and experiments on Human Connectome Project (HCP) data demonstrate that our
method can handle both of the two main challenges, yielding more accurate and
reliable DEC compared to state-of-the-art and baseline methods. Additionally,
we investigate the trustworthiness of DTI data as prior knowledge for DEC
discovery and show the improvements in DEC discovery when the DTI data is
incorporated into the process.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07081" title="Abstract">arXiv:2309.07081</a> (cross-list from eess.AS) [<a href="/pdf/2309.07081" title="Download PDF">pdf</a>, <a href="/format/2309.07081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Whisper perform speech-based in-context learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Siyin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+C+H">Chao-Han Huck Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Ji Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">This paper investigates the in-context learning abilities of the Whisper
automatic speech recognition (ASR) models released by OpenAI. A novel
speech-based in-context learning (SICL) approach is proposed for test-time
adaptation, which can reduce the word error rates (WERs) with only a small
number of labelled speech samples without gradient descent. Language-level
adaptation experiments using Chinese dialects showed that when applying SICL to
isolated word ASR, consistent and considerable relative WER reductions can be
achieved using Whisper models of any size on two dialects, which is on average
32.3%. A k-nearest-neighbours-based in-context example selection technique can
be applied to further improve the efficiency of SICL, which can increase the
average relative WER reduction to 36.4%. The findings are verified using
speaker adaptation or continuous speech recognition tasks, and both achieved
considerable relative WER reductions. Detailed quantitative analyses are also
provided to shed light on SICL's adaptability to phonological variances and
dialect-specific lexical nuances.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07096" title="Abstract">arXiv:2309.07096</a> (cross-list from q-bio.NC) [<a href="/pdf/2309.07096" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The legibility of the imaged human brain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ruffle%2C+J+K">James K Ruffle</a>, 
<a href="/search/q-bio?searchtype=author&query=Gray%2C+R+J">Robert J Gray</a>, 
<a href="/search/q-bio?searchtype=author&query=Mohinta%2C+S">Samia Mohinta</a>, 
<a href="/search/q-bio?searchtype=author&query=Pombo%2C+G">Guilherme Pombo</a>, 
<a href="/search/q-bio?searchtype=author&query=Kaul%2C+C">Chaitanya Kaul</a>, 
<a href="/search/q-bio?searchtype=author&query=Hyare%2C+H">Harpreet Hyare</a>, 
<a href="/search/q-bio?searchtype=author&query=Rees%2C+G">Geraint Rees</a>, 
<a href="/search/q-bio?searchtype=author&query=Nachev%2C+P">Parashkev Nachev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 6 figures, 1 table, 2 supplementary figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Our knowledge of the organisation of the human brain at the population-level
is yet to translate into power to predict functional differences at the
individual-level, limiting clinical applications, and casting doubt on the
generalisability of inferred mechanisms. It remains unknown whether the
difficulty arises from the absence of individuating biological patterns within
the brain, or from limited power to access them with the models and compute at
our disposal. Here we comprehensively investigate the resolvability of such
patterns with data and compute at unprecedented scale. Across 23810 unique
participants from UK Biobank, we systematically evaluate the predictability of
25 individual biological characteristics, from all available combinations of
structural and functional neuroimaging data. Over 4526 GPU*hours of
computation, we train, optimize, and evaluate out-of-sample 700 individual
predictive models, including multilayer perceptrons of demographic,
psychological, serological, chronic morbidity, and functional connectivity
characteristics, and both uni- and multi-modal 3D convolutional neural network
models of macro- and micro-structural brain imaging. We find a marked
discrepancy between the high predictability of sex (balanced accuracy 99.7%),
age (mean absolute error 2.048 years, R2 0.859), and weight (mean absolute
error 2.609Kg, R2 0.625), for which we set new state-of-the-art performance,
and the surprisingly low predictability of other characteristics. Neither
structural nor functional imaging predicted individual psychology better than
the coincidence of common chronic morbidity (p&lt;0.05). Serology predicted common
morbidity (p&lt;0.05) and was best predicted by it (p&lt;0.001), followed by
structural neuroimaging (p&lt;0.05). Our findings suggest either more informative
imaging or more powerful models will be needed to decipher individual level
characteristics from the brain.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07110" title="Abstract">arXiv:2309.07110</a> (cross-list from stat.ML) [<a href="/pdf/2309.07110" title="Download PDF">pdf</a>, <a href="/format/2309.07110" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Augmentation via Subgroup Mixup for Improving Fairness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Navarro%2C+M">Madeline Navarro</a>, 
<a href="/search/stat?searchtype=author&query=Little%2C+C">Camille Little</a>, 
<a href="/search/stat?searchtype=author&query=Allen%2C+G+I">Genevera I. Allen</a>, 
<a href="/search/stat?searchtype=author&query=Segarra%2C+S">Santiago Segarra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we propose data augmentation via pairwise mixup across
subgroups to improve group fairness. Many real-world applications of machine
learning systems exhibit biases across certain groups due to
under-representation or training data that reflects societal biases. Inspired
by the successes of mixup for improving classification performance, we develop
a pairwise mixup scheme to augment training data and encourage fair and
accurate decision boundaries for all subgroups. Data augmentation for group
fairness allows us to add new samples of underrepresented groups to balance
subpopulations. Furthermore, our method allows us to use the generalization
ability of mixup to improve both fairness and accuracy. We compare our proposed
mixup to existing data augmentation and bias mitigation approaches on both
synthetic simulations and real-world benchmark fair classification data,
demonstrating that we are able to achieve fair outcomes with robust if not
improved accuracy.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Thu, 14 Sep 23</h3>
<dl>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.09455" title="Abstract">arXiv:1910.09455</a> (replaced) [<a href="/pdf/1910.09455" title="Download PDF">pdf</a>, <a href="/format/1910.09455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-wise Decomposition for Accelerating Separable Convolutions in  Efficient Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yihui He</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jianing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianren Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1911.10737" title="Abstract">arXiv:1911.10737</a> (replaced) [<a href="/pdf/1911.10737" title="Download PDF">pdf</a>, <a href="/format/1911.10737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nearest Neighbor Sampling of Point Sets using Rays
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Liangchen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ly%2C+L">Louis Ly</a>, 
<a href="/search/cs?searchtype=author&query=Macdonald%2C+C">Colin Macdonald</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y+R">Yen-Hsi Richard Tsai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 14 figures, accepted to Communication on Applied Mathematics and Computation (CAMC), Focused Issue in Honor of Prof. Stanley Osher on the Occasion of His 80th Birthday. Fixed typos and improved notations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.04178" title="Abstract">arXiv:2006.04178</a> (replaced) [<a href="/pdf/2006.04178" title="Download PDF">pdf</a>, <a href="/ps/2006.04178" title="Download PostScript">ps</a>, <a href="/format/2006.04178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Vortex Method: from Finite Lagrangian Particles to Infinite  Dimensional Eulerian Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Xiong%2C+S">Shiying Xiong</a>, 
<a href="/search/physics?searchtype=author&query=He%2C+X">Xingzhe He</a>, 
<a href="/search/physics?searchtype=author&query=Tong%2C+Y">Yunjin Tong</a>, 
<a href="/search/physics?searchtype=author&query=Deng%2C+Y">Yitong Deng</a>, 
<a href="/search/physics?searchtype=author&query=Zhu%2C+B">Bo Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.06448" title="Abstract">arXiv:2008.06448</a> (replaced) [<a href="/pdf/2008.06448" title="Download PDF">pdf</a>, <a href="/format/2008.06448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loghub: A Large Collection of System Log Datasets for AI-driven Log  Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jieming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+S">Shilin He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+P">Pinjia He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ISSRE 2023, Loghub datasets available at <a href="https://github.com/logpai/loghub">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2010.10421" title="Abstract">arXiv:2010.10421</a> (replaced) [<a href="/pdf/2010.10421" title="Download PDF">pdf</a>, <a href="/ps/2010.10421" title="Download PostScript">ps</a>, <a href="/format/2010.10421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed ADMM with linear updates over directed networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rokade%2C+K">Kiran Rokade</a>, 
<a href="/search/math?searchtype=author&query=Kalaimani%2C+R+K">Rachel Kalpana Kalaimani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.05365" title="Abstract">arXiv:2011.05365</a> (replaced) [<a href="/pdf/2011.05365" title="Download PDF">pdf</a>, <a href="/format/2011.05365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Nearly-Linear Time Algorithm for Linear Programs with Small Treewidth:  A Multiscale Representation of Robust Central Path
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+S">Sally Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y+T">Yin Tat Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+G">Guanghao Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2101.03058" title="Abstract">arXiv:2101.03058</a> (replaced) [<a href="/pdf/2101.03058" title="Download PDF">pdf</a>, <a href="/format/2101.03058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Answer Counting under Guarded TGDs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feier%2C+C">Cristina Feier</a>, 
<a href="/search/cs?searchtype=author&query=Lutz%2C+C">Carsten Lutz</a>, 
<a href="/search/cs?searchtype=author&query=Przyby%C5%82ko%2C+M">Marcin Przyby&#x142;ko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.07980" title="Abstract">arXiv:2104.07980</a> (replaced) [<a href="/pdf/2104.07980" title="Download PDF">pdf</a>, <a href="/ps/2104.07980" title="Download PostScript">ps</a>, <a href="/format/2104.07980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Comparison Between A Simple Full-Duplex Multi-Antenna Relay  And A Passive Reflecting Intelligent Surface
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bazrafkan%2C+A">Armin Bazrafkan</a>, 
<a href="/search/cs?searchtype=author&query=Poposka%2C+M">Marija Poposka</a>, 
<a href="/search/cs?searchtype=author&query=Hadzi-Velkov%2C+Z">Zoran Hadzi-Velkov</a>, 
<a href="/search/cs?searchtype=author&query=Popovski%2C+P">Petar Popovski</a>, 
<a href="/search/cs?searchtype=author&query=Zlatanov%2C+N">Nikola Zlatanov</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications, vol. 22, no. 8, pp.
  5461-5472, Aug. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.09770" title="Abstract">arXiv:2106.09770</a> (replaced) [<a href="/pdf/2106.09770" title="Download PDF">pdf</a>, <a href="/ps/2106.09770" title="Download PostScript">ps</a>, <a href="/format/2106.09770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is Channel Estimation Necessary to Select Phase-Shifts for RIS-Assisted  Massive MIMO?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+%C3%96+T">&#xd6;zlem Tu&#x11f;fe Demir</a>, 
<a href="/search/cs?searchtype=author&query=Bj%C3%B6rnson%2C+E">Emil Bj&#xf6;rnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in IEEE Transactions on Wireless Communications, vol. 21, no. 11, November 2022
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Wireless Communications, vol. 21, no. 11,
  November 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.11173" title="Abstract">arXiv:2108.11173</a> (replaced) [<a href="/pdf/2108.11173" title="Download PDF">pdf</a>, <a href="/format/2108.11173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Incorporating Surprisingly Popular Algorithm and Euclidean  Distance-based Adaptive Topology into PSO
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jizong Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pengyue Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Q">Quanlong Cui</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Liang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yanchun Liang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Han Huang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H+P">Heow Pueh Lee</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+C">Chunyan Miao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">You Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chunguo Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.00644" title="Abstract">arXiv:2109.00644</a> (replaced) [<a href="/pdf/2109.00644" title="Download PDF">pdf</a>, <a href="/format/2109.00644" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RIFLE: Imputation and Robust Inference from Low Order Marginals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baharlouei%2C+S">Sina Baharlouei</a>, 
<a href="/search/cs?searchtype=author&query=Ogudu%2C+K">Kelechi Ogudu</a>, 
<a href="/search/cs?searchtype=author&query=Suen%2C+S">Sze-chuan Suen</a>, 
<a href="/search/cs?searchtype=author&query=Razaviyayn%2C+M">Meisam Razaviyayn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 11 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Transaction on Machine Learning Research (TMLR), 09/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Mathematical Software (cs.MS)

</div>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.08123" title="Abstract">arXiv:2109.08123</a> (replaced) [<a href="/pdf/2109.08123" title="Download PDF">pdf</a>, <a href="/format/2109.08123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural &#xc9;tendue Expander for Ultra-Wide-Angle High-Fidelity  Holographic Display
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tseng%2C+E">Ethan Tseng</a>, 
<a href="/search/eess?searchtype=author&query=Baek%2C+S">Seung-Hwan Baek</a>, 
<a href="/search/eess?searchtype=author&query=Kuo%2C+G">Grace Kuo</a>, 
<a href="/search/eess?searchtype=author&query=Matsuda%2C+N">Nathan Matsuda</a>, 
<a href="/search/eess?searchtype=author&query=Maimone%2C+A">Andrew Maimone</a>, 
<a href="/search/eess?searchtype=author&query=Schiffers%2C+F">Florian Schiffers</a>, 
<a href="/search/eess?searchtype=author&query=Chakravarthula%2C+P">Praneeth Chakravarthula</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+Q">Qiang Fu</a>, 
<a href="/search/eess?searchtype=author&query=Heidrich%2C+W">Wolfgang Heidrich</a>, 
<a href="/search/eess?searchtype=author&query=Lanman%2C+D">Douglas Lanman</a>, 
<a href="/search/eess?searchtype=author&query=Heide%2C+F">Felix Heide</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.07292" title="Abstract">arXiv:2110.07292</a> (replaced) [<a href="/pdf/2110.07292" title="Download PDF">pdf</a>, <a href="/ps/2110.07292" title="Download PostScript">ps</a>, <a href="/format/2110.07292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sign and Relevance Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Daryanavard%2C+S">Sama Daryanavard</a>, 
<a href="/search/cs?searchtype=author&query=Porr%2C+B">Bernd Porr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.12550" title="Abstract">arXiv:2111.12550</a> (replaced) [<a href="/pdf/2111.12550" title="Download PDF">pdf</a>, <a href="/format/2111.12550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Worker-Task Specialization Model for Crowdsourcing: Efficient  Inference and Fundamental Limits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Doyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jeonghwan Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+H+W">Hye Won Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at IEEE Transactions on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.00720" title="Abstract">arXiv:2112.00720</a> (replaced) [<a href="/pdf/2112.00720" title="Download PDF">pdf</a>, <a href="/format/2112.00720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight quasi-universality of Reeb graph distances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bauer%2C+U">Ulrich Bauer</a>, 
<a href="/search/math?searchtype=author&query=Bjerkevik%2C+H+B">H&#xe5;vard Bakke Bjerkevik</a>, 
<a href="/search/math?searchtype=author&query=Fluhr%2C+B">Benedikt Fluhr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 8 figures. This version establishes the tightness of all the bounds shown in the conference paper for SoCG 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geometric Topology (math.GT)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00799" title="Abstract">arXiv:2202.00799</a> (replaced) [<a href="/pdf/2202.00799" title="Download PDF">pdf</a>, <a href="/format/2202.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Remove, Reduce, Inform: What Actions do People Want Social Media  Platforms to Take on Potentially Misleading Content?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atreja%2C+S">Shubham Atreja</a>, 
<a href="/search/cs?searchtype=author&query=Hemphill%2C+L">Libby Hemphill</a>, 
<a href="/search/cs?searchtype=author&query=Resnick%2C+P">Paul Resnick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted at CSCW 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09518" title="Abstract">arXiv:2202.09518</a> (replaced) [<a href="/pdf/2202.09518" title="Download PDF">pdf</a>, <a href="/format/2202.09518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Out-of-Memory NMF on CPU/GPU Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boureima%2C+I">Ismael Boureima</a>, 
<a href="/search/cs?searchtype=author&query=Bhattarai%2C+M">Manish Bhattarai</a>, 
<a href="/search/cs?searchtype=author&query=Eren%2C+M">Maksim Eren</a>, 
<a href="/search/cs?searchtype=author&query=Skau%2C+E">Erik Skau</a>, 
<a href="/search/cs?searchtype=author&query=Romero%2C+P">Philip Romero</a>, 
<a href="/search/cs?searchtype=author&query=Eidenbenz%2C+S">Stephan Eidenbenz</a>, 
<a href="/search/cs?searchtype=author&query=Alexandrov%2C+B">Boian Alexandrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at Journal of Supercomputing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.06008" title="Abstract">arXiv:2203.06008</a> (replaced) [<a href="/pdf/2203.06008" title="Download PDF">pdf</a>, <a href="/format/2203.06008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delaunay-like Triangulation of Smooth Orientable Submanifolds by L1-Norm  Minimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Attali%2C+D">Dominique Attali</a>, 
<a href="/search/cs?searchtype=author&query=Lieutier%2C+A">Andr&#xe9; Lieutier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 48 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.14092" title="Abstract">arXiv:2203.14092</a> (replaced) [<a href="/pdf/2203.14092" title="Download PDF">pdf</a>, <a href="/format/2203.14092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A large scale multi-view RGBD visual affordance learning dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+Z">Zeyad Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+S+A+A">Syed Afaq Ali Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04901" title="Abstract">arXiv:2204.04901</a> (replaced) [<a href="/pdf/2204.04901" title="Download PDF">pdf</a>, <a href="/format/2204.04901" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropic transfer operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Junge%2C+O">Oliver Junge</a>, 
<a href="/search/math?searchtype=author&query=Matthes%2C+D">Daniel Matthes</a>, 
<a href="/search/math?searchtype=author&query=Schmitzer%2C+B">Bernhard Schmitzer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> revised version, streamlined presentation, added numerical comparison with other methods
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03202" title="Abstract">arXiv:2205.03202</a> (replaced) [<a href="/pdf/2205.03202" title="Download PDF">pdf</a>, <a href="/ps/2205.03202" title="Download PostScript">ps</a>, <a href="/format/2205.03202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perseus: A Simple and Optimal High-Order Method for Variational  Inequalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lin%2C+T">Tianyi Lin</a>, 
<a href="/search/math?searchtype=author&query=Jordan%2C+M+I">Michael. I. Jordan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improve the paper significantly; 40 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.03526" title="Abstract">arXiv:2205.03526</a> (replaced) [<a href="/pdf/2205.03526" title="Download PDF">pdf</a>, <a href="/ps/2205.03526" title="Download PostScript">ps</a>, <a href="/format/2205.03526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The general position avoidance game and hardness of general position  games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=V.%2C+U+C+S">Ullas Chandran S. V.</a>, 
<a href="/search/math?searchtype=author&query=Klavzar%2C+S">Sandi Klavzar</a>, 
<a href="/search/math?searchtype=author&query=K.%2C+N+P">Neethu P. K.</a>, 
<a href="/search/math?searchtype=author&query=Sampaio%2C+R">Rudini Sampaio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.08340" title="Abstract">arXiv:2205.08340</a> (replaced) [<a href="/pdf/2205.08340" title="Download PDF">pdf</a>, <a href="/format/2205.08340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified framework for dataset shift diagnostics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Polo%2C+F+M">Felipe Maia Polo</a>, 
<a href="/search/stat?searchtype=author&query=Izbicki%2C+R">Rafael Izbicki</a>, 
<a href="/search/stat?searchtype=author&query=Lacerda%2C+E+G">Evanildo Gomes Lacerda Jr</a>, 
<a href="/search/stat?searchtype=author&query=Ibieta-Jimenez%2C+J+P">Juan Pablo Ibieta-Jimenez</a>, 
<a href="/search/stat?searchtype=author&query=Vicente%2C+R">Renato Vicente</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Information Sciences (2023): 119612
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.10968" title="Abstract">arXiv:2206.10968</a> (replaced) [<a href="/pdf/2206.10968" title="Download PDF">pdf</a>, <a href="/ps/2206.10968" title="Download PostScript">ps</a>, <a href="/format/2206.10968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple-Access Channel Coding with Non-Signaling Correlations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fawzi%2C+O">Omar Fawzi</a>, 
<a href="/search/cs?searchtype=author&query=Ferm%C3%A9%2C+P">Paul Ferm&#xe9;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages. TIT Version. Added independent non-signaling assisted capacity region characterization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12440" title="Abstract">arXiv:2206.12440</a> (replaced) [<a href="/pdf/2206.12440" title="Download PDF">pdf</a>, <a href="/format/2206.12440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undetectable GPS-Spoofing Attack on Time Series Phasor Measurement Unit  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+I">Imtiaj Khan</a>, 
<a href="/search/eess?searchtype=author&query=Centeno%2C+V">Virgilio Centeno</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.04320" title="Abstract">arXiv:2207.04320</a> (replaced) [<a href="/pdf/2207.04320" title="Download PDF">pdf</a>, <a href="/format/2207.04320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Snipper: A Spatiotemporal Transformer for Simultaneous Multi-Person 3D  Pose Estimation Tracking and Forecasting on a Video Snippet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zou%2C+S">Shihao Zou</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yuanlu Xu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lingni Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Li Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Vo%2C+M">Minh Vo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.08610" title="Abstract">arXiv:2207.08610</a> (replaced) [<a href="/pdf/2207.08610" title="Download PDF">pdf</a>, <a href="/format/2207.08610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rapid and robust synchronization via weak synaptic coupling Extended  arXiv version
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+J+G">Jin Gyu Lee</a>, 
<a href="/search/eess?searchtype=author&query=Sepulchre%2C+R">Rodolphe Sepulchre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.14336" title="Abstract">arXiv:2207.14336</a> (replaced) [<a href="/pdf/2207.14336" title="Download PDF">pdf</a>, <a href="/format/2207.14336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data centers with quantum random access memory and quantum networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hann%2C+C+T">Connor T. Hann</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, many figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08464" title="Abstract">arXiv:2208.08464</a> (replaced) [<a href="/pdf/2208.08464" title="Download PDF">pdf</a>, <a href="/format/2208.08464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CTRL: Clustering Training Losses for Label Error Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+C">Chang Yue</a>, 
<a href="/search/cs?searchtype=author&query=Jha%2C+N+K">Niraj K. Jha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10727" title="Abstract">arXiv:2208.10727</a> (replaced) [<a href="/pdf/2208.10727" title="Download PDF">pdf</a>, <a href="/format/2208.10727" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Homomorphically Full Oriented Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bellitto%2C+T">Thomas Bellitto</a>, 
<a href="/search/cs?searchtype=author&query=Duffy%2C+C">Christopher Duffy</a>, 
<a href="/search/cs?searchtype=author&query=MacGillivray%2C+G">Gary MacGillivray</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Discrete Mathematics and Theoretical Computer Science 25:2 #13
  (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.13902" title="Abstract">arXiv:2208.13902</a> (replaced) [<a href="/pdf/2208.13902" title="Download PDF">pdf</a>, <a href="/format/2208.13902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Radial Prediction Domain Adaption Classifier for the MIDOG 2022  Challenge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Annuscheit%2C+J">Jonas Annuscheit</a>, 
<a href="/search/cs?searchtype=author&query=Krumnow%2C+C">Christian Krumnow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Contribution to the MIDOG-2022-Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.02388" title="Abstract">arXiv:2209.02388</a> (replaced) [<a href="/pdf/2209.02388" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pathway to Future Symbiotic Creativity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jie Fu</a>, 
<a href="/search/cs?searchtype=author&query=Jensen%2C+H">Henrik Jensen</a>, 
<a href="/search/cs?searchtype=author&query=Rosas%2C+F">Fernando Rosas</a>, 
<a href="/search/cs?searchtype=author&query=Shaw%2C+J">Jeffrey Shaw</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jianliang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09421" title="Abstract">arXiv:2209.09421</a> (replaced) [<a href="/pdf/2209.09421" title="Download PDF">pdf</a>, <a href="/format/2209.09421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Information-based Source Seeking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianpeng Zhang</a> (1), 
<a href="/search/cs?searchtype=author&query=Qin%2C+V">Victor Qin</a> (2), 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yujie Tang</a> (3), 
<a href="/search/cs?searchtype=author&query=Li%2C+N">Na Li</a> (1) ((1) Harvard University, (2) Massachusetts Institute of Technology, (3) Peking University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.10465" title="Abstract">arXiv:2209.10465</a> (replaced) [<a href="/pdf/2209.10465" title="Download PDF">pdf</a>, <a href="/format/2209.10465" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Many Grid-Forming Converters do We Need? A Perspective From Small  Signal Stability and Power Grid Strength
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xin%2C+H">Huanhai Xin</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yuxuan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xia Chen</a>, 
<a href="/search/eess?searchtype=author&query=Prieto-Araujo%2C+E">Eduardo Prieto-Araujo</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14369" title="Abstract">arXiv:2209.14369</a> (replaced) [<a href="/pdf/2209.14369" title="Download PDF">pdf</a>, <a href="/format/2209.14369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social Search: retrieving information in Online Social Platforms -- A  Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amendola%2C+M">Maddalena Amendola</a>, 
<a href="/search/cs?searchtype=author&query=Passarella%2C+A">Andrea Passarella</a>, 
<a href="/search/cs?searchtype=author&query=Perego%2C+R">Raffaele Perego</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07869" title="Abstract">arXiv:2210.07869</a> (replaced) [<a href="/pdf/2210.07869" title="Download PDF">pdf</a>, <a href="/ps/2210.07869" title="Download PostScript">ps</a>, <a href="/format/2210.07869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Witnessed Symmetric Choice and Interpretations in Fixed-Point Logic with  Counting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lichter%2C+M">Moritz Lichter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 5 figures, [v2] and [v3] Corrected minor mistakes and added figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08092" title="Abstract">arXiv:2210.08092</a> (replaced) [<a href="/pdf/2210.08092" title="Download PDF">pdf</a>, <a href="/format/2210.08092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probably Approximately Correct Nonlinear Model Predictive Control  (PAC-NMPC)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+A">Adam Polevoy</a>, 
<a href="/search/cs?searchtype=author&query=Kobilarov%2C+M">Marin Kobilarov</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Joseph Moore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.02982" title="Abstract">arXiv:2211.02982</a> (replaced) [<a href="/pdf/2211.02982" title="Download PDF">pdf</a>, <a href="/format/2211.02982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event and Entity Extraction from Generated Video Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Scherer%2C+J">Johannes Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Scherp%2C+A">Ansgar Scherp</a>, 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+D">Deepayan Bhowmik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at CD-MAKE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03231" title="Abstract">arXiv:2211.03231</a> (replaced) [<a href="/pdf/2211.03231" title="Download PDF">pdf</a>, <a href="/format/2211.03231" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spectral Analysis of Graph Neural Networks on Dense and Sparse Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruiz%2C+L">Luana Ruiz</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+N">Ningyuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Villar%2C+S">Soledad Villar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of ICASSP 2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08413" title="Abstract">arXiv:2211.08413</a> (replaced) [<a href="/pdf/2211.08413" title="Download PDF">pdf</a>, <a href="/format/2211.08413" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Federated Learning: Fundamentals, State of the Art,  Frameworks, Trends, and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Beltr%C3%A1n%2C+E+T+M">Enrique Tom&#xe1;s Mart&#xed;nez Beltr&#xe1;n</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+M+Q">Mario Quiles P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+P+M+S">Pedro Miguel S&#xe1;nchez S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Bernal%2C+S+L">Sergio L&#xf3;pez Bernal</a>, 
<a href="/search/cs?searchtype=author&query=Bovet%2C+G">G&#xe9;r&#xf4;me Bovet</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+M+G">Manuel Gil P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+G+M">Gregorio Mart&#xed;nez P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Celdr%C3%A1n%2C+A+H">Alberto Huertas Celdr&#xe1;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI)

</div>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.10865" title="Abstract">arXiv:2211.10865</a> (replaced) [<a href="/pdf/2211.10865" title="Download PDF">pdf</a>, <a href="/format/2211.10865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IC3D: Image-Conditioned 3D Diffusion for Shape Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sbrolli%2C+C">Cristian Sbrolli</a>, 
<a href="/search/cs?searchtype=author&query=Cudrano%2C+P">Paolo Cudrano</a>, 
<a href="/search/cs?searchtype=author&query=Frosi%2C+M">Matteo Frosi</a>, 
<a href="/search/cs?searchtype=author&query=Matteucci%2C+M">Matteo Matteucci</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures; appendix 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12135" title="Abstract">arXiv:2211.12135</a> (replaced) [<a href="/pdf/2211.12135" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Technologies, Training Initiatives and the Future of Manuscript  Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Poleg%2C+E">Eyal Poleg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16799" title="Abstract">arXiv:2211.16799</a> (replaced) [<a href="/pdf/2211.16799" title="Download PDF">pdf</a>, <a href="/format/2211.16799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NOPE-SAC: Neural One-Plane RANSAC for Sparse-View Planar 3D  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+B">Bin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+N">Nan Xue</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianfu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE TPAMI; Code is available at <a href="https://github.com/IceTTTb/NopeSAC">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01173" title="Abstract">arXiv:2212.01173</a> (replaced) [<a href="/pdf/2212.01173" title="Download PDF">pdf</a>, <a href="/format/2212.01173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DWRSeg: Rethinking Efficient Acquisition of Multi-scale Contextual  Information for Real-time Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Haoran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shouchun Xu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Z">Zhongjian Dai</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yaping Dai</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangyang Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01378" title="Abstract">arXiv:2212.01378</a> (replaced) [<a href="/pdf/2212.01378" title="Download PDF">pdf</a>, <a href="/format/2212.01378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Don-Yehiya%2C+S">Shachar Don-Yehiya</a>, 
<a href="/search/cs?searchtype=author&query=Venezian%2C+E">Elad Venezian</a>, 
<a href="/search/cs?searchtype=author&query=Raffel%2C+C">Colin Raffel</a>, 
<a href="/search/cs?searchtype=author&query=Slonim%2C+N">Noam Slonim</a>, 
<a href="/search/cs?searchtype=author&query=Katz%2C+Y">Yoav Katz</a>, 
<a href="/search/cs?searchtype=author&query=Choshen%2C+L">Leshem Choshen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACL 23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.04492" title="Abstract">arXiv:2212.04492</a> (replaced) [<a href="/pdf/2212.04492" title="Download PDF">pdf</a>, <a href="/format/2212.04492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-View Object Reconstruction with Unknown Categories and Camera Poses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hanwen Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhenyu Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Grauman%2C+K">Kristen Grauman</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.08678" title="Abstract">arXiv:2212.08678</a> (replaced) [<a href="/pdf/2212.08678" title="Download PDF">pdf</a>, <a href="/format/2212.08678" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An in-principle super-polynomial quantum advantage for approximating  combinatorial optimization problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pirnay%2C+N">Niklas Pirnay</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ulitzsch%2C+V">Vincent Ulitzsch</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wilde%2C+F">Frederik Wilde</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eisert%2C+J">Jens Eisert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Seifert%2C+J">Jean-Pierre Seifert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5+13 pages, 5 figures, presentation improved
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Other Condensed Matter (cond-mat.other); Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11819" title="Abstract">arXiv:2212.11819</a> (replaced) [<a href="/pdf/2212.11819" title="Download PDF">pdf</a>, <a href="/format/2212.11819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interaction-Aware Motion Planning for Autonomous Vehicles with  Multi-Modal Obstacle Uncertainty Predictions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jian Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Olofsson%2C+B">Bj&#xf6;rn Olofsson</a>, 
<a href="/search/eess?searchtype=author&query=Frisk%2C+E">Erik Frisk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.12964" title="Abstract">arXiv:2212.12964</a> (replaced) [<a href="/pdf/2212.12964" title="Download PDF">pdf</a>, <a href="/format/2212.12964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Security -- A Question of Perspective. A Large-Scale Telephone  Survey with Four At-Risk User Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herbert%2C+F">Franziska Herbert</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">Steffen Becker</a>, 
<a href="/search/cs?searchtype=author&query=Buckmann%2C+A">Annalina Buckmann</a>, 
<a href="/search/cs?searchtype=author&query=Kowalewski%2C+M">Marvin Kowalewski</a>, 
<a href="/search/cs?searchtype=author&query=Hielscher%2C+J">Jonas Hielscher</a>, 
<a href="/search/cs?searchtype=author&query=Acar%2C+Y">Yasemin Acar</a>, 
<a href="/search/cs?searchtype=author&query=D%C3%BCrmuth%2C+M">Markus D&#xfc;rmuth</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yixin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Sasse%2C+M+A">M. Angela Sasse</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14864" title="Abstract">arXiv:2212.14864</a> (replaced) [<a href="/pdf/2212.14864" title="Download PDF">pdf</a>, <a href="/format/2212.14864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification for sparse Fourier recovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+F">Frederik Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Krahmer%2C+F">Felix Krahmer</a>, 
<a href="/search/cs?searchtype=author&query=Verdun%2C+C+M">Claudio Mayrink Verdun</a>, 
<a href="/search/cs?searchtype=author&query=Menzel%2C+M+I">Marion I. Menzel</a>, 
<a href="/search/cs?searchtype=author&query=Rauhut%2C+H">Holger Rauhut</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00545" title="Abstract">arXiv:2301.00545</a> (replaced) [<a href="/pdf/2301.00545" title="Download PDF">pdf</a>, <a href="/format/2301.00545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Knockoffs-SPR: Clean Sample Selection in Learning with Noisy Labels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yikai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+X">Xinwei Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> update: refined theory and analysis, release code
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01718" title="Abstract">arXiv:2301.01718</a> (replaced) [<a href="/pdf/2301.01718" title="Download PDF">pdf</a>, <a href="/format/2301.01718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An adaptive, training-free reduced-order model for convection-dominated  problems based on hybrid snapshots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zucatti%2C+V">Victor Zucatti</a>, 
<a href="/search/math?searchtype=author&query=Zahr%2C+M+J">Matthew J. Zahr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02817" title="Abstract">arXiv:2301.02817</a> (replaced) [<a href="/pdf/2301.02817" title="Download PDF">pdf</a>, <a href="/ps/2301.02817" title="Download PostScript">ps</a>, <a href="/format/2301.02817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cost-optimal Seeding Strategy During a Botanical Pandemic in  Domesticated Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06732" title="Abstract">arXiv:2301.06732</a> (replaced) [<a href="/e-print/2301.06732" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solar Coronal Hole Analysis and Prediction using Computer Vision and  LSTM Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Yun%2C+J">Juyoung Yun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is old technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Solar and Stellar Astrophysics (astro-ph.SR)</span>; Earth and Planetary Astrophysics (astro-ph.EP); Machine Learning (cs.LG); Space Physics (physics.space-ph)

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06781" title="Abstract">arXiv:2301.06781</a> (replaced) [<a href="/pdf/2301.06781" title="Download PDF">pdf</a>, <a href="/format/2301.06781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A nested divide-and-conquer method for tensor Sylvester equations with  positive definite hierarchically semiseparable coefficients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Massei%2C+S">Stefano Massei</a>, 
<a href="/search/math?searchtype=author&query=Robol%2C+L">Leonardo Robol</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10670" title="Abstract">arXiv:2301.10670</a> (replaced) [<a href="/pdf/2301.10670" title="Download PDF">pdf</a>, <a href="/format/2301.10670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TMSA: Towards Arbitrary Text-driven Image Manipulation via Space  Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunpeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Z">Zihan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+C">Chao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+G">Guowei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Chun Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10672" title="Abstract">arXiv:2301.10672</a> (replaced) [<a href="/pdf/2301.10672" title="Download PDF">pdf</a>, <a href="/format/2301.10672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implicit Shape Model Trees: Recognition of 3-D Indoor Scenes and  Prediction of Object Poses for Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%C3%9Fner%2C+P">Pascal Mei&#xdf;ner</a>, 
<a href="/search/cs?searchtype=author&query=Dillmann%2C+R">R&#xfc;diger Dillmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 24 figures; For associated video clips, see <a href="https://www.youtube.com/playlist?list=PL3RZ_UQY_uOIfuIJNqdS8wDMjTjOAeOmu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10908" title="Abstract">arXiv:2301.10908</a> (replaced) [<a href="/pdf/2301.10908" title="Download PDF">pdf</a>, <a href="/format/2301.10908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distilling Cognitive Backdoor Patterns within an Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Hanxun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xingjun Ma</a>, 
<a href="/search/cs?searchtype=author&query=Erfani%2C+S">Sarah Erfani</a>, 
<a href="/search/cs?searchtype=author&query=Bailey%2C+J">James Bailey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICLR2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03735" title="Abstract">arXiv:2302.03735</a> (replaced) [<a href="/pdf/2302.03735" title="Download PDF">pdf</a>, <a href="/format/2302.03735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-train, Prompt and Recommendation: A Comprehensive Survey of Language  Modelling Paradigm Adaptations in Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Peng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lemei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gulla%2C+J+A">Jon Atle Gulla</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at Transactions of the Association for Computational Linguistics (TACL) in September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05185" title="Abstract">arXiv:2302.05185</a> (replaced) [<a href="/pdf/2302.05185" title="Download PDF">pdf</a>, <a href="/format/2302.05185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Penalty-based Bilevel Gradient Descent Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Han Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Q">Quan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianyi Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved Section 4 by removing a critical assumption; Added Section 5 and citations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09656" title="Abstract">arXiv:2302.09656</a> (replaced) [<a href="/pdf/2302.09656" title="Download PDF">pdf</a>, <a href="/format/2302.09656" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imprecise Bayesian Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Caprio%2C+M">Michele Caprio</a>, 
<a href="/search/cs?searchtype=author&query=Dutta%2C+S">Souradeep Dutta</a>, 
<a href="/search/cs?searchtype=author&query=Jang%2C+K+J">Kuk Jin Jang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+V">Vivian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Ivanov%2C+R">Radoslav Ivanov</a>, 
<a href="/search/cs?searchtype=author&query=Sokolsky%2C+O">Oleg Sokolsky</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+I">Insup Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11657" title="Abstract">arXiv:2302.11657</a> (replaced) [<a href="/pdf/2302.11657" title="Download PDF">pdf</a>, <a href="/ps/2302.11657" title="Download PostScript">ps</a>, <a href="/format/2302.11657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Broadcasting with Random Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Efthymiou%2C+C">Charilaos Efthymiou</a>, 
<a href="/search/cs?searchtype=author&query=Zampetakis%2C+K">Kostas Zampetakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Mathematical Physics (math-ph); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14735" title="Abstract">arXiv:2302.14735</a> (replaced) [<a href="/pdf/2302.14735" title="Download PDF">pdf</a>, <a href="/format/2302.14735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IMU-based Online Multi-lidar Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Das%2C+S">Sandipan Das</a>, 
<a href="/search/cs?searchtype=author&query=Boberg%2C+B">Bengt Boberg</a>, 
<a href="/search/cs?searchtype=author&query=Fallon%2C+M">Maurice Fallon</a>, 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+S">Saikat Chatterjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For associated video, see <a href="https://youtu.be/HJ0CBWTFOhs">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00028" title="Abstract">arXiv:2303.00028</a> (replaced) [<a href="/pdf/2303.00028" title="Download PDF">pdf</a>, <a href="/format/2303.00028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Sensor Placement from Regression with Sparse Gaussian  Processes in Continuous and Discrete Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jakkala%2C+K">Kalvik Jakkala</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+S">Srinivas Akella</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02064" title="Abstract">arXiv:2303.02064</a> (replaced) [<a href="/pdf/2303.02064" title="Download PDF">pdf</a>, <a href="/format/2303.02064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QAOA with $N\cdot p\geq 200$
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Shaydulin%2C+R">Ruslan Shaydulin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Experiments on H2 processor with $N\cdot p = 320$ added in v2
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04837" title="Abstract">arXiv:2303.04837</a> (replaced) [<a href="/pdf/2303.04837" title="Download PDF">pdf</a>, <a href="/format/2303.04837" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-Binary Gender Expression in Online Interactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dorn%2C+R">Rebecca Dorn</a>, 
<a href="/search/cs?searchtype=author&query=Mokhberian%2C+N">Negar Mokhberian</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Julie Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Abramson%2C+J">Jeremy Abramson</a>, 
<a href="/search/cs?searchtype=author&query=Morstatter%2C+F">Fred Morstatter</a>, 
<a href="/search/cs?searchtype=author&query=Lerman%2C+K">Kristina Lerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05471" title="Abstract">arXiv:2303.05471</a> (replaced) [<a href="/pdf/2303.05471" title="Download PDF">pdf</a>, <a href="/ps/2303.05471" title="Download PostScript">ps</a>, <a href="/format/2303.05471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring New Topologies for the Theory of Clones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bucciarelli%2C+A">Antonio Bucciarelli</a>, 
<a href="/search/cs?searchtype=author&query=Salibra%2C+A">Antonino Salibra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06315" title="Abstract">arXiv:2303.06315</a> (replaced) [<a href="/pdf/2303.06315" title="Download PDF">pdf</a>, <a href="/format/2303.06315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DETA: Denoised Task Adaptation for Few-Shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Ji Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Hengtao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jingkuan Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07137" title="Abstract">arXiv:2303.07137</a> (replaced) [<a href="/pdf/2303.07137" title="Download PDF">pdf</a>, <a href="/ps/2303.07137" title="Download PostScript">ps</a>, <a href="/format/2303.07137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence proof for the GenCol algorithm in the case of two-marginal  optimal transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Friesecke%2C+G">Gero Friesecke</a>, 
<a href="/search/math?searchtype=author&query=Penka%2C+M">Maximilian Penka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A section on the multi-marginal case was added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10008" title="Abstract">arXiv:2303.10008</a> (replaced) [<a href="/pdf/2303.10008" title="Download PDF">pdf</a>, <a href="/format/2303.10008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Configurable EBEN: Extreme Bandwidth Extension Network to enhance  body-conducted speech capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hauret%2C+J">Julien Hauret</a>, 
<a href="/search/eess?searchtype=author&query=Joubaud%2C+T">Thomas Joubaud</a>, 
<a href="/search/eess?searchtype=author&query=Zimpfer%2C+V">V&#xe9;ronique Zimpfer</a>, 
<a href="/search/eess?searchtype=author&query=Bavu%2C+%C3%89">&#xc9;ric Bavu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE/ACM Transactions on Audio, Speech and Language Processing on 14/08/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15651" title="Abstract">arXiv:2303.15651</a> (replaced) [<a href="/pdf/2303.15651" title="Download PDF">pdf</a>, <a href="/format/2303.15651" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4D Panoptic Segmentation as Invariant and Equivariant Field Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+M">Minghan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shizhong Han</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Borse%2C+S">Shubhankar Borse</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffari%2C+M">Maani Ghaffari</a>, 
<a href="/search/cs?searchtype=author&query=Porikli%2C+F">Fatih Porikli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages. Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.15666" title="Abstract">arXiv:2303.15666</a> (replaced) [<a href="/pdf/2303.15666" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perceptual Requirements for World-Locked Rendering in AR and VR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guan%2C+P">Phillip Guan</a>, 
<a href="/search/cs?searchtype=author&query=Penner%2C+E">Eric Penner</a>, 
<a href="/search/cs?searchtype=author&query=Hegland%2C+J">Joel Hegland</a>, 
<a href="/search/cs?searchtype=author&query=Letham%2C+B">Benjamin Letham</a>, 
<a href="/search/cs?searchtype=author&query=Lanman%2C+D">Douglas Lanman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16203" title="Abstract">arXiv:2303.16203</a> (replaced) [<a href="/pdf/2303.16203" title="Download PDF">pdf</a>, <a href="/format/2303.16203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Your Diffusion Model is Secretly a Zero-Shot Classifier
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+A+C">Alexander C. Li</a>, 
<a href="/search/cs?searchtype=author&query=Prabhudesai%2C+M">Mihir Prabhudesai</a>, 
<a href="/search/cs?searchtype=author&query=Duggal%2C+S">Shivam Duggal</a>, 
<a href="/search/cs?searchtype=author&query=Brown%2C+E">Ellis Brown</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In ICCV 2023. Website at <a href="https://diffusion-classifier.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16207" title="Abstract">arXiv:2303.16207</a> (replaced) [<a href="/pdf/2303.16207" title="Download PDF">pdf</a>, <a href="/format/2303.16207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Quality-Diversity Transformer: Generating Behavior-Conditioned  Trajectories with Decision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mac%C3%A9%2C+V">Valentin Mac&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Boige%2C+R">Rapha&#xeb;l Boige</a>, 
<a href="/search/cs?searchtype=author&query=Chalumeau%2C+F">Felix Chalumeau</a>, 
<a href="/search/cs?searchtype=author&query=Pierrot%2C+T">Thomas Pierrot</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Guillaume Richard</a>, 
<a href="/search/cs?searchtype=author&query=Perrin-Gilbert%2C+N">Nicolas Perrin-Gilbert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10+7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17086" title="Abstract">arXiv:2303.17086</a> (replaced) [<a href="/pdf/2303.17086" title="Download PDF">pdf</a>, <a href="/ps/2303.17086" title="Download PostScript">ps</a>, <a href="/format/2303.17086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularized Control Synthesis for Complex Signal Temporal Logic  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zengjie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.18013" title="Abstract">arXiv:2303.18013</a> (replaced) [<a href="/pdf/2303.18013" title="Download PDF">pdf</a>, <a href="/format/2303.18013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LaCViT: A Label-aware Contrastive Training Framework for Vision  Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zaiqiao Meng</a>, 
<a href="/search/cs?searchtype=author&query=Camarasa%2C+G+A">Gerardo Aragon Camarasa</a>, 
<a href="/search/cs?searchtype=author&query=McCreadie%2C+R">Richard McCreadie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00210" title="Abstract">arXiv:2304.00210</a> (replaced) [<a href="/pdf/2304.00210" title="Download PDF">pdf</a>, <a href="/format/2304.00210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Max-Plus Synchronization in Decentralized Trading Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Riess%2C+H">Hans Riess</a>, 
<a href="/search/cs?searchtype=author&query=Munger%2C+M">Michael Munger</a>, 
<a href="/search/cs?searchtype=author&query=Zavlanos%2C+M+M">Michael M. Zavlanos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Discrete Mathematics (cs.DM); Theoretical Economics (econ.TH); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00752" title="Abstract">arXiv:2304.00752</a> (replaced) [<a href="/pdf/2304.00752" title="Download PDF">pdf</a>, <a href="/format/2304.00752" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Optimal Control for Nonlinear Systems with Parametric  Uncertainties via System Level Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leeman%2C+A+P">Antoine P. Leeman</a>, 
<a href="/search/eess?searchtype=author&query=Sieber%2C+J">Jerome Sieber</a>, 
<a href="/search/eess?searchtype=author&query=Bennani%2C+S">Samir Bennani</a>, 
<a href="/search/eess?searchtype=author&query=Zeilinger%2C+M+N">Melanie N. Zeilinger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for CDC (Singapore, 13-15 December 2023). Code: <a href="https://gitlab.ethz.ch/ics/nonlinear-parametric-SLS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04602" title="Abstract">arXiv:2304.04602</a> (replaced) [<a href="/pdf/2304.04602" title="Download PDF">pdf</a>, <a href="/format/2304.04602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning a Universal Human Prior for Dexterous Manipulation from Human  Preference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zihan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuanpei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+A+Z">Allen Z. Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+S+S">Shixiang Shane Gu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+C">Chi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04690" title="Abstract">arXiv:2304.04690</a> (replaced) [<a href="/pdf/2304.04690" title="Download PDF">pdf</a>, <a href="/ps/2304.04690" title="Download PostScript">ps</a>, <a href="/format/2304.04690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digraph Colouring and Arc-Connectivity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aboulker%2C+P">Pierre Aboulker</a>, 
<a href="/search/math?searchtype=author&query=Aubian%2C+G">Guillaume Aubian</a>, 
<a href="/search/math?searchtype=author&query=Charbit%2C+P">Pierre Charbit</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06104" title="Abstract">arXiv:2304.06104</a> (replaced) [<a href="/pdf/2304.06104" title="Download PDF">pdf</a>, <a href="/ps/2304.06104" title="Download PostScript">ps</a>, <a href="/format/2304.06104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Primal-Dual Contextual Bayesian Optimization for Control System Online  Optimization with Time-Average Constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenjie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuning Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Svetozarevic%2C+B">Bratislav Svetozarevic</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06963" title="Abstract">arXiv:2304.06963</a> (replaced) [<a href="/pdf/2304.06963" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Delay Impact on Stubborn Mining Attack Severity in Imperfect Bitcoin  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haoran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaolin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%A1i%C4%87%2C+J">Jelena Mi&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%A1i%C4%87%2C+V+B">Vojislav B. Mi&#x161;i&#x107;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2302.00210">arXiv:2302.00210</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07336" title="Abstract">arXiv:2304.07336</a> (replaced) [<a href="/pdf/2304.07336" title="Download PDF">pdf</a>, <a href="/format/2304.07336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New options for explicit all Mach number schemes by suitable choice of  time integration methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kemm%2C+F">Friedemann Kemm</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08397" title="Abstract">arXiv:2304.08397</a> (replaced) [<a href="/pdf/2304.08397" title="Download PDF">pdf</a>, <a href="/ps/2304.08397" title="Download PostScript">ps</a>, <a href="/format/2304.08397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grassmannians of codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Cardinali%2C+I">I. Cardinali</a>, 
<a href="/search/math?searchtype=author&query=Giuzzi%2C+L">L. Giuzzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages/minor corrections/updated bibliography
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11075" title="Abstract">arXiv:2304.11075</a> (replaced) [<a href="/pdf/2304.11075" title="Download PDF">pdf</a>, <a href="/format/2304.11075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sicard%2C+C">Clement Sicard</a>, 
<a href="/search/cs?searchtype=author&query=Pyszkowski%2C+K">Kajetan Pyszkowski</a>, 
<a href="/search/cs?searchtype=author&query=Gillioz%2C+V">Victor Gillioz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, SwissText conference
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Swiss Text Analytics Conference, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11520" title="Abstract">arXiv:2304.11520</a> (replaced) [<a href="/pdf/2304.11520" title="Download PDF">pdf</a>, <a href="/format/2304.11520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Processing Natural Language on Embedded Devices: How Well Do Modern  Models Perform?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Souvika Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Babar%2C+M+F">Mohammad Fakhruddin Babar</a>, 
<a href="/search/cs?searchtype=author&query=Hassan%2C+M+M">Md Mahadi Hassan</a>, 
<a href="/search/cs?searchtype=author&query=Hasan%2C+M">Monowar Hasan</a>, 
<a href="/search/cs?searchtype=author&query=Santu%2C+S+K+K">Shubhra Kanti Karmaker Santu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.01303" title="Abstract">arXiv:2305.01303</a> (replaced) [<a href="/pdf/2305.01303" title="Download PDF">pdf</a>, <a href="/format/2305.01303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HuNavSim: A ROS 2 Human Navigation Simulator for Benchmarking  Human-Aware Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez-Higueras%2C+N">No&#xe9; P&#xe9;rez-Higueras</a>, 
<a href="/search/cs?searchtype=author&query=Otero%2C+R">Roberto Otero</a>, 
<a href="/search/cs?searchtype=author&query=Caballero%2C+F">Fernando Caballero</a>, 
<a href="/search/cs?searchtype=author&query=Merino%2C+L">Luis Merino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version of the paper accepted in the RA-L Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06121" title="Abstract">arXiv:2305.06121</a> (replaced) [<a href="/pdf/2305.06121" title="Download PDF">pdf</a>, <a href="/format/2305.06121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transformer-based model for monocular visual odometry: a video  understanding approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fran%C3%A7ani%2C+A+O">Andr&#xe9; O. Fran&#xe7;ani</a>, 
<a href="/search/cs?searchtype=author&query=Maximo%2C+M+R+O+A">Marcos R. O. A. Maximo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06695" title="Abstract">arXiv:2305.06695</a> (replaced) [<a href="/pdf/2305.06695" title="Download PDF">pdf</a>, <a href="/format/2305.06695" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Visual-Genetic Biometrics for Taxonomic Classification of Rare  Species
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karaderi%2C+T">Tayfun Karaderi</a>, 
<a href="/search/cs?searchtype=author&query=Burghardt%2C+T">Tilo Burghardt</a>, 
<a href="/search/cs?searchtype=author&query=Morard%2C+R">Raphael Morard</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D">Daniela Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06908" title="Abstract">arXiv:2305.06908</a> (replaced) [<a href="/pdf/2305.06908" title="Download PDF">pdf</a>, <a href="/format/2305.06908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency  Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhen Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+W">Wei Xue</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qifeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yike Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM MM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.07748" title="Abstract">arXiv:2305.07748</a> (replaced) [<a href="/pdf/2305.07748" title="Download PDF">pdf</a>, <a href="/format/2305.07748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reactive Landing Controller for Quadruped Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roscia%2C+F">Francesco Roscia</a>, 
<a href="/search/cs?searchtype=author&query=Focchi%2C+M">Michele Focchi</a>, 
<a href="/search/cs?searchtype=author&query=Del+Prete%2C+A">Andrea Del Prete</a>, 
<a href="/search/cs?searchtype=author&query=Caldwell%2C+D+G">Darwin G. Caldwell</a>, 
<a href="/search/cs?searchtype=author&query=Semini%2C+C">Claudio Semini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables, submitted to ral, accompanying video at <a href="https://youtu.be/KnmNbhkOKWI">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09105" title="Abstract">arXiv:2305.09105</a> (replaced) [<a href="/pdf/2305.09105" title="Download PDF">pdf</a>, <a href="/format/2305.09105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing pre-scheduled, intermittently-observed MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+P">Patrick Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Federico Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Shell%2C+D+A">Dylan A. Shell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12143" title="Abstract">arXiv:2305.12143</a> (replaced) [<a href="/pdf/2305.12143" title="Download PDF">pdf</a>, <a href="/format/2305.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Horn Envelopes via Queries from Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blum%2C+S">Sophie Blum</a>, 
<a href="/search/cs?searchtype=author&query=Koudijs%2C+R">Raoul Koudijs</a>, 
<a href="/search/cs?searchtype=author&query=Ozaki%2C+A">Ana Ozaki</a>, 
<a href="/search/cs?searchtype=author&query=Touileb%2C+S">Samia Touileb</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 2 figures; manuscript accepted for publication in the International Journal of Approximate Reasoning (IJAR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13239" title="Abstract">arXiv:2305.13239</a> (replaced) [<a href="/pdf/2305.13239" title="Download PDF">pdf</a>, <a href="/ps/2305.13239" title="Download PostScript">ps</a>, <a href="/format/2305.13239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling from the random cluster model on random regular graphs at all  temperatures via Glauber dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Galanis%2C+A">Andreas Galanis</a>, 
<a href="/search/math?searchtype=author&query=Goldberg%2C+L+A">Leslie Ann Goldberg</a>, 
<a href="/search/math?searchtype=author&query=Smolarova%2C+P">Paulina Smolarova</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14020" title="Abstract">arXiv:2305.14020</a> (replaced) [<a href="/pdf/2305.14020" title="Download PDF">pdf</a>, <a href="/format/2305.14020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does ChatGPT have Theory of Mind?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holterman%2C+B">Bart Holterman</a>, 
<a href="/search/cs?searchtype=author&query=van+Deemter%2C+K">Kees van Deemter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15661" title="Abstract">arXiv:2305.15661</a> (replaced) [<a href="/pdf/2305.15661" title="Download PDF">pdf</a>, <a href="/format/2305.15661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerated solutions of convection-dominated partial differential  equations using implicit feature tracking and empirical quadrature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mirhoseini%2C+M+A">Marzieh Alireza Mirhoseini</a>, 
<a href="/search/math?searchtype=author&query=Zahr%2C+M+J">Matthew J. Zahr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15701" title="Abstract">arXiv:2305.15701</a> (replaced) [<a href="/pdf/2305.15701" title="Download PDF">pdf</a>, <a href="/format/2305.15701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Sensitivity Learning for Temporal Action Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiayi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+R">Ruijie Quan</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+J">Junjun Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18248" title="Abstract">arXiv:2305.18248</a> (replaced) [<a href="/pdf/2305.18248" title="Download PDF">pdf</a>, <a href="/format/2305.18248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Language Models Know When They&#x27;re Hallucinating References?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+A">Ayush Agrawal</a>, 
<a href="/search/cs?searchtype=author&query=Suzgun%2C+M">Mirac Suzgun</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+L">Lester Mackey</a>, 
<a href="/search/cs?searchtype=author&query=Kalai%2C+A+T">Adam Tauman Kalai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18691" title="Abstract">arXiv:2305.18691</a> (replaced) [<a href="/pdf/2305.18691" title="Download PDF">pdf</a>, <a href="/format/2305.18691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-MoE: Memory-Efficient Multi-Task Vision Transformer Architecture  with Task-level Sparsity via Mixture-of-Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+R">Rishov Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Hanxue Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhiwen Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+C">Cong Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 12 figures. Accepted at ICCAD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18823" title="Abstract">arXiv:2305.18823</a> (replaced) [<a href="/pdf/2305.18823" title="Download PDF">pdf</a>, <a href="/format/2305.18823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker anonymization using orthogonal Householder neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xiaoxiao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+E">Erica Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Yamagishi%2C+J">Junichi Yamagishi</a>, 
<a href="/search/cs?searchtype=author&query=Tomashenko%2C+N">Natalia Tomashenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/ACM Transactions on Audio, Speech, and Language Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19028" title="Abstract">arXiv:2305.19028</a> (replaced) [<a href="/pdf/2305.19028" title="Download PDF">pdf</a>, <a href="/ps/2305.19028" title="Download PostScript">ps</a>, <a href="/format/2305.19028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed Precision Rayleigh Quotient Iteration for Total Least Squares  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Oktay%2C+E">Eda Oktay</a>, 
<a href="/search/math?searchtype=author&query=Carson%2C+E">Erin Carson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01111" title="Abstract">arXiv:2306.01111</a> (replaced) [<a href="/pdf/2306.01111" title="Download PDF">pdf</a>, <a href="/format/2306.01111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Versatility of Zero-Shot CLIP for Interstitial Lung  Disease Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Uden%2C+C">Cara Van Uden</a>, 
<a href="/search/cs?searchtype=author&query=Bluethgen%2C+C">Christian Bluethgen</a>, 
<a href="/search/cs?searchtype=author&query=Attias%2C+M">Maayane Attias</a>, 
<a href="/search/cs?searchtype=author&query=Polacin%2C+M">Malgorzata Polacin</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+H+H">Haiwei Henry Guo</a>, 
<a href="/search/cs?searchtype=author&query=Simha%2C+N">Neha Simha</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+R">Rishi Raj</a>, 
<a href="/search/cs?searchtype=author&query=Langlotz%2C+C">Curtis Langlotz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01188" title="Abstract">arXiv:2306.01188</a> (replaced) [<a href="/pdf/2306.01188" title="Download PDF">pdf</a>, <a href="/format/2306.01188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Event-based Stereo Visual Odometry with Native Temporal Resolution via  Continuous-time Gaussian Process Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gammell%2C+J+D">Jonathan D. Gammell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures. DOI: 10.1109/LRA.2023.3311374
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Robotics and Automation Letters (RA-L), vol. 8, no. 10, pp.
  6707-6714, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01198" title="Abstract">arXiv:2306.01198</a> (replaced) [<a href="/pdf/2306.01198" title="Download PDF">pdf</a>, <a href="/format/2306.01198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Confidence Intervals for Error Rates in 1:1 Matching Tasks: Critical  Statistical Analysis and Recommendations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fogliato%2C+R">Riccardo Fogliato</a>, 
<a href="/search/stat?searchtype=author&query=Patil%2C+P">Pratik Patil</a>, 
<a href="/search/stat?searchtype=author&query=Perona%2C+P">Pietro Perona</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02278" title="Abstract">arXiv:2306.02278</a> (replaced) [<a href="/pdf/2306.02278" title="Download PDF">pdf</a>, <a href="/format/2306.02278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Payoff Mechanism Design for Coordination in Multi-Agent Task Allocation  Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+S">Shinkyu Park</a>, 
<a href="/search/eess?searchtype=author&query=Barreiro-Gomez%2C+J">Julian Barreiro-Gomez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.03218" title="Abstract">arXiv:2306.03218</a> (replaced) [<a href="/pdf/2306.03218" title="Download PDF">pdf</a>, <a href="/format/2306.03218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal transport for automatic alignment of untargeted metabolomic data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Breeur%2C+M">Marie Breeur</a>, 
<a href="/search/q-bio?searchtype=author&query=Stepaniants%2C+G">George Stepaniants</a>, 
<a href="/search/q-bio?searchtype=author&query=Keski-Rahkonen%2C+P">Pekka Keski-Rahkonen</a>, 
<a href="/search/q-bio?searchtype=author&query=Rigollet%2C+P">Philippe Rigollet</a>, 
<a href="/search/q-bio?searchtype=author&query=Viallon%2C+V">Vivian Viallon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05138" title="Abstract">arXiv:2306.05138</a> (replaced) [<a href="/pdf/2306.05138" title="Download PDF">pdf</a>, <a href="/format/2306.05138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient-Informed Quality Diversity for the Illumination of Discrete  Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boige%2C+R">Raphael Boige</a>, 
<a href="/search/cs?searchtype=author&query=Richard%2C+G">Guillaume Richard</a>, 
<a href="/search/cs?searchtype=author&query=Dona%2C+J">J&#xe9;r&#xe9;mie Dona</a>, 
<a href="/search/cs?searchtype=author&query=Pierrot%2C+T">Thomas Pierrot</a>, 
<a href="/search/cs?searchtype=author&query=Cully%2C+A">Antoine Cully</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> GECCO 2023 Proceedings of the Genetic and Evolutionary Computation
  Conference; Pages 119-128
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06235" title="Abstract">arXiv:2306.06235</a> (replaced) [<a href="/pdf/2306.06235" title="Download PDF">pdf</a>, <a href="/ps/2306.06235" title="Download PostScript">ps</a>, <a href="/format/2306.06235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving the Steiner Point Removal Problem in Planar Graphs via  Shortcut Partitions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+H">Hsien-Chih Chang</a>, 
<a href="/search/cs?searchtype=author&query=Conroy%2C+J">Jonathan Conroy</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hung Le</a>, 
<a href="/search/cs?searchtype=author&query=Milenkovic%2C+L">Lazar Milenkovic</a>, 
<a href="/search/cs?searchtype=author&query=Solomon%2C+S">Shay Solomon</a>, 
<a href="/search/cs?searchtype=author&query=Than%2C+C">Cuong Than</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript not intended for publication. The results have been subsumed by <a href="/abs/2308.00555">arXiv:2308.00555</a> from the same authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06383" title="Abstract">arXiv:2306.06383</a> (replaced) [<a href="/pdf/2306.06383" title="Download PDF">pdf</a>, <a href="/ps/2306.06383" title="Download PostScript">ps</a>, <a href="/format/2306.06383" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using orthogonally structured positive bases for constructing positive  $k$-spanning sets with cosine measure guarantees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hare%2C+W">Warren Hare</a>, 
<a href="/search/math?searchtype=author&query=Jarry-Bolduc%2C+G">Gabriel Jarry-Bolduc</a>, 
<a href="/search/math?searchtype=author&query=Kerleau%2C+S">S&#xe9;bastien Kerleau</a>, 
<a href="/search/math?searchtype=author&query=Royer%2C+C+W">Cl&#xe9;ment W. Royer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09704" title="Abstract">arXiv:2306.09704</a> (replaced) [<a href="/pdf/2306.09704" title="Download PDF">pdf</a>, <a href="/format/2306.09704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-corpus Readability Compatibility Assessment for English Texts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhenzhen Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Han Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shaohong Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages,17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10313" title="Abstract">arXiv:2306.10313</a> (replaced) [<a href="/pdf/2306.10313" title="Download PDF">pdf</a>, <a href="/format/2306.10313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversaries with Limited Information in the Friedkin--Johnsen Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tu%2C+S">Sijing Tu</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+S">Stefan Neumann</a>, 
<a href="/search/cs?searchtype=author&query=Gionis%2C+A">Aristides Gionis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12741" title="Abstract">arXiv:2306.12741</a> (replaced) [<a href="/pdf/2306.12741" title="Download PDF">pdf</a>, <a href="/format/2306.12741" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Solutions for Multidimensional Approximate Agreement via  Centroid Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cambus%2C+M">Melanie Cambus</a>, 
<a href="/search/cs?searchtype=author&query=Melnyk%2C+D">Darya Melnyk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13933" title="Abstract">arXiv:2306.13933</a> (replaced) [<a href="/pdf/2306.13933" title="Download PDF">pdf</a>, <a href="/format/2306.13933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boost Video Frame Interpolation via Motion Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoyun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+W">Weidi Xie</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ya Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BMVC 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15142" title="Abstract">arXiv:2306.15142</a> (replaced) [<a href="/e-print/2306.15142" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LRANet: Towards Accurate and Efficient Scene Text Detection with  Low-Rank Approximation Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuchen Su</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhineng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhiwen Shao</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuning Du</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Z">Zhilong Ji</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jinfeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yu-Gang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> There were some errors in the experimental results of the first version, such as inaccurate measurement of FPS and low F-meansure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16846" title="Abstract">arXiv:2306.16846</a> (replaced) [<a href="/pdf/2306.16846" title="Download PDF">pdf</a>, <a href="/format/2306.16846" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Degree-Controllable Lightweight Fast Style Transfer with Detail  Attention-enhanced
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+J+S">Jiang Shi Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17100" title="Abstract">arXiv:2306.17100</a> (replaced) [<a href="/pdf/2306.17100" title="Download PDF">pdf</a>, <a href="/format/2306.17100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RL4CO: an Extensive Reinforcement Learning for Combinatorial  Optimization Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berto%2C+F">Federico Berto</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+C">Chuanbo Hua</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Junyoung Park</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyeonah Kim</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+J">Jiwoo Son</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Haeyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Joungho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jinkyoo Park</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Added several improvements to the writing; add search methods; new results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.02799" title="Abstract">arXiv:2307.02799</a> (replaced) [<a href="/pdf/2307.02799" title="Download PDF">pdf</a>, <a href="/format/2307.02799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Few-shot Personalized Saliency Prediction Based on Inter-personnel Gaze  Patterns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moroto%2C+Y">Yuya Moroto</a>, 
<a href="/search/eess?searchtype=author&query=Maeda%2C+K">Keisuke Maeda</a>, 
<a href="/search/eess?searchtype=author&query=Ogawa%2C+T">Takahiro Ogawa</a>, 
<a href="/search/eess?searchtype=author&query=Haseyama%2C+M">Miki Haseyama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04375" title="Abstract">arXiv:2307.04375</a> (replaced) [<a href="/pdf/2307.04375" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Runtime Customizable Trusted Execution Environment on FPGA-SoC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanling Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaolin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haoran Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Yanwei Gong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06266" title="Abstract">arXiv:2307.06266</a> (replaced) [<a href="/pdf/2307.06266" title="Download PDF">pdf</a>, <a href="/format/2307.06266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a privacy-preserving distributed cloud service for preprocessing  very large medical images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuandou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kanwal%2C+N">Neel Kanwal</a>, 
<a href="/search/cs?searchtype=author&query=Engan%2C+K">Kjersti Engan</a>, 
<a href="/search/cs?searchtype=author&query=Rong%2C+C">Chunming Rong</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhiming Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE ICDH 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06435" title="Abstract">arXiv:2307.06435</a> (replaced) [<a href="/pdf/2307.06435" title="Download PDF">pdf</a>, <a href="/format/2307.06435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Overview of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Naveed%2C+H">Humza Naveed</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A+U">Asad Ullah Khan</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+S">Shi Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Saqib%2C+M">Muhammad Saqib</a>, 
<a href="/search/cs?searchtype=author&query=Anwar%2C+S">Saeed Anwar</a>, 
<a href="/search/cs?searchtype=author&query=Usman%2C+M">Muhammad Usman</a>, 
<a href="/search/cs?searchtype=author&query=Akhtar%2C+N">Naveed Akhtar</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>, 
<a href="/search/cs?searchtype=author&query=Mian%2C+A">Ajmal Mian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in-progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06571" title="Abstract">arXiv:2307.06571</a> (replaced) [<a href="/pdf/2307.06571" title="Download PDF">pdf</a>, <a href="/format/2307.06571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unpacking polarization: Antagonism and Alignment in Signed Networks of  Online Interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fraxanet%2C+E">Emma Fraxanet</a>, 
<a href="/search/cs?searchtype=author&query=Pellert%2C+M">Max Pellert</a>, 
<a href="/search/cs?searchtype=author&query=Schweighofer%2C+S">Simon Schweighofer</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+V">Vicen&#xe7; G&#xf3;mez</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+D">David Garcia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07131" title="Abstract">arXiv:2307.07131</a> (replaced) [<a href="/pdf/2307.07131" title="Download PDF">pdf</a>, <a href="/ps/2307.07131" title="Download PostScript">ps</a>, <a href="/format/2307.07131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelising Glauber dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Holden Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09225" title="Abstract">arXiv:2307.09225</a> (replaced) [<a href="/pdf/2307.09225" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Body Digital Twin: A Master Plan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chenyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+W">Wentian Yi</a>, 
<a href="/search/cs?searchtype=author&query=Occhipinti%2C+E">Edoardo Occhipinti</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yanning Dai</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shuo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Occhipinti%2C+L+G">Luigi G. Occhipinti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures, 2 boxes
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10475" title="Abstract">arXiv:2307.10475</a> (replaced) [<a href="/pdf/2307.10475" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Findings of Factify 2: Multimodal Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suryavardan%2C+S">S Suryavardan</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+S">Shreyash Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+M">Megha Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Patwa%2C+P">Parth Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Rani%2C+A">Anku Rani</a>, 
<a href="/search/cs?searchtype=author&query=Chadha%2C+A">Aman Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Reganti%2C+A">Aishwarya Reganti</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+A">Amitava Das</a>, 
<a href="/search/cs?searchtype=author&query=Sheth%2C+A">Amit Sheth</a>, 
<a href="/search/cs?searchtype=author&query=Chinnakotla%2C+M">Manoj Chinnakotla</a>, 
<a href="/search/cs?searchtype=author&query=Ekbal%2C+A">Asif Ekbal</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+S">Srijan Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Defactify2 @AAAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10674" title="Abstract">arXiv:2307.10674</a> (replaced) [<a href="/pdf/2307.10674" title="Download PDF">pdf</a>, <a href="/format/2307.10674" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network  Visualisations in Virtual Reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feyer%2C+S+P">Stefan P. Feyer</a>, 
<a href="/search/cs?searchtype=author&query=Pinaud%2C+B">Bruno Pinaud</a> (LaBRI, UB), 
<a href="/search/cs?searchtype=author&query=Kobourov%2C+S+G">Stephen G. Kobourov</a>, 
<a href="/search/cs?searchtype=author&query=Brich%2C+N">Nicolas Brich</a>, 
<a href="/search/cs?searchtype=author&query=Krone%2C+M">Michael Krone</a> (NYU), 
<a href="/search/cs?searchtype=author&query=Kerren%2C+A">Andreas Kerren</a> (LIU), 
<a href="/search/cs?searchtype=author&query=Behrisch%2C+M">Michael Behrisch</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+F">Falk Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Karsten Klein</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Visualization and Computer Graphics, In
  press, To appear. Accepted to IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11137" title="Abstract">arXiv:2307.11137</a> (replaced) [<a href="/pdf/2307.11137" title="Download PDF">pdf</a>, <a href="/format/2307.11137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Of Models and Tin Men: A Behavioural Economics Study of Principal-Agent  Problems in AI Alignment using Large-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phelps%2C+S">Steve Phelps</a>, 
<a href="/search/cs?searchtype=author&query=Ranson%2C+R">Rebecca Ranson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures. For code see <a href="https://github.com/phelps-sg/llm-cooperation">this https URL</a> Updated with minor corrections: - corrected typo: "mesa-optimiser" instead of "meso-optimiser" - Cited Yang et al (2023) in support of claim that LLMs can solve optimisation problems - Acknowledged Seth Aslin for corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; General Economics (econ.GN)

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11336" title="Abstract">arXiv:2307.11336</a> (replaced) [<a href="/pdf/2307.11336" title="Download PDF">pdf</a>, <a href="/format/2307.11336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Character Time-series Matching For Robust License Plate Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Che%2C+Q+H">Quang Huy Che</a>, 
<a href="/search/cs?searchtype=author&query=Thanh%2C+T+D">Tung Do Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Van%2C+C+T">Cuong Truong Van</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2022 International Conference on Multimedia Analysis and Pattern
  Recognition (MAPR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12510" title="Abstract">arXiv:2307.12510</a> (replaced) [<a href="/pdf/2307.12510" title="Download PDF">pdf</a>, <a href="/ps/2307.12510" title="Download PostScript">ps</a>, <a href="/format/2307.12510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Temporal Graph Benchmark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in progress, more results are added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14336" title="Abstract">arXiv:2307.14336</a> (replaced) [<a href="/pdf/2307.14336" title="Download PDF">pdf</a>, <a href="/format/2307.14336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAMo: Leveraging Memory and Attention for Monocular Video Depth  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yasarla%2C+R">Rajeev Yasarla</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+H">Hong Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jeong%2C+J">Jisoo Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yunxiao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Garrepalli%2C+R">Risheek Garrepalli</a>, 
<a href="/search/cs?searchtype=author&query=Porikli%2C+F">Fatih Porikli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14735" title="Abstract">arXiv:2307.14735</a> (replaced) [<a href="/pdf/2307.14735" title="Download PDF">pdf</a>, <a href="/format/2307.14735" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test Time Adaptation for Blind Image Quality Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Subhadeep Roy</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Shankhanil Mitra</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+S">Soma Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Soundararajan%2C+R">Rajiv Soundararajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00296" title="Abstract">arXiv:2308.00296</a> (replaced) [<a href="/pdf/2308.00296" title="Download PDF">pdf</a>, <a href="/format/2308.00296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical asymptotic stability of data-driven model predictive control  using extended DMD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bold%2C+L">Lea Bold</a>, 
<a href="/search/math?searchtype=author&query=Gr%C3%BCne%2C+L">Lars Gr&#xfc;ne</a>, 
<a href="/search/math?searchtype=author&query=Schaller%2C+M">Manuel Schaller</a>, 
<a href="/search/math?searchtype=author&query=Worthmann%2C+K">Karl Worthmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00507" title="Abstract">arXiv:2308.00507</a> (replaced) [<a href="/pdf/2308.00507" title="Download PDF">pdf</a>, <a href="/format/2308.00507" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Prognostic Prediction of Pancreatic Cancer Using Multi-Phase CT  by Integrating Neural Distance and Texture-Aware Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Dong%2C+H">Hexin Dong</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+J">Jiawen Yao</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+Y">Yuxing Tang</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+M">Mingze Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+Y">Yingda Xia</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jian Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Hong Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Dong%2C+B">Bin Dong</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+L">Le Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Li Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Z">Zaiyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yu Shi</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Ling Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.00802" title="Abstract">arXiv:2308.00802</a> (replaced) [<a href="/pdf/2308.00802" title="Download PDF">pdf</a>, <a href="/format/2308.00802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GRDD: A Dataset for Greek Dialectal NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatzikyriakidis%2C+S">Stergios Chatzikyriakidis</a>, 
<a href="/search/cs?searchtype=author&query=Qwaider%2C+C">Chatrine Qwaider</a>, 
<a href="/search/cs?searchtype=author&query=Kolokousis%2C+I">Ilias Kolokousis</a>, 
<a href="/search/cs?searchtype=author&query=Koula%2C+C">Christina Koula</a>, 
<a href="/search/cs?searchtype=author&query=Papadakis%2C+D">Dimitris Papadakis</a>, 
<a href="/search/cs?searchtype=author&query=Sakellariou%2C+E">Efthymia Sakellariou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01825" title="Abstract">arXiv:2308.01825</a> (replaced) [<a href="/pdf/2308.01825" title="Download PDF">pdf</a>, <a href="/format/2308.01825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Relationship on Learning Mathematical Reasoning with Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Hongyi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+G">Guanting Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+K">Keming Lu</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Chuanqi Tan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+C">Chang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jingren Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working in Progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03266" title="Abstract">arXiv:2308.03266</a> (replaced) [<a href="/pdf/2308.03266" title="Download PDF">pdf</a>, <a href="/format/2308.03266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and  Effective Hotword Customization Ability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+X">Xian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yexin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zerui Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yanni Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhifu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04025" title="Abstract">arXiv:2308.04025</a> (replaced) [<a href="/pdf/2308.04025" title="Download PDF">pdf</a>, <a href="/format/2308.04025" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MSAC: Multiple Speech Attribute Control Method for Reliable Speech  Emotion Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuguang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuheng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Jingjing Yin</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yanni Hu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Heng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianjun Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04407" title="Abstract">arXiv:2308.04407</a> (replaced) [<a href="/pdf/2308.04407" title="Download PDF">pdf</a>, <a href="/format/2308.04407" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chrisimos: A useful Proof-of-Work for finding Minimal Dominating Set of  a graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chatterjee%2C+D">Diptendu Chatterjee</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+P">Prabal Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Mazumdar%2C+S">Subhra Mazumdar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 3 figures. An abridged version of the paper got accepted in The International Symposium on Intelligent and Trustworthy Computing, Communications, and Networking (ITCCN-2023) held in conjunction with the 22nd IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom-2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05076" title="Abstract">arXiv:2308.05076</a> (replaced) [<a href="/pdf/2308.05076" title="Download PDF">pdf</a>, <a href="/format/2308.05076" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHERI Performance Enhancement for a Bytecode Interpreter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lowther%2C+D">Duncan Lowther</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+D">Dejice Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+J">Jeremy Singer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05693" title="Abstract">arXiv:2308.05693</a> (replaced) [<a href="/pdf/2308.05693" title="Download PDF">pdf</a>, <a href="/format/2308.05693" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limitations of Game Comonads via Homomorphism Indistinguishability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lichter%2C+M">Moritz Lichter</a>, 
<a href="/search/cs?searchtype=author&query=Pago%2C+B">Benedikt Pago</a>, 
<a href="/search/cs?searchtype=author&query=Seppelt%2C+T">Tim Seppelt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Minor corrections in Section 6
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06851" title="Abstract">arXiv:2308.06851</a> (replaced) [<a href="/pdf/2308.06851" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Offensive Gameplan in the National Basketball Association  with Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+E">Eamon Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures. Revision: Corrected text and citation formatting issues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07347" title="Abstract">arXiv:2308.07347</a> (replaced) [<a href="/e-print/2308.07347" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman  Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+S">Swetha Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Whitley%2C+D">Darrell Whitley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Plan not to publish the article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08096" title="Abstract">arXiv:2308.08096</a> (replaced) [<a href="/pdf/2308.08096" title="Download PDF">pdf</a>, <a href="/format/2308.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenges with Passwordless FIDO2 in an Enterprise Setting: A Usability  Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kepkowski%2C+M">Michal Kepkowski</a>, 
<a href="/search/cs?searchtype=author&query=Machulak%2C+M">Maciej Machulak</a>, 
<a href="/search/cs?searchtype=author&query=Wood%2C+I">Ian Wood</a>, 
<a href="/search/cs?searchtype=author&query=Kaafar%2C+D">Dali Kaafar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published in the IEEE Secure Development Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08347" title="Abstract">arXiv:2308.08347</a> (replaced) [<a href="/pdf/2308.08347" title="Download PDF">pdf</a>, <a href="/ps/2308.08347" title="Download PostScript">ps</a>, <a href="/format/2308.08347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continuing WebAssembly with Effect Handlers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phipps-Costin%2C+L">Luna Phipps-Costin</a>, 
<a href="/search/cs?searchtype=author&query=Rossberg%2C+A">Andreas Rossberg</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Arjun Guha</a>, 
<a href="/search/cs?searchtype=author&query=Leijen%2C+D">Daan Leijen</a>, 
<a href="/search/cs?searchtype=author&query=Hillerstr%C3%B6m%2C+D">Daniel Hillerstr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Sivaramakrishnan%2C+K">KC Sivaramakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Pretnar%2C+M">Matija Pretnar</a>, 
<a href="/search/cs?searchtype=author&query=Lindley%2C+S">Sam Lindley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09285" title="Abstract">arXiv:2308.09285</a> (replaced) [<a href="/pdf/2308.09285" title="Download PDF">pdf</a>, <a href="/format/2308.09285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RFDforFin: Robust Deep Forgery Detection for GAN-generated Fingerprint  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miao%2C+H">Hui Miao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuanfang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09392" title="Abstract">arXiv:2308.09392</a> (replaced) [<a href="/pdf/2308.09392" title="Download PDF">pdf</a>, <a href="/format/2308.09392" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attacking logo-based phishing website detectors with adversarial  perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jehyun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+Z">Zhe Xin</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+M+N+P">Melanie Ng Pei See</a>, 
<a href="/search/cs?searchtype=author&query=Sabharwal%2C+K">Kanav Sabharwal</a>, 
<a href="/search/cs?searchtype=author&query=Apruzzese%2C+G">Giovanni Apruzzese</a>, 
<a href="/search/cs?searchtype=author&query=Divakaran%2C+D+M">Dinil Mon Divakaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ESORICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09435" title="Abstract">arXiv:2308.09435</a> (replaced) [<a href="/pdf/2308.09435" title="Download PDF">pdf</a>, <a href="/format/2308.09435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Methodology for Generative Spelling Correction via Natural Spelling  Errors Emulation across Multiple Domains and Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martynov%2C+N">Nikita Martynov</a>, 
<a href="/search/cs?searchtype=author&query=Baushenko%2C+M">Mark Baushenko</a>, 
<a href="/search/cs?searchtype=author&query=Kozlova%2C+A">Anastasia Kozlova</a>, 
<a href="/search/cs?searchtype=author&query=Kolomeytseva%2C+K">Katerina Kolomeytseva</a>, 
<a href="/search/cs?searchtype=author&query=Abramov%2C+A">Aleksandr Abramov</a>, 
<a href="/search/cs?searchtype=author&query=Fenogenova%2C+A">Alena Fenogenova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear in EACL 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10301" title="Abstract">arXiv:2308.10301</a> (replaced) [<a href="/pdf/2308.10301" title="Download PDF">pdf</a>, <a href="/format/2308.10301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Integer Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Q">Qizheng He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> include the code and add more experiments
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Number Theory (math.NT)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11909" title="Abstract">arXiv:2308.11909</a> (replaced) [<a href="/pdf/2308.11909" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge-aware Hard Clustering Graph Pooling for Brain Imaging Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Cheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiayi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lijuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuqi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P">Ping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Honghan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13442" title="Abstract">arXiv:2308.13442</a> (replaced) [<a href="/pdf/2308.13442" title="Download PDF">pdf</a>, <a href="/format/2308.13442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unlocking Fine-Grained Details with Wavelet-based High-Frequency  Enhancement in Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Azad%2C+R">Reza Azad</a>, 
<a href="/search/cs?searchtype=author&query=Kazerouni%2C+A">Amirhossein Kazerouni</a>, 
<a href="/search/cs?searchtype=author&query=Sulaiman%2C+A">Alaa Sulaiman</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgpour%2C+A">Afshin Bozorgpour</a>, 
<a href="/search/cs?searchtype=author&query=Aghdam%2C+E+K">Ehsan Khodapanah Aghdam</a>, 
<a href="/search/cs?searchtype=author&query=Jose%2C+A">Abin Jose</a>, 
<a href="/search/cs?searchtype=author&query=Merhof%2C+D">Dorit Merhof</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in MICCAI 2023 workshop MLMI
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> MICCAI 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13561" title="Abstract">arXiv:2308.13561</a> (replaced) [<a href="/pdf/2308.13561" title="Download PDF">pdf</a>, <a href="/format/2308.13561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Project Aria: A New Tool for Egocentric Multi-Modal AI Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Somasundaram%2C+K">Kiran Somasundaram</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Jing Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Huixuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Straub%2C+J">Julian Straub</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+M">Mingfei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Goesele%2C+M">Michael Goesele</a>, 
<a href="/search/cs?searchtype=author&query=Engel%2C+J+J">Jakob Julian Engel</a>, 
<a href="/search/cs?searchtype=author&query=De+Nardi%2C+R">Renzo De Nardi</a>, 
<a href="/search/cs?searchtype=author&query=Newcombe%2C+R">Richard Newcombe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14131" title="Abstract">arXiv:2308.14131</a> (replaced) [<a href="/pdf/2308.14131" title="Download PDF">pdf</a>, <a href="/ps/2308.14131" title="Download PostScript">ps</a>, <a href="/format/2308.14131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Approximation Algorithms for Multidepot Capacitated Vehicle  Routing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jingyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14279" title="Abstract">arXiv:2308.14279</a> (replaced) [<a href="/pdf/2308.14279" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling unknown large networks restricted by low sampling rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiao%2C+B">Bo Jiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages,14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14926" title="Abstract">arXiv:2308.14926</a> (replaced) [<a href="/pdf/2308.14926" title="Download PDF">pdf</a>, <a href="/format/2308.14926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monus semantics in vector addition systems with states
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baumann%2C+P">Pascal Baumann</a>, 
<a href="/search/cs?searchtype=author&query=Madnani%2C+K">Khushraj Madnani</a>, 
<a href="/search/cs?searchtype=author&query=Mazowiecki%2C+F">Filip Mazowiecki</a>, 
<a href="/search/cs?searchtype=author&query=Zetzsche%2C+G">Georg Zetzsche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Formal Languages and Automata Theory (cs.FL)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15321" title="Abstract">arXiv:2308.15321</a> (replaced) [<a href="/pdf/2308.15321" title="Download PDF">pdf</a>, <a href="/format/2308.15321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Elucidating the Exposure Bias in Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ning%2C+M">Mang Ning</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingxiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+J">Jianlin Su</a>, 
<a href="/search/cs?searchtype=author&query=Salah%2C+A+A">Albert Ali Salah</a>, 
<a href="/search/cs?searchtype=author&query=Ertugrul%2C+I+O">Itir Onal Ertugrul</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15366" title="Abstract">arXiv:2308.15366</a> (replaced) [<a href="/pdf/2308.15366" title="Download PDF">pdf</a>, <a href="/format/2308.15366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnomalyGPT: Detecting Industrial Anomalies using Large Vision-Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaopeng Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bingke Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+G">Guibo Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yingying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+M">Ming Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinqiao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://anomalygpt.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16547" title="Abstract">arXiv:2308.16547</a> (replaced) [<a href="/pdf/2308.16547" title="Download PDF">pdf</a>, <a href="/format/2308.16547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fully adaptive structure-preserving hyper-reduction of parametric  Hamiltonian systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Pagliantini%2C+C">Cecilia Pagliantini</a>, 
<a href="/search/math?searchtype=author&query=Vismara%2C+F">Federico Vismara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16612" title="Abstract">arXiv:2308.16612</a> (replaced) [<a href="/pdf/2308.16612" title="Download PDF">pdf</a>, <a href="/format/2308.16612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Gradient Regularizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zixiang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiangjun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xiangyong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+D">Deyu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00811" title="Abstract">arXiv:2309.00811</a> (replaced) [<a href="/pdf/2309.00811" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A double-decomposition based parallel exact algorithm for the feedback  length minimization problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Z">Zhen Shang</a> (1), 
<a href="/search/cs?searchtype=author&query=Hao%2C+J">Jin-Kao Hao</a> (2), 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fei Ma</a> (1) ((1) School of Economics and Management, Chang&#x27;an University, China, (2) LERIA, Universit&#xe9; d&#x27;Angers, Angers, France)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by PeerJ Computer Science on August 28, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00997" title="Abstract">arXiv:2309.00997</a> (replaced) [<a href="/pdf/2309.00997" title="Download PDF">pdf</a>, <a href="/format/2309.00997" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Switch and Conquer: Efficient Algorithms By Switching Stochastic  Gradient Oracles For Decentralized Saddle Point Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+C">Chhavi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+V">Vishnu Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Balamurugan%2C+P">P. Balamurugan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2205.14452">arXiv:2205.14452</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01516" title="Abstract">arXiv:2309.01516</a> (replaced) [<a href="/pdf/2309.01516" title="Download PDF">pdf</a>, <a href="/format/2309.01516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiWay-Adapater: Adapting large-scale multi-modal models for scalable  image-text retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Long%2C+Z">Zijun Long</a>, 
<a href="/search/cs?searchtype=author&query=Killick%2C+G">George Killick</a>, 
<a href="/search/cs?searchtype=author&query=McCreadie%2C+R">Richard McCreadie</a>, 
<a href="/search/cs?searchtype=author&query=Camarasa%2C+G+A">Gerardo Aragon Camarasa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01538" title="Abstract">arXiv:2309.01538</a> (replaced) [<a href="/pdf/2309.01538" title="Download PDF">pdf</a>, <a href="/format/2309.01538" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatRule: Mining Logical Rules with Large Language Models for Knowledge  Graph Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linhao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ju%2C+J">Jiaxin Ju</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+B">Bo Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuan-Fang Li</a>, 
<a href="/search/cs?searchtype=author&query=Haffari%2C+G">Gholamreza Haffari</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shirui Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01556" title="Abstract">arXiv:2309.01556</a> (replaced) [<a href="/pdf/2309.01556" title="Download PDF">pdf</a>, <a href="/format/2309.01556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Loopless Algorithms to Generate Maximum Length Gray Cycles wrt.  k-Character Substitution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%A9raud%2C+J">Jean N&#xe9;raud</a> (LITIS, UNIROUEN)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2108.13659">arXiv:2108.13659</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01582" title="Abstract">arXiv:2309.01582</a> (replaced) [<a href="/pdf/2309.01582" title="Download PDF">pdf</a>, <a href="/format/2309.01582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Visual Quality and Transferability of Adversarial Attacks on  Face Recognition Simultaneously with Adversarial Restoration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+F">Fengfan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Hefei Ling</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yuxuan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiazhong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> \copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02422" title="Abstract">arXiv:2309.02422</a> (replaced) [<a href="/pdf/2309.02422" title="Download PDF">pdf</a>, <a href="/format/2309.02422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Mean Discrepancy Meets Neural Networks: The  Radon-Kolmogorov-Smirnov Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Paik%2C+S">Seunghoon Paik</a>, 
<a href="/search/stat?searchtype=author&query=Celentano%2C+M">Michael Celentano</a>, 
<a href="/search/stat?searchtype=author&query=Green%2C+A">Alden Green</a>, 
<a href="/search/stat?searchtype=author&query=Tibshirani%2C+R+J">Ryan J. Tibshirani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02769" title="Abstract">arXiv:2309.02769</a> (replaced) [<a href="/pdf/2309.02769" title="Download PDF">pdf</a>, <a href="/format/2309.02769" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unifying over-smoothing and over-squashing in graph neural networks: A  physics informed approach and beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Z">Zhiqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+D">Dai Shi</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+A">Andi Han</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yi Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qibin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Junbin Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02969" title="Abstract">arXiv:2309.02969</a> (replaced) [<a href="/pdf/2309.02969" title="Download PDF">pdf</a>, <a href="/format/2309.02969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Case for Asymmetric Systolic Array Floorplanning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peltekis%2C+C">C. Peltekis</a>, 
<a href="/search/cs?searchtype=author&query=Filippas%2C+D">D. Filippas</a>, 
<a href="/search/cs?searchtype=author&query=Dimitrakopoulos%2C+G">G. Dimitrakopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nicopoulos%2C+C">C. Nicopoulos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CNNA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03347" title="Abstract">arXiv:2309.03347</a> (replaced) [<a href="/pdf/2309.03347" title="Download PDF">pdf</a>, <a href="/format/2309.03347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tensor Networks for Solving Realistic Time-independent Boltzmann Neutron  Transport Equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Truong%2C+D+P">Duc P. Truong</a>, 
<a href="/search/math?searchtype=author&query=Ortega%2C+M+I">Mario I. Ortega</a>, 
<a href="/search/math?searchtype=author&query=Boureima%2C+I">Ismael Boureima</a>, 
<a href="/search/math?searchtype=author&query=Manzini%2C+G">Gianmarco Manzini</a>, 
<a href="/search/math?searchtype=author&query=Rasmussen%2C+K+%C3%98">Kim &#xd8;. Rasmussen</a>, 
<a href="/search/math?searchtype=author&query=Alexandrov%2C+B+S">Boian S. Alexandrov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 38 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03532" title="Abstract">arXiv:2309.03532</a> (replaced) [<a href="/pdf/2309.03532" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A few misfits can Change the World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almirall%2C+E">Esteve Almirall</a>, 
<a href="/search/cs?searchtype=author&query=Willmott%2C+S">Steve Willmott</a>, 
<a href="/search/cs?searchtype=author&query=Cort%C3%A9s%2C+U">Ulises Cort&#xe9;s</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Theoretical Economics (econ.TH)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03581" title="Abstract">arXiv:2309.03581</a> (replaced) [<a href="/pdf/2309.03581" title="Download PDF">pdf</a>, <a href="/format/2309.03581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Hyperparameter Optimization in Multi-Objective Problems via  Preference Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giovanelli%2C+J">Joseph Giovanelli</a>, 
<a href="/search/cs?searchtype=author&query=Tornede%2C+A">Alexander Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Tornede%2C+T">Tanja Tornede</a>, 
<a href="/search/cs?searchtype=author&query=Lindauer%2C+M">Marius Lindauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04339" title="Abstract">arXiv:2309.04339</a> (replaced) [<a href="/pdf/2309.04339" title="Download PDF">pdf</a>, <a href="/format/2309.04339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Submodular Maximization via Online Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si-Salem%2C+T">Tareq Si-Salem</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zcan%2C+G">G&#xf6;zde &#xd6;zcan</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaou%2C+I">Iasonas Nikolaou</a>, 
<a href="/search/cs?searchtype=author&query=Terzi%2C+E">Evimaria Terzi</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+S">Stratis Ioannidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04434" title="Abstract">arXiv:2309.04434</a> (replaced) [<a href="/pdf/2309.04434" title="Download PDF">pdf</a>, <a href="/format/2309.04434" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Informed Neural Networks for an optimal counterdiabatic quantum  computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ferrer-S%C3%A1nchez%2C+A">Antonio Ferrer-S&#xe1;nchez</a>, 
<a href="/search/quant-ph?searchtype=author&query=Flores-Garrigos%2C+C">Carlos Flores-Garrigos</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hernani-Morales%2C+C">Carlos Hernani-Morales</a>, 
<a href="/search/quant-ph?searchtype=author&query=Orqu%C3%ADn-Marqu%C3%A9s%2C+J+J">Jos&#xe9; J. Orqu&#xed;n-Marqu&#xe9;s</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hegade%2C+N+N">Narendra N. Hegade</a>, 
<a href="/search/quant-ph?searchtype=author&query=Cadavid%2C+A+G">Alejandro Gomez Cadavid</a>, 
<a href="/search/quant-ph?searchtype=author&query=Montalban%2C+I">Iraitz Montalban</a>, 
<a href="/search/quant-ph?searchtype=author&query=Solano%2C+E">Enrique Solano</a>, 
<a href="/search/quant-ph?searchtype=author&query=Vives-Gilabert%2C+Y">Yolanda Vives-Gilabert</a>, 
<a href="/search/quant-ph?searchtype=author&query=Mart%C3%ADn-Guerrero%2C+J+D">Jos&#xe9; D. Mart&#xed;n-Guerrero</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 10 figures, 1 algorithm, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04494" title="Abstract">arXiv:2309.04494</a> (replaced) [<a href="/pdf/2309.04494" title="Download PDF">pdf</a>, <a href="/format/2309.04494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Existence of Steady-State Solutions to the Equations Governing  Fluid Flow in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Srinivasan%2C+S">Shriram Srinivasan</a>, 
<a href="/search/math?searchtype=author&query=Panda%2C+N">Nishant Panda</a>, 
<a href="/search/math?searchtype=author&query=Sundar%2C+K">Kaarthik Sundar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04573" title="Abstract">arXiv:2309.04573</a> (replaced) [<a href="/pdf/2309.04573" title="Download PDF">pdf</a>, <a href="/format/2309.04573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rai%2C+S+N">Shyam Nandan Rai</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>, 
<a href="/search/cs?searchtype=author&query=Masone%2C+C">Carlo Masone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages. arXiv admin note: substantial text overlap with <a href="/abs/2307.13316">arXiv:2307.13316</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04697" title="Abstract">arXiv:2309.04697</a> (replaced) [<a href="/pdf/2309.04697" title="Download PDF">pdf</a>, <a href="/format/2309.04697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leakage-Abuse Attacks Against Forward and Backward Private Searchable  Symmetric Encryption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Lei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+L">Leqian Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chengzhi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xingliang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Cong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this paper has been accepted to the 30th ACM Conference on Computer and Communications Security (CCS'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04833" title="Abstract">arXiv:2309.04833</a> (replaced) [<a href="/pdf/2309.04833" title="Download PDF">pdf</a>, <a href="/format/2309.04833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effectiveness of Security Interventions on GitHub
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fischer%2C+F">Felix Fischer</a>, 
<a href="/search/cs?searchtype=author&query=H%C3%B6benreich%2C+J">Jonas H&#xf6;benreich</a>, 
<a href="/search/cs?searchtype=author&query=Grossklags%2C+J">Jens Grossklags</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04841" title="Abstract">arXiv:2309.04841</a> (replaced) [<a href="/pdf/2309.04841" title="Download PDF">pdf</a>, <a href="/format/2309.04841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Simulation of High-Depth QAOA Circuits
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Lykov%2C+D">Danylo Lykov</a>, 
<a href="/search/quant-ph?searchtype=author&query=Shaydulin%2C+R">Ruslan Shaydulin</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sun%2C+Y">Yue Sun</a>, 
<a href="/search/quant-ph?searchtype=author&query=Alexeev%2C+Y">Yuri Alexeev</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Additional references added in v2
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE/ACM Third International Workshop on Quantum Computing
  Software (QCS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Performance (cs.PF)

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05071" title="Abstract">arXiv:2309.05071</a> (replaced) [<a href="/pdf/2309.05071" title="Download PDF">pdf</a>, <a href="/format/2309.05071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Super-Resolution Surface Reconstruction from Few Low-Resolution Slices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhang%2C+Y">Yiyao Zhang</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+S">Shang-Hua Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 25 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> AIMS Journal Inverse Problems and Imaging (IPI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05077" title="Abstract">arXiv:2309.05077</a> (replaced) [<a href="/pdf/2309.05077" title="Download PDF">pdf</a>, <a href="/ps/2309.05077" title="Download PostScript">ps</a>, <a href="/format/2309.05077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalization error bounds for iterative learning algorithms with  bounded updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jingwen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+N">Nanning Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05153" title="Abstract">arXiv:2309.05153</a> (replaced) [<a href="/pdf/2309.05153" title="Download PDF">pdf</a>, <a href="/format/2309.05153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Energy-Based Models by Cooperative Diffusion Recovery  Likelihood
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhu%2C+Y">Yaxuan Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Xie%2C+J">Jianwen Xie</a>, 
<a href="/search/stat?searchtype=author&query=Wu%2C+Y">Yingnian Wu</a>, 
<a href="/search/stat?searchtype=author&query=Gao%2C+R">Ruiqi Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05210" title="Abstract">arXiv:2309.05210</a> (replaced) [<a href="/pdf/2309.05210" title="Download PDF">pdf</a>, <a href="/ps/2309.05210" title="Download PostScript">ps</a>, <a href="/format/2309.05210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Impact of Post-Training Quantization on Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Somnath Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05235" title="Abstract">arXiv:2309.05235</a> (replaced) [<a href="/pdf/2309.05235" title="Download PDF">pdf</a>, <a href="/format/2309.05235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P2LSG: Powers-of-2 Low-Discrepancy Sequence Generator for Stochastic  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+M+S">Mehran Shoushtari Moghadam</a>, 
<a href="/search/cs?searchtype=author&query=Aygun%2C+S">Sercan Aygun</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+R">Mohsen Riahi Alam</a>, 
<a href="/search/cs?searchtype=author&query=Najafi%2C+M+H">M. Hassan Najafi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, Accepted in 29th ASP-DAC 2024 Conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05248" title="Abstract">arXiv:2309.05248</a> (replaced) [<a href="/pdf/2309.05248" title="Download PDF">pdf</a>, <a href="/format/2309.05248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Speaker Diarization with Large Language Models: A Contextual  Beam Search Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+T+J">Tae Jin Park</a>, 
<a href="/search/eess?searchtype=author&query=Dhawan%2C+K">Kunal Dhawan</a>, 
<a href="/search/eess?searchtype=author&query=Koluguri%2C+N">Nithin Koluguri</a>, 
<a href="/search/eess?searchtype=author&query=Balam%2C+J">Jagadeesh Balam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages 1 reference page, ICASSP format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05282" title="Abstract">arXiv:2309.05282</a> (replaced) [<a href="/pdf/2309.05282" title="Download PDF">pdf</a>, <a href="/format/2309.05282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can you text what is happening? Integrating pre-trained language  encoders into trajectory prediction models for autonomous driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keysan%2C+A">Ali Keysan</a>, 
<a href="/search/cs?searchtype=author&query=Look%2C+A">Andreas Look</a>, 
<a href="/search/cs?searchtype=author&query=Kosman%2C+E">Eitan Kosman</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrsun%2C+G">Gonca G&#xfc;rsun</a>, 
<a href="/search/cs?searchtype=author&query=Wagner%2C+J">J&#xf6;rg Wagner</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Rakitsch%2C+B">Barbara Rakitsch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05519" title="Abstract">arXiv:2309.05519</a> (replaced) [<a href="/pdf/2309.05519" title="Download PDF">pdf</a>, <a href="/format/2309.05519" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NExT-GPT: Any-to-Any Multimodal LLM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shengqiong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Fei%2C+H">Hao Fei</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+L">Leigang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+W">Wei Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chua%2C+T">Tat-Seng Chua</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05575" title="Abstract">arXiv:2309.05575</a> (replaced) [<a href="/pdf/2309.05575" title="Download PDF">pdf</a>, <a href="/format/2309.05575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic Diffusion Stencils: From Simple Derivations over Stability  Estimates to ResNet Implementations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schrader%2C+K">Karl Schrader</a>, 
<a href="/search/math?searchtype=author&query=Weickert%2C+J">Joachim Weickert</a>, 
<a href="/search/math?searchtype=author&query=Krause%2C+M">Michael Krause</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05605" title="Abstract">arXiv:2309.05605</a> (replaced) [<a href="/pdf/2309.05605" title="Download PDF">pdf</a>, <a href="/format/2309.05605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Memory Injections: Correcting Multi-Hop Reasoning Failures during  Inference in Transformer-Based Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sakarvadia%2C+M">Mansi Sakarvadia</a>, 
<a href="/search/cs?searchtype=author&query=Ajith%2C+A">Aswathy Ajith</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+A">Arham Khan</a>, 
<a href="/search/cs?searchtype=author&query=Grzenda%2C+D">Daniel Grzenda</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+N">Nathaniel Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Bauer%2C+A">Andr&#xe9; Bauer</a>, 
<a href="/search/cs?searchtype=author&query=Chard%2C+K">Kyle Chard</a>, 
<a href="/search/cs?searchtype=author&query=Foster%2C+I">Ian Foster</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05827" title="Abstract">arXiv:2309.05827</a> (replaced) [<a href="/pdf/2309.05827" title="Download PDF">pdf</a>, <a href="/ps/2309.05827" title="Download PostScript">ps</a>, <a href="/format/2309.05827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digraph Branchings and Matrix Determinants
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ghosh%2C+S">Sayani Ghosh</a>, 
<a href="/search/math?searchtype=author&query=Meyer%2C+B+S">Bradley S. Meyer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05918" title="Abstract">arXiv:2309.05918</a> (replaced) [<a href="/pdf/2309.05918" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stochastic LLMs do not Understand Language: Towards Symbolic,  Explainable and Ontologically Based LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saba%2C+W+S">Walid S. Saba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05952" title="Abstract">arXiv:2309.05952</a> (replaced) [<a href="/pdf/2309.05952" title="Download PDF">pdf</a>, <a href="/format/2309.05952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatMPC: Natural Language based MPC Personalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyaoka%2C+Y">Yuya Miyaoka</a>, 
<a href="/search/cs?searchtype=author&query=Inoue%2C+M">Masaki Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Nii%2C+T">Tomotaka Nii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06055" title="Abstract">arXiv:2309.06055</a> (replaced) [<a href="/pdf/2309.06055" title="Download PDF">pdf</a>, <a href="/format/2309.06055" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backdoor Attacks and Countermeasures in Natural Language Processing  Models: A Comprehensive Security Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengzhou Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+W">Wei Du</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gongshen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06062" title="Abstract">arXiv:2309.06062</a> (replaced) [<a href="/pdf/2309.06062" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Selection of contributing factors for predicting landslide  susceptibility using machine learning and deep learning models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Cheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+L">Lei Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Stochastic Environmental Research and Risk Assessment
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Geophysics (physics.geo-ph)

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06067" title="Abstract">arXiv:2309.06067</a> (replaced) [<a href="/pdf/2309.06067" title="Download PDF">pdf</a>, <a href="/ps/2309.06067" title="Download PostScript">ps</a>, <a href="/format/2309.06067" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Batch Implicit Neural Representation for MRI Parallel Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yusheng Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jianan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+X">Xiling Liu</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+T">Tao Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lv%2C+Z">Zhihan Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06068" title="Abstract">arXiv:2309.06068</a> (replaced) [<a href="/pdf/2309.06068" title="Download PDF">pdf</a>, <a href="/ps/2309.06068" title="Download PostScript">ps</a>, <a href="/format/2309.06068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Distribution Testing with Heterogeneous Constraints: Your  Epsilon Might Not Be Mine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Canonne%2C+C+L">Cl&#xe9;ment L. Canonne</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yucheng Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06118" title="Abstract">arXiv:2309.06118</a> (replaced) [<a href="/pdf/2309.06118" title="Download PDF">pdf</a>, <a href="/format/2309.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C-RITNet: Set Infrared and Visible Image Fusion Free from Complementary  Information Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keying Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06175" title="Abstract">arXiv:2309.06175</a> (replaced) [<a href="/pdf/2309.06175" title="Download PDF">pdf</a>, <a href="/format/2309.06175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity  Recognition and Linking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+D">Di Lu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhongping Liang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Caixia Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaojie Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06229" title="Abstract">arXiv:2309.06229</a> (replaced) [<a href="/pdf/2309.06229" title="Download PDF">pdf</a>, <a href="/format/2309.06229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PreciseBugCollector: Extensible, Executable and Precise Bug-fix  Collection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Ye He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Goues%2C+C+L">Claire Le Goues</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the industry challenge track of ASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06323" title="Abstract">arXiv:2309.06323</a> (replaced) [<a href="/pdf/2309.06323" title="Download PDF">pdf</a>, <a href="/format/2309.06323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation  for Novel View Synthesis from a Single Image
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiaoyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiwei Lin</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+X">Xiaojun Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongtao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Deqing Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06330" title="Abstract">arXiv:2309.06330</a> (replaced) [<a href="/pdf/2309.06330" title="Download PDF">pdf</a>, <a href="/format/2309.06330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inexact Decentralized Dual Gradient Tracking for Constraint-Coupled  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Li%2C+J">Jingwang Li</a>, 
<a href="/search/math?searchtype=author&query=Su%2C+H">Housheng Su</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item268">Cross-lists</a></li>
<li><a href="#item308">Replacements</a></li>
</ul>
<small>[ total of 505 entries:  <b>1-505</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
