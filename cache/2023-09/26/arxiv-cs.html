<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Fri 22 Sep 23  to  Mon 25 Sep 23, announced Tue, 26 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item590">Cross-lists</a></li>
<li><a href="#item679">Replacements</a></li>
</ul>
<small>[ total of 1069 entries:  <b>1-1069</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Tue, 26 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13044" title="Abstract">arXiv:2309.13044</a> [<a href="/pdf/2309.13044" title="Download PDF">pdf</a>, <a href="/ps/2309.13044" title="Download PostScript">ps</a>, <a href="/format/2309.13044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What is the Title of this Paper? Solving logic puzzles using algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakshit%2C+U">Ujaan Rakshit</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+N">Nishchal Dwivedi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work delves into the realm of logic puzzles by focusing on the Knight
and Knave problems popularized by Raymond Smullyan in his book series "What is
the Name of This Book?". The puzzles revolve around characters known as Knights
(truth-tellers) and Knaves (liars), challenging solvers to determine the true
identity of each person based on their statements. This paper explores the
utilization of Python algorithms to automate the process of solving these
puzzles, offering a computational approach that enhances efficiency and
accessibility. In this work, we aim to develop a Python algorithm capable of
parsing and analyzing the statements provided in the Knight and Knave puzzles.
A logical reasoning framework is integrated within the algorithm to deduce the
identities of the characters based on their statements. The algorithm processes
the input statements, create a knowledge base, and make deductions following
the rules of Knight and Knave logic. The developed algorithm is thoroughly
tested on various instances of Knight and Knave puzzles, comparing its results
to known solutions and manual approaches. We further expand the scope of the
problem by introducing a Normal (who can sometimes lie and sometimes say the
truth).
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13046" title="Abstract">arXiv:2309.13046</a> [<a href="/pdf/2309.13046" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy Preserving Machine Learning for Behavioral Authentication  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+M">Md Morshedul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Rafiq%2C+M+A">Md Abdur Rafiq</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">A behavioral authentication (BA) system uses the behavioral characteristics
of users to verify their identity claims. A BA verification algorithm can be
constructed by training a neural network (NN) classifier on users' profiles.
The trained NN model classifies the presented verification data, and if the
classification matches the claimed identity, the verification algorithm accepts
the claim. This classification-based approach removes the need to maintain a
profile database. However, similar to other NN architectures, the NN classifier
of the BA system is vulnerable to privacy attacks. To protect the privacy of
training and test data used in an NN different techniques are widely used. In
this paper, our focus is on a non-crypto-based approach, and we used random
projection (RP) to ensure data privacy in an NN model. RP is a
distance-preserving transformation based on a random matrix. Before sharing the
profiles with the verifier, users will transform their profiles by RP and keep
their matrices secret. To reduce the computation load in RP, we use sparse
random projection, which is very effective for low-compute devices. Along with
correctness and security properties, our system can ensure the changeability
property of the BA system. We also introduce an ML-based privacy attack, and
our proposed system is robust against this and other privacy and security
attacks. We implemented our approach on three existing behavioral BA systems
and achieved a below 2.0% FRR and a below 1.0% FAR rate. Moreover, the machine
learning-based privacy attacker can only recover below 3.0% to 12.0% of
features from a portion of the projected profiles. However, these recovered
features are not sufficient to know details about the users' behavioral pattern
or to be used in a subsequent attack. Our approach is general and can be used
in other NN-based BA systems as well as in traditional biometric systems.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13049" title="Abstract">arXiv:2309.13049</a> [<a href="/pdf/2309.13049" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Driven Personalised Offloading Device Prescriptions: A Cutting-Edge  Approach to Preventing Diabetes-Related Plantar Forefoot Ulcers and  Complications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+S">Sayed Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Kabir%2C+M+A">Muhammad Ashad Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M+E+H">Muhammad E. H. Chowdhury</a>, 
<a href="/search/cs?searchtype=author&query=Nancarrow%2C+S">Susan Nancarrow</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Diabetes-related foot ulcers and complications are a significant concern for
individuals with diabetes, leading to severe health implications such as
lower-limb amputation and reduced quality of life. This chapter discusses
applying AI-driven personalised offloading device prescriptions as an advanced
solution for preventing such conditions. By harnessing the capabilities of
artificial intelligence, this cutting-edge approach enables the prescription of
offloading devices tailored to each patient's specific requirements. This
includes the patient's preferences on offloading devices such as footwear and
foot orthotics and their adaptations that suit the patient's intention of use
and lifestyle. Through a series of studies, real-world data analysis and
machine learning algorithms, high-risk areas can be identified, facilitating
the recommendation of precise offloading strategies, including custom orthotic
insoles, shoe adaptations, or specialised footwear. By including
patient-specific factors to promote adherence, proactively addressing pressure
points and promoting optimal foot mechanics, these personalised offloading
devices have the potential to minimise the occurrence of foot ulcers and
associated complications. This chapter proposes an AI-powered Clinical Decision
Support System (CDSS) to recommend personalised prescriptions of offloading
devices (footwear and insoles) for patients with diabetes who are at risk of
foot complications. This innovative approach signifies a transformative leap in
diabetic foot care, offering promising opportunities for preventive healthcare
interventions.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13050" title="Abstract">arXiv:2309.13050</a> [<a href="/pdf/2309.13050" title="Download PDF">pdf</a>, <a href="/format/2309.13050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding the Alphabet Soup of Degrees in the United States Postsecondary  Education System Through Hybrid Method: Database and Text Mining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voghoei%2C+S">Sahar Voghoei</a>, 
<a href="/search/cs?searchtype=author&query=Byars%2C+J">James Byars</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+J+A">John A Miller</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+K">Khaled Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Arabnia%2C+H+A">Hamid A Arabnia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 Pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This paper proposes a model to predict the levels (e.g., Bachelor, Master,
etc.) of postsecondary degree awards that have been ambiguously expressed in
the student tracking reports of the National Student Clearinghouse (NSC). The
model will be the hybrid of two modules. The first module interprets the
relevant abbreviatory elements embedded in NSC reports by referring to a
comprehensive database that we have made of nearly 950 abbreviations for degree
titles used by American postsecondary educators. The second module is a
combination of feature classification and text mining modeled with CNN-BiLSTM,
which is preceded by several steps of heavy pre-processing. The model proposed
in this paper was trained with four multi-label datasets of different grades of
resolution and returned 97.83\% accuracy with the most sophisticated dataset.
Such a thorough classification of degree levels will provide insights into the
modeling patterns of student success and mobility. To date, such a
classification strategy has not been attempted except using manual methods and
simple text parsing logic.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13051" title="Abstract">arXiv:2309.13051</a> [<a href="/pdf/2309.13051" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Contextual Topic Modeling and Content Analysis of Iranian laws and  Regulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hemmat%2C+Z">Zahra Hemmat</a>, 
<a href="/search/cs?searchtype=author&query=Mehraeen%2C+M">Mohammad Mehraeen</a>, 
<a href="/search/cs?searchtype=author&query=Fattahi%2C+R">Rahmatolloah Fattahi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A constitution is the highest legal document of a country and serves as a
guide for the establishment of other laws. The constitution defines the
political principles, structure, hierarchy, position, and limits of the
political power of a country's government. It determines and guarantees the
rights of citizens. This study aimed at topic modeling of Iranian laws. As part
of this research, 11760 laws were collected from the Dotic website. Then, topic
modeling was conducted on the title and content of the regularizations using
LDA. Data analysis with topic modeling led to the identification of 10 topics
including Economic, Customs, Housing and Urban Development, Agriculture,
Insurance, Legal and judicial, Cultural, Information Technology, Political, and
Government. The largest topic, Economic, accounts for 29% of regulations, while
the smallest are Political and Government, accounting for 2%. This research
utilizes a topic modeling method in exploring law texts and identifying trends
in regularizations from 2016-2023. In this study, it was found that
regularizations constitute a significant percentage of law, most of which are
related to economics and customs. Cultural regularizations have increased in
2023. It can be concluded any law enacted each year can reflect society's
conditions and legislators' top concerns.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13052" title="Abstract">arXiv:2309.13052</a> [<a href="/pdf/2309.13052" title="Download PDF">pdf</a>, <a href="/format/2309.13052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Students Success Modeling: Most Important Factors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Voghoei%2C+S">Sahar Voghoei</a>, 
<a href="/search/cs?searchtype=author&query=Byars%2C+J+M">James M. Byars</a>, 
<a href="/search/cs?searchtype=author&query=King%2C+S+J">Scott Jackson King</a>, 
<a href="/search/cs?searchtype=author&query=Shapouri%2C+S">Soheil Shapouri</a>, 
<a href="/search/cs?searchtype=author&query=Yaghoobian%2C+H">Hamed Yaghoobian</a>, 
<a href="/search/cs?searchtype=author&query=Rasheed%2C+K+M">Khaled M. Rasheed</a>, 
<a href="/search/cs?searchtype=author&query=Arabnia%2C+H+R">Hamid R. Arabnia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 17 figures, 1 apendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The importance of retention rate for higher education institutions has
encouraged data analysts to present various methods to predict at-risk
students. The present study, motivated by the same encouragement, proposes a
deep learning model trained with 121 features of diverse categories extracted
or engineered out of the records of 60,822 postsecondary students. The model
undertakes to identify students likely to graduate, the ones likely to transfer
to a different school, and the ones likely to drop out and leave their higher
education unfinished. This study undertakes to adjust its predictive methods
for different stages of curricular progress of students. The temporal aspects
introduced for this purpose are accounted for by incorporating layers of LSTM
in the model. Our experiments demonstrate that distinguishing between
to-be-graduate and at-risk students is reasonably achievable in the earliest
stages, and then it rapidly improves, but the resolution within the latter
category (dropout vs. transfer) depends on data accumulated over time. However,
the model remarkably foresees the fate of students who stay in the school for
three years. The model is also assigned to present the weightiest features in
the procedure of prediction, both on institutional and student levels. A large,
diverse sample size along with the investigation of more than one hundred
extracted or engineered features in our study provide new insights into
variables that affect students success, predict dropouts with reasonable
accuracy, and shed light on the less investigated issue of transfer between
colleges. More importantly, by providing individual-level predictions (as
opposed to school-level predictions) and addressing the outcomes of transfers,
this study improves the use of ML in the prediction of educational outcomes.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13053" title="Abstract">arXiv:2309.13053</a> [<a href="/pdf/2309.13053" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Curriculum Theory to Inform Approaches to Generative AI in Schools
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Healy%2C+M">Myke Healy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In an educational landscape dramatically altered by the swift proliferation
of Large Language Models, this essay interrogates the urgent this essay
interrogates the urgent pedagogical modifications required in secondary
schooling. Anchored in Madeline Grumet's triadic framework of curriculum
inquiry, the study delineates the multifaceted relationship between Generative
AI and Elliot Eisner's explicit, implicit, and null curriculum concepts. It
scrutinizes the logistical and ethical challenges, such as the reliability of
AI detectors, that educators confront when attempting to assimilate this
nascent technology into long-standing curricular structures. Engaging with Ted
Aoki's theory of the "zone of between", the essay illuminates educators'
dilemmas in reconciling prescriptive curricular aims with the fluid realities
of classroom life, all within an educational milieu in constant flux due to
Generative AI. The paper culminates in a reflective analysis by the researcher,
identifying avenues for further scholarly investigation within each of Grumet's
constitutive strands of curriculum theory, thereby providing a roadmap for
future research on Generative AI's transformative impact on educational
practice.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13054" title="Abstract">arXiv:2309.13054</a> [<a href="/pdf/2309.13054" title="Download PDF">pdf</a>, <a href="/format/2309.13054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Commons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guha%2C+R+V">Ramanathan V. Guha</a>, 
<a href="/search/cs?searchtype=author&query=Radhakrishnan%2C+P">Prashanth Radhakrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Au%2C+C">Carolyn Au</a>, 
<a href="/search/cs?searchtype=author&query=Tirumali%2C+A">Ajai Tirumali</a>, 
<a href="/search/cs?searchtype=author&query=Amjad%2C+M+J">Muhammad J. Amjad</a>, 
<a href="/search/cs?searchtype=author&query=Piekos%2C+S">Samantha Piekos</a>, 
<a href="/search/cs?searchtype=author&query=Diaz%2C+N">Natalie Diaz</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jennifer Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Julia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ramaswami%2C+P">Prem Ramaswami</a>, 
<a href="/search/cs?searchtype=author&query=Manyika%2C+J">James Manyika</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Publicly available data from open sources (e.g., United States Census Bureau
(Census), World Health Organization (WHO), Intergovernmental Panel on Climate
Change (IPCC)) are vital resources for policy makers, students and researchers
across different disciplines. Combining data from different sources requires
the user to reconcile the differences in schemas, formats, assumptions, and
more. This data wrangling is time consuming, tedious and needs to be repeated
by every user of the data. Our goal with Data Commons (DC) is to help make
public data accessible and useful to those who want to understand this data and
use it to solve societal challenges and opportunities. We do the data
processing and make the processed data widely available via standard schemas
and Cloud APIs. Data Commons is a distributed network of sites that publish
data in a common schema and interoperate using the Data Commons APIs. Data from
different Data Commons can be joined easily. The aggregate of these Data
Commons can be viewed as a single Knowledge Graph. This Knowledge Graph can
then be searched over using Natural Language questions utilizing advances in
Large Language Models. This paper describes the architecture of Data Commons,
some of the major deployments and highlights directions for future work.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13055" title="Abstract">arXiv:2309.13055</a> [<a href="/pdf/2309.13055" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Originality and the Future of Copyright in an Age of Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jurcys%2C+P">Paulius Jurcys</a>, 
<a href="/search/cs?searchtype=author&query=Fenwick%2C+M">Mark Fenwick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This papers explores the question of human authorship when works are created
with generative AI tools.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13056" title="Abstract">arXiv:2309.13056</a> [<a href="/pdf/2309.13056" title="Download PDF">pdf</a>, <a href="/format/2309.13056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Book Chapter in Computational Demography and Health
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almquist%2C+Z+W">Zack W. Almquist</a>, 
<a href="/search/cs?searchtype=author&query=Allen%2C+C">Courtney Allen</a>, 
<a href="/search/cs?searchtype=author&query=Kahveci%2C+I">Ihsan Kahveci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Recent developments in computing, data entry and generation, and analytic
tools have changed the landscape of modern demography and health research.
These changes have come to be known as computational demography, big data, and
precision health in the field. This emerging interdisciplinary research
comprises social scientists, physical scientists, engineers, data scientists,
and disease experts. This work has changed how we use administrative data,
conduct surveys, and allow for complex behavioral studies via big data
(electronic trace data from mobile phones, apps, etc.). This chapter reviews
this emerging field's new data sources, methods, and applications.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13057" title="Abstract">arXiv:2309.13057</a> [<a href="/pdf/2309.13057" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Return on Investment in AI Ethics: A Holistic Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bevilacqua%2C+M">Marialena Bevilacqua</a>, 
<a href="/search/cs?searchtype=author&query=Berente%2C+N">Nicholas Berente</a>, 
<a href="/search/cs?searchtype=author&query=Domin%2C+H">Heather Domin</a>, 
<a href="/search/cs?searchtype=author&query=Goehring%2C+B">Brian Goehring</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Francesca Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A subsequent version of this paper will be published in the Hawaii International Conference on System Sciences (HICSS) 2024 Proceedings
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">We propose a Holistic Return on Ethics (HROE) framework for understanding the
return on organizational investments in artificial intelligence (AI) ethics
efforts. This framework is useful for organizations that wish to quantify the
return for their investment decisions. The framework identifies the direct
economic returns of such investments, the indirect paths to return through
intangibles associated with organizational reputation, and real options
associated with capabilities. The holistic framework ultimately provides
organizations with the competency to employ and justify AI ethics investments.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13058" title="Abstract">arXiv:2309.13058</a> [<a href="/pdf/2309.13058" title="Download PDF">pdf</a>, <a href="/format/2309.13058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mathematical Modeling and Optimal Control of Untrue Information :  Dynamic SEIZ in Online Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mansal%2C+F">Fulgence Mansal</a>, 
<a href="/search/cs?searchtype=author&query=Faye%2C+I">Ibrahima Faye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We propose to model the phenomenon of the spread of a rumor in this paper. We
manipulate a model that is based on SEIR model that specializes in spreading
rumors. In the second part, we introduce a control strategy to fight against
the diffusion of the rumor. Our main objective is to characterize the three
optimal controls that minimize the number of spreaders, susceptibles who enter
and spread the rumor, and skeptics. For that matter, using the maximum
principle of Pontryagin, we prove the existence and give characterization of
our controls. To illustrate the theoretical results obtained, numerical
simulations are given to concretize our approach.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13059" title="Abstract">arXiv:2309.13059</a> [<a href="/pdf/2309.13059" title="Download PDF">pdf</a>, <a href="/format/2309.13059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Traditional Teaching: The Potential of Large Language Models and  Chatbots in Graduate Engineering Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abedi%2C+M">Mahyar Abedi</a>, 
<a href="/search/cs?searchtype=author&query=Alshybani%2C+I">Ibrahem Alshybani</a>, 
<a href="/search/cs?searchtype=author&query=Shahadat%2C+M+R+B">Muhammad Rubayat Bin Shahadat</a>, 
<a href="/search/cs?searchtype=author&query=Murillo%2C+M+S">Michael S. Murillo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 44 pages, 16 figures, preprint for PLOS ONE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">In the rapidly evolving landscape of education, digital technologies have
repeatedly disrupted traditional pedagogical methods. This paper explores the
latest of these disruptions: the potential integration of large language models
(LLMs) and chatbots into graduate engineering education. We begin by tracing
historical and technological disruptions to provide context and then introduce
key terms such as machine learning and deep learning and the underlying
mechanisms of recent advancements, namely attention/transformer models and
graphics processing units. The heart of our investigation lies in the
application of an LLM-based chatbot in a graduate fluid mechanics course. We
developed a question bank from the course material and assessed the chatbot's
ability to provide accurate, insightful responses. The results are encouraging,
demonstrating not only the bot's ability to effectively answer complex
questions but also the potential advantages of chatbot usage in the classroom,
such as the promotion of self-paced learning, the provision of instantaneous
feedback, and the reduction of instructors' workload. The study also examines
the transformative effect of intelligent prompting on enhancing the chatbot's
performance. Furthermore, we demonstrate how powerful plugins like Wolfram
Alpha for mathematical problem-solving and code interpretation can
significantly extend the chatbot's capabilities, transforming it into a
comprehensive educational tool. While acknowledging the challenges and ethical
implications surrounding the use of such AI models in education, we advocate
for a balanced approach. The use of LLMs and chatbots in graduate education can
be greatly beneficial but requires ongoing evaluation and adaptation to ensure
ethical and efficient use.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13060" title="Abstract">arXiv:2309.13060</a> [<a href="/pdf/2309.13060" title="Download PDF">pdf</a>, <a href="/format/2309.13060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementing Learning Principles with a Personal AI Tutor: A Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baillifard%2C+A">Ambroise Baillifard</a>, 
<a href="/search/cs?searchtype=author&query=Gabella%2C+M">Maxime Gabella</a>, 
<a href="/search/cs?searchtype=author&query=Lavenex%2C+P+B">Pamela Banta Lavenex</a>, 
<a href="/search/cs?searchtype=author&query=Martarelli%2C+C+S">Corinna S. Martarelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Effective learning strategies based on principles like personalization,
retrieval practice, and spaced repetition are often challenging to implement
due to practical constraints. Here we explore the integration of AI tutors to
complement learning programs in accordance with learning sciences. A
semester-long study was conducted at UniDistance Suisse, where an AI tutor app
was provided to psychology students taking a neuroscience course (N=51). After
automatically generating microlearning questions from existing course materials
using GPT-3, the AI tutor developed a dynamic neural-network model of each
student's grasp of key concepts. This enabled the implementation of distributed
retrieval practice, personalized to each student's individual level and
abilities. The results indicate that students who actively engaged with the AI
tutor achieved significantly higher grades. Moreover, active engagement led to
an average improvement of up to 15 percentile points compared to a parallel
course without AI tutor. Additionally, the grasp strongly correlated with the
exam grade, thus validating the relevance of neural-network predictions. This
research demonstrates the ability of personal AI tutors to model human learning
processes and effectively enhance academic performance. By integrating AI
tutors into their programs, educators can offer students personalized learning
experiences grounded in the principles of learning sciences, thereby addressing
the challenges associated with implementing effective learning strategies.
These findings contribute to the growing body of knowledge on the
transformative potential of AI in education.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13061" title="Abstract">arXiv:2309.13061</a> [<a href="/pdf/2309.13061" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying BioBERT to Extract Germline Gene-Disease Associations for  Building a Knowledge Graph from the Biomedical Literature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gonzalez%2C+A+D+D">Armando D. Diaz Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Songhui Yue</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+S+T">Sean T. Hayes</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+K+S">Kevin S. Hughes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 7th International Conference on Information System and Data
  Mining (ICISDM), Atlanta, USA, May 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Published biomedical information has and continues to rapidly increase. The
recent advancements in Natural Language Processing (NLP), have generated
considerable interest in automating the extraction, normalization, and
representation of biomedical knowledge about entities such as genes and
diseases. Our study analyzes germline abstracts in the construction of
knowledge graphs of the of the immense work that has been done in this area for
genes and diseases. This paper presents SimpleGermKG, an automatic knowledge
graph construction approach that connects germline genes and diseases. For the
extraction of genes and diseases, we employ BioBERT, a pre-trained BERT model
on biomedical corpora. We propose an ontology-based and rule-based algorithm to
standardize and disambiguate medical terms. For semantic relationships between
articles, genes, and diseases, we implemented a part-whole relation approach to
connect each entity with its data source and visualize them in a graph-based
knowledge representation. Lastly, we discuss the knowledge graph applications,
limitations, and challenges to inspire the future research of germline corpora.
Our knowledge graph contains 297 genes, 130 diseases, and 46,747 triples.
Graph-based visualizations are used to show the results.
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13063" title="Abstract">arXiv:2309.13063</a> [<a href="/pdf/2309.13063" title="Download PDF">pdf</a>, <a href="/format/2309.13063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models to Generate, Validate, and Apply User Intent  Taxonomies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+C">Chirag Shah</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+R+W">Ryen W. White</a>, 
<a href="/search/cs?searchtype=author&query=Andersen%2C+R">Reid Andersen</a>, 
<a href="/search/cs?searchtype=author&query=Buscher%2C+G">Georg Buscher</a>, 
<a href="/search/cs?searchtype=author&query=Counts%2C+S">Scott Counts</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+S+S+S">Sarkar Snigdha Sarathi Das</a>, 
<a href="/search/cs?searchtype=author&query=Montazer%2C+A">Ali Montazer</a>, 
<a href="/search/cs?searchtype=author&query=Manivannan%2C+S">Sathish Manivannan</a>, 
<a href="/search/cs?searchtype=author&query=Neville%2C+J">Jennifer Neville</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+X">Xiaochuan Ni</a>, 
<a href="/search/cs?searchtype=author&query=Rangan%2C+N">Nagu Rangan</a>, 
<a href="/search/cs?searchtype=author&query=Safavi%2C+T">Tara Safavi</a>, 
<a href="/search/cs?searchtype=author&query=Suri%2C+S">Siddharth Suri</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+M">Mengting Wan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Leijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Longqi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Log data can reveal valuable information about how users interact with web
search services, what they want, and how satisfied they are. However, analyzing
user intents in log data is not easy, especially for new forms of web search
such as AI-driven chat. To understand user intents from log data, we need a way
to label them with meaningful categories that capture their diversity and
dynamics. Existing methods rely on manual or ML-based labeling, which are
either expensive or inflexible for large and changing datasets. We propose a
novel solution using large language models (LLMs), which can generate rich and
relevant concepts, descriptions, and examples for user intents. However, using
LLMs to generate a user intent taxonomy and apply it to do log analysis can be
problematic for two main reasons: such a taxonomy is not externally validated,
and there may be an undesirable feedback loop. To overcome these issues, we
propose a new methodology with human experts and assessors to verify the
quality of the LLM-generated taxonomy. We also present an end-to-end pipeline
that uses an LLM with human-in-the-loop to produce, refine, and use labels for
user intent analysis in log data. Our method offers a scalable and adaptable
way to analyze user intents in web-scale log data with minimal human effort. We
demonstrate its effectiveness by uncovering new insights into user intents from
search and chat logs from Bing.
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13065" title="Abstract">arXiv:2309.13065</a> [<a href="/pdf/2309.13065" title="Download PDF">pdf</a>, <a href="/format/2309.13065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personality Profiling: How informative are social media profiles in  predicting personal information?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watt%2C+J">Joshua Watt</a>, 
<a href="/search/cs?searchtype=author&query=Tuke%2C+J">Jonathan Tuke</a>, 
<a href="/search/cs?searchtype=author&query=Mitchell%2C+L">Lewis Mitchell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures. Dataset available at <a href="https://figshare.com/articles/dataset/Self-Reported_Myers-Briggs_Personality_Types_on_Twitter/23620554">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">Personality profiling has been utilised by companies for targeted
advertising, political campaigns and vaccine campaigns. However, the accuracy
and versatility of such models still remains relatively unknown. Consequently,
we aim to explore the extent to which peoples' online digital footprints can be
used to profile their Myers-Briggs personality type. We analyse and compare the
results of four models: logistic regression, naive Bayes, support vector
machines (SVMs) and random forests. We discover that a SVM model achieves the
best accuracy of 20.95% for predicting someones complete personality type.
However, logistic regression models perform only marginally worse and are
significantly faster to train and perform predictions. We discover that many
labelled datasets present substantial class imbalances of personal
characteristics on social media, including our own. As a result, we highlight
the need for attentive consideration when reporting model performance on these
datasets and compare a number of methods for fixing the class-imbalance
problems. Moreover, we develop a statistical framework for assessing the
importance of different sets of features in our models. We discover some
features to be more informative than others in the Intuitive/Sensory (p =
0.032) and Thinking/Feeling (p = 0.019) models. While we apply these methods to
Myers-Briggs personality profiling, they could be more generally used for any
labelling of individuals on social media.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13066" title="Abstract">arXiv:2309.13066</a> [<a href="/pdf/2309.13066" title="Download PDF">pdf</a>, <a href="/format/2309.13066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Discovery and Counterfactual Explanations for Personalized  Student Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+B+I">Bevan I. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">The paper focuses on identifying the causes of student performance to provide
personalized recommendations for improving pass rates. We introduce the need to
move beyond predictive models and instead identify causal relationships. We
propose using causal discovery techniques to achieve this. The study's main
contributions include using causal discovery to identify causal predictors of
student performance and applying counterfactual analysis to provide
personalized recommendations. The paper describes the application of causal
discovery methods, specifically the PC algorithm, to real-life student
performance data. It addresses challenges such as sample size limitations and
emphasizes the role of domain knowledge in causal discovery. The results reveal
the identified causal relationships, such as the influence of earlier test
grades and mathematical ability on final student performance. Limitations of
this study include the reliance on domain expertise for accurate causal
discovery, and the necessity of larger sample sizes for reliable results. The
potential for incorrect causal structure estimations is acknowledged. A major
challenge remains, which is the real-time implementation and validation of
counterfactual recommendations. In conclusion, the paper demonstrates the value
of causal discovery for understanding student performance and providing
personalized recommendations. It highlights the challenges, benefits, and
limitations of using causal inference in an educational context, setting the
stage for future studies to further explore and refine these methods.
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13068" title="Abstract">arXiv:2309.13068</a> [<a href="/pdf/2309.13068" title="Download PDF">pdf</a>, <a href="/format/2309.13068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UNICON: A unified framework for behavior-based consumer segmentation in  e-commerce
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dibak%2C+M">Manuel Dibak</a>, 
<a href="/search/cs?searchtype=author&query=Vlasov%2C+V">Vladimir Vlasov</a>, 
<a href="/search/cs?searchtype=author&query=Karessli%2C+N">Nour Karessli</a>, 
<a href="/search/cs?searchtype=author&query=Dedik%2C+D">Darya Dedik</a>, 
<a href="/search/cs?searchtype=author&query=Malykh%2C+E">Egor Malykh</a>, 
<a href="/search/cs?searchtype=author&query=Wasilewski%2C+J">Jacek Wasilewski</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+T">Ton Torres</a>, 
<a href="/search/cs?searchtype=author&query=Ramallo%2C+A+P">Ana Peleteiro Ramallo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Data-driven personalization is a key practice in fashion e-commerce,
improving the way businesses serve their consumers needs with more relevant
content. While hyper-personalization offers highly targeted experiences to each
consumer, it requires a significant amount of private data to create an
individualized journey. To alleviate this, group-based personalization provides
a moderate level of personalization built on broader common preferences of a
consumer segment, while still being able to personalize the results. We
introduce UNICON, a unified deep learning consumer segmentation framework that
leverages rich consumer behavior data to learn long-term latent representations
and utilizes them to extract two pivotal types of segmentation catering various
personalization use-cases: lookalike, expanding a predefined target seed
segment with consumers of similar behavior, and data-driven, revealing
non-obvious consumer segments with similar affinities. We demonstrate through
extensive experimentation our framework effectiveness in fashion to identify
lookalike Designer audience and data-driven style segments. Furthermore, we
present experiments that showcase how segment information can be incorporated
in a hybrid recommender system combining hyper and group-based personalization
to exploit the advantages of both alternatives and provide improvements on
consumer experience.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13069" title="Abstract">arXiv:2309.13069</a> [<a href="/pdf/2309.13069" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning Technique Based Fake News Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sutradhar%2C+B+K">Biplob Kumar Sutradhar</a>, 
<a href="/search/cs?searchtype=author&query=Zonaid%2C+M">Md. Zonaid</a>, 
<a href="/search/cs?searchtype=author&query=Ria%2C+N+J">Nushrat Jahan Ria</a>, 
<a href="/search/cs?searchtype=author&query=Noori%2C+S+R+H">Sheak Rashed Haider Noori</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">False news has received attention from both the general public and the
scholarly world. Such false information has the ability to affect public
perception, giving nefarious groups the chance to influence the results of
public events like elections. Anyone can share fake news or facts about anyone
or anything for their personal gain or to cause someone trouble. Also,
information varies depending on the part of the world it is shared on. Thus, in
this paper, we have trained a model to classify fake and true news by utilizing
the 1876 news data from our collected dataset. We have preprocessed the data to
get clean and filtered texts by following the Natural Language Processing
approaches. Our research conducts 3 popular Machine Learning (Stochastic
gradient descent, Na\"ive Bayes, Logistic Regression,) and 2 Deep Learning
(Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms.
After we have found our best Naive Bayes classifier with 56% accuracy and an
F1-macro score of an average of 32%.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13071" title="Abstract">arXiv:2309.13071</a> [<a href="/pdf/2309.13071" title="Download PDF">pdf</a>, <a href="/format/2309.13071" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tree-Based Reconstructive Partitioning: A Novel Low-Data Level  Generation Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halina%2C+E">Emily Halina</a>, 
<a href="/search/cs?searchtype=author&query=Guzdial%2C+M">Matthew Guzdial</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, The 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Procedural Content Generation (PCG) is the algorithmic generation of content,
often applied to games. PCG and PCG via Machine Learning (PCGML) have appeared
in published games. However, it can prove difficult to apply these approaches
in the early stages of an in-development game. PCG requires expertise in
representing designer notions of quality in rules or functions, and PCGML
typically requires significant training data, which may not be available early
in development. In this paper, we introduce Tree-based Reconstructive
Partitioning (TRP), a novel PCGML approach aimed to address this problem. Our
results, across two domains, demonstrate that TRP produces levels that are more
playable and coherent, and that the approach is more generalizable with less
training data. We consider TRP to be a promising new approach that can afford
the introduction of PCGML into the early stages of game development without
requiring human expertise or significant training data.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13072" title="Abstract">arXiv:2309.13072</a> [<a href="/pdf/2309.13072" title="Download PDF">pdf</a>, <a href="/format/2309.13072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Reasoning by Neuro-Symbolic Approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xianggen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhengdong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mou%2C+L">Lili Mou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Compendium of Neurosymbolic Artificial Intelligence, 665--692, 2023, IOS Press
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning has largely improved the performance of various natural
language processing (NLP) tasks. However, most deep learning models are
black-box machinery, and lack explicit interpretation. In this chapter, we will
introduce our recent progress on neuro-symbolic approaches to NLP, which
combines different schools of AI, namely, symbolism and connectionism.
Generally, we will design a neural system with symbolic latent structures for
an NLP task, and apply reinforcement learning or its relaxation to perform
weakly supervised reasoning in the downstream task. Our framework has been
successfully applied to various tasks, including table query reasoning,
syntactic structure reasoning, information extraction reasoning, and rule
reasoning. For each application, we will introduce the background, our
approach, and experimental results.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13075" title="Abstract">arXiv:2309.13075</a> [<a href="/pdf/2309.13075" title="Download PDF">pdf</a>, <a href="/format/2309.13075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCREWS: A Modular Framework for Reasoning with Revisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shridhar%2C+K">Kumar Shridhar</a>, 
<a href="/search/cs?searchtype=author&query=Jhamtani%2C+H">Harsh Jhamtani</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Eisner%2C+J">Jason Eisner</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+P">Patrick Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) can improve their accuracy on various tasks
through iteratively refining and revising their output based on feedback. We
observe that these revisions can introduce errors, in which case it is better
to roll back to a previous result. Further, revisions are typically
homogeneous: they use the same reasoning method that produced the initial
answer, which may not correct errors. To enable exploration in this space, we
present SCREWS, a modular framework for reasoning with revisions. It is
comprised of three main modules: Sampling, Conditional Resampling, and
Selection, each consisting of sub-modules that can be hand-selected per task.
We show that SCREWS not only unifies several previous approaches under a common
framework, but also reveals several novel strategies for identifying improved
reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT
and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning
strategies for each: arithmetic word problems, multi-hop question answering,
and code debugging. Heterogeneous revision strategies prove to be important, as
does selection between original and revised candidates.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13077" title="Abstract">arXiv:2309.13077</a> [<a href="/pdf/2309.13077" title="Download PDF">pdf</a>, <a href="/format/2309.13077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Differentiable Framework for End-to-End Learning of Hybrid Structured  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eo%2C+M">Moonjung Eo</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+S">Suhyun Kang</a>, 
<a href="/search/cs?searchtype=author&query=Rhee%2C+W">Wonjong Rhee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Filter pruning and low-rank decomposition are two of the foundational
techniques for structured compression. Although recent efforts have explored
hybrid approaches aiming to integrate the advantages of both techniques, their
performance gains have been modest at best. In this study, we develop a
\textit{Differentiable Framework~(DF)} that can express filter selection, rank
selection, and budget constraint into a single analytical formulation. Within
the framework, we introduce DML-S for filter selection, integrating scheduling
into existing mask learning techniques. Additionally, we present DTL-S for rank
selection, utilizing a singular value thresholding operator. The framework with
DML-S and DTL-S offers a hybrid structured compression methodology that
facilitates end-to-end learning through gradient-base optimization.
Experimental results demonstrate the efficacy of DF, surpassing
state-of-the-art structured compression methods. Our work establishes a robust
and versatile avenue for advancing structured compression techniques.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13078" title="Abstract">arXiv:2309.13078</a> [<a href="/pdf/2309.13078" title="Download PDF">pdf</a>, <a href="/format/2309.13078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LPML: LLM-Prompting Markup Language for Mathematical Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamauchi%2C+R">Ryutaro Yamauchi</a>, 
<a href="/search/cs?searchtype=author&query=Sonoda%2C+S">Sho Sonoda</a>, 
<a href="/search/cs?searchtype=author&query=Sannai%2C+A">Akiyoshi Sannai</a>, 
<a href="/search/cs?searchtype=author&query=Kumagai%2C+W">Wataru Kumagai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Programming Languages (cs.PL)

</div>
<p class="mathjax">In utilizing large language models (LLMs) for mathematical reasoning,
addressing the errors in the reasoning and calculation present in the generated
text by LLMs is a crucial challenge. In this paper, we propose a novel
framework that integrates the Chain-of-Thought (CoT) method with an external
tool (Python REPL). We discovered that by prompting LLMs to generate structured
text in XML-like markup language, we could seamlessly integrate CoT and the
external tool and control the undesired behaviors of LLMs. With our approach,
LLMs can utilize Python computation to rectify errors within CoT. We applied
our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and
demonstrated that combining CoT and Python REPL through the markup language
enhances the reasoning capability of LLMs. Our approach enables LLMs to write
the markup language and perform advanced mathematical reasoning using only
zero-shot prompting.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13079" title="Abstract">arXiv:2309.13079</a> [<a href="/pdf/2309.13079" title="Download PDF">pdf</a>, <a href="/format/2309.13079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for  Domain-specific Large Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yidong Liu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Shang%2C+F">FuKai Shang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yao Li</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Rui Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">With the advancement of deep learning technologies, general-purpose large
models such as GPT-4 have demonstrated exceptional capabilities across various
domains. Nevertheless, there remains a demand for high-quality, domain-specific
outputs in areas like healthcare, law, and finance. This paper first evaluates
the existing large models for specialized domains and discusses their
limitations. To cater to the specific needs of certain domains, we introduce
the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and
governmental sectors. The dataset, sourced from publicly available internet
data from 2022, underwent multiple rounds of cleansing and processing to ensure
high quality and reliable origins, with provisions for consistent and stable
updates. This dataset not only supports the pre-training of large models for
Chinese vertical domains but also aids in propelling deep learning research and
applications in related fields.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13080" title="Abstract">arXiv:2309.13080</a> [<a href="/pdf/2309.13080" title="Download PDF">pdf</a>, <a href="/ps/2309.13080" title="Download PostScript">ps</a>, <a href="/format/2309.13080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPICED: News Similarity Detection Dataset with Multiple Topics and  Complexity Levels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shushkevich%2C+E">Elena Shushkevich</a>, 
<a href="/search/cs?searchtype=author&query=Mai%2C+L">Long Mai</a>, 
<a href="/search/cs?searchtype=author&query=Loureiro%2C+M+V">Manuel V. Loureiro</a>, 
<a href="/search/cs?searchtype=author&query=Derby%2C+S">Steven Derby</a>, 
<a href="/search/cs?searchtype=author&query=Wijaya%2C+T+K">Tri Kurniawan Wijaya</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Nowadays, the use of intelligent systems to detect redundant information in
news articles has become especially prevalent with the proliferation of news
media outlets in order to enhance user experience. However, the heterogeneous
nature of news can lead to spurious findings in these systems: Simple
heuristics such as whether a pair of news are both about politics can provide
strong but deceptive downstream performance. Segmenting news similarity
datasets into topics improves the training of these models by forcing them to
learn how to distinguish salient characteristics under more narrow domains.
However, this requires the existence of topic-specific datasets, which are
currently lacking. In this article, we propose a new dataset of similar news,
SPICED, which includes seven topics: Crime &amp; Law, Culture &amp; Entertainment,
Disasters &amp; Accidents, Economy &amp; Business, Politics &amp; Conflicts, Science &amp;
Technology, and Sports. Futhermore, we present four distinct approaches for
generating news pairs, which are used in the creation of datasets specifically
designed for news similarity detection task. We benchmarked the created
datasets using MinHash, BERT, SBERT, and SimCSE models.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13081" title="Abstract">arXiv:2309.13081</a> [<a href="/pdf/2309.13081" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transitioning To The Digital Generation Case Studies (Previous Digital  Point Studies In Japan Cases:1993-2023)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawahata%2C+Y">Yasuko Kawahata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Part of the 22nd IEEE WIC International Conference on Web Intelligence and Intelligent Agent Technology WI-IAT2023, Workshop of The 8th International Workshop on Application of Big Data for Computational Social Science, WI Artificial Intelligence in the Connected World October 26-29, 2023, Venice, Italy
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">In this paper, we discuss at The 8th International Workshop on Application of
Big Data for Computational Social Science, October 26-29, 2023, Venice, Italy.
To achieve the realization of the Global and Innovation Gateway for All (GIGA)
initiative (2019), proposed in December 2019 by the Primary and Secondary
Education Planning Division of the Elementary and Secondary Education Bureau of
the Ministry of Education, Culture, Sports, Science and Technology, a movement
has emerged to utilize information and communication technology (ICT) in the
field of education. The history of ICT education in Japan dates back to the 100
Schools Project (1994), which aimed to provide network access environments, and
the New 100 Schools Project (1997), which marked the beginning of full-scale
ICT education in Japan. In this paper, we discuss the usage dynamics of
smartphone-based learning applications among young people (analyzing data from
January to September 2020) and their current status. Further, the results are
summarized and future research topics and issues are discussed. The results
show that there are situations in which ICT learning environments can be
effectively utilized and others in which they cannot, depending on the
differences between digital students and analog students who utilize ICT in
their studies; this indicates that we are currently in a transition to a
generation of digital natives. ICT education has both advantages and
disadvantages, and it is expected that it will be used in combination with
conventional educational methods while assessing the characteristics of ICT
education in the future. Of course, there are many challenges. We plan to
discuss how to appeal in this regard at the Workshop.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13085" title="Abstract">arXiv:2309.13085</a> [<a href="/pdf/2309.13085" title="Download PDF">pdf</a>, <a href="/format/2309.13085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does My Dog &#x27;&#x27;Speak&#x27;&#x27; Like Me? The Acoustic Correlation between Pet Dogs  and Their Human Owners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jieyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kenny Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">How hosts language influence their pets' vocalization is an interesting yet
underexplored problem. This paper presents a preliminary investigation into the
possible correlation between domestic dog vocal expressions and their human
host's language environment. We first present a new dataset of Shiba Inu dog
vocals from YouTube, which provides 7500 clean sound clips, including their
contextual information of these vocals and their owner's speech clips with a
carefully-designed data processing pipeline. The contextual information
includes the scene category in which the vocal was recorded, the dog's location
and activity. With a classification task and prominent factor analysis, we
discover significant acoustic differences in the dog vocals from the two
language environments. We further identify some acoustic features from dog
vocalizations that are potentially correlated to their host language patterns.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13086" title="Abstract">arXiv:2309.13086</a> [<a href="/pdf/2309.13086" title="Download PDF">pdf</a>, <a href="/format/2309.13086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Lexical Analysis of Dog Vocalizations via Online Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yufei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chunhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jieyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+K">Kenny Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Deciphering the semantics of animal language has been a grand challenge. This
study presents a data-driven investigation into the semantics of dog
vocalizations via correlating different sound types with consistent semantics.
We first present a new dataset of Shiba Inu sounds, along with contextual
information such as location and activity, collected from YouTube with a
well-constructed pipeline. The framework is also applicable to other animal
species. Based on the analysis of conditioned probability between dog
vocalizations and corresponding location and activity, we discover supporting
evidence for previous heuristic research on the semantic meaning of various dog
sounds. For instance, growls can signify interactions. Furthermore, our study
yields new insights that existing word types can be subdivided into
finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related.
For example, whimper can be subdivided into two types, attention-seeking and
discomfort.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13087" title="Abstract">arXiv:2309.13087</a> [<a href="/pdf/2309.13087" title="Download PDF">pdf</a>, <a href="/format/2309.13087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning algorithms for identification of whisky using portable Raman  spectroscopy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+J">Kwang Jun Lee</a>, 
<a href="/search/cs?searchtype=author&query=Trowbridge%2C+A+C">Alexander C. Trowbridge</a>, 
<a href="/search/cs?searchtype=author&query=Bruce%2C+G+D">Graham D. Bruce</a>, 
<a href="/search/cs?searchtype=author&query=Dwapanyin%2C+G+O">George O. Dwapanyin</a>, 
<a href="/search/cs?searchtype=author&query=Dunning%2C+K+R">Kylie R. Dunning</a>, 
<a href="/search/cs?searchtype=author&query=Dholakia%2C+K">Kishan Dholakia</a>, 
<a href="/search/cs?searchtype=author&query=Schartner%2C+E+P">Erik P. Schartner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 4 figures, 2 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Reliable identification of high-value products such as whisky is an
increasingly important area, as issues such as brand substitution (i.e.
fraudulent products) and quality control are critical to the industry. We have
examined a range of machine learning algorithms and interfaced them directly
with a portable Raman spectroscopy device to both identify and characterize the
ethanol/methanol concentrations of commercial whisky samples. We demonstrate
that machine learning models can achieve over 99% accuracy in brand
identification across twenty-eight commercial samples. To demonstrate the
flexibility of this approach we utilised the same samples and algorithms to
quantify ethanol concentrations, as well as measuring methanol levels in spiked
whisky samples. Our machine learning techniques are then combined with a
through-the-bottle method to perform spectral analysis and identification
without requiring the sample to be decanted from the original container,
showing the practical potential of this approach to the detection of
counterfeit or adulterated spirits and other high value liquid samples.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13092" title="Abstract">arXiv:2309.13092</a> [<a href="/pdf/2309.13092" title="Download PDF">pdf</a>, <a href="/format/2309.13092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prototype-Enhanced Hypergraph Learning for Heterogeneous Information  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiayi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Efthymiou%2C+A">Athanasios Efthymiou</a>, 
<a href="/search/cs?searchtype=author&query=Rudinac%2C+S">Stevan Rudinac</a>, 
<a href="/search/cs?searchtype=author&query=Kackovic%2C+M">Monika Kackovic</a>, 
<a href="/search/cs?searchtype=author&query=Wijnberg%2C+N">Nachoem Wijnberg</a>, 
<a href="/search/cs?searchtype=author&query=Worring%2C+M">Marcel Worring</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The variety and complexity of relations in multimedia data lead to
Heterogeneous Information Networks (HINs). Capturing the semantics from such
networks requires approaches capable of utilizing the full richness of the
HINs. Existing methods for modeling HINs employ techniques originally designed
for graph neural networks, and HINs decomposition analysis, like using manually
predefined metapaths. In this paper, we introduce a novel prototype-enhanced
hypergraph learning approach for node classification in HINs. Using hypergraphs
instead of graphs, our method captures higher-order relationships among nodes
and extracts semantic information without relying on metapaths. Our method
leverages the power of prototypes to improve the robustness of the hypergraph
learning process and creates the potential to provide human-interpretable
insights into the underlying network structure. Extensive experiments on three
real-world HINs demonstrate the effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13094" title="Abstract">arXiv:2309.13094</a> [<a href="/pdf/2309.13094" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computational Natural Philosophy: A Thread from Presocratics through  Turing to ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dodig-Crnkovic%2C+G">Gordana Dodig-Crnkovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Literature (cs.GL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Modern computational natural philosophy conceptualizes the universe in terms
of information and computation, establishing a framework for the study of
cognition and intelligence. Despite some critiques, this computational
perspective has significantly influenced our understanding of the natural
world, leading to the development of AI systems like ChatGPT based on deep
neural networks. Advancements in this domain have been facilitated by
interdisciplinary research, integrating knowledge from multiple fields to
simulate complex systems. Large Language Models (LLMs), such as ChatGPT,
represent this approach's capabilities, utilizing reinforcement learning with
human feedback (RLHF). Current research initiatives aim to integrate neural
networks with symbolic computing, introducing a new generation of hybrid
computational models.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13095" title="Abstract">arXiv:2309.13095</a> [<a href="/pdf/2309.13095" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Independent DE Optimizations to Tackle Uncertainty and  Variability in Demand in Inventory Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Sukanya Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+V">Vivek Mishra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 2 figures, 6 tables, IEEE (ICITEE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">To determine the effectiveness of metaheuristic Differential Evolution
optimization strategy for inventory management (IM) in the context of
stochastic demand, this empirical study undertakes a thorough investigation.
The primary objective is to discern the most effective strategy for minimizing
inventory costs within the context of uncertain demand patterns. Inventory
costs refer to the expenses associated with holding and managing inventory
within a business. The approach combines a continuous review of IM policies
with a Monte Carlo Simulation (MCS). To find the optimal solution, the study
focuses on meta-heuristic approaches and compares multiple algorithms. The
outcomes reveal that the Differential Evolution (DE) algorithm outperforms its
counterparts in optimizing IM. To fine-tune the parameters, the study employs
the Latin Hypercube Sampling (LHS) statistical method. To determine the final
solution, a method is employed in this study which combines the outcomes of
multiple independent DE optimizations, each initiated with different random
initial conditions. This approach introduces a novel and promising dimension to
the field of inventory management, offering potential enhancements in
performance and cost efficiency, especially in the presence of stochastic
demand patterns.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13097" title="Abstract">arXiv:2309.13097</a> [<a href="/pdf/2309.13097" title="Download PDF">pdf</a>, <a href="/format/2309.13097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Object Counting with Language-Vision Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jingyi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+H">Hieu Le</a>, 
<a href="/search/cs?searchtype=author&query=Samaras%2C+D">Dimitris Samaras</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of CVPR23 <a href="/abs/2303.02001">arXiv:2303.02001</a> . Currently under review at T-PAMI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Class-agnostic object counting aims to count object instances of an arbitrary
class at test time. It is challenging but also enables many potential
applications. Current methods require human-annotated exemplars as inputs which
are often unavailable for novel categories, especially for autonomous systems.
Thus, we propose zero-shot object counting (ZSC), a new setting where only the
class name is available during test time. This obviates the need for human
annotators and enables automated operation. To perform ZSC, we propose finding
a few object crops from the input image and use them as counting exemplars. The
goal is to identify patches containing the objects of interest while also being
visually representative for all instances in the image. To do this, we first
construct class prototypes using large language-vision models, including CLIP
and Stable Diffusion, to select the patches containing the target objects.
Furthermore, we propose a ranking model that estimates the counting error of
each patch to select the most suitable exemplars for counting. Experimental
results on a recent class-agnostic counting dataset, FSC-147, validate the
effectiveness of our method.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13098" title="Abstract">arXiv:2309.13098</a> [<a href="/pdf/2309.13098" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Data Mapping of Online Hate Speech, Misinformation, and  General Mental Health: A Large Language Model Based Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alexander%2C+A">Andrew Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongbin Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 43 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Topology (math.AT); Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">The advent of social media has led to an increased concern over its potential
to propagate hate speech and misinformation, which, in addition to contributing
to prejudice and discrimination, has been suspected of playing a role in
increasing social violence and crimes in the United States. While literature
has shown the existence of an association between posting hate speech and
misinformation online and certain personality traits of posters, the general
relationship and relevance of online hate speech/misinformation in the context
of overall psychological wellbeing of posters remain elusive. One difficulty
lies in the lack of adequate data analytics tools capable of adequately
analyzing the massive amount of social media posts to uncover the underlying
hidden links. Recent progresses in machine learning and large language models
such as ChatGPT have made such an analysis possible. In this study, we
collected thousands of posts from carefully selected communities on the social
media site Reddit. We then utilized OpenAI's GPT3 to derive embeddings of these
posts, which are high-dimensional real-numbered vectors that presumably
represent the hidden semantics of posts. We then performed various
machine-learning classifications based on these embeddings in order to
understand the role of hate speech/misinformation in various communities.
Finally, a topological data analysis (TDA) was applied to the embeddings to
obtain a visual map connecting online hate speech, misinformation, various
psychiatric disorders, and general mental health.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13099" title="Abstract">arXiv:2309.13099</a> [<a href="/pdf/2309.13099" title="Download PDF">pdf</a>, <a href="/format/2309.13099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lamarck&#x27;s Revenge: Inheritance of Learned Traits Can Make Robot  Evolution Better
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Miras%2C+K">Karine Miras</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J">Jakub Tomczak</a>, 
<a href="/search/cs?searchtype=author&query=Eiben%2C+A+E">Agoston E. Eiben</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint-nature scientific report. arXiv admin note: text overlap with <a href="/abs/2303.12594">arXiv:2303.12594</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Evolutionary robot systems offer two principal advantages: an advanced way of
developing robots through evolutionary optimization and a special research
platform to conduct what-if experiments regarding questions about evolution.
Our study sits at the intersection of these. We investigate the question ``What
if the 18th-century biologist Lamarck was not completely wrong and individual
traits learned during a lifetime could be passed on to offspring through
inheritance?'' We research this issue through simulations with an evolutionary
robot framework where morphologies (bodies) and controllers (brains) of robots
are evolvable and robots also can improve their controllers through learning
during their lifetime. Within this framework, we compare a Lamarckian system,
where learned bits of the brain are inheritable, with a Darwinian system, where
they are not. Analyzing simulations based on these systems, we obtain new
insights about Lamarckian evolution dynamics and the interaction between
evolution and learning. Specifically, we show that Lamarckism amplifies the
emergence of `morphological intelligence', the ability of a given robot body to
acquire a good brain by learning, and identify the source of this success:
`newborn' robots have a higher fitness because their inherited brains match
their bodies better than those in a Darwinian system.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13101" title="Abstract">arXiv:2309.13101</a> [<a href="/pdf/2309.13101" title="Download PDF">pdf</a>, <a href="/format/2309.13101" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable 3D Gaussians for High-Fidelity Monocular Dynamic Scene  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Ziyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xinyu Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+S">Shaohui Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xiaogang Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Implicit neural representation has opened up new avenues for dynamic scene
reconstruction and rendering. Nonetheless, state-of-the-art methods of dynamic
neural rendering rely heavily on these implicit representations, which
frequently struggle with accurately capturing the intricate details of objects
in the scene. Furthermore, implicit methods struggle to achieve real-time
rendering in general dynamic scenes, limiting their use in a wide range of
tasks. To address the issues, we propose a deformable 3D Gaussians Splatting
method that reconstructs scenes using explicit 3D Gaussians and learns
Gaussians in canonical space with a deformation field to model monocular
dynamic scenes. We also introduced a smoothing training mechanism with no extra
overhead to mitigate the impact of inaccurate poses in real datasets on the
smoothness of time interpolation tasks. Through differential gaussian
rasterization, the deformable 3D Gaussians not only achieve higher rendering
quality but also real-time rendering speed. Experiments show that our method
outperforms existing methods significantly in terms of both rendering quality
and speed, making it well-suited for tasks such as novel-view synthesis, time
synthesis, and real-time rendering.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13103" title="Abstract">arXiv:2309.13103</a> [<a href="/pdf/2309.13103" title="Download PDF">pdf</a>, <a href="/format/2309.13103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OpportunityFinder: A Framework for Automated Causal Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Huy Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Grover%2C+P">Prince Grover</a>, 
<a href="/search/cs?searchtype=author&query=Khatwani%2C+D">Devashish Khatwani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> KDD 2023 Workshop - Causal Inference and Machine Learning in Practice
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">We introduce OpportunityFinder, a code-less framework for performing a
variety of causal inference studies with panel data for non-expert users. In
its current state, OpportunityFinder only requires users to provide raw
observational data and a configuration file. A pipeline is then triggered that
inspects/processes data, chooses the suitable algorithm(s) to execute the
causal study. It returns the causal impact of the treatment on the configured
outcome, together with sensitivity and robustness results. Causal inference is
widely studied and used to estimate the downstream impact of individual's
interactions with products and features. It is common that these causal studies
are performed by scientists and/or economists periodically. Business
stakeholders are often bottle-necked on scientist or economist bandwidth to
conduct causal studies. We offer OpportunityFinder as a solution for commonly
performed causal studies with four key features: (1) easy to use for both
Business Analysts and Scientists, (2) abstraction of multiple algorithms under
a single I/O interface, (3) support for causal impact analysis under binary
treatment with panel data and (4) dynamic selection of algorithm based on scale
of data.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13119" title="Abstract">arXiv:2309.13119</a> [<a href="/pdf/2309.13119" title="Download PDF">pdf</a>, <a href="/format/2309.13119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-Based Motion Planning: A Comparative Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Orthey%2C+A">Andreas Orthey</a>, 
<a href="/search/cs?searchtype=author&query=Chamzas%2C+C">Constantinos Chamzas</a>, 
<a href="/search/cs?searchtype=author&query=Kavraki%2C+L+E">Lydia E. Kavraki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures, Accepted for Volume 7 (2024) of the Annual Review of Control, Robotics, and Autonomous Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Sampling-based motion planning is one of the fundamental paradigms to
generate robot motions, and a cornerstone of robotics research. This
comparative review provides an up-to-date guideline and reference manual for
the use of sampling-based motion planning algorithms. This includes a history
of motion planning, an overview about the most successful planners, and a
discussion on their properties. It is also shown how planners can handle
special cases and how extensions of motion planning can be accommodated. To put
sampling-based motion planning into a larger context, a discussion of
alternative motion generation frameworks is presented which highlights their
respective differences to sampling-based motion planning. Finally, a set of
sampling-based motion planners are compared on 24 challenging planning
problems. This evaluation gives insights into which planners perform well in
which situations and where future research would be required. This comparative
review thereby provides not only a useful reference manual for researchers in
the field, but also a guideline for practitioners to make informed algorithmic
decisions.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13130" title="Abstract">arXiv:2309.13130</a> [<a href="/pdf/2309.13130" title="Download PDF">pdf</a>, <a href="/format/2309.13130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Insights from an OTTR-centric Ontology Engineering Methodology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Blum%2C+M">Moritz Blum</a>, 
<a href="/search/cs?searchtype=author&query=Ell%2C+B">Basil Ell</a>, 
<a href="/search/cs?searchtype=author&query=Cimiano%2C+P">Philipp Cimiano</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Paper accepted at the 14th Workshop on Ontology Design and Patterns (WOP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">OTTR is a language for representing ontology modeling patterns, which enables
to build ontologies or knowledge bases by instantiating templates. Thereby,
particularities of the ontological representation language are hidden from the
domain experts, and it enables ontology engineers to, to some extent, separate
the processes of deciding about what information to model from deciding about
how to model the information, e.g., which design patterns to use. Certain
decisions can thus be postponed for the benefit of focusing on one of these
processes. To date, only few works on ontology engineering where ontology
templates are applied are described in the literature.
<br />In this paper, we outline our methodology and report findings from our
ontology engineering activities in the domain of Material Science. In these
activities, OTTR templates play a key role. Our ontology engineering process is
bottom-up, as we begin modeling activities from existing data that is then, via
templates, fed into a knowledge graph, and it is top-down, as we first focus on
which data to model and postpone the decision of how to model the data.
<br />We find, among other things, that OTTR templates are especially useful as a
means of communication with domain experts. Furthermore, we find that because
OTTR templates encapsulate modeling decisions, the engineering process becomes
flexible, meaning that design decisions can be changed at little cost.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13132" title="Abstract">arXiv:2309.13132</a> [<a href="/pdf/2309.13132" title="Download PDF">pdf</a>, <a href="/format/2309.13132" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding Calibration of Deep Neural Networks for Medical Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sambyal%2C+A+S">Abhishek Singh Sambyal</a>, 
<a href="/search/cs?searchtype=author&query=Niyaz%2C+U">Usma Niyaz</a>, 
<a href="/search/cs?searchtype=author&query=Krishnan%2C+N+C">Narayanan C. Krishnan</a>, 
<a href="/search/cs?searchtype=author&query=Bathula%2C+D+R">Deepti R. Bathula</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Computer Methods and Programs in Biomedicine Journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of medical image analysis, achieving high accuracy is not
enough; ensuring well-calibrated predictions is also crucial. Confidence scores
of a deep neural network play a pivotal role in explainability by providing
insights into the model's certainty, identifying cases that require attention,
and establishing trust in its predictions. Consequently, the significance of a
well-calibrated model becomes paramount in the medical imaging domain, where
accurate and reliable predictions are of utmost importance. While there has
been a significant effort towards training modern deep neural networks to
achieve high accuracy on medical imaging tasks, model calibration and factors
that affect it remain under-explored. To address this, we conducted a
comprehensive empirical study that explores model performance and calibration
under different training regimes. We considered fully supervised training,
which is the prevailing approach in the community, as well as rotation-based
self-supervised method with and without transfer learning, across various
datasets and architecture sizes. Multiple calibration metrics were employed to
gain a holistic understanding of model calibration. Our study reveals that
factors such as weight distributions and the similarity of learned
representations correlate with the calibration trends observed in the models.
Notably, models trained using rotation-based self-supervised pretrained regime
exhibit significantly better calibration while achieving comparable or even
superior performance compared to fully supervised models across different
medical imaging datasets. These findings shed light on the importance of model
calibration in medical image analysis and highlight the benefits of
incorporating self-supervised learning approach to improve both performance and
calibration.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13135" title="Abstract">arXiv:2309.13135</a> [<a href="/pdf/2309.13135" title="Download PDF">pdf</a>, <a href="/format/2309.13135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting Response to Treatment with Deep Learning and Pharmacokinetic  Priors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Potosnak%2C+W">Willa Potosnak</a>, 
<a href="/search/cs?searchtype=author&query=Challu%2C+C">Cristian Challu</a>, 
<a href="/search/cs?searchtype=author&query=Olivares%2C+K+G">Kin G. Olivares</a>, 
<a href="/search/cs?searchtype=author&query=Dubrawski%2C+A">Artur Dubrawski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Forecasting healthcare time series is crucial for early detection of adverse
outcomes and for patient monitoring. Forecasting, however, can be difficult in
practice due to noisy and intermittent data. The challenges are often
exacerbated by change points induced via extrinsic factors, such as the
administration of medication. We propose a novel encoder that informs deep
learning models of the pharmacokinetic effects of drugs to allow for accurate
forecasting of time series affected by treatment. We showcase the effectiveness
of our approach in a task to forecast blood glucose using both realistically
simulated and real-world data. Our pharmacokinetic encoder helps deep learning
models surpass baselines by approximately 11% on simulated data and 8% on
real-world data. The proposed approach can have multiple beneficial
applications in clinical practice, such as issuing early warnings about
unexpected treatment responses, or helping to characterize patient-specific
treatment effects in terms of drug absorption and elimination characteristics.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13136" title="Abstract">arXiv:2309.13136</a> [<a href="/pdf/2309.13136" title="Download PDF">pdf</a>, <a href="/format/2309.13136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contextual Emotion Estimation from Image Captions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+V">Vera Yang</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Archita Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Etesam%2C+Y">Yasaman Etesam</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chuxuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+A">Angelica Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACII 2023. Project page: <a href="http://rosielab.github.io/emotion-captions/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Emotion estimation in images is a challenging task, typically using computer
vision methods to directly estimate people's emotions using face, body pose and
contextual cues. In this paper, we explore whether Large Language Models (LLMs)
can support the contextual emotion estimation task, by first captioning images,
then using an LLM for inference. First, we must understand: how well do LLMs
perceive human emotions? And which parts of the information enable them to
determine emotions? One initial challenge is to construct a caption that
describes a person within a scene with information relevant for emotion
perception. Towards this goal, we propose a set of natural language descriptors
for faces, bodies, interactions, and environments. We use them to manually
generate captions and emotion annotations for a subset of 331 images from the
EMOTIC dataset. These captions offer an interpretable representation for
emotion estimation, towards understanding how elements of a scene affect
emotion perception in LLMs and beyond. Secondly, we test the capability of a
large language model to infer an emotion from the resulting image captions. We
find that GPT-3.5, specifically the text-davinci-003 model, provides
surprisingly reasonable emotion predictions consistent with human annotations,
but accuracy can depend on the emotion concept. Overall, the results suggest
promise in the image captioning and LLM approach.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13137" title="Abstract">arXiv:2309.13137</a> [<a href="/pdf/2309.13137" title="Download PDF">pdf</a>, <a href="/format/2309.13137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trading-off Mutual Information on Feature Aggregation for Face  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Akyash%2C+M">Mohammad Akyash</a>, 
<a href="/search/cs?searchtype=author&query=Zafari%2C+A">Ali Zafari</a>, 
<a href="/search/cs?searchtype=author&query=Nasrabadi%2C+N+M">Nasser M. Nasrabadi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to 22$^{nd}$ IEEE International Conference on Machine Learning and Applications 2023 (ICMLA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the advances in the field of Face Recognition (FR), the precision of
these methods is not yet sufficient. To improve the FR performance, this paper
proposes a technique to aggregate the outputs of two state-of-the-art (SOTA)
deep FR models, namely ArcFace and AdaFace. In our approach, we leverage the
transformer attention mechanism to exploit the relationship between different
parts of two feature maps. By doing so, we aim to enhance the overall
discriminative power of the FR system. One of the challenges in feature
aggregation is the effective modeling of both local and global dependencies.
Conventional transformers are known for their ability to capture long-range
dependencies, but they often struggle with modeling local dependencies
accurately. To address this limitation, we augment the self-attention mechanism
to capture both local and global dependencies effectively. This allows our
model to take advantage of the overlapping receptive fields present in
corresponding locations of the feature maps. However, fusing two feature maps
from different FR models might introduce redundancies to the face embedding.
Since these models often share identical backbone architectures, the resulting
feature maps may contain overlapping information, which can mislead the
training process. To overcome this problem, we leverage the principle of
Information Bottleneck to obtain a maximally informative facial representation.
This ensures that the aggregated features retain the most relevant and
discriminative information while minimizing redundant or misleading details. To
evaluate the effectiveness of our proposed method, we conducted experiments on
popular benchmarks and compared our results with state-of-the-art algorithms.
The consistent improvement we observed in these benchmarks demonstrates the
efficacy of our approach in enhancing FR performance.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13139" title="Abstract">arXiv:2309.13139</a> [<a href="/pdf/2309.13139" title="Download PDF">pdf</a>, <a href="/format/2309.13139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exposing the Unseen: Exposure Time Emulation for Offline Benchmarking of  Vision Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gamache%2C+O">Olivier Gamache</a>, 
<a href="/search/cs?searchtype=author&query=Fortin%2C+J">Jean-Michel Fortin</a>, 
<a href="/search/cs?searchtype=author&query=Boxan%2C+M">Mat&#x11b;j Boxan</a>, 
<a href="/search/cs?searchtype=author&query=Pomerleau%2C+F">Fran&#xe7;ois Pomerleau</a>, 
<a href="/search/cs?searchtype=author&query=Gigu%C3%A8re%2C+P">Philippe Gigu&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures, submitted to 2024 IEEE International Conference on Robotics and Automation (ICRA 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Visual Odometry (VO) is one of the fundamental tasks in computer vision for
robotics. However, its performance is deeply affected by High Dynamic Range
(HDR) scenes, omnipresent outdoor. While new Automatic-Exposure (AE) approaches
to mitigate this have appeared, their comparison in a reproducible manner is
problematic. This stems from the fact that the behavior of AE depends on the
environment, and it affects the image acquisition process. Consequently, AE has
traditionally only been benchmarked in an online manner, making the experiments
non-reproducible. To solve this, we propose a new methodology based on an
emulator that can generate images at any exposure time. It leverages BorealHDR,
a unique multi-exposure stereo dataset collected over 8.4 km, on 50
trajectories with challenging illumination conditions. Moreover, it contains
pose ground truth for each image and a global 3D map, based on lidar data. We
show that using these images acquired at different exposure times, we can
emulate realistic images keeping a Root-Mean-Square Error (RMSE) below 1.78 %
compared to ground truth images. To demonstrate the practicality of our
approach for offline benchmarking, we compared three state-of-the-art AE
algorithms on key elements of Visual Simultaneous Localization And Mapping
(VSLAM) pipeline, against four baselines. Consequently, reproducible evaluation
of AE is now possible, speeding up the development of future approaches. Our
code and dataset are available online at this link:
https://github.com/norlab-ulaval/BorealHDR
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13144" title="Abstract">arXiv:2309.13144</a> [<a href="/pdf/2309.13144" title="Download PDF">pdf</a>, <a href="/format/2309.13144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SoRTS: Learned Tree Search for Long Horizon Social Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Navarro%2C+I">Ingrid Navarro</a>, 
<a href="/search/cs?searchtype=author&query=Patrikar%2C+J">Jay Patrikar</a>, 
<a href="/search/cs?searchtype=author&query=Dantas%2C+J+P+A">Joao P. A. Dantas</a>, 
<a href="/search/cs?searchtype=author&query=Baijal%2C+R">Rohan Baijal</a>, 
<a href="/search/cs?searchtype=author&query=Higgins%2C+I">Ian Higgins</a>, 
<a href="/search/cs?searchtype=author&query=Scherer%2C+S">Sebastian Scherer</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jean Oh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.01428">arXiv:2304.01428</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The fast-growing demand for fully autonomous robots in shared spaces calls
for the development of trustworthy agents that can safely and seamlessly
navigate in crowded environments. Recent models for motion prediction show
promise in characterizing social interactions in such environments. Still,
adapting them for navigation is challenging as they often suffer from
generalization failures. Prompted by this, we propose Social Robot Tree Search
(SoRTS), an algorithm for safe robot navigation in social domains. SoRTS aims
to augment existing socially aware motion prediction models for long-horizon
navigation using Monte Carlo Tree Search.
<br />We use social navigation in general aviation as a case study to evaluate our
approach and further the research in full-scale aerial autonomy. In doing so,
we introduce XPlaneROS, a high-fidelity aerial simulator that enables
human-robot interaction. We use XPlaneROS to conduct a first-of-its-kind user
study where 26 FAA-certified pilots interact with a human pilot, our algorithm,
and its ablation. Our results, supported by statistical evidence, show that
SoRTS exhibits a comparable performance to competent human pilots,
significantly outperforming its ablation. Finally, we complement these results
with a broad set of self-play experiments to showcase our algorithm's
performance in scenarios with increasing complexity.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13147" title="Abstract">arXiv:2309.13147</a> [<a href="/pdf/2309.13147" title="Download PDF">pdf</a>, <a href="/format/2309.13147" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cardiovascular Disease Risk Prediction via Social Media
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Habib%2C+A+Z+S+B">Al Zadid Sultan Bin Habib</a>, 
<a href="/search/cs?searchtype=author&query=Syed%2C+M+A+B">Md Asif Bin Syed</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+T">Md Tanvirul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Adjeroh%2C+D+A">Donald A. Adjeroh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 3 figures, 16th International Conference on Social Computing, Behavioral-Cultural Modeling &amp; Prediction and Behavior Representation in Modeling and Simulation (SBP-BRiMS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Researchers utilize Twitter and sentiment analysis to forecast the risk of
Cardiovascular Disease (CVD). We have introduced a novel CVD-related keyword
dictionary by scrutinizing the emotions conveyed in tweets. We gathered tweets
from eighteen U.S. states, encompassing the Appalachian region. Employing the
VADER model for sentiment analysis, we categorized users as potentially at risk
for CVD. Machine Learning (ML) models were employed to assess individuals' CVD
risk and were subsequently applied to a CDC dataset containing demographic
information for comparison. We considered various performance evaluation
metrics, including Test Accuracy, Precision, Recall, F1 score, Mathew's
Correlation Coefficient (MCC), and Cohen's Kappa (CK) score. Our findings
demonstrate that analyzing the emotional content of tweets outperforms the
predictive capabilities of demographic data alone, enabling the identification
of individuals at potential risk of developing CVD. This research underscores
the potential of Natural Language Processing (NLP) and ML techniques in
leveraging tweets to identify individuals with CVD risks, offering an
alternative approach to traditional demographic information for public health
monitoring.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13150" title="Abstract">arXiv:2309.13150</a> [<a href="/pdf/2309.13150" title="Download PDF">pdf</a>, <a href="/format/2309.13150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pixel-wise Smoothing for Certified Robustness against Camera Motion  Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hanjiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zuxin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Linyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 5 figures, 13 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">In recent years, computer vision has made remarkable advancements in
autonomous driving and robotics. However, it has been observed that deep
learning-based visual perception models lack robustness when faced with camera
motion perturbations. The current certification process for assessing
robustness is costly and time-consuming due to the extensive number of image
projections required for Monte Carlo sampling in the 3D camera motion space. To
address these challenges, we present a novel, efficient, and practical
framework for certifying the robustness of 3D-2D projective transformations
against camera motion perturbations. Our approach leverages a smoothing
distribution over the 2D pixel space instead of in the 3D physical space,
eliminating the need for costly camera motion sampling and significantly
enhancing the efficiency of robustness certifications. With the pixel-wise
smoothed classifier, we are able to fully upper bound the projection errors
using a technique of uniform partitioning in camera motion space. Additionally,
we extend our certification framework to a more general scenario where only a
single-frame point cloud is required in the projection oracle. This is achieved
by deriving Lipschitz-based approximated partition intervals. Through extensive
experimentation, we validate the trade-off between effectiveness and efficiency
enabled by our proposed method. Remarkably, our approach achieves approximately
80% certified accuracy while utilizing only 30% of the projected image frames.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13151" title="Abstract">arXiv:2309.13151</a> [<a href="/pdf/2309.13151" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Brain Computer Interface Using Non-Invasive Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghosh%2C+R">Ritam Ghosh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Research on Brain-Computer Interface (BCI) began in the 1970s and has
increased in volume and diversified significantly since then. Today BCI is
widely used for applications like assistive devices for physically challenged
users, mental state monitoring, input devices for hands-free applications,
marketing, education, security, games and entertainment. This article explores
the advantages and disadvantages of invasive and non-invasive BCI technologies
and focuses on use cases of several non-invasive technologies, namely
electroencephalogram (EEG), functional Magnetic Resonance Imaging (fMRI), Near
Infrared Spectroscopy (NIRs) and hybrid systems.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13155" title="Abstract">arXiv:2309.13155</a> [<a href="/pdf/2309.13155" title="Download PDF">pdf</a>, <a href="/format/2309.13155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Agent Reach-Avoid Games: Two Attackers Versus One Defender and  Mixed Integer Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hu%2C+H">Hanyang Hu</a>, 
<a href="/search/eess?searchtype=author&query=Bui%2C+M">Minh Bui</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+M">Mo Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">We propose a hybrid approach that combines Hamilton-Jacobi (HJ) reachability
and mixed-integer optimization for solving a reach-avoid game with multiple
attackers and defenders. The reach-avoid game is an important problem with
potential applications in air traffic control and multi-agent motion planning;
however, solving this game for many attackers and defenders is intractable due
to the adversarial nature of the agents and the high problem dimensionality. In
this paper, we first propose an HJ reachability-based method for solving the
reach-avoid game in which 2 attackers are playing against 1 defender; we derive
the numerically convergent optimal winning sets for the two sides in
environments with obstacles. Utilizing this result and previous results for the
1 vs. 1 game, we further propose solving the general multi-agent reach-avoid
game by determining the defender assignments that can maximize the number of
attackers captured via a Mixed Integer Program (MIP). Our method generalizes
previous state-of-the-art results and is especially useful when there are fewer
defenders than attackers. We validate our theoretical results in numerical
simulations.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13160" title="Abstract">arXiv:2309.13160</a> [<a href="/pdf/2309.13160" title="Download PDF">pdf</a>, <a href="/format/2309.13160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rivera%2C+M">Mariano Rivera</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Variational Autoencoders (VAEs) have become a cornerstone in generative
modeling and representation learning within machine learning. This paper
explores a nuanced aspect of VAEs, focusing on interpreting the Kullback
Leibler (KL) Divergence, a critical component within the Evidence Lower Bound
(ELBO) that governs the trade-off between reconstruction accuracy and
regularization. While the KL Divergence enforces alignment between latent
variable distributions and a prior imposing a structure on the overall latent
space but leaves individual variable distributions unconstrained. The proposed
method redefines the ELBO with a mixture of Gaussians for the posterior
probability, introduces a regularization term to prevent variance collapse, and
employs a PatchGAN discriminator to enhance texture realism. Implementation
details involve ResNetV2 architectures for both the Encoder and Decoder. The
experiments demonstrate the ability to generate realistic faces, offering a
promising solution for enhancing VAE based generative models.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13165" title="Abstract">arXiv:2309.13165</a> [<a href="/pdf/2309.13165" title="Download PDF">pdf</a>, <a href="/format/2309.13165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models Are Also Good Prototypical Commonsense Reasoners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qianglong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yifei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+H">Hongxiang Yao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Commonsense reasoning is a pivotal skill for large language models, yet it
presents persistent challenges in specific tasks requiring this competence.
Traditional fine-tuning approaches can be resource-intensive and potentially
compromise a model's generalization capacity. Furthermore, state-of-the-art
language models like GPT-3.5 and Claude are primarily accessible through API
calls, which makes fine-tuning models challenging. To address these challenges,
we draw inspiration from the outputs of large models for tailored tasks and
semi-automatically developed a set of novel prompts from several perspectives,
including task-relevance, supportive evidence generation (e.g. chain-of-thought
and knowledge), diverse path decoding to aid the model. Experimental results on
ProtoQA dataset demonstrate that with better designed prompts we can achieve
the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max
Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for the
first time) compared to the previous SOTA model and achieved an improvement on
StrategyQA and CommonsenseQA2.0 (3% and 1%, respectively). Furthermore, with
the generated Chain-of-Thought and knowledge, we can improve the
interpretability of the model while also surpassing the previous SOTA models.
We hope that our work can provide insight for the NLP community to develop
better prompts and explore the potential of large language models for more
complex reasoning tasks.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13166" title="Abstract">arXiv:2309.13166</a> [<a href="/pdf/2309.13166" title="Download PDF">pdf</a>, <a href="/format/2309.13166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invisible Watermarking for Audio Generation Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+X">Xirong Cao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Jadav%2C+D">Divyesh Jadav</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanzhao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+C">Chen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenqi Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is an invited paper for IEEE TPS, part of the IEEE CIC/CogMI/TPS 2023 conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Diffusion models have gained prominence in the image domain for their
capabilities in data generation and transformation, achieving state-of-the-art
performance in various tasks in both image and audio domains. In the rapidly
evolving field of audio-based machine learning, safeguarding model integrity
and establishing data copyright are of paramount importance. This paper
presents the first watermarking technique applied to audio diffusion models
trained on mel-spectrograms. This offers a novel approach to the aforementioned
challenges. Our model excels not only in benign audio generation, but also
incorporates an invisible watermarking trigger mechanism for model
verification. This watermark trigger serves as a protective layer, enabling the
identification of model ownership and ensuring its integrity. Through extensive
experiments, we demonstrate that invisible watermark triggers can effectively
protect against unauthorized modifications while maintaining high utility in
benign audio generation tasks.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13167" title="Abstract">arXiv:2309.13167</a> [<a href="/pdf/2309.13167" title="Download PDF">pdf</a>, <a href="/format/2309.13167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flow Factorized Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yue Song</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+T+A">T. Anderson Keller</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A prominent goal of representation learning research is to achieve
representations which are factorized in a useful manner with respect to the
ground truth factors of variation. The fields of disentangled and equivariant
representation learning have approached this ideal from a range of
complimentary perspectives; however, to date, most approaches have proven to
either be ill-specified or insufficiently flexible to effectively separate all
realistic factors of interest in a learned latent space. In this work, we
propose an alternative viewpoint on such structured representation learning
which we call Flow Factorized Representation Learning, and demonstrate it to
learn both more efficient and more usefully structured representations than
existing frameworks. Specifically, we introduce a generative model which
specifies a distinct set of latent probability paths that define different
input transformations. Each latent flow is generated by the gradient field of a
learned potential following dynamic optimal transport. Our novel setup brings
new understandings to both \textit{disentanglement} and \textit{equivariance}.
We show that our model achieves higher likelihoods on standard representation
learning benchmarks while simultaneously being closer to approximately
equivariant models. Furthermore, we demonstrate that the transformations
learned by our model are flexibly composable and can also extrapolate to new
data, implying a degree of robustness and generalizability approaching the
ultimate goal of usefully factorized representation learning.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13168" title="Abstract">arXiv:2309.13168</a> [<a href="/pdf/2309.13168" title="Download PDF">pdf</a>, <a href="/format/2309.13168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FATHER: FActory on THE Road
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szab%C3%B3%2C+G">G&#xe9;za Szab&#xf3;</a>, 
<a href="/search/cs?searchtype=author&query=T%C3%A1rnok%2C+B">Bal&#xe1;zs T&#xe1;rnok</a>, 
<a href="/search/cs?searchtype=author&query=Vajda%2C+L">Levente Vajda</a>, 
<a href="/search/cs?searchtype=author&query=Pet%C5%91%2C+J">J&#xf3;zsef Pet&#x151;</a>, 
<a href="/search/cs?searchtype=author&query=Vid%C3%A1cs%2C+A">Attila Vid&#xe1;cs</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proc., 35th European Simulation and Modelling Conference, Oct 27-29, 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In most factories today the robotic cells are deployed on well enforced bases
to avoid any external impact on the accuracy of production. In contrast to
that, we evaluate a futuristic concept where the whole robotic cell could work
in a moving platform. Imagine a trailer of a truck moving along the motorway
while exposed to heavy physical impacts due to maneuvering. The key question
here is how the robotic cell behaves and how the productivity is affected. We
propose a system architecture (FATHER) and show some solutions including
network related information and artificial intelligence to make the proposed
futuristic concept feasible to implement.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13169" title="Abstract">arXiv:2309.13169</a> [<a href="/pdf/2309.13169" title="Download PDF">pdf</a>, <a href="/format/2309.13169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloudy Forecast: How Predictable is Communication Latency in the Cloud?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hilyard%2C+O">Owen Hilyard</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bocheng Cui</a>, 
<a href="/search/cs?searchtype=author&query=Webster%2C+M">Marielle Webster</a>, 
<a href="/search/cs?searchtype=author&query=Muralikrishna%2C+A+B">Abishek Bangalore Muralikrishna</a>, 
<a href="/search/cs?searchtype=author&query=Charapko%2C+A">Aleksey Charapko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Many systems and services rely on timing assumptions for performance and
availability to perform critical aspects of their operation, such as various
timeouts for failure detectors or optimizations to concurrency control
mechanisms. Many such assumptions rely on the ability of different components
to communicate on time -- a delay in communication may trigger the failure
detector or cause the system to enter a less-optimized execution mode.
Unfortunately, these timing assumptions are often set with little regard to
actual communication guarantees of the underlying infrastructure -- in
particular, the variability of communication delays between processes in
different nodes/servers. The higher communication variability holds especially
true for systems deployed in the public cloud since the cloud is a utility
shared by many users and organizations, making it prone to higher performance
variance due to noisy neighbor syndrome. In this work, we present Cloud Latency
Tester (CLT), a simple tool that can help measure the variability of
communication delays between nodes to help engineers set proper values for
their timing assumptions. We also provide our observational analysis of running
CLT in three major cloud providers and share the lessons we learned.
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13170" title="Abstract">arXiv:2309.13170</a> [<a href="/pdf/2309.13170" title="Download PDF">pdf</a>, <a href="/format/2309.13170" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Efficient Deep Learning Architectures For Side-Channel  Attacks on AES
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berreby%2C+Y">Yoha&#xef;-Eliel Berreby</a>, 
<a href="/search/cs?searchtype=author&query=Sauvage%2C+L">Laurent Sauvage</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures. This manuscript is a report produced as part of a T\'el\'ecom Paris "PRIM" (Project Recherche et Innovation Master / Master's Research and Innovation Project)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Over the past few years, deep learning has been getting progressively more
popular for the exploitation of side-channel vulnerabilities in embedded
cryptographic applications, as it offers advantages in terms of the amount of
attack traces required for effective key recovery. A number of effective
attacks using neural networks have already been published, but reducing their
cost in terms of the amount of computing resources and data required is an
ever-present goal, which we pursue in this work. We focus on the ANSSI
Side-Channel Attack Database (ASCAD), and produce a JAX-based framework for
deep-learning-based SCA, with which we reproduce a selection of previous
results and build upon them in an attempt to improve their performance. We also
investigate the effectiveness of various Transformer-based models.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13171" title="Abstract">arXiv:2309.13171</a> [<a href="/pdf/2309.13171" title="Download PDF">pdf</a>, <a href="/format/2309.13171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PAC-NMPC with Learned Perception-Informed Value Function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Polevoy%2C+A">Adam Polevoy</a>, 
<a href="/search/cs?searchtype=author&query=Gonzales%2C+M">Mark Gonzales</a>, 
<a href="/search/cs?searchtype=author&query=Kobilarov%2C+M">Marin Kobilarov</a>, 
<a href="/search/cs?searchtype=author&query=Moore%2C+J">Joseph Moore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Nonlinear model predictive control (NMPC) is typically restricted to short,
finite horizons to limit the computational burden of online optimization. This
makes a global planner necessary to avoid local minima when using NMPC for
navigation in complex environments. For this reason, the performance of NMPC
approaches are often limited by that of the global planner. While control
policies trained with reinforcement learning (RL) can theoretically learn to
avoid such local minima, they are usually unable to guarantee enforcement of
general state constraints. In this paper, we augment a sampling-based
stochastic NMPC (SNMPC) approach with an RL trained perception-informed value
function. This allows the system to avoid observable local minima in the
environment by reasoning about perception information beyond the finite
planning horizon. By using Probably Approximately Correct NMPC (PAC-NMPC) as
our base controller, we are also able to generate statistical guarantees of
performance and safety. We demonstrate our approach in simulation and on
hardware using a 1/10th scale rally car with lidar.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13172" title="Abstract">arXiv:2309.13172</a> [<a href="/pdf/2309.13172" title="Download PDF">pdf</a>, <a href="/format/2309.13172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Walking-by-Logic: Signal Temporal Logic-Guided Model Predictive Control  for Bipedal Locomotion Resilient to External Perturbations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+Z">Zhaoyuan Gu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Rongming Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yates%2C+W">William Yates</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yipu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Ye Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This study proposes a novel planning framework based on a model predictive
control formulation that incorporates signal temporal logic (STL)
specifications for task completion guarantees and robustness quantification.
This marks the first-ever study to apply STL-guided trajectory optimization for
bipedal locomotion push recovery, where the robot experiences unexpected
disturbances. Existing recovery strategies often struggle with complex task
logic reasoning and locomotion robustness evaluation, making them susceptible
to failures caused by inappropriate recovery strategies or insufficient
robustness. To address this issue, the STL-guided framework generates optimal
and safe recovery trajectories that simultaneously satisfy the task
specification and maximize the locomotion robustness. Our framework outperforms
a state-of-the-art locomotion controller in a high-fidelity dynamic simulation,
especially in scenarios involving crossed-leg maneuvers. Furthermore, it
demonstrates versatility in tasks such as locomotion on stepping stones, where
the robot must select from a set of disjointed footholds to maneuver
successfully.
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13173" title="Abstract">arXiv:2309.13173</a> [<a href="/pdf/2309.13173" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls  of Large Language Models on Bengali NLP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kabir%2C+M">Mohsinul Kabir</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+S">Mohammed Saidul Islam</a>, 
<a href="/search/cs?searchtype=author&query=Laskar%2C+M+T+R">Md Tahmid Rahman Laskar</a>, 
<a href="/search/cs?searchtype=author&query=Nayeem%2C+M+T">Mir Tafseer Nayeem</a>, 
<a href="/search/cs?searchtype=author&query=Bari%2C+M+S">M Saiful Bari</a>, 
<a href="/search/cs?searchtype=author&query=Hoque%2C+E">Enamul Hoque</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> First two authors contributed equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have emerged as one of the most important
breakthroughs in natural language processing (NLP) for their impressive skills
in language generation and other language-specific tasks. Though LLMs have been
evaluated in various tasks, mostly in English, they have not yet undergone
thorough evaluation in under-resourced languages such as Bengali (Bangla). In
this paper, we evaluate the performance of LLMs for the low-resourced Bangla
language. We select various important and diverse Bangla NLP tasks, such as
abstractive summarization, question answering, paraphrasing, natural language
inference, text classification, and sentiment analysis for zero-shot evaluation
with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with
state-of-the-art fine-tuned models. Our experimental results demonstrate an
inferior performance of LLMs for different Bangla NLP tasks, calling for
further effort to develop better understanding of LLMs in low-resource
languages like Bangla.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13174" title="Abstract">arXiv:2309.13174</a> [<a href="/pdf/2309.13174" title="Download PDF">pdf</a>, <a href="/format/2309.13174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust self-propulsion in sand using simply controlled vibrating cubes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bangyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kojouharov%2C+V">Velin Kojouharov</a>, 
<a href="/search/cs?searchtype=author&query=Hammond%2C+F+L">Frank L. Hammond III</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+D+I">Daniel I. Goldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Much of the Earth and many surfaces of extraterrestrial bodies are composed
of in-cohesive particle matter. Locomoting on granular terrain is challenging
for common robotic devices, either wheeled or legged. In this work, we discover
a robust alternative locomotion mechanism on granular media -- generating
movement via self-vibration. To demonstrate the effectiveness of this
locomotion mechanism, we develop a cube-shaped robot with an embedded vibratory
motor and conduct systematic experiments on diverse granular terrains of
various particle properties. We investigate how locomotion changes as a
function of vibration frequency/intensity on granular terrains. Compared to
hard surfaces, we find such a vibratory locomotion mechanism enables the robot
to move faster, and more stable on granular surfaces, facilitated by the
interaction between the body and surrounding granules. The simplicity in
structural design and controls of this robotic system indicates that vibratory
locomotion can be a valuable alternative way to produce robust locomotion on
granular terrains. We further demonstrate that such cube-shape robots can be
used as modular units for morphologically structured vibratory robots with
capabilities of maneuverable forward and turning motions, showing potential
practical scenarios for robotic systems.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13175" title="Abstract">arXiv:2309.13175</a> [<a href="/pdf/2309.13175" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> American Family Cohort, a data resource description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Balraj%2C+D">Deepa Balraj</a>, 
<a href="/search/cs?searchtype=author&query=Vala%2C+A">Ayin Vala</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shiying Hao</a>, 
<a href="/search/cs?searchtype=author&query=Philofsky%2C+M">Melanie Philofsky</a>, 
<a href="/search/cs?searchtype=author&query=Tsvetkova%2C+A">Anna Tsvetkova</a>, 
<a href="/search/cs?searchtype=author&query=Trach%2C+E">Elena Trach</a>, 
<a href="/search/cs?searchtype=author&query=Narra%2C+S+P">Shravani Priya Narra</a>, 
<a href="/search/cs?searchtype=author&query=Zhuk%2C+O">Oleg Zhuk</a>, 
<a href="/search/cs?searchtype=author&query=Shamkhorskaya%2C+M">Mary Shamkhorskaya</a>, 
<a href="/search/cs?searchtype=author&query=Singer%2C+J">Jim Singer</a>, 
<a href="/search/cs?searchtype=author&query=Mesterhazy%2C+J">Joseph Mesterhazy</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Somalee Datta</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+I">Isabella Chu</a>, 
<a href="/search/cs?searchtype=author&query=Rehkopf%2C+D">David Rehkopf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This manuscript is a research resource description and presents a large and
novel Electronic Health Records (EHR) data resource, American Family Cohort
(AFC). The AFC data is derived from Centers for Medicare and Medicaid Services
(CMS) certified American Board of Family Medicine (ABFM) PRIME registry. The
PRIME registry is the largest national Qualified Clinical Data Registry (QCDR)
for Primary Care. The data is converted to a popular common data model, the
Observational Health Data Sciences and Informatics (OHDSI) Observational
Medical Outcomes Partnership (OMOP) Common Data Model (CDM).
<br />The resource presents approximately 90 million encounters for 7.5 million
patients. All 100% of the patients present age, gender, and address
information, and 73% report race. Nealy 93% of patients have lab data in LOINC,
86% have medication data in RxNorm, 93% have diagnosis in SNOWMED and ICD, 81%
have procedures in HCPCS or CPT, and 61% have insurance information. The
richness, breadth, and diversity of this research accessible and research ready
data is expected to accelerate observational studies in many diverse areas. We
expect this resource to facilitate research in many years to come.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13176" title="Abstract">arXiv:2309.13176</a> [<a href="/pdf/2309.13176" title="Download PDF">pdf</a>, <a href="/format/2309.13176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk  Disclosures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sherman%2C+E">Eli Sherman</a>, 
<a href="/search/cs?searchtype=author&query=Eisenberg%2C+I+W">Ian W. Eisenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">As AI systems' sophistication and proliferation have increased, awareness of
the risks has grown proportionally (Sorkin et al. 2023). In response, calls
have grown for stronger emphasis on disclosure and transparency in the AI
industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing
use of technical disclosures, like model cards (Mitchell et al. 2019), to
yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is
complicated, with actors representing various expertise, perspectives, and
values, it is crucial that consumers of a transparency disclosure be able to
understand the risks of the AI system the disclosure concerns. In this paper we
propose a risk profiling standard which can guide downstream decision-making,
including triaging further risk assessment, informing procurement and
deployment, and directing regulatory frameworks. The standard is built on our
proposed taxonomy of AI risks, which reflects a high-level categorization of
the wide variety of risks proposed in the literature. We outline the myriad
data sources needed to construct informative Risk Profiles and propose a
template-based methodology for collating risk information into a standard, yet
flexible, structure. We apply this methodology to a number of prominent AI
systems using publicly available information. To conclude, we discuss design
decisions for the profiles and future work.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13179" title="Abstract">arXiv:2309.13179</a> [<a href="/pdf/2309.13179" title="Download PDF">pdf</a>, <a href="/format/2309.13179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Multi-Objective Optimization through Machine  Learning-Supported Multiphysics Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Botache%2C+D">Diego Botache</a>, 
<a href="/search/cs?searchtype=author&query=Decke%2C+J">Jens Decke</a>, 
<a href="/search/cs?searchtype=author&query=Ripken%2C+W">Winfried Ripken</a>, 
<a href="/search/cs?searchtype=author&query=Dornipati%2C+A">Abhinay Dornipati</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B6tz-Hahn%2C+F">Franz G&#xf6;tz-Hahn</a>, 
<a href="/search/cs?searchtype=author&query=Ayeb%2C+M">Mohamed Ayeb</a>, 
<a href="/search/cs?searchtype=author&query=Sick%2C+B">Bernhard Sick</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Multiphysics simulations that involve multiple coupled physical phenomena
quickly become computationally expensive. This imposes challenges for
practitioners aiming to find optimal configurations for these problems
satisfying multiple objectives, as optimization algorithms often require
querying the simulation many times. This paper presents a methodological
framework for training, self-optimizing, and self-organizing surrogate models
to approximate and speed up Multiphysics simulations. We generate two
real-world tabular datasets, which we make publicly available, and show that
surrogate models can be trained on relatively small amounts of data to
approximate the underlying simulations accurately. We conduct extensive
experiments combining four machine learning and deep learning algorithms with
two optimization algorithms and a comprehensive evaluation strategy. Finally,
we evaluate the performance of our combined training and optimization pipeline
by verifying the generated Pareto-optimal results using the ground truth
simulations. We also employ explainable AI techniques to analyse our surrogates
and conduct a preselection strategy to determine the most relevant features in
our real-world examples. This approach lets us understand the underlying
problem and identify critical partial dependencies.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13181" title="Abstract">arXiv:2309.13181</a> [<a href="/pdf/2309.13181" title="Download PDF">pdf</a>, <a href="/format/2309.13181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diagnosing and exploiting the computational demands of videos games for  deep reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Govindarajan%2C+L+N">Lakshmi Narasimhan Govindarajan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R+G">Rex G Liu</a>, 
<a href="/search/cs?searchtype=author&query=Linsley%2C+D">Drew Linsley</a>, 
<a href="/search/cs?searchtype=author&query=Ashok%2C+A+K">Alekh Karkada Ashok</a>, 
<a href="/search/cs?searchtype=author&query=Reuter%2C+M">Max Reuter</a>, 
<a href="/search/cs?searchtype=author&query=Frank%2C+M+J">Michael J Frank</a>, 
<a href="/search/cs?searchtype=author&query=Serre%2C+T">Thomas Serre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
<p class="mathjax">Humans learn by interacting with their environments and perceiving the
outcomes of their actions. A landmark in artificial intelligence has been the
development of deep reinforcement learning (dRL) algorithms capable of doing
the same in video games, on par with or better than humans. However, it remains
unclear whether the successes of dRL models reflect advances in visual
representation learning, the effectiveness of reinforcement learning algorithms
at discovering better policies, or both. To address this question, we introduce
the Learning Challenge Diagnosticator (LCD), a tool that separately measures
the perceptual and reinforcement learning demands of a task. We use LCD to
discover a novel taxonomy of challenges in the Procgen benchmark, and
demonstrate that these predictions are both highly reliable and can instruct
algorithmic development. More broadly, the LCD reveals multiple failure cases
that can occur when optimizing dRL algorithms over entire video game benchmarks
like Procgen, and provides a pathway towards more efficient progress.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13182" title="Abstract">arXiv:2309.13182</a> [<a href="/pdf/2309.13182" title="Download PDF">pdf</a>, <a href="/format/2309.13182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Effective Distillation of Table-based Reasoning Ability from LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+B">Bohao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Chenghao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chenghua Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have demonstrated remarkable performance across
a wide range of natural language processing tasks. However, their remarkable
parameter size and their impressive high requirement of computing resources
pose challenges for their practical deployment. Recent research has revealed
that specific capabilities of LLMs, such as numerical reasoning, can be
transferred to smaller models through distillation. Some studies explore the
potential of leveraging LLMs to perform table-based reasoning. Nevertheless,
prior to our work, there has been no investigation into the prospect of
specialising table reasoning skills in smaller models specifically tailored for
table-to-text generation tasks. In this paper, we propose a novel table-based
reasoning distillation, with the aim of distilling distilling LLMs into
tailored, smaller models specifically designed for table-based reasoning task.
Experimental results have shown that a 0.22 billion parameter model
(Flan-T5-base) fine-tuned using distilled data, not only achieves a significant
improvement compared to traditionally fine-tuned baselines but also surpasses
specific LLMs like gpt-3.5-turbo on the scientific table-to-text generation
dataset (SciGen). The code and data are released in
https://github.com/Bernard-Yang/TableDistill.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13184" title="Abstract">arXiv:2309.13184</a> [<a href="/pdf/2309.13184" title="Download PDF">pdf</a>, <a href="/format/2309.13184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Document Understanding for Healthcare Referrals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mistry%2C+J">Jimit Mistry</a>, 
<a href="/search/cs?searchtype=author&query=Arzeno%2C+N+M">Natalia M. Arzeno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted and presented at the 11th IEEE International Conference on Healthcare Informatics (ICHI) 2023 - Industry Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Reliance on scanned documents and fax communication for healthcare referrals
leads to high administrative costs and errors that may affect patient care. In
this work we propose a hybrid model leveraging LayoutLMv3 along with
domain-specific rules to identify key patient, physician, and exam-related
entities in faxed referral documents. We explore some of the challenges in
applying a document understanding model to referrals, which have formats
varying by medical practice, and evaluate model performance using MUC-5 metrics
to obtain appropriate metrics for the practical use case. Our analysis shows
the addition of domain-specific rules to the transformer model yields greatly
increased precision and F1 scores, suggesting a hybrid model trained on a
curated dataset can increase efficiency in referral management.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13185" title="Abstract">arXiv:2309.13185</a> [<a href="/pdf/2309.13185" title="Download PDF">pdf</a>, <a href="/format/2309.13185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visualizing Topological Importance: A Class-Driven Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+Y">Yu Qin</a>, 
<a href="/search/cs?searchtype=author&query=Fasy%2C+B+T">Brittany Terese Fasy</a>, 
<a href="/search/cs?searchtype=author&query=Wenk%2C+C">Carola Wenk</a>, 
<a href="/search/cs?searchtype=author&query=Summa%2C+B">Brian Summa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents the first approach to visualize the importance of
topological features that define classes of data. Topological features, with
their ability to abstract the fundamental structure of complex data, are an
integral component of visualization and analysis pipelines. Although not all
topological features present in data are of equal importance. To date, the
default definition of feature importance is often assumed and fixed. This work
shows how proven explainable deep learning approaches can be adapted for use in
topological classification. In doing so, it provides the first technique that
illuminates what topological structures are important in each dataset in
regards to their class label. In particular, the approach uses a learned metric
classifier with a density estimator of the points of a persistence diagram as
input. This metric learns how to reweigh this density such that classification
accuracy is high. By extracting this weight, an importance field on persistent
point density can be created. This provides an intuitive representation of
persistence point importance that can be used to drive new visualizations. This
work provides two examples: Visualization on each diagram directly and, in the
case of sublevel set filtrations on images, directly on the images themselves.
This work highlights real-world examples of this approach visualizing the
important topological features in graph, 3D shape, and medical image data.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13188" title="Abstract">arXiv:2309.13188</a> [<a href="/pdf/2309.13188" title="Download PDF">pdf</a>, <a href="/format/2309.13188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Discriminators for Content-Consistent Unpaired Image-to-Image  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stuhr%2C+B">Bonifaz Stuhr</a>, 
<a href="/search/cs?searchtype=author&query=Brauer%2C+J">J&#xfc;rgen Brauer</a>, 
<a href="/search/cs?searchtype=author&query=Schick%2C+B">Bernhard Schick</a>, 
<a href="/search/cs?searchtype=author&query=Gonz%C3%A0lez%2C+J">Jordi Gonz&#xe0;lez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 22 figures, under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">A common goal of unpaired image-to-image translation is to preserve content
consistency between source images and translated images while mimicking the
style of the target domain. Due to biases between the datasets of both domains,
many methods suffer from inconsistencies caused by the translation process.
Most approaches introduced to mitigate these inconsistencies do not constrain
the discriminator, leading to an even more ill-posed training setup. Moreover,
none of these approaches is designed for larger crop sizes. In this work, we
show that masking the inputs of a global discriminator for both domains with a
content-based mask is sufficient to reduce content inconsistencies
significantly. However, this strategy leads to artifacts that can be traced
back to the masking process. To reduce these artifacts, we introduce a local
discriminator that operates on pairs of small crops selected with a similarity
sampling strategy. Furthermore, we apply this sampling strategy to sample
global input crops from the source and target dataset. In addition, we propose
feature-attentive denormalization to selectively incorporate content-based
statistics into the generator stream. In our experiments, we show that our
method achieves state-of-the-art performance in photorealistic sim-to-real
translation and weather translation and also performs well in day-to-night
translation. Additionally, we propose the cKVD metric, which builds on the sKVD
metric and enables the examination of translation quality at the class or
category level.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13190" title="Abstract">arXiv:2309.13190</a> [<a href="/pdf/2309.13190" title="Download PDF">pdf</a>, <a href="/format/2309.13190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-frequency channels, shape bias, and adversarial robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subramanian%2C+A">Ajay Subramanian</a>, 
<a href="/search/cs?searchtype=author&query=Sizikova%2C+E">Elena Sizikova</a>, 
<a href="/search/cs?searchtype=author&query=Majaj%2C+N+J">Najib J. Majaj</a>, 
<a href="/search/cs?searchtype=author&query=Pelli%2C+D+G">Denis G. Pelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Neural Information Processing Systems (NeurIPS) 2023 (Oral Presentation)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">What spatial frequency information do humans and neural networks use to
recognize objects? In neuroscience, critical band masking is an established
tool that can reveal the frequency-selective filters used for object
recognition. Critical band masking measures the sensitivity of recognition
performance to noise added at each spatial frequency. Existing critical band
masking studies show that humans recognize periodic patterns (gratings) and
letters by means of a spatial-frequency filter (or "channel'') that has a
frequency bandwidth of one octave (doubling of frequency). Here, we introduce
critical band masking as a task for network-human comparison and test 14 humans
and 76 neural networks on 16-way ImageNet categorization in the presence of
narrowband noise. We find that humans recognize objects in natural images using
the same one-octave-wide channel that they use for letters and gratings, making
it a canonical feature of human object recognition. On the other hand, the
neural network channel, across various architectures and training strategies,
is 2-4 times as wide as the human channel. In other words, networks are
vulnerable to high and low frequency noise that does not affect human
performance. Adversarial and augmented-image training are commonly used to
increase network robustness and shape bias. Does this training align network
and human object recognition channels? Three network channel properties
(bandwidth, center frequency, peak noise sensitivity) correlate strongly with
shape bias (53% variance explained) and with robustness of
adversarially-trained networks (74% variance explained). Adversarial training
increases robustness but expands the channel bandwidth even further away from
the human bandwidth. Thus, critical band masking reveals that the network
channel is more than twice as wide as the human channel, and that adversarial
training only increases this difference.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13191" title="Abstract">arXiv:2309.13191</a> [<a href="/pdf/2309.13191" title="Download PDF">pdf</a>, <a href="/format/2309.13191" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grassroots Flash: A Payment System for Grassroots Cryptocurrencies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lewis-Pye%2C+A">Andrew Lewis-Pye</a>, 
<a href="/search/cs?searchtype=author&query=Naor%2C+O">Oded Naor</a>, 
<a href="/search/cs?searchtype=author&query=Shapiro%2C+E">Ehud Shapiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>; Computational Engineering, Finance, and Science (cs.CE); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The goal of grassroots cryptocurrencies is to provide a foundation with which
local digital economies can emerge independently of each other and of global
digital platforms and global cryptocurrencies; can form and grow without
initial capital or external credit; can trade with each other; and can
gradually merge into a global digital economy. Grassroots cryptocurrencies turn
mutual trust into liquidity and thus could be a powerful means for 'banking the
unbanked'. Grassroots cryptocurrencies have not been provided yet with a
payment system, which is the goal of this paper. Here, we present Grassroots
Flash, a payment system for grassroots cryptocurrencies that employs the
blocklace -- a DAG-like counterpart of the blockchain data structure. We
analyze its security (safety, liveness, and privacy) and efficiency, prove that
it is indeed grassroots.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13192" title="Abstract">arXiv:2309.13192</a> [<a href="/pdf/2309.13192" title="Download PDF">pdf</a>, <a href="/format/2309.13192" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Green AI in Fine-tuning Large Language Models via Adaptive  Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kai Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hanyun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Heng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Fine-tuning is the most effective way of adapting pre-trained large language
models (LLMs) to downstream applications. With the fast growth of LLM-enabled
AI applications and democratization of open-souced LLMs, fine-tuning has become
possible for non-expert individuals, but intensively performed LLM fine-tuning
worldwide could result in significantly high energy consumption and carbon
footprint, which may bring large environmental impact. Mitigating such
environmental impact towards Green AI directly correlates to reducing the FLOPs
of fine-tuning, but existing techniques on efficient LLM fine-tuning can only
achieve limited reduction of such FLOPs, due to their ignorance of the
backpropagation cost in fine-tuning. To address this limitation, in this paper
we present GreenTrainer, a new LLM fine-tuning technique that adaptively
evaluates different tensors' backpropagation costs and contributions to the
fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the
most appropriate set of tensors in training. Such selection in GreenTrainer is
made based on a given objective of FLOPs reduction, which can flexibly adapt to
the carbon footprint in energy supply and the need in Green AI. Experiment
results over multiple open-sourced LLM models and abstractive summarization
datasets show that, compared to fine-tuning the whole LLM model, GreenTrainer
can save up to 64% FLOPs in fine-tuning without any noticeable model accuracy
loss. Compared to the existing fine-tuning techniques such as LoRa,
GreenTrainer can achieve up to 4% improvement on model accuracy with on-par
FLOPs reduction.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13193" title="Abstract">arXiv:2309.13193</a> [<a href="/pdf/2309.13193" title="Download PDF">pdf</a>, <a href="/format/2309.13193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurrealDriver: Designing Generative Driver Agent Simulation Framework in  Urban Contexts based on Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+Y">Ye Jin</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xiaoxi Shen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Huiling Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">Jingli Qin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jintao Xie</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peizhong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guyue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+J">Jiangtao Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Simulation plays a critical role in the research and development of
autonomous driving and intelligent transportation systems. However, the current
simulation platforms exhibit limitations in the realism and diversity of agent
behaviors, which impede the transfer of simulation outcomes to the real world.
In this paper, we propose a generative driver agent simulation framework based
on large language models (LLMs), capable of perceiving complex traffic
scenarios and providing realistic driving maneuvers. Notably, we conducted
interviews with 24 drivers and used their detailed descriptions of driving
behavior as chain-of-thought prompts to develop a `coach agent' module, which
can evaluate and assist driver agents in accumulating driving experience and
developing human-like driving styles. Through practical simulation experiments
and user experiments, we validate the feasibility of this framework in
generating reliable driver agents and analyze the roles of each module. The
results show that the framework with full architect decreased the collision
rate by 81.04% and increased the human-likeness by 50%. Our research proposes
the first urban context driver agent simulation framework based on LLMs and
provides valuable insights into the future of agent simulation for complex
tasks.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13194" title="Abstract">arXiv:2309.13194</a> [<a href="/pdf/2309.13194" title="Download PDF">pdf</a>, <a href="/format/2309.13194" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Short-Term Load Forecasting with Personalization Layers for  Heterogeneous Clients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bose%2C+S">Shourya Bose</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kibaek Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The advent of smart meters has enabled pervasive collection of energy
consumption data for training short-term load forecasting (STLF) models. In
response to privacy concerns, federated learning (FL) has been proposed as a
privacy-preserving approach for training, but the quality of trained models
degrades as client data becomes heterogeneous. In this paper we alleviate this
drawback using personalization layers, wherein certain layers of an STLF model
in an FL framework are trained exclusively on the clients' own data. To that
end, we propose a personalized FL algorithm (PL-FL) enabling FL to handle
personalization layers. The PL-FL algorithm is implemented by using the Argonne
Privacy-Preserving Federated Learning package. We test the forecast performance
of models trained on the NREL ComStock dataset, which contains heterogeneous
energy consumption data of multiple commercial buildings. Superior performance
of models trained with PL-FL demonstrates that personalization layers enable
classical FL algorithms to handle clients with heterogeneous data.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13196" title="Abstract">arXiv:2309.13196</a> [<a href="/pdf/2309.13196" title="Download PDF">pdf</a>, <a href="/format/2309.13196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ClusterFormer: Clustering As A Universal Visual Learner
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J+C">James C. Liang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Y">Yiming Cui</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Dongfang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper presents CLUSTERFORMER, a universal vision model that is based on
the CLUSTERing paradigm with TransFORMER. It comprises two novel designs: 1.
recurrent cross-attention clustering, which reformulates the cross-attention
mechanism in Transformer and enables recursive updates of cluster centers to
facilitate strong representation learning; and 2. feature dispatching, which
uses the updated cluster centers to redistribute image features through
similarity-based metrics, resulting in a transparent pipeline. This elegant
design streamlines an explainable and transferable workflow, capable of
tackling heterogeneous vision tasks (i.e., image classification, object
detection, and image segmentation) with varying levels of clustering
granularity (i.e., image-, box-, and pixel-level). Empirical results
demonstrate that CLUSTERFORMER outperforms various well-known specialized
architectures, achieving 83.41% top-1 acc. over ImageNet-1K for image
classification, 54.2% and 47.0% mAP over MS COCO for object detection and
instance segmentation, 52.4% mIoU over ADE20K for semantic segmentation, and
55.8% PQ over COCO Panoptic for panoptic segmentation. For its efficacy, we
hope our work can catalyze a paradigm shift in universal models in computer
vision.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13201" title="Abstract">arXiv:2309.13201</a> [<a href="/pdf/2309.13201" title="Download PDF">pdf</a>, <a href="/format/2309.13201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Output-Sampled Model Predictive Path Integral Control (o-MPPI) for  Increased Efficiency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Leon">Leon</a> (Liangwu)Yan, 
<a href="/search/eess?searchtype=author&query=Devasia%2C+S">Santosh Devasia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The success of the model predictive path integral control (MPPI) approach
depends on the appropriate selection of the input distribution used for
sampling. However, it can be challenging to select inputs that satisfy output
constraints in dynamic environments. The main contribution of this paper is to
propose an output-sampling-based MPPI (o-MPPI), which improves the ability of
samples to satisfy output constraints and thereby increases MPPI efficiency.
Comparative simulations and experiments of dynamic autonomous driving of bots
around a track are provided to show that the proposed o-MPPI is more efficient
and requires substantially (20-times) less number of rollouts and (4-times)
smaller prediction horizon when compared with the standard MPPI for similar
success rates. The supporting video for the paper can be found at
https://youtu.be/snhlZj3l5CE.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13202" title="Abstract">arXiv:2309.13202</a> [<a href="/pdf/2309.13202" title="Download PDF">pdf</a>, <a href="/format/2309.13202" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models and Control Mechanisms Improve Text Readability of  Biomedical Abstracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zihao Li</a>, 
<a href="/search/cs?searchtype=author&query=Belkadi%2C+S">Samuel Belkadi</a>, 
<a href="/search/cs?searchtype=author&query=Micheletti%2C+N">Nicolo Micheletti</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Lifeng Han</a>, 
<a href="/search/cs?searchtype=author&query=Shardlow%2C+M">Matthew Shardlow</a>, 
<a href="/search/cs?searchtype=author&query=Nenadic%2C+G">Goran Nenadic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> working paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Biomedical literature often uses complex language and inaccessible
professional terminologies. That is why simplification plays an important role
in improving public health literacy. Applying Natural Language Processing (NLP)
models to automate such tasks allows for quick and direct accessibility for lay
readers. In this work, we investigate the ability of state-of-the-art large
language models (LLMs) on the task of biomedical abstract simplification, using
the publicly available dataset for plain language adaptation of biomedical
abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and
prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and
BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT,
and 3) Control-token mechanisms on BART-based models. We used a range of
automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and
also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT)
mechanisms reported the highest SARI score of 46.54 and T5-base reported the
highest BERTscore 72.62. In human evaluation, BART-L-w-CTs achieved a better
simplicity score over T5-Base (2.9 vs. 2.2), while T5-Base achieved a better
meaning preservation score over BART-L-w-CTs (3.1 vs. 2.6). We also categorised
the system outputs with examples, hoping this will shed some light for future
research on this task. Our code, fine-tuned models, and data splits are
available at \url{https://github.com/HECTA-UoM/PLABA-MU}
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13205" title="Abstract">arXiv:2309.13205</a> [<a href="/pdf/2309.13205" title="Download PDF">pdf</a>, <a href="/format/2309.13205" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Practical Survey on Zero-shot Prompt Design for In-context Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in International Conference Recent Advances in Natural Language Processing (RANLP2023) <a href="https://ranlp.org/ranlp2023/index.php/accepted-papers/">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> RANLP 2023: 14th Conf. Recent Advances in NLP, pp. 637 to 643,
  Varna, Bulgaria
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">The remarkable advancements in large language models (LLMs) have brought
about significant improvements in Natural Language Processing(NLP) tasks. This
paper presents a comprehensive review of in-context learning techniques,
focusing on different types of prompts, including discrete, continuous,
few-shot, and zero-shot, and their impact on LLM performance. We explore
various approaches to prompt design, such as manual design, optimization
algorithms, and evaluation methods, to optimize LLM performance across diverse
tasks. Our review covers key research studies in prompt engineering, discussing
their methodologies and contributions to the field. We also delve into the
challenges faced in evaluating prompt performance, given the absence of a
single "best" prompt and the importance of considering multiple metrics. In
conclusion, the paper highlights the critical role of prompt design in
harnessing the full potential of LLMs and provides insights into the
combination of manual design, optimization techniques, and rigorous evaluation
for more effective and efficient use of LLMs in various NLP tasks.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13206" title="Abstract">arXiv:2309.13206</a> [<a href="/pdf/2309.13206" title="Download PDF">pdf</a>, <a href="/format/2309.13206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Intent-Aware Autonomous Driving: A Case Study on Highway Merging  Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahajan%2C+N">Nishtha Mahajan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this work, we use the communication of intent as a means to facilitate
cooperation between autonomous vehicle agents. Generally speaking, intents can
be any reliable information about its future behavior that a vehicle
communicates with another vehicle. We implement this as an intent-sharing task
atop the merging environment in the simulator of highway-env, which provides a
collection of environments for learning decision-making strategies for
autonomous vehicles. Under a simple setting between two agents, we carefully
investigate how intent-sharing can aid the receiving vehicle in adjusting its
behavior in highway merging scenarios.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13207" title="Abstract">arXiv:2309.13207</a> [<a href="/pdf/2309.13207" title="Download PDF">pdf</a>, <a href="/format/2309.13207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation  for Earth System Science Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schreck%2C+J+S">John S. Schreck</a>, 
<a href="/search/cs?searchtype=author&query=Gagne%2C+D+J">David John Gagne II</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+C">Charlie Becker</a>, 
<a href="/search/cs?searchtype=author&query=Chapman%2C+W+E">William E. Chapman</a>, 
<a href="/search/cs?searchtype=author&query=Elmore%2C+K">Kim Elmore</a>, 
<a href="/search/cs?searchtype=author&query=Gantos%2C+G">Gabrielle Gantos</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+E">Eliot Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kimpara%2C+D">Dhamma Kimpara</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+T">Thomas Martin</a>, 
<a href="/search/cs?searchtype=author&query=Molina%2C+M+J">Maria J. Molina</a>, 
<a href="/search/cs?searchtype=author&query=Pryzbylo%2C+V+M">Vanessa M. Pryzbylo</a>, 
<a href="/search/cs?searchtype=author&query=Radford%2C+J">Jacob Radford</a>, 
<a href="/search/cs?searchtype=author&query=Saavedra%2C+B">Belen Saavedra</a>, 
<a href="/search/cs?searchtype=author&query=Willson%2C+J">Justin Willson</a>, 
<a href="/search/cs?searchtype=author&query=Wirz%2C+C">Christopher Wirz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Robust quantification of predictive uncertainty is critical for understanding
factors that drive weather and climate outcomes. Ensembles provide predictive
uncertainty estimates and can be decomposed physically, but both physics and
machine learning ensembles are computationally expensive. Parametric deep
learning can estimate uncertainty with one model by predicting the parameters
of a probability distribution but do not account for epistemic uncertainty..
Evidential deep learning, a technique that extends parametric deep learning to
higher-order distributions, can account for both aleatoric and epistemic
uncertainty with one model. This study compares the uncertainty derived from
evidential neural networks to those obtained from ensembles. Through
applications of classification of winter precipitation type and regression of
surface layer fluxes, we show evidential deep learning models attaining
predictive accuracy rivaling standard methods, while robustly quantifying both
sources of uncertainty. We evaluate the uncertainty in terms of how well the
predictions are calibrated and how well the uncertainty correlates with
prediction error. Analyses of uncertainty in the context of the inputs reveal
sensitivities to underlying meteorological processes, facilitating
interpretation of the models. The conceptual simplicity, interpretability, and
computational efficiency of evidential neural networks make them highly
extensible, offering a promising approach for reliable and practical
uncertainty quantification in Earth system science modeling. In order to
encourage broader adoption of evidential deep learning in Earth System Science,
we have developed a new Python package, MILES-GUESS
(https://github.com/ai2es/miles-guess), that enables users to train and
evaluate both evidential and ensemble deep learning.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13214" title="Abstract">arXiv:2309.13214</a> [<a href="/pdf/2309.13214" title="Download PDF">pdf</a>, <a href="/ps/2309.13214" title="Download PostScript">ps</a>, <a href="/format/2309.13214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the Impact of Personality on Affective States from Video Game  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashani%2C+A">Atieh Kashani</a>, 
<a href="/search/cs?searchtype=author&query=Pfau%2C+J">Johannes Pfau</a>, 
<a href="/search/cs?searchtype=author&query=El-Nasr%2C+M+S">Magy Seif El-Nasr</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">Individual differences in personality determine our preferences, traits and
values, which should similarly hold for the way we express ourselves. With
current advancements and transformations of technology and society, text-based
communication has become ordinary and often even surpasses natural voice
conversations -- with distinct challenges and opportunities. In this
exploratory work, we investigate the impact of personality on the tendency how
players of a team-based collaborative alternate reality game express themselves
affectively. We collected chat logs from eleven players over two weeks, labeled
them according to their affective state, and assessed the connection between
them and the five-factor personality domains and facets. After applying
multi-linear regression, we found a series of reasonable correlations between
(combinations of) personality variables and expressed affect -- as increased
confusion could be predicted by lower self-competence (C1), personal annoyance
by vulnerability to stress (N6) and expressing anger occured more often in
players that are prone to anxiety (N1), less humble and modest (A5), think less
carefully before they act (C6) and have higher neuroticism (N). Expanding the
data set, sample size and input modalities in subsequent work, we aim to
confirm these findings and reveal even more interesting connections that could
inform affective computing and games user research equally.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13216" title="Abstract">arXiv:2309.13216</a> [<a href="/pdf/2309.13216" title="Download PDF">pdf</a>, <a href="/format/2309.13216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MISFIT-V: Misaligned Image Synthesis and Fusion using Information from  Thermal and Visual
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chauhan%2C+A">Aadhar Chauhan</a>, 
<a href="/search/cs?searchtype=author&query=Remy%2C+I">Isaac Remy</a>, 
<a href="/search/cs?searchtype=author&query=Broyles%2C+D">Danny Broyles</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+K">Karen Leung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
<p class="mathjax">Detecting humans from airborne visual and thermal imagery is a fundamental
challenge for Wilderness Search-and-Rescue (WiSAR) teams, who must perform this
function accurately in the face of immense pressure. The ability to fuse these
two sensor modalities can potentially reduce the cognitive load on human
operators and/or improve the effectiveness of computer vision object detection
models. However, the fusion task is particularly challenging in the context of
WiSAR due to hardware limitations and extreme environmental factors. This work
presents Misaligned Image Synthesis and Fusion using Information from Thermal
and Visual (MISFIT-V), a novel two-pronged unsupervised deep learning approach
that utilizes a Generative Adversarial Network (GAN) and a cross-attention
mechanism to capture the most relevant features from each modality.
Experimental results show MISFIT-V offers enhanced robustness against
misalignment and poor lighting/thermal environmental conditions compared to
existing visual-thermal image fusion methods.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13218" title="Abstract">arXiv:2309.13218</a> [<a href="/pdf/2309.13218" title="Download PDF">pdf</a>, <a href="/format/2309.13218" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Copilot for Business Optimisation: A Framework and A Case Study in  Production Scheduling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarasinghe%2C+P+T">Pivithuru Thejan Amarasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Su Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Alahakoon%2C+D">Damminda Alahakoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Business optimisation is the process of finding and implementing efficient
and cost-effective means of operation to bring a competitive advantage for
businesses. Synthesizing problem formulations is an integral part of business
optimisation which is centred around human expertise, thus with a high
potential of becoming a bottleneck. With the recent advancements in Large
Language Models (LLMs), human expertise needed in problem formulation can
potentially be minimized using Artificial Intelligence (AI). However,
developing a LLM for problem formulation is challenging, due to training data
requirements, token limitations, and the lack of appropriate performance
metrics in LLMs. To minimize the requirement of large training data,
considerable attention has recently been directed towards fine-tuning
pre-trained LLMs for downstream tasks, rather than training a LLM from scratch
for a specific task. In this paper, we adopt this approach and propose an
AI-Copilot for business optimisation by fine-tuning a pre-trained LLM for
problem formulation. To address token limitations, we introduce modularization
and prompt engineering techniques to synthesize complex problem formulations as
modules that fit into the token limits of LLMs. In addition, we design
performance evaluation metrics that are more suitable for assessing the
accuracy and quality of problem formulations compared to existing evaluation
metrics. Experiment results demonstrate that our AI-Copilot can synthesize
complex and large problem formulations for a typical business optimisation
problem in production scheduling.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13220" title="Abstract">arXiv:2309.13220</a> [<a href="/pdf/2309.13220" title="Download PDF">pdf</a>, <a href="/format/2309.13220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poster: Self-Supervised Quantization-Aware Knowledge Distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+K">Kaiqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+M">Ming Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Quantization-aware training (QAT) starts with a pre-trained full-precision
model and performs quantization during retraining. However, existing QAT works
require supervision from the labels and they suffer from accuracy loss due to
reduced precision. To address these limitations, this paper proposes a novel
Self-Supervised Quantization-Aware Knowledge Distillation framework (SQAKD).
SQAKD first unifies the forward and backward dynamics of various quantization
functions and then reframes QAT as a co-optimization problem that
simultaneously minimizes the KL-Loss and the discretization error, in a
self-supervised manner. The evaluation shows that SQAKD significantly improves
the performance of various state-of-the-art QAT works. SQAKD establishes
stronger baselines and does not require extensive labeled training data,
potentially making state-of-the-art QAT research more accessible.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13222" title="Abstract">arXiv:2309.13222</a> [<a href="/pdf/2309.13222" title="Download PDF">pdf</a>, <a href="/format/2309.13222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hindi to English: Transformer-Based Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gangar%2C+K">Kavit Gangar</a>, 
<a href="/search/cs?searchtype=author&query=Ruparel%2C+H">Hardik Ruparel</a>, 
<a href="/search/cs?searchtype=author&query=Lele%2C+S">Shreyas Lele</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Springer International Conference on Communication, Computing and
  Electronics Systems. 2020 337-347
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Machine Translation (MT) is one of the most prominent tasks in Natural
Language Processing (NLP) which involves the automatic conversion of texts from
one natural language to another while preserving its meaning and fluency.
Although the research in machine translation has been going on since multiple
decades, the newer approach of integrating deep learning techniques in natural
language processing has led to significant improvements in the translation
quality. In this paper, we have developed a Neural Machine Translation (NMT)
system by training the Transformer model to translate texts from Indian
Language Hindi to English. Hindi being a low resource language has made it
difficult for neural networks to understand the language thereby leading to a
slow growth in the development of neural machine translators. Thus, to address
this gap, we implemented back-translation to augment the training data and for
creating the vocabulary, we experimented with both word and subword level
tokenization using Byte Pair Encoding (BPE) thereby ending up training the
Transformer in 10 different configurations. This led us to achieve a
state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay
English-Hindi Corpus in one of the configurations.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13223" title="Abstract">arXiv:2309.13223</a> [<a href="/pdf/2309.13223" title="Download PDF">pdf</a>, <a href="/format/2309.13223" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal Reasoning: Charting a Revolutionary Course for Next-Generation  AI-Native Wireless Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thomas%2C+C+K">Christo Kurisummoottil Thomas</a>, 
<a href="/search/cs?searchtype=author&query=Chaccour%2C+C">Christina Chaccour</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+C+S">Choong Seon Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the basic premise that next-generation wireless networks (e.g., 6G)
will be artificial intelligence (AI)-native, to date, most existing efforts
remain either qualitative or incremental extensions to existing ``AI for
wireless'' paradigms. Indeed, creating AI-native wireless networks faces
significant technical challenges due to the limitations of data-driven,
training-intensive AI. These limitations include the black-box nature of the AI
models, their curve-fitting nature, which can limit their ability to reason and
adapt, their reliance on large amounts of training data, and the energy
inefficiency of large neural networks. In response to these limitations, this
article presents a comprehensive, forward-looking vision that addresses these
shortcomings by introducing a novel framework for building AI-native wireless
networks; grounded in the emerging field of causal reasoning. Causal reasoning,
founded on causal discovery, causal representation learning, and causal
inference, can help build explainable, reasoning-aware, and sustainable
wireless networks. Towards fulfilling this vision, we first highlight several
wireless networking challenges that can be addressed by causal discovery and
representation, including ultra-reliable beamforming for terahertz (THz)
systems, near-accurate physical twin modeling for digital twins, training data
augmentation, and semantic communication. We showcase how incorporating causal
discovery can assist in achieving dynamic adaptability, resilience, and
cognition in addressing these challenges. Furthermore, we outline potential
frameworks that leverage causal inference to achieve the overarching objectives
of future-generation networks, including intent management, dynamic
adaptability, human-level cognition, reasoning, and the critical element of
time sensitivity.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13224" title="Abstract">arXiv:2309.13224</a> [<a href="/pdf/2309.13224" title="Download PDF">pdf</a>, <a href="/format/2309.13224" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pick Planning Strategies for Large-Scale Package Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shuai Li</a>, 
<a href="/search/cs?searchtype=author&query=Keipour%2C+A">Azarakhsh Keipour</a>, 
<a href="/search/cs?searchtype=author&query=Jamieson%2C+K">Kevin Jamieson</a>, 
<a href="/search/cs?searchtype=author&query=Hudson%2C+N">Nicolas Hudson</a>, 
<a href="/search/cs?searchtype=author&query=Szhao%2C+S">Sicong Szhao</a>, 
<a href="/search/cs?searchtype=author&query=Swan%2C+C">Charles Swan</a>, 
<a href="/search/cs?searchtype=author&query=Bekris%2C+K">Kostas Bekris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Learning Meets Model-based Methods for Manipulation and Grasping Workshop. arXiv admin note: substantial text overlap with <a href="/abs/2305.10272">arXiv:2305.10272</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automating warehouse operations can reduce logistics overhead costs,
ultimately driving down the final price for consumers, increasing the speed of
delivery, and enhancing the resiliency to market fluctuations.
<br />This extended abstract showcases a large-scale package manipulation from
unstructured piles in Amazon Robotics' Robot Induction (Robin) fleet, which is
used for picking and singulating up to 6 million packages per day and so far
has manipulated over 2 billion packages. It describes the various heuristic
methods developed over time and their successor, which utilizes a pick success
predictor trained on real production data.
<br />To the best of the authors' knowledge, this work is the first large-scale
deployment of learned pick quality estimation methods in a real production
system.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13225" title="Abstract">arXiv:2309.13225</a> [<a href="/pdf/2309.13225" title="Download PDF">pdf</a>, <a href="/format/2309.13225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Approximate All Pairs Shortest Paths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+B">Barna Saha</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+C">Christopher Ye</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 81 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">The all pairs shortest path problem (APSP) is one of the foundational
problems in computer science. For weighted dense graphs on $n$ vertices, no
truly sub-cubic algorithms exist to compute APSP exactly even for undirected
graphs. This is popularly known as the APSP conjecture and has played a
prominent role in developing the field of fine-grained complexity. The seminal
result of Seidel uses fast matrix multiplication (FMM) to compute APSP on
unweighted undirected graphs exactly in $\tilde{O}(n^{\omega})$ time, where
$\omega=2.372$. Even for unweighted undirected graphs, it is not possible to
obtain a $(2-\epsilon)$-approximation of APSP in $o(n^\omega)$ time.
<br />In this paper, we provide a multitude of new results for multiplicative and
additive approximations of APSP in undirected graphs for both unweighted and
weighted cases. We provide new algorithms for multiplicative 2-approximation of
unweighted graphs: a deterministic one that runs in $\tilde{O}(n^{2.072})$ time
and a randomized one that runs in $\tilde{O}(n^{2.032})$ on expectation
improving upon the best known bound of $\tilde{O}(n^{2.25})$ by Roditty (STOC,
2023). For $2$-approximating paths of length $\geq k$, $k \geq 4$, we provide
the first improvement after Dor, Halperin, Zwick (2000) for dense graphs even
just using combinatorial methods, and then improve it further using FMM. We
next consider additive approximations, and provide improved bounds for all
additive $\beta$-approximations, $\beta \geq 4$. For weighted graphs, we show
that by allowing small additive errors along with an
$(1+\epsilon)$-multiplicative approximation, it is possible to improve upon
Zwick's $\tilde{O}(n^\omega)$ algorithm. Our results point out the crucial role
that FMM can play even on approximating APSP on unweighted undirected graphs,
and reveal new bottlenecks towards achieving a quadratic running time to
approximate APSP.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13226" title="Abstract">arXiv:2309.13226</a> [<a href="/pdf/2309.13226" title="Download PDF">pdf</a>, <a href="/format/2309.13226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real3D-AD: A Dataset of Point Cloud Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+G">Guoyang Xie</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Ruitao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinpeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jinbao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+F">Feng Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">High-precision point cloud anomaly detection is the gold standard for
identifying the defects of advancing machining and precision manufacturing.
Despite some methodological advances in this area, the scarcity of datasets and
the lack of a systematic benchmark hinder its development. We introduce
Real3D-AD, a challenging high-precision point cloud anomaly detection dataset,
addressing the limitations in the field. With 1,254 high-resolution 3D items
(\xgy{from forty thousand to millions of points for each item}), Real3D-AD is
the largest dataset for high-precision 3D industrial anomaly detection to date.
Real3D-AD surpasses existing 3D anomaly detection datasets available regarding
point cloud resolution (0.0010mm-0.0015mm), $360^{\circ}$ degree coverage and
perfect prototype. Additionally, we present a comprehensive benchmark for
Real3D-AD, revealing the absence of baseline methods for high-precision point
cloud anomaly detection. To address this, we propose Reg3D-AD, a
registration-based 3D anomaly detection method incorporating a novel feature
memory bank that preserves local and global representations. Extensive
experiments on the Real3D-AD dataset highlight the effectiveness of Reg3D-AD.
For reproducibility and accessibility, we provide the Real3D-AD dataset,
benchmark source code, and Reg3D-AD on our
website:https://github.com/M-3LAB/Real3D-AD.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13227" title="Abstract">arXiv:2309.13227</a> [<a href="/pdf/2309.13227" title="Download PDF">pdf</a>, <a href="/format/2309.13227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance of negative sampling in weak label learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Ankit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+F">Fuyu Tang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zelin Ye</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rita Singh</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+B">Bhiksha Raj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Weak-label learning is a challenging task that requires learning from data
"bags" containing positive and negative instances, but only the bag labels are
known. The pool of negative instances is usually larger than positive
instances, thus making selecting the most informative negative instance
critical for performance. Such a selection strategy for negative instances from
each bag is an open problem that has not been well studied for weak-label
learning. In this paper, we study several sampling strategies that can measure
the usefulness of negative instances for weak-label learning and select them
accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that
it improves the weak-label classification performance and reduces the
computational cost compared to random sampling methods. Our work reveals that
negative instances are not all equally irrelevant, and selecting them wisely
can benefit weak-label learning.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13229" title="Abstract">arXiv:2309.13229</a> [<a href="/pdf/2309.13229" title="Download PDF">pdf</a>, <a href="/format/2309.13229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heterogeneous Feature Representation for Digital Twin-Oriented Complex  Networked Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jiaqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gabrys%2C+B">Bogdan Gabrys</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+K">Katarzyna Musial</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Building models of Complex Networked Systems (CNS) that can accurately
represent reality forms an important research area. To be able to reflect real
world systems, the modelling needs to consider not only the intensity of
interactions between the entities but also features of all the elements of the
system. This study aims to improve the expressive power of node features in
Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous
feature representation principles. This involves representing features with
crisp feature values and fuzzy sets, each describing the objective and the
subjective inductions of the nodes' features and feature differences. Our
empirical analysis builds DT-CNSs to recreate realistic physical contact
networks in different countries from real node feature distributions based on
various representation principles and an optimised feature preference. We also
investigate their respective disaster resilience to an epidemic outbreak
starting from the most popular node. The results suggest that the increasing
flexibility of feature representation with fuzzy sets improves the expressive
power and enables more accurate modelling. In addition, the heterogeneous
features influence the network structure and the speed of the epidemic
outbreak, requiring various mitigation policies targeted at different people.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13230" title="Abstract">arXiv:2309.13230</a> [<a href="/pdf/2309.13230" title="Download PDF">pdf</a>, <a href="/format/2309.13230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NJUNLP&#x27;s Participation for the WMT2023 Quality Estimation Shared Task
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xiang Geng</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+Z">Zhejian Lai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shimin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiajun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We introduce the submissions of the NJUNLP team to the WMT 2023 Quality
Estimation (QE) shared task. Our team submitted predictions for the
English-German language pair on all two sub-tasks: (i) sentence- and word-level
quality prediction; and (ii) fine-grained error span detection. This year, we
further explore pseudo data methods for QE based on NJUQE framework
(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel
data from the WMT translation task. We pre-train the XLMR large model on pseudo
QE data, then fine-tune it on real QE data. At both stages, we jointly learn
sentence-level scores and word-level tags. Empirically, we conduct experiments
to find the key hyper-parameters that improve the performance. Technically, we
propose a simple method that covert the word-level outputs to fine-grained
error span results. Overall, our models achieved the best results in
English-German for both word-level and fine-grained error span detection
sub-tasks by a considerable margin.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13233" title="Abstract">arXiv:2309.13233</a> [<a href="/pdf/2309.13233" title="Download PDF">pdf</a>, <a href="/format/2309.13233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Simulation with Large Language Models for Evaluating Task-Oriented  Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Davidson%2C+S">Sam Davidson</a>, 
<a href="/search/cs?searchtype=author&query=Romeo%2C+S">Salvatore Romeo</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+R">Raphael Shu</a>, 
<a href="/search/cs?searchtype=author&query=Gung%2C+J">James Gung</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Arshit Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Mansour%2C+S">Saab Mansour</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">One of the major impediments to the development of new task-oriented dialogue
(TOD) systems is the need for human evaluation at multiple stages and
iterations of the development process. In an effort to move toward automated
evaluation of TOD, we propose a novel user simulator built using recently
developed large pretrained language models (LLMs). In order to increase the
linguistic diversity of our system relative to the related previous work, we do
not fine-tune the LLMs used by our system on existing TOD datasets; rather we
use in-context learning to prompt the LLMs to generate robust and
linguistically diverse output with the goal of simulating the behavior of human
interlocutors. Unlike previous work, which sought to maximize goal success rate
(GSR) as the primary metric of simulator performance, our goal is a system
which achieves a GSR similar to that observed in human interactions with TOD
systems. Using this approach, our current simulator is effectively able to
interact with several TOD systems, especially on single-intent conversational
goals, while generating lexically and syntactically diverse output relative to
previous simulators that rely upon fine-tuned models. Finally, we collect a
Human2Bot dataset of humans interacting with the same TOD systems with which we
experimented in order to better quantify these achievements.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13235" title="Abstract">arXiv:2309.13235</a> [<a href="/pdf/2309.13235" title="Download PDF">pdf</a>, <a href="/format/2309.13235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M$^3$CS: Multi-Target Masked Point Modeling with Learnable Codebook and  Siamese Decoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Q">Qibo Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Honghui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenxiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Haiming Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+H">Haochao Ying</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+W">Wei Hua</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaofei He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Masked point modeling has become a promising scheme of self-supervised
pre-training for point clouds. Existing methods reconstruct either the original
points or related features as the objective of pre-training. However,
considering the diversity of downstream tasks, it is necessary for the model to
have both low- and high-level representation modeling capabilities to capture
geometric details and semantic contexts during pre-training. To this end,
M$^3$CS is proposed to enable the model with the above abilities. Specifically,
with masked point cloud as input, M$^3$CS introduces two decoders to predict
masked representations and the original points simultaneously. While an extra
decoder doubles parameters for the decoding process and may lead to
overfitting, we propose siamese decoders to keep the amount of learnable
parameters unchanged. Further, we propose an online codebook projecting
continuous tokens into discrete ones before reconstructing masked points. In
such way, we can enforce the decoder to take effect through the combinations of
tokens rather than remembering each token. Comprehensive experiments show that
M$^3$CS achieves superior performance at both classification and segmentation
tasks, outperforming existing methods.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13236" title="Abstract">arXiv:2309.13236</a> [<a href="/pdf/2309.13236" title="Download PDF">pdf</a>, <a href="/format/2309.13236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accurately recover global quasiperiodic systems by finite points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jiang%2C+K">Kai Jiang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Q">Qi Zhou</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+P">Pingwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Quasiperiodic systems, related to irrational numbers, are space-filling
structures without decay nor translation invariance. How to accurately recover
these systems, especially for non-smooth cases, presents a big challenge in
numerical computation. In this paper, we propose a new algorithm, finite points
recovery (FPR) method, which is available for both smooth and non-smooth cases,
to address this challenge. The FPR method first establishes a homomorphism
between the lower-dimensional definition domain of the quasiperiodic function
and the higher-dimensional torus, then recovers the global quasiperiodic system
by employing interpolation technique with finite points in the definition
domain without dimensional lifting. Furthermore, we develop accurate and
efficient strategies of selecting finite points according to the arithmetic
properties of irrational numbers. The corresponding mathematical theory,
convergence analysis, and computational complexity analysis on choosing finite
points are presented. Numerical experiments demonstrate the effectiveness and
superiority of FPR approach in recovering both smooth quasiperiodic functions
and piecewise constant Fibonacci quasicrystals. While existing spectral methods
encounter difficulties in accurately recovering non-smooth quasiperiodic
functions.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13237" title="Abstract">arXiv:2309.13237</a> [<a href="/pdf/2309.13237" title="Download PDF">pdf</a>, <a href="/format/2309.13237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatial-Temporal Knowledge-Embedded Transformer for Video Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pu%2C+T">Tao Pu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tianshui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Hefeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yongyi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Liang Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video scene graph generation (VidSGG) aims to identify objects in visual
scenes and infer their relationships for a given video. It requires not only a
comprehensive understanding of each object scattered on the whole scene but
also a deep dive into their temporal motions and interactions. Inherently,
object pairs and their relationships enjoy spatial co-occurrence correlations
within each image and temporal consistency/transition correlations across
different images, which can serve as prior knowledge to facilitate VidSGG model
learning and inference. In this work, we propose a spatial-temporal
knowledge-embedded transformer (STKET) that incorporates the prior
spatial-temporal knowledge into the multi-head cross-attention mechanism to
learn more representative relationship representations. Specifically, we first
learn spatial co-occurrence and temporal transition correlations in a
statistical manner. Then, we design spatial and temporal knowledge-embedded
layers that introduce the multi-head cross-attention mechanism to fully explore
the interaction between visual representation and the knowledge to generate
spatial- and temporal-embedded representations, respectively. Finally, we
aggregate these representations for each subject-object pair to predict the
final semantic labels and their relationships. Extensive experiments show that
STKET outperforms current competing algorithms by a large margin, e.g.,
improving the mR@50 by 8.1%, 4.7%, and 2.1% on different settings over current
algorithms.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13240" title="Abstract">arXiv:2309.13240</a> [<a href="/pdf/2309.13240" title="Download PDF">pdf</a>, <a href="/format/2309.13240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeRF-Enhanced Outpainting for Faithful Field-of-View Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+R">Rui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiachen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zihan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S+X">Sharon X. Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">In various applications, such as robotic navigation and remote visual
assistance, expanding the field of view (FOV) of the camera proves beneficial
for enhancing environmental perception. Unlike image outpainting techniques
aimed solely at generating aesthetically pleasing visuals, these applications
demand an extended view that faithfully represents the scene. To achieve this,
we formulate a new problem of faithful FOV extrapolation that utilizes a set of
pre-captured images as prior knowledge of the scene. To address this problem,
we present a simple yet effective solution called NeRF-Enhanced Outpainting
(NEO) that uses extended-FOV images generated through NeRF to train a
scene-specific image outpainting model. To assess the performance of NEO, we
conduct comprehensive evaluations on three photorealistic datasets and one
real-world dataset. Extensive experiments on the benchmark datasets showcase
the robustness and potential of our method in addressing this challenge. We
believe our work lays a strong foundation for future exploration within the
research community.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13242" title="Abstract">arXiv:2309.13242</a> [<a href="/pdf/2309.13242" title="Download PDF">pdf</a>, <a href="/format/2309.13242" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniHead: Unifying Multi-Perception for Detection Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hantao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Rui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yachao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoran Duan</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yawen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+R">Runze Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiu Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yefeng Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The detection head constitutes a pivotal component within object detectors,
tasked with executing both classification and localization functions.
Regrettably, the commonly used parallel head often lacks omni perceptual
capabilities, such as deformation perception, global perception and cross-task
perception. Despite numerous methods attempt to enhance these abilities from a
single aspect, achieving a comprehensive and unified solution remains a
significant challenge. In response to this challenge, we have developed an
innovative detection head, termed UniHead, to unify three perceptual abilities
simultaneously. More precisely, our approach (1) introduces deformation
perception, enabling the model to adaptively sample object features; (2)
proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range
dependencies, thereby achieving global perception; and (3) devises a Cross-task
Interaction Transformer (CIT) that facilitates interaction between the
classification and localization branches, thus aligning the two tasks. As a
plug-and-play method, the proposed UniHead can be conveniently integrated with
existing detectors. Extensive experiments on the COCO dataset demonstrate that
our UniHead can bring significant improvements to many detectors. For instance,
the UniHead can obtain +2.7 AP gains in RetinaNet, +2.9 AP gains in FreeAnchor,
and +2.1 AP gains in GFL. The code will be publicly available. Code Url:
https://github.com/zht8506/UniHead.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13243" title="Abstract">arXiv:2309.13243</a> [<a href="/pdf/2309.13243" title="Download PDF">pdf</a>, <a href="/format/2309.13243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChEDDAR: Student-ChatGPT Dialogue in EFL Writing Education
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jieun Han</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+H">Haneul Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Myung%2C+J">Junho Myung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+T+Y">Tak Yeon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Ahn%2C+S">So-Yeon Ahn</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+A">Alice Oh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The integration of generative AI in education is expanding, yet empirical
analyses of large-scale, real-world interactions between students and AI
systems still remain limited. In this study, we present ChEDDAR, ChatGPT &amp; EFL
Learner's Dialogue Dataset As Revising an essay, which is collected from a
semester-long longitudinal experiment involving 212 college students enrolled
in English as Foreign Langauge (EFL) writing courses. The students were asked
to revise their essays through dialogues with ChatGPT. ChEDDAR includes a
conversation log, utterance-level essay edit history, self-rated satisfaction,
and students' intent, in addition to session-level pre-and-post surveys
documenting their objectives and overall experiences. We analyze students'
usage patterns and perceptions regarding generative AI with respect to their
intent and satisfaction. As a foundational step, we establish baseline results
for two pivotal tasks in task-oriented dialogue systems within educational
contexts: intent detection and satisfaction estimation. We finally suggest
further research to refine the integration of generative AI into education
settings, outlining potential scenarios utilizing ChEDDAR. ChEDDAR is publicly
available at https://github.com/zeunie/ChEDDAR.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13244" title="Abstract">arXiv:2309.13244</a> [<a href="/pdf/2309.13244" title="Download PDF">pdf</a>, <a href="/ps/2309.13244" title="Download PostScript">ps</a>, <a href="/format/2309.13244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chunking Tasks for Present-Biased Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Halpern%2C+J">Joe Halpern</a>, 
<a href="/search/cs?searchtype=author&query=Saraf%2C+A">Aditya Saraf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Economics and Computation 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Everyone puts things off sometimes. How can we combat this tendency to
procrastinate? A well-known technique used by instructors is to break up a
large project into more manageable chunks. But how should this be done best?
Here we study the process of chunking using the graph-theoretic model of
present bias introduced by Kleinberg and Oren (2014). We first analyze how to
optimally chunk single edges within a task graph, given a limited number of
chunks. We show that for edges on the shortest path, the optimal chunking makes
initial chunks easy and later chunks progressively harder. For edges not on the
shortest path, optimal chunking is significantly more complex, but we provide
an efficient algorithm that chunks the edge optimally. We then use our optimal
edge-chunking algorithm to optimally chunk task graphs. We show that with a
linear number of chunks on each edge, the biased agent's cost can be
exponentially lowered, to within a constant factor of the true cheapest path.
Finally, we extend our model to the case where a task designer must chunk a
graph for multiple types of agents simultaneously. The problem grows
significantly more complex with even two types of agents, but we provide
optimal graph chunking algorithms for two types. Our work highlights the
efficacy of chunking as a means to combat present bias.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13245" title="Abstract">arXiv:2309.13245</a> [<a href="/pdf/2309.13245" title="Download PDF">pdf</a>, <a href="/format/2309.13245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+J">Jinhao Duan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Lyutianyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Ping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jize Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, there has been a surge of interest and attention in
Transformer-based structures, such as Vision Transformer (ViT) and Vision
Multilayer Perceptron (VMLP). Compared with the previous convolution-based
structures, the Transformer-based structure under investigation showcases a
comparable or superior performance under its distinctive attention-based input
token mixer strategy. Introducing adversarial examples as a robustness
consideration has had a profound and detrimental impact on the performance of
well-established convolution-based structures. This inherent vulnerability to
adversarial attacks has also been demonstrated in Transformer-based structures.
In this paper, our emphasis lies on investigating the intrinsic robustness of
the structure rather than introducing novel defense measures against
adversarial attacks. To address the susceptibility to robustness issues, we
employ a rational structure design approach to mitigate such vulnerabilities.
Specifically, we enhance the adversarial robustness of the structure by
increasing the proportion of high-frequency structural robust biases. As a
result, we introduce a novel structure called Robust Bias Transformer-based
Structure (RBFormer) that shows robust superiority compared to several existing
baseline structures. Through a series of extensive experiments, RBFormer
outperforms the original structures by a significant margin, achieving an
impressive improvement of +16.12% and +5.04% across different evaluation
criteria on CIFAR-10 and ImageNet-1k, respectively.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13246" title="Abstract">arXiv:2309.13246</a> [<a href="/pdf/2309.13246" title="Download PDF">pdf</a>, <a href="/ps/2309.13246" title="Download PostScript">ps</a>, <a href="/format/2309.13246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can I Trust the Explanations? Investigating Explainable Machine Learning  Methods for Monotonic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangxing Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">In recent years, explainable machine learning methods have been very
successful. Despite their success, most explainable machine learning methods
are applied to black-box models without any domain knowledge. By incorporating
domain knowledge, science-informed machine learning models have demonstrated
better generalization and interpretation. But do we obtain consistent
scientific explanations if we apply explainable machine learning methods to
science-informed machine learning models? This question is addressed in the
context of monotonic models that exhibit three different types of monotonicity.
To demonstrate monotonicity, we propose three axioms. Accordingly, this study
shows that when only individual monotonicity is involved, the baseline Shapley
value provides good explanations; however, when strong pairwise monotonicity is
involved, the Integrated gradients method provides reasonable explanations on
average.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13247" title="Abstract">arXiv:2309.13247</a> [<a href="/pdf/2309.13247" title="Download PDF">pdf</a>, <a href="/format/2309.13247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-modal Domain Adaptation for REG via Relation Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yifan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Domain adaptation, which aims to transfer knowledge between domains, has been
well studied in many areas such as image classification and object detection.
However, for multi-modal tasks, conventional approaches rely on large-scale
pre-training. But due to the difficulty of acquiring multi-modal data,
large-scale pre-training is often impractical. Therefore, domain adaptation,
which can efficiently utilize the knowledge from different datasets (domains),
is crucial for multi-modal tasks. In this paper, we focus on the Referring
Expression Grounding (REG) task, which is to localize an image region described
by a natural language expression. Specifically, we propose a novel approach to
effectively transfer multi-modal knowledge through a specially
relation-tailored approach for the REG problem. Our approach tackles the
multi-modal domain adaptation problem by simultaneously enriching inter-domain
relations and transferring relations between domains. Experiments show that our
proposed approach significantly improves the transferability of multi-modal
domains and enhances adaptation performance in the REG problem.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13248" title="Abstract">arXiv:2309.13248</a> [<a href="/pdf/2309.13248" title="Download PDF">pdf</a>, <a href="/format/2309.13248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Amodal Video Segmentation from Learning Supervised Signals  with Object-centric Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+K">Ke Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jingshi Lei</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuelin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Miaopeng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+T">Tianjun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tong He</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanwei Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video amodal segmentation is a particularly challenging task in computer
vision, which requires to deduce the full shape of an object from the visible
parts of it. Recently, some studies have achieved promising performance by
using motion flow to integrate information across frames under a
self-supervised setting. However, motion flow has a clear limitation by the two
factors of moving cameras and object deformation. This paper presents a
rethinking to previous works. We particularly leverage the supervised signals
with object-centric representation in \textit{real-world scenarios}. The
underlying idea is the supervision signal of the specific object and the
features from different views can mutually benefit the deduction of the full
mask in any specific frame. We thus propose an Efficient object-centric
Representation amodal Segmentation (EoRaS). Specially, beyond solely relying on
supervision signals, we design a translation module to project image features
into the Bird's-Eye View (BEV), which introduces 3D information to improve
current feature quality. Furthermore, we propose a multi-view fusion layer
based temporal module which is equipped with a set of object slots and
interacts with features from different views by attention mechanism to fulfill
sufficient object representation completion. As a result, the full mask of the
object can be decoded from image features updated by object slots. Extensive
experiments on both real-world and synthetic benchmarks demonstrate the
superiority of our proposed method, achieving state-of-the-art performance. Our
code will be released at \url{https://github.com/kfan21/EoRaS}.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13249" title="Abstract">arXiv:2309.13249</a> [<a href="/pdf/2309.13249" title="Download PDF">pdf</a>, <a href="/format/2309.13249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Document-Level Information Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hanwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lifu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Document-level information extraction (IE) is a crucial task in natural
language processing (NLP). This paper conducts a systematic review of recent
document-level IE literature. In addition, we conduct a thorough error analysis
with current state-of-the-art algorithms and identify their limitations as well
as the remaining challenges for the task of document-level IE. According to our
findings, labeling noises, entity coreference resolution, and lack of
reasoning, severely affect the performance of document-level IE. The objective
of this survey paper is to provide more insights and help NLP researchers to
further enhance document-level IE performance.
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13254" title="Abstract">arXiv:2309.13254</a> [<a href="/pdf/2309.13254" title="Download PDF">pdf</a>, <a href="/format/2309.13254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zen: Near-Optimal Sparse Tensor Synchronization for Distributed DNN  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhuang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhaozhuo Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Anshumali Shrivastava</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+T+S+E">T. S. Eugene Ng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Distributed training is the de facto standard to scale up the training of
Deep Neural Networks (DNNs) with multiple GPUs. The performance bottleneck of
distributed training lies in communications for gradient synchronization.
Recently, practitioners have observed sparsity in gradient tensors, suggesting
the potential to reduce the traffic volume in communication and improve
end-to-end training efficiency. Yet, the optimal communication scheme to fully
leverage sparsity is still missing. This paper aims to address this gap. We
first analyze the characteristics of sparse tensors in popular DNN models to
understand the fundamentals of sparsity. We then systematically explore the
design space of communication schemes for sparse tensors and find the optimal
one. % We then find the optimal scheme based on the characteristics by
systematically exploring the design space. We also develop a gradient
synchronization system called Zen that approximately realizes it for sparse
tensors. We demonstrate that Zen can achieve up to 5.09x speedup in
communication time and up to 2.48x speedup in training throughput compared to
the state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13255" title="Abstract">arXiv:2309.13255</a> [<a href="/pdf/2309.13255" title="Download PDF">pdf</a>, <a href="/format/2309.13255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Multiscale Coupling Methods of Molecular Mechanics based on a  Unified Framework of a Posteriori Error Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Yangshuai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">Multiscale coupling methods are significant methodologies for the modeling
and simulation of materials with defects, intending to achieve the
(quasi-)optimal balance of accuracy and efficiency. The a posteriori analysis
and corresponding adaptive algorithms play a crucial role in the efficient
implementation of multiscale coupling methods. This paper proposes a unified
framework for residual-based a posteriori error estimates that can be applied
to general consistent multiscale coupling methods. In particular, we prove that
the error estimator based on the residual force can provide the upper bound of
the true approximation error. As prototypical examples, we present a variety of
adaptive computations based on this reliable error estimator for the blended
atomistic-to-continuum (a/c) coupling methods, including the energy-based
blended quasi-continuum (BQCE), the force-based blended quasi-continuum (BQCF)
and the recently developed blended ghost force correction (BGFC) methods. We
develop a coarse-grained technique for the efficient evaluation of the error
estimator. A robust adaptive algorithm is therefore proposed and validated with
different types of crystalline defects, some of which are not considered in
previous related literature on the adaptive a/c coupling methods. The results
demonstrate that the adaptive algorithm leads to the same optimal convergence
rate of the error as the a priori error estimate, but with considerable
computational efficiency. This study provides valuable insights into the design
and implementation of adaptive multiscale methods, and represents a significant
contribution to the literature on a/c coupling methods.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13256" title="Abstract">arXiv:2309.13256</a> [<a href="/pdf/2309.13256" title="Download PDF">pdf</a>, <a href="/format/2309.13256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defending Pre-trained Language Models as Few-shot Learners against  Backdoor Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhaohan Xi</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changjiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+R">Ren Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shouling Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+F">Fenglong Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained language models (PLMs) have demonstrated remarkable performance
as few-shot learners. However, their security risks under such settings are
largely unexplored. In this work, we conduct a pilot study showing that PLMs as
few-shot learners are highly vulnerable to backdoor attacks while existing
defenses are inadequate due to the unique challenges of few-shot scenarios. To
address such challenges, we advocate MDP, a novel lightweight, pluggable, and
effective defense for PLMs as few-shot learners. Specifically, MDP leverages
the gap between the masking-sensitivity of poisoned and clean samples: with
reference to the limited few-shot data as distributional anchors, it compares
the representations of given samples under varying masking and identifies
poisoned samples as ones with significant variations. We show analytically that
MDP creates an interesting dilemma for the attacker to choose between attack
effectiveness and detection evasiveness. The empirical evaluation using
benchmark datasets and representative attacks validates the efficacy of MDP.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13257" title="Abstract">arXiv:2309.13257</a> [<a href="/pdf/2309.13257" title="Download PDF">pdf</a>, <a href="/format/2309.13257" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RTrack: Accelerating Convergence for Visual Object Tracking via  Pseudo-Boxes Exploration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+G">Guotian Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+B">Bi Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianqi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Q">Qingmao Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single object tracking (SOT) heavily relies on the representation of the
target object as a bounding box. However, due to the potential deformation and
rotation experienced by the tracked targets, the genuine bounding box fails to
capture the appearance information explicitly and introduces cluttered
background. This paper proposes RTrack, a novel object representation baseline
tracker that utilizes a set of sample points to get a pseudo bounding box.
RTrack automatically arranges these points to define the spatial extents and
highlight local areas. Building upon the baseline, we conducted an in-depth
exploration of the training potential and introduced a one-to-many leading
assignment strategy. It is worth noting that our approach achieves competitive
performance to the state-of-the-art trackers on the GOT-10k dataset while
reducing training time to just 10% of the previous state-of-the-art (SOTA)
trackers' training costs. The substantial reduction in training costs brings
single-object tracking (SOT) closer to the object detection (OD) task.
Extensive experiments demonstrate that our proposed RTrack achieves SOTA
results with faster convergence.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13258" title="Abstract">arXiv:2309.13258</a> [<a href="/pdf/2309.13258" title="Download PDF">pdf</a>, <a href="/format/2309.13258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Order-preserving Consistency Regularization for Domain Adaptation and  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jing%2C+M">Mengmeng Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhen%2C+X">Xiantong Zhen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingjing Li</a>, 
<a href="/search/cs?searchtype=author&query=Snoek%2C+C">Cees Snoek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deep learning models fail on cross-domain challenges if the model is
oversensitive to domain-specific attributes, e.g., lightning, background,
camera angle, etc. To alleviate this problem, data augmentation coupled with
consistency regularization are commonly adopted to make the model less
sensitive to domain-specific attributes. Consistency regularization enforces
the model to output the same representation or prediction for two views of one
image. These constraints, however, are either too strict or not
order-preserving for the classification probabilities. In this work, we propose
the Order-preserving Consistency Regularization (OCR) for cross-domain tasks.
The order-preserving property for the prediction makes the model robust to
task-irrelevant transformations. As a result, the model becomes less sensitive
to the domain-specific attributes. The comprehensive experiments show that our
method achieves clear advantages on five different cross-domain tasks.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13259" title="Abstract">arXiv:2309.13259</a> [<a href="/pdf/2309.13259" title="Download PDF">pdf</a>, <a href="/format/2309.13259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WikiMT++ Dataset Card
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Monan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shangda Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT),
featuring 1010 curated lead sheets in ABC notation. To expand application
scenarios of WikiMT, we add both objective (album, lyrics, video) and
subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes,
enhancing its usability for music information retrieval, conditional music
generation, automatic composition, and emotion classification, etc.
Additionally, CLaMP is implemented to correct the attributes inherited from
WikiMT to reduce errors introduced during original data collection and enhance
the accuracy and completeness of our dataset.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13264" title="Abstract">arXiv:2309.13264</a> [<a href="/pdf/2309.13264" title="Download PDF">pdf</a>, <a href="/format/2309.13264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Randomize to Generalize: Domain Randomization for Runway FOD Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farooq%2C+J">Javaria Farooq</a>, 
<a href="/search/cs?searchtype=author&query=Aafaq%2C+N">Nayyer Aafaq</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+M+K+A">M Khizer Ali Khan</a>, 
<a href="/search/cs?searchtype=author&query=Saleem%2C+A">Ammar Saleem</a>, 
<a href="/search/cs?searchtype=author&query=Siddiqui%2C+M+I">M Ibraheem Siddiqui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Tiny Object Detection is challenging due to small size, low resolution,
occlusion, background clutter, lighting conditions and small object-to-image
ratio. Further, object detection methodologies often make underlying assumption
that both training and testing data remain congruent. However, this presumption
often leads to decline in performance when model is applied to
out-of-domain(unseen) data. Techniques like synthetic image generation are
employed to improve model performance by leveraging variations in input data.
Such an approach typically presumes access to 3D-rendered datasets. In
contrast, we propose a novel two-stage methodology Synthetic Randomized Image
Augmentation (SRIA), carefully devised to enhance generalization capabilities
of models encountering 2D datasets, particularly with lower resolution which is
more practical in real-world scenarios. The first stage employs a weakly
supervised technique to generate pixel-level segmentation masks. Subsequently,
the second stage generates a batch-wise synthesis of artificial images,
carefully designed with an array of diverse augmentations. The efficacy of
proposed technique is illustrated on challenging foreign object debris (FOD)
detection. We compare our results with several SOTA models including CenterNet,
SSD, YOLOv3, YOLOv4, YOLOv5, and Outer Vit on a publicly available FOD-A
dataset. We also construct an out-of-distribution test set encompassing 800
annotated images featuring a corpus of ten common categories. Notably, by
harnessing merely 1.81% of objects from source training data and amalgamating
with 29 runway background images, we generate 2227 synthetic images. Subsequent
model retraining via transfer learning, utilizing enriched dataset generated by
domain randomization, demonstrates significant improvement in detection
accuracy. We report that detection accuracy improved from an initial 41% to 92%
for OOD test set.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13265" title="Abstract">arXiv:2309.13265</a> [<a href="/pdf/2309.13265" title="Download PDF">pdf</a>, <a href="/format/2309.13265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Declarative Specification for Authoring Metrics Dashboards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Epperson%2C+W">Will Epperson</a>, 
<a href="/search/cs?searchtype=author&query=Wongsuphasawat%2C+K">Kanit Wongsuphasawat</a>, 
<a href="/search/cs?searchtype=author&query=Whilden%2C+A">Allison Whilden</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+F">Fan Du</a>, 
<a href="/search/cs?searchtype=author&query=Talbot%2C+J">Justin Talbot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at Visual Data Science (VDS) Symposium at IEEE VIS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Despite their ubiquity, authoring dashboards for metrics reporting in modern
data analysis tools remains a manual, time-consuming process. Rather than
focusing on interesting combinations of their data, users have to spend time
creating each chart in a dashboard one by one. This makes dashboard creation
slow and tedious. We conducted a review of production metrics dashboards and
found that many dashboards contain a common structure: breaking down one or
more metrics by different dimensions. In response, we developed a high-level
specification for describing dashboards as sections of metrics repeated across
the same dimensions and a graphical interface, Quick Dashboard, for authoring
dashboards based on this specification. We present several usage examples that
demonstrate the flexibility of this specification to create various kinds of
dashboards and support a data-first approach to dashboard authoring.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13266" title="Abstract">arXiv:2309.13266</a> [<a href="/pdf/2309.13266" title="Download PDF">pdf</a>, <a href="/format/2309.13266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Navigation with Cross-Modal Fusion and Knowledge Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Wenzhe Cai</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+G">Guangran Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Lingyue Kong</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+L">Lu Dong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Changyin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICRA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, learning-based approaches show promising results in navigation
tasks. However, the poor generalization capability and the simulation-reality
gap prevent a wide range of applications. We consider the problem of improving
the generalization of mobile robots and achieving sim-to-real transfer for
navigation skills. To that end, we propose a cross-modal fusion method and a
knowledge transfer framework for better generalization. This is realized by a
teacher-student distillation architecture. The teacher learns a discriminative
representation and the near-perfect policy in an ideal environment. By
imitating the behavior and representation of the teacher, the student is able
to align the features from noisy multi-modal input and reduce the influence of
variations on navigation policy. We evaluate our method in simulated and
real-world environments. Experiments show that our method outperforms the
baselines by a large margin and achieves robust navigation performance with
varying working conditions.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13269" title="Abstract">arXiv:2309.13269</a> [<a href="/pdf/2309.13269" title="Download PDF">pdf</a>, <a href="/format/2309.13269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided  Quality Scores
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+P">Pengfei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuhan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+J">Jiubin Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Localization Quality Estimation (LQE) helps to improve detection performance
as it benefits post processing through jointly considering classification score
and localization accuracy. In this perspective, for further leveraging the
close relationship between localization accuracy and IoU
(Intersection-Over-Union), and for depressing those inconsistent predictions,
we designed an elegant LQE branch to acquire localization quality score guided
by predicted IoU. Distinctly, for alleviating the inconsistency of
classification score and localization quality during training and inference,
under which some predictions with low classification scores but high LQE scores
will impair the performance, instead of separately and independently setting,
we embedded LQE branch into classification branch, producing a joint
classification-localization-quality representation. Then a novel one stage
detector termed CLQ is proposed. Extensive experiments show that CLQ achieves
state-of-the-arts' performance at an accuracy of 47.8 AP and a speed of 11.5
fps with ResNeXt-101 as backbone on COCO test-dev. Finally, we extend CLQ to
ATSS, producing a reliable 1.2 AP gain, showing our model's strong adaptability
and scalability. Codes are released at https://github.com/PanffeeReal/CLQ.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13271" title="Abstract">arXiv:2309.13271</a> [<a href="/pdf/2309.13271" title="Download PDF">pdf</a>, <a href="/format/2309.13271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Secure Inter-domain Routing and Forwarding via Verifiable Forwarding  Commitments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoliang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhuotao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qi Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yangfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Sitong Ling</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+J">Jiangou Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Ke Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 17 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">The Internet inter-domain routing system is vulnerable. On the control plane,
the de facto Border Gateway Protocol (BGP) does not have built-in mechanisms to
authenticate routing announcements, so an adversary can announce virtually
arbitrary paths to hijack network traffic; on the data plane, it is difficult
to ensure that actual forwarding path complies with the control plane
decisions. The community has proposed significant research to secure the
routing system. Yet, existing secure BGP protocols (e.g., BGPsec) are not
incrementally deployable, and existing path authorization protocols are not
compatible with the current Internet routing infrastructure. In this paper, we
propose FC-BGP, the first secure Internet inter-domain routing system that can
simultaneously authenticate BGP announcements and validate data plane
forwarding in an efficient and incrementally-deployable manner. FC-BGP is built
upon a novel primitive, name Forwarding Commitment, to certify an AS's routing
intent on its directly connected hops. We analyze the security benefits of
FC-BGP in the Internet at different deployment rates. Further, we implement a
prototype of FC-BGP and extensively evaluate it over a large-scale overlay
network with 100 virtual machines deployed globally. The results demonstrate
that FC-BGP saves roughly 55% of the overhead required to validate BGP
announcements compared with BGPsec, and meanwhile FC-BGP introduces a small
overhead for building a globally-consistent view on the desirable forwarding
paths.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13272" title="Abstract">arXiv:2309.13272</a> [<a href="/pdf/2309.13272" title="Download PDF">pdf</a>, <a href="/format/2309.13272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Natural Language Processing for Requirements Formalization: How to  Derive New Approaches?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sudhi%2C+V">Viju Sudhi</a>, 
<a href="/search/cs?searchtype=author&query=Kutty%2C+L">Libin Kutty</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6pler%2C+R">Robin Gr&#xf6;pler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 7 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Concurrency, Specification and Programming. Studies in
  Computational Intelligence, vol 1091. Springer, Cham, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">It is a long-standing desire of industry and research to automate the
software development and testing process as much as possible. In this process,
requirements engineering (RE) plays a fundamental role for all other steps that
build on it. Model-based design and testing methods have been developed to
handle the growing complexity and variability of software systems. However,
major effort is still required to create specification models from a large set
of functional requirements provided in natural language. Numerous approaches
based on natural language processing (NLP) have been proposed in the literature
to generate requirements models using mainly syntactic properties. Recent
advances in NLP show that semantic quantities can also be identified and used
to provide better assistance in the requirements formalization process. In this
work, we present and discuss principal ideas and state-of-the-art methodologies
from the field of NLP in order to guide the readers on how to create a set of
rules and methods for the semi-automated formalization of requirements
according to their specific use case and needs. We discuss two different
approaches in detail and highlight the iterative development of rule sets. The
requirements models are represented in a human- and machine-readable format in
the form of pseudocode. The presented methods are demonstrated on two
industrial use cases from the automotive and railway domains. It shows that
using current pre-trained NLP models requires less effort to create a set of
rules and can be easily adapted to specific use cases and domains. In addition,
findings and shortcomings of this research area are highlighted and an outlook
on possible future developments is given.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13274" title="Abstract">arXiv:2309.13274</a> [<a href="/pdf/2309.13274" title="Download PDF">pdf</a>, <a href="/format/2309.13274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided  Video DecodER
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mingzhen Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zihan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiahui Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sihan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jing Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video generation necessitates both global coherence and local realism. This
work presents a novel non-autoregressive method GLOBER, which first generates
global features to obtain comprehensive global guidance and then synthesizes
video frames based on the global features to generate coherent videos.
Specifically, we propose a video auto-encoder, where a video encoder encodes
videos into global features, and a video decoder, built on a diffusion model,
decodes the global features and synthesizes video frames in a
non-autoregressive manner. To achieve maximum flexibility, our video decoder
perceives temporal information through normalized frame indexes, which enables
it to synthesize arbitrary sub video clips with predetermined starting and
ending frame indexes. Moreover, a novel adversarial loss is introduced to
improve the global coherence and local realism between the synthesized video
frames. Finally, we employ a diffusion-based video generator to fit the global
features outputted by the video encoder for video generation. Extensive
experimental results demonstrate the effectiveness and efficiency of our
proposed method, and new state-of-the-art results have been achieved on
multiple benchmarks.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13276" title="Abstract">arXiv:2309.13276</a> [<a href="/pdf/2309.13276" title="Download PDF">pdf</a>, <a href="/format/2309.13276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discwise Active Learning for LiDAR Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Unal%2C+O">Ozan Unal</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+D">Dengxin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Unal%2C+A+T">Ali Tamer Unal</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE RA-L
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">While LiDAR data acquisition is easy, labeling for semantic segmentation
remains highly time consuming and must therefore be done selectively. Active
learning (AL) provides a solution that can iteratively and intelligently label
a dataset while retaining high performance and a low budget. In this work we
explore AL for LiDAR semantic segmentation. As a human expert is a component of
the pipeline, a practical framework must consider common labeling techniques
such as sequential labeling that drastically improve annotation times. We
therefore propose a discwise approach (DiAL), where in each iteration, we query
the region a single frame covers on global coordinates, labeling all frames
simultaneously. We then tackle the two major challenges that emerge with
discwise AL. Firstly we devise a new acquisition function that takes 3D point
density changes into consideration which arise due to location changes or
ego-vehicle motion. Next we solve a mixed-integer linear program that provides
a general solution to the selection of multiple frames while taking into
consideration the possibilities of disc intersections. Finally we propose a
semi-supervised learning approach to utilize all frames within our dataset and
improve performance.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13281" title="Abstract">arXiv:2309.13281</a> [<a href="/pdf/2309.13281" title="Download PDF">pdf</a>, <a href="/format/2309.13281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Reverse Engineering: Creating computer-aided design (CAD)  models from multi-view images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jobczyk%2C+H">Henrik Jobczyk</a>, 
<a href="/search/cs?searchtype=author&query=Homann%2C+H">Hanno Homann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at GCPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generation of computer-aided design (CAD) models from multi-view images may
be useful in many practical applications. To date, this problem is usually
solved with an intermediate point-cloud reconstruction and involves manual work
to create the final CAD models. In this contribution, we present a novel
network for an automated reverse engineering task. Our network architecture
combines three distinct stages: A convolutional neural network as the encoder
stage, a multi-view pooling stage and a transformer-based CAD sequence
generator.
<br />The model is trained and evaluated on a large number of simulated input
images and extensive optimization of model architectures and hyper-parameters
is performed. A proof-of-concept is demonstrated by successfully reconstructing
a number of valid CAD models from simulated test image data. Various accuracy
metrics are calculated and compared to a state-of-the-art point-based network.
<br />Finally, a real world test is conducted supplying the network with actual
photographs of two three-dimensional test objects. It is shown that some of the
capabilities of our network can be transferred to this domain, even though the
training exclusively incorporates purely synthetic training data. However to
date, the feasible model complexity is still limited to basic shapes.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13285" title="Abstract">arXiv:2309.13285</a> [<a href="/pdf/2309.13285" title="Download PDF">pdf</a>, <a href="/format/2309.13285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collision Avoidance and Navigation for a Quadrotor Swarm Using  End-to-end Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zhehui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhaojing Yang</a>, 
<a href="/search/cs?searchtype=author&query=Krupani%2C+R">Rahul Krupani</a>, 
<a href="/search/cs?searchtype=author&query=%C5%9Eenba%C5%9Flar%2C+B">Bask&#x131;n &#x15e;enba&#x15f;lar</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+S">Sumeet Batra</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G+S">Gaurav S. Sukhatme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
<p class="mathjax">End-to-end deep reinforcement learning (DRL) for quadrotor control promises
many benefits -- easy deployment, task generalization and real-time execution
capability. Prior end-to-end DRL-based methods have showcased the ability to
deploy learned controllers onto single quadrotors or quadrotor teams
maneuvering in simple, obstacle-free environments. However, the addition of
obstacles increases the number of possible interactions exponentially, thereby
increasing the difficulty of training RL policies. In this work, we propose an
end-to-end DRL approach to control quadrotor swarms in environments with
obstacles. We provide our agents a curriculum and a replay buffer of the
clipped collision episodes to improve performance in obstacle-rich
environments. We implement an attention mechanism to attend to the neighbor
robots and obstacle interactions - the first successful demonstration of this
mechanism on policies for swarm behavior deployed on severely
compute-constrained hardware. Our work is the first work that demonstrates the
possibility of learning neighbor-avoiding and obstacle-avoiding control
policies trained with end-to-end DRL that transfers zero-shot to real
quadrotors. Our approach scales to 32 robots with 80% obstacle density in
simulation and 8 robots with 20% obstacle density in physical deployment. Video
demonstrations are available on the project website at:
https://sites.google.com/view/obst-avoid-swarm-rl.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13287" title="Abstract">arXiv:2309.13287</a> [<a href="/pdf/2309.13287" title="Download PDF">pdf</a>, <a href="/format/2309.13287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conjunctive Queries on Probabilistic Graphs: The Limits of  Approximability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amarilli%2C+A">Antoine Amarilli</a>, 
<a href="/search/cs?searchtype=author&query=van+Bremen%2C+T">Timothy van Bremen</a>, 
<a href="/search/cs?searchtype=author&query=Meel%2C+K+S">Kuldeep S. Meel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages. Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Query evaluation over probabilistic databases is a notoriously intractable
problem -- not only in combined complexity, but for many natural queries in
data complexity as well. This motivates the study of probabilistic query
evaluation through the lens of approximation algorithms, and particularly of
combined FPRASes, whose runtime is polynomial in both the query and instance
size. In this paper, we focus on tuple-independent probabilistic databases over
binary signatures, which can be equivalently viewed as probabilistic graphs. We
study in which cases we can devise combined FPRASes for probabilistic query
evaluation in this setting.
<br />We settle the complexity of this problem for a variety of query and instance
classes, by proving both approximability and (conditional) inapproximability
results. This allows us to deduce many corollaries of possible independent
interest. For example, we show how the results of Arenas et al. on counting
fixed-length strings accepted by an NFA imply the existence of an FPRAS for the
two-terminal network reliability problem on directed acyclic graphs: this was
an open problem until now. We also show that one cannot extend the recent
result of van Bremen and Meel that gives a combined FPRAS for self-join-free
conjunctive queries of bounded hypertree width on probabilistic databases:
neither the bounded-hypertree-width condition nor the self-join-freeness
hypothesis can be relaxed. Finally, we complement all our inapproximability
results with unconditional lower bounds, showing that DNNF provenance circuits
must have at least moderately exponential size in combined complexity.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13289" title="Abstract">arXiv:2309.13289</a> [<a href="/pdf/2309.13289" title="Download PDF">pdf</a>, <a href="/format/2309.13289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofan Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Daipeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zhuyang Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 9 figures, 71 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Unsupervised skin lesion segmentation offers several benefits, including
conserving expert human resources, reducing discrepancies due to subjective
human labeling, and adapting to novel environments. However, segmenting
dermoscopic images without manual labeling guidance presents significant
challenges due to dermoscopic image artifacts such as hair noise, blister
noise, and subtle edge differences. To address these challenges, we introduce
an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin
lesion segmentation. The USL-Net can effectively segment a range of lesions,
eliminating the need for manual labeling guidance. Initially, features are
extracted using contrastive learning, followed by the generation of Class
Activation Maps (CAMs) as saliency maps using these features. The different CAM
locations correspond to the importance of the lesion region based on their
saliency. High-saliency regions in the map serve as pseudo-labels for lesion
regions while low-saliency regions represent the background. However,
intermediate regions can be hard to classify, often due to their proximity to
lesion edges or interference from hair or blisters. Rather than risk potential
pseudo-labeling errors or learning confusion by forcefully classifying these
regions, we consider them as uncertainty regions, exempting them from
pseudo-labeling and allowing the network to self-learn. Further, we employ
connectivity detection and centrality detection to refine foreground
pseudo-labels and reduce noise-induced errors. The application of cycle
refining enhances performance further. Our method underwent thorough
experimental validation on the ISIC-2017, ISIC-2018, and PH2 datasets,
demonstrating that its performance is on par with weakly supervised and
supervised methods, and exceeds that of other existing unsupervised methods.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13292" title="Abstract">arXiv:2309.13292</a> [<a href="/pdf/2309.13292" title="Download PDF">pdf</a>, <a href="/format/2309.13292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Fairness: Age-Harmless Parkinson&#x27;s Detection via Voice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yicheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+X">Xiaotian Han</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Leisheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+N">Na Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Parkinson's disease (PD), a neurodegenerative disorder, often manifests as
speech and voice dysfunction. While utilizing voice data for PD detection has
great potential in clinical applications, the widely used deep learning models
currently have fairness issues regarding different ages of onset. These deep
models perform well for the elderly group (age $&gt;$ 55) but are less accurate
for the young group (age $\leq$ 55). Through our investigation, the discrepancy
between the elderly and the young arises due to 1) an imbalanced dataset and 2)
the milder symptoms often seen in early-onset patients. However, traditional
debiasing methods are impractical as they typically impair the prediction
accuracy for the majority group while minimizing the discrepancy. To address
this issue, we present a new debiasing method using GradCAM-based feature
masking combined with ensemble models, ensuring that neither fairness nor
accuracy is compromised. Specifically, the GradCAM-based feature masking
selectively obscures age-related features in the input voice data while
preserving essential information for PD detection. The ensemble models further
improve the prediction accuracy for the minority (young group). Our approach
effectively improves detection accuracy for early-onset patients without
sacrificing performance for the elderly group. Additionally, we propose a
two-step detection strategy for the young group, offering a practical risk
assessment for potential early-onset PD patients.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13294" title="Abstract">arXiv:2309.13294</a> [<a href="/pdf/2309.13294" title="Download PDF">pdf</a>, <a href="/format/2309.13294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MP-MVS: Multi-Scale Windows PatchMatch and Planar Prior Multi-View  Stereo
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+R">Rongxuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xueyan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+C">Chao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Youyang Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Significant strides have been made in enhancing the accuracy of Multi-View
Stereo (MVS)-based 3D reconstruction. However, untextured areas with unstable
photometric consistency often remain incompletely reconstructed. In this paper,
we propose a resilient and effective multi-view stereo approach (MP-MVS). We
design a multi-scale windows PatchMatch (mPM) to obtain reliable depth of
untextured areas. In contrast with other multi-scale approaches, which is
faster and can be easily extended to PatchMatch-based MVS approaches.
Subsequently, we improve the existing checkerboard sampling schemes by limiting
our sampling to distant regions, which can effectively improve the efficiency
of spatial propagation while mitigating outlier generation. Finally, we
introduce and improve planar prior assisted PatchMatch of ACMP. Instead of
relying on photometric consistency, we utilize geometric consistency
information between multi-views to select reliable triangulated vertices. This
strategy can obtain a more accurate planar prior model to rectify photometric
consistency measurements. Our approach has been tested on the ETH3D High-res
multi-view benchmark with several state-of-the-art approaches. The results
demonstrate that our approach can reach the state-of-the-art. The associated
codes will be accessible at https://github.com/RongxuanTan/MP-MVS.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13296" title="Abstract">arXiv:2309.13296</a> [<a href="/pdf/2309.13296" title="Download PDF">pdf</a>, <a href="/format/2309.13296" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Content Diversity and User Exploration in Online Movie  Recommenders: A Field Experiment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Akella%2C+A">Avinash Akella</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+R">Ruoyan Kong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+M">Moyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Konstan%2C+J+A">Joseph A. Konstan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International Journal of Human Computer Interaction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Recommender systems often struggle to strike a balance between matching
users' tastes and providing unexpected recommendations. When recommendations
are too narrow and fail to cover the full range of users' preferences, the
system is perceived as useless. Conversely, when the system suggests too many
items that users don't like, it is considered impersonal or ineffective. To
better understand user sentiment about the breadth of recommendations given by
a movie recommender, we conducted interviews and surveys and found out that
many users considered narrow recommendations to be useful, while a smaller
number explicitly wanted greater breadth. Additionally, we designed and ran an
online field experiment with a larger user group, evaluating two new interfaces
designed to provide users with greater access to broader recommendations. We
looked at user preferences and behavior for two groups of users: those with
higher initial movie diversity and those with lower diversity. Among our
findings, we discovered that different level of exploration control and users'
subjective preferences on interfaces are more predictive of their satisfaction
with the recommender.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13297" title="Abstract">arXiv:2309.13297</a> [<a href="/pdf/2309.13297" title="Download PDF">pdf</a>, <a href="/format/2309.13297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for  Aspect-Based Sentiment Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chebolu%2C+S+U+S">Siva Uday Sampreeth Chebolu</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Lipka%2C+N">Nedim Lipka</a>, 
<a href="/search/cs?searchtype=author&query=Solorio%2C+T">Thamar Solorio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Initial submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Aspect-based sentiment Analysis (ABSA) delves into understanding sentiments
specific to distinct elements within textual content. It aims to analyze
user-generated reviews to determine a) the target entity being reviewed, b) the
high-level aspect to which it belongs, c) the sentiment words used to express
the opinion, and d) the sentiment expressed toward the targets and the aspects.
While various benchmark datasets have fostered advancements in ABSA, they often
come with domain limitations and data granularity challenges. Addressing these,
we introduce the OATS dataset, which encompasses three fresh domains and
consists of 20,000 sentence-level quadruples and 13,000 review-level tuples.
Our initiative seeks to bridge specific observed gaps: the recurrent focus on
familiar domains like restaurants and laptops, limited data for intricate
quadruple extraction tasks, and an occasional oversight of the synergy between
sentence and review-level sentiments. Moreover, to elucidate OATS's potential
and shed light on various ABSA subtasks that OATS can solve, we conducted
in-domain and cross-domain experiments, establishing initial baselines. We hope
the OATS dataset augments current resources, paving the way for an encompassing
exploration of ABSA.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13300" title="Abstract">arXiv:2309.13300</a> [<a href="/pdf/2309.13300" title="Download PDF">pdf</a>, <a href="/format/2309.13300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sewage Discharging in a Line: Global Optimization and Grand Cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xucheng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lindong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yifu Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">Anran Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
<p class="mathjax">Players cooperating in a line is a special while essential phenomenon in real
life collaborating activities such as assembly line production, pipeline supply
chain management and other streamlining operational settings. In this paper, we
study the scenario of cooperative sewage discharge with multiple participants
positioning in a line along a river such that the optimization decision and
cooperation strategy are mutually affected by both upstream and downstream
players. We make three main contributions accordingly: Firstly, we formalize
the sewage discharge problem (SDP) for different groups of players, and use
greedy strategy and dynamic programming to design the optimal algorithms to
solve the SDP in polynomial time. Secondly, we show that the cooperative game
defined on sewage discharge problem, referred to as SDG, has a non-empty core
due to its special line-positioning structure. Therefore, a grand stable
cooperation is guaranteed. Furthermore, inspired by the fact that the SDG is
core non-empty while non-convex, we successfully identify a relaxed concept of
convexity -- directional-convexity, which can also serve as a sufficient
condition for a cooperative game having a non-empty core.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13302" title="Abstract">arXiv:2309.13302</a> [<a href="/pdf/2309.13302" title="Download PDF">pdf</a>, <a href="/format/2309.13302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaining the Sparse Rewards by Exploring Binary Lottery Tickets in  Spiking Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+H">Hao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiahang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+E">Erjia Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+P">Pu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Mengshu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jize Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xue Lin</a>, 
<a href="/search/cs?searchtype=author&query=Kailkhura%2C+B">Bhavya Kailkhura</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kaidi Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Renjing Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Spiking Neural Network (SNN) as a brain-inspired strategy receives lots of
attention because of the high-sparsity and low-power properties derived from
its inherent spiking information state. To further improve the efficiency of
SNN, some works declare that the Lottery Tickets (LTs) Hypothesis, which
indicates that the Artificial Neural Network (ANN) contains a subnetwork
without sacrificing the performance of the original network, also exists in
SNN. However, the spiking information handled by SNN has a natural similarity
and affinity with binarization in sparsification. Therefore, to further explore
SNN efficiency, this paper focuses on (1) the presence or absence of LTs in the
binary SNN, and (2) whether the spiking mechanism is a superior strategy in
terms of handling binary information compared to simple model binarization. To
certify these consumptions, a sparse training method is proposed to find Binary
Weights Spiking Lottery Tickets (BinW-SLT) under different network structures.
Through comprehensive evaluations, we show that BinW-SLT could attain up to
+5.86% and +3.17% improvement on CIFAR-10 and CIFAR-100 compared with binary
LTs, as well as achieve 1.86x and 8.92x energy saving compared with
full-precision SNN and ANN.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13303" title="Abstract">arXiv:2309.13303</a> [<a href="/pdf/2309.13303" title="Download PDF">pdf</a>, <a href="/format/2309.13303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> C$^2$VAE: Gaussian Copula-based VAE Differing Disentangled from Coupled  Representations with Contrastive Posterior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zhangkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
<p class="mathjax">We present a self-supervised variational autoencoder (VAE) to jointly learn
disentangled and dependent hidden factors and then enhance disentangled
representation learning by a self-supervised classifier to eliminate coupled
representations in a contrastive manner. To this end, a Contrastive Copula VAE
(C$^2$VAE) is introduced without relying on prior knowledge about data in the
probabilistic principle and involving strong modeling assumptions on the
posterior in the neural architecture. C$^2$VAE simultaneously factorizes the
posterior (evidence lower bound, ELBO) with total correlation (TC)-driven
decomposition for learning factorized disentangled representations and extracts
the dependencies between hidden features by a neural Gaussian copula for copula
coupled representations. Then, a self-supervised contrastive classifier
differentiates the disentangled representations from the coupled
representations, where a contrastive loss regularizes this contrastive
classification together with the TC loss for eliminating entangled factors and
strengthening disentangled representations. C$^2$VAE demonstrates a strong
effect in enhancing disentangled representation learning. C$^2$VAE further
contributes to improved optimization addressing the TC-based VAE instability
and the trade-off between reconstruction and representation.
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13305" title="Abstract">arXiv:2309.13305</a> [<a href="/pdf/2309.13305" title="Download PDF">pdf</a>, <a href="/format/2309.13305" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilevel User Credibility Assessment in Social Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moradi%2C+M">Mohammad Moradi</a>, 
<a href="/search/cs?searchtype=author&query=Chehreghani%2C+M+H">Mostafa Haghir Chehreghani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">Online social networks are one of the largest platforms for disseminating
both real and fake news. Many users on these networks, intentionally or
unintentionally, spread harmful content, fake news, and rumors in fields such
as politics and business. As a result, numerous studies have been conducted in
recent years to assess the credibility of users. A shortcoming of most of
existing methods is that they assess users by placing them in one of two
categories, real or fake. However, in real-world applications it is usually
more desirable to consider several levels of user credibility. Another
shortcoming is that existing approaches only use a portion of important
features, which downgrades their performance. In this paper, due to the lack of
an appropriate dataset for multilevel user credibility assessment, first we
design a method to collect data suitable to assess credibility at multiple
levels. Then, we develop the MultiCred model that places users at one of
several levels of credibility, based on a rich and diverse set of features
extracted from users' profile, tweets and comments. MultiCred exploits deep
language models to analyze textual data and deep neural models to process
non-textual features. Our extensive experiments reveal that MultiCred
considerably outperforms existing approaches, in terms of several accuracy
measures.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13306" title="Abstract">arXiv:2309.13306</a> [<a href="/pdf/2309.13306" title="Download PDF">pdf</a>, <a href="/format/2309.13306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Incomplete Annotation Issue in Universal Lesion Detection  Task By Exploratory Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+X">Xiaoyu Bai</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+B">Benteng Ma</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Changyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yong Xia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Universal lesion detection has great value for clinical practice as it aims
to detect various types of lesions in multiple organs on medical images. Deep
learning methods have shown promising results, but demanding large volumes of
annotated data for training. However, annotating medical images is costly and
requires specialized knowledge. The diverse forms and contrasts of objects in
medical images make fully annotation even more challenging, resulting in
incomplete annotations. Directly training ULD detectors on such datasets can
yield suboptimal results. Pseudo-label-based methods examine the training data
and mine unlabelled objects for retraining, which have shown to be effective to
tackle this issue. Presently, top-performing methods rely on a dynamic
label-mining mechanism, operating at the mini-batch level. However, the model's
performance varies at different iterations, leading to inconsistencies in the
quality of the mined labels and limits their performance enhancement. Inspired
by the observation that deep models learn concepts with increasing complexity,
we introduce an innovative exploratory training to assess the reliability of
mined lesions over time. Specifically, we introduce a teacher-student detection
model as basis, where the teacher's predictions are combined with incomplete
annotations to train the student. Additionally, we design a prediction bank to
record high-confidence predictions. Each sample is trained several times,
allowing us to get a sequence of records for each sample. If a prediction
consistently appears in the record sequence, it is likely to be a true object,
otherwise it may just a noise. This serves as a crucial criterion for selecting
reliable mined lesions for retraining. Our experimental results substantiate
that the proposed framework surpasses state-of-the-art methods on two medical
image datasets, demonstrating its superior performance.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13307" title="Abstract">arXiv:2309.13307</a> [<a href="/pdf/2309.13307" title="Download PDF">pdf</a>, <a href="/format/2309.13307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CORE: Common Random Reconstruction for Distributed Optimization with  Provable Low Communication Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+P">Pengyun Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hanzhen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Cong Fang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+D">Di He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhouchen Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+S">Song-chun Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">With distributed machine learning being a prominent technique for large-scale
machine learning tasks, communication complexity has become a major bottleneck
for speeding up training and scaling up machine numbers. In this paper, we
propose a new technique named Common randOm REconstruction(CORE), which can be
used to compress the information transmitted between machines in order to
reduce communication complexity without other strict conditions. Especially,
our technique CORE projects the vector-valued information to a low-dimensional
one through common random vectors and reconstructs the information with the
same random noises after communication. We apply CORE to two distributed tasks,
respectively convex optimization on linear models and generic non-convex
optimization, and design new distributed algorithms, which achieve provably
lower communication complexities. For example, we show for linear models
CORE-based algorithm can encode the gradient vector to $\mathcal{O}(1)$-bits
(against $\mathcal{O}(d)$), with the convergence rate not worse, preceding the
existing results.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13308" title="Abstract">arXiv:2309.13308</a> [<a href="/pdf/2309.13308" title="Download PDF">pdf</a>, <a href="/format/2309.13308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibrating LLM-Based Evaluator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuxuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+T">Tianchi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaohan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zihan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haizhen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+F">Furu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Feng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages,11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Recent advancements in large language models (LLMs) on language modeling and
emergent capabilities make them a promising reference-free evaluator of natural
language generation quality, and a competent alternative to human evaluation.
However, hindered by the closed-source or high computational demand to host and
tune, there is a lack of practice to further calibrate an off-the-shelf
LLM-based evaluator towards better human alignment. In this work, we propose
AutoCalibrate, a multi-stage, gradient-free approach to automatically calibrate
and align an LLM-based evaluator toward human preference. Instead of explicitly
modeling human preferences, we first implicitly encompass them within a set of
human labels. Then, an initial set of scoring criteria is drafted by the
language model itself, leveraging in-context learning on different few-shot
examples. To further calibrate this set of criteria, we select the best
performers and re-draft them with self-refinement. Our experiments on multiple
text quality evaluation datasets illustrate a significant improvement in
correlation with expert evaluation through calibration. Our comprehensive
qualitative analysis conveys insightful intuitions and observations on the
essence of effective scoring criteria.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13310" title="Abstract">arXiv:2309.13310</a> [<a href="/pdf/2309.13310" title="Download PDF">pdf</a>, <a href="/format/2309.13310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Interpretable Systematic Review of Machine Learning Models for  Predictive Maintenance of Aircraft Engine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasib%2C+A+A">Abdullah Al Hasib</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+A">Ashikur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Khabir%2C+M">Mahpara Khabir</a>, 
<a href="/search/cs?searchtype=author&query=Shawon%2C+M+T+R">Md. Tanvir Rouf Shawon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper presents an interpretable review of various machine learning and
deep learning models to predict the maintenance of aircraft engine to avoid any
kind of disaster. One of the advantages of the strategy is that it can work
with modest datasets. In this study, sensor data is utilized to predict
aircraft engine failure within a predetermined number of cycles using LSTM,
Bi-LSTM, RNN, Bi-RNN GRU, Random Forest, KNN, Naive Bayes, and Gradient
Boosting. We explain how deep learning and machine learning can be used to
generate predictions in predictive maintenance using a straightforward scenario
with just one data source. We applied lime to the models to help us understand
why machine learning models did not perform well than deep learning models. An
extensive analysis of the model's behavior is presented for several test data
to understand the black box scenario of the models. A lucrative accuracy of
97.8%, 97.14%, and 96.42% are achieved by GRU, Bi-LSTM, and LSTM respectively
which denotes the capability of the models to predict maintenance at an early
stage.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13311" title="Abstract">arXiv:2309.13311</a> [<a href="/pdf/2309.13311" title="Download PDF">pdf</a>, <a href="/format/2309.13311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tag-based Visual Odometry Estimation for Indoor UAVs Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bertoni%2C+M">Massimiliano Bertoni</a>, 
<a href="/search/cs?searchtype=author&query=Montecchio%2C+S">Simone Montecchio</a>, 
<a href="/search/cs?searchtype=author&query=Michieletto%2C+G">Giulia Michieletto</a>, 
<a href="/search/cs?searchtype=author&query=Oboe%2C+R">Roberto Oboe</a>, 
<a href="/search/cs?searchtype=author&query=Cenedese%2C+A">Angelo Cenedese</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The agility and versatility offered by UAV platforms still encounter
obstacles for full exploitation in industrial applications due to their indoor
usage limitations. A significant challenge in this sense is finding a reliable
and cost-effective way to localize aerial vehicles in a GNSS-denied
environment. In this paper, we focus on the visual-based positioning paradigm:
high accuracy in UAVs position and orientation estimation is achieved by
leveraging the potentials offered by a dense and size-heterogenous map of tags.
In detail, we propose an efficient visual odometry procedure focusing on
hierarchical tags selection, outliers removal, and multi-tag estimation fusion,
to facilitate the visual-inertial reconciliation. Experimental results show the
validity of the proposed localization architecture as compared to the state of
the art.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13316" title="Abstract">arXiv:2309.13316</a> [<a href="/pdf/2309.13316" title="Download PDF">pdf</a>, <a href="/ps/2309.13316" title="Download PostScript">ps</a>, <a href="/format/2309.13316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> High order approximation to Caputo derivative on graded mesh and  time-fractional diffusion equation for non-smooth solutions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kumari%2C+S">Shweta Kumari</a>, 
<a href="/search/math?searchtype=author&query=Singh%2C+A+K">Abhishek Kumar Singh</a>, 
<a href="/search/math?searchtype=author&query=Mehandiratta%2C+V">Vaibhav Mehandiratta</a>, 
<a href="/search/math?searchtype=author&query=Mehra%2C+M">Mani Mehra</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 2 figures and 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, a high-order approximation to Caputo-type time-fractional
diffusion equations involving an initial-time singularity of the solution is
proposed. At first, we employ a numerical algorithm based on the Lagrange
polynomial interpolation to approximate the Caputo derivative on the
non-uniform mesh. Then truncation error rate and the optimal grading constant
of the approximation on a graded mesh are obtained as
$\min\{4-\alpha,r\alpha\}$ and $\frac{4-\alpha}{\alpha}$, respectively, where
$\alpha\in(0,1)$ is the order of fractional derivative and $r\geq 1$ is the
mesh grading parameter. Using this new approximation, a difference scheme for
the Caputo-type time-fractional diffusion equation on graded temporal mesh is
formulated. The scheme proves to be uniquely solvable for general $r$. Then we
derive the unconditional stability of the scheme on uniform mesh. The
convergence of the scheme, in particular for $r=1$, is analyzed for non-smooth
solutions and concluded for smooth solutions. Finally, the accuracy of the
scheme is verified by analyzing the error through a few numerical examples.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13317" title="Abstract">arXiv:2309.13317</a> [<a href="/pdf/2309.13317" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Class Attendance System in Education with Deep Learning Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demir%2C+H">H&#xfc;daverdi Demir</a>, 
<a href="/search/cs?searchtype=author&query=Sava%C5%9F%2C+S">Serkan Sava&#x15f;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> International LET-IN 2022 Conference Proceedings Book, October 06-08, 2022, Ankara, T\"urkiye. ISBN: 978-605-71971-1-5
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International LET-IN (LEarning &amp; Teaching INovations) 2022
  Conference Proceedings Book, pp: 151-160, October 06-08, 2022, Ankara,
  Turkiye
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">With the advancing technology, the hardware gain of computers and the
increase in the processing capacity of processors have facilitated the
processing of instantaneous and real-time images. Face recognition processes
are also studies in the field of image processing. Facial recognition processes
are frequently used in security applications and commercial applications.
Especially in the last 20 years, the high performances of artificial
intelligence (AI) studies have contributed to the spread of these studies in
many different fields. Education is one of them. The potential and advantages
of using AI in education; can be grouped under three headings: student,
teacher, and institution. One of the institutional studies may be the security
of educational environments and the contribution of automation to education and
training processes. From this point of view, deep learning methods, one of the
sub-branches of AI, were used in this study. For object detection from images,
a pioneering study has been designed and successfully implemented to keep
records of students' entrance to the educational institution and to perform
class attendance with images taken from the camera using image processing
algorithms. The application of the study to real-life problems will be carried
out in a school determined in the 2022-2023 academic year.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13318" title="Abstract">arXiv:2309.13318</a> [<a href="/pdf/2309.13318" title="Download PDF">pdf</a>, <a href="/format/2309.13318" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spanish Resource Grammar version 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zamaraeva%2C+O">Olga Zamaraeva</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Rodr%C3%ADguez%2C+C">Carlos G&#xf3;mez-Rodr&#xed;guez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present the latest version of the Spanish Resource Grammar (SRG). The new
SRG uses the recent version of Freeling morphological analyzer and tagger and
is accompanied by a manually verified treebank and a list of documented issues.
We also present the grammar's coverage and overgeneration on a small portion of
a learner corpus, an entirely new research line with respect to the SRG. The
grammar can be used for linguistic research, such as for empirically driven
development of syntactic theory, and in natural language processing
applications such as computer-assisted language learning. Finally, as the
treebanks grow, they can be used for training high-quality semantic parsers and
other systems which may benefit from precise and detailed semantics.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13320" title="Abstract">arXiv:2309.13320</a> [<a href="/pdf/2309.13320" title="Download PDF">pdf</a>, <a href="/format/2309.13320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GlotScript: A Resource and Tool for Low Resource Writing System  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kargaran%2C+A+H">Amir Hossein Kargaran</a>, 
<a href="/search/cs?searchtype=author&query=Yvon%2C+F">Fran&#xe7;ois Yvon</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtze%2C+H">Hinrich Sch&#xfc;tze</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present GlotScript, an open resource and tool for low resource writing
system identification. GlotScript-R is a resource that provides the attested
writing systems for more than 7,000 languages. It is compiled by aggregating
information from existing writing system resources. GlotScript-T is a writing
system identification tool that covers all 161 Unicode 15.0 scripts. For an
input text, it returns its script distribution where scripts are identified by
ISO 15924 codes. We also present two use cases for GlotScript. First, we
demonstrate that GlotScript supports cleaning multilingual corpora such as mC4
and OSCAR. Second, we analyze the tokenization of a number of language models
such as GPT-4 using GlotScript and provide insights on the coverage of low
resource scripts and languages by each language model. We hope that GlotScript
will become a useful resource for work on low resource languages in the NLP
community. GlotScript-R and GlotScript-T are available at
https://github.com/cisnlp/GlotScript.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13321" title="Abstract">arXiv:2309.13321</a> [<a href="/pdf/2309.13321" title="Download PDF">pdf</a>, <a href="/format/2309.13321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ONNX-to-Hardware Design Flow for the Generation of Adaptive  Neural-Network Accelerators on FPGAs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manca%2C+F">Federico Manca</a>, 
<a href="/search/cs?searchtype=author&query=Ratto%2C+F">Francesco Ratto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the CPS workshop 2023 (<a href="http://www.cpsschool.eu/cps-workshop">this http URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Neural Networks (NN) provide a solid and reliable way of executing different
types of applications, ranging from speech recognition to medical diagnosis,
speeding up onerous and long workloads. The challenges involved in their
implementation at the edge include providing diversity, flexibility, and
sustainability. That implies, for instance, supporting evolving applications
and algorithms energy-efficiently. Using hardware or software accelerators can
deliver fast and efficient computation of the \acp{nn}, while flexibility can
be exploited to support long-term adaptivity. Nonetheless, handcrafting an NN
for a specific device, despite the possibility of leading to an optimal
solution, takes time and experience, and that's why frameworks for hardware
accelerators are being developed. This work-in-progress study focuses on
exploring the possibility of combining the toolchain proposed by Ratto et al.,
which has the distinctive ability to favor adaptivity, with approximate
computing. The goal will be to allow lightweight adaptable NN inference on
FPGAs at the edge. Before that, the work presents a detailed review of
established frameworks that adopt a similar streaming architecture for future
comparison.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13322" title="Abstract">arXiv:2309.13322</a> [<a href="/pdf/2309.13322" title="Download PDF">pdf</a>, <a href="/format/2309.13322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Text to Source: Results in Detecting Large Language Model-Generated  Content
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antoun%2C+W">Wissam Antoun</a>, 
<a href="/search/cs?searchtype=author&query=Sagot%2C+B">Beno&#xee;t Sagot</a>, 
<a href="/search/cs?searchtype=author&query=Seddah%2C+D">Djam&#xe9; Seddah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The widespread use of Large Language Models (LLMs), celebrated for their
ability to generate human-like text, has raised concerns about misinformation
and ethical implications. Addressing these concerns necessitates the
development of robust methods to detect and attribute text generated by LLMs.
This paper investigates "Cross-Model Detection," evaluating whether a
classifier trained to distinguish between source LLM-generated and
human-written text can also detect text from a target LLM without further
training. The study comprehensively explores various LLM sizes and families,
and assesses the impact of conversational fine-tuning techniques on classifier
generalization. The research also delves into Model Attribution, encompassing
source model identification, model family classification, and model size
classification. Our results reveal several key findings: a clear inverse
relationship between classifier effectiveness and model size, with larger LLMs
being more challenging to detect, especially when the classifier is trained on
data from smaller models. Training on data from similarly sized LLMs can
improve detection performance from larger models but may lead to decreased
performance when dealing with smaller models. Additionally, model attribution
experiments show promising results in identifying source models and model
families, highlighting detectable signatures in LLM-generated text. Overall,
our study contributes valuable insights into the interplay of model size,
family, and training data in LLM detection and attribution.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13325" title="Abstract">arXiv:2309.13325</a> [<a href="/pdf/2309.13325" title="Download PDF">pdf</a>, <a href="/format/2309.13325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint Explainability and Sensitivity-Aware Federated Deep Learning for  Transparent 6G RAN Slicing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Swastika Roy</a>, 
<a href="/search/cs?searchtype=author&query=Rezazadeh%2C+F">Farhad Rezazadeh</a>, 
<a href="/search/cs?searchtype=author&query=Chergui%2C+H">Hatim Chergui</a>, 
<a href="/search/cs?searchtype=author&query=Verikoukis%2C+C">Christos Verikoukis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 Figure. arXiv admin note: substantial text overlap with <a href="/abs/2307.09494">arXiv:2307.09494</a>, <a href="/abs/2210.10147">arXiv:2210.10147</a>, <a href="/abs/2307.12903">arXiv:2307.12903</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">In recent years, wireless networks are evolving complex, which upsurges the
use of zero-touch artificial intelligence (AI)-driven network automation within
the telecommunication industry. In particular, network slicing, the most
promising technology beyond 5G, would embrace AI models to manage the complex
communication network. Besides, it is also essential to build the
trustworthiness of the AI black boxes in actual deployment when AI makes
complex resource management and anomaly detection. Inspired by closed-loop
automation and Explainable Artificial intelligence (XAI), we design an
Explainable Federated deep learning (FDL) model to predict per-slice RAN
dropped traffic probability while jointly considering the sensitivity and
explainability-aware metrics as constraints in such non-IID setup. In precise,
we quantitatively validate the faithfulness of the explanations via the
so-called attribution-based \emph{log-odds metric} that is included as a
constraint in the run-time FL optimization task. Simulation results confirm its
superiority over an unconstrained integrated-gradient (IG) \emph{post-hoc} FDL
baseline.
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13329" title="Abstract">arXiv:2309.13329</a> [<a href="/pdf/2309.13329" title="Download PDF">pdf</a>, <a href="/format/2309.13329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Ethereum&#x27;s Hidden Centralization Incentives: Does Connectivity  Impact Performance?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortes-Goicoechea%2C+M">Mikel Cortes-Goicoechea</a>, 
<a href="/search/cs?searchtype=author&query=Mohandas-Daryanani%2C+T">Tarun Mohandas-Daryanani</a>, 
<a href="/search/cs?searchtype=author&query=Munoz-Tapia%2C+J+L">Jose Luis Munoz-Tapia</a>, 
<a href="/search/cs?searchtype=author&query=Bautista-Gomez%2C+L">Leonardo Bautista-Gomez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> THE FIFTH INTERNATIONAL CONFERENCE ON BLOCKCHAIN COMPUTING AND APPLICATIONS (BCCA 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Modern public blockchains like Ethereum rely on p2p networks to run
distributed and censorship-resistant applications. With its wide adoption, it
operates as a highly critical public ledger. On its transition to become more
scalable and sustainable, shifting to PoS without sacrificing the security and
resilience of PoW, Ethereum offers a range of consensus clients to participate
in the network. In this paper, we present a methodology to measure the
performance of the consensus clients based on the latency to receive messages
from the p2p network. The paper includes a study that identifies the incentives
and limitations that the network experiences, presenting insights about the
latency impact derived from running the software in different locations.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13330" title="Abstract">arXiv:2309.13330</a> [<a href="/pdf/2309.13330" title="Download PDF">pdf</a>, <a href="/format/2309.13330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting Temperature of Major Cities Using Machine Learning and Deep  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaharabi%2C+W">Wasiou Jaharabi</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+I+A">MD Ibrahim Al Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Tahmid%2C+R">Rownak Tahmid</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+Z">Md. Zuhayer Islam</a>, 
<a href="/search/cs?searchtype=author&query=Rayhan%2C+T+M+S">T.M. Saad Rayhan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 31 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Currently, the issue that concerns the world leaders most is climate change
for its effect on agriculture, environment and economies of daily life. So, to
combat this, temperature prediction with strong accuracy is vital. So far, the
most effective widely used measure for such forecasting is Numerical weather
prediction (NWP) which is a mathematical model that needs broad data from
different applications to make predictions. This expensive, time and labor
consuming work can be minimized through making such predictions using Machine
learning algorithms. Using the database made by University of Dayton which
consists the change of temperature in major cities we used the Time Series
Analysis method where we use LSTM for the purpose of turning existing data into
a tool for future prediction. LSTM takes the long-term data as well as any
short-term exceptions or anomalies that may have occurred and calculates trend,
seasonality and the stationarity of a data. By using models such as ARIMA,
SARIMA, Prophet with the concept of RNN and LSTM we can, filter out any
abnormalities, preprocess the data compare it with previous trends and make a
prediction of future trends. Also, seasonality and stationarity help us analyze
the reoccurrence or repeat over one year variable and removes the constrain of
time in which the data was dependent so see the general changes that are
predicted. By doing so we managed to make prediction of the temperature of
different cities during any time in future based on available data and built a
method of accurate prediction. This document contains our methodology for being
able to make such predictions.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13333" title="Abstract">arXiv:2309.13333</a> [<a href="/pdf/2309.13333" title="Download PDF">pdf</a>, <a href="/format/2309.13333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> mdendro: An R package for extended agglomerative hierarchical clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fern%C3%A1ndez%2C+A">Alberto Fern&#xe1;ndez</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez%2C+S">Sergio G&#xf3;mez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 11 figures. Software available at CRAN (<a href="https://cran.r-project.org/package=mdendro">this https URL</a>) and Github (<a href="https://sergio-gomez.github.io/mdendro/">this https URL</a>)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Data Analysis, Statistics and Probability (physics.data-an); Computation (stat.CO)

</div>
<p class="mathjax">"mdendro" is an R package that provides a comprehensive collection of linkage
methods for agglomerative hierarchical clustering on a matrix of proximity data
(distances or similarities), returning a multifurcated dendrogram or
multidendrogram. Multidendrograms can group more than two clusters at the same
time, solving the nonuniqueness problem that arises when there are ties in the
data. This problem causes that different binary dendrograms are possible
depending both on the order of the input data and on the criterion used to
break ties. Weighted and unweighted versions of the most common linkage methods
are included in the package, which also implements two parametric linkage
methods. In addition, package "mdendro" provides five descriptive measures to
analyze the resulting dendrograms: cophenetic correlation coefficient, space
distortion ratio, agglomerative coefficient, chaining coefficient and tree
balance.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13335" title="Abstract">arXiv:2309.13335</a> [<a href="/pdf/2309.13335" title="Download PDF">pdf</a>, <a href="/format/2309.13335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-enhanced Vector Index
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hailin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yujing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+R">Ruiheng Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Ting Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+Z">Ziming Miao</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Yingyan Hou</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xupeng Miao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+B">Bochen Pang</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+Y">Yuefeng Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+W">Weiwei Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+F">Fan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xing Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Mao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+B">Bin Cui</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Embedding-based retrieval methods construct vector indices to search for
document representations that are most similar to the query representations.
They are widely used in document retrieval due to low latency and decent recall
performance. Recent research indicates that deep retrieval solutions offer
better model quality, but are hindered by unacceptable serving latency and the
inability to support document updates. In this paper, we aim to enhance the
vector index with end-to-end deep generative models, leveraging the
differentiable advantages of deep retrieval models while maintaining desirable
serving efficiency. We propose Model-enhanced Vector Index (MEVI), a
differentiable model-enhanced index empowered by a twin-tower representation
model. MEVI leverages a Residual Quantization (RQ) codebook to bridge the
sequence-to-sequence deep retrieval and embedding-based models. To
substantially reduce the inference time, instead of decoding the unique
document ids in long sequential steps, we first generate some semantic virtual
cluster ids of candidate documents in a small number of steps, and then
leverage the well-adapted embedding vectors to further perform a fine-grained
search for the relevant documents in the candidate virtual clusters. We
empirically show that our model achieves better performance on the commonly
used academic benchmarks MSMARCO Passage and Natural Questions, with comparable
serving latency to dense retrieval solutions.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13336" title="Abstract">arXiv:2309.13336</a> [<a href="/pdf/2309.13336" title="Download PDF">pdf</a>, <a href="/format/2309.13336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDrive v2: an Analysis of the Impact of Label Skewness in Federated  Semantic Segmentation for Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%C3%AC%2C+E">Eros Fan&#xec;</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5th Italian Conference on Robotics and Intelligent Machines (I-RIM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose FedDrive v2, an extension of the Federated Learning benchmark for
Semantic Segmentation in Autonomous Driving. While the first version aims at
studying the effect of domain shift of the visual features across clients, in
this work, we focus on the distribution skewness of the labels. We propose six
new federated scenarios to investigate how label skewness affects the
performance of segmentation models and compare it with the effect of domain
shift. Finally, we study the impact of using the domain information during
testing.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13337" title="Abstract">arXiv:2309.13337</a> [<a href="/pdf/2309.13337" title="Download PDF">pdf</a>, <a href="/format/2309.13337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Asymptotic Learning Curves of Kernel Ridge Regression under  Power-law Decay
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yicheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haobo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Q">Qian Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">The widely observed 'benign overfitting phenomenon' in the neural network
literature raises the challenge to the 'bias-variance trade-off' doctrine in
the statistical learning theory. Since the generalization ability of the 'lazy
trained' over-parametrized neural network can be well approximated by that of
the neural tangent kernel regression, the curve of the excess risk (namely, the
learning curve) of kernel ridge regression attracts increasing attention
recently. However, most recent arguments on the learning curve are heuristic
and are based on the 'Gaussian design' assumption. In this paper, under mild
and more realistic assumptions, we rigorously provide a full characterization
of the learning curve: elaborating the effect and the interplay of the choice
of the regularization parameter, the source condition and the noise. In
particular, our results suggest that the 'benign overfitting phenomenon' exists
in very wide neural networks only when the noise level is small.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13339" title="Abstract">arXiv:2309.13339</a> [<a href="/pdf/2309.13339" title="Download PDF">pdf</a>, <a href="/format/2309.13339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models  through Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xufeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengdi Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wenhao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Weber%2C+C">Cornelius Weber</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J+H">Jae Hee Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+K">Kun Chu</a>, 
<a href="/search/cs?searchtype=author&query=Wermter%2C+S">Stefan Wermter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Symbolic Computation (cs.SC)

</div>
<p class="mathjax">Recent advancements in large language models have showcased their remarkable
generalizability across various domains. However, their reasoning abilities
still have significant room for improvement, especially when confronted with
scenarios requiring multi-step reasoning. Although large language models
possess extensive knowledge, their behavior, particularly in terms of
reasoning, often fails to effectively utilize this knowledge to establish a
coherent thinking paradigm. Generative language models sometimes show
hallucinations as their reasoning procedures are unconstrained by logical
principles. Aiming to improve the zero-shot chain-of-thought reasoning ability
of large language models, we propose Logical Chain-of-Thought (LogiCoT), a
neurosymbolic framework that leverages principles from symbolic logic to verify
and revise the reasoning processes accordingly. Experimental evaluations
conducted on language tasks in diverse domains, including arithmetic,
commonsense, symbolic, causal inference, and social problems, demonstrate the
efficacy of the enhanced reasoning paradigm by logic.
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13340" title="Abstract">arXiv:2309.13340</a> [<a href="/pdf/2309.13340" title="Download PDF">pdf</a>, <a href="/format/2309.13340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain  Black-box Text Classifiers?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhattacharjee%2C+A">Amrita Bhattacharjee</a>, 
<a href="/search/cs?searchtype=author&query=Moraffah%2C+R">Raha Moraffah</a>, 
<a href="/search/cs?searchtype=author&query=Garland%2C+J">Joshua Garland</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Huan Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models (LLMs) are increasingly being used for tasks beyond
text generation, including complex tasks such as data labeling, information
extraction, etc. With the recent surge in research efforts to comprehend the
full extent of LLM capabilities, in this work, we investigate the role of LLMs
as counterfactual explanation modules, to explain decisions of black-box text
classifiers. Inspired by causal thinking, we propose a pipeline for using LLMs
to generate post-hoc, model-agnostic counterfactual explanations in a
principled way via (i) leveraging the textual understanding capabilities of the
LLM to identify and extract latent features, and (ii) leveraging the
perturbation and generation capabilities of the same LLM to generate a
counterfactual explanation by perturbing input features derived from the
extracted latent features. We evaluate three variants of our framework, with
varying degrees of specificity, on a suite of state-of-the-art LLMs, including
ChatGPT and LLaMA 2. We evaluate the effectiveness and quality of the generated
counterfactual explanations, over a variety of text classification benchmarks.
Our results show varied performance of these models in different settings, with
a full two-step feature extraction based variant outperforming others in most
cases. Our pipeline can be used in automated explanation systems, potentially
reducing human effort.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13342" title="Abstract">arXiv:2309.13342</a> [<a href="/pdf/2309.13342" title="Download PDF">pdf</a>, <a href="/format/2309.13342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evolve the Model Universe of a System Universe
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Uncertain, unpredictable, real time, and lifelong evolution causes
operational failures in intelligent software systems, leading to significant
damages, safety and security hazards, and tragedies. To fully unleash the
potential of such systems and facilitate their wider adoption, ensuring the
trustworthiness of their decision making under uncertainty is the prime
challenge. To overcome this challenge, an intelligent software system and its
operating environment should be continuously monitored, tested, and refined
during its lifetime operation. Existing technologies, such as digital twins,
can enable continuous synchronisation with such systems to reflect their most
updated states. Such representations are often in the form of prior knowledge
based and machine learning models, together called model universe. In this
paper, we present our vision of combining techniques from software engineering,
evolutionary computation, and machine learning to support the model universe
evolution.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13343" title="Abstract">arXiv:2309.13343</a> [<a href="/pdf/2309.13343" title="Download PDF">pdf</a>, <a href="/format/2309.13343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two vs. Four-Channel Sound Event Localization and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wilkins%2C+J">Julia Wilkins</a>, 
<a href="/search/cs?searchtype=author&query=Fuentes%2C+M">Magdalena Fuentes</a>, 
<a href="/search/cs?searchtype=author&query=Bondi%2C+L">Luca Bondi</a>, 
<a href="/search/cs?searchtype=author&query=Ghaffarzadegan%2C+S">Shabnam Ghaffarzadegan</a>, 
<a href="/search/cs?searchtype=author&query=Abavisani%2C+A">Ali Abavisani</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+J+P">Juan Pablo Bello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Sound event localization and detection (SELD) systems estimate both the
direction-of-arrival (DOA) and class of sound sources over time. In the DCASE
2022 SELD Challenge (Task 3), models are designed to operate in a 4-channel
setting. While beneficial to further the development of SELD systems using a
multichannel recording setup such as first-order Ambisonics (FOA), most
consumer electronics devices rarely are able to record using more than two
channels. For this reason, in this work we investigate the performance of the
DCASE 2022 SELD baseline model using three audio input representations: FOA,
binaural, and stereo. We perform a novel comparative analysis illustrating the
effect of these audio input representations on SELD performance. Crucially, we
show that binaural and stereo (i.e. 2-channel) audio-based SELD models are
still able to localize and detect sound sources laterally quite well, despite
overall performance degrading as less audio information is provided. Further,
we segment our analysis by scenes containing varying degrees of sound source
polyphony to better understand the effect of audio input representation on
localization and detection performance as scene conditions become increasingly
complex.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13345" title="Abstract">arXiv:2309.13345</a> [<a href="/pdf/2309.13345" title="Download PDF">pdf</a>, <a href="/format/2309.13345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAMBOO: A Comprehensive Benchmark for Evaluating Long Text Modeling  Capacities of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zican Dong</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+T">Tianyi Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+W+X">Wayne Xin Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Ji-Rong Wen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have achieved dramatic proficiency over NLP
tasks with normal length. Recently, multiple studies have committed to
extending the context length and enhancing the long text modeling capabilities
of LLMs. To comprehensively evaluate the long context ability of LLMs, we
propose BAMBOO, a multi-task long context benchmark. BAMBOO has been designed
with four principles: comprehensive capacity evaluation, avoidance of data
contamination, accurate automatic evaluation, and different length levels. It
consists of 10 datasets from 5 different long text understanding tasks, i.e.
question answering, hallucination detection, text sorting, language modeling,
and code completion, to cover core capacities and various domains of LLMs. We
conduct experiments with five long context models on BAMBOO and further discuss
four key research questions of long text. We also qualitatively analyze current
long context models and point out future directions for enhancing long text
modeling capacities. We release our data, prompts, and code at
https://github.com/RUCAIBox/BAMBOO.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13347" title="Abstract">arXiv:2309.13347</a> [<a href="/pdf/2309.13347" title="Download PDF">pdf</a>, <a href="/format/2309.13347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> My Science Tutor (MyST) -- A Large Corpus of Children&#x27;s Conversational  Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pradhan%2C+S+S">Sameer S. Pradhan</a>, 
<a href="/search/cs?searchtype=author&query=Cole%2C+R+A">Ronald A. Cole</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+W+H">Wayne H. Ward</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This article describes the MyST corpus developed as part of the My Science
Tutor project -- one of the largest collections of children's conversational
speech comprising approximately 400 hours, spanning some 230K utterances across
about 10.5K virtual tutor sessions by around 1.3K third, fourth and fifth grade
students. 100K of all utterances have been transcribed thus far. The corpus is
freely available (https://myst.cemantix.org) for non-commercial use using a
creative commons license. It is also available for commercial use
(https://boulderlearning.com/resources/myst-corpus/). To date, ten
organizations have licensed the corpus for commercial use, and approximately 40
university and other not-for-profit research groups have downloaded the corpus.
It is our hope that the corpus can be used to improve automatic speech
recognition algorithms, build and evaluate conversational AI agents for
education, and together help accelerate development of multimodal applications
to improve children's excitement and learning about science, and help them
learn remotely.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13349" title="Abstract">arXiv:2309.13349</a> [<a href="/pdf/2309.13349" title="Download PDF">pdf</a>, <a href="/format/2309.13349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding-up Evolutionary Algorithms to solve Black-Box Optimization  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Echevarrieta%2C+J">Judith Echevarrieta</a>, 
<a href="/search/cs?searchtype=author&query=Arza%2C+E">Etor Arza</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+A">Aritz P&#xe9;rez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Population-based evolutionary algorithms are often considered when
approaching computationally expensive black-box optimization problems. They
employ a selection mechanism to choose the best solutions from a given
population after comparing their objective values, which are then used to
generate the next population. This iterative process explores the solution
space efficiently, leading to improved solutions over time. However, these
algorithms require a large number of evaluations to provide a quality solution,
which might be computationally expensive when the evaluation cost is high. In
some cases, it is possible to replace the original objective function with a
less accurate approximation of lower cost. This introduces a trade-off between
the evaluation cost and its accuracy.
<br />In this paper, we propose a technique capable of choosing an appropriate
approximate function cost during the execution of the optimization algorithm.
The proposal finds the minimum evaluation cost at which the solutions are still
properly ranked, and consequently, more evaluations can be computed in the same
amount of time with minimal accuracy loss. An experimental section on four very
different problems reveals that the proposed approach can reach the same
objective value in less than half of the time in certain cases.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13352" title="Abstract">arXiv:2309.13352</a> [<a href="/pdf/2309.13352" title="Download PDF">pdf</a>, <a href="/ps/2309.13352" title="Download PostScript">ps</a>, <a href="/format/2309.13352" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hybrid High-Order Method for a Class of Strongly Nonlinear Elliptic  Boundary Value Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mallik%2C+G">Gouranga Mallik</a>, 
<a href="/search/math?searchtype=author&query=Gudi%2C+T">Thirupathi Gudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2110.15579">arXiv:2110.15579</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this article, we design and analyze a Hybrid High-Order (HHO) finite
element approximation for a class of strongly nonlinear boundary value
problems. We consider an HHO discretization for a suitable linearized problem
and show its well-posedness using the Gardings type inequality. The essential
ingredients for the HHO approximation involve local reconstruction and
high-order stabilization. We establish the existence of a unique solution for
the HHO approximation using the Brouwer fixed point theorem and contraction
principle. We derive an optimal order a priori error estimate in the discrete
energy norm. Numerical experiments are performed to illustrate the convergence
histories.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13353" title="Abstract">arXiv:2309.13353</a> [<a href="/pdf/2309.13353" title="Download PDF">pdf</a>, <a href="/format/2309.13353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Grids: Exploring Elastic Input Sampling for Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pardyl%2C+A">Adam Pardyl</a>, 
<a href="/search/cs?searchtype=author&query=Kurzejamski%2C+G">Grzegorz Kurzejamski</a>, 
<a href="/search/cs?searchtype=author&query=Olszewski%2C+J">Jan Olszewski</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Zieli%C5%84ski%2C+B">Bartosz Zieli&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision transformers have excelled in various computer vision tasks but mostly
rely on rigid input sampling using a fixed-size grid of patches. This limits
their applicability in real-world problems, such as in the field of robotics
and UAVs, where one can utilize higher input elasticity to boost model
performance and efficiency. Our paper addresses this limitation by formalizing
the concept of input elasticity for vision transformers and introducing an
evaluation protocol, including dedicated metrics for measuring input
elasticity. Moreover, we propose modifications to the transformer architecture
and training regime, which increase its elasticity. Through extensive
experimentation, we spotlight opportunities and challenges associated with
input sampling strategies.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13354" title="Abstract">arXiv:2309.13354</a> [<a href="/pdf/2309.13354" title="Download PDF">pdf</a>, <a href="/format/2309.13354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal  Hate Speech Detection using Fused Ensemble Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kashif%2C+M">Mohammad Kashif</a>, 
<a href="/search/cs?searchtype=author&query=Zohair%2C+M">Mohammad Zohair</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Saquib Ali</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">With a surge in the usage of social media postings to express opinions,
emotions, and ideologies, there has been a significant shift towards the
calibration of social media as a rapid medium of conveying viewpoints and
outlooks over the globe. Concurrently, the emergence of a multitude of
conflicts between two entities has given rise to a stream of social media
content containing propaganda, hate speech, and inconsiderate views. Thus, the
issue of monitoring social media postings is rising swiftly, attracting major
attention from those willing to solve such problems. One such problem is Hate
Speech detection. To mitigate this problem, we present our novel ensemble
learning approach for detecting hate speech, by classifying text-embedded
images into two labels, namely "Hate Speech" and "No Hate Speech". We have
incorporated state-of-art models including InceptionV3, BERT, and XLNet. Our
proposed ensemble model yielded promising results with 75.21 and 74.96 as
accuracy and F-1 score (respectively). We also present an empirical evaluation
of the text-embedded images to elaborate on how well the model was able to
predict and classify. We release our codebase here
(https://github.com/M0hammad-Kashif/MultiModalHateSpeech).
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13356" title="Abstract">arXiv:2309.13356</a> [<a href="/pdf/2309.13356" title="Download PDF">pdf</a>, <a href="/format/2309.13356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Large Language Models&#x27; Cognitive Moral Development through  Defining Issues Test
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanmay%2C+K">Kumar Tanmay</a>, 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+A">Aditi Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+U">Utkarsh Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Choudhury%2C+M">Monojit Choudhury</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development of large language models has instilled widespread interest
among the researchers to understand their inherent reasoning and
problem-solving capabilities. Despite good amount of research going on to
elucidate these capabilities, there is a still an appreciable gap in
understanding moral development and judgments of these models. The current
approaches of evaluating the ethical reasoning abilities of these models as a
classification task pose numerous inaccuracies because of over-simplification.
In this study, we built a psychological connection by bridging two disparate
fields-human psychology and AI. We proposed an effective evaluation framework
which can help to delineate the model's ethical reasoning ability in terms of
moral consistency and Kohlberg's moral development stages with the help of
Psychometric Assessment Tool-Defining Issues Test.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13358" title="Abstract">arXiv:2309.13358</a> [<a href="/pdf/2309.13358" title="Download PDF">pdf</a>, <a href="/format/2309.13358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Quantum Software Requirements Engineering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Shaukat Ali</a>, 
<a href="/search/cs?searchtype=author&query=Arcaini%2C+P">Paolo Arcaini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Quantum software engineering (QSE) is receiving increasing attention, as
evidenced by increasing publications on topics, e.g., quantum software
modeling, testing, and debugging. However, in the literature, quantum software
requirements engineering (QSRE) is still a software engineering area that is
relatively less investigated. To this end, in this paper, we provide an initial
set of thoughts about how requirements engineering for quantum software might
differ from that for classical software after making an effort to map classical
requirements classifications (e.g., functional and extra-functional
requirements) into the context of quantum software. Moreover, we provide
discussions on various aspects of QSRE that deserve attention from the quantum
software engineering community.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13360" title="Abstract">arXiv:2309.13360</a> [<a href="/pdf/2309.13360" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impacts of DEM Type and Resolution on Deep Learning-Based Flood  Inundation Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fereshtehpour%2C+M">Mohammad Fereshtehpour</a>, 
<a href="/search/cs?searchtype=author&query=Esmaeilzadeh%2C+M">Mostafa Esmaeilzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Alipour%2C+R+S">Reza Saleh Alipour</a>, 
<a href="/search/cs?searchtype=author&query=Burian%2C+S+J">Steven J. Burian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">This paper presents a comprehensive study focusing on the influence of DEM
type and spatial resolution on the accuracy of flood inundation prediction. The
research employs a state-of-the-art deep learning method using a 1D
convolutional neural network (CNN). The CNN-based method employs training input
data in the form of synthetic hydrographs, along with target data represented
by water depth obtained utilizing a 2D hydrodynamic model, LISFLOOD-FP. The
performance of the trained CNN models is then evaluated and compared with the
observed flood event. This study examines the use of digital surface models
(DSMs) and digital terrain models (DTMs) derived from a LIDAR-based 1m DTM,
with resolutions ranging from 15 to 30 meters. The proposed methodology is
implemented and evaluated in a well-established benchmark location in Carlisle,
UK. The paper also discusses the applicability of the methodology to address
the challenges encountered in a data-scarce flood-prone region, exemplified by
Pakistan. The study found that DTM performs better than DSM at lower
resolutions. Using a 30m DTM improved flood depth prediction accuracy by about
21% during the peak stage. Increasing the resolution to 15m increased RMSE and
overlap index by at least 50% and 20% across all flood phases. The study
demonstrates that while coarser resolution may impact the accuracy of the CNN
model, it remains a viable option for rapid flood prediction compared to
hydrodynamic modeling approaches.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13361" title="Abstract">arXiv:2309.13361</a> [<a href="/pdf/2309.13361" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Machine Learning with Chaotic Strange Attractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kesgin%2C+B+U">Bahad&#x131;r Utku Kesgin</a>, 
<a href="/search/cs?searchtype=author&query=Te%C4%9Fin%2C+U">U&#x11f;ur Te&#x11f;in</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Manuscript is 13 pages, 4 figures. Supplementary Material is 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning studies need colossal power to process massive datasets and
train neural networks to reach high accuracies, which have become gradually
unsustainable. Limited by the von Neumann bottleneck, current computing
architectures and methods fuel this high power consumption. Here, we present an
analog computing method that harnesses chaotic nonlinear attractors to perform
machine learning tasks with low power consumption. Inspired by neuromorphic
computing, our model is a programmable, versatile, and generalized platform for
machine learning tasks. Our mode provides exceptional performance in clustering
by utilizing chaotic attractors' nonlinear mapping and sensitivity to initial
conditions. When deployed as a simple analog device, it only requires
milliwatt-scale power levels while being on par with current machine learning
techniques. We demonstrate low errors and high accuracies with our model for
regression and classification-based learning tasks.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13362" title="Abstract">arXiv:2309.13362</a> [<a href="/pdf/2309.13362" title="Download PDF">pdf</a>, <a href="/ps/2309.13362" title="Download PostScript">ps</a>, <a href="/format/2309.13362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix product and quasi-twisted codes in one class
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eldin%2C+R+T">Ramy Taki Eldin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Many classical constructions, such as Plotkin's and Turyn's, were generalized
by matrix product (MP) codes. Quasi-twisted (QT) codes, on the other hand, form
an algebraically rich structure class that contains many codes with best-known
parameters. We significantly extend the definition of MP codes to establish a
broader class of generalized matrix product (GMP) codes that contains QT codes
as well. We propose a generator matrix formula for any linear GMP code and
provide a condition for determining the code size. We prove that any QT code
has a GMP structure. Then we show how to build a generator polynomial matrix
for a QT code from its GMP structure, and vice versa. Despite that the class of
QT codes contains many codes with best-known parameters, we present different
examples of GMP codes with best-known parameters that are neither MP nor QT.
Two different lower bounds on the minimum distance of GMP codes are presented;
they generalize their counterparts in the MP codes literature. The second
proposed lower bound replaces the non-singular by columns matrix with a less
restrictive condition. Some examples are provided for comparing the two
proposed bounds, as well as showing that these bounds are tight.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13363" title="Abstract">arXiv:2309.13363</a> [<a href="/pdf/2309.13363" title="Download PDF">pdf</a>, <a href="/format/2309.13363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLPST: MLP is All You Need for Spatio-Temporal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zijian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Ze Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiwei Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zitao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Junbo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+S+J">S. Joe Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongwei Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Traffic prediction is a typical spatio-temporal data mining task and has
great significance to the public transportation system. Considering the demand
for its grand application, we recognize key factors for an ideal
spatio-temporal prediction method: efficient, lightweight, and effective.
However, the current deep model-based spatio-temporal prediction solutions
generally own intricate architectures with cumbersome optimization, which can
hardly meet these expectations. To accomplish the above goals, we propose an
intuitive and novel framework, MLPST, a pure multi-layer perceptron
architecture for traffic prediction. Specifically, we first capture spatial
relationships from both local and global receptive fields. Then, temporal
dependencies in different intervals are comprehensively considered. Through
compact and swift MLP processing, MLPST can well capture the spatial and
temporal dependencies while requiring only linear computational complexity, as
well as model parameters that are more than an order of magnitude lower than
baselines. Extensive experiments validated the superior effectiveness and
efficiency of MLPST against advanced baselines, and among models with optimal
accuracy, MLPST achieves the best time and space efficiency.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13365" title="Abstract">arXiv:2309.13365</a> [<a href="/pdf/2309.13365" title="Download PDF">pdf</a>, <a href="/format/2309.13365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in  IBMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohler%2C+H">Hecotr Kohler</a>, 
<a href="/search/cs?searchtype=author&query=Akrour%2C+R">Riad Akrour</a>, 
<a href="/search/cs?searchtype=author&query=Preux%2C+P">Philippe Preux</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2304.05839">arXiv:2304.05839</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Interpretability of AI models allows for user safety checks to build trust in
such AIs. In particular, Decision Trees (DTs) provide a global look at the
learned model and transparently reveal which features of the input are critical
for making a decision. However, interpretability is hindered if the DT is too
large. To learn compact trees, a recent Reinforcement Learning (RL) framework
has been proposed to explore the space of DTs using deep RL. This framework
augments a decision problem (e.g. a supervised classification task) with
additional actions that gather information about the features of an otherwise
hidden input. By appropriately penalizing these actions, the agent learns to
optimally trade-off size and performance of DTs. In practice, a reactive policy
for a partially observable Markov decision process (MDP) needs to be learned,
which is still an open problem. We show in this paper that deep RL can fail
even on simple toy tasks of this class. However, when the underlying decision
problem is a supervised classification task, we show that finding the optimal
tree can be cast as a fully observable Markov decision problem and be solved
efficiently, giving rise to a new family of algorithms for learning DTs that go
beyond the classical greedy maximization ones.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13373" title="Abstract">arXiv:2309.13373</a> [<a href="/pdf/2309.13373" title="Download PDF">pdf</a>, <a href="/format/2309.13373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asca: less audio data is more insightful
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+H">Hongwu Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio recognition in specialized areas such as birdsong and submarine
acoustics faces challenges in large-scale pre-training due to the limitations
in available samples imposed by sampling environments and specificity
requirements. While the Transformer model excels in audio recognition, its
dependence on vast amounts of data becomes restrictive in resource-limited
settings. Addressing this, we introduce the Audio Spectrogram Convolution
Attention (ASCA) based on CoAtNet, integrating a Transformer-convolution hybrid
architecture, novel network design, and attention techniques, further augmented
with data enhancement and regularization strategies. On the BirdCLEF2023 and
AudioSet(Balanced), ASCA achieved accuracies of 81.2% and 35.1%, respectively,
significantly outperforming competing methods. The unique structure of our
model enriches output, enabling generalization across various audio detection
tasks. Our code can be found at https://github.com/LeeCiang/ASCA.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13375" title="Abstract">arXiv:2309.13375</a> [<a href="/pdf/2309.13375" title="Download PDF">pdf</a>, <a href="/format/2309.13375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative Retrieval with Semantic Tree-Structured Item Identifiers via  Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Si%2C+Z">Zihua Si</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zhongxiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiale Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guozhang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zang%2C+X">Xiaoxue Zang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yang Song</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jun Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 main pages, 3 pages for appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">The retrieval phase is a vital component in recommendation systems, requiring
the model to be effective and efficient. Recently, generative retrieval has
become an emerging paradigm for document retrieval, showing notable
performance. These methods enjoy merits like being end-to-end differentiable,
suggesting their viability in recommendation. However, these methods fall short
in efficiency and effectiveness for large-scale recommendations. To obtain
efficiency and effectiveness, this paper introduces a generative retrieval
framework, namely SEATER, which learns SEmAntic Tree-structured item
identifiERs via contrastive learning. Specifically, we employ an
encoder-decoder model to extract user interests from historical behaviors and
retrieve candidates via tree-structured item identifiers. SEATER devises a
balanced k-ary tree structure of item identifiers, allocating semantic space to
each token individually. This strategy maintains semantic consistency within
the same level, while distinct levels correlate to varying semantic
granularities. This structure also maintains consistent and fast inference
speed for all items. Considering the tree structure, SEATER learns identifier
tokens' semantics, hierarchical relationships, and inter-token dependencies. To
achieve this, we incorporate two contrastive learning tasks with the generation
task to optimize both the model and identifiers. The infoNCE loss aligns the
token embeddings based on their hierarchical positions. The triplet loss ranks
similar identifiers in desired orders. In this way, SEATER achieves both
efficiency and effectiveness. Extensive experiments on three public datasets
and an industrial dataset have demonstrated that SEATER outperforms
state-of-the-art models significantly.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13377" title="Abstract">arXiv:2309.13377</a> [<a href="/pdf/2309.13377" title="Download PDF">pdf</a>, <a href="/format/2309.13377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Invariant Representations with a Nonparametric Nadaraya-Watson  Head
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+A+Q">Alan Q. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M">Minh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Sabuncu%2C+M+R">Mert R. Sabuncu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Machine learning models will often fail when deployed in an environment with
a data distribution that is different than the training distribution. When
multiple environments are available during training, many methods exist that
learn representations which are invariant across the different distributions,
with the hope that these representations will be transportable to unseen
domains. In this work, we present a nonparametric strategy for learning
invariant representations based on the recently-proposed Nadaraya-Watson (NW)
head. The NW head makes a prediction by comparing the learned representations
of the query to the elements of a support set that consists of labeled data. We
demonstrate that by manipulating the support set, one can encode different
causal assumptions. In particular, restricting the support set to a single
environment encourages the model to learn invariant features that do not depend
on the environment. We present a causally-motivated setup for our modeling and
training strategy and validate on three challenging real-world domain
generalization tasks in computer vision.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13378" title="Abstract">arXiv:2309.13378</a> [<a href="/pdf/2309.13378" title="Download PDF">pdf</a>, <a href="/format/2309.13378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciphering Spatio-Temporal Graph Forecasting: A Causal Lens and  Treatment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+Y">Yutong Xia</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuxuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Haomin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhengyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+R">Roger Zimmermann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spatio-Temporal Graph (STG) forecasting is a fundamental task in many
real-world applications. Spatio-Temporal Graph Neural Networks have emerged as
the most popular method for STG forecasting, but they often struggle with
temporal out-of-distribution (OoD) issues and dynamic spatial causation. In
this paper, we propose a novel framework called CaST to tackle these two
challenges via causal treatments. Concretely, leveraging a causal lens, we
first build a structural causal model to decipher the data generation process
of STGs. To handle the temporal OoD issue, we employ the back-door adjustment
by a novel disentanglement block to separate invariant parts and temporal
environments from input data. Moreover, we utilize the front-door adjustment
and adopt the Hodge-Laplacian operator for edge-level convolution to model the
ripple effect of causation. Experiments results on three real-world datasets
demonstrate the effectiveness and practicality of CaST, which consistently
outperforms existing methods with good interpretability.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13384" title="Abstract">arXiv:2309.13384</a> [<a href="/pdf/2309.13384" title="Download PDF">pdf</a>, <a href="/format/2309.13384" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Sweet Spot of Contrastive Views for Knowledge-enhanced  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haibo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuan Yao</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+H">Hanghang Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recommender systems, knowledge graph (KG) can offer critical information
that is lacking in the original user-item interaction graph (IG). Recent
process has explored this direction and shows that contrastive learning is a
promising way to integrate both. However, we observe that existing KG-enhanced
recommenders struggle in balancing between the two contrastive views of IG and
KG, making them sometimes even less effective than simply applying contrastive
learning on IG without using KG. In this paper, we propose a new contrastive
learning framework for KG-enhanced recommendation. Specifically, to make full
use of the knowledge, we construct two separate contrastive views for KG and
IG, and maximize their mutual information; to ease the contrastive learning on
the two views, we further fuse KG information into IG in a one-direction
manner.Extensive experimental results on three real-world datasets demonstrate
the effectiveness and efficiency of our method, compared to the
state-of-the-art. Our code is available through the anonymous
link:https://figshare.com/articles/conference_contribution/SimKGCL/22783382
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13387" title="Abstract">arXiv:2309.13387</a> [<a href="/pdf/2309.13387" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YOLORe-IDNet: An Efficient Multi-Camera System for Person-Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gautam%2C+V">Vipin Gautam</a>, 
<a href="/search/cs?searchtype=author&query=Prasad%2C+S">Shitala Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+S">Sharad Sinha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The growing need for video surveillance in public spaces has created a demand
for systems that can track individuals across multiple cameras feeds in
real-time. While existing tracking systems have achieved impressive performance
using deep learning models, they often rely on pre-existing images of suspects
or historical data. However, this is not always feasible in cases where
suspicious individuals are identified in real-time and without prior knowledge.
We propose a person-tracking system that combines correlation filters and
Intersection Over Union (IOU) constraints for robust tracking, along with a
deep learning model for cross-camera person re-identification (Re-ID) on top of
YOLOv5. The proposed system quickly identifies and tracks suspect in real-time
across multiple cameras and recovers well after full or partial occlusion,
making it suitable for security and surveillance applications. It is
computationally efficient and achieves a high F1-Score of 79% and an IOU of 59%
comparable to existing state-of-the-art algorithms, as demonstrated in our
evaluation on a publicly available OTB-100 dataset. The proposed system offers
a robust and efficient solution for the real-time tracking of individuals
across multiple camera feeds. Its ability to track targets without prior
knowledge or historical data is a significant improvement over existing
systems, making it well-suited for public safety and surveillance applications.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13391" title="Abstract">arXiv:2309.13391</a> [<a href="/pdf/2309.13391" title="Download PDF">pdf</a>, <a href="/format/2309.13391" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> D-Separation for Causal Self-Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haozhao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ruixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhiying Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">YuanKai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yang Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Rationalization is a self-explaining framework for NLP models. Conventional
work typically uses the maximum mutual information (MMI) criterion to find the
rationale that is most indicative of the target label. However, this criterion
can be influenced by spurious features that correlate with the causal rationale
or the target label. Instead of attempting to rectify the issues of the MMI
criterion, we propose a novel criterion to uncover the causal rationale, termed
the Minimum Conditional Dependence (MCD) criterion, which is grounded on our
finding that the non-causal features and the target label are
\emph{d-separated} by the causal rationale. By minimizing the dependence
between the unselected parts of the input and the target label conditioned on
the selected rationale candidate, all the causes of the label are compelled to
be selected. In this study, we employ a simple and practical measure of
dependence, specifically the KL-divergence, to validate our proposed MCD
criterion. Empirically, we demonstrate that MCD improves the F1 score by up to
$13.7\%$ compared to previous state-of-the-art MMI-based methods. Our code is
available at: \url{https://github.com/jugechengzi/Rationalization-MCD}.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13393" title="Abstract">arXiv:2309.13393</a> [<a href="/pdf/2309.13393" title="Download PDF">pdf</a>, <a href="/format/2309.13393" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AgriSORT: A Simple Online Real-time Tracking-by-Detection framework for  robotics in precision agriculture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saraceni%2C+L">Leonardo Saraceni</a>, 
<a href="/search/cs?searchtype=author&query=Motoi%2C+I+M">Ionut M. Motoi</a>, 
<a href="/search/cs?searchtype=author&query=Nardi%2C+D">Daniele Nardi</a>, 
<a href="/search/cs?searchtype=author&query=Ciarfuglia%2C+T+A">Thomas A. Ciarfuglia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, submitted to International Conference on Robotics and Automation (ICRA) 2024. Code and dataset will be soon available on my github, after the acceptance to the conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The problem of multi-object tracking (MOT) consists in detecting and tracking
all the objects in a video sequence while keeping a unique identifier for each
object. It is a challenging and fundamental problem for robotics. In precision
agriculture the challenge of achieving a satisfactory solution is amplified by
extreme camera motion, sudden illumination changes, and strong occlusions. Most
modern trackers rely on the appearance of objects rather than motion for
association, which can be ineffective when most targets are static objects with
the same appearance, as in the agricultural case. To this end, on the trail of
SORT [5], we propose AgriSORT, a simple, online, real-time
tracking-by-detection pipeline for precision agriculture based only on motion
information that allows for accurate and fast propagation of tracks between
frames. The main focuses of AgriSORT are efficiency, flexibility, minimal
dependencies, and ease of deployment on robotic platforms. We test the proposed
pipeline on a novel MOT benchmark specifically tailored for the agricultural
context, based on video sequences taken in a table grape vineyard, particularly
challenging due to strong self-similarity and density of the instances. Both
the code and the dataset are available for future comparisons.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13394" title="Abstract">arXiv:2309.13394</a> [<a href="/pdf/2309.13394" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart City Digital Twin Framework for Real-Time Multi-Data Integration  and Wide Public Distribution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adreani%2C+L">Lorenzo Adreani</a>, 
<a href="/search/cs?searchtype=author&query=Bellini%2C+P">Pierfrancesco Bellini</a>, 
<a href="/search/cs?searchtype=author&query=Fanfani%2C+M">Marco Fanfani</a>, 
<a href="/search/cs?searchtype=author&query=Nesi%2C+P">Paolo Nesi</a>, 
<a href="/search/cs?searchtype=author&query=Pantaleo%2C+G">Gianni Pantaleo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Digital Twins are digital replica of real entities and are becoming
fundamental tools to monitor and control the status of entities, predict their
future evolutions, and simulate alternative scenarios to understand the impact
of changes. Thanks to the large deployment of sensors, with the increasing
information it is possible to build accurate reproductions of urban
environments including structural data and real-time information. Such
solutions help city councils and decision makers to face challenges in urban
development and improve the citizen quality of life, by ana-lysing the actual
conditions, evaluating in advance through simulations and what-if analysis the
outcomes of infrastructural or political chang-es, or predicting the effects of
humans and/or of natural events. Snap4City Smart City Digital Twin framework is
capable to respond to the requirements identified in the literature and by the
international forums. Differently from other solutions, the proposed
architecture provides an integrated solution for data gathering, indexing,
computing and information distribution offered by the Snap4City IoT platform,
therefore realizing a continuously updated Digital Twin. 3D building models,
road networks, IoT devices, WoT Entities, point of interests, routes, paths,
etc., as well as results from data analytical processes for traffic density
reconstruction, pollutant dispersion, predictions of any kind, what-if
analysis, etc., are all integrated into an accessible web interface, to support
the citizens participation in the city decision processes. What-If analysis to
let the user performs simulations and observe possible outcomes. As case of
study, the Digital Twin of the city of Florence (Italy) is presented. Snap4City
platform, is released as open-source, and made available through GitHub and as
docker compose.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13395" title="Abstract">arXiv:2309.13395</a> [<a href="/pdf/2309.13395" title="Download PDF">pdf</a>, <a href="/ps/2309.13395" title="Download PostScript">ps</a>, <a href="/format/2309.13395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Further Study of Vectorial Dual-Bent Functions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaxin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+F">Fang-Wei Fu</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Y">Yadi Wei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jing Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Vectorial dual-bent functions have recently attracted some researchers'
interest as they play a significant role in constructing partial difference
sets, association schemes, bent partitions and linear codes. In this paper, we
further study vectorial dual-bent functions $F: V_{n}^{(p)}\rightarrow
V_{m}^{(p)}$, where $2\leq m \leq \frac{n}{2}$, $V_{n}^{(p)}$ denotes an
$n$-dimensional vector space over the prime field $\mathbb{F}_{p}$. We give new
characterizations of certain vectorial dual-bent functions (called vectorial
dual-bent functions with Condition A) in terms of amorphic association schemes,
linear codes and generalized Hadamard matrices, respectively. When $p=2$, we
characterize vectorial dual-bent functions with Condition A in terms of bent
partitions. Furthermore, we characterize certain bent partitions in terms of
amorphic association schemes, linear codes and generalized Hadamard matrices,
respectively. For general vectorial dual-bent functions $F:
V_{n}^{(p)}\rightarrow V_{m}^{(p)}$ with $F(0)=0, F(x)=F(-x)$ and $2\leq m \leq
\frac{n}{2}$, we give a necessary and sufficient condition on constructing
association schemes. Based on such a result, more association schemes are
constructed from vectorial dual-bent functions.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13396" title="Abstract">arXiv:2309.13396</a> [<a href="/pdf/2309.13396" title="Download PDF">pdf</a>, <a href="/format/2309.13396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EquiCity Game: A mathematical serious game for participatory design of  spatial configurations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nourian%2C+P">Pirouz Nourian</a>, 
<a href="/search/cs?searchtype=author&query=Azadi%2C+S">Shervin Azadi</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+N">Nan Bai</a>, 
<a href="/search/cs?searchtype=author&query=de+Andrade%2C+B">Bruno de Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Zaid%2C+N+A">Nour Abu Zaid</a>, 
<a href="/search/cs?searchtype=author&query=Rezvani%2C+S">Samaneh Rezvani</a>, 
<a href="/search/cs?searchtype=author&query=Roders%2C+A+P">Ana Pereira Roders</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages (the paper), 15 pages (supplemental materials), under review since May 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">We propose mechanisms for a mathematical social-choice game that is designed
to mediate decision-making processes for city planning, urban area
redevelopment, and architectural design (massing) of urban housing complexes.
The proposed game is effectively a multi-player generative configurator
equipped with automated appraisal/scoring mechanisms for revealing the
aggregate impact of alternatives; featuring a participatory digital process to
support transparent and inclusive decision-making processes in spatial design
for ensuring an equitable balance of sustainable development goals. As such,
the game effectively empowers a group of decision-makers to reach a fair
consensus by mathematically simulating many rounds of trade-offs between their
decisions, with different levels of interest or control over various types of
investments. Our proposed gamified design process encompasses decision-making
about the most idiosyncratic aspects of a site related to its heritage status
and cultural significance to the physical aspects such as balancing access to
sunlight and the right to sunlight of the neighbours of the site, ensuring
coherence of the entire configuration with regards to a network of desired
closeness ratings, the satisfaction of a programme of requirements, and
intricately balancing individual development goals in conjunction with communal
goals and environmental design codes. The game is developed fully based on an
algebraic computational process on our own digital twinning platform, using
open geospatial data and open-source computational tools such as NumPy. The
mathematical process consists of a Markovian design machine for balancing the
decisions of actors, a massing configurator equipped with Fuzzy Logic and
Multi-Criteria Decision Analysis, algebraic graph-theoretical accessibility
evaluators, and automated solar-climatic evaluators using geospatial
computational geometry.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13401" title="Abstract">arXiv:2309.13401</a> [<a href="/pdf/2309.13401" title="Download PDF">pdf</a>, <a href="/format/2309.13401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual-Reference Source-Free Active Domain Adaptation for Nasopharyngeal  Carcinoma Tumor Segmentation across Multiple Hospitals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongqiu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shichen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuan He</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jinfeng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mengwan Wu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jinlan He</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+W">Wenjun Liao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xiangde Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Nasopharyngeal carcinoma (NPC) is a prevalent and clinically significant
malignancy that predominantly impacts the head and neck area. Precise
delineation of the Gross Tumor Volume (GTV) plays a pivotal role in ensuring
effective radiotherapy for NPC. Despite recent methods that have achieved
promising results on GTV segmentation, they are still limited by lacking
carefully-annotated data and hard-to-access data from multiple hospitals in
clinical practice. Although some unsupervised domain adaptation (UDA) has been
proposed to alleviate this problem, unconditionally mapping the distribution
distorts the underlying structural information, leading to inferior
performance. To address this challenge, we devise a novel Sourece-Free Active
Domain Adaptation (SFADA) framework to facilitate domain adaptation for the GTV
segmentation task. Specifically, we design a dual reference strategy to select
domain-invariant and domain-specific representative samples from a specific
target domain for annotation and model fine-tuning without relying on
source-domain data. Our approach not only ensures data privacy but also reduces
the workload for oncologists as it just requires annotating a few
representative samples from the target domain and does not need to access the
source data. We collect a large-scale clinical dataset comprising 1057 NPC
patients from five hospitals to validate our approach. Experimental results
show that our method outperforms the UDA methods and achieves comparable
results to the fully supervised upper bound, even with few annotations,
highlighting the significant medical utility of our approach. In addition,
there is no public dataset about multi-center NPC segmentation, we will release
code and dataset for future research.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13402" title="Abstract">arXiv:2309.13402</a> [<a href="/pdf/2309.13402" title="Download PDF">pdf</a>, <a href="/format/2309.13402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ML Algorithm Synthesizing Domain Knowledge for Fungal Spores  Concentration Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Syed%2C+M+A+B">Md Asif Bin Syed</a>, 
<a href="/search/cs?searchtype=author&query=Wasi%2C+A+T">Azmine Toushik Wasi</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+I">Imtiaz Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The pulp and paper manufacturing industry requires precise quality control to
ensure pure, contaminant-free end products suitable for various applications.
Fungal spore concentration is a crucial metric that affects paper usability,
and current testing methods are labor-intensive with delayed results, hindering
real-time control strategies. To address this, a machine learning algorithm
utilizing time-series data and domain knowledge was proposed. The optimal model
employed Ridge Regression achieving an MSE of 2.90 on training and validation
data. This approach could lead to significant improvements in efficiency and
sustainability by providing real-time predictions for fungal spore
concentrations. This paper showcases a promising method for real-time fungal
spore concentration prediction, enabling stringent quality control measures in
the pulp-and-paper industry.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13403" title="Abstract">arXiv:2309.13403</a> [<a href="/pdf/2309.13403" title="Download PDF">pdf</a>, <a href="/format/2309.13403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Game of Travesty: Decoy-based Psychological Cyber Deception for  Proactive Human Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yinan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Quanyan Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The concept of cyber deception has been receiving emerging attention. The
development of cyber defensive deception techniques requires interdisciplinary
work, among which cognitive science plays an important role. In this work, we
adopt a signaling game framework between a defender and a human agent to
develop a cyber defensive deception protocol that takes advantage of the
cognitive biases of human decision-making using quantum decision theory to
combat insider attacks (IA). The defender deceives an inside human attacker by
luring him to access decoy sensors via generators producing perceptions of
classical signals to manipulate the human attacker's psychological state of
mind. Our results reveal that even without changing the classical traffic data,
strategically designed generators can result in a worse performance for
defending against insider attackers in identifying decoys than the ones in the
deceptive scheme without generators, which generate random information based on
input signals. The proposed framework leads to fundamental theories in
designing more effective signaling schemes.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13405" title="Abstract">arXiv:2309.13405</a> [<a href="/pdf/2309.13405" title="Download PDF">pdf</a>, <a href="/format/2309.13405" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Large-Scale MTP2 Gaussian Graphical Models via Bridge-Block  Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ying%2C+J">Jiaxi Ying</a>, 
<a href="/search/cs?searchtype=author&query=Palomar%2C+D+P">Daniel P. Palomar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper studies the problem of learning the large-scale Gaussian graphical
models that are multivariate totally positive of order two ($\text{MTP}_2$). By
introducing the concept of bridge, which commonly exists in large-scale sparse
graphs, we show that the entire problem can be equivalently optimized through
(1) several smaller-scaled sub-problems induced by a \emph{bridge-block
decomposition} on the thresholded sample covariance graph and (2) a set of
explicit solutions on entries corresponding to \emph{bridges}. From practical
aspect, this simple and provable discipline can be applied to break down a
large problem into small tractable ones, leading to enormous reduction on the
computational complexity and substantial improvements for all existing
algorithms. The synthetic and real-world experiments demonstrate that our
proposed method presents a significant speed-up compared to the
state-of-the-art benchmarks.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13409" title="Abstract">arXiv:2309.13409</a> [<a href="/pdf/2309.13409" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Time-Series Forecasting: Unleashing Long-Term Dependencies with  Fractionally Differenced Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+V">Vivek Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+S">Srashti Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Sukanya Kundu</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+G+K">Goutam Kumar Kundu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Numerical Analysis (math.NA); Statistics Theory (math.ST)

</div>
<p class="mathjax">This study introduces a novel forecasting strategy that leverages the power
of fractional differencing (FD) to capture both short- and long-term
dependencies in time series data. Unlike traditional integer differencing
methods, FD preserves memory in series while stabilizing it for modeling
purposes. By applying FD to financial data from the SPY index and incorporating
sentiment analysis from news reports, this empirical analysis explores the
effectiveness of FD in conjunction with binary classification of target
variables. Supervised classification algorithms were employed to validate the
performance of FD series. The results demonstrate the superiority of FD over
integer differencing, as confirmed by Receiver Operating Characteristic/Area
Under the Curve (ROCAUC) and Mathews Correlation Coefficient (MCC) evaluations.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13410" title="Abstract">arXiv:2309.13410</a> [<a href="/pdf/2309.13410" title="Download PDF">pdf</a>, <a href="/format/2309.13410" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tropical neural networks and its applications to classifying  phylogenetic trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yoshida%2C+R">Ruriko Yoshida</a>, 
<a href="/search/cs?searchtype=author&query=Aliatimis%2C+G">Georgios Aliatimis</a>, 
<a href="/search/cs?searchtype=author&query=Miura%2C+K">Keiji Miura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">Deep neural networks show great success when input vectors are in an
Euclidean space. However, those classical neural networks show a poor
performance when inputs are phylogenetic trees, which can be written as vectors
in the tropical projective torus. Here we propose tropical embedding to
transform a vector in the tropical projective torus to a vector in the
Euclidean space via the tropical metric. We introduce a tropical neural network
where the first layer is a tropical embedding layer and the following layers
are the same as the classical ones. We prove that this neural network with the
tropical metric is a universal approximator and we derive a backpropagation
rule for deep neural networks. Then we provide TensorFlow 2 codes for
implementing a tropical neural network in the same fashion as the classical
one, where the weights initialization problem is considered according to the
extreme value statistics. We apply our method to empirical data including
sequences of hemagglutinin for influenza virus from New York. Finally we show
that a tropical neural network can be interpreted as a generalization of a
tropical logistic regression.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13411" title="Abstract">arXiv:2309.13411</a> [<a href="/pdf/2309.13411" title="Download PDF">pdf</a>, <a href="/format/2309.13411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Attributions of Input Variables in a Coalition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xinhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+H">Huiqi Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Quanshi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper aims to develop a new attribution method to explain the conflict
between individual variables' attributions and their coalition's attribution
from a fully new perspective. First, we find that the Shapley value can be
reformulated as the allocation of Harsanyi interactions encoded by the AI
model. Second, based the re-alloction of interactions, we extend the Shapley
value to the attribution of coalitions. Third we ective. We derive the
fundamental mechanism behind the conflict. This conflict come from the
interaction containing partial variables in their coalition.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13414" title="Abstract">arXiv:2309.13414</a> [<a href="/pdf/2309.13414" title="Download PDF">pdf</a>, <a href="/format/2309.13414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> State-space Models with Layer-wise Nonlinearity are Universal  Approximators with Exponential Decaying Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shida Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Beichen Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Dynamical Systems (math.DS)

</div>
<p class="mathjax">State-space models have gained popularity in sequence modelling due to their
simple and efficient network structures. However, the absence of nonlinear
activation along the temporal direction limits the model's capacity. In this
paper, we prove that stacking state-space models with layer-wise nonlinear
activation is sufficient to approximate any continuous sequence-to-sequence
relationship. Our findings demonstrate that the addition of layer-wise
nonlinear activation enhances the model's capacity to learn complex sequence
patterns. Meanwhile, it can be seen both theoretically and empirically that the
state-space models do not fundamentally resolve the exponential decaying memory
issue. Theoretical results are justified by numerical verifications.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13415" title="Abstract">arXiv:2309.13415</a> [<a href="/pdf/2309.13415" title="Download PDF">pdf</a>, <a href="/format/2309.13415" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dream the Impossible: Outlier Imagination with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+X">Xuefeng Du</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yiyou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaojin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yixuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Utilizing auxiliary outlier datasets to regularize the machine learning model
has demonstrated promise for out-of-distribution (OOD) detection and safe
prediction. Due to the labor intensity in data collection and cleaning,
automating outlier data generation has been a long-desired alternative. Despite
the appeal, generating photo-realistic outliers in the high dimensional pixel
space has been an open challenge for the field. To tackle the problem, this
paper proposes a new framework DREAM-OOD, which enables imagining
photo-realistic outliers by way of diffusion models, provided with only the
in-distribution (ID) data and classes. Specifically, DREAM-OOD learns a
text-conditioned latent space based on ID data, and then samples outliers in
the low-likelihood region via the latent, which can be decoded into images by
the diffusion model. Different from prior works, DREAM-OOD enables visualizing
and understanding the imagined outliers, directly in the pixel space. We
conduct comprehensive quantitative and qualitative studies to understand the
efficacy of DREAM-OOD, and show that training with the samples generated by
DREAM-OOD can benefit OOD detection performance. Code is publicly available at
https://github.com/deeplearning-wisc/dream-ood.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13420" title="Abstract">arXiv:2309.13420</a> [<a href="/pdf/2309.13420" title="Download PDF">pdf</a>, <a href="/format/2309.13420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DenMune: Density peak based clustering using mutual nearest neighbors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abbas%2C+M">Mohamed Abbas</a>, 
<a href="/search/cs?searchtype=author&query=El-Zoghobi%2C+A">Adel El-Zoghobi</a>, 
<a href="/search/cs?searchtype=author&query=Shoukry%2C+A">Amin Shoukry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pyMune is a Python package that implements this clustering algorithm proposed in this paper, DenMune. It is opensource and reproducible, doi:10.1016/j.simpa.2023.100564
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition 109 (2021) 107589
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Many clustering algorithms fail when clusters are of arbitrary shapes, of
varying densities, or the data classes are unbalanced and close to each other,
even in two dimensions. A novel clustering algorithm, DenMune is presented to
meet this challenge. It is based on identifying dense regions using mutual
nearest neighborhoods of size K, where K is the only parameter required from
the user, besides obeying the mutual nearest neighbor consistency principle.
The algorithm is stable for a wide range of values of K. Moreover, it is able
to automatically detect and remove noise from the clustering process as well as
detecting the target clusters. It produces robust results on various low and
high-dimensional datasets relative to several known state-of-the-art clustering
algorithms.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13425" title="Abstract">arXiv:2309.13425</a> [<a href="/pdf/2309.13425" title="Download PDF">pdf</a>, <a href="/format/2309.13425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MiliPoint: A Point Cloud Dataset for mmWave Radar
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+H">Han Cui</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+S">Shu Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jiacheng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Z">Zichao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Dahnoun%2C+N">Naim Dahnoun</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yiren Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Millimetre-wave (mmWave) radar has emerged as an attractive and
cost-effective alternative for human activity sensing compared to traditional
camera-based systems. mmWave radars are also non-intrusive, providing better
protection for user privacy. However, as a Radio Frequency (RF) based
technology, mmWave radars rely on capturing reflected signals from objects,
making them more prone to noise compared to cameras. This raises an intriguing
question for the deep learning community: Can we develop more effective point
set-based deep learning methods for such attractive sensors?
<br />To answer this question, our work, termed MiliPoint, delves into this idea by
providing a large-scale, open dataset for the community to explore how mmWave
radars can be utilised for human activity recognition. Moreover, MiliPoint
stands out as it is larger in size than existing datasets, has more diverse
human actions represented, and encompasses all three key tasks in human
activity recognition. We have also established a range of point-based deep
neural networks such as DGCNN, PointNet++ and PointTransformer, on MiliPoint,
which can serve to set the ground baseline for further development.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13426" title="Abstract">arXiv:2309.13426</a> [<a href="/pdf/2309.13426" title="Download PDF">pdf</a>, <a href="/format/2309.13426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Chat About Boring Problems: Studying GPT-based text normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bartley%2C+T+M">Travis M. Bartley</a>, 
<a href="/search/cs?searchtype=author&query=Graterol-Fuenmayor%2C+M">Mariana Graterol-Fuenmayor</a>, 
<a href="/search/cs?searchtype=author&query=Lavrukhin%2C+V">Vitaly Lavrukhin</a>, 
<a href="/search/cs?searchtype=author&query=Bakhturina%2C+E">Evelina Bakhturina</a>, 
<a href="/search/cs?searchtype=author&query=Ginsburg%2C+B">Boris Ginsburg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Text normalization - the conversion of text from written to spoken form - is
traditionally assumed to be an ill-formed task for language models. In this
work, we argue otherwise. We empirically show the capacity of Large-Language
Models (LLM) for text normalization in few-shot scenarios. Combining
self-consistency reasoning with linguistic-informed prompt engineering, we find
LLM based text normalization to achieve error rates around 40\% lower than top
normalization systems. Further, upon error analysis, we note key limitations in
the conventional design of text normalization tasks. We create a new taxonomy
of text normalization errors and apply it to results from GPT-3.5-Turbo and
GPT-4.0. Through this new framework, we can identify strengths and weaknesses
of GPT-based TN, opening opportunities for future work.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13428" title="Abstract">arXiv:2309.13428</a> [<a href="/pdf/2309.13428" title="Download PDF">pdf</a>, <a href="/format/2309.13428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation Algorithms for the Two-Watchman Route in a Simple Polygon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+B+J">Bengt J. Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Packer%2C+E">Eli Packer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The two-watchman route problem is that of computing a pair of closed tours in
an environment so that the two tours together see the whole environment and
some length measure on the two tours is minimized. Two standard measures are:
the minmax measure, where we want the tours where the longest of them has
smallest length, and the minsum measure, where we want the tours for which the
sum of their lengths is the smallest. It is known that computing a minmax
two-watchman route is NP-hard for simple rectilinear polygons and thus also for
simple polygons. Also, any c-approximation algorithm for the minmax
two-watchman route is automatically a 2c-approximation algorithm for the minsum
two-watchman route. We exhibit two constant factor approximation algorithms for
computing minmax two-watchman routes in simple polygons with approximation
factors 5.969 and 11.939, having running times O(n^8) and O(n^4) respectively,
where n is the number of vertices of the polygon. We also use the same
techniques to obtain a 6.922-approximation for the fixed two-watchman route
problem running in O(n^2) time, i.e., when two starting points of the two tours
are given as input.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13429" title="Abstract">arXiv:2309.13429</a> [<a href="/pdf/2309.13429" title="Download PDF">pdf</a>, <a href="/format/2309.13429" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modeling Student Performance in Game-Based Learning Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+H">Hyunbae Jeon</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Harry He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Anthony Wang</a>, 
<a href="/search/cs?searchtype=author&query=Spooner%2C+S">Susanna Spooner</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This study investigates game-based learning in the context of the educational
game "Jo Wilder and the Capitol Case," focusing on predicting student
performance using various machine learning models, including K-Nearest
Neighbors (KNN), Multi-Layer Perceptron (MLP), and Random Forest. The research
aims to identify the features most predictive of student performance and
correct question answering. By leveraging gameplay data, we establish complete
benchmarks for these models and explore the importance of applying proper data
aggregation methods. By compressing all numeric data to min/max/mean/sum and
categorical data to first, last, count, and nunique, we reduced the size of the
original training data from 4.6 GB to 48 MB of preprocessed training data,
maintaining high F1 scores and accuracy.
<br />Our findings suggest that proper preprocessing techniques can be vital in
enhancing the performance of non-deep-learning-based models. The MLP model
outperformed the current state-of-the-art French Touch model, achieving an F-1
score of 0.83 and an accuracy of 0.74, suggesting its suitability for this
dataset. Future research should explore using larger datasets, other
preprocessing techniques, more advanced deep learning techniques, and
real-world applications to provide personalized learning recommendations to
students based on their predicted performance. This paper contributes to the
understanding of game-based learning and provides insights into optimizing
educational game experiences for improved student outcomes and skill
development.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13430" title="Abstract">arXiv:2309.13430</a> [<a href="/pdf/2309.13430" title="Download PDF">pdf</a>, <a href="/format/2309.13430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resolving References in Visually-Grounded Dialogue via Text Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Willemsen%2C+B">Bram Willemsen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+L">Livia Qian</a>, 
<a href="/search/cs?searchtype=author&query=Skantze%2C+G">Gabriel Skantze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at SIGDIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Vision-language models (VLMs) have shown to be effective at image retrieval
based on simple text queries, but text-image retrieval based on conversational
input remains a challenge. Consequently, if we want to use VLMs for reference
resolution in visually-grounded dialogue, the discourse processing capabilities
of these models need to be augmented. To address this issue, we propose
fine-tuning a causal large language model (LLM) to generate definite
descriptions that summarize coreferential information found in the linguistic
context of references. We then use a pretrained VLM to identify referents based
on the generated descriptions, zero-shot. We evaluate our approach on a
manually annotated dataset of visually-grounded dialogues and achieve results
that, on average, exceed the performance of the baselines we compare against.
Furthermore, we find that using referent descriptions based on larger context
windows has the potential to yield higher returns.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13438" title="Abstract">arXiv:2309.13438</a> [<a href="/pdf/2309.13438" title="Download PDF">pdf</a>, <a href="/format/2309.13438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking superpixel segmentation from biologically inspired mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">TingYu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">DaiPeng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhange%2C+Z">ZhenGuang Zhange</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recently, advancements in deep learning-based superpixel segmentation methods
have brought about improvements in both the efficiency and the performance of
segmentation. However, a significant challenge remains in generating
superpixels that strictly adhere to object boundaries while conveying rich
visual significance, especially when cross-surface color correlations may
interfere with objects. Drawing inspiration from neural structure and visual
mechanisms, we propose a biological network architecture comprising an Enhanced
Screening Module (ESM) and a novel Boundary-Aware Label (BAL) for superpixel
segmentation. The ESM enhances semantic information by simulating the
interactive projection mechanisms of the visual cortex. Additionally, the BAL
emulates the spatial frequency characteristics of visual cortical cells to
facilitate the generation of superpixels with strong boundary adherence. We
demonstrate the effectiveness of our approach through evaluations on both the
BSDS500 dataset and the NYUv2 dataset.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13439" title="Abstract">arXiv:2309.13439</a> [<a href="/pdf/2309.13439" title="Download PDF">pdf</a>, <a href="/format/2309.13439" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Finding Order in Chaos: A Novel Data Augmentation Method for Time Series  in Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Demirel%2C+B+U">Berken Utku Demirel</a>, 
<a href="/search/cs?searchtype=author&query=Holz%2C+C">Christian Holz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceedings of NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">The success of contrastive learning is well known to be dependent on data
augmentation. Although the degree of data augmentations has been well
controlled by utilizing pre-defined techniques in some domains like vision,
time-series data augmentation is less explored and remains a challenging
problem due to the complexity of the data generation mechanism, such as the
intricate mechanism involved in the cardiovascular system. Moreover, there is
no widely recognized and general time-series augmentation method that can be
applied across different tasks. In this paper, we propose a novel data
augmentation method for quasi-periodic time-series tasks that aims to connect
intra-class samples together, and thereby find order in the latent space. Our
method builds upon the well-known mixup technique by incorporating a novel
approach that accounts for the periodic nature of non-stationary time-series.
Also, by controlling the degree of chaos created by data augmentation, our
method leads to improved feature representations and performance on downstream
tasks. We evaluate our proposed method on three time-series tasks, including
heart rate estimation, human activity recognition, and cardiovascular disease
detection. Extensive experiments against state-of-the-art methods show that the
proposed approach outperforms prior works on optimal data generation and known
data augmentation techniques in the three tasks, reflecting the effectiveness
of the presented method. Source code:
https://github.com/eth-siplab/Finding_Order_in_Chaos
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13442" title="Abstract">arXiv:2309.13442</a> [<a href="/pdf/2309.13442" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Do Drivers Behave at Roundabouts in a Mixed Traffic? A Case Study  Using Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamad%2C+F+A">Farah Abu Hamad</a>, 
<a href="/search/cs?searchtype=author&query=Hasiba%2C+R">Rama Hasiba</a>, 
<a href="/search/cs?searchtype=author&query=Shahwan%2C+D">Deema Shahwan</a>, 
<a href="/search/cs?searchtype=author&query=Ashqar%2C+H+I">Huthaifa I. Ashqar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Driving behavior is considered a unique driving habit of each driver and has
a significant impact on road safety. Classifying driving behavior and
introducing policies based on the results can reduce the severity of crashes on
the road. Roundabouts are particularly interesting because of the
interconnected interaction between different road users at the area of
roundabouts, which different driving behavior is hypothesized. This study
investigates driving behavior at roundabouts in a mixed traffic environment
using a data-driven unsupervised machine learning to classify driving behavior
at three roundabouts in Germany. We used a dataset of vehicle kinematics to a
group of different vehicles and vulnerable road users (VRUs) at roundabouts and
classified them into three categories (i.e., conservative, normal, and
aggressive). Results showed that most of the drivers proceeding through a
roundabout can be mostly classified into two driving styles: conservative and
normal because traffic speeds in roundabouts are relatively lower than in other
signalized and unsignalized intersections. Results also showed that about 77%
of drivers who interacted with pedestrians or cyclists were classified as
conservative drivers compared to about 42% of conservative drivers that did not
interact or about 51% from all drivers. It seems that drivers tend to behave
abnormally as they interact with VRUs at roundabouts, which increases the risk
of crashes when an intersection is multimodal. Results of this study could be
helpful in improving the safety of roads by allowing policymakers to determine
the effective and suitable safety countermeasures. Results will also be
beneficial for the Advanced Driver Assistance System (ADAS) as the technology
is being deployed in a mixed traffic environment.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13443" title="Abstract">arXiv:2309.13443</a> [<a href="/pdf/2309.13443" title="Download PDF">pdf</a>, <a href="/format/2309.13443" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Early Classification for Dynamic Inference of Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingcun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G+L">Grace Li Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep neural networks (DNNs) have been successfully applied in various fields.
In DNNs, a large number of multiply-accumulate (MAC) operations is required to
be performed, posing critical challenges in applying them in
resource-constrained platforms, e.g., edge devices. Dynamic neural networks
have been introduced to allow a structural adaption, e.g., early-exit,
according to different inputs to reduce the computational cost of DNNs.
Existing early-exit techniques deploy classifiers at intermediate layers of
DNNs to push them to make a classification decision as early as possible.
However, the learned features at early layers might not be sufficient to
exclude all the irrelevant classes and decide the correct class, leading to
suboptimal results. To address this challenge, in this paper, we propose a
class-based early-exit for dynamic inference. Instead of pushing DNNs to make a
dynamic decision at intermediate layers, we take advantages of the learned
features in these layers to exclude as many irrelevant classes as possible, so
that later layers only have to determine the target class among the remaining
classes. Until at a layer only one class remains, this class is the
corresponding classification result. To realize this class-based exclusion, we
assign each class with a classifier at intermediate layers and train the
networks together with these classifiers. Afterwards, an exclusion strategy is
developed to exclude irrelevant classes at early layers. Experimental results
demonstrate the computational cost of DNNs in inference can be reduced
significantly.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13444" title="Abstract">arXiv:2309.13444</a> [<a href="/pdf/2309.13444" title="Download PDF">pdf</a>, <a href="/format/2309.13444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Moving Target Defense based Secured Network Slicing System in the O-RAN  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Motalleb%2C+M+K">Mojdeh Karbalaee Motalleb</a>, 
<a href="/search/cs?searchtype=author&query=Benza%C3%AFd%2C+C">Chafika Benza&#xef;d</a>, 
<a href="/search/cs?searchtype=author&query=Taleb%2C+T">Tarik Taleb</a>, 
<a href="/search/cs?searchtype=author&query=Shah-Mansouri%2C+V">Vahid Shah-Mansouri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The open radio access network (O-RAN) architecture's native virtualization
and embedded intelligence facilitate RAN slicing and enable comprehensive
end-to-end services in post-5G networks. However, any vulnerabilities could
harm security. Therefore, artificial intelligence (AI) and machine learning
(ML) security threats can even threaten O-RAN benefits. This paper proposes a
novel approach to estimating the optimal number of predefined VNFs for each
slice while addressing secure AI/ML methods for dynamic service admission
control and power minimization in the O-RAN architecture. We solve this problem
on two-time scales using mathematical methods for determining the predefined
number of VNFs on a large time scale and the proximal policy optimization
(PPO), a Deep Reinforcement Learning algorithm, for solving dynamic service
admission control and power minimization for different slices on a small-time
scale. To secure the ML system for O-RAN, we implement a moving target defense
(MTD) strategy to prevent poisoning attacks by adding uncertainty to the
system. Our experimental results show that the proposed PPO-based service
admission control approach achieves an admission rate above 80\% and that the
MTD strategy effectively strengthens the robustness of the PPO method against
adversarial attacks.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13445" title="Abstract">arXiv:2309.13445</a> [<a href="/pdf/2309.13445" title="Download PDF">pdf</a>, <a href="/format/2309.13445" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AxOMaP: Designing FPGA-based Approximate Arithmetic Operators using  Mathematical Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahoo%2C+S+S">Siva Satyendra Sahoo</a>, 
<a href="/search/cs?searchtype=author&query=Ullah%2C+S">Salim Ullah</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Akash Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, Under review at ACM TRETS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Artificial Intelligence (cs.AI); Signal Processing (eess.SP)

</div>
<p class="mathjax">With the increasing application of machine learning (ML) algorithms in
embedded systems, there is a rising necessity to design low-cost computer
arithmetic for these resource-constrained systems. As a result, emerging models
of computation, such as approximate and stochastic computing, that leverage the
inherent error-resilience of such algorithms are being actively explored for
implementing ML inference on resource-constrained systems. Approximate
computing (AxC) aims to provide disproportionate gains in the power,
performance, and area (PPA) of an application by allowing some level of
reduction in its behavioral accuracy (BEHAV). Using approximate operators
(AxOs) for computer arithmetic forms one of the more prevalent methods of
implementing AxC. AxOs provide the additional scope for finer granularity of
optimization, compared to only precision scaling of computer arithmetic. To
this end, designing platform-specific and cost-efficient approximate operators
forms an important research goal. Recently, multiple works have reported using
AI/ML-based approaches for synthesizing novel FPGA-based AxOs. However, most of
such works limit usage of AI/ML to designing ML-based surrogate functions used
during iterative optimization processes. To this end, we propose a novel data
analysis-driven mathematical programming-based approach to synthesizing
approximate operators for FPGAs. Specifically, we formulate mixed integer
quadratically constrained programs based on the results of correlation analysis
of the characterization data and use the solutions to enable a more directed
search approach for evolutionary optimization algorithms. Compared to
traditional evolutionary algorithms-based optimization, we report up to 21%
improvement in the hypervolume, for joint optimization of PPA and BEHAV, in the
design of signed 8-bit multipliers.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13446" title="Abstract">arXiv:2309.13446</a> [<a href="/pdf/2309.13446" title="Download PDF">pdf</a>, <a href="/format/2309.13446" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Timeline Modeling For News Story Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Meng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mingda Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jialu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hanjun Dai</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+M">Ming-Hsuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+S">Shuiwang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zheyun Feng</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+B">Boqing Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a spotlight by NeurIPS 2023, Track on Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In this paper, we present a novel problem, namely video timeline modeling.
Our objective is to create a video-associated timeline from a set of videos
related to a specific topic, thereby facilitating the content and structure
understanding of the story being told. This problem has significant potential
in various real-world applications, such as news story summarization. To
bootstrap research in this area, we curate a realistic benchmark dataset,
YouTube-News-Timeline, consisting of over $12$k timelines and $300$k YouTube
news videos. Additionally, we propose a set of quantitative metrics as the
protocol to comprehensively evaluate and compare methodologies. With such a
testbed, we further develop and benchmark exploratory deep learning approaches
to tackle this problem. We anticipate that this exploratory work will pave the
way for further research in video timeline modeling. The assets are available
via
https://github.com/google-research/google-research/tree/master/video_timeline_modeling.
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13448" title="Abstract">arXiv:2309.13448</a> [<a href="/pdf/2309.13448" title="Download PDF">pdf</a>, <a href="/format/2309.13448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grounding Description-Driven Dialogue State Trackers with  Knowledge-Seeking Turns
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coca%2C+A">Alexandru Coca</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+B">Bo-Hsiang Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jinghong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weizhe Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Weixuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Anders%2C+T">Tisha Anders</a>, 
<a href="/search/cs?searchtype=author&query=Byrne%2C+B">Bill Byrne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Best Long Paper of SIGDIAL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Schema-guided dialogue state trackers can generalise to new domains without
further training, yet they are sensitive to the writing style of the schemata.
Augmenting the training set with human or synthetic schema paraphrases improves
the model robustness to these variations but can be either costly or difficult
to control. We propose to circumvent these issues by grounding the state
tracking model in knowledge-seeking turns collected from the dialogue corpus as
well as the schema. Including these turns in prompts during finetuning and
inference leads to marked improvements in model robustness, as demonstrated by
large average joint goal accuracy and schema sensitivity improvements on SGD
and SGD-X.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13450" title="Abstract">arXiv:2309.13450</a> [<a href="/pdf/2309.13450" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conducting A/B Experiments with a Scalable Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hornback%2C+A">Andrew Hornback</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+S">Sungeun An</a>, 
<a href="/search/cs?searchtype=author&query=Bunin%2C+S">Scott Bunin</a>, 
<a href="/search/cs?searchtype=author&query=Buckley%2C+S">Stephen Buckley</a>, 
<a href="/search/cs?searchtype=author&query=Kos%2C+J">John Kos</a>, 
<a href="/search/cs?searchtype=author&query=Goel%2C+A">Ashok Goel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">A/B experiments are commonly used in research to compare the effects of
changing one or more variables in two different experimental groups - a control
group and a treatment group. While the benefits of using A/B experiments are
widely known and accepted, there is less agreement on a principled approach to
creating software infrastructure systems to assist in rapidly conducting such
experiments. We propose a four-principle approach for developing a software
architecture to support A/B experiments that is domain agnostic and can help
alleviate some of the resource constraints currently needed to successfully
implement these experiments: the software architecture (i) must retain the
typical properties of A/B experiments, (ii) capture problem solving activities
and outcomes, (iii) allow researchers to understand the behavior and outcomes
of participants in the experiment, and (iv) must enable automated analysis. We
successfully developed a software system to encapsulate these principles and
implement it in a real-world A/B experiment.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13451" title="Abstract">arXiv:2309.13451</a> [<a href="/pdf/2309.13451" title="Download PDF">pdf</a>, <a href="/format/2309.13451" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Aware Map Compression for Online Path-Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Psomiadis%2C+E">Evangelos Psomiadis</a>, 
<a href="/search/cs?searchtype=author&query=Maity%2C+D">Dipankar Maity</a>, 
<a href="/search/cs?searchtype=author&query=Tsiotras%2C+P">Panagiotis Tsiotras</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper addresses the problem of the communication of optimally compressed
information for mobile robot path-planning. In this context, mobile robots
compress their current local maps to assist another robot in reaching a target
in an unknown environment. We propose a framework that sequentially selects the
optimal compression, guided by the robot's path, by balancing the map
resolution and communication cost. Our approach is tractable in close-to-real
scenarios and does not necessitate prior environment knowledge. We design a
novel decoder that leverages compressed information to estimate the unknown
environment via convex optimization with linear constraints and an encoder that
utilizes the decoder to select the optimal compression. Numerical simulations
are conducted in a large close-to-real map and a maze map and compared with two
alternative approaches. The results confirm the effectiveness of our framework
in assisting the robot reach its target by reducing transmitted information, on
average, by approximately 50% while maintaining satisfactory performance.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13452" title="Abstract">arXiv:2309.13452</a> [<a href="/pdf/2309.13452" title="Download PDF">pdf</a>, <a href="/format/2309.13452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Monotonic Neural Ordinary Differential Equation: Time-series Forecasting  for Cumulative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhichao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+L">Leilei Ding</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+Z">Zhixuan Chu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+Y">Yucheng Qi</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jianmin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as CIKM'23 Applied Research Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Time-Series Forecasting based on Cumulative Data (TSFCD) is a crucial problem
in decision-making across various industrial scenarios. However, existing
time-series forecasting methods often overlook two important characteristics of
cumulative data, namely monotonicity and irregularity, which limit their
practical applicability. To address this limitation, we propose a principled
approach called Monotonic neural Ordinary Differential Equation (MODE) within
the framework of neural ordinary differential equations. By leveraging MODE, we
are able to effectively capture and represent the monotonicity and irregularity
in practical cumulative data. Through extensive experiments conducted in a
bonus allocation scenario, we demonstrate that MODE outperforms
state-of-the-art methods, showcasing its ability to handle both monotonicity
and irregularity in cumulative data and delivering superior forecasting
performance.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13456" title="Abstract">arXiv:2309.13456</a> [<a href="/pdf/2309.13456" title="Download PDF">pdf</a>, <a href="/format/2309.13456" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Optimal Control Framework for Influencing Human Driving Behavior in  Mixed-Autonomy Traffic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chari%2C+A">Anirudh Chari</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/eess?searchtype=author&query=Grover%2C+J">Jaskaran Grover</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As autonomous vehicles (AVs) become increasingly prevalent, their interaction
with human drivers presents a critical challenge. Current AVs lack social
awareness, causing behavior that is often awkward or unsafe. To combat this,
social AVs, which are proactive rather than reactive in their behavior, have
been explored in recent years. With knowledge of robot-human interaction
dynamics, a social AV can influence a human driver to exhibit desired behaviors
by strategically altering its own behaviors. In this paper, we present a novel
framework for achieving human influence. The foundation of our framework lies
in an innovative use of control barrier functions to formulate the desired
objectives of influence as constraints in an optimal control problem. The
computed controls gradually push the system state toward satisfaction of the
objectives, e.g. slowing the human down to some desired speed. We demonstrate
the proposed framework's feasibility in a variety of scenarios related to
car-following and lane changes, including multi-robot and multi-human
configurations. In two case studies, we validate the framework's effectiveness
when applied to the problems of traffic flow optimization and aggressive
behavior mitigation. Given these results, the main contribution of our
framework is its versatility in a wide spectrum of influence objectives and
mixed-autonomy configurations.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13457" title="Abstract">arXiv:2309.13457</a> [<a href="/pdf/2309.13457" title="Download PDF">pdf</a>, <a href="/format/2309.13457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Turbulence in Focus: Benchmarking Scaling Behavior of 3D Volumetric  Super-Resolution with BLASTNet 2.0 Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chung%2C+W+T">Wai Tong Chung</a>, 
<a href="/search/cs?searchtype=author&query=Akoush%2C+B">Bassem Akoush</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+P">Pushan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Tamkin%2C+A">Alex Tamkin</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+K+S">Ki Sung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jacqueline Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jack Guo</a>, 
<a href="/search/cs?searchtype=author&query=Brouzet%2C+D">Davy Brouzet</a>, 
<a href="/search/cs?searchtype=author&query=Talei%2C+M">Mohsen Talei</a>, 
<a href="/search/cs?searchtype=author&query=Savard%2C+B">Bruno Savard</a>, 
<a href="/search/cs?searchtype=author&query=Poludnenko%2C+A+Y">Alexei Y Poludnenko</a>, 
<a href="/search/cs?searchtype=author&query=Ihme%2C+M">Matthias Ihme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Advances in Neural Information Processing Systems 36 (NeurIPS 2023). Keywords: Super-resolution, 3D, Neural Scaling, Physics-informed Loss, Computational Fluid Dynamics, Partial Differential Equations, Turbulent Reacting Flows, Direct Numerical Simulation, Fluid Mechanics, Combustion. 55 pages, 21 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computational Physics (physics.comp-ph); Fluid Dynamics (physics.flu-dyn)

</div>
<p class="mathjax">Analysis of compressible turbulent flows is essential for applications
related to propulsion, energy generation, and the environment. Here, we present
BLASTNet 2.0, a 2.2 TB network-of-datasets containing 744 full-domain samples
from 34 high-fidelity direct numerical simulations, which addresses the current
limited availability of 3D high-fidelity reacting and non-reacting compressible
turbulent flow simulation data. With this data, we benchmark a total of 49
variations of five deep learning approaches for 3D super-resolution - which can
be applied for improving scientific imaging, simulations, turbulence models, as
well as in computer vision applications. We perform neural scaling analysis on
these models to examine the performance of different machine learning (ML)
approaches, including two scientific ML techniques. We demonstrate that (i)
predictive performance can scale with model size and cost, (ii) architecture
matters significantly, especially for smaller models, and (iii) the benefits of
physics-based losses can persist with increasing model size. The outcomes of
this benchmark study are anticipated to offer insights that can aid the design
of 3D super-resolution models, especially for turbulence models, while this
data is expected to foster ML methods for a broad range of flow physics
applications. This data is publicly available with download links and browsing
tools consolidated at https://blastnet.github.io.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13464" title="Abstract">arXiv:2309.13464</a> [<a href="/pdf/2309.13464" title="Download PDF">pdf</a>, <a href="/format/2309.13464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Personalised and Adjustable Interval Type-2 Fuzzy-Based PPG Quality  Assessment for the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miranda%2C+J+A">Jose A. Miranda</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Ongil%2C+C">Celia L&#xf3;pez-Ongil</a>, 
<a href="/search/cs?searchtype=author&query=Andreu-Perez%2C+J">Javier Andreu-Perez</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Fuzzy Systems (FUZZ 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Most of today's wearable technology provides seamless cardiac activity
monitoring. Specifically, the vast majority employ Photoplethysmography (PPG)
sensors to acquire blood volume pulse information, which is further analysed to
extract useful and physiologically related features. Nevertheless, PPG-based
signal reliability presents different challenges that strongly affect such data
processing. This is mainly related to the fact of PPG morphological wave
distortion due to motion artefacts, which can lead to erroneous interpretation
of the extracted cardiac-related features. On this basis, in this paper, we
propose a novel personalised and adjustable Interval Type-2 Fuzzy Logic System
(IT2FLS) for assessing the quality of PPG signals. The proposed system employs
a personalised approach to adapt the IT2FLS parameters to the unique
characteristics of each individual's PPG signals.Additionally, the system
provides adjustable levels of personalisation, allowing healthcare providers to
adjust the system to meet specific requirements for different applications. The
proposed system obtained up to 93.72\% for average accuracy during validation.
The presented system has the potential to enable ultra-low complexity and
real-time PPG quality assessment, improving the accuracy and reliability of
PPG-based health monitoring systems at the edge.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13466" title="Abstract">arXiv:2309.13466</a> [<a href="/pdf/2309.13466" title="Download PDF">pdf</a>, <a href="/format/2309.13466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Learning: A Hybrid Approach to Social Robot Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+A+H">Amir Hossain Raj</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zichao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Karnan%2C+H">Haresh Karnan</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+R">Rohan Chandra</a>, 
<a href="/search/cs?searchtype=author&query=Payandeh%2C+A">Amirreza Payandeh</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+L">Luisa Mao</a>, 
<a href="/search/cs?searchtype=author&query=Stone%2C+P">Peter Stone</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Empowering robots to navigate in a socially compliant manner is essential for
the acceptance of robots moving in human-inhabited environments. Previously,
roboticists have developed classical navigation systems with decades of
empirical validation to achieve safety and efficiency. However, the many
complex factors of social compliance make classical navigation systems hard to
adapt to social situations, where no amount of tuning enables them to be both
safe (people are too unpredictable) and efficient (the frozen robot problem).
With recent advances in deep learning approaches, the common reaction has been
to entirely discard classical navigation systems and start from scratch,
building a completely new learning-based social navigation planner. In this
work, we find that this reaction is unnecessarily extreme: using a large-scale
real-world social navigation dataset, SCAND, we find that classical systems can
be used safely and efficiently in a large number of social situations (up to
80%). We therefore ask if we can rethink this problem by leveraging the
advantages of both classical and learning-based approaches. We propose a hybrid
strategy in which we learn to switch between a classical geometric planner and
a data-driven method. Our experiments on both SCAND and two physical robots
show that the hybrid planner can achieve better social compliance in terms of a
variety of metrics, compared to using either the classical or learning-based
approach alone.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13467" title="Abstract">arXiv:2309.13467</a> [<a href="/pdf/2309.13467" title="Download PDF">pdf</a>, <a href="/format/2309.13467" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SUDS: Sanitizing Universal and Dependent Steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Robinette%2C+P+K">Preston K. Robinette</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H+D">Hanchen D. Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shehadeh%2C+N">Nishan Shehadeh</a>, 
<a href="/search/cs?searchtype=author&query=Moyer%2C+D">Daniel Moyer</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+T+T">Taylor T. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to European Conference on Artificial Intelligence (ECAI) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Steganography, or hiding messages in plain sight, is a form of information
hiding that is most commonly used for covert communication. As modern
steganographic mediums include images, text, audio, and video, this
communication method is being increasingly used by bad actors to propagate
malware, exfiltrate data, and discreetly communicate. Current protection
mechanisms rely upon steganalysis, or the detection of steganography, but these
approaches are dependent upon prior knowledge, such as steganographic
signatures from publicly available tools and statistical knowledge about known
hiding methods. These dependencies render steganalysis useless against new or
unique hiding methods, which are becoming increasingly common with the
application of deep learning models. To mitigate the shortcomings of
steganalysis, this work focuses on a deep learning sanitization technique
called SUDS that is not reliant upon knowledge of steganographic hiding
techniques and is able to sanitize universal and dependent steganography. SUDS
is tested using least significant bit method (LSB), dependent deep hiding
(DDH), and universal deep hiding (UDH). We demonstrate the capabilities and
limitations of SUDS by answering five research questions, including baseline
comparisons and an ablation study. Additionally, we apply SUDS to a real-world
scenario, where it is able to increase the resistance of a poisoned classifier
against attacks by 1375%.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13470" title="Abstract">arXiv:2309.13470</a> [<a href="/pdf/2309.13470" title="Download PDF">pdf</a>, <a href="/format/2309.13470" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAVE-Net: Hallucinated Audio-Visual Embeddings for Few-Shot  Classification with Unimodal Cues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jha%2C+A">Ankit Jha</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+D">Debabrata Pal</a>, 
<a href="/search/cs?searchtype=author&query=Singha%2C+M">Mainak Singha</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+N">Naman Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+B">Biplab Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Page, 2 Figures, 2 Tables, Accepted in Adapting to Change: Reliable Multimodal Learning Across Domains Workshop, ECML PKDD 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognition of remote sensing (RS) or aerial images is currently of great
interest, and advancements in deep learning algorithms added flavor to it in
recent years. Occlusion, intra-class variance, lighting, etc., might arise
while training neural networks using unimodal RS visual input. Even though
joint training of audio-visual modalities improves classification performance
in a low-data regime, it has yet to be thoroughly investigated in the RS
domain. Here, we aim to solve a novel problem where both the audio and visual
modalities are present during the meta-training of a few-shot learning (FSL)
classifier; however, one of the modalities might be missing during the
meta-testing stage. This problem formulation is pertinent in the RS domain,
given the difficulties in data acquisition or sensor malfunctioning. To
mitigate, we propose a novel few-shot generative framework, Hallucinated
Audio-Visual Embeddings-Network (HAVE-Net), to meta-train cross-modal features
from limited unimodal data. Precisely, these hallucinated features are
meta-learned from base classes and used for few-shot classification on novel
classes during the inference phase. The experimental results on the benchmark
ADVANCE and AudioSetZSL datasets show that our hallucinated modality
augmentation strategy for few-shot classification outperforms the classifier
performance trained with the real multimodal information at least by 0.8-2%.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13471" title="Abstract">arXiv:2309.13471</a> [<a href="/pdf/2309.13471" title="Download PDF">pdf</a>, <a href="/format/2309.13471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cloud Watching: Understanding Attacks Against Cloud-Hosted Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+L">Liz Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Manda Tran</a>, 
<a href="/search/cs?searchtype=author&query=Kallitsis%2C+M">Michalis Kallitsis</a>, 
<a href="/search/cs?searchtype=author&query=Fass%2C+A">Aurore Fass</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 2023 ACM Internet Measurement Conference (IMC '23), October 24--26, 2023, Montreal, QC, Canada
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Cloud computing has dramatically changed service deployment patterns. In this
work, we analyze how attackers identify and target cloud services in contrast
to traditional enterprise networks and network telescopes. Using a diverse set
of cloud honeypots in 5~providers and 23~countries as well as 2~educational
networks and 1~network telescope, we analyze how IP address assignment,
geography, network, and service-port selection, influence what services are
targeted in the cloud. We find that scanners that target cloud compute are
selective: they avoid scanning networks without legitimate services and they
discriminate between geographic regions. Further, attackers mine
Internet-service search engines to find exploitable services and, in some
cases, they avoid targeting IANA-assigned protocols, causing researchers to
misclassify at least 15\% of traffic on select ports. Based on our results, we
derive recommendations for researchers and operators.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13472" title="Abstract">arXiv:2309.13472</a> [<a href="/pdf/2309.13472" title="Download PDF">pdf</a>, <a href="/format/2309.13472" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Aware Learning for 3D Point Cloud
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper proposes an innovative approach to Hierarchical Edge Aware 3D
Point Cloud Learning (HEA-Net) that seeks to address the challenges of noise in
point cloud data, and improve object recognition and segmentation by focusing
on edge features. In this study, we present an innovative edge-aware learning
methodology, specifically designed to enhance point cloud classification and
segmentation. Drawing inspiration from the human visual system, the concept of
edge-awareness has been incorporated into this methodology, contributing to
improved object recognition while simultaneously reducing computational time.
Our research has led to the development of an advanced 3D point cloud learning
framework that effectively manages object classification and segmentation
tasks. A unique fusion of local and global network learning paradigms has been
employed, enriched by edge-focused local and global embeddings, thereby
significantly augmenting the model's interpretative prowess. Further, we have
applied a hierarchical transformer architecture to boost point cloud processing
efficiency, thus providing nuanced insights into structural understanding. Our
approach demonstrates significant promise in managing noisy point cloud data
and highlights the potential of edge-aware strategies in 3D point cloud
learning. The proposed approach is shown to outperform existing techniques in
object classification and segmentation tasks, as demonstrated by experiments on
ModelNet40 and ShapeNet datasets.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13473" title="Abstract">arXiv:2309.13473</a> [<a href="/pdf/2309.13473" title="Download PDF">pdf</a>, <a href="/format/2309.13473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainability in HPC: Vision and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chadha%2C+M">Mohak Chadha</a>, 
<a href="/search/cs?searchtype=author&query=Arima%2C+E">Eishi Arima</a>, 
<a href="/search/cs?searchtype=author&query=Raoofy%2C+A">Amir Raoofy</a>, 
<a href="/search/cs?searchtype=author&query=Gerndt%2C+M">Michael Gerndt</a>, 
<a href="/search/cs?searchtype=author&query=Schulz%2C+M">Martin Schulz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ACM Sustainable Supercomputing Workshop in conjunction with SC'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Tackling climate change by reducing and eventually eliminating carbon
emissions is a significant milestone on the path toward establishing an
environmentally sustainable society. As we transition into the exascale era,
marked by an increasing demand and scale of HPC resources, the HPC community
must embrace the challenge of reducing carbon emissions from designing and
operating modern HPC systems. In this position paper, we describe challenges
and highlight different opportunities that can aid HPC sites in reducing the
carbon footprint of modern HPC systems.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13475" title="Abstract">arXiv:2309.13475</a> [<a href="/pdf/2309.13475" title="Download PDF">pdf</a>, <a href="/format/2309.13475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Mitigating System-Level Anomalies of Vision-Based  Controllers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Aryaman Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+K">Kaustav Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Bansal%2C+S">Somil Bansal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Autonomous systems, such as self-driving cars and drones, have made
significant strides in recent years by leveraging visual inputs and machine
learning for decision-making and control. Despite their impressive performance,
these vision-based controllers can make erroneous predictions when faced with
novel or out-of-distribution inputs. Such errors can cascade to catastrophic
system failures and compromise system safety. In this work, we introduce a
run-time anomaly monitor to detect and mitigate such closed-loop, system-level
failures. Specifically, we leverage a reachability-based framework to
stress-test the vision-based controller offline and mine its system-level
failures. This data is then used to train a classifier that is leveraged online
to flag inputs that might cause system breakdowns. The anomaly detector
highlights issues that transcend individual modules and pertain to the safety
of the overall system. We also design a fallback controller that robustly
handles these detected anomalies to preserve system safety. We validate the
proposed approach on an autonomous aircraft taxiing system that uses a
vision-based controller for taxiing. Our results show the efficacy of the
proposed approach in identifying and handling system-level anomalies,
outperforming methods such as prediction error-based detection, and ensembling,
thereby enhancing the overall safety and robustness of autonomous systems.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13476" title="Abstract">arXiv:2309.13476</a> [<a href="/pdf/2309.13476" title="Download PDF">pdf</a>, <a href="/format/2309.13476" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical attention interpretation: an interpretable speech-level  transformer for bi-modal depression detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Q">Qingkun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Luz%2C+S">Saturnino Luz</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Fuente+Garcia%2C+S">Sofia de la Fuente Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, submitted to IEEE International Conference on Acoustics, Speech, and Signal Processing
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Depression is a common mental disorder. Automatic depression detection tools
using speech, enabled by machine learning, help early screening of depression.
This paper addresses two limitations that may hinder the clinical
implementations of such tools: noise resulting from segment-level labelling and
a lack of model interpretability. We propose a bi-modal speech-level
transformer to avoid segment-level labelling and introduce a hierarchical
interpretation approach to provide both speech-level and sentence-level
interpretations, based on gradient-weighted attention maps derived from all
attention layers to track interactions between input features. We show that the
proposed model outperforms a model that learns at a segment level ($p$=0.854,
$r$=0.947, $F1$=0.947 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model
interpretation, using one true positive sample, we show which sentences within
a given speech are most relevant to depression detection; and which text tokens
and Mel-spectrogram regions within these sentences are most relevant to
depression detection. These interpretations allow clinicians to verify the
validity of predictions made by depression detection tools, promoting their
clinical implementations.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13477" title="Abstract">arXiv:2309.13477</a> [<a href="/pdf/2309.13477" title="Download PDF">pdf</a>, <a href="/format/2309.13477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spectral boundary conditions for volumetric frame fields design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Nesterenko%2C+Y">Yuri Nesterenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Using the 4th and the 3rd degree spherical harmonics as the representations
for volumetric frames, we describe a simple algebraic technique for combining
multiple frame orientation constraints into a single quadratic penalty
function. This technique allows to solve volumetric frame fields design
problems using a coarse-to-fine strategy on hierarchical grids with immersed
boundaries. These results were presented for the first time at the FRAMES 2023
European workshop on meshing.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13480" title="Abstract">arXiv:2309.13480</a> [<a href="/pdf/2309.13480" title="Download PDF">pdf</a>, <a href="/format/2309.13480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bringing Spatial Interaction Measures into Multi-Criteria Assessment of  Redistricting Plans Using Interactive Web Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kruse%2C+J">Jacob Kruse</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Song Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+Y">Yuhan Ji</a>, 
<a href="/search/cs?searchtype=author&query=Szabo%2C+D+P">Daniel P. Szabo</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+K">Kenneth Mayer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Cartography and Geographic Information Science, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">Redistricting is the process by which electoral district boundaries are
drawn, and a common normative assumption in this process is that districts
should be drawn so as to capture coherent communities of interest (COIs). While
states rely on various proxies for community illustration, such as compactness
metrics and municipal split counts, to guide redistricting, recent legal
challenges and scholarly works have shown the failings of such proxy measures
and the difficulty of balancing multiple criteria in district plan creation. To
address these issues, we propose the use of spatial interaction communities to
directly quantify the degree to which districts capture the underlying COIs.
Using large-scale human mobility flow data, we condense spatial interaction
community capture for a set of districts into a single number, the interaction
ratio (IR), which can be used for redistricting plan evaluation. To compare the
IR to traditional redistricting criteria (compactness and fairness), and to
explore the range of IR values found in valid districting plans, we employ a
Markov chain-based regionalization algorithm (ReCom) to produce ensembles of
valid plans, and calculate the degree to which they capture spatial interaction
communities. Furthermore, we propose two methods for biasing the ReCom
algorithm towards different IR values. We perform a multi-criteria assessment
of the space of valid maps, and present the results in an interactive web map.
The experiments on Wisconsin congressional districting plans demonstrate the
effectiveness of our methods for biasing sampling towards higher or lower IR
values. Furthermore, the analysis of the districts produced with these methods
suggests that districts with higher IR and compactness values tend to produce
district plans that are more proportional with regards to seats allocated to
each of the two major parties.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13481" title="Abstract">arXiv:2309.13481</a> [<a href="/pdf/2309.13481" title="Download PDF">pdf</a>, <a href="/format/2309.13481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-time Bandwidth Estimation from Offline Expert Demonstrations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gottipati%2C+A">Aashish Gottipati</a>, 
<a href="/search/cs?searchtype=author&query=Khairy%2C+S">Sami Khairy</a>, 
<a href="/search/cs?searchtype=author&query=Mittag%2C+G">Gabriel Mittag</a>, 
<a href="/search/cs?searchtype=author&query=Gopal%2C+V">Vishak Gopal</a>, 
<a href="/search/cs?searchtype=author&query=Cutler%2C+R">Ross Cutler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In this work, we tackle the problem of bandwidth estimation (BWE) for
real-time communication systems; however, in contrast to previous works, we
leverage the vast efforts of prior heuristic-based BWE methods and synergize
these approaches with deep learning-based techniques. Our work addresses
challenges in generalizing to unseen network dynamics and extracting rich
representations from prior experience, two key challenges in integrating
data-driven bandwidth estimators into real-time systems. To that end, we
propose Merlin, the first purely offline, data-driven solution to BWE that
harnesses prior heuristic-based methods to extract an expert BWE policy.
Through a series of experiments, we demonstrate that Merlin surpasses
state-of-the-art heuristic-based and deep learning-based bandwidth estimators
in terms of objective quality of experience metrics while generalizing beyond
the offline world to in-the-wild network deployments where Merlin achieves a
42.85% and 12.8% reduction in packet loss and delay, respectively, when
compared against WebRTC in inter-continental videoconferencing calls. We hope
that Merlin's offline-oriented design fosters new strategies for real-time
network control.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13482" title="Abstract">arXiv:2309.13482</a> [<a href="/pdf/2309.13482" title="Download PDF">pdf</a>, <a href="/format/2309.13482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Scheme of ResNet and Softmax
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhao Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+J">Junze Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Large language models (LLMs) have brought significant changes to human
society. Softmax regression and residual neural networks (ResNet) are two
important techniques in deep learning: they not only serve as significant
theoretical components supporting the functionality of LLMs but also are
related to many other machine learning and theoretical computer science fields,
including but not limited to image classification, object detection, semantic
segmentation, and tensors.
<br />Previous research works studied these two concepts separately. In this paper,
we provide a theoretical analysis of the regression problem: $\| \langle
\exp(Ax) + A x , {\bf 1}_n \rangle^{-1} ( \exp(Ax) + Ax ) - b \|_2^2$, where
$A$ is a matrix in $\mathbb{R}^{n \times d}$, $b$ is a vector in
$\mathbb{R}^n$, and ${\bf 1}_n$ is the $n$-dimensional vector whose entries are
all $1$. This regression problem is a unified scheme that combines softmax
regression and ResNet, which has never been done before. We derive the
gradient, Hessian, and Lipschitz properties of the loss function. The Hessian
is shown to be positive semidefinite, and its structure is characterized as the
sum of a low-rank matrix and a diagonal matrix. This enables an efficient
approximate Newton method.
<br />As a result, this unified scheme helps to connect two previously thought
unrelated fields and provides novel insight into loss landscape and
optimization for emerging over-parameterized neural networks, which is
meaningful for future research in deep learning models.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13485" title="Abstract">arXiv:2309.13485</a> [<a href="/pdf/2309.13485" title="Download PDF">pdf</a>, <a href="/format/2309.13485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretable and Flexible Target-Conditioned Neural Planners For  Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haolan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jishen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Learning-based approaches to autonomous vehicle planners have the potential
to scale to many complicated real-world driving scenarios by leveraging huge
amounts of driver demonstrations. However, prior work only learns to estimate a
single planning trajectory, while there may be multiple acceptable plans in
real-world scenarios. To solve the problem, we propose an interpretable neural
planner to regress a heatmap, which effectively represents multiple potential
goals in the bird's-eye view of an autonomous vehicle. The planner employs an
adaptive Gaussian kernel and relaxed hourglass loss to better capture the
uncertainty of planning problems. We also use a negative Gaussian kernel to add
supervision to the heatmap regression, enabling the model to learn collision
avoidance effectively. Our systematic evaluation on the Lyft Open Dataset
across a diverse range of real-world driving scenarios shows that our model
achieves a safer and more flexible driving performance than prior works.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13489" title="Abstract">arXiv:2309.13489</a> [<a href="/pdf/2309.13489" title="Download PDF">pdf</a>, <a href="/format/2309.13489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Systematic Errors in Object Detectors with the SCROD  Pipeline
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boreiko%2C+V">Valentyn Boreiko</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+M">Matthias Hein</a>, 
<a href="/search/cs?searchtype=author&query=Metzen%2C+J+H">Jan Hendrik Metzen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The identification and removal of systematic errors in object detectors can
be a prerequisite for their deployment in safety-critical applications like
automated driving and robotics. Such systematic errors can for instance occur
under very specific object poses (location, scale, orientation), object
colors/textures, and backgrounds. Real images alone are unlikely to cover all
relevant combinations. We overcome this limitation by generating synthetic
images with fine-granular control. While generating synthetic images with
physical simulators and hand-designed 3D assets allows fine-grained control
over generated images, this approach is resource-intensive and has limited
scalability. In contrast, using generative models is more scalable but less
reliable in terms of fine-grained control. In this paper, we propose a novel
framework that combines the strengths of both approaches. Our meticulously
designed pipeline along with custom models enables us to generate street scenes
with fine-grained control in a fully automated and scalable manner. Moreover,
our framework introduces an evaluation setting that can serve as a benchmark
for similar pipelines. This evaluation setting will contribute to advancing the
field and promoting standardized testing procedures.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13492" title="Abstract">arXiv:2309.13492</a> [<a href="/pdf/2309.13492" title="Download PDF">pdf</a>, <a href="/format/2309.13492" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Portrait Stylization: Artistic Style Transfer with Auxiliary Networks  for Human Face Stylization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ambiel%2C+T">Thiago Ambiel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Today's image style transfer methods have difficulty retaining humans face
individual features after the whole stylizing process. This occurs because the
features like face geometry and people's expressions are not captured by the
general-purpose image classifiers like the VGG-19 pre-trained models. This
paper proposes the use of embeddings from an auxiliary pre-trained face
recognition model to encourage the algorithm to propagate human face features
from the content image to the final stylized result.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13494" title="Abstract">arXiv:2309.13494</a> [<a href="/pdf/2309.13494" title="Download PDF">pdf</a>, <a href="/format/2309.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Communication-Constrained Multi-Robot Exploration with Intermittent  Rendezvous
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=da+silva%2C+A+R">Alysson Ribeiro da silva</a>, 
<a href="/search/cs?searchtype=author&query=Chaimowicz%2C+L">Luiz Chaimowicz</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Silva%2C+T+C">Thales Costa Silva</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+A">Ani Hsieh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 12 figures, 1 table, video: <a href="https://youtu.be/EuVbCoyjuIY">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">A challenge in Multi-Robot Exploration (MRE) tasks is formulating efficient
distributed exploration strategies since, in general, robots cannot communicate
freely and the environment can be dynamic and unknown. Most solutions deliver
good performance at the cost of adding more robots or network relays while
exploring, which helps to connect the robots through time. This paper proposes
a novel intermittent rendezvous method that allows robots to explore an unknown
environment while sharing maps at rendezvous points without adding relays or
other robots. We propose dynamically updating the rendezvous locations
throughout the exploration and designing an exploration strategy that
prioritizes future rendezvous. We generate our rendezvous strategies
automatically by reducing the MRE to instances of the Job Shop Schedule Problem
(JSSP) with temporal connectivity graphs. We evaluate our method in simulation
in various virtual urban environments and in a Gazebo simulation using the
Robot Operating System (ROS). Our results suggest that our method can be better
than using relays or maintaining intermittent communication with a base station
since we can explore faster without additional hardware to create a relay
network.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13495" title="Abstract">arXiv:2309.13495</a> [<a href="/pdf/2309.13495" title="Download PDF">pdf</a>, <a href="/format/2309.13495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ZDNS: A Fast DNS Toolkit for Internet Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+L">Liz Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Akiwate%2C+G">Gautam Akiwate</a>, 
<a href="/search/cs?searchtype=author&query=Berger%2C+B">Briana Berger</a>, 
<a href="/search/cs?searchtype=author&query=Drakontaidis%2C+S">Spencer Drakontaidis</a>, 
<a href="/search/cs?searchtype=author&query=Ascheman%2C+A">Anna Ascheman</a>, 
<a href="/search/cs?searchtype=author&query=Pearce%2C+P">Paul Pearce</a>, 
<a href="/search/cs?searchtype=author&query=Adrian%2C+D">David Adrian</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 22nd ACM Internet Measurement Conference. 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">Active DNS measurement is fundamental to understanding and improving the DNS
ecosystem. However, the absence of an extensible, high-performance, and
easy-to-use DNS toolkit has limited both the reproducibility and coverage of
DNS research. In this paper, we introduce ZDNS, a modular and open-source
active DNS measurement framework optimized for large-scale research studies of
DNS on the public Internet. We describe ZDNS' architecture, evaluate its
performance, and present two case studies that highlight how the tool can be
used to shed light on the operational complexities of DNS. We hope that ZDNS
will enable researchers to better -- and in a more reproducible manner --
understand Internet behavior.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13496" title="Abstract">arXiv:2309.13496</a> [<a href="/pdf/2309.13496" title="Download PDF">pdf</a>, <a href="/format/2309.13496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stratosphere: Finding Vulnerable Cloud Storage Buckets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cable%2C+J">Jack Cable</a>, 
<a href="/search/cs?searchtype=author&query=Gregory%2C+D">Drew Gregory</a>, 
<a href="/search/cs?searchtype=author&query=Izhikevich%2C+L">Liz Izhikevich</a>, 
<a href="/search/cs?searchtype=author&query=Durumeric%2C+Z">Zakir Durumeric</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proceedings of the 24th International Symposium on Research in Attacks, Intrusions and Defenses. 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Misconfigured cloud storage buckets have leaked hundreds of millions of
medical, voter, and customer records. These breaches are due to a combination
of easily-guessable bucket names and error-prone security configurations,
which, together, allow attackers to easily guess and access sensitive data. In
this work, we investigate the security of buckets, finding that prior studies
have largely underestimated cloud insecurity by focusing on simple,
easy-to-guess names. By leveraging prior work in the password analysis space,
we introduce Stratosphere, a system that learns how buckets are named in
practice in order to efficiently guess the names of vulnerable buckets. Using
Stratosphere, we find wide-spread exploitation of buckets and vulnerable
configurations continuing to increase over the years. We conclude with
recommendations for operators, researchers, and cloud providers.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13498" title="Abstract">arXiv:2309.13498</a> [<a href="/pdf/2309.13498" title="Download PDF">pdf</a>, <a href="/format/2309.13498" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Consensus Algorithms of Distributed Ledger Technology -- A Comprehensive  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alkhodair%2C+A+J">Ahmad J. Alkhodair</a>, 
<a href="/search/cs?searchtype=author&query=Mohanty%2C+S+P">Saraju P. Mohanty</a>, 
<a href="/search/cs?searchtype=author&query=Kougianos%2C+E">Elias Kougianos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages, 20 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The most essential component of every Distributed Ledger Technology (DLT) is
the Consensus Algorithm (CA), which enables users to reach a consensus in a
decentralized and distributed manner. Numerous CA exist, but their viability
for particular applications varies, making their trade-offs a crucial factor to
consider when implementing DLT in a specific field. This article provided a
comprehensive analysis of the various consensus algorithms used in distributed
ledger technologies (DLT) and blockchain networks. We cover an extensive array
of thirty consensus algorithms. Eleven attributes including hardware
requirements, pre-trust level, tolerance level, and more, were used to generate
a series of comparison tables evaluating these consensus algorithms. In
addition, we discuss DLT classifications, the categories of certain consensus
algorithms, and provide examples of authentication-focused and
data-storage-focused DLTs. In addition, we analyze the pros and cons of
particular consensus algorithms, such as Nominated Proof of Stake (NPoS),
Bonded Proof of Stake (BPoS), and Avalanche. In conclusion, we discuss the
applicability of these consensus algorithms to various Cyber Physical System
(CPS) use cases, including supply chain management, intelligent transportation
systems, and smart healthcare.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13499" title="Abstract">arXiv:2309.13499</a> [<a href="/pdf/2309.13499" title="Download PDF">pdf</a>, <a href="/format/2309.13499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controller Synthesis of Collaborative Signal Temporal Logic Tasks for  Multi-Agent Systems via Assume-Guarantee Contracts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Siyuan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Saoud%2C+A">Adnane Saoud</a>, 
<a href="/search/eess?searchtype=author&query=Dimarogonas%2C+D+V">Dimos V. Dimarogonas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2203.10041">arXiv:2203.10041</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">This paper considers the problem of controller synthesis of signal temporal
logic (STL) specifications for large-scale multi-agent systems, where the
agents are dynamically coupled and subject to collaborative tasks. A
compositional framework based on continuous-time assume-guarantee contracts is
developed to break the complex and large synthesis problem into subproblems of
manageable sizes. We first show how to formulate the collaborative STL tasks as
assume-guarantee contracts by leveraging the idea of funnel-based control. The
concept of contracts is used to establish our compositionality result, which
allows us to guarantee the satisfaction of a global contract by the multi-agent
system when all agents satisfy their local contracts. Then, a closed-form
continuous-time feedback controller is designed to enforce local contracts over
the agents in a distributed manner, which further guarantees the global task
satisfaction based on the compositionality result. Finally, the effectiveness
of our results is demonstrated by two numerical examples.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13500" title="Abstract">arXiv:2309.13500</a> [<a href="/pdf/2309.13500" title="Download PDF">pdf</a>, <a href="/format/2309.13500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Student Performance Prediction on Learnersourced Questions  with SGNN-LLM Synergy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+L">Lin Ni</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Sijie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xianda Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Denny%2C+P">Paul Denny</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As an emerging education strategy, learnersourcing offers the potential for
personalized learning content creation, but also grapples with the challenge of
predicting student performance due to inherent noise in student-generated data.
While graph-based methods excel in capturing dense learner-question
interactions, they falter in cold start scenarios, characterized by limited
interactions, as seen when questions lack substantial learner responses. In
response, we introduce an innovative strategy that synergizes the potential of
integrating Signed Graph Neural Networks (SGNNs) and Large Language Model (LLM)
embeddings. Our methodology employs a signed bipartite graph to comprehensively
model student answers, complemented by a contrastive learning framework that
enhances noise resilience. Furthermore, LLM's contribution lies in generating
foundational question embeddings, proving especially advantageous in addressing
cold start scenarios characterized by limited graph data interactions.
Validation across five real-world datasets sourced from the PeerWise platform
underscores our approach's effectiveness. Our method outperforms baselines,
showcasing enhanced predictive accuracy and robustness.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13501" title="Abstract">arXiv:2309.13501</a> [<a href="/pdf/2309.13501" title="Download PDF">pdf</a>, <a href="/format/2309.13501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Why Trick Me: The Honeypot Traps on Decentralized Exchanges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gan%2C+R">Rundong Gan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Le Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Decentralized Exchanges (DEXs) are one of the most important infrastructures
in the world of Decentralized Finance (DeFi) and are generally considered more
reliable than centralized exchanges (CEXs). However, some well-known
decentralized exchanges (e.g., Uniswap) allow the deployment of any unaudited
ERC20 tokens, resulting in the creation of numerous honeypot traps designed to
steal traders' assets: traders can exchange valuable assets (e.g., ETH) for
fraudulent tokens in liquidity pools but are unable to exchange them back for
the original assets.
<br />In this paper, we introduce honeypot traps on decentralized exchanges and
provide a taxonomy for these traps according to the attack effect. For
different types of traps, we design a detection scheme based on historical data
analysis and transaction simulation. We randomly select 10,000 pools from
Uniswap V2 \&amp; V3, and then utilize our method to check these pools.Finally, we
discover 8,443 abnormal pools, which shows that honeypot traps may exist widely
in exchanges like Uniswap. Furthermore, we discuss possible mitigation and
defense strategies to protect traders' assets.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13503" title="Abstract">arXiv:2309.13503</a> [<a href="/pdf/2309.13503" title="Download PDF">pdf</a>, <a href="/format/2309.13503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Green&#x27;s Functions for High Order Finite Difference Stencils
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gabbard%2C+J">James Gabbard</a>, 
<a href="/search/math?searchtype=author&query=van+Rees%2C+W+M">Wim M. van Rees</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Lattice Green's Functions (LGFs) are fundamental solutions to discretized
linear operators, and as such they are a useful tool for solving discretized
elliptic PDEs on domains that are unbounded in one or more directions. The
majority of existing numerical solvers that make use of LGFs rely on a
second-order discretization and operate on domains with free-space boundary
conditions in all directions. Under these conditions, fast expansion methods
are available that enable precomputation of 2D or 3D LGFs in linear time,
avoiding the need for brute-force multi-dimensional quadrature of numerically
unstable integrals. Here we focus on higher-order discretizations of the
Laplace operator on domains with more general boundary conditions, by (1)
providing an algorithm for fast and accurate evaluation of the LGFs associated
with high-order dimension-split centered finite differences on unbounded
domains, and (2) deriving closed-form expressions for the LGFs associated with
both dimension-split and Mehrstellen discretizations on domains with one
unbounded dimension. Through numerical experiments we demonstrate that these
techniques provide LGF evaluations with near machine-precision accuracy, and
that the resulting LGFs allow for numerically consistent solutions to
high-order discretizations of the Poisson's equation on fully or partially
unbounded 3D domains.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13505" title="Abstract">arXiv:2309.13505</a> [<a href="/pdf/2309.13505" title="Download PDF">pdf</a>, <a href="/format/2309.13505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Semantic Gaps for Language-Supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xing%2C+Y">Yun Xing</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jian Kang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+A">Aoran Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+J">Jiahao Nie</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+S">Shao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+S">Shijian Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 poster. Code will be available at <a href="https://github.com/xing0047/CoCu">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision-Language Pre-training has demonstrated its remarkable zero-shot
recognition ability and potential to learn generalizable visual representations
from language supervision. Taking a step ahead, language-supervised semantic
segmentation enables spatial localization of textual inputs by learning pixel
grouping solely from image-text pairs. Nevertheless, the state-of-the-art
suffers from clear semantic gaps between visual and textual modality: plenty of
visual concepts appeared in images are missing in their paired captions. Such
semantic misalignment circulates in pre-training, leading to inferior zero-shot
performance in dense predictions due to insufficient visual concepts captured
in textual representations. To close such semantic gap, we propose Concept
Curation (CoCu), a pipeline that leverages CLIP to compensate for the missing
semantics. For each image-text pair, we establish a concept archive that
maintains potential visually-matched concepts with our proposed vision-driven
expansion and text-to-vision-guided ranking. Relevant concepts can thus be
identified via cluster-guided sampling and fed into pre-training, thereby
bridging the gap between visual and textual semantics. Extensive experiments
over a broad suite of 8 segmentation benchmarks show that CoCu achieves superb
zero-shot transfer performance and greatly boosts language-supervised
segmentation baseline by a large margin, suggesting the value of bridging
semantic gap in pre-training data.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13506" title="Abstract">arXiv:2309.13506</a> [<a href="/pdf/2309.13506" title="Download PDF">pdf</a>, <a href="/format/2309.13506" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating the Usability of Differential Privacy Tools with Data  Practitioners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ngong%2C+I+C">Ivoline C. Ngong</a>, 
<a href="/search/cs?searchtype=author&query=Stenger%2C+B">Brad Stenger</a>, 
<a href="/search/cs?searchtype=author&query=Near%2C+J+P">Joseph P. Near</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Y">Yuanyuan Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Differential privacy (DP) has become the gold standard in privacy-preserving
data analytics, but implementing it in real-world datasets and systems remains
challenging. Recently developed DP tools aim to ease data practitioners' burden
in implementing DP solutions, but limited research has investigated these DP
tools' usability. Through a usability study with 24 US data practitioners with
varying prior DP knowledge, we comprehensively evaluate the usability of four
Python-based open-source DP tools: DiffPrivLib, Tumult Analytics, PipelineDP,
and OpenDP. Our results suggest that DP tools can help novices learn DP
concepts; that Application Programming Interface (API) design and documentation
are vital for learnability and error prevention; and that user satisfaction
highly correlates with the effectiveness of the tool. We discuss the balance
between ease of use and the learning curve needed to appropriately implement DP
and also provide recommendations to improve DP tools' usability to broaden
adoption.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13508" title="Abstract">arXiv:2309.13508</a> [<a href="/pdf/2309.13508" title="Download PDF">pdf</a>, <a href="/format/2309.13508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guided Cooperation in Hierarchical Reinforcement Learning via  Model-based Rollout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yaoru Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yeming Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Goal-conditioned hierarchical reinforcement learning (HRL) presents a
promising approach for enabling effective exploration in complex long-horizon
reinforcement learning (RL) tasks via temporal abstraction. Yet, most
goal-conditioned HRL algorithms focused on the subgoal discovery, regardless of
inter-level coupling. In essence, for hierarchical systems, the increased
inter-level communication and coordination can induce more stable and robust
policy improvement. Here, we present a goal-conditioned HRL framework with
Guided Cooperation via Model-based Rollout (GCMR), which estimates forward
dynamics to promote inter-level cooperation. The GCMR alleviates the
state-transition error within off-policy correction through a model-based
rollout, further improving the sample efficiency. Meanwhile, to avoid being
disrupted by these corrected but possibly unseen or faraway goals, lower-level
Q-function gradients are constrained using a gradient penalty with a
model-inferred upper bound, leading to a more stable behavioral policy.
Besides, we propose a one-step rollout-based planning to further facilitate
inter-level cooperation, where the higher-level Q-function is used to guide the
lower-level policy by estimating the value of future states so that global task
information is transmitted downwards to avoid local pitfalls. Experimental
results demonstrate that incorporating the proposed GCMR framework with ACLG, a
disentangled variant of HIGL, yields more stable and robust policy improvement
than baselines and substantially outperforms previous state-of-the-art (SOTA)
HRL algorithms in both hard-exploration problems and robotic control.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13509" title="Abstract">arXiv:2309.13509</a> [<a href="/pdf/2309.13509" title="Download PDF">pdf</a>, <a href="/format/2309.13509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Coco-Nut: Corpus of Japanese Utterance and Voice Characteristics  Description for Prompt-based Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+A">Aya Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Takamichi%2C+S">Shinnosuke Takamichi</a>, 
<a href="/search/cs?searchtype=author&query=Saito%2C+Y">Yuki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Nakata%2C+W">Wataru Nakata</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+D">Detai Xin</a>, 
<a href="/search/cs?searchtype=author&query=Saruwatari%2C+H">Hiroshi Saruwatari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In text-to-speech, controlling voice characteristics is important in
achieving various-purpose speech synthesis. Considering the success of
text-conditioned generation, such as text-to-image, free-form text instruction
should be useful for intuitive and complicated control of voice
characteristics. A sufficiently large corpus of high-quality and diverse voice
samples with corresponding free-form descriptions can advance such control
research. However, neither an open corpus nor a scalable method is currently
available. To this end, we develop Coco-Nut, a new corpus including diverse
Japanese utterances, along with text transcriptions and free-form voice
characteristics descriptions. Our methodology to construct this corpus consists
of 1) automatic collection of voice-related audio data from the Internet, 2)
quality assurance, and 3) manual annotation using crowdsourcing. Additionally,
we benchmark our corpus on the prompt embedding model trained by contrastive
speech-text learning.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13512" title="Abstract">arXiv:2309.13512</a> [<a href="/pdf/2309.13512" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object Classification Model Using Ensemble Learning with Gray-Level  Co-Occurrence Matrix and Histogram Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kurniati%2C+F+T">Florentina Tatrin Kurniati</a>, 
<a href="/search/cs?searchtype=author&query=Manongga%2C+D+H">Daniel HF Manongga</a>, 
<a href="/search/cs?searchtype=author&query=Sediyono%2C+E">Eko Sediyono</a>, 
<a href="/search/cs?searchtype=author&query=Prasetyo%2C+S+Y+J">Sri Yulianto Joko Prasetyo</a>, 
<a href="/search/cs?searchtype=author&query=Huizen%2C+R+R">Roy Rudolf Huizen</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JITEKI,Vol.9,No.3,September2023,pp.793-801;http://journal.uad.ac.id/index.php/JITEKI/article/view/26683
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of object classification, identification based on object
variations is a challenge in itself. Variations include shape, size, color, and
texture, these can cause problems in recognizing and distinguishing objects
accurately. The purpose of this research is to develop a classification method
so that objects can be accurately identified. The proposed classification model
uses Voting and Combined Classifier, with Random Forest, K-NN, Decision Tree,
SVM, and Naive Bayes classification methods. The test results show that the
voting method and Combined Classifier obtain quite good results with each of
them, ensemble voting with an accuracy value of 92.4%, 78.6% precision, 95.2%
recall, and 86.1% F1-score. While the combined classifier with an accuracy
value of 99.3%, a precision of 97.6%, a recall of 100%, and a 98.8% F1-score.
Based on the test results, it can be concluded that the use of the Combined
Classifier and voting methods is proven to increase the accuracy value. The
contribution of this research increases the effectiveness of the Ensemble
Learning method, especially the voting ensemble method and the Combined
Classifier in increasing the accuracy of object classification in image
processing.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13513" title="Abstract">arXiv:2309.13513</a> [<a href="/pdf/2309.13513" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Study of Perceptual Training of Chinese Mandarin Tones for  Monolingual Speakers of English Using Adaptive Computer Based Training  Software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuke Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">The study explored a new technique of phonetic tone training, which may have
a positive impact on second language learning and tone training.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13515" title="Abstract">arXiv:2309.13515</a> [<a href="/pdf/2309.13515" title="Download PDF">pdf</a>, <a href="/format/2309.13515" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-based Perception Contracts and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dawei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+B+C">Benjamin C. Yang</a>, 
<a href="/search/cs?searchtype=author&query=Mitra%2C+S">Sayan Mitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Perception modules are integral in many modern autonomous systems, but their
accuracy can be subject to the vagaries of the environment. In this paper, we
propose a learning-based approach that can automatically characterize the error
of a perception module from data and use this for safe control. The proposed
approach constructs a {\em perception contract (PC)\/} which generates a set
that contains the ground-truth value that is being estimated by the perception
module, with high probability. We apply the proposed approach to study a vision
pipeline deployed on a quadcopter. With the proposed approach, we successfully
constructed a PC for the vision pipeline. We then designed a control algorithm
that utilizes the learned PC, with the goal of landing the quadcopter safely on
a landing pad. Experiments show that with the learned PC, the control algorithm
safely landed the quadcopter despite the error from the perception module,
while the baseline algorithm without using the learned PC failed to do so.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13516" title="Abstract">arXiv:2309.13516</a> [<a href="/pdf/2309.13516" title="Download PDF">pdf</a>, <a href="/format/2309.13516" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InSpaceType: Reconsider Space Type in Indoor Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Cho-Ying Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Quankai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chin-Cheng Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Te-Lin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jing-Wen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Neumann%2C+U">Ulrich Neumann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Indoor monocular depth estimation has attracted increasing research interest.
Most previous works have been focusing on methodology, primarily experimenting
with NYU-Depth-V2 (NYUv2) Dataset, and only concentrated on the overall
performance over the test set. However, little is known regarding robustness
and generalization when it comes to applying monocular depth estimation methods
to real-world scenarios where highly varying and diverse functional
\textit{space types} are present such as library or kitchen. A study for
performance breakdown into space types is essential to realize a pretrained
model's performance variance. To facilitate our investigation for robustness
and address limitations of previous works, we collect InSpaceType, a
high-quality and high-resolution RGBD dataset for general indoor environments.
We benchmark 11 recent methods on InSpaceType and find they severely suffer
from performance imbalance concerning space types, which reveals their
underlying bias. We extend our analysis to 4 other datasets, 3 mitigation
approaches, and the ability to generalize to unseen space types. Our work marks
the first in-depth investigation of performance imbalance across space types
for indoor monocular depth estimation, drawing attention to potential safety
concerns for model deployment without considering space types, and further
shedding light on potential ways to improve robustness. See
\url{https://depthcomputation.github.io/DepthPublic} for data.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13517" title="Abstract">arXiv:2309.13517</a> [<a href="/pdf/2309.13517" title="Download PDF">pdf</a>, <a href="/ps/2309.13517" title="Download PostScript">ps</a>, <a href="/format/2309.13517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lifting Theorems Meet Information Complexity: Known and New Lower Bounds  of Set-disjointness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guangxu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiapeng Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Working Paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Set-disjointness problems are one of the most fundamental problems in
communication complexity and have been extensively studied in past decades.
Given its importance, many lower bound techniques were introduced to prove
communication lower bounds of set-disjointness. Combining ideas from
information complexity and query-to-communication lifting theorems, we
introduce a density increment argument to prove communication lower bounds for
set-disjointness:
<br />We give a simple proof showing that a large rectangle cannot be
$0$-monochromatic for multi-party unique-disjointness.
<br />We interpret the direct-sum argument as a density increment process and give
an alternative proof of randomized communication lower bounds for multi-party
unique-disjointness.
<br />Avoiding full simulations in lifting theorems, we simplify and improve
communication lower bounds for sparse unique-disjointness.
<br />Potential applications to be unified and improved by our density increment
argument are also discussed.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13519" title="Abstract">arXiv:2309.13519</a> [<a href="/pdf/2309.13519" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Modeling of an Unsaturated Bentonite Buffer Model Test Under  High Temperatures Using an Enhanced Axisymmetric Reproducing Kernel Particle  Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baek%2C+J">Jonghyuk Baek</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanran Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiaolong He</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Y">Yu Lu</a>, 
<a href="/search/cs?searchtype=author&query=McCartney%2C+J+S">John S. McCartney</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J+S">J. S. Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 19 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In deep geological repositories for high level nuclear waste with close
canister spacings, bentonite buffers can experience temperatures higher than
100 {\deg}C. In this range of extreme temperatures, phenomenological
constitutive laws face limitations in capturing the thermo-hydro-mechanical
(THM) behavior of the bentonite, since the pre-defined functional constitutive
laws often lack generality and flexibility to capture a wide range of complex
coupling phenomena as well as the effects of stress state and path dependency.
In this work, a deep neural network (DNN)-based soil-water retention curve
(SWRC) of bentonite is introduced and integrated into a Reproducing Kernel
Particle Method (RKPM) for conducting THM simulations of the bentonite buffer.
The DNN-SWRC model incorporates temperature as an additional input variable,
allowing it to learn the relationship between suction and degree of saturation
under the general non-isothermal condition, which is difficult to represent
using a phenomenological SWRC. For effective modeling of the tank-scale test,
new axisymmetric Reproducing Kernel basis functions enriched with singular
Dirichlet enforcement representing heater placement and an effective convective
heat transfer coefficient representing thin-layer composite tank construction
are developed. The proposed method is demonstrated through the modeling of a
tank-scale experiment involving a cylindrical layer of MX-80 bentonite exposed
to central heating.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13523" title="Abstract">arXiv:2309.13523</a> [<a href="/pdf/2309.13523" title="Download PDF">pdf</a>, <a href="/format/2309.13523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LiDAR-UDA: Self-ensembling Through Time for Unsupervised LiDAR Domain  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaban%2C+A">Amirreza Shaban</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">JoonHo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+S">Sanghun Jung</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangyun Meng</a>, 
<a href="/search/cs?searchtype=author&query=Boots%2C+B">Byron Boots</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We introduce LiDAR-UDA, a novel two-stage self-training-based Unsupervised
Domain Adaptation (UDA) method for LiDAR segmentation. Existing self-training
methods use a model trained on labeled source data to generate pseudo labels
for target data and refine the predictions via fine-tuning the network on the
pseudo labels. These methods suffer from domain shifts caused by different
LiDAR sensor configurations in the source and target domains. We propose two
techniques to reduce sensor discrepancy and improve pseudo label quality: 1)
LiDAR beam subsampling, which simulates different LiDAR scanning patterns by
randomly dropping beams; 2) cross-frame ensembling, which exploits temporal
consistency of consecutive frames to generate more reliable pseudo labels. Our
method is simple, generalizable, and does not incur any extra inference cost.
We evaluate our method on several public LiDAR datasets and show that it
outperforms the state-of-the-art methods by more than $3.9\%$ mIoU on average
for all scenarios. Code will be available at
https://github.com/JHLee0513/LiDARUDA.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13524" title="Abstract">arXiv:2309.13524</a> [<a href="/pdf/2309.13524" title="Download PDF">pdf</a>, <a href="/format/2309.13524" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global-correlated 3D-decoupling Transformer for Clothed Avatar  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zechuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Li Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Ling Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reconstructing 3D clothed human avatars from single images is a challenging
task, especially when encountering complex poses and loose clothing. Current
methods exhibit limitations in performance, largely attributable to their
dependence on insufficient 2D image features and inconsistent query methods.
Owing to this, we present the Global-correlated 3D-decoupling Transformer for
clothed Avatar reconstruction (GTA), a novel transformer-based architecture
that reconstructs clothed human avatars from monocular images. Our approach
leverages transformer architectures by utilizing a Vision Transformer model as
an encoder for capturing global-correlated image features. Subsequently, our
innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane
features, using learnable embeddings as queries for cross-plane generation. To
effectively enhance feature fusion with the tri-plane 3D feature and human body
prior, we propose a hybrid prior fusion strategy combining spatial and
prior-enhanced queries, leveraging the benefits of spatial localization and
human body prior knowledge. Comprehensive experiments on CAPE and THuman2.0
datasets illustrate that our method outperforms state-of-the-art approaches in
both geometry and texture reconstruction, exhibiting high robustness to
challenging poses and loose clothing, and producing higher-resolution textures.
Codes will be available at https://github.com/River-Zhang/GTA.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13525" title="Abstract">arXiv:2309.13525</a> [<a href="/pdf/2309.13525" title="Download PDF">pdf</a>, <a href="/format/2309.13525" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Supervised Domain Generalization for Object Detection via  Language-Guided Feature Alignment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Malakouti%2C+S">Sina Malakouti</a>, 
<a href="/search/cs?searchtype=author&query=Kovashka%2C+A">Adriana Kovashka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing domain adaptation (DA) and generalization (DG) methods in object
detection enforce feature alignment in the visual space but face challenges
like object appearance variability and scene complexity, which make it
difficult to distinguish between objects and achieve accurate detection. In
this paper, we are the first to address the problem of semi-supervised domain
generalization by exploring vision-language pre-training and enforcing feature
alignment through the language space. We employ a novel Cross-Domain
Descriptive Multi-Scale Learning (CDDMSL) aiming to maximize the agreement
between descriptions of an image presented with different domain-specific
characteristics in the embedding space. CDDMSL significantly outperforms
existing methods, achieving 11.7% and 7.5% improvement in DG and DA settings,
respectively. Comprehensive analysis and ablation studies confirm the
effectiveness of our method, positioning CDDMSL as a promising approach for
domain generalization in object detection tasks.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13526" title="Abstract">arXiv:2309.13526</a> [<a href="/pdf/2309.13526" title="Download PDF">pdf</a>, <a href="/format/2309.13526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdaMap: High-Scalable Real-Time Cooperative Perception at the Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yongjie Xue</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuru Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dawei Chen</a>, 
<a href="/search/cs?searchtype=author&query=hAN%2C+K">Kyungtae hAN</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IEEE/ACM SEC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Cooperative perception is the key approach to augment the perception of
connected and automated vehicles (CAVs) toward safe autonomous driving.
However, it is challenging to achieve real-time perception sharing for hundreds
of CAVs in large-scale deployment scenarios. In this paper, we propose AdaMap,
a new high-scalable real-time cooperative perception system, which achieves
assured percentile end-to-end latency under time-varying network dynamics. To
achieve AdaMap, we design a tightly coupled data plane and control plane. In
the data plane, we design a new hybrid localization module to dynamically
switch between object detection and tracking, and a novel point cloud
representation module to adaptively compress and reconstruct the point cloud of
detected objects. In the control plane, we design a new graph-based object
selection method to un-select excessive multi-viewed point clouds of objects,
and a novel approximated gradient descent algorithm to optimize the
representation of point clouds. We implement AdaMap on an emulation platform,
including realistic vehicle and server computation and a simulated 5G network,
under a 150-CAV trace collected from the CARLA simulator. The evaluation
results show that, AdaMap reduces up to 49x average transmission data size at
the cost of 0.37 reconstruction loss, as compared to state-of-the-art
solutions, which verifies its high scalability, adaptability, and computation
efficiency.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13528" title="Abstract">arXiv:2309.13528</a> [<a href="/pdf/2309.13528" title="Download PDF">pdf</a>, <a href="/format/2309.13528" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Iterative Reachability Estimation for Safe Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganai%2C+M">Milan Ganai</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zheng Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C">Chenning Yu</a>, 
<a href="/search/cs?searchtype=author&query=Herbert%2C+S">Sylvia Herbert</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Sicun Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">Ensuring safety is important for the practical deployment of reinforcement
learning (RL). Various challenges must be addressed, such as handling
stochasticity in the environments, providing rigorous guarantees of persistent
state-wise safety satisfaction, and avoiding overly conservative behaviors that
sacrifice performance. We propose a new framework, Reachability Estimation for
Safe Policy Optimization (RESPO), for safety-constrained RL in general
stochastic settings. In the feasible set where there exist violation-free
policies, we optimize for rewards while maintaining persistent safety. Outside
this feasible set, our optimization produces the safest behavior by
guaranteeing entrance into the feasible set whenever possible with the least
cumulative discounted violations. We introduce a class of algorithms using our
novel reachability estimation function to optimize in our proposed framework
and in similar frameworks such as those concurrently handling multiple hard and
soft constraints. We theoretically establish that our algorithms almost surely
converge to locally optimal policies of our safe optimization framework. We
evaluate the proposed methods on a diverse suite of safe RL environments from
Safety Gym, PyBullet, and MuJoCo, and show the benefits in improving both
reward performance and safety compared with state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13532" title="Abstract">arXiv:2309.13532</a> [<a href="/pdf/2309.13532" title="Download PDF">pdf</a>, <a href="/format/2309.13532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anisotropic body compliance facilitates robotic sidewinding in complex  environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kojouharov%2C+V">Velin Kojouharov</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+M">Matthew Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Maeng%2C+J">Jiyeon Maeng</a>, 
<a href="/search/cs?searchtype=author&query=Goldman%2C+D+I">Daniel I. Goldman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Sidewinding, a locomotion strategy characterized by the coordination of
lateral and vertical body undulations, is frequently observed in rattlesnakes
and has been successfully reconstructed by limbless robotic systems for
effective movement across diverse terrestrial terrains. However, the
integration of compliant mechanisms into sidewinding limbless robots remains
less explored, posing challenges for navigation in complex, rheologically
diverse environments. Inspired by a notable control simplification via
mechanical intelligence in lateral undulation, which offloads feedback control
to passive body mechanics and interactions with the environment, we present an
innovative design of a mechanically intelligent limbless robot for sidewinding.
This robot features a decentralized bilateral cable actuation system that
resembles organismal muscle actuation mechanisms. We develop a feedforward
controller that incorporates programmable body compliance into the sidewinding
gait template. Our experimental results highlight the emergence of mechanical
intelligence when the robot is equipped with an appropriate level of body
compliance. This allows the robot to 1) locomote more energetically
efficiently, as evidenced by a reduced cost of transport, and 2) navigate
through terrain heterogeneities, all achieved in an open-loop manner, without
the need for environmental awareness.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13536" title="Abstract">arXiv:2309.13536</a> [<a href="/pdf/2309.13536" title="Download PDF">pdf</a>, <a href="/format/2309.13536" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tackling the Unlimited Staleness in Federated Learning with Intertwined  Data and Device Heterogeneities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haoming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Wei Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">The efficiency of Federated Learning (FL) is often affected by both data and
device heterogeneities. Data heterogeneity is defined as the heterogeneity of
data distributions on different clients. Device heterogeneity is defined as the
clients' variant latencies in uploading their local model updates due to
heterogeneous conditions of local hardware resources, and causes the problem of
staleness when being addressed by asynchronous FL. Traditional schemes of
tackling the impact of staleness consider data and device heterogeneities as
two separate and independent aspects in FL, but this assumption is unrealistic
in many practical FL scenarios where data and device heterogeneities are
intertwined. In these cases, traditional schemes of weighted aggregation in FL
have been proved to be ineffective, and a better approach is to convert a stale
model update into a non-stale one. In this paper, we present a new FL framework
that leverages the gradient inversion technique for such conversion, hence
efficiently tackling unlimited staleness in clients' model updates. Our basic
idea is to use gradient inversion to get estimations of clients' local training
data from their uploaded stale model updates, and use these estimations to
compute non-stale client model updates. In this way, we address the problem of
possible data quality drop when using gradient inversion, while still
preserving the clients' local data privacy. We compared our approach with the
existing FL strategies on mainstream datasets and models, and experiment
results demonstrate that when tackling unlimited staleness, our approach can
significantly improve the trained model accuracy by up to 20% and speed up the
FL training progress by up to 35%.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13541" title="Abstract">arXiv:2309.13541</a> [<a href="/pdf/2309.13541" title="Download PDF">pdf</a>, <a href="/format/2309.13541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient All-to-All Collective Communication Schedules for  Direct-Connect Topologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Siddharth Pal</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Fantl%2C+J">Jason Fantl</a>, 
<a href="/search/cs?searchtype=author&query=Khoury%2C+J">Joud Khoury</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Arvind Krishnamurthy</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+P">Prithwish Basu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">The all-to-all collective communications primitive is widely used in machine
learning (ML) and high performance computing (HPC) workloads, and optimizing
its performance is of interest to both ML and HPC communities. All-to-all is a
particularly challenging workload that can severely strain the underlying
interconnect bandwidth at scale. This is mainly because of the quadratic
scaling in the number of messages that must be simultaneously serviced combined
with large message sizes. This paper takes a holistic approach to optimize the
performance of all-to-all collective communications on supercomputer-scale
direct-connect interconnects. We address several algorithmic and practical
challenges in developing efficient and bandwidth-optimal all-to-all schedules
for any topology, lowering the schedules to various backends and fabrics that
may or may not expose additional forwarding bandwidth, establishing an upper
bound on all-to-all throughput, and exploring novel topologies that deliver
near-optimal all-to-all performance.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13542" title="Abstract">arXiv:2309.13542</a> [<a href="/pdf/2309.13542" title="Download PDF">pdf</a>, <a href="/format/2309.13542" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Integrated Sensing and Communications for IoT: Synergies with Key 6G  Technology Enablers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaushik%2C+A">Aryan Kaushik</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rohit Singh</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Honghao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Dayarathna%2C+S">Shalanika Dayarathna</a>, 
<a href="/search/cs?searchtype=author&query=Senanayake%2C+R">Rajitha Senanayake</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+X">Xueli An</a>, 
<a href="/search/cs?searchtype=author&query=Stirling-Gallacher%2C+R+A">Richard A. Stirling-Gallacher</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+W">Wonjae Shin</a>, 
<a href="/search/cs?searchtype=author&query=Di+Renzo%2C+M">Marco Di Renzo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) and wireless generations have been evolving
simultaneously for the past few decades. Built upon wireless communication and
sensing technologies, IoT networks are usually evaluated based on metrics that
measure the device ability to sense information and effectively share it with
the network, which makes Integrated Sensing and Communication (ISAC) a pivotal
candidate for the sixth-generation (6G) IoT standards. This paper reveals
several innovative aspects of ISAC from an IoT perspective in 6G, empowering
various modern IoT use cases and key technology enablers. Moreover, we address
the challenges and future potential of ISAC-enabled IoT, including synergies
with Reconfigurable Intelligent Surfaces (RIS), Artificial Intelligence (AI),
and key updates of ISAC-IoT in 6G standardization. Furthermore, several
evolutionary concepts are introduced to open future research in 6G ISAC-IoT,
including the interplay with Non-Terrestrial Networks (NTN) and Orthogonal
Time-Frequency Space (OTFS) modulation.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13543" title="Abstract">arXiv:2309.13543</a> [<a href="/pdf/2309.13543" title="Download PDF">pdf</a>, <a href="/format/2309.13543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Substituting Data Annotation with Balanced Updates and Collective Loss  in Multi-label Text Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ozmen%2C+M">Muberra Ozmen</a>, 
<a href="/search/cs?searchtype=author&query=Cotnareanu%2C+J">Joseph Cotnareanu</a>, 
<a href="/search/cs?searchtype=author&query=Coates%2C+M">Mark Coates</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Proc. Conf. Lifelong Learning Agents (CoLLAs), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Multi-label text classification (MLTC) is the task of assigning multiple
labels to a given text, and has a wide range of application domains. Most
existing approaches require an enormous amount of annotated data to learn a
classifier and/or a set of well-defined constraints on the label space
structure, such as hierarchical relations which may be complicated to provide
as the number of labels increases. In this paper, we study the MLTC problem in
annotation-free and scarce-annotation settings in which the magnitude of
available supervision signals is linear to the number of labels. Our method
follows three steps, (1) mapping input text into a set of preliminary label
likelihoods by natural language inference using a pre-trained language model,
(2) calculating a signed label dependency graph by label descriptions, and (3)
updating the preliminary label likelihoods with message passing along the label
dependency graph, driven with a collective loss function that injects the
information of expected label frequency and average multi-label cardinality of
predictions. The experiments show that the proposed framework achieves
effective performance under low supervision settings with almost imperceptible
computational and memory overheads added to the usage of pre-trained language
model outperforming its initial performance by 70\% in terms of example-based
F1 score.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13544" title="Abstract">arXiv:2309.13544</a> [<a href="/pdf/2309.13544" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Related Rhythms: Recommendation System To Discover Music You May Like
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+R">Rahul Singh</a>, 
<a href="/search/cs?searchtype=author&query=Kanuparthi%2C+P">Pranav Kanuparthi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Machine Learning models are being utilized extensively to drive recommender
systems, which is a widely explored topic today. This is especially true of the
music industry, where we are witnessing a surge in growth. Besides a large
chunk of active users, these systems are fueled by massive amounts of data.
These large-scale systems yield applications that aim to provide a better user
experience and to keep customers actively engaged. In this paper, a distributed
Machine Learning (ML) pipeline is delineated, which is capable of taking a
subset of songs as input and producing a new subset of songs identified as
being similar to the inputted subset. The publicly accessible Million Songs
Dataset (MSD) enables researchers to develop and explore reasonably efficient
systems for audio track analysis and recommendations, without having to access
a commercialized music platform. The objective of the proposed application is
to leverage an ML system trained to optimally recommend songs that a user might
like.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13546" title="Abstract">arXiv:2309.13546</a> [<a href="/pdf/2309.13546" title="Download PDF">pdf</a>, <a href="/format/2309.13546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DFRD: Data-Free Robustness Distillation for Heterogeneous Federated  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+K">Kangyang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yexuan Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yunshi Lan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+M">Ming Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published as a conference paper at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Federated Learning (FL) is a privacy-constrained decentralized machine
learning paradigm in which clients enable collaborative training without
compromising private data. However, how to learn a robust global model in the
data-heterogeneous and model-heterogeneous FL scenarios is challenging. To
address it, we resort to data-free knowledge distillation to propose a new FL
method (namely DFRD). DFRD equips a conditional generator on the server to
approximate the training space of the local models uploaded by clients, and
systematically investigates its training in terms of fidelity, transferability}
and diversity. To overcome the catastrophic forgetting of the global model
caused by the distribution shifts of the generator across communication rounds,
we maintain an exponential moving average copy of the generator on the server.
Additionally, we propose dynamic weighting and label sampling to accurately
extract knowledge from local models. Finally, our extensive experiments on
various image classification tasks illustrate that DFRD achieves significant
performance gains compared to SOTA baselines.
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13549" title="Abstract">arXiv:2309.13549</a> [<a href="/pdf/2309.13549" title="Download PDF">pdf</a>, <a href="/format/2309.13549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Robot 3D Perception in Urban Environments: The UT Campus  Object Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Arthur Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Eranki%2C+C">Chaitanya Eranki</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Christina Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Ji-Hwan Park</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+R">Raymond Hong</a>, 
<a href="/search/cs?searchtype=author&query=Kalyani%2C+P">Pranav Kalyani</a>, 
<a href="/search/cs?searchtype=author&query=Kalyanaraman%2C+L">Lochana Kalyanaraman</a>, 
<a href="/search/cs?searchtype=author&query=Gamare%2C+A">Arsh Gamare</a>, 
<a href="/search/cs?searchtype=author&query=Bagad%2C+A">Arnav Bagad</a>, 
<a href="/search/cs?searchtype=author&query=Esteva%2C+M">Maria Esteva</a>, 
<a href="/search/cs?searchtype=author&query=Biswas%2C+J">Joydeep Biswas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 18 figures, 12 tables. Website: <a href="https://amrl.cs.utexas.edu/coda">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We introduce the UT Campus Object Dataset (CODa), a mobile robot egocentric
perception dataset collected on the University of Texas Austin Campus. Our
dataset contains 8.5 hours of multimodal sensor data: synchronized 3D point
clouds and stereo RGB video from a 128-channel 3D LiDAR and two 1.25MP RGB
cameras at 10 fps; RGB-D videos from an additional 0.5MP sensor at 7 fps, and a
9-DOF IMU sensor at 40 Hz. We provide 58 minutes of ground-truth annotations
containing 1.3 million 3D bounding boxes with instance IDs for 53 semantic
classes, 5000 frames of 3D semantic annotations for urban terrain, and
pseudo-ground truth localization. We repeatedly traverse identical geographic
locations for a wide range of indoor and outdoor areas, weather conditions, and
times of the day. Using CODa, we empirically demonstrate that: 1) 3D object
detection performance in urban settings is significantly higher when trained
using CODa compared to existing datasets even when employing state-of-the-art
domain adaptation approaches, 2) sensor-specific fine-tuning improves 3D object
detection accuracy and 3) pretraining on CODa improves cross-dataset 3D object
detection performance in urban settings compared to pretraining on AV datasets.
Using our dataset and annotations, we release benchmarks for 3D object
detection and 3D semantic segmentation using established metrics. In the
future, the CODa benchmark will include additional tasks like unsupervised
object discovery and re-identification. We publicly release CODa on the Texas
Data Repository, pre-trained models, dataset development package, and
interactive dataset viewer. We expect CODa to be a valuable dataset for
research in egocentric 3D perception and planning for autonomous navigation in
urban environments.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13550" title="Abstract">arXiv:2309.13550</a> [<a href="/pdf/2309.13550" title="Download PDF">pdf</a>, <a href="/format/2309.13550" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A  Controllable and Interpretable AI System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pham%2C+T+T">Trong Thang Pham</a>, 
<a href="/search/cs?searchtype=author&query=Brecheisen%2C+J">Jacob Brecheisen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+A">Anh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hien Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+N">Ngan Le</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In the field of chest X-ray (CXR) diagnosis, existing works often focus
solely on determining where a radiologist looks, typically through tasks such
as detection, segmentation, or classification. However, these approaches are
often designed as black-box models, lacking interpretability. In this paper, we
introduce a novel and unified controllable interpretable pipeline for decoding
the intense focus of radiologists in CXR diagnosis. Our approach addresses
three key questions: where a radiologist looks, how long they focus on specific
areas, and what findings they diagnose. By capturing the intensity of the
radiologist's gaze, we provide a unified solution that offers insights into the
cognitive process underlying radiological interpretation. Unlike current
methods that rely on black-box machine learning models, which can be prone to
extracting erroneous information from the entire input image during the
diagnosis process, we tackle this issue by effectively masking out irrelevant
information. Our approach leverages a vision-language model, allowing for
precise control over the interpretation process while ensuring the exclusion of
irrelevant features. To train our model, we utilize an eye gaze dataset to
extract anatomical gaze information and generate ground truth heatmaps. Through
extensive experimentation, we demonstrate the efficacy of our method. We
showcase that the attention heatmaps, designed to mimic radiologists' focus,
encode sufficient and relevant information, enabling accurate classification
tasks using only a portion of CXR.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13554" title="Abstract">arXiv:2309.13554</a> [<a href="/pdf/2309.13554" title="Download PDF">pdf</a>, <a href="/format/2309.13554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Stochastic Interacting Particle-Field Algorithm for 3D  Parabolic-Parabolic Keller-Segel Chemotaxis System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+Z">Zhongjian Wang</a>, 
<a href="/search/math?searchtype=author&query=Xin%2C+J">Jack Xin</a>, 
<a href="/search/math?searchtype=author&query=Zhang%2C+Z">Zhiwen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We introduce an efficient stochastic interacting particle-field (SIPF)
algorithm with no history dependence for computing aggregation patterns and
near singular solutions of parabolic-parabolic Keller-Segel (KS) chemotaxis
system in three space dimensions (3D). The KS solutions are approximated as
empirical measures of particles coupled with a smoother field (concentration of
chemo-attractant) variable computed by the spectral method. Instead of using
heat kernels causing history dependence and high memory cost, we leverage the
implicit Euler discretization to derive a one-step recursion in time for
stochastic particle positions and the field variable based on the explicit
Green's function of an elliptic operator of the form Laplacian minus a positive
constant. In numerical experiments, we observe that the resulting SIPF
algorithm is convergent and self-adaptive to the high gradient part of
solutions. Despite the lack of analytical knowledge (e.g. a self-similar
ansatz) of the blowup, the SIPF algorithm provides a low-cost approach to study
the emergence of finite time blowup in 3D by only dozens of Fourier modes and
through varying the amount of initial mass and tracking the evolution of the
field variable. Notably, the algorithm can handle at ease multi-modal initial
data and the subsequent complex evolution involving the merging of particle
clusters and formation of a finite time singularity.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13556" title="Abstract">arXiv:2309.13556</a> [<a href="/pdf/2309.13556" title="Download PDF">pdf</a>, <a href="/format/2309.13556" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOGICSEG: Parsing Visual Semantics with Neural Logic Learning and  Reasoning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liulei Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenguan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+Y">Yang Yi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 (Oral). Code: <a href="https://github.com/lingorX/LogicSeg/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Current high-performance semantic segmentation models are purely data-driven
sub-symbolic approaches and blind to the structured nature of the visual world.
This is in stark contrast to human cognition which abstracts visual perceptions
at multiple levels and conducts symbolic reasoning with such structured
abstraction. To fill these fundamental gaps, we devise LOGICSEG, a holistic
visual semantic parser that integrates neural inductive learning and logic
reasoning with both rich data and symbolic knowledge. In particular, the
semantic concepts of interest are structured as a hierarchy, from which a set
of constraints are derived for describing the symbolic relations and formalized
as first-order logic rules. After fuzzy logic-based continuous relaxation,
logical formulae are grounded onto data and neural computational graphs, hence
enabling logic-induced network training. During inference, logical constraints
are packaged into an iterative process and injected into the network in a form
of several matrix multiplications, so as to achieve hierarchy-coherent
prediction with logic reasoning. These designs together make LOGICSEG a general
and compact neural-logic machine that is readily integrated into existing
segmentation models. Extensive experiments over four datasets with various
segmentation models and backbones verify the effectiveness and generality of
LOGICSEG. We believe this study opens a new avenue for visual semantic parsing.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13559" title="Abstract">arXiv:2309.13559</a> [<a href="/pdf/2309.13559" title="Download PDF">pdf</a>, <a href="/format/2309.13559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Swashplateless-elevon Actuation for a Dual-rotor Tail-sitter VTOL UAV
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+F">Fanze Kong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haotian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiayuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziwei Ye</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fangcheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Ximin Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fu Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we propose a novel swashplateless-elevon actuation (SEA) for
dual-rotor tail-sitter vertical takeoff and landing (VTOL) unmanned aerial
vehicles (UAVs). In contrast to the conventional elevon actuation (CEA) which
controls both pitch and yaw using elevons, the SEA adopts swashplateless
mechanisms to generate an extra moment through motor speed modulation to
control pitch and uses elevons solely for controlling yaw, without requiring
additional actuators. This decoupled control strategy mitigates the saturation
of elevons' deflection needed for large pitch and yaw control actions, thus
improving the UAV's control performance on trajectory tracking and disturbance
rejection performance in the presence of large external disturbances.
Furthermore, the SEA overcomes the actuation degradation issues experienced by
the CEA when the UAV is in close proximity to the ground, leading to a smoother
and more stable take-off process. We validate and compare the performances of
the SEA and the CEA in various real-world flight conditions, including
take-off, trajectory tracking, and hover flight and position steps under
external disturbance. Experimental results demonstrate that the SEA has better
performances than the CEA. Moreover, we verify the SEA's feasibility in the
attitude transition process and fixed-wing-mode flight of the VTOL UAV. The
results indicate that the SEA can accurately control pitch in the presence of
high-speed incoming airflow and maintain a stable attitude during fixed-wing
mode flight. Video of all experiments can be found in
youtube.com/watch?v=Sx9Rk4Zf7sQ
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13561" title="Abstract">arXiv:2309.13561</a> [<a href="/pdf/2309.13561" title="Download PDF">pdf</a>, <a href="/format/2309.13561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cordyceps@LT-EDI: Patching Language-Specific Homophobia/Transphobia  Classifiers with a Multilingual Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ninalga%2C+D">Dean Ninalga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Detecting transphobia, homophobia, and various other forms of hate speech is
difficult. Signals can vary depending on factors such as language, culture,
geographical region, and the particular online platform. Here, we present a
joint multilingual (M-L) and language-specific (L-S) approach to homophobia and
transphobic hate speech detection (HSD). M-L models are needed to catch words,
phrases, and concepts that are less common or missing in a particular language
and subsequently overlooked by L-S models. Nonetheless, L-S models are better
situated to understand the cultural and linguistic context of the users who
typically write in a particular language. Here we construct a simple and
successful way to merge the M-L and L-S approaches through simple weight
interpolation in such a way that is interpretable and data-driven. We
demonstrate our system on task A of the 'Shared Task on Homophobia/Transphobia
Detection in social media comments' dataset for homophobia and transphobic HSD.
Our system achieves the best results in three of five languages and achieves a
0.997 macro average F1-score on Malayalam texts.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13562" title="Abstract">arXiv:2309.13562</a> [<a href="/pdf/2309.13562" title="Download PDF">pdf</a>, <a href="/format/2309.13562" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keeping in Time: Adding Temporal Context to Sentiment Analysis Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ninalga%2C+D">Dean Ninalga</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents a state-of-the-art solution to the LongEval CLEF 2023 Lab
Task 2: LongEval-Classification. The goal of this task is to improve and
preserve the performance of sentiment analysis models across shorter and longer
time periods. Our framework feeds date-prefixed textual inputs to a pre-trained
language model, where the timestamp is included in the text. We show
date-prefixed samples better conditions model outputs on the temporal context
of the respective texts. Moreover, we further boost performance by performing
self-labeling on unlabeled data to train a student model. We augment the
self-labeling process using a novel augmentation strategy leveraging the
date-prefixed formatting of our samples. We demonstrate concrete performance
gains on the LongEval-Classification evaluation set over non-augmented
self-labeling. Our framework achieves a 2nd place ranking with an overall score
of 0.6923 and reports the best Relative Performance Drop (RPD) of -0.0656 over
the short evaluation set.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13563" title="Abstract">arXiv:2309.13563</a> [<a href="/pdf/2309.13563" title="Download PDF">pdf</a>, <a href="/format/2309.13563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multivariate Prototype Representation for Domain-Generalized Incremental  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+C">Can Peng</a>, 
<a href="/search/cs?searchtype=author&query=Koniusz%2C+P">Piotr Koniusz</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kaiyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lovell%2C+B+C">Brian C. Lovell</a>, 
<a href="/search/cs?searchtype=author&query=Moghadam%2C+P">Peyman Moghadam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deep learning models suffer from catastrophic forgetting when being
fine-tuned with samples of new classes. This issue becomes even more pronounced
when faced with the domain shift between training and testing data. In this
paper, we study the critical and less explored Domain-Generalized
Class-Incremental Learning (DGCIL). We design a DGCIL approach that remembers
old classes, adapts to new classes, and can classify reliably objects from
unseen domains. Specifically, our loss formulation maintains classification
boundaries and suppresses the domain-specific information of each class. With
no old exemplars stored, we use knowledge distillation and estimate old class
prototype drift as incremental training advances. Our prototype representations
are based on multivariate Normal distributions whose means and covariances are
constantly adapted to changing model features to represent old classes well by
adapting to the feature space drift. For old classes, we sample pseudo-features
from the adapted Normal distributions with the help of Cholesky decomposition.
In contrast to previous pseudo-feature sampling strategies that rely solely on
average mean prototypes, our method excels at capturing varying semantic
information. Experiments on several benchmarks validate our claims.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13567" title="Abstract">arXiv:2309.13567</a> [<a href="/pdf/2309.13567" title="Download PDF">pdf</a>, <a href="/format/2309.13567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MentalLLaMA: Interpretable Mental Health Analysis on Social Media with  Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kailai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tianlin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kuang%2C+Z">Ziyan Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Q">Qianqian Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ananiadou%2C+S">Sophia Ananiadou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">With the development of web technology, social media texts are becoming a
rich source for automatic mental health analysis. As traditional discriminative
methods bear the problem of low interpretability, the recent large language
models have been explored for interpretable mental health analysis on social
media, which aims to provide detailed explanations along with predictions. The
results show that ChatGPT can generate approaching-human explanations for its
correct classifications. However, LLMs still achieve unsatisfactory
classification performance in a zero-shot/few-shot manner. Domain-specific
finetuning is an effective solution, but faces 2 challenges: 1) lack of
high-quality training data. 2) no open-source LLMs for interpretable mental
health analysis were released to lower the finetuning cost. To alleviate these
problems, we build the first multi-task and multi-source interpretable mental
health instruction (IMHI) dataset on social media, with 105K data samples. The
raw social media data are collected from 10 existing sources covering 8 mental
health analysis tasks. We use expert-written few-shot prompts and collected
labels to prompt ChatGPT and obtain explanations from its responses. To ensure
the reliability of the explanations, we perform strict automatic and human
evaluations on the correctness, consistency, and quality of generated data.
Based on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA,
the first open-source LLM series for interpretable mental health analysis with
instruction-following capability. We also evaluate the performance of
MentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their
correctness for making predictions and the quality of explanations are
examined. The results show that MentalLLaMA approaches state-of-the-art
discriminative methods in correctness and generates high-quality explanations.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13570" title="Abstract">arXiv:2309.13570</a> [<a href="/pdf/2309.13570" title="Download PDF">pdf</a>, <a href="/format/2309.13570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Subcentimeter Accuracy Digital-Twin Tracking via An RGBD-based  Transformer Model and A Comprehensive Mobile Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Z">Zixun Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+K">Keling Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S+Z">Seth Z. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chuanyu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianjian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Weiyu Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+A+Y">Allen Y. Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The potential of digital twin technology, involving the creation of precise
digital replicas of physical objects, to reshape AR experiences in 3D object
tracking and localization scenarios is significant. However, enabling 3D object
tracking with subcentimeter accuracy in dynamic mobile AR environments remains
a formidable challenge. These scenarios often require a more robust pose
estimator capable of handling the inherent sensor-level measurement noise. In
this paper, recognizing the absence of comprehensive solutions in existing
literature, we build upon our previous work, the Digital Twin Tracking Dataset
(DTTD), to address these challenges in mobile AR settings. Specifically, we
propose a transformer-based 6DoF pose estimator designed to withstand the
challenges posed by noisy depth data. Simultaneously, we introduce a novel RGBD
dataset captured using a cutting-edge mobile sensor, the iPhone 14 Pro,
expanding the applicability of our approach to iPhone sensor data. Through
extensive experimentation and in-depth analysis, we illustrate the
effectiveness of our methods in the face of significant depth data errors,
surpassing the performance of existing baselines. Code will be made publicly
available.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13573" title="Abstract">arXiv:2309.13573</a> [<a href="/pdf/2309.13573" title="Download PDF">pdf</a>, <a href="/format/2309.13573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The second multi-channel multi-party meeting transcription challenge  (M2MeT) 2.0): A benchmark for speaker-attributed ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yuhao Liang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+M">Mohan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+F">Fan Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangze Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhihao Du</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+A">Kong Aik Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhijie Yan</a>, 
<a href="/search/cs?searchtype=author&query=Bu%2C+H">Hui Bu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the success of the first Multi-channel Multi-party Meeting Transcription
challenge (M2MeT), the second M2MeT challenge (M2MeT 2.0) held in ASRU2023
particularly aims to tackle the complex task of speaker-attributed ASR
(SA-ASR), which directly addresses the practical and challenging problem of
"who spoke what at when" at typical meeting scenario. We particularly
established two sub-tracks. 1) The fixed training condition sub-track, where
the training data is constrained to predetermined datasets, but participants
can use any open-source pre-trained model. 2) The open training condition
sub-track, which allows for the use of all available data and models. In
addition, we release a new 10-hour test set for challenge ranking. This paper
provides an overview of the dataset, track settings, results, and analysis of
submitted systems, as a benchmark to show the current state of
speaker-attributed ASR.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13574" title="Abstract">arXiv:2309.13574</a> [<a href="/pdf/2309.13574" title="Download PDF">pdf</a>, <a href="/ps/2309.13574" title="Download PostScript">ps</a>, <a href="/format/2309.13574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM for Test Script Generation and Migration: Challenges, Capabilities,  and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shengcheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chunrong Fang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+Y">Yuchen Ling</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chentian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenyu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 23rd IEEE International Conference on Software Quality, Reliability, and Security (QRS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper investigates the application of large language models (LLM) in the
domain of mobile application test script generation. Test script generation is
a vital component of software testing, enabling efficient and reliable
automation of repetitive test tasks. However, existing generation approaches
often encounter limitations, such as difficulties in accurately capturing and
reproducing test scripts across diverse devices, platforms, and applications.
These challenges arise due to differences in screen sizes, input modalities,
platform behaviors, API inconsistencies, and application architectures.
Overcoming these limitations is crucial for achieving robust and comprehensive
test automation.
<br />By leveraging the capabilities of LLMs, we aim to address these challenges
and explore its potential as a versatile tool for test automation. We
investigate how well LLMs can adapt to diverse devices and systems while
accurately capturing and generating test scripts. Additionally, we evaluate its
cross-platform generation capabilities by assessing its ability to handle
operating system variations and platform-specific behaviors. Furthermore, we
explore the application of LLMs in cross-app migration, where it generates test
scripts across different applications and software environments based on
existing scripts.
<br />Throughout the investigation, we analyze its adaptability to various user
interfaces, app architectures, and interaction patterns, ensuring accurate
script generation and compatibility. The findings of this research contribute
to the understanding of LLMs' capabilities in test automation. Ultimately, this
research aims to enhance software testing practices, empowering app developers
to achieve higher levels of software quality and development efficiency.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13575" title="Abstract">arXiv:2309.13575</a> [<a href="/pdf/2309.13575" title="Download PDF">pdf</a>, <a href="/format/2309.13575" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Weight Fixing: Large-scale training of neural network  weight uncertainties for quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subia-Waud%2C+C">Christopher Subia-Waud</a>, 
<a href="/search/cs?searchtype=author&query=Dasmahapatra%2C+S">Srinandan Dasmahapatra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Weight-sharing quantization has emerged as a technique to reduce energy
expenditure during inference in large neural networks by constraining their
weights to a limited set of values. However, existing methods for
weight-sharing quantization often make assumptions about the treatment of
weights based on value alone that neglect the unique role weight position
plays. This paper proposes a probabilistic framework based on Bayesian neural
networks (BNNs) and a variational relaxation to identify which weights can be
moved to which cluster centre and to what degree based on their individual
position-specific learned uncertainty distributions. We introduce a new
initialisation setting and a regularisation term which allow for the training
of BNNs under complex dataset-model combinations. By leveraging the flexibility
of weight values captured through a probability distribution, we enhance noise
resilience and downstream compressibility. Our iterative clustering procedure
demonstrates superior compressibility and higher accuracy compared to
state-of-the-art methods on both ResNet models and the more complex
transformer-based architectures. In particular, our method outperforms the
state-of-the-art quantization method top-1 accuracy by 1.6% on ImageNet using
DeiT-Tiny, with its 5 million+ weights now represented by only 296 unique
values.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13578" title="Abstract">arXiv:2309.13578</a> [<a href="/pdf/2309.13578" title="Download PDF">pdf</a>, <a href="/format/2309.13578" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A SAM-based Solution for Hierarchical Panoptic Segmentation of Crops and  Weeds Competition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K+D">Khoa Dang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Phung%2C+T">Thanh-Hai Phung</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+H">Hoang-Giang Cao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical report of NYCU-WEED team for the challenge of hierarchical panoptic segmentation of crops and weeds using the PhenoBench dataset at the 8th Workshop on Computer Vision in Plant Phenotyping and Agriculture (CVPPA) - International Conference on Computer Vision (ICCV) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Panoptic segmentation in agriculture is an advanced computer vision technique
that provides a comprehensive understanding of field composition. It
facilitates various tasks such as crop and weed segmentation, plant panoptic
segmentation, and leaf instance segmentation, all aimed at addressing
challenges in agriculture. Exploring the application of panoptic segmentation
in agriculture, the 8th Workshop on Computer Vision in Plant Phenotyping and
Agriculture (CVPPA) hosted the challenge of hierarchical panoptic segmentation
of crops and weeds using the PhenoBench dataset. To tackle the tasks presented
in this competition, we propose an approach that combines the effectiveness of
the Segment AnyThing Model (SAM) for instance segmentation with prompt input
from object detection models. Specifically, we integrated two notable
approaches in object detection, namely DINO and YOLO-v8. Our best-performing
model achieved a PQ+ score of 81.33 based on the evaluation metrics of the
competition.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13579" title="Abstract">arXiv:2309.13579</a> [<a href="/pdf/2309.13579" title="Download PDF">pdf</a>, <a href="/format/2309.13579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing Is Not Always Believing: Invisible Collision Attack and Defence  on Pre-Trained Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+M">Minghang Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Junming Shao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large-scale pre-trained models (PTMs) such as BERT and GPT have achieved
great success in diverse fields. The typical paradigm is to pre-train a big
deep learning model on large-scale data sets, and then fine-tune the model on
small task-specific data sets for downstream tasks. Although PTMs have rapidly
progressed with wide real-world applications, they also pose significant risks
of potential attacks. Existing backdoor attacks or data poisoning methods often
build up the assumption that the attacker invades the computers of victims or
accesses the target data, which is challenging in real-world scenarios. In this
paper, we propose a novel framework for an invisible attack on PTMs with
enhanced MD5 collision. The key idea is to generate two equal-size models with
the same MD5 checksum by leveraging the MD5 chosen-prefix collision.
Afterwards, the two ``same" models will be deployed on public websites to
induce victims to download the poisoned model. Unlike conventional attacks on
deep learning models, this new attack is flexible, covert, and
model-independent. Additionally, we propose a simple defensive strategy for
recognizing the MD5 chosen-prefix collision and provide a theoretical
justification for its feasibility. We extensively validate the effectiveness
and stealthiness of our proposed attack and defensive method on different
models and data sets.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13586" title="Abstract">arXiv:2309.13586</a> [<a href="/pdf/2309.13586" title="Download PDF">pdf</a>, <a href="/format/2309.13586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Task-Oriented Dexterous Grasp Synthesis via Differentiable Grasp Wrench  Boundary Estimator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiayi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jialiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">He Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In review. ICRA 2024 submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Analytical dexterous grasping synthesis is often driven by grasp quality
metrics. However, existing metrics possess many problems, such as being
computationally expensive, physically inaccurate, and non-differentiable.
Moreover, none of them can facilitate the synthesis of non-force-closure
grasps, which account for a significant portion of task-oriented grasping such
as lid screwing and button pushing. The main challenge behind all the above
drawbacks is the difficulty in modeling the complex Grasp Wrench Space (GWS).
In this work, we overcome this challenge by proposing a novel GWS estimator,
thus enabling gradient-based task-oriented dexterous grasp synthesis for the
first time. Our key contribution is a fast, accurate, and differentiable
technique to estimate the GWS boundary with good physical interpretability by
parallel sampling and mapping, which does not require iterative optimization.
Second, based on our differentiable GWS estimator, we derive a task-oriented
energy function to enable gradient-based grasp synthesis and a metric to
evaluate non-force-closure grasps. Finally, we improve the previous dexterous
grasp synthesis pipeline mainly by a novel technique to make nearest-point
calculation differentiable, even on mesh edges and vertices. Extensive
experiments are performed to verify the efficiency and effectiveness of our
methods. Our GWS estimator can run in several milliseconds on GPUs with minimal
memory cost, more than three orders of magnitude faster than the classic
discretization-based method. Using this GWS estimator, we synthesize 0.1
million dexterous grasps to show that our pipeline can significantly outperform
the SOTA method, even in task-unaware force-closure-grasp synthesis. For
task-oriented grasp synthesis, we provide some qualitative results.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13591" title="Abstract">arXiv:2309.13591</a> [<a href="/pdf/2309.13591" title="Download PDF">pdf</a>, <a href="/format/2309.13591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Distributed Learning: Tight Error Bounds and Breakdown Point  under Data Heterogeneity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Allouah%2C+Y">Youssef Allouah</a>, 
<a href="/search/cs?searchtype=author&query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+N">Nirupam Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Pinot%2C+R">Rafa&#xeb;l Pinot</a>, 
<a href="/search/cs?searchtype=author&query=Rizk%2C+G">Geovani Rizk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)

</div>
<p class="mathjax">The theory underlying robust distributed learning algorithms, designed to
resist adversarial machines, matches empirical observations when data is
homogeneous. Under data heterogeneity however, which is the norm in practical
scenarios, established lower bounds on the learning error are essentially
vacuous and greatly mismatch empirical observations. This is because the
heterogeneity model considered is too restrictive and does not cover basic
learning tasks such as least-squares regression. We consider in this paper a
more realistic heterogeneity model, namely (G,B)-gradient dissimilarity, and
show that it covers a larger class of learning problems than existing theory.
Notably, we show that the breakdown point under heterogeneity is lower than the
classical fraction 1/2. We also prove a new lower bound on the learning error
of any distributed learning algorithm. We derive a matching upper bound for a
robust variant of distributed gradient descent, and empirically show that our
analysis reduces the gap between theory and practice.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13595" title="Abstract">arXiv:2309.13595</a> [<a href="/pdf/2309.13595" title="Download PDF">pdf</a>, <a href="/format/2309.13595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Shape Optimization by Constrained First-Order Least Mean Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Starke%2C+G">Gerhard Starke</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this work, the problem of shape optimization, subject to PDE constraints,
is reformulated as an $L^p$ best approximation problem under divergence
constraints to the shape tensor introduced in Laurain and Sturm: ESAIM Math.
Model. Numer. Anal. 50 (2016). More precisely, the main result of this paper
states that the $L^p$ distance of the above approximation problem is equal to
the dual norm of the shape derivative considered as a functional on
$W^{1,p^\ast}$ (where $1/p + 1/p^\ast = 1$). This implies that for any given
shape, one can evaluate its distance from being a stationary one with respect
to the shape derivative by simply solving the associated $L^p$-type least mean
approximation problem. Moreover, the Lagrange multiplier for the divergence
constraint turns out to be the shape deformation of steepest descent. This
provides a way, as an alternative to the approach by Deckelnick, Herbert and
Hinze: ESAIM Control Optim. Calc. Var. 28 (2022), for computing shape gradients
in $W^{1,p^\ast}$ for $p^\ast \in ( 2 , \infty )$. The discretization of the
least mean approximation problem is done with (lowest-order) matrix-valued
Raviart-Thomas finite element spaces leading to piecewise constant
approximations of the shape deformation acting as Lagrange multiplier.
Admissible deformations in $W^{1,p^\ast}$ to be used in a shape gradient
iteration are reconstructed locally. Our computational results confirm that the
$L^p$ distance of the best approximation does indeed measure the distance of
the considered shape to optimality. Also confirmed by our computational tests
are the observations that choosing $p^\ast$ (much) larger than 2 (which means
that $p$ must be close to 1 in our best approximation problem) decreases the
chance of encountering mesh degeneracy during the shape gradient iteration.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13596" title="Abstract">arXiv:2309.13596</a> [<a href="/pdf/2309.13596" title="Download PDF">pdf</a>, <a href="/format/2309.13596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancements in 3D Lane Detection Using LiDAR Point Clouds: From Data  Collection to Model Development
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Runkai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+Y">Yuwen Heng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuanda Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shilei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Heng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+C">Changhao Yao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jiawen Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+W">Weidong Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Advanced Driver-Assistance Systems (ADAS) have successfully integrated
learning-based techniques into vehicle perception and decision-making. However,
their application in 3D lane detection for effective driving environment
perception is hindered by the lack of comprehensive LiDAR datasets. The sparse
nature of LiDAR point cloud data prevents an efficient manual annotation
process. To solve this problem, we present LiSV-3DLane, a large-scale 3D lane
dataset that comprises 20k frames of surround-view LiDAR point clouds with
enriched semantic annotation. Unlike existing datasets confined to a frontal
perspective, LiSV-3DLane provides a full 360-degree spatial panorama around the
ego vehicle, capturing complex lane patterns in both urban and highway
environments. We leverage the geometric traits of lane lines and the intrinsic
spatial attributes of LiDAR data to design a simple yet effective automatic
annotation pipeline for generating finer lane labels. To propel future
research, we propose a novel LiDAR-based 3D lane detection model, LiLaDet,
incorporating the spatial geometry learning of the LiDAR point cloud into
Bird's Eye View (BEV) based lane identification. Experimental results indicate
that LiLaDet outperforms existing camera- and LiDAR-based approaches in the 3D
lane detection task on the K-Lane dataset and our LiSV-3DLane.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13598" title="Abstract">arXiv:2309.13598</a> [<a href="/pdf/2309.13598" title="Download PDF">pdf</a>, <a href="/format/2309.13598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Posterior Distribution in Denoising: Application to Uncertainty  Quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manor%2C+H">Hila Manor</a>, 
<a href="/search/cs?searchtype=author&query=Michaeli%2C+T">Tomer Michaeli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and examples are available on the project's webpage in <a href="https://hilamanor.github.io/GaussianDenoisingPosterior/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
<p class="mathjax">Denoisers play a central role in many applications, from noise suppression in
low-grade imaging sensors, to empowering score-based generative models. The
latter category of methods makes use of Tweedie's formula, which links the
posterior mean in Gaussian denoising (i.e., the minimum MSE denoiser) with the
score of the data distribution. Here, we derive a fundamental relation between
the higher-order central moments of the posterior distribution, and the
higher-order derivatives of the posterior mean. We harness this result for
uncertainty quantification of pre-trained denoisers. Particularly, we show how
to efficiently compute the principal components of the posterior distribution
for any desired region of an image, as well as to approximate the full marginal
distribution along those (or any other) one-dimensional directions. Our method
is fast and memory efficient, as it does not explicitly compute or store the
high-order moment tensors and it requires no training or fine tuning of the
denoiser. Code and examples are available on the project's webpage in
https://hilamanor.github.io/GaussianDenoisingPosterior/
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13599" title="Abstract">arXiv:2309.13599</a> [<a href="/pdf/2309.13599" title="Download PDF">pdf</a>, <a href="/format/2309.13599" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Cluster Assumption to Graph Convolution: Graph-based  Semi-Supervised Learning Revisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+H">Hongming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Li Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jianhua Li</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Z">Zhiguo Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+P+S">Philip S. Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Graph-based semi-supervised learning (GSSL) has long been a hot research
topic. Traditional methods are generally shallow learners, based on the cluster
assumption. Recently, graph convolutional networks (GCNs) have become the
predominant techniques for their promising performance. In this paper, we
theoretically discuss the relationship between these two types of methods in a
unified optimization framework. One of the most intriguing findings is that,
unlike traditional ones, typical GCNs may not jointly consider the graph
structure and label information at each layer. Motivated by this, we further
propose three simple but powerful graph convolution methods. The first is a
supervised method OGC which guides the graph convolution process with labels.
The others are two unsupervised methods: GGC and its multi-scale version GGCM,
both aiming to preserve the graph structure information during the convolution
process. Finally, we conduct extensive experiments to show the effectiveness of
our methods.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13600" title="Abstract">arXiv:2309.13600</a> [<a href="/pdf/2309.13600" title="Download PDF">pdf</a>, <a href="/format/2309.13600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Dimensional Hyena for Spatial Inductive Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zimerman%2C+I">Itamar Zimerman</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+L">Lior Wolf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, Vision Transformers have attracted increasing interest from
computer vision researchers. However, the advantage of these transformers over
CNNs is only fully manifested when trained over a large dataset, mainly due to
the reduced inductive bias towards spatial locality within the transformer's
self-attention mechanism. In this work, we present a data-efficient vision
transformer that does not rely on self-attention. Instead, it employs a novel
generalization to multiple axes of the very recent Hyena layer. We propose
several alternative approaches for obtaining this generalization and delve into
their unique distinctions and considerations from both empirical and
theoretical perspectives.
<br />Our empirical findings indicate that the proposed Hyena N-D layer boosts the
performance of various Vision Transformer architectures, such as ViT, Swin, and
DeiT across multiple datasets. Furthermore, in the small dataset regime, our
Hyena-based ViT is favorable to ViT variants from the recent literature that
are specifically designed for solving the same challenge, i.e., working with
small datasets or incorporating image-specific inductive bias into the
self-attention mechanism. Finally, we show that a hybrid approach that is based
on Hyena N-D for the first layers in ViT, followed by layers that incorporate
conventional attention, consistently boosts the performance of various vision
transformer architectures.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13601" title="Abstract">arXiv:2309.13601</a> [<a href="/pdf/2309.13601" title="Download PDF">pdf</a>, <a href="/format/2309.13601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FaceAtt: Enhancing Image Captioning with Facial Attributes for Portrait  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haque%2C+N">Naimul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Labiba%2C+I">Iffat Labiba</a>, 
<a href="/search/cs?searchtype=author&query=Akter%2C+S">Sadia Akter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated image caption generation is a critical area of research that
enhances accessibility and understanding of visual content for diverse
audiences. In this study, we propose the FaceAtt model, a novel approach to
attribute-focused image captioning that emphasizes the accurate depiction of
facial attributes within images. FaceAtt automatically detects and describes a
wide range of attributes, including emotions, expressions, pointed noses, fair
skin tones, hair textures, attractiveness, and approximate age ranges.
Leveraging deep learning techniques, we explore the impact of different image
feature extraction methods on caption quality and evaluate our model's
performance using metrics such as BLEU and METEOR. Our FaceAtt model leverages
annotated attributes of portraits as supplementary prior knowledge for our
portrait images before captioning. This innovative addition yields a subtle yet
discernible enhancement in the resulting scores, exemplifying the potency of
incorporating additional attribute vectors during training. Furthermore, our
research contributes to the broader discourse on ethical considerations in
automated captioning. This study sets the stage for future research in refining
attribute-focused captioning techniques, with a focus on enhancing linguistic
coherence, addressing biases, and accommodating diverse user needs.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13604" title="Abstract">arXiv:2309.13604</a> [<a href="/pdf/2309.13604" title="Download PDF">pdf</a>, <a href="/format/2309.13604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Aware Continual Test Time Adaptation for Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ni%2C+J">Jiayi Ni</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Senqiao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+W">Wenyu Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+R">Ran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zehui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shanghang Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Since autonomous driving systems usually face dynamic and ever-changing
environments, continual test-time adaptation (CTTA) has been proposed as a
strategy for transferring deployed models to continually changing target
domains. However, the pursuit of long-term adaptation often introduces
catastrophic forgetting and error accumulation problems, which impede the
practical implementation of CTTA in the real world. Recently, existing CTTA
methods mainly focus on utilizing a majority of parameters to fit target domain
knowledge through self-training. Unfortunately, these approaches often amplify
the challenge of error accumulation due to noisy pseudo-labels, and pose
practical limitations stemming from the heavy computational costs associated
with entire model updates. In this paper, we propose a distribution-aware
tuning (DAT) method to make the semantic segmentation CTTA efficient and
practical in real-world applications. DAT adaptively selects and updates two
small groups of trainable parameters based on data distribution during the
continual adaptation process, including domain-specific parameters (DSP) and
task-relevant parameters (TRP). Specifically, DSP exhibits sensitivity to
outputs with substantial distribution shifts, effectively mitigating the
problem of error accumulation. In contrast, TRP are allocated to positions that
are responsive to outputs with minor distribution shifts, which are fine-tuned
to avoid the catastrophic forgetting problem. In addition, since CTTA is a
temporal task, we introduce the Parameter Accumulation Update (PAU) strategy to
collect the updated DSP and TRP in target domain sequences. We conduct
extensive experiments on two widely-used semantic segmentation CTTA benchmarks,
achieving promising performance compared to previous state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13606" title="Abstract">arXiv:2309.13606</a> [<a href="/pdf/2309.13606" title="Download PDF">pdf</a>, <a href="/format/2309.13606" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating progressive failure in laminated glass beams with a  randomized phase-field solver
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+J">Jaroslav Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Zemanov%C3%A1%2C+A">Alena Zemanov&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Zeman%2C+J">Jan Zeman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 17 figures, and 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Materials Science (cond-mat.mtrl-sci)

</div>
<p class="mathjax">Laminated glass achieves improved post-critical response through the
composite effect of stiff glass layers and more compliant polymer films,
manifested in progressive layer failure by multiple localized cracks. As a
result, laminated glass exhibits greater ductility than non-laminated glass,
making structures made with it suitable for safety-critical applications while
maintaining their aesthetic qualities. However, as shown in our previous
studies, such post-critical response is challenging to reproduce using
deterministic failure models, which mostly predict failure through a single
through-thickness crack localized simultaneously in all layers. In this
numerical-experimental study, we explore the extent to which progressive
failure can be predicted by a simple randomized model, where layer-wise tensile
strength is modeled by independent, identically distributed Weibull variables.
On the numerical side, we employ a computationally efficient,
dimensionally-reduced phase field formulation -- with each layer considered to
be a Reissner-Mindlin beam -- to study progressive failure through
combinatorial analysis and detailed Monte Carlo simulations. The reference
experimental data were obtained from displacement-controlled four-point bending
tests performed on multi-layer laminated glass beams. For certain combinations
of the glass layer strengths, results show that the randomized model can
reproduce progressive structural failure and the formation of multiple
localized cracks in the glass layers. However, the predicted response was less
ductile than that observed in experiments, and the model could not reproduce
the most frequent glass layer failure sequence. These findings highlight the
need to consider strength variability along the length of a beam and to include
it in phase-field formulations.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13607" title="Abstract">arXiv:2309.13607</a> [<a href="/pdf/2309.13607" title="Download PDF">pdf</a>, <a href="/format/2309.13607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance  Field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijiang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zhongwei Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+D">Dongmei Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">3D style transfer aims to render stylized novel views of 3D scenes with the
specified style, which requires high-quality rendering and keeping multi-view
consistency. Benefiting from the ability of 3D representation from Neural
Radiance Field (NeRF), existing methods learn the stylized NeRF by giving a
reference style from an image. However, they suffer the challenges of
high-quality stylization with texture details for multi-style transfer and
stylization with multimodal guidance. In this paper, we reveal that the same
objects in 3D scenes show various states (color tone, details, etc.) from
different views after stylization since previous methods optimized by
single-view image-based style loss functions, leading NeRF to tend to smooth
texture details, further resulting in low-quality rendering. To tackle these
problems, we propose a novel Multimodal-guided 3D Multi-style transfer of NeRF,
termed MM-NeRF, which achieves high-quality 3D multi-style rendering with
texture details and can be driven by multimodal-style guidance. First, MM-NeRF
adopts a unified framework to project multimodal guidance into CLIP space and
extracts multimodal style features to guide the multi-style stylization. To
relieve the problem of lacking details, we propose a novel Multi-Head Learning
Scheme (MLS), in which each style head predicts the parameters of the color
head of NeRF. MLS decomposes the learning difficulty caused by the
inconsistency of multi-style transfer and improves the quality of stylization.
In addition, the MLS can generalize pre-trained MM-NeRF to any new styles by
adding heads with small training costs (a few minutes). Extensive experiments
on three real-world 3D scene datasets show that MM-NeRF achieves high-quality
3D multi-style stylization with multimodal guidance, keeps multi-view
consistency, and keeps semantic consistency of multimodal style guidance. Codes
will be released later.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13609" title="Abstract">arXiv:2309.13609</a> [<a href="/pdf/2309.13609" title="Download PDF">pdf</a>, <a href="/format/2309.13609" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vulnerabilities in Video Quality Assessment Models: The Challenge of  Adversarial Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+A">Ao-Xiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+Y">Yu Ran</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+W">Weixuan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuan-Gen Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">No-Reference Video Quality Assessment (NR-VQA) plays an essential role in
improving the viewing experience of end-users. Driven by deep learning, recent
NR-VQA models based on Convolutional Neural Networks (CNNs) and Transformers
have achieved outstanding performance. To build a reliable and practical
assessment system, it is of great necessity to evaluate their robustness.
However, such issue has received little attention in the academic community. In
this paper, we make the first attempt to evaluate the robustness of NR-VQA
models against adversarial attacks under black-box setting, and propose a
patch-based random search method for black-box attack. Specifically,
considering both the attack effect on quality score and the visual quality of
adversarial video, the attack problem is formulated as misleading the estimated
quality score under the constraint of just-noticeable difference (JND). Built
upon such formulation, a novel loss function called Score-Reversed Boundary
Loss is designed to push the adversarial video's estimated quality score far
away from its ground-truth score towards a specific boundary, and the JND
constraint is modeled as a strict $L_2$ and $L_\infty$ norm restriction. By
this means, both white-box and black-box attacks can be launched in an
effective and imperceptible manner. The source code is available at
https://github.com/GZHU-DVL/AttackVQA.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13610" title="Abstract">arXiv:2309.13610</a> [<a href="/pdf/2309.13610" title="Download PDF">pdf</a>, <a href="/format/2309.13610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jicheng Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Le-Tuan%2C+A">Anh Le-Tuan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Duc%2C+M">Manh Nguyen-Duc</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+T">Trung-Kien Tran</a>, 
<a href="/search/cs?searchtype=author&query=Hauswirth%2C+M">Manfred Hauswirth</a>, 
<a href="/search/cs?searchtype=author&query=Le-Phuoc%2C+D">Danh Le-Phuoc</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The availability of vast amounts of visual data with heterogeneous features
is a key factor for developing, testing, and benchmarking of new computer
vision (CV) algorithms and architectures. Most visual datasets are created and
curated for specific tasks or with limited image data distribution for very
specific situations, and there is no unified approach to manage and access them
across diverse sources, tasks, and taxonomies. This not only creates
unnecessary overheads when building robust visual recognition systems, but also
introduces biases into learning systems and limits the capabilities of
data-centric AI. To address these problems, we propose the Vision Knowledge
Graph (VisionKG), a novel resource that interlinks, organizes and manages
visual datasets via knowledge graphs and Semantic Web technologies. It can
serve as a unified framework facilitating simple access and querying of
state-of-the-art visual datasets, regardless of their heterogeneous formats and
taxonomies. One of the key differences between our approach and existing
methods is that ours is knowledge-based rather than metadatabased. It enhances
the enrichment of the semantics at both image and instance levels and offers
various data retrieval and exploratory services via SPARQL. VisionKG currently
contains 519 million RDF triples that describe approximately 40 million
entities, and are accessible at https://vision.semkg.org and through APIs. With
the integration of 30 datasets and four popular CV tasks, we demonstrate its
usefulness across various scenarios when working with CV pipelines.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13612" title="Abstract">arXiv:2309.13612</a> [<a href="/pdf/2309.13612" title="Download PDF">pdf</a>, <a href="/ps/2309.13612" title="Download PostScript">ps</a>, <a href="/format/2309.13612" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twins and the Future of their Use Enabling Shift Left and Shift  Right Cybersecurity Operations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohsin%2C+A">Ahmad Mohsin</a>, 
<a href="/search/cs?searchtype=author&query=Janicke%2C+H">Helge Janicke</a>, 
<a href="/search/cs?searchtype=author&query=Nepal%2C+S">Surya Nepal</a>, 
<a href="/search/cs?searchtype=author&query=Holmes%2C+D">David Holmes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE Submitted Paper: Trust, Privacy and Security in Intelligent Systems, and Applications
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Digital Twins (DTs), optimize operations and monitor performance in Smart
Critical Systems (SCS) domains like smart grids and manufacturing. DT-based
cybersecurity solutions are in their infancy, lacking a unified strategy to
overcome challenges spanning next three to five decades. These challenges
include reliable data accessibility from Cyber-Physical Systems (CPS),
operating in unpredictable environments. Reliable data sources are pivotal for
intelligent cybersecurity operations aided with underlying modeling
capabilities across the SCS lifecycle, necessitating a DT. To address these
challenges, we propose Security Digital Twins (SDTs) collecting realtime data
from CPS, requiring the Shift Left and Shift Right (SLSR) design paradigm for
SDT to implement both design time and runtime cybersecurity operations.
Incorporating virtual CPS components (VC) in Cloud/Edge, data fusion to SDT
models is enabled with high reliability, providing threat insights and
enhancing cyber resilience. VC-enabled SDT ensures accurate data feeds for
security monitoring for both design and runtime. This design paradigm shift
propagates innovative SDT modeling and analytics for securing future critical
systems. This vision paper outlines intelligent SDT design through innovative
techniques, exploring hybrid intelligence with data-driven and rule-based
semantic SDT models. Various operational use cases are discussed for securing
smart critical systems through underlying modeling and analytics capabilities.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13614" title="Abstract">arXiv:2309.13614</a> [<a href="/pdf/2309.13614" title="Download PDF">pdf</a>, <a href="/format/2309.13614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boosting Offline Reinforcement Learning for Autonomous Driving with  Hierarchical Latent Skills
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zenan Li</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+F">Fan Nie</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Q">Qiao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Da%2C+F">Fang Da</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hang Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Learning-based vehicle planning is receiving increasing attention with the
emergence of diverse driving simulators and large-scale driving datasets. While
offline reinforcement learning (RL) is well suited for these safety-critical
tasks, it still struggles to plan over extended periods. In this work, we
present a skill-based framework that enhances offline RL to overcome the
long-horizon vehicle planning challenge. Specifically, we design a variational
autoencoder (VAE) to learn skills from offline demonstrations. To mitigate
posterior collapse of common VAEs, we introduce a two-branch sequence encoder
to capture both discrete options and continuous variations of the complex
driving skills. The final policy treats learned skills as actions and can be
trained by any off-the-shelf offline RL algorithms. This facilitates a shift in
focus from per-step actions to temporally extended skills, thereby enabling
long-term reasoning into the future. Extensive results on CARLA prove that our
model consistently outperforms strong baselines at both training and new
scenarios. Additional visualizations and experiments demonstrate the
interpretability and transferability of extracted skills.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13617" title="Abstract">arXiv:2309.13617</a> [<a href="/pdf/2309.13617" title="Download PDF">pdf</a>, <a href="/format/2309.13617" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularising the Cauchy problem for Laplace&#x27;s equation by fractional  operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Rundell%2C+B+K+a+W">Barbara Kaltenbacher an William Rundell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we revisit the classical Cauchy problem for Laplace's equation
as well as two further related problems in the light of regularisation of this
highly ill-conditioned problem by replacing integer derivatives with fractional
ones. We do so in the spirit of quasi reversibility, replacing a classically
severely ill-posed PDE problem by a nearby well-posed or only mildly ill-posed
one. In order to be able to make use of the known stabilising effect of
one-dimensional fractional derivatives of Abel type we work in a particular
rectangular (in higher space dimensions cylindrical) geometry. We start with
the plain Cauchy problem of reconstructing the values of a harmonic function
inside this domain from its Dirichlet and Neumann trace on part of the boundary
(the cylinder base) and explore three options for doing this with fractional
operators. The two other related problems are the recovery of a free boundary
and then this together with simultaneous recovery of the impedance function in
the boundary condition. Our main technique here will be Newton's method. The
paper contains numerical reconstructions and convergence results for the
devised methods.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13618" title="Abstract">arXiv:2309.13618</a> [<a href="/pdf/2309.13618" title="Download PDF">pdf</a>, <a href="/format/2309.13618" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reinforcement-Enhanced Autoregressive Feature Transformation:  Gradient-steered Search in Continuous Space for Postfix Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Feature transformation aims to generate new pattern-discriminative feature
space from original features to improve downstream machine learning (ML) task
performances. However, the discrete search space for the optimal feature
explosively grows on the basis of combinations of features and operations from
low-order forms to high-order forms. Existing methods, such as exhaustive
search, expansion reduction, evolutionary algorithms, reinforcement learning,
and iterative greedy, suffer from large search space. Overly emphasizing
efficiency in algorithm design usually sacrifices stability or robustness. To
fundamentally fill this gap, we reformulate discrete feature transformation as
a continuous space optimization task and develop an
embedding-optimization-reconstruction framework. This framework includes four
steps: 1) reinforcement-enhanced data preparation, aiming to prepare
high-quality transformation-accuracy training data; 2) feature transformation
operation sequence embedding, intending to encapsulate the knowledge of
prepared training data within a continuous space; 3) gradient-steered optimal
embedding search, dedicating to uncover potentially superior embeddings within
the learned space; 4) transformation operation sequence reconstruction,
striving to reproduce the feature transformation solution to pinpoint the
optimal feature space.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13619" title="Abstract">arXiv:2309.13619</a> [<a href="/pdf/2309.13619" title="Download PDF">pdf</a>, <a href="/format/2309.13619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Changes-Aware Transformer: Learning Generalized Changes Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+L">Licheng Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jie Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Shuyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Difference features obtained by comparing the images of two periods play an
indispensable role in the change detection (CD) task. However, a pair of
bi-temporal images can exhibit diverse changes, which may cause various
difference features. Identifying changed pixels with differ difference features
to be the same category is thus a challenge for CD. Most nowadays' methods
acquire distinctive difference features in implicit ways like enhancing image
representation or supervision information. Nevertheless, informative image
features only guarantee object semantics are modeled and can not guarantee that
changed pixels have similar semantics in the difference feature space and are
distinct from those unchanged ones. In this work, the generalized
representation of various changes is learned straightforwardly in the
difference feature space, and a novel Changes-Aware Transformer (CAT) for
refining difference features is proposed. This generalized representation can
perceive which pixels are changed and which are unchanged and further guide the
update of pixels' difference features. CAT effectively accomplishes this
refinement process through the stacked cosine cross-attention layer and
self-attention layer. After refinement, the changed pixels in the difference
feature space are closer to each other, which facilitates change detection. In
addition, CAT is compatible with various backbone networks and existing CD
methods. Experiments on remote sensing CD data set and street scene CD data set
show that our method achieves state-of-the-art performance and has excellent
generalization.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13620" title="Abstract">arXiv:2309.13620</a> [<a href="/pdf/2309.13620" title="Download PDF">pdf</a>, <a href="/ps/2309.13620" title="Download PostScript">ps</a>, <a href="/format/2309.13620" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIS: Practical robust invertible network for image steganography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yitian Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xuhua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+X">Xiaodong Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Image steganography is a technique of hiding secret information inside
another image, so that the secret is not visible to human eyes and can be
recovered when needed. Most of the existing image steganography methods have
low hiding robustness when the container images affected by distortion. Such as
Gaussian noise and lossy compression. This paper proposed PRIS to improve the
robustness of image steganography, it based on invertible neural networks, and
put two enhance modules before and after the extraction process with a 3-step
training strategy. Moreover, rounding error is considered which is always
ignored by existing methods, but actually it is unavoidable in practical. A
gradient approximation function (GAF) is also proposed to overcome the
undifferentiable issue of rounding distortion. Experimental results show that
our PRIS outperforms the state-of-the-art robust image steganography method in
both robustness and practicability. Codes are available at
https://github.com/yanghangAI/PRIS, demonstration of our model in practical at
<a href="http://yanghang.site/hide/.">this http URL</a>
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13623" title="Abstract">arXiv:2309.13623</a> [<a href="/pdf/2309.13623" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Control Performance Analysis of Power Steering System Electromechanical  Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pramod%2C+P">Prerit Pramod</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Modern power steering systems employ an electric motor drive system to
provide torque assistance to the driver. The closed-loop mechanical system
dynamics that impact stability, performance and steering feel are significantly
impacted by the electrical dynamics of the actuator depending on the structure
and tuning of the motor torque controller. This paper presents an integrated
approach to the analysis of this electromechanical dynamic control interaction
through mathematical modeling which is confirmed with simulations.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13625" title="Abstract">arXiv:2309.13625</a> [<a href="/pdf/2309.13625" title="Download PDF">pdf</a>, <a href="/format/2309.13625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xin Li</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+D">Dongze Lian</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhihe Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+J">Jiawang Bai</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhibo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xinchao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023. The manuscript will be further revised based on the reviews
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Adapter-style efficient transfer learning (ETL) has shown excellent
performance in the tuning of vision-language models (VLMs) under the low-data
regime, where only a few additional parameters are introduced to excavate the
task-specific knowledge based on the general and powerful representation of
VLMs. However, most adapter-style works face two limitations: (i) modeling
task-specific knowledge with a single modality only; and (ii) overlooking the
exploitation of the inter-class relationships in downstream tasks, thereby
leading to sub-optimal solutions. To mitigate that, we propose an effective
adapter-style tuning strategy, dubbed GraphAdapter, which performs the textual
adapter by explicitly modeling the dual-modality structure knowledge (i.e., the
correlation of different semantics/classes in textual and visual modalities)
with a dual knowledge graph. In particular, the dual knowledge graph is
established with two sub-graphs, i.e., a textual knowledge sub-graph, and a
visual knowledge sub-graph, where the nodes and edges represent the
semantics/classes and their correlations in two modalities, respectively. This
enables the textual feature of each prompt to leverage the task-specific
structure knowledge from both textual and visual modalities, yielding a more
effective classifier for downstream tasks. Extensive experimental results on 11
benchmark datasets reveal that our GraphAdapter significantly outperforms
previous adapter-based methods. The code will be released at
https://github.com/lixinustc/GraphAdapter
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13631" title="Abstract">arXiv:2309.13631</a> [<a href="/pdf/2309.13631" title="Download PDF">pdf</a>, <a href="/format/2309.13631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6-DOF All-Terrain Cyclocopter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingwei Li</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+B">Boyuan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kangyao Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents the design of a 6-DOF all-terrain micro aerial vehicle
and two control strategies for multimodal flight, which are experimentally
validated. The micro aerial vehicle is propelled by four motors and controlled
by a single servo for the control of the cycloidal rotors(cyclorotors) speed
and lift direction. Despite the addition of the servo, the system remains
underactuated. To address the traditional underactuation problem of cycloidal
rotor aircraft, we increase the number of control variables. We propose a PID
and a nonlinear model predictive control (NMPC) framework to tackle the model's
nonlinearities and achieve control of attitude, position, and their
derivatives.Experimental results demonstrate the effectiveness of the proposed
multimodal control strategy for 6-DOF all-terrain micro aerial vehicles. The
vehicle can operate in aerial, terrestrial, and aquatic modes and can adapt to
different terrains and environmental conditions. Our approach enhances the
vehicle's performance in each mode of operation, and the results show the
advantages of the proposed strategy compared to other control strategies.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13633" title="Abstract">arXiv:2309.13633</a> [<a href="/pdf/2309.13633" title="Download PDF">pdf</a>, <a href="/format/2309.13633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EvalLM: Interactive Evaluation of Large Language Model Prompts on  User-Defined Criteria
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T+S">Tae Soo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yoonjoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Shin%2C+J">Jamin Shin</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Young-Ho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Juho Kim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">By simply composing prompts, developers can prototype novel generative
applications with Large Language Models (LLMs). To refine prototypes into
products, however, developers must iteratively revise prompts by evaluating
outputs to diagnose weaknesses. Formative interviews (N=8) revealed that
developers invest significant effort in manually evaluating outputs as they
assess context-specific and subjective criteria. We present EvalLM, an
interactive system for iteratively refining prompts by evaluating multiple
outputs on user-defined criteria. By describing criteria in natural language,
users can employ the system's LLM-based evaluator to get an overview of where
prompts excel or fail, and improve these based on the evaluator's feedback. A
comparative study (N=12) showed that EvalLM, when compared to manual
evaluation, helped participants compose more diverse criteria, examine twice as
many outputs, and reach satisfactory prompts with 59% fewer revisions. Beyond
prompts, our work can be extended to augment model evaluation and alignment in
specific application contexts.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13634" title="Abstract">arXiv:2309.13634</a> [<a href="/pdf/2309.13634" title="Download PDF">pdf</a>, <a href="/format/2309.13634" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unique Least Common Ancestors and Clusters in Directed Acyclic Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shanavas%2C+A+V">Ameera Vaheeda Shanavas</a>, 
<a href="/search/cs?searchtype=author&query=Changat%2C+M">Manoj Changat</a>, 
<a href="/search/cs?searchtype=author&query=Hellmuth%2C+M">Marc Hellmuth</a>, 
<a href="/search/cs?searchtype=author&query=Stadler%2C+P+F">Peter F. Stadler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Combinatorics (math.CO); Populations and Evolution (q-bio.PE)

</div>
<p class="mathjax">We investigate the connections between clusters and least common ancestors
(LCAs) in directed acyclic graphs (DAGs). We focus on the class of DAGs having
unique least common ancestors for certain subsets of their minimal elements
since these are of interest, particularly as models of phylogenetic networks.
Here, we use the close connection between the canonical k-ary transit function
and the closure function on a set system to show that pre-k-ary clustering
systems are exactly those that derive from a class of DAGs with unique LCAs.
Moreover, we show that k-ary T-systems and k-weak hierarchies are associated
with DAGs that satisfy stronger conditions on the existence of unique LCAs for
sets of size at most k.
</p>
</div>
</dd>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13635" title="Abstract">arXiv:2309.13635</a> [<a href="/pdf/2309.13635" title="Download PDF">pdf</a>, <a href="/format/2309.13635" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PanopticNDT: Efficient and Robust Panoptic Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seichter%2C+D">Daniel Seichter</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+B">Benedict Stephan</a>, 
<a href="/search/cs?searchtype=author&query=Fischedick%2C+S+B">S&#xf6;hnke Benedikt Fischedick</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+S">Steffen M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Rabes%2C+L">Leonard Rabes</a>, 
<a href="/search/cs?searchtype=author&query=Gross%2C+H">Horst-Michael Gross</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">As the application scenarios of mobile robots are getting more complex and
challenging, scene understanding becomes increasingly crucial. A mobile robot
that is supposed to operate autonomously in indoor environments must have
precise knowledge about what objects are present, where they are, what their
spatial extent is, and how they can be reached; i.e., information about free
space is also crucial. Panoptic mapping is a powerful instrument providing such
information. However, building 3D panoptic maps with high spatial resolution is
challenging on mobile robots, given their limited computing capabilities. In
this paper, we propose PanopticNDT - an efficient and robust panoptic mapping
approach based on occupancy normal distribution transform (NDT) mapping. We
evaluate our approach on the publicly available datasets Hypersim and
ScanNetV2. The results reveal that our approach can represent panoptic
information at a higher level of detail than other state-of-the-art approaches
while enabling real-time panoptic mapping on mobile robots. Finally, we prove
the real-world applicability of PanopticNDT with qualitative results in a
domestic application.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13636" title="Abstract">arXiv:2309.13636</a> [<a href="/pdf/2309.13636" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Development of an intelligent system for the detection of corona virus  using artificial neural network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%2C+N+E">Nwafor Emmanuel O</a>, 
<a href="/search/cs?searchtype=author&query=Umeh%2C+N+M">Ngozi Maryrose Umeh</a>, 
<a href="/search/cs?searchtype=author&query=Onyenwe%2C+I+E">Ikechukwu Ekene Onyenwe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Real-Time Application and Computing
  Systems (IJORTACS) Volume 1, Issue XI, November 2022, pp. 294-306
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents the development of an intelligent system for the
detection of coronavirus using artificial neural network. This was done after
series of literature review which indicated that high fever accounts for 87.9%
of the COVID-19 symptoms. 683 temperature data of COVID-19 patients at &gt;= 38C^o
were collected from Colliery hospital Enugu, Nigeria and used to train an
artificial neural network detective model for the detection of COVID-19. The
reference model generated was used converted into Verilog codes using Hardware
Description Language (HDL) and then burn into a Field Programming Gate Array
(FPGA) controller using FPGA tool in Matlab. The performance of the model when
evaluated using confusion matrix, regression and means square error (MSE)
showed that the regression value is 0.967; the accuracy is 97% and then MSE is
0.00100Mu. These results all implied that the new detection system for is
reliable and very effective for the detection of COVID-19.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13638" title="Abstract">arXiv:2309.13638</a> [<a href="/pdf/2309.13638" title="Download PDF">pdf</a>, <a href="/format/2309.13638" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Embers of Autoregression: Understanding Large Language Models Through  the Problem They are Trained to Solve
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=McCoy%2C+R+T">R. Thomas McCoy</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>, 
<a href="/search/cs?searchtype=author&query=Friedman%2C+D">Dan Friedman</a>, 
<a href="/search/cs?searchtype=author&query=Hardy%2C+M">Matthew Hardy</a>, 
<a href="/search/cs?searchtype=author&query=Griffiths%2C+T+L">Thomas L. Griffiths</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 50 pages plus 11 page of references and 23 pages of appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The widespread adoption of large language models (LLMs) makes it important to
recognize their strengths and limitations. We argue that in order to develop a
holistic understanding of these systems we need to consider the problem that
they were trained to solve: next-word prediction over Internet text. By
recognizing the pressures that this task exerts we can make predictions about
the strategies that LLMs will adopt, allowing us to reason about when they will
succeed or fail. This approach - which we call the teleological approach -
leads us to identify three factors that we hypothesize will influence LLM
accuracy: the probability of the task to be performed, the probability of the
target output, and the probability of the provided input. We predict that LLMs
will achieve higher accuracy when these probabilities are high than when they
are low - even in deterministic settings where probability should not matter.
To test our predictions, we evaluate two LLMs (GPT-3.5 and GPT-4) on eleven
tasks, and we find robust evidence that LLMs are influenced by probability in
the ways that we have hypothesized. In many cases, the experiments reveal
surprising failure modes. For instance, GPT-4's accuracy at decoding a simple
cipher is 51% when the output is a high-probability word sequence but only 13%
when it is low-probability. These results show that AI practitioners should be
careful about using LLMs in low-probability situations. More broadly, we
conclude that we should not evaluate LLMs as if they are humans but should
instead treat them as a distinct type of system - one that has been shaped by
its own particular set of pressures.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13643" title="Abstract">arXiv:2309.13643</a> [<a href="/pdf/2309.13643" title="Download PDF">pdf</a>, <a href="/format/2309.13643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REWAFL: Residual Energy and Wireless Aware Participant Selection for  Efficient Federated Learning over Mobile Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Y. Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">X. Qin</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+J">J. Geng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">R. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+Y">Y. Hou</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+Y">Y. Gong</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+M">M. Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">P. Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Networking and Internet Architecture (cs.NI)

</div>
<p class="mathjax">Participant selection (PS) helps to accelerate federated learning (FL)
convergence, which is essential for the practical deployment of FL over mobile
devices. While most existing PS approaches focus on improving training accuracy
and efficiency rather than residual energy of mobile devices, which
fundamentally determines whether the selected devices can participate.
Meanwhile, the impacts of mobile devices' heterogeneous wireless transmission
rates on PS and FL training efficiency are largely ignored. Moreover, PS causes
the staleness issue. Prior research exploits isolated functions to force
long-neglected devices to participate, which is decoupled from original PS
designs. In this paper, we propose a residual energy and wireless aware PS
design for efficient FL training over mobile devices (REWAFL). REW AFL
introduces a novel PS utility function that jointly considers global FL
training utilities and local energy utility, which integrates energy
consumption and residual battery energy of candidate mobile devices. Under the
proposed PS utility function framework, REW AFL further presents a residual
energy and wireless aware local computing policy. Besides, REWAFL buries the
staleness solution into its utility function and local computing policy. The
experimental results show that REW AFL is effective in improving training
accuracy and efficiency, while avoiding "flat battery" of mobile devices.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13646" title="Abstract">arXiv:2309.13646</a> [<a href="/pdf/2309.13646" title="Download PDF">pdf</a>, <a href="/format/2309.13646" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ILNet: Low-level Matters for Salient Infrared Small Target Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoqing Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jinfu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Runshi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yifei Xu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Infrared small target detection is a technique for finding small targets from
infrared clutter background. Due to the dearth of high-level semantic
information, small infrared target features are weakened in the deep layers of
the CNN, which underachieves the CNN's representation ability. To address the
above problem, in this paper, we propose an infrared low-level network (ILNet)
that considers infrared small targets as salient areas with little semantic
information. Unlike other SOTA methods, ILNet pays greater attention to
low-level information instead of treating them equally. A new lightweight
feature fusion module, named Interactive Polarized Orthogonal Fusion module
(IPOF), is proposed, which integrates more important low-level features from
the shallow layers into the deep layers. A Dynamic One-Dimensional Aggregation
layers (DODA) are inserted into the IPOF, to dynamically adjust the aggregation
of low dimensional information according to the number of input channels. In
addition, the idea of ensemble learning is used to design a Representative
Block (RB) to dynamically allocate weights for shallow and deep layers.
Experimental results on the challenging NUAA-SIRST (78.22% nIoU and 1.33e-6 Fa)
and IRSTD-1K (68.91% nIoU and 3.23e-6 Fa) dataset demonstrate that the proposed
ILNet can get better performances than other SOTA methods. Moreover, ILNet can
obtain a greater improvement with the increasement of data volume. Training
code are available at https://github.com/Li-Haoqing/ILNet.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13647" title="Abstract">arXiv:2309.13647</a> [<a href="/pdf/2309.13647" title="Download PDF">pdf</a>, <a href="/ps/2309.13647" title="Download PostScript">ps</a>, <a href="/format/2309.13647" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online Bin Covering with Exact Parameter Advice
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brodnik%2C+A">Andrej Brodnik</a>, 
<a href="/search/cs?searchtype=author&query=Nilsson%2C+B+J">Bengt J. Nilsson</a>, 
<a href="/search/cs?searchtype=author&query=Vujovic%2C+G">Gordana Vujovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 2 figure, submitted to Informatica
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We show an asymptotic 2/3-competitive strategy for the bin covering problem
using O(b+log n) bits of advice, where b is the number of bits used to encode a
rational value and n is the length of the input sequence.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13648" title="Abstract">arXiv:2309.13648</a> [<a href="/pdf/2309.13648" title="Download PDF">pdf</a>, <a href="/format/2309.13648" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Costs of Swapping on the Uniswap Protocol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adams%2C+A">Austin Adams</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+B+Y">Benjamin Y Chan</a>, 
<a href="/search/cs?searchtype=author&query=Markovich%2C+S">Sarit Markovich</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xin Wan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 31 pages, 7 tables, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">We present the first in-depth empirical characterization of the costs of
trading on a decentralized exchange (DEX). Using quoted prices from the Uniswap
Labs interface for two pools -- USDC-ETH (5bps) and PEPE-ETH (30bps) -- we
evaluate the efficiency of trading on DEXs. Our main tool is slippage -- the
difference between the realized execution price of a trade, and its quoted
price -- which we breakdown into its benign and adversarial components. We also
present an alternative way to quantify and identify slippage due to adversarial
reordering of transactions, which we call reordering slippage, that does not
require quoted prices or mempool data to calculate. We find that the
composition of transaction costs varies tremendously with the trade's
characteristics. Specifically, while for small swaps, gas costs dominate costs,
for large swaps price-impact and slippage account for the majority of it.
Moreover, when trading PEPE, a popular 'memecoin', the probability of
adversarial slippage is about 80% higher than when trading a mature asset like
USDC.
<br />Overall, our results provide preliminary evidence that DEXs offer a
compelling trust-less alternative to centralized exchanges for trading digital
assets.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13653" title="Abstract">arXiv:2309.13653</a> [<a href="/pdf/2309.13653" title="Download PDF">pdf</a>, <a href="/ps/2309.13653" title="Download PostScript">ps</a>, <a href="/format/2309.13653" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probabilistic Bounds for Data Storage with Feature Selection and  Undersampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+G">Ghurumuruhan Ganesan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">In this paper we consider data storage from a probabilistic point of view and
obtain bounds for efficient storage in the presence of feature selection and
undersampling, both of which are important from the data science perspective.
First, we consider encoding of correlated sources for nonstationary data and
obtain a Slepian-Wolf type result for the probability of error. We then
reinterpret our result by allowing one source to be the set of features to be
discarded and other source to be remaining data to be encoded. Next, we
consider neighbourhood domination in random graphs where we impose the
condition that a fraction of neighbourhood must be present for each vertex and
obtain optimal bounds on the minimum size of such a set. We show how such sets
are useful for data undersampling in the presence of imbalanced datasets and
briefly illustrate our result using~\(k-\)nearest neighbours type
classification rules as an example.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13655" title="Abstract">arXiv:2309.13655</a> [<a href="/pdf/2309.13655" title="Download PDF">pdf</a>, <a href="/format/2309.13655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptation of the super resolution SOTA for Art Restoration in camera  capture images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nagar%2C+S">Sandeep Nagar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> COMPETITIONS @ ICETCI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Preserving cultural heritage is of paramount importance. In the domain of art
restoration, developing a computer vision model capable of effectively
restoring deteriorated images of art pieces was difficult, but now we have a
good computer vision state-of-art. Traditional restoration methods are often
time-consuming and require extensive expertise. The aim of this work is to
design an automated solution based on computer vision models that can enhance
and reconstruct degraded artworks, improving their visual quality while
preserving their original characteristics and artifacts. The model should
handle a diverse range of deterioration types, including but not limited to
noise, blur, scratches, fading, and other common forms of degradation. We adapt
the current state-of-art for the image super-resolution based on the Diffusion
Model (DM) and fine-tune it for Image art restoration. Our results show that
instead of fine-tunning multiple different models for different kinds of
degradation, fine-tuning one super-resolution, We train it on multiple datasets
to make it robust. code link: https://github.com/Naagar/art_restoration_DM
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13657" title="Abstract">arXiv:2309.13657</a> [<a href="/pdf/2309.13657" title="Download PDF">pdf</a>, <a href="/ps/2309.13657" title="Download PostScript">ps</a>, <a href="/format/2309.13657" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Probabilistic Model for Data Redundancy in the Feature Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganesan%2C+G">Ghurumuruhan Ganesan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">In this paper, we use a probabilistic model to estimate the number of
uncorrelated features in a large dataset. Our model allows for both pairwise
feature correlation (collinearity) and interdependency of multiple features
(multicollinearity) and we use the probabilistic method to obtain upper and
lower bounds of the same order, for the size of a feature set that exhibits low
collinearity and low multicollinearity. We also prove an auxiliary result
regarding mutually good constrained sets that is of independent interest.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13658" title="Abstract">arXiv:2309.13658</a> [<a href="/pdf/2309.13658" title="Download PDF">pdf</a>, <a href="/ps/2309.13658" title="Download PostScript">ps</a>, <a href="/format/2309.13658" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fantastic Generalization Measures are Nowhere to be Found
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gastpar%2C+M">Michael Gastpar</a>, 
<a href="/search/cs?searchtype=author&query=Nachum%2C+I">Ido Nachum</a>, 
<a href="/search/cs?searchtype=author&query=Shafer%2C+J">Jonathan Shafer</a>, 
<a href="/search/cs?searchtype=author&query=Weinberger%2C+T">Thomas Weinberger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE); Machine Learning (stat.ML)

</div>
<p class="mathjax">Numerous generalization bounds have been proposed in the literature as
potential explanations for the ability of neural networks to generalize in the
overparameterized setting. However, none of these bounds are tight. For
instance, in their paper ``Fantastic Generalization Measures and Where to Find
Them'', Jiang et al. (2020) examine more than a dozen generalization bounds,
and show empirically that none of them imply guarantees that can explain the
remarkable performance of neural networks. This raises the question of whether
tight generalization bounds are at all possible. We consider two types of
generalization bounds common in the literature: (1) bounds that depend on the
training set and the output of the learning algorithm. There are multiple
bounds of this type in the literature (e.g., norm-based and margin-based
bounds), but we prove mathematically that no such bound can be uniformly tight
in the overparameterized setting; (2) bounds that depend on the training set
and on the learning algorithm (e.g., stability bounds). For these bounds, we
show a trade-off between the algorithm's performance and the bound's tightness.
Namely, if the algorithm achieves good accuracy on certain distributions in the
overparameterized setting, then no generalization bound can be tight for it. We
conclude that generalization bounds in the overparameterized setting cannot be
tight without suitable assumptions on the population distribution.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13662" title="Abstract">arXiv:2309.13662</a> [<a href="/pdf/2309.13662" title="Download PDF">pdf</a>, <a href="/format/2309.13662" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topology-Agnostic Detection of Temporal Money Laundering Flows in  Billion-Scale Transactions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tariq%2C+H">Haseeb Tariq</a>, 
<a href="/search/cs?searchtype=author&query=Hassani%2C+M">Marwan Hassani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Social and Information Networks (cs.SI); Statistical Finance (q-fin.ST)

</div>
<p class="mathjax">Money launderers exploit the weaknesses in detection systems by purposefully
placing their ill-gotten money into multiple accounts, at different banks. That
money is then layered and moved around among mule accounts to obscure the
origin and the flow of transactions. Consequently, the money is integrated into
the financial system without raising suspicion. Path finding algorithms that
aim at tracking suspicious flows of money usually struggle with scale and
complexity. Existing community detection techniques also fail to properly
capture the time-dependent relationships. This is particularly evident when
performing analytics over massive transaction graphs. We propose a framework
(called FaSTMAN), adapted for domain-specific constraints, to efficiently
construct a temporal graph of sequential transactions. The framework includes a
weighting method, using 2nd order graph representation, to quantify the
significance of the edges. This method enables us to distribute complex queries
on smaller and densely connected networks of flows. Finally, based on those
queries, we can effectively identify networks of suspicious flows. We
extensively evaluate the scalability and the effectiveness of our framework
against two state-of-the-art solutions for detecting suspicious flows of
transactions. For a dataset of over 1 Billion transactions from multiple large
European banks, the results show a clear superiority of our framework both in
efficiency and usefulness.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13669" title="Abstract">arXiv:2309.13669</a> [<a href="/pdf/2309.13669" title="Download PDF">pdf</a>, <a href="/format/2309.13669" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Apple Fruitlet Sizing with Next Best View Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Freeman%2C+H">Harry Freeman</a>, 
<a href="/search/cs?searchtype=author&query=Kantor%2C+G">George Kantor</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we present a next-best-view planning approach to autonomously
size apple fruitlets. State-of-the-art viewpoint planners in agriculture are
designed to size large and more sparsely populated fruit. They rely on lower
resolution maps and sizing methods that do not generalize to smaller fruit
sizes. To overcome these limitations, our method combines viewpoint sampling
around semantically labeled regions of interest, along with an attention-guided
information gain mechanism to more strategically select viewpoints that target
the small fruits' volume. Additionally, we integrate a dual-map representation
of the environment that is able to both speed up expensive ray casting
operations and maintain the high occupancy resolution required to informatively
plan around the fruit. When sizing, a robust estimation and graph clustering
approach is introduced to associate fruit detections across images. Through
simulated experiments, we demonstrate that our viewpoint planner improves
sizing accuracy compared to state of the art and ablations. We also provide
quantitative results on data collected by a real robotic system in the field.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13671" title="Abstract">arXiv:2309.13671</a> [<a href="/pdf/2309.13671" title="Download PDF">pdf</a>, <a href="/format/2309.13671" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OneSeg: Self-learning and One-shot Learning based Single-slice  Annotation for 3D Medical Image Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yixuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jintai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+D+Z">Danny Z. Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jian Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">As deep learning methods continue to improve medical image segmentation
performance, data annotation is still a big bottleneck due to the
labor-intensive and time-consuming burden on medical experts, especially for 3D
images. To significantly reduce annotation efforts while attaining competitive
segmentation accuracy, we propose a self-learning and one-shot learning based
framework for 3D medical image segmentation by annotating only one slice of
each 3D image. Our approach takes two steps: (1) self-learning of a
reconstruction network to learn semantic correspondence among 2D slices within
3D images, and (2) representative selection of single slices for one-shot
manual annotation and propagating the annotated data with the well-trained
reconstruction network. Extensive experiments verify that our new framework
achieves comparable performance with less than 1% annotated data compared with
fully supervised methods and generalizes well on several out-of-distribution
testing sets.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13672" title="Abstract">arXiv:2309.13672</a> [<a href="/pdf/2309.13672" title="Download PDF">pdf</a>, <a href="/format/2309.13672" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Image-to-Image Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Ziwei Luo</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jing Hu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chengming Feng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+S">Shu Hu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B">Bin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+S">Siwei Lyu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most existing Image-to-Image Translation (I2IT) methods generate images in a
single run of a deep learning (DL) model. However, designing such a single-step
model is always challenging, requiring a huge number of parameters and easily
falling into bad global minimums and overfitting. In this work, we reformulate
I2IT as a step-wise decision-making problem via deep reinforcement learning
(DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The
key feature in the RL-I2IT framework is to decompose a monolithic learning
process into small steps with a lightweight model to progressively transform a
source image successively to a target image. Considering that it is challenging
to handle high dimensional continuous state and action spaces in the
conventional RL framework, we introduce meta policy with a new concept Plan to
the standard Actor-Critic model, which is of a lower dimension than the
original image and can facilitate the actor to generate a tractable high
dimensional action. In the RL-I2IT framework, we also employ a task-specific
auxiliary learning strategy to stabilize the training process and improve the
performance of the corresponding task. Experiments on several I2IT tasks
demonstrate the effectiveness and robustness of the proposed method when facing
high-dimensional continuous action space problems.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13676" title="Abstract">arXiv:2309.13676</a> [<a href="/pdf/2309.13676" title="Download PDF">pdf</a>, <a href="/format/2309.13676" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BdSpell: A YOLO-based Real-time Finger Spelling System for Bangla Sign  Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haque%2C+N">Naimul Haque</a>, 
<a href="/search/cs?searchtype=author&query=Serker%2C+M">Meraj Serker</a>, 
<a href="/search/cs?searchtype=author&query=Bashar%2C+T+B">Tariq Bin Bashar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the domain of Bangla Sign Language (BdSL) interpretation, prior approaches
often imposed a burden on users, requiring them to spell words without hidden
characters, which were subsequently corrected using Bangla grammar rules due to
the missing classes in BdSL36 dataset. However, this method posed a challenge
in accurately guessing the incorrect spelling of words. To address this
limitation, we propose a novel real-time finger spelling system based on the
YOLOv5 architecture. Our system employs specified rules and numerical classes
as triggers to efficiently generate hidden and compound characters, eliminating
the necessity for additional classes and significantly enhancing user
convenience. Notably, our approach achieves character spelling in an impressive
1.32 seconds with a remarkable accuracy rate of 98\%. Furthermore, our YOLOv5
model, trained on 9147 images, demonstrates an exceptional mean Average
Precision (mAP) of 96.4\%. These advancements represent a substantial
progression in augmenting BdSL interpretation, promising increased inclusivity
and accessibility for the linguistic minority. This innovative framework,
characterized by compatibility with existing YOLO versions, stands as a
transformative milestone in enhancing communication modalities and linguistic
equity within the Bangla Sign Language community.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13679" title="Abstract">arXiv:2309.13679</a> [<a href="/pdf/2309.13679" title="Download PDF">pdf</a>, <a href="/format/2309.13679" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network-PSO-based Velocity Control Algorithm for Landing UAVs on  a Boat
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+L">Li-Fan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Rastgaar%2C+M">Mo Rastgaar</a>, 
<a href="/search/cs?searchtype=author&query=Mahmoudian%2C+N">Nina Mahmoudian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Precise landing of Unmanned Aerial Vehicles (UAVs) onto moving platforms like
Autonomous Surface Vehicles (ASVs) is both important and challenging,
especially in GPS-denied environments, for collaborative navigation of
heterogeneous vehicles. UAVs need to land within a confined space onboard ASV
to get energy replenishment, while ASV is subject to translational and
rotational disturbances due to wind and water flow. Current solutions either
rely on high-level waypoint navigation, which struggles to robustly land on
varied-speed targets, or necessitate laborious manual tuning of controller
parameters, and expensive sensors for target localization. Therefore, we
propose an adaptive velocity control algorithm that leverages Particle Swarm
Optimization (PSO) and Neural Network (NN) to optimize PID parameters across
varying flight altitudes and distinct speeds of a moving boat. The cost
function of PSO includes the status change rates of UAV and proximity to the
target. The NN further interpolates the PSO-founded PID parameters. The
proposed method implemented on a water strider hexacopter design, not only
ensures accuracy but also increases robustness. Moreover, this NN-PSO can be
readily adapted to suit various mission requirements. Its ability to achieve
precise landings extends its applicability to scenarios, including but not
limited to rescue missions, package deliveries, and workspace inspections.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13681" title="Abstract">arXiv:2309.13681</a> [<a href="/pdf/2309.13681" title="Download PDF">pdf</a>, <a href="/format/2309.13681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Large Batch Training via Gradient Signal to Noise Ratio  (GSNR)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+G">Guo-qing Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jinlong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zixiang Ding</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+L">Lin Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wei Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">As models for nature language processing (NLP), computer vision (CV) and
recommendation systems (RS) require surging computation, a large number of
GPUs/TPUs are paralleled as a large batch (LB) to improve training throughput.
However, training such LB tasks often meets large generalization gap and
downgrades final precision, which limits enlarging the batch size. In this
work, we develop the variance reduced gradient descent technique (VRGD) based
on the gradient signal to noise ratio (GSNR) and apply it onto popular
optimizers such as SGD/Adam/LARS/LAMB. We carry out a theoretical analysis of
convergence rate to explain its fast training dynamics, and a generalization
analysis to demonstrate its smaller generalization gap on LB training.
Comprehensive experiments demonstrate that VRGD can accelerate training ($1\sim
2 \times$), narrow generalization gap and improve final accuracy. We push the
batch size limit of BERT pretraining up to 128k/64k and DLRM to 512k without
noticeable accuracy loss. We improve ImageNet Top-1 accuracy at 96k by $0.52pp$
than LARS. The generalization gap of BERT and ImageNet training is
significantly reduce by over $65\%$.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13682" title="Abstract">arXiv:2309.13682</a> [<a href="/pdf/2309.13682" title="Download PDF">pdf</a>, <a href="/format/2309.13682" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Causal-DFQ: Causality Guided Data-free Network Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shang%2C+Y">Yuzhang Shang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bingxin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Gaowen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kompella%2C+R">Ramana Kompella</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Y">Yan Yan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Model quantization, which aims to compress deep neural networks and
accelerate inference speed, has greatly facilitated the development of
cumbersome models on mobile and edge devices. There is a common assumption in
quantization methods from prior works that training data is available. In
practice, however, this assumption cannot always be fulfilled due to reasons of
privacy and security, rendering these methods inapplicable in real-life
situations. Thus, data-free network quantization has recently received
significant attention in neural network compression. Causal reasoning provides
an intuitive way to model causal relationships to eliminate data-driven
correlations, making causality an essential component of analyzing data-free
problems. However, causal formulations of data-free quantization are inadequate
in the literature. To bridge this gap, we construct a causal graph to model the
data generation and discrepancy reduction between the pre-trained and quantized
models. Inspired by the causal understanding, we propose the Causality-guided
Data-free Network Quantization method, Causal-DFQ, to eliminate the reliance on
data via approaching an equilibrium of causality-driven intervened
distributions. Specifically, we design a content-style-decoupled generator,
synthesizing images conditioned on the relevant and irrelevant factors; then we
propose a discrepancy reduction loss to align the intervened distributions of
the pre-trained and quantized models. It is worth noting that our work is the
first attempt towards introducing causality to data-free quantization problem.
Extensive experiments demonstrate the efficacy of Causal-DFQ. The code is
available at https://github.com/42Shawn/Causal-DFQ.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13684" title="Abstract">arXiv:2309.13684</a> [<a href="/pdf/2309.13684" title="Download PDF">pdf</a>, <a href="/format/2309.13684" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Always Nice and Confident, Sometimes wrong&quot;: Developer&#x27;s Experiences  Engaging Generative AI Chatbots Versus Human-Powered Q&amp;A Platforms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Mynatt%2C+E">Elizabeth Mynatt</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+V">Varun Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+J">Jonathan Bell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Software engineers have historically relied on human-powered Q&amp;A platforms,
like Stack Overflow (SO), as coding aids. With the rise of generative AI,
developers have adopted AI chatbots, such as ChatGPT, in their software
development process. Recognizing the potential parallels between human-powered
Q&amp;A platforms and AI-powered question-based chatbots, we investigate and
compare how developers integrate this assistance into their real-world coding
experiences by conducting thematic analysis of Reddit posts. Through a
comparative study of SO and ChatGPT, we identified each platform's strengths,
use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear,
comprehensive responses and fosters a more respectful environment than SO.
However, concerns about ChatGPT's reliability stem from its overly confident
tone and the absence of validation mechanisms like SO's voting system. Based on
these findings, we recommend leveraging each platform's unique features to
improve developer experiences in the future.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13685" title="Abstract">arXiv:2309.13685</a> [<a href="/pdf/2309.13685" title="Download PDF">pdf</a>, <a href="/format/2309.13685" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Searchable Encryption for Cloud Data Based on Full-Blind Quantum  Computation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinsong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haibin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+Z">Zhibin Lei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 2019. 7: p. 186284-186295
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Cryptography and Security (cs.CR); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Searchable encryption (SE) is a positive way to protect users sensitive data
in cloud computing setting, while preserving search ability on the server side,
i.e., it allows the server to search encrypted data without leaking information
about the plaintext data. In this paper, a multi-client universal circuit-based
full-blind quantum computation (FBQC) model is proposed. In order to meet the
requirements of multi-client accessing or computing encrypted cloud data, all
clients with limited quantum ability outsource the key generation to a trusted
key center and upload their encrypted data to the data center. Considering the
feasibility of physical implementation, all quantum gates in the circuit are
replaced with the combination of {\pi}/8 rotation operator set {Rz({\pi}/4),
Ry({\pi}/4), CRz({\pi}/4), CRy({\pi}/4), CCRz({\pi}/4), CCRy({\pi}/4)}. In
addition, the data center is only allowed to perform one {\pi}/8 rotation
operator each time, but does not know the structure of the circuit (i.e.,
quantum computation), so it can guarantee the blindness of computation. Then,
through combining this multi-client FBQC model and Grover searching algorithm,
we continue to propose a quantum searchable encryption scheme for cloud data.
It solves the problem of multi-client access mode under searchable encryption
in the cloud environment, and has the ability to resist against some quantum
attacks. To better demonstrate our scheme, an example of our scheme to search
on encrypted 2-qubit state is given in detail. Furthermore, the security of our
scheme is analysed from two aspects: external attacks and internal attacks, and
the result indicates that it can resist against such kinds of attacks and also
guarantee the blindness of data and computation.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13690" title="Abstract">arXiv:2309.13690</a> [<a href="/pdf/2309.13690" title="Download PDF">pdf</a>, <a href="/format/2309.13690" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable data concentrator with baseline interconnection network for  triggerless data acquisition systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zabo%C5%82otny%2C+W+M">Wojciech M. Zabo&#x142;otny</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Triggerless Data Acquisition Systems (DAQs) require transmitting the data
stream from multiple links to the processing node. The short input data words
must be concentrated and packed into the longer bit vectors the output
interface (e.g. PCI Express) uses. In that process, the unneeded data must be
eliminated, and a dense stream of useful DAQ data must be created.
Additionally, the time order of the data should be preserved. This paper
presents a new solution using the Baseline Network with Reversed Outputs
(BNRO)for high-speed data routing.A thorough analysis of the network operation
enabled increased scalability compared to the previously published concentrator
based on 8x8 network. The presented solution may be scaled by adding additional
layers to the BNRO network while minimizing resource consumption. Simulations
were done for 4 and 5 layers (16 and 32 inputs). The FPGA synthesis has been
performed for 16inputs. The pipeline registers may be added in each network
independently, shortening the critical path and increasing the maximum
acceptable clock frequency.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13692" title="Abstract">arXiv:2309.13692</a> [<a href="/pdf/2309.13692" title="Download PDF">pdf</a>, <a href="/ps/2309.13692" title="Download PostScript">ps</a>, <a href="/format/2309.13692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Regularization and Optimal Multiclass Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Asilis%2C+J">Julian Asilis</a>, 
<a href="/search/cs?searchtype=author&query=Devic%2C+S">Siddartha Devic</a>, 
<a href="/search/cs?searchtype=author&query=Dughmi%2C+S">Shaddin Dughmi</a>, 
<a href="/search/cs?searchtype=author&query=Sharan%2C+V">Vatsal Sharan</a>, 
<a href="/search/cs?searchtype=author&query=Teng%2C+S">Shang-Hua Teng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 40 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The quintessential learning algorithm of empirical risk minimization (ERM) is
known to fail in various settings for which uniform convergence does not
characterize learning. It is therefore unsurprising that the practice of
machine learning is rife with considerably richer algorithmic techniques for
successfully controlling model capacity. Nevertheless, no such technique or
principle has broken away from the pack to characterize optimal learning in
these more general settings.
<br />The purpose of this work is to characterize the role of regularization in
perhaps the simplest setting for which ERM fails: multiclass learning with
arbitrary label sets. Using one-inclusion graphs (OIGs), we exhibit optimal
learning algorithms that dovetail with tried-and-true algorithmic principles:
Occam's Razor as embodied by structural risk minimization (SRM), the principle
of maximum entropy, and Bayesian reasoning. Most notably, we introduce an
optimal learner which relaxes structural risk minimization on two dimensions:
it allows the regularization function to be "local" to datapoints, and uses an
unsupervised learning stage to learn this regularizer at the outset. We justify
these relaxations by showing that they are necessary: removing either dimension
fails to yield a near-optimal learner. We also extract from OIGs a
combinatorial sequence we term the Hall complexity, which is the first to
characterize a problem's transductive error rate exactly.
<br />Lastly, we introduce a generalization of OIGs and the transductive learning
setting to the agnostic case, where we show that optimal orientations of
Hamming graphs -- judged using nodes' outdegrees minus a system of
node-dependent credits -- characterize optimal learners exactly. We demonstrate
that an agnostic version of the Hall complexity again characterizes error rates
exactly, and exhibit an optimal learner using maximum entropy programs.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13697" title="Abstract">arXiv:2309.13697</a> [<a href="/pdf/2309.13697" title="Download PDF">pdf</a>, <a href="/format/2309.13697" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Deep Multi-View Clustering with Global Self-Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyue Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jie Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yazhou Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+X">Xiaorong Pu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Ce Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Z">Zhifeng Hao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Federated multi-view clustering has the potential to learn a global
clustering model from data distributed across multiple devices. In this
setting, label information is unknown and data privacy must be preserved,
leading to two major challenges. First, views on different clients often have
feature heterogeneity, and mining their complementary cluster information is
not trivial. Second, the storage and usage of data from multiple clients in a
distributed environment can lead to incompleteness of multi-view data. To
address these challenges, we propose a novel federated deep multi-view
clustering method that can mine complementary cluster structures from multiple
clients, while dealing with data incompleteness and privacy concerns.
Specifically, in the server environment, we propose sample alignment and data
extension techniques to explore the complementary cluster structures of
multiple views. The server then distributes global prototypes and global
pseudo-labels to each client as global self-supervised information. In the
client environment, multiple clients use the global self-supervised information
and deep autoencoders to learn view-specific cluster assignments and embedded
features, which are then uploaded to the server for refining the global
self-supervised information. Finally, the results of our extensive experiments
demonstrate that our proposed method exhibits superior performance in
addressing the challenges of incomplete multi-view data in distributed
environments.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13698" title="Abstract">arXiv:2309.13698</a> [<a href="/pdf/2309.13698" title="Download PDF">pdf</a>, <a href="/ps/2309.13698" title="Download PostScript">ps</a>, <a href="/format/2309.13698" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Counting Vanishing Matrix-Vector Products
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brand%2C+C">Cornelius Brand</a>, 
<a href="/search/cs?searchtype=author&query=Korchemna%2C+V">Viktoriia Korchemna</a>, 
<a href="/search/cs?searchtype=author&query=Skotnica%2C+M">Michael Skotnica</a>, 
<a href="/search/cs?searchtype=author&query=Simonov%2C+K">Kirill Simonov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 4 figures; it contains result from <a href="/abs/2209.09788">arXiv:2209.09788</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Complexity (cs.CC)</span>

</div>
<p class="mathjax">Consider the following parameterized counting variation of the classic subset
sum problem, which arises notably in the context of higher homotopy groups of
topological spaces: Let $\mathbf{v} \in \mathbb{Q}^d$ be a rational vector,
$(T_{1}, T_{2} \ldots T_{m})$ a list of $d \times d$ rational matrices, $S \in
\mathbb{Q}^{h \times d}$ a rational matrix not necessarily square and $k$ a
parameter. The goal is to compute the number of ways one can choose $k$
matrices $T_{i_1}, T_{i_2}, \ldots, T_{i_k}$ from the list such that $ST_{i_k}
\cdots T_{i_1}\mathbf{v} = \mathbf{0} \in \mathbb{Q}^h$.
<br />In this paper, we show that this problem is $\# W[2]$-hard for parameter $k$.
%This strengthens a result of Matou\v{s}ek, who showed $\# W[1]$-hardness of
that problem. As a consequence, computing the $k$-th homotopy group of a
$d$-dimensional topological space for $d &gt; 3$ is $\# W[2]$-hard for parameter
$k$. We also discuss a decision version of the problem and its several
modifications for which we show $W[1]/W[2]$-hardness. This is in contrast to
the parameterized $k$-sum problem, which is only $W[1]$-hard
(Abboud-Lewi-Williams, ESA'14). In addition, we show that the decision version
of the problem without parameter is an undecidable problem, and we give a
fixed-parameter tractable algorithm for matrices of bounded size over finite
fields, parameterized the matrix dimensions and the order of the field.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13700" title="Abstract">arXiv:2309.13700</a> [<a href="/pdf/2309.13700" title="Download PDF">pdf</a>, <a href="/format/2309.13700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Video Adverse-Weather-Component Suppression Network via Weather  Messenger and Adversarial Backpropagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yijun Yang</a>, 
<a href="/search/cs?searchtype=author&query=Aviles-Rivero%2C+A+I">Angelica I. Aviles-Rivero</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Huazhu Fu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiming Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lei Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Although convolutional neural networks (CNNs) have been proposed to remove
adverse weather conditions in single images using a single set of pre-trained
weights, they fail to restore weather videos due to the absence of temporal
information. Furthermore, existing methods for removing adverse weather
conditions (e.g., rain, fog, and snow) from videos can only handle one type of
adverse weather. In this work, we propose the first framework for restoring
videos from all adverse weather conditions by developing a video
adverse-weather-component suppression network (ViWS-Net). To achieve this, we
first devise a weather-agnostic video transformer encoder with multiple
transformer stages. Moreover, we design a long short-term temporal modeling
mechanism for weather messenger to early fuse input adjacent video frames and
learn weather-specific information. We further introduce a weather
discriminator with gradient reversion, to maintain the weather-invariant common
information and suppress the weather-specific information in pixel features, by
adversarially predicting weather types. Finally, we develop a messenger-driven
video transformer decoder to retrieve the residual weather-specific feature,
which is spatiotemporally aggregated with hierarchical pixel features and
refined to predict the clean target frame of input videos. Experimental
results, on benchmark datasets and real-world weather videos, demonstrate that
our ViWS-Net outperforms current state-of-the-art methods in terms of restoring
videos degraded by any weather condition.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13701" title="Abstract">arXiv:2309.13701</a> [<a href="/pdf/2309.13701" title="Download PDF">pdf</a>, <a href="/format/2309.13701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ALLURE: A Systematic Protocol for Auditing and Improving LLM-based  Evaluation of Text using Iterative In-Context-Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hasanbeig%2C+H">Hosein Hasanbeig</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+H">Hiteshi Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Betthauser%2C+L">Leo Betthauser</a>, 
<a href="/search/cs?searchtype=author&query=Frujeri%2C+F+V">Felipe Vieira Frujeri</a>, 
<a href="/search/cs?searchtype=author&query=Momennejad%2C+I">Ida Momennejad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">From grading papers to summarizing medical documents, large language models
(LLMs) are evermore used for evaluation of text generated by humans and AI
alike. However, despite their extensive utility, LLMs exhibit distinct failure
modes, necessitating a thorough audit and improvement of their text evaluation
capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large
Language Models Understanding and Reasoning Errors. ALLURE involves comparing
LLM-generated evaluations with annotated data, and iteratively incorporating
instances of significant deviation into the evaluator, which leverages
in-context learning (ICL) to enhance and improve robust evaluation of text by
LLMs. Through this iterative process, we aim to refine the performance of the
evaluator LLM, ultimately reducing the reliance on human annotators in the
evaluation process. We anticipate ALLURE to serve diverse applications of LLMs
in various domains related to evaluation of textual data and productivity in
these fields.
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13702" title="Abstract">arXiv:2309.13702</a> [<a href="/pdf/2309.13702" title="Download PDF">pdf</a>, <a href="/ps/2309.13702" title="Download PostScript">ps</a>, <a href="/format/2309.13702" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skill Check: Some Considerations on the Evaluation of Gamemastering  Models for Role-playing Games
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=G%C3%B3ngora%2C+S">Santiago G&#xf3;ngora</a>, 
<a href="/search/cs?searchtype=author&query=Chiruzzo%2C+L">Luis Chiruzzo</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9ndez%2C+G">Gonzalo M&#xe9;ndez</a>, 
<a href="/search/cs?searchtype=author&query=Gerv%C3%A1s%2C+P">Pablo Gerv&#xe1;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages. Accepted at GALA 2023 (Games and Learning Alliance 12th International Conference)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In role-playing games a Game Master (GM) is the player in charge of the game,
who must design the challenges the players face and narrate the outcomes of
their actions. In this work we discuss some challenges to model GMs from an
Interactive Storytelling and Natural Language Processing perspective. Following
those challenges we propose three test categories to evaluate such dialogue
systems, and we use them to test ChatGPT, Bard and OpenAssistant as
out-of-the-box GMs.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13704" title="Abstract">arXiv:2309.13704</a> [<a href="/pdf/2309.13704" title="Download PDF">pdf</a>, <a href="/format/2309.13704" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sound-Print: Generalised Face Presentation Attack Detection using Deep  Representation of Sound Echoes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramachandra%2C+R">Raghavendra Ramachandra</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J+M">Jag Mohan Singh</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+S">Sushma Venkatesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IJCB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial biometrics are widely deployed in smartphone-based applications
because of their usability and increased verification accuracy in unconstrained
scenarios. The evolving applications of smartphone-based facial recognition
have also increased Presentation Attacks (PAs), where an attacker can present a
Presentation Attack Instrument (PAI) to maliciously gain access to the
application. Because the materials used to generate PAI are not deterministic,
the detection of unknown presentation attacks is challenging. In this paper, we
present an acoustic echo-based face Presentation Attack Detection (PAD) on a
smartphone in which the PAs are detected based on the reflection profiles of
the transmitted signal. We propose a novel transmission signal based on the
wide pulse that allows us to model the background noise before transmitting the
signal and increase the Signal-to-Noise Ratio (SNR). The received signal
reflections were processed to remove background noise and accurately represent
reflection characteristics. The reflection profiles of the bona fide and PAs
are different owing to the different reflection characteristics of the human
skin and artefact materials. Extensive experiments are presented using the
newly collected Acoustic Sound Echo Dataset (ASED) with 4807 samples captured
from bona fide and four different types of PAIs, including print (two types),
display, and silicone face-mask attacks. The obtained results indicate the
robustness of the proposed method for detecting unknown face presentation
attacks.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13705" title="Abstract">arXiv:2309.13705</a> [<a href="/pdf/2309.13705" title="Download PDF">pdf</a>, <a href="/format/2309.13705" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Neural-Guided Dynamic Symbolic Network for Exploring Mathematical  Expressions from Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenqiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weijun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Lina Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanjie Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Symbolic regression (SR) is a powerful technique for discovering the
underlying mathematical expressions from observed data. Inspired by the success
of deep learning, recent efforts have focused on two categories for SR methods.
One is using a neural network or genetic programming to search the expression
tree directly. Although this has shown promising results, the large search
space poses difficulties in learning constant factors and processing
high-dimensional problems. Another approach is leveraging a transformer-based
model training on synthetic data and offers advantages in inference speed.
However, this method is limited to fixed small numbers of dimensions and may
encounter inference problems when given data is out-of-distribution compared to
the synthetic data. In this work, we propose DySymNet, a novel neural-guided
Dynamic Symbolic Network for SR. Instead of searching for expressions within a
large search space, we explore DySymNet with various structures and optimize
them to identify expressions that better-fitting the data. With a topology
structure like neural networks, DySymNet not only tackles the challenge of
high-dimensional problems but also proves effective in optimizing constants.
Based on extensive numerical experiments using low-dimensional public standard
benchmarks and the well-known SRBench with more variables, our method achieves
state-of-the-art performance in terms of fitting accuracy and robustness to
noise.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13707" title="Abstract">arXiv:2309.13707</a> [<a href="/pdf/2309.13707" title="Download PDF">pdf</a>, <a href="/format/2309.13707" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ORLA*: Mobile Manipulator-Based Object Rearrangement with Lazy A*
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+K">Kai Gao</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+J">Jingjin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Effectively performing object rearrangement is an essential skill for mobile
manipulators, e.g., setting up a dinner table or organizing a desk. A key
challenge in such problems is deciding an appropriate manipulation order for
objects to effectively untangle dependencies between objects while considering
the necessary motions for realizing the manipulations (e.g., pick and place).
To our knowledge, computing time-optimal multi-object rearrangement solutions
for mobile manipulators remains a largely untapped research direction. In this
research, we propose ORLA*, which leverages delayed (lazy) evaluation in
searching for a high-quality object pick and place sequence that considers both
end-effector and mobile robot base travel. ORLA* also supports multi-layered
rearrangement tasks considering pile stability using machine learning.
Employing an optimal solver for finding temporary locations for displacing
objects, ORLA* can achieve global optimality. Through extensive simulation and
ablation study, we confirm the effectiveness of ORLA* delivering quality
solutions for challenging rearrangement instances. Supplementary materials are
available at: https://gaokai15.github.io/ORLA-Star/
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13716" title="Abstract">arXiv:2309.13716</a> [<a href="/pdf/2309.13716" title="Download PDF">pdf</a>, <a href="/format/2309.13716" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOSAIC: Multi-Object Segmented Arbitrary Stylization Using CLIP
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ganugula%2C+P">Prajwal Ganugula</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+Y+S+S+S+S">Y S S S Santosh Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Reddy%2C+N+K+S">N K Sagar Reddy</a>, 
<a href="/search/cs?searchtype=author&query=Chellingi%2C+P">Prabhath Chellingi</a>, 
<a href="/search/cs?searchtype=author&query=Thakur%2C+A">Avinash Thakur</a>, 
<a href="/search/cs?searchtype=author&query=Kasera%2C+N">Neeraj Kasera</a>, 
<a href="/search/cs?searchtype=author&query=Anand%2C+C+S">C Shyam Anand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Camera ready, New Ideas in Vision Transformers workshop, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Style transfer driven by text prompts paved a new path for creatively
stylizing the images without collecting an actual style image. Despite having
promising results, with text-driven stylization, the user has no control over
the stylization. If a user wants to create an artistic image, the user requires
fine control over the stylization of various entities individually in the
content image, which is not addressed by the current state-of-the-art
approaches. On the other hand, diffusion style transfer methods also suffer
from the same issue because the regional stylization control over the stylized
output is ineffective. To address this problem, We propose a new method
Multi-Object Segmented Arbitrary Stylization Using CLIP (MOSAIC), that can
apply styles to different objects in the image based on the context extracted
from the input prompt. Text-based segmentation and stylization modules which
are based on vision transformer architecture, were used to segment and stylize
the objects. Our method can extend to any arbitrary objects, styles and produce
high-quality images compared to the current state of art methods. To our
knowledge, this is the first attempt to perform text-guided arbitrary
object-wise stylization. We demonstrate the effectiveness of our approach
through qualitative and quantitative analysis, showing that it can generate
visually appealing stylized images with enhanced control over stylization and
the ability to generalize to unseen object classes.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13718" title="Abstract">arXiv:2309.13718</a> [<a href="/pdf/2309.13718" title="Download PDF">pdf</a>, <a href="/format/2309.13718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Relations Classification using Imbalanced Predictions  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alqaaidi%2C+S+K">Sakher Khalil Alqaaidi</a>, 
<a href="/search/cs?searchtype=author&query=Bozorgi%2C+E">Elika Bozorgi</a>, 
<a href="/search/cs?searchtype=author&query=Kochut%2C+K+J">Krzysztof J. Kochut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> `
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The relation classification task assigns the proper semantic relation to a
pair of subject and object entities; the task plays a crucial role in various
text mining applications, such as knowledge graph construction and entities
interaction discovery in biomedical text. Current relation classification
models employ additional procedures to identify multiple relations in a single
sentence. Furthermore, they overlook the imbalanced predictions pattern. The
pattern arises from the presence of a few valid relations that need positive
labeling in a relatively large predefined relations set. We propose a multiple
relations classification model that tackles these issues through a customized
output architecture and by exploiting additional input features. Our findings
suggest that handling the imbalanced predictions leads to significant
improvements, even on a modest training design. The results demonstrate
superiority performance on benchmark datasets commonly used in relation
classification. To the best of our knowledge, this work is the first that
recognizes the imbalanced predictions within the relation classification task.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13720" title="Abstract">arXiv:2309.13720</a> [<a href="/pdf/2309.13720" title="Download PDF">pdf</a>, <a href="/format/2309.13720" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Evaluation of Motion Planners for Quadrotors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y+S">Yifei Simon Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Jarin-Lipschitz%2C+L">Laura Jarin-Lipschitz</a>, 
<a href="/search/cs?searchtype=author&query=Chaudhari%2C+P">Pratik Chaudhari</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The field of quadrotor motion planning has experienced significant
advancements over the last decade. Most successful approaches rely on two
stages: a front-end that determines the best path by incorporating geometric
(and in some cases kinematic or input) constraints, that effectively specify
the homotopy class of the trajectory; and a back-end that optimizes the path
with a suitable objective function, constrained by the robot's dynamics as well
as state/input constraints. However, there is no systematic approach or design
guidelines to design both the front and the back ends for a wide range of
environments, and no literature evaluates the performance of the trajectory
planning algorithm with varying degrees of environment complexity. In this
paper, we propose a modular approach to designing the software planning stack
and offer a parameterized set of environments to systematically evaluate the
performance of two-stage planners. Our parametrized environments enable us to
access different front and back-end planners as a function of environmental
clutter and complexity. We use simulation and experimental results to
demonstrate the performance of selected planning algorithms across a range of
environments. Finally, we open source the planning/evaluation stack and
parameterized environments to facilitate more in-depth studies of quadrotor
motion planning, available at https://github.com/KumarRobotics/kr_mp_design
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13722" title="Abstract">arXiv:2309.13722</a> [<a href="/pdf/2309.13722" title="Download PDF">pdf</a>, <a href="/ps/2309.13722" title="Download PostScript">ps</a>, <a href="/format/2309.13722" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep neural networks with ReLU, leaky ReLU, and softplus activation  provably overcome the curse of dimensionality for Kolmogorov partial  differential equations with Lipschitz nonlinearities in the $L^p$-sense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ackermann%2C+J">Julia Ackermann</a>, 
<a href="/search/math?searchtype=author&query=Jentzen%2C+A">Arnulf Jentzen</a>, 
<a href="/search/math?searchtype=author&query=Kruse%2C+T">Thomas Kruse</a>, 
<a href="/search/math?searchtype=author&query=Kuckuck%2C+B">Benno Kuckuck</a>, 
<a href="/search/math?searchtype=author&query=Padgett%2C+J+L">Joshua Lee Padgett</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 52 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">Recently, several deep learning (DL) methods for approximating
high-dimensional partial differential equations (PDEs) have been proposed. The
interest that these methods have generated in the literature is in large part
due to simulations which appear to demonstrate that such DL methods have the
capacity to overcome the curse of dimensionality (COD) for PDEs in the sense
that the number of computational operations they require to achieve a certain
approximation accuracy $\varepsilon\in(0,\infty)$ grows at most polynomially in
the PDE dimension $d\in\mathbb N$ and the reciprocal of $\varepsilon$. While
there is thus far no mathematical result that proves that one of such methods
is indeed capable of overcoming the COD, there are now a number of rigorous
results in the literature that show that deep neural networks (DNNs) have the
expressive power to approximate PDE solutions without the COD in the sense that
the number of parameters used to describe the approximating DNN grows at most
polynomially in both the PDE dimension $d\in\mathbb N$ and the reciprocal of
the approximation accuracy $\varepsilon&gt;0$. Roughly speaking, in the literature
it is has been proved for every $T&gt;0$ that solutions $u_d\colon
[0,T]\times\mathbb R^d\to \mathbb R$, $d\in\mathbb N$, of semilinear heat PDEs
with Lipschitz continuous nonlinearities can be approximated by DNNs with ReLU
activation at the terminal time in the $L^2$-sense without the COD provided
that the initial value functions $\mathbb R^d\ni x\mapsto u_d(0,x)\in\mathbb
R$, $d\in\mathbb N$, can be approximated by ReLU DNNs without the COD. It is
the key contribution of this work to generalize this result by establishing
this statement in the $L^p$-sense with $p\in(0,\infty)$ and by allowing the
activation function to be more general covering the ReLU, the leaky ReLU, and
the softplus activation functions as special cases.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13731" title="Abstract">arXiv:2309.13731</a> [<a href="/pdf/2309.13731" title="Download PDF">pdf</a>, <a href="/format/2309.13731" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arabic Sentiment Analysis with Noisy Deep Explainable Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Atabuzzaman%2C+M">Md. Atabuzzaman</a>, 
<a href="/search/cs?searchtype=author&query=Shajalal%2C+M">Md Shajalal</a>, 
<a href="/search/cs?searchtype=author&query=Baby%2C+M+B">Maksuda Bilkis Baby</a>, 
<a href="/search/cs?searchtype=author&query=Boden%2C+A">Alexander Boden</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the pre-print version of our accepted paper at the 7th International Conference on Natural Language Processing and Information Retrieval~(ACM NLPIR'2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Sentiment Analysis (SA) is an indispensable task for many real-world
applications. Compared to limited resourced languages (i.e., Arabic, Bengali),
most of the research on SA are conducted for high resourced languages (i.e.,
English, Chinese). Moreover, the reasons behind any prediction of the Arabic
sentiment analysis methods exploiting advanced artificial intelligence
(AI)-based approaches are like black-box - quite difficult to understand. This
paper proposes an explainable sentiment classification framework for the Arabic
language by introducing a noise layer on Bi-Directional Long Short-Term Memory
(BiLSTM) and Convolutional Neural Networks (CNN)-BiLSTM models that overcome
over-fitting problem. The proposed framework can explain specific predictions
by training a local surrogate explainable model to understand why a particular
sentiment (positive or negative) is being predicted. We carried out experiments
on public benchmark Arabic SA datasets. The results concluded that adding noise
layers improves the performance in sentiment analysis for the Arabic language
by reducing overfitting and our method outperformed some known state-of-the-art
methods. In addition, the introduced explainability with noise layer could make
the model more transparent and accountable and hence help adopting AI-enabled
system in practice.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13734" title="Abstract">arXiv:2309.13734</a> [<a href="/pdf/2309.13734" title="Download PDF">pdf</a>, <a href="/format/2309.13734" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Use of Large Language Models for Stance Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cruickshank%2C+I+J">Iain J. Cruickshank</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+L+H+X">Lynnette Hui Xian Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICWSM 2024. 9 pages, plus appendix and 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Stance detection, the task of predicting an author's viewpoint towards a
subject of interest, has long been a focal point of research. Current stance
detection methods predominantly rely on manual annotation of sentences,
followed by training a supervised machine learning model. This manual
annotation process, however, imposes limitations on the model's ability to
fully comprehend the stances in the sentence and hampers its potential to
generalize across different contexts. In this study, we investigate the use of
Large Language Models (LLMs) for the task of stance classification, with an
absolute minimum use of human labels. We scrutinize four distinct types of
prompting schemes combined with LLMs, comparing their accuracies with manual
stance determination. Our study reveals that while LLMs can match or sometimes
even exceed the benchmark results in each dataset, their overall accuracy is
not definitively better than what can be produced by supervised models. This
suggests potential areas for improvement in the stance classification for LLMs.
The application of LLMs, however, opens up promising avenues for unsupervised
stance detection, thereby curtailing the need for manual collection and
annotation of stances. This not only streamlines the process but also paves the
way for expanding stance detection capabilities across languages. Through this
paper, we shed light on the stance classification abilities of LLMs, thereby
contributing valuable insights that can guide future advancements in this
domain.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13736" title="Abstract">arXiv:2309.13736</a> [<a href="/pdf/2309.13736" title="Download PDF">pdf</a>, <a href="/format/2309.13736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometry of Linear Neural Networks: Equivariance and Invariance under  Permutation Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kohn%2C+K">Kathl&#xe9;n Kohn</a>, 
<a href="/search/cs?searchtype=author&query=Sattelberger%2C+A">Anna-Laura Sattelberger</a>, 
<a href="/search/cs?searchtype=author&query=Shahverdi%2C+V">Vahid Shahverdi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 2 figures, comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Algebraic Geometry (math.AG)

</div>
<p class="mathjax">The set of functions parameterized by a linear fully-connected neural network
is a determinantal variety. We investigate the subvariety of functions that are
equivariant or invariant under the action of a permutation group. Examples of
such group actions are translations or $90^\circ$ rotations on images. For such
equivariant or invariant subvarieties, we provide an explicit description of
their dimension, their degree as well as their Euclidean distance degree, and
their singularities. We fully characterize invariance for arbitrary permutation
groups, and equivariance for cyclic groups. We draw conclusions for the
parameterization and the design of equivariant and invariant linear networks,
such as a weight sharing property, and we prove that all invariant linear
functions can be learned by linear autoencoders.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13737" title="Abstract">arXiv:2309.13737</a> [<a href="/pdf/2309.13737" title="Download PDF">pdf</a>, <a href="/format/2309.13737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Terrestrial Locomotion of PogoX: From Hardware Design to Energy Shaping  and Step-to-step Dynamics Based Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+J">Jiarong Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhiheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+X">Xiaobin Xiong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">We present a novel controller design on a robotic locomotor that combines an
aerial vehicle with a spring-loaded leg. The main motivation is to enable the
terrestrial locomotion capability on aerial vehicles so that they are carrying
heavy loads: heavy enough that flying is no longer possible, e.g., when the
thrust-to-weight ratio (TWR) is small. The robot is designed with a pogo-stick
leg and a quadrotor, and thus it is named as PogoX. We show that with a simple
and lightweight spring-loaded leg, the robot is capable of hopping with TWR
$&lt;1$. The control of hopping is realized via two components: a vertical height
control via control Lyapunov function-based energy shaping, and a step-to-step
(S2S) dynamics based horizontal velocity control that is inspired by the
hopping of the Spring-Loaded Inverted Pendulum (SLIP). The controller is
successfully realized on the physical robot, showing dynamic terrestrial
locomotion of PogoX which can hop at variable heights and different horizontal
velocities with robustness to ground height variations and external pushes.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13742" title="Abstract">arXiv:2309.13742</a> [<a href="/pdf/2309.13742" title="Download PDF">pdf</a>, <a href="/format/2309.13742" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DROP: Dynamics Responses from Human Motion Prior and Projective Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yifeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Won%2C+J">Jungdam Won</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Y">Yuting Ye</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+K">C. Karen Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SIGGRAPH Asia 2023, Video <a href="https://youtu.be/tF5WW7qNMLI">this https URL</a>, Website: <a href="https://stanford-tml.github.io/drop/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Synthesizing realistic human movements, dynamically responsive to the
environment, is a long-standing objective in character animation, with
applications in computer vision, sports, and healthcare, for motion prediction
and data augmentation. Recent kinematics-based generative motion models offer
impressive scalability in modeling extensive motion data, albeit without an
interface to reason about and interact with physics. While
simulator-in-the-loop learning approaches enable highly physically realistic
behaviors, the challenges in training often affect scalability and adoption. We
introduce DROP, a novel framework for modeling Dynamics Responses of humans
using generative mOtion prior and Projective dynamics. DROP can be viewed as a
highly stable, minimalist physics-based human simulator that interfaces with a
kinematics-based generative motion prior. Utilizing projective dynamics, DROP
allows flexible and simple integration of the learned motion prior as one of
the projective energies, seamlessly incorporating control provided by the
motion prior with Newtonian dynamics. Serving as a model-agnostic plug-in, DROP
enables us to fully leverage recent advances in generative motion models for
physics-based motion synthesis. We conduct extensive evaluations of our model
across different motion tasks and various physical perturbations, demonstrating
the scalability and diversity of responses.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13743" title="Abstract">arXiv:2309.13743</a> [<a href="/pdf/2309.13743" title="Download PDF">pdf</a>, <a href="/format/2309.13743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Adaptive MPC Using Uncertainty Compensation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tao%2C+R">Ran Tao</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+P">Pan Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Kolmanovsky%2C+I">Ilya Kolmanovsky</a>, 
<a href="/search/eess?searchtype=author&query=Hovakimyan%2C+N">Naira Hovakimyan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2208.02985">arXiv:2208.02985</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper presents an uncertainty compensation-based robust adaptive model
predictive control (MPC) framework for linear systems with both matched and
unmatched nonlinear uncertainties subject to both state and input constraints.
In particular, the proposed control framework leverages an L1 adaptive
controller (L1AC) to compensate for the matched uncertainties and to provide
guaranteed uniform bounds on the error between the actual states and control
inputs and those from a nominal i.e., uncertainty-free, system. The performance
bounds provided by the L1AC are then used to tighten the state and control
constraints of the actual system, and a model predictive controller is designed
for the nominal system with the tightened constraints. The proposed control
framework, which we denote as uncertainty compensation-based MPC (UC-MPC),
guarantees constraint satisfaction and achieves improved performance compared
with existing methods. Simulation results on a flight control example
demonstrate the benefits of the proposed framework.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13744" title="Abstract">arXiv:2309.13744</a> [<a href="/pdf/2309.13744" title="Download PDF">pdf</a>, <a href="/format/2309.13744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Systematic Literature Review of Computer Vision Applications in  Robotized Wire Harness Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salunkhe%2C+O">Omkar Salunkhe</a>, 
<a href="/search/cs?searchtype=author&query=Quadrini%2C+W">Walter Quadrini</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mkull%2C+D">Dan L&#xe4;mkull</a>, 
<a href="/search/cs?searchtype=author&query=Ore%2C+F">Fredrik Ore</a>, 
<a href="/search/cs?searchtype=author&query=Despeisse%2C+M">M&#xe9;lanie Despeisse</a>, 
<a href="/search/cs?searchtype=author&query=Fumagalli%2C+L">Luca Fumagalli</a>, 
<a href="/search/cs?searchtype=author&query=Stahre%2C+J">Johan Stahre</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">This article presents a systematic literature review on computer vision
applications that have been proposed for robotized wire harness assembly,
derives challenges from existing studies, and identifies opportunities for
future research to promote a more practical robotized assembly of wire
harnesses.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13745" title="Abstract">arXiv:2309.13745</a> [<a href="/pdf/2309.13745" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Vision Technology for Robotized Wire Harness Assembly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Salunkhe%2C+O">Omkar Salunkhe</a>, 
<a href="/search/cs?searchtype=author&query=Quadrini%2C+W">Walter Quadrini</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%A4mkull%2C+D">Dan L&#xe4;mkull</a>, 
<a href="/search/cs?searchtype=author&query=Ore%2C+F">Fredrik Ore</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>, 
<a href="/search/cs?searchtype=author&query=Stahre%2C+J">Johan Stahre</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by CIRP CMS 2023. The information of the published version will be updated later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Wire harnesses are essential hardware for electronic systems in modern
automotive vehicles. With a shift in the automotive industry towards
electrification and autonomous driving, more and more automotive electronics
are responsible for energy transmission and safety-critical functions such as
maneuvering, driver assistance, and safety system. This paradigm shift places
more demand on automotive wiring harnesses from the safety perspective and
stresses the greater importance of high-quality wire harness assembly in
vehicles. However, most of the current operations of wire harness assembly are
still performed manually by skilled workers, and some of the manual processes
are problematic from different perspectives, such as quality control and
ergonomics. There is also a persistent demand in the industry to increase
competitiveness and gain market share. Hence, assuring assembly quality while
improving ergonomics and optimizing labor costs is desired. Robotized assembly,
accomplished by robots or in human-robot collaboration, is a key enabler for
fulfilling the increasingly demanding quality and safety as it enables more
replicable, transparent, and comprehensible processes than completely manual
operations. However, robotized assembly of wire harnesses is challenging in
real environments due to the flexibility of the deformable objects, though many
preliminary automation solutions have been proposed under simplified industrial
configurations. Previous research efforts have proposed the use of computer
vision technology to facilitate robotized automation of wire harness assembly,
enabling the robots to better perceive and manipulate the flexible wire
harness. This article presents an overview on computer vision technology
proposed for robotized wire harness assembly and derives research gaps that
require further study to facilitate a more practical robotized assembly of wire
harness.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13746" title="Abstract">arXiv:2309.13746</a> [<a href="/pdf/2309.13746" title="Download PDF">pdf</a>, <a href="/format/2309.13746" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning-Based Connector Detection for Robotized Assembly of  Automotive Wire Harnesses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Johansson%2C+B">Bj&#xf6;rn Johansson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE CASE 2023 and has been presented on the conference. The information of the published version will be updated later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The shift towards electrification and autonomous driving in the automotive
industry results in more and more automotive wire harnesses being installed in
modern automobiles, which stresses the great significance of guaranteeing the
quality of automotive wire harness assembly. The mating of connectors is
essential in the final assembly of automotive wire harnesses due to the
importance of connectors on wire harness connection and signal transmission.
However, the current manual operation of mating connectors leads to severe
problems regarding assembly quality and ergonomics, where the robotized
assembly has been considered, and different vision-based solutions have been
proposed to facilitate a better perception of the robot control system on
connectors. Nonetheless, there has been a lack of deep learning-based solutions
for detecting automotive wire harness connectors in previous literature. This
paper presents a deep learning-based connector detection for robotized
automotive wire harness assembly. A dataset of twenty automotive wire harness
connectors was created to train and evaluate a two-stage and a one-stage object
detection model, respectively. The experiment results indicate the
effectiveness of deep learning-based connector detection for automotive wire
harness assembly but are limited by the design of the exteriors of connectors.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13748" title="Abstract">arXiv:2309.13748</a> [<a href="/pdf/2309.13748" title="Download PDF">pdf</a>, <a href="/format/2309.13748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Does the &quot;most sinfully decadent cake ever&quot; taste good? Answering Yes/No  Questions from Figurative Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rakshit%2C+G">Geetanjali Rakshit</a>, 
<a href="/search/cs?searchtype=author&query=Flanigan%2C+J">Jeffrey Flanigan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at RANLP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Figurative language is commonplace in natural language, and while making
communication memorable and creative, can be difficult to understand. In this
work, we investigate the robustness of Question Answering (QA) models on
figurative text. Yes/no questions, in particular, are a useful probe of
figurative language understanding capabilities of large language models. We
propose FigurativeQA, a set of 1000 yes/no questions with figurative and
non-figurative contexts, extracted from the domains of restaurant and product
reviews. We show that state-of-the-art BERT-based QA models exhibit an average
performance drop of up to 15\% points when answering questions from figurative
contexts, as compared to non-figurative ones. While models like GPT-3 and
ChatGPT are better at handling figurative texts, we show that further
performance gains can be achieved by automatically simplifying the figurative
contexts into their non-figurative (literal) counterparts. We find that the
best overall model is ChatGPT with chain-of-thought prompting to generate
non-figurative contexts. Our work provides a promising direction for building
more robust QA models with figurative language understanding capabilities.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13752" title="Abstract">arXiv:2309.13752</a> [<a href="/pdf/2309.13752" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hongyan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Y">Yao Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The current learning process of deep learning, regardless of any deep neural
network (DNN) architecture and/or learning algorithm used, is essentially a
single resolution training. We explore multiresolution learning and show that
multiresolution learning can significantly improve robustness of DNN models for
both 1D signal and 2D signal (image) prediction problems. We demonstrate this
improvement in terms of both noise and adversarial robustness as well as with
small training dataset size. Our results also suggest that it may not be
necessary to trade standard accuracy for robustness with multiresolution
learning, which is, interestingly, contrary to the observation obtained from
the traditional single resolution learning setting.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13753" title="Abstract">arXiv:2309.13753</a> [<a href="/pdf/2309.13753" title="Download PDF">pdf</a>, <a href="/format/2309.13753" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Stitching: Learning Transferable Robot Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jian%2C+P">Pingcheng Jian</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E">Easop Lee</a>, 
<a href="/search/cs?searchtype=author&query=Bell%2C+Z">Zachary Bell</a>, 
<a href="/search/cs?searchtype=author&query=Zavlanos%2C+M+M">Michael M. Zavlanos</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Boyuan Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Training robots with reinforcement learning (RL) typically involves heavy
interactions with the environment, and the acquired skills are often sensitive
to changes in task environments and robot kinematics. Transfer RL aims to
leverage previous knowledge to accelerate learning of new tasks or new body
configurations. However, existing methods struggle to generalize to novel
robot-task combinations and scale to realistic tasks due to complex
architecture design or strong regularization that limits the capacity of the
learned policy. We propose Policy Stitching, a novel framework that facilitates
robot transfer learning for novel combinations of robots and tasks. Our key
idea is to apply modular policy design and align the latent representations
between the modular interfaces. Our method allows direct stitching of the robot
and task modules trained separately to form a new policy for fast adaptation.
Our simulated and real-world experiments on various 3D manipulation tasks
demonstrate the superior zero-shot and few-shot transfer learning performances
of our method. Our project website is at:
<a href="http://generalroboticslab.com/PolicyStitching/">this http URL</a> .
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13755" title="Abstract">arXiv:2309.13755</a> [<a href="/pdf/2309.13755" title="Download PDF">pdf</a>, <a href="/format/2309.13755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Recursive Data-enabled Predictive Control: an Application to  Consistent Predictors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shi%2C+J">Jicheng Shi</a>, 
<a href="/search/eess?searchtype=author&query=Jones%2C+C+N">Colin N. Jones</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In the field of model predictive control, the Data-enabled Predictive
Controller (DeePC) offers direct predictive control, bypassing traditional
modeling. However, challenges emerge with increased computational demand due to
recursive I/O data updates. This paper introduces a novel recursive updating
mechanism for DeePC. It emphasizes the use of Singular Value Decomposition
(SVD) for efficient low-dimensional transformations of DeePC in its general
form, as well as a fast SVD update scheme. We apply the mechanism to two
data-driven predictors ensuring consistent predictions for open-loop and
closed-loop data. Our proposed methodologies' efficacy is validated through
simulation studies.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13761" title="Abstract">arXiv:2309.13761</a> [<a href="/pdf/2309.13761" title="Download PDF">pdf</a>, <a href="/format/2309.13761" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Classification: A Perspective of Deep Learning Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhongwei Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In recent years, with the rapid development of information on the Internet,
the number of complex texts and documents has increased exponentially, which
requires a deeper understanding of deep learning methods in order to accurately
classify texts using deep learning techniques, and thus deep learning methods
have become increasingly important in text classification. Text classification
is a class of tasks that automatically classifies a set of documents into
multiple predefined categories based on their content and subject matter. Thus,
the main goal of text classification is to enable users to extract information
from textual resources and process processes such as retrieval, classification,
and machine learning techniques together in order to classify different
categories. Many new techniques of deep learning have already achieved
excellent results in natural language processing. The success of these learning
algorithms relies on their ability to understand complex models and non-linear
relationships in data. However, finding the right structure, architecture, and
techniques for text classification is a challenge for researchers. This paper
introduces deep learning-based text classification algorithms, including
important steps required for text classification tasks such as feature
extraction, feature reduction, and evaluation strategies and methods. At the
end of the article, different deep learning text classification methods are
compared and summarized.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13762" title="Abstract">arXiv:2309.13762</a> [<a href="/pdf/2309.13762" title="Download PDF">pdf</a>, <a href="/format/2309.13762" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Veer: Verifying Equivalence of Workflow Versions in Iterative Data  Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsudais%2C+S">Sadeem Alsudais</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Avinash Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Data analytics using GUI-based workflows is an iterative process in which an
analyst makes many iterations of changes to refine the workflow, generating a
different version at each iteration. In many cases, the result of executing a
workflow version is equivalent to a result of a prior executed version.
Identifying such equivalence between the execution results of different
workflow versions is important for optimizing the performance of a workflow by
reusing results from a previous run. The size of the workflows and the
complexity of their operators often make existing equivalence verifiers (EVs)
not able to solve the problem. In this paper, we present "Veer," which
leverages the fact that two workflow versions can be very similar except for a
few changes. The solution divides the workflow version pair into small parts,
called windows, and verifies the equivalence within each window by using an
existing EV as a black box. We develop solutions to efficiently generate
windows and verify the equivalence within each window. Our thorough experiments
on real workflows show that Veer is able to not only verify the equivalence of
workflows that cannot be supported by existing EVs but also do the verification
efficiently.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13763" title="Abstract">arXiv:2309.13763</a> [<a href="/pdf/2309.13763" title="Download PDF">pdf</a>, <a href="/format/2309.13763" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combining Two Adversarial Attacks Against Person Re-Identification  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+O.+Andrade%2C+E">Eduardo de O. Andrade</a>, 
<a href="/search/cs?searchtype=author&query=Sampaio%2C+I+G+B">Igor Garcia Ballhausen Sampaio</a>, 
<a href="/search/cs?searchtype=author&query=Gu%C3%A9rin%2C+J">Joris Gu&#xe9;rin</a>, 
<a href="/search/cs?searchtype=author&query=Viterbo%2C+J">Jos&#xe9; Viterbo</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 18th International Joint Conference on Computer
  Vision, Imaging and Computer Graphics Theory and Applications - Volume 5
  VISAPP: VISAPP, 437-444, 2023 , Lisbon, Portugal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The field of Person Re-Identification (Re-ID) has received much attention
recently, driven by the progress of deep neural networks, especially for image
classification. The problem of Re-ID consists in identifying individuals
through images captured by surveillance cameras in different scenarios.
Governments and companies are investing a lot of time and money in Re-ID
systems for use in public safety and identifying missing persons. However,
several challenges remain for successfully implementing Re-ID, such as
occlusions and light reflections in people's images. In this work, we focus on
adversarial attacks on Re-ID systems, which can be a critical threat to the
performance of these systems. In particular, we explore the combination of
adversarial attacks against Re-ID models, trying to strengthen the decrease in
the classification results. We conduct our experiments on three datasets:
DukeMTMC-ReID, Market-1501, and CUHK03. We combine the use of two types of
adversarial attacks, P-FGSM and Deep Mis-Ranking, applied to two popular Re-ID
models: IDE (ResNet-50) and AlignedReID. The best result demonstrates a
decrease of 3.36% in the Rank-10 metric for AlignedReID applied to CUHK03. We
also try to use Dropout during the inference as a defense method.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13770" title="Abstract">arXiv:2309.13770</a> [<a href="/pdf/2309.13770" title="Download PDF">pdf</a>, <a href="/format/2309.13770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Devil in the Number: Towards Robust Multi-modality Data Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yichen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zihan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+W">Wenhao Chai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhonghan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+E">Enxin Song</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gaoang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 Workshop: TNGCV-DataComp
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">In order to appropriately filter multi-modality data sets on a web-scale, it
becomes crucial to employ suitable filtering methods to boost performance and
reduce training costs. For instance, LAION papers employs the CLIP score filter
to select data with CLIP scores surpassing a certain threshold. On the other
hand, T-MARS achieves high-quality data filtering by detecting and masking text
within images and then filtering by CLIP score. Through analyzing the dataset,
we observe a significant proportion of redundant information, such as numbers,
present in the textual content. Our experiments on a subset of the data unveil
the profound impact of these redundant elements on the CLIP scores. A logical
approach would involve reevaluating the CLIP scores after eliminating these
influences. Experimentally, our text-based CLIP filter outperforms the
top-ranked method on the ``small scale" of DataComp (a data filtering
benchmark) on ImageNet distribution shifts, achieving a 3.6% performance
improvement. The results also demonstrate that our proposed text-masked filter
outperforms the original CLIP score filter when selecting the top 40% of the
data. The impact of numbers on CLIP and their handling provide valuable
insights for improving the effectiveness of CLIP training, including language
rewrite techniques.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13772" title="Abstract">arXiv:2309.13772</a> [<a href="/pdf/2309.13772" title="Download PDF">pdf</a>, <a href="/format/2309.13772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Segmentation from a Moving Monocular Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yuxiang Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zelek%2C+J">John Zelek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IROS 2023 Workshop on Robotic Perception And Mapping: Frontier Vision and Learning Techniques
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Identifying and segmenting moving objects from a moving monocular camera is
difficult when there is unknown camera motion, different types of object
motions and complex scene structures. To tackle these challenges, we take
advantage of two popular branches of monocular motion segmentation approaches:
point trajectory based and optical flow based methods, by synergistically
fusing these two highly complementary motion cues at object level. By doing
this, we are able to model various complex object motions in different scene
structures at once, which has not been achieved by existing methods. We first
obtain object-specific point trajectories and optical flow mask for each common
object in the video, by leveraging the recent foundational models in object
recognition, segmentation and tracking. We then construct two robust affinity
matrices representing the pairwise object motion affinities throughout the
whole video using epipolar geometry and the motion information provided by
optical flow. Finally, co-regularized multi-view spectral clustering is used to
fuse the two affinity matrices and obtain the final clustering. Our method
shows state-of-the-art performance on the KT3DMoSeg dataset, which contains
complex motions and scene structures. Being able to identify moving objects
allows us to remove them for map building when using visual SLAM or SFM.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13773" title="Abstract">arXiv:2309.13773</a> [<a href="/pdf/2309.13773" title="Download PDF">pdf</a>, <a href="/format/2309.13773" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust  Parameters of Unseen Limited Precision Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Stone Yun</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Poster and extended abstract to be presented at the Workshop for Low Bit Quantized Neural Networks (LQBNN) @ ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Graph Hypernetworks (GHN) can predict the parameters of varying unseen CNN
architectures with surprisingly good accuracy at a fraction of the cost of
iterative optimization. Following these successes, preliminary research has
explored the use of GHNs to predict quantization-robust parameters for 8-bit
and 4-bit quantized CNNs. However, this early work leveraged full-precision
float32 training and only quantized for testing. We explore the impact of
quantization-aware training and/or other quantization-based training strategies
on quantized robustness and performance of GHN predicted parameters for
low-precision CNNs. We show that quantization-aware training can significantly
improve quantized accuracy for GHN predicted parameters of 4-bit quantized CNNs
and even lead to greater-than-random accuracy for 2-bit quantized CNNs. These
promising results open the door for future explorations such as investigating
the use of GHN predicted parameters as initialization for further quantized
training of individual CNNs, further exploration of "extreme bitwidth"
quantization, and mixed precision quantization schemes.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13775" title="Abstract">arXiv:2309.13775</a> [<a href="/pdf/2309.13775" title="Download PDF">pdf</a>, <a href="/format/2309.13775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rashomon Importance Distribution: Getting RID of Unstable, Single  Model-based Variable Importance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donnelly%2C+J">Jon Donnelly</a>, 
<a href="/search/cs?searchtype=author&query=Katta%2C+S">Srikar Katta</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>, 
<a href="/search/cs?searchtype=author&query=Browne%2C+E+P">Edward P. Browne</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in NeurIPS 2023 as a spotlight paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Genomics (q-bio.GN); Machine Learning (stat.ML)

</div>
<p class="mathjax">Quantifying variable importance is essential for answering high-stakes
questions in fields like genetics, public policy, and medicine. Current methods
generally calculate variable importance for a given model trained on a given
dataset. However, for a given dataset, there may be many models that explain
the target outcome equally well; without accounting for all possible
explanations, different researchers may arrive at many conflicting yet equally
valid conclusions given the same data. Additionally, even when accounting for
all possible explanations for a given dataset, these insights may not
generalize because not all good explanations are stable across reasonable data
perturbations. We propose a new variable importance framework that quantifies
the importance of a variable across the set of all good models and is stable
across the data distribution. Our framework is extremely flexible and can be
integrated with most existing model classes and global variable importance
metrics. We demonstrate through experiments that our framework recovers
variable importance rankings for complex simulation setups where other methods
fail. Further, we show that our framework accurately estimates the true
importance of a variable for the underlying data distribution. We provide
theoretical guarantees on the consistency and finite sample error rates for our
estimator. Finally, we demonstrate its utility with a real-world case study
exploring which genes are important for predicting HIV load in persons with
HIV, highlighting an important gene that has not previously been studied in
connection with HIV. Code is available here.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13781" title="Abstract">arXiv:2309.13781</a> [<a href="/pdf/2309.13781" title="Download PDF">pdf</a>, <a href="/format/2309.13781" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Machine Learning for ICU Readmission Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+S%C3%A1%2C+A">Alex de S&#xe1;</a>, 
<a href="/search/cs?searchtype=author&query=Gould%2C+D">Daniel Gould</a>, 
<a href="/search/cs?searchtype=author&query=Fedyukova%2C+A">Anna Fedyukova</a>, 
<a href="/search/cs?searchtype=author&query=Nicholas%2C+M">Mitchell Nicholas</a>, 
<a href="/search/cs?searchtype=author&query=Dockrell%2C+L">Lucy Dockrell</a>, 
<a href="/search/cs?searchtype=author&query=Fletcher%2C+C">Calvin Fletcher</a>, 
<a href="/search/cs?searchtype=author&query=Pilcher%2C+D">David Pilcher</a>, 
<a href="/search/cs?searchtype=author&query=Capurro%2C+D">Daniel Capurro</a>, 
<a href="/search/cs?searchtype=author&query=Ascher%2C+D">David Ascher</a>, 
<a href="/search/cs?searchtype=author&query=El-Khawas%2C+K">Khaled El-Khawas</a>, 
<a href="/search/cs?searchtype=author&query=Pires%2C+D">Douglas Pires</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To whom correspondence should be addressed to D.E.V.P at douglas.pires@unimelb.edu.au. Correspondence may also be addressed to A.G.C.S at alex.desa@baker.edu.au or K.E-K. at k.elkhawas@alfred.org.au. A.G.C.S, D.G., A.F. and K.E-K contributed equally to this work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The intensive care unit (ICU) comprises a complex hospital environment, where
decisions made by clinicians have a high level of risk for the patients' lives.
A comprehensive care pathway must then be followed to reduce p complications.
Uncertain, competing and unplanned aspects within this environment increase the
difficulty in uniformly implementing the care pathway. Readmission contributes
to this pathway's difficulty, occurring when patients are admitted again to the
ICU in a short timeframe, resulting in high mortality rates and high resource
utilisation. Several works have tried to predict readmission through patients'
medical information. Although they have some level of success while predicting
readmission, those works do not properly assess, characterise and understand
readmission prediction. This work proposes a standardised and explainable
machine learning pipeline to model patient readmission on a multicentric
database (i.e., the eICU cohort with 166,355 patients, 200,859 admissions and
6,021 readmissions) while validating it on monocentric (i.e., the MIMIC IV
cohort with 382,278 patients, 523,740 admissions and 5,984 readmissions) and
multicentric settings. Our machine learning pipeline achieved predictive
performance in terms of the area of the receiver operating characteristic curve
(AUC) up to 0.7 with a Random Forest classification model, yielding an overall
good calibration and consistency on validation sets. From explanations provided
by the constructed models, we could also derive a set of insightful
conclusions, primarily on variables related to vital signs and blood tests
(e.g., albumin, blood urea nitrogen and hemoglobin levels), demographics (e.g.,
age, and admission height and weight), and ICU-associated variables (e.g., unit
type). These insights provide an invaluable source of information during
clinicians' decision-making while discharging ICU patients.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13782" title="Abstract">arXiv:2309.13782</a> [<a href="/pdf/2309.13782" title="Download PDF">pdf</a>, <a href="/ps/2309.13782" title="Download PostScript">ps</a>, <a href="/format/2309.13782" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Computational Benefit of Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zhou Lu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Human perception inherently operates in a multimodal manner. Similarly, as
machines interpret the empirical world, their learning processes ought to be
multimodal. The recent, remarkable successes in empirical multimodal learning
underscore the significance of understanding this paradigm. Yet, a solid
theoretical foundation for multimodal learning has eluded the field for some
time. While a recent study by Lu (2023) has shown the superior sample
complexity of multimodal learning compared to its unimodal counterpart, another
basic question remains: does multimodal learning also offer computational
advantages over unimodal learning? This work initiates a study on the
computational benefit of multimodal learning. We demonstrate that, under
certain conditions, multimodal learning can outpace unimodal learning
exponentially in terms of computation. Specifically, we present a learning task
that is NP-hard for unimodal learning but is solvable in polynomial time by a
multimodal algorithm. Our construction is based on a novel modification to the
intersection of two half-spaces problem.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13785" title="Abstract">arXiv:2309.13785</a> [<a href="/pdf/2309.13785" title="Download PDF">pdf</a>, <a href="/format/2309.13785" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Study of Robust Adaptive Beamforming Algorithms Based on Power Method  Processing and Spatial Spectrum Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadzadeh%2C+S">S. Mohammadzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Nascimento%2C+V+H">V. H. Nascimento</a>, 
<a href="/search/cs?searchtype=author&query=de+Lamare%2C+R+C">R. C. de Lamare</a>, 
<a href="/search/cs?searchtype=author&query=Kukrer%2C+O">O. Kukrer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Robust adaptive beamforming (RAB) based on interference-plus-noise covariance
(INC) matrix reconstruction can experience performance degradation when model
mismatch errors exist, particularly when the input signal-to-noise ratio (SNR)
is large. In this work, we devise an efficient RAB technique for dealing with
covariance matrix reconstruction issues. The proposed method involves INC
matrix reconstruction using an idea in which the power and the steering vector
of the interferences are estimated based on the power method. Furthermore,
spatial match processing is computed to reconstruct the desired
signal-plus-noise covariance matrix. Then, the noise components are excluded to
retain the desired signal (DS) covariance matrix. A key feature of the proposed
technique is to avoid eigenvalue decomposition of the INC matrix to obtain the
dominant power of the interference-plus-noise region. Moreover, the INC
reconstruction is carried out according to the definition of the theoretical
INC matrix. Simulation results are shown and discussed to verify the
effectiveness of the proposed method against existing approaches.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13786" title="Abstract">arXiv:2309.13786</a> [<a href="/pdf/2309.13786" title="Download PDF">pdf</a>, <a href="/format/2309.13786" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distribution-Free Statistical Dispersion Control for Societal  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhun Deng</a>, 
<a href="/search/cs?searchtype=author&query=Zollo%2C+T+P">Thomas P. Zollo</a>, 
<a href="/search/cs?searchtype=author&query=Snell%2C+J+C">Jake C. Snell</a>, 
<a href="/search/cs?searchtype=author&query=Pitassi%2C+T">Toniann Pitassi</a>, 
<a href="/search/cs?searchtype=author&query=Zemel%2C+R">Richard Zemel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS as spotlight (top 3% among submissions)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Explicit finite-sample statistical guarantees on model performance are an
important ingredient in responsible machine learning. Previous work has focused
mainly on bounding either the expected loss of a predictor or the probability
that an individual prediction will incur a loss value in a specified range.
However, for many high-stakes applications, it is crucial to understand and
control the dispersion of a loss distribution, or the extent to which different
members of a population experience unequal effects of algorithmic decisions. We
initiate the study of distribution-free control of statistical dispersion
measures with societal implications and propose a simple yet flexible framework
that allows us to handle a much richer class of statistical functionals beyond
previous work. Our methods are verified through experiments in toxic comment
detection, medical imaging, and film recommendation.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13788" title="Abstract">arXiv:2309.13788</a> [<a href="/pdf/2309.13788" title="Download PDF">pdf</a>, <a href="/format/2309.13788" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can LLM-Generated Misinformation Be Detected?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Canyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+K">Kai Shu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The code, dataset and more resources on LLMs and misinformation will be released on the project website: <a href="https://llm-misinformation.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
<p class="mathjax">The advent of Large Language Models (LLMs) has made a transformative impact.
However, the potential that LLMs such as ChatGPT can be exploited to generate
misinformation has posed a serious concern to online safety and public trust. A
fundamental research question is: will LLM-generated misinformation cause more
harm than human-written misinformation? We propose to tackle this question from
the perspective of detection difficulty. We first build a taxonomy of
LLM-generated misinformation. Then we categorize and validate the potential
real-world methods for generating misinformation with LLMs. Then, through
extensive empirical investigation, we discover that LLM-generated
misinformation can be harder to detect for humans and detectors compared to
human-written misinformation with the same semantics, which suggests it can
have more deceptive styles and potentially cause more harm. We also discuss the
implications of our discovery on combating misinformation in the age of LLMs
and the countermeasures.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13793" title="Abstract">arXiv:2309.13793</a> [<a href="/pdf/2309.13793" title="Download PDF">pdf</a>, <a href="/format/2309.13793" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReMasker: Imputing Tabular Data with Masked Autoencoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+T">Tianyu Du</a>, 
<a href="/search/cs?searchtype=author&query=Melis%2C+L">Luca Melis</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Ting Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We present ReMasker, a new method of imputing missing values in tabular data
by extending the masked autoencoding framework. Compared with prior work,
ReMasker is both simple -- besides the missing values (i.e., naturally masked),
we randomly ``re-mask'' another set of values, optimize the autoencoder by
reconstructing this re-masked set, and apply the trained model to predict the
missing values; and effective -- with extensive evaluation on benchmark
datasets, we show that ReMasker performs on par with or outperforms
state-of-the-art methods in terms of both imputation fidelity and utility under
various missingness settings, while its performance advantage often increases
with the ratio of missing data. We further explore theoretical justification
for its effectiveness, showing that ReMasker tends to learn
missingness-invariant representations of tabular data. Our findings indicate
that masked modeling represents a promising direction for further research on
tabular data imputation. The code is publicly available.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13794" title="Abstract">arXiv:2309.13794</a> [<a href="/pdf/2309.13794" title="Download PDF">pdf</a>, <a href="/format/2309.13794" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Projected Randomized Smoothing for Certified Adversarial Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pfrommer%2C+S">Samuel Pfrommer</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+B+G">Brendon G. Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Sojoudi%2C+S">Somayeh Sojoudi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research (TMLR) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Randomized smoothing is the current state-of-the-art method for producing
provably robust classifiers. While randomized smoothing typically yields robust
$\ell_2$-ball certificates, recent research has generalized provable robustness
to different norm balls as well as anisotropic regions. This work considers a
classifier architecture that first projects onto a low-dimensional
approximation of the data manifold and then applies a standard classifier. By
performing randomized smoothing in the low-dimensional projected space, we
characterize the certified region of our smoothed composite classifier back in
the high-dimensional input space and prove a tractable lower bound on its
volume. We show experimentally on CIFAR-10 and SVHN that classifiers without
the initial projection are vulnerable to perturbations that are normal to the
data manifold and yet are captured by the certified regions of our method. We
compare the volume of our certified regions against various baselines and show
that our method improves on the state-of-the-art by many orders of magnitude.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13795" title="Abstract">arXiv:2309.13795</a> [<a href="/pdf/2309.13795" title="Download PDF">pdf</a>, <a href="/format/2309.13795" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modelling and Search-Based Testing of Robot Controllers Using Enzymatic  Numerical P Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bobe%2C+R+T">Radu Traian Bobe</a>, 
<a href="/search/cs?searchtype=author&query=Ipate%2C+F">Florentin Ipate</a>, 
<a href="/search/cs?searchtype=author&query=Niculescu%2C+I+M">Ionu&#x163; Mihai Niculescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 1-10
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">The safety of the systems controlled by software is a very important area in
a digitalized society, as the number of automated processes is increasing. In
this paper, we present the results of testing the accuracy of different lane
keeping controllers for an educational robot. In our approach, the robot is
controlled using numerical P systems and enzymatic numerical P systems. For
tests generation, we used an open-source tool implementing a search-based
software testing approach.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13796" title="Abstract">arXiv:2309.13796</a> [<a href="/pdf/2309.13796" title="Download PDF">pdf</a>, <a href="/format/2309.13796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Z3 to Verify Inferences in Fragments of Linear Logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Docef%2C+A">Alen Docef</a>, 
<a href="/search/cs?searchtype=author&query=Negulescu%2C+R">Radu Negulescu</a>, 
<a href="/search/cs?searchtype=author&query=Prunescu%2C+M">Mihai Prunescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 11-25
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Linear logic is a substructural logic proposed as a refinement of classical
and intuitionistic logics, with applications in programming languages, game
semantics, and quantum physics. We present a template for Gentzen-style linear
logic sequents that supports verification of logic inference rules using
automatic theorem proving. Specifically, we use the Z3 Theorem Prover [8] to
check targeted inference rules based on a set of inference rules that are
presumed to be valid. To demonstrate the approach, we apply it to validate
several derived inference rules for two different fragments of linear logic:
MLL+Mix (Multiplicative Linear Logic extended with a Mix rule) and MILL
(Multiplicative Intuitionistic Linear Logic).
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13797" title="Abstract">arXiv:2309.13797</a> [<a href="/pdf/2309.13797" title="Download PDF">pdf</a>, <a href="/format/2309.13797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> q-Overlaps in the Random Exact Cover Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Istrate%2C+G">Gabriel Istrate</a>, 
<a href="/search/cs?searchtype=author&query=Negrea%2C+R">Romeo Negrea</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 26-40
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Statistical Mechanics (cond-mat.stat-mech)

</div>
<p class="mathjax">We prove upper and lower bounds for the threshold of the q-overlap-k-Exact
cover problem.
<br />These results are motivated by the one-step replica symmetry breaking
approach of Statistical Physics, and the hope of using an approach based on
that of Mezard et al. (2005) to rigorously prove that for some values of the
order parameter the overlap distribution of k-Exact Cover has discontinuous
support.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13798" title="Abstract">arXiv:2309.13798</a> [<a href="/pdf/2309.13798" title="Download PDF">pdf</a>, <a href="/format/2309.13798" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matching-Logic-Based Understanding of Polynomial Functors and their  Initial/Final Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lucanu%2C+D">Dorel Lucanu</a> (Alexandru Ioan Cuza University of Iasi, Romania)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 41-55
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">In this paper, we investigate how the initial models and the final models for
the polynomial functors can be uniformly specified in matching logic.
</p>
</div>
</dd>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13799" title="Abstract">arXiv:2309.13799</a> [<a href="/pdf/2309.13799" title="Download PDF">pdf</a>, <a href="/ps/2309.13799" title="Download PostScript">ps</a>, <a href="/format/2309.13799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Parallel Dynamic Epistemic Perspective over Muddy Children Puzzle
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Macovei%2C+B">Bogdan Macovei</a> (University of Bucharest)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 56-64
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Epistemic protocols represents a current field of interest, with numerous
approaches still being studied. In this paper we formalize parallel sessions of
the The Muddy Children Puzzle using Public Observation Logic, a system that
allows epistemic update. We consider agents with roles in multiple sessions and
the information update in all parallel sessions as new information is
discovered in any particular session.
</p>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13800" title="Abstract">arXiv:2309.13800</a> [<a href="/pdf/2309.13800" title="Download PDF">pdf</a>, <a href="/ps/2309.13800" title="Download PostScript">ps</a>, <a href="/format/2309.13800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumerating All Maximal Clique-Partitions of an Undirected Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marin%2C+M">Mircea Marin</a> (West University of Timisoara, Romania), 
<a href="/search/cs?searchtype=author&query=Kutsia%2C+T">Temur Kutsia</a> (Johannes Kepler University, Linz, Austria), 
<a href="/search/cs?searchtype=author&query=Pau%2C+C">Cleo Pau</a> (Johannes Kepler University, Linz, Austria), 
<a href="/search/cs?searchtype=author&query=Rukhaia%2C+M">Mikheil Rukhaia</a> (Institute of Applied Mathematics, Tbilisi State University, Georgia)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 65-79
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>

</div>
<p class="mathjax">We address the problem of enumerating all maximal clique-partitions of an
undirected graph and present an algorithm based on the observation that every
maximal clique-partition can be produced from the maximal clique-cover of the
graph by assigning the vertices shared among maximal cliques, to belong to only
one clique. This simple algorithm has the following drawbacks: (1) the search
space is very large; (2) it finds some clique-partitions which are not maximal;
and (3) some clique-partitions are found more than once. We propose two
criteria to avoid these drawbacks. The outcome is an algorithm that explores a
much smaller search space and guarantees that every maximal clique-partition is
computed only once. The algorithm can be used in problems such as
anti-unification with proximity relations or in resource allocation tasks when
one looks for several alternative ways to allocate resources.
</p>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13801" title="Abstract">arXiv:2309.13801</a> [<a href="/pdf/2309.13801" title="Download PDF">pdf</a>, <a href="/format/2309.13801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Formalized Extension of the Substitution Lemma in Coq
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lima%2C+M+J+D">Maria J. D. Lima</a> (UnB), 
<a href="/search/cs?searchtype=author&query=de+Moura%2C+F+L+C">Fl&#xe1;vio L. C. de Moura</a> (UnB)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 80-95
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The substitution lemma is a renowned theorem within the realm of
lambda-calculus theory and concerns the interactional behaviour of the
metasubstitution operation. In this work, we augment the lambda-calculus's
grammar with an uninterpreted explicit substitution operator, which allows the
use of our framework for different calculi with explicit substitutions. Our
primary contribution lies in verifying that, despite these modifications, the
substitution lemma continues to remain valid. This confirmation was achieved
using the Coq proof assistant. Our formalization methodology employs a nominal
approach, which provides a direct implementation of the alpha-equivalence
concept. The strategy involved in variable renaming within the proofs presents
a challenge, specially on ensuring an exploration of the implications of our
extension to the grammar of the lambda-calculus.
</p>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13802" title="Abstract">arXiv:2309.13802</a> [<a href="/pdf/2309.13802" title="Download PDF">pdf</a>, <a href="/format/2309.13802" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> While Loops in Coq
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nowak%2C+D">David Nowak</a> (CNRS, Lille, France), 
<a href="/search/cs?searchtype=author&query=Rusu%2C+V">Vlad Rusu</a> (Inria, Lille, France)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 96-109
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">While loops are present in virtually all imperative programming languages.
They are important both for practical reasons (performing a number of
iterations not known in advance) and theoretical reasons (achieving Turing
completeness). In this paper we propose an approach for incorporating while
loops in an imperative language shallowly embedded in the Coq proof assistant.
The main difficulty is that proving the termination of while loops is
nontrivial, or impossible in the case of non-termination, whereas Coq only
accepts programs endowed with termination proofs. Our solution is based on a
new, general method for defining possibly non-terminating recursive functions
in Coq. We illustrate the approach by proving termination and partial
correctness of a program on linked lists.
</p>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13803" title="Abstract">arXiv:2309.13803</a> [<a href="/pdf/2309.13803" title="Download PDF">pdf</a>, <a href="/format/2309.13803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-preserving Linear Computations in Spiking Neural P Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Plesa%2C+M">Mihail-Iulian Plesa</a> (University of Bucharest), 
<a href="/search/cs?searchtype=author&query=Gheorghe%2C+M">Marian Gheorghe</a> (University of Bradford), 
<a href="/search/cs?searchtype=author&query=Ipate%2C+F">Florentin Ipate</a> (University of Bucharest)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 110-119
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Spiking Neural P systems are a class of membrane computing models inspired
directly by biological neurons. Besides the theoretical progress made in this
new computational model, there are also numerous applications of P systems in
fields like formal verification, artificial intelligence, or cryptography.
Motivated by all the use cases of SN P systems, in this paper, we present a new
privacy-preserving protocol that enables a client to compute a linear function
using an SN P system hosted on a remote server. Our protocol allows the client
to use the server to evaluate functions of the form t_1k + t_2 without
revealing t_1, t_2 or k and without the server knowing the result. We also
present an SN P system to implement any linear function over natural numbers
and some security considerations of our protocol in the honest-but-curious
security model.
</p>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13804" title="Abstract">arXiv:2309.13804</a> [<a href="/pdf/2309.13804" title="Download PDF">pdf</a>, <a href="/ps/2309.13804" title="Download PostScript">ps</a>, <a href="/format/2309.13804" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symmetric Functions over Finite Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prunescu%2C+M">Mihai Prunescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 131-143
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">The number of linear independent algebraic relations among elementary
symmetric polynomial functions over finite fields is computed. An algorithm
able to find all such relations is described. It is proved that the basis of
the ideal of algebraic relations found by the algorithm consists of polynomials
having coefficients in the prime field F_p.
</p>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13805" title="Abstract">arXiv:2309.13805</a> [<a href="/pdf/2309.13805" title="Download PDF">pdf</a>, <a href="/format/2309.13805" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Vulnerabilities in Smart Contracts using Interval Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Susan%2C+%C5%9E">&#x15e;tefan-Claudiu Susan</a>, 
<a href="/search/cs?searchtype=author&query=Arusoaie%2C+A">Andrei Arusoaie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 144-151
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">This paper serves as a progress report on our research, specifically focusing
on utilizing interval analysis, an existing static analysis method, for
detecting vulnerabilities in smart contracts. We present a selection of
motivating examples featuring vulnerable smart contracts and share the results
from our experiments conducted with various existing detection tools. Our
findings reveal that these tools were unable to detect the vulnerabilities in
our examples. To enhance detection capabilities, we implement interval analysis
on top of Slither [3], an existing detection tool, and demonstrate its
effectiveness in identifying certain vulnerabilities that other tools fail to
detect.
</p>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13807" title="Abstract">arXiv:2309.13807</a> [<a href="/pdf/2309.13807" title="Download PDF">pdf</a>, <a href="/format/2309.13807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forecasting large collections of time series: feature-based methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Li Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Feng Li</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+Y">Yanfei Kang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In economics and many other forecasting domains, the real world problems are
too complex for a single model that assumes a specific data generation process.
The forecasting performance of different methods changes depending on the
nature of the time series. When forecasting large collections of time series,
two lines of approaches have been developed using time series features, namely
feature-based model selection and feature-based model combination. This chapter
discusses the state-of-the-art feature-based methods, with reference to
open-source software implementations.
</p>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13808" title="Abstract">arXiv:2309.13808</a> [<a href="/pdf/2309.13808" title="Download PDF">pdf</a>, <a href="/ps/2309.13808" title="Download PostScript">ps</a>, <a href="/format/2309.13808" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Muddy Children Puzzle (work in progress)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Trufa%C5%9F%2C+D">Dafina Trufa&#x15f;</a> (University of Bucharest), 
<a href="/search/cs?searchtype=author&query=Teodorescu%2C+I">Ioan Teodorescu</a> (University of Bucharest), 
<a href="/search/cs?searchtype=author&query=Diaconescu%2C+D">Denisa Diaconescu</a> (University of Bucharest), 
<a href="/search/cs?searchtype=author&query=%C5%9Eerb%C4%83nu%C5%A3%C4%83%2C+T">Traian &#x15e;erb&#x103;nu&#x163;&#x103;</a> (University of Bucharest), 
<a href="/search/cs?searchtype=author&query=Zamfir%2C+V">Vlad Zamfir</a> (independent researcher)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings FROM 2023, <a href="/abs/2309.12959">arXiv:2309.12959</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 389, 2023, pp. 152-166
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Multiagent Systems (cs.MA)

</div>
<p class="mathjax">In this work-in-progress paper we explore using the recently introduced VLSM
formalism to define and reason about the dynamics of agent-based systems. To
this aim we use VLSMs to formally present several possible approaches to
modeling the interactions in the Muddy Children Puzzle as protocols that reach
consensus asynchronously.
</p>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13810" title="Abstract">arXiv:2309.13810</a> [<a href="/pdf/2309.13810" title="Download PDF">pdf</a>, <a href="/format/2309.13810" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Boundary-Aware Proposal Generation Method for Temporal Action  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chunyan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiahui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Caili Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The goal of Temporal Action Localization (TAL) is to find the categories and
temporal boundaries of actions in an untrimmed video. Most TAL methods rely
heavily on action recognition models that are sensitive to action labels rather
than temporal boundaries. More importantly, few works consider the background
frames that are similar to action frames in pixels but dissimilar in semantics,
which also leads to inaccurate temporal boundaries. To address the challenge
above, we propose a Boundary-Aware Proposal Generation (BAPG) method with
contrastive learning. Specifically, we define the above background frames as
hard negative samples. Contrastive learning with hard negative mining is
introduced to improve the discrimination of BAPG. BAPG is independent of the
existing TAL network architecture, so it can be applied plug-and-play to
mainstream TAL models. Extensive experimental results on THUMOS14 and
ActivityNet-1.3 demonstrate that BAPG can significantly improve the performance
of TAL.
</p>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13813" title="Abstract">arXiv:2309.13813</a> [<a href="/pdf/2309.13813" title="Download PDF">pdf</a>, <a href="/format/2309.13813" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient RRT*-based Safety-Constrained Motion Planning for Continuum  Robots in Dynamic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Peiyu Luo</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shilong Yao</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+Y">Yiyao Yue</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+M+Q+-">Max Q.-H. Meng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Continuum robots, characterized by their high flexibility and infinite
degrees of freedom (DoFs), have gained prominence in applications such as
minimally invasive surgery and hazardous environment exploration. However, the
intrinsic complexity of continuum robots requires a significant amount of time
for their motion planning, posing a hurdle to their practical implementation.
To tackle these challenges, efficient motion planning methods such as Rapidly
Exploring Random Trees (RRT) and its variant, RRT*, have been employed. This
paper introduces a unique RRT*-based motion control method tailored for
continuum robots. Our approach embeds safety constraints derived from the
robots' posture states, facilitating autonomous navigation and obstacle
avoidance in rapidly changing environments. Simulation results show efficient
trajectory planning amidst multiple dynamic obstacles and provide a robust
performance evaluation based on the generated postures. Finally, preliminary
tests were conducted on a two-segment cable-driven continuum robot prototype,
confirming the effectiveness of the proposed planning approach. This method is
versatile and can be adapted and deployed for various types of continuum robots
through parameter adjustments.
</p>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13814" title="Abstract">arXiv:2309.13814</a> [<a href="/pdf/2309.13814" title="Download PDF">pdf</a>, <a href="/format/2309.13814" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DVI-SLAM: A Dual Visual Inertial SLAM Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xiongfeng Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhihua Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiming Li</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+P">Ping Tan</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">SoonYong Cho</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qiang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recent deep learning based visual simultaneous localization and mapping
(SLAM) methods have made significant progress. However, how to make full use of
visual information as well as better integrate with inertial measurement unit
(IMU) in visual SLAM has potential research value. This paper proposes a novel
deep SLAM network with dual visual factors. The basic idea is to integrate both
photometric factor and re-projection factor into the end-to-end differentiable
structure through multi-factor data association module. We show that the
proposed network dynamically learns and adjusts the confidence maps of both
visual factors and it can be further extended to include the IMU factors as
well. Extensive experiments validate that our proposed method significantly
outperforms the state-of-the-art methods on several public datasets, including
TartanAir, EuRoC and ETH3D-SLAM. Specifically, when dynamically fusing the
three factors together, the absolute trajectory error for both monocular and
stereo configurations on EuRoC dataset has reduced by 45.3% and 36.2%
respectively.
</p>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13822" title="Abstract">arXiv:2309.13822</a> [<a href="/pdf/2309.13822" title="Download PDF">pdf</a>, <a href="/format/2309.13822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PARTICLE: Part Discovery and Contrastive Learning for Fine-grained  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saha%2C+O">Oindrila Saha</a>, 
<a href="/search/cs?searchtype=author&query=Maji%2C+S">Subhransu Maji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We develop techniques for refining representations for fine-grained
classification and segmentation tasks in a self-supervised manner. We find that
fine-tuning methods based on instance-discriminative contrastive learning are
not as effective, and posit that recognizing part-specific variations is
crucial for fine-grained categorization. We present an iterative learning
approach that incorporates part-centric equivariance and invariance objectives.
First, pixel representations are clustered to discover parts. We analyze the
representations from convolutional and vision transformer networks that are
best suited for this task. Then, a part-centric learning step aggregates and
contrasts representations of parts within an image. We show that this improves
the performance on image classification and part segmentation tasks across
datasets. For example, under a linear-evaluation scheme, the classification
accuracy of a ResNet50 trained on ImageNet using DetCon, a self-supervised
learning approach, improves from 35.4% to 42.0% on the Caltech-UCSD Birds, from
35.5% to 44.1% on the FGVC Aircraft, and from 29.7% to 37.4% on the Stanford
Cars. We also observe significant gains in few-shot part segmentation tasks
using the proposed technique, while instance-discriminative learning was not as
effective. Smaller, yet consistent, improvements are also observed for stronger
networks based on transformers.
</p>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13824" title="Abstract">arXiv:2309.13824</a> [<a href="/pdf/2309.13824" title="Download PDF">pdf</a>, <a href="/format/2309.13824" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TriMe++: Multi-threaded triangular meshing in two dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jiayin Lu</a>, 
<a href="/search/cs?searchtype=author&query=Rycroft%2C+C+H">Christ H. Rycroft</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Numerical Analysis (math.NA); Applied Physics (physics.app-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We present TriMe++, a multi-threaded software library designed for generating
two-dimensional meshes for intricate geometric shapes using the Delaunay
triangulation. Multi-threaded parallel computing is implemented throughout the
meshing procedure, making it suitable for fast generation of large-scale
meshes. Three iterative meshing algorithms are implemented: the DistMesh
algorithm, the centroidal Voronoi diagram meshing, and a hybrid of the two. We
compare the performance of the three meshing methods in TriMe++, and show that
the hybrid method retains the advantages of the other two. The software library
achieves significant parallel speedup when generating a large mesh with $10^6$
points. TriMe++ can handle complicated geometries and generates adaptive meshes
of high quality.
</p>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13827" title="Abstract">arXiv:2309.13827</a> [<a href="/pdf/2309.13827" title="Download PDF">pdf</a>, <a href="/ps/2309.13827" title="Download PostScript">ps</a>, <a href="/format/2309.13827" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A simple linear-time algorithm for generating auxiliary 3-edge-connected  subgraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tsin%2C+Y+H">Yung H. Tsin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">A linear-time algorithm for generating auxiliary subgraphs for the
3-edge-connected components of a connected multigraph is presented. The
algorithm uses an innovative graph contraction operation and makes only one
pass over the graph. By contrast, the previously best-known algorithms make
multiple passes over the graph to decompose it into its 2-edge-connected
components or 2-vertex-connected components, then its 3-edge-connected
components or 3-vertex-connected components, and then construct a cactus
representation for the 2-cuts to generate the auxiliary subgraphs for the
3-edge-connected components.
</p>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13833" title="Abstract">arXiv:2309.13833</a> [<a href="/pdf/2309.13833" title="Download PDF">pdf</a>, <a href="/format/2309.13833" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dual Feature Augmentation Network for Generalized Zero-shot Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+L">Lei Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Duan%2C+H">Haoran Duan</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+Y">Yang Long</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Zero-shot learning (ZSL) aims to infer novel classes without training samples
by transferring knowledge from seen classes. Existing embedding-based
approaches for ZSL typically employ attention mechanisms to locate attributes
on an image. However, these methods often ignore the complex entanglement among
different attributes' visual features in the embedding space. Additionally,
these methods employ a direct attribute prediction scheme for classification,
which does not account for the diversity of attributes in images of the same
category. To address these issues, we propose a novel Dual Feature Augmentation
Network (DFAN), which comprises two feature augmentation modules, one for
visual features and the other for semantic features. The visual feature
augmentation module explicitly learns attribute features and employs cosine
distance to separate them, thus enhancing attribute representation. In the
semantic feature augmentation module, we propose a bias learner to capture the
offset that bridges the gap between actual and predicted attribute values from
a dataset's perspective. Furthermore, we introduce two predictors to reconcile
the conflicts between local and global features. Experimental results on three
benchmarks demonstrate the marked advancement of our method compared to
state-of-the-art approaches. Our code is available at
https://github.com/Sion1/DFAN.
</p>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13834" title="Abstract">arXiv:2309.13834</a> [<a href="/pdf/2309.13834" title="Download PDF">pdf</a>, <a href="/format/2309.13834" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prior Bilinear Based Models for Knowledge Graph Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiayi Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+R">Ruilin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiaqi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jing Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">Bilinear based models are powerful and widely used approaches for Knowledge
Graphs Completion (KGC). Although bilinear based models have achieved
significant advances, these studies mainly concentrate on posterior properties
(based on evidence, e.g. symmetry pattern) while neglecting the prior
properties. In this paper, we find a prior property named "the law of identity"
that cannot be captured by bilinear based models, which hinders them from
comprehensively modeling the characteristics of KGs. To address this issue, we
introduce a solution called Unit Ball Bilinear Model (UniBi). This model not
only achieves theoretical superiority but also offers enhanced interpretability
and performance by minimizing ineffective learning through minimal constraints.
Experiments demonstrate that UniBi models the prior property and verify its
interpretability and performance.
</p>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13836" title="Abstract">arXiv:2309.13836</a> [<a href="/pdf/2309.13836" title="Download PDF">pdf</a>, <a href="/format/2309.13836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Energy Efficiency of THz-NOMA enhanced UAV Cooperative Network  with SWIPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jalali%2C+J">Jalal Jalali</a>, 
<a href="/search/cs?searchtype=author&query=Khalili%2C+A">Ata Khalili</a>, 
<a href="/search/cs?searchtype=author&query=Tabassum%2C+H">Hina Tabassum</a>, 
<a href="/search/cs?searchtype=author&query=Berkvens%2C+R">Rafael Berkvens</a>, 
<a href="/search/cs?searchtype=author&query=Famaey%2C+J">Jeroen Famaey</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper considers the energy efficiency (EE) maximization of a
simultaneous wireless information and power transfer (SWIPT)-assisted unmanned
aerial vehicles (UAV) cooperative network operating at TeraHertz (THz)
frequencies. The source performs SWIPT enabling the UAV to receive both power
and information while also transmitting the information to a designated
destination node. Subsequently, the UAV utilizes the harvested energy to relay
the data to the intended destination node effectively. Specifically, we
maximize EE by optimizing the non-orthogonal multiple access (NOMA) power
allocation coefficients, SWIPT power splitting (PS) ratio, and UAV trajectory.
The main problem is broken down into a two-stage optimization problem and
solved using an alternating optimization approach. In the first stage,
optimization of the PS ratio and trajectory is performed by employing
successive convex approximation using a lower bound on the exponential factor
in the THz channel model. In the second phase, the NOMA power coefficients are
optimized using a quadratic transform approach. Numerical results demonstrate
the effectiveness of our proposed resource allocation algorithm compared to the
baselines where there is no trajectory optimization or no NOMA power or PS
optimization.
</p>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13837" title="Abstract">arXiv:2309.13837</a> [<a href="/pdf/2309.13837" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Backorder Prediction in Inventory Management: Classification Techniques  and Cost Considerations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maitra%2C+S">Sarit Maitra</a>, 
<a href="/search/cs?searchtype=author&query=Kundu%2C+S">Sukanya Kundu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures, IEEE (ICSEC 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">This article introduces an advanced analytical approach for predicting
backorders in inventory management. Backorder refers to an order that cannot be
immediately fulfilled due to stock depletion. Multiple classification
techniques, including Balanced Bagging Classifiers, Fuzzy Logic, Variational
Autoencoder - Generative Adversarial Networks, and Multi-layer Perceptron
classifiers, are assessed in this work using performance evaluation metrics
such as ROC-AUC and PR-AUC. Moreover, this work incorporates a profit function
and misclassification costs, considering the financial implications and costs
associated with inventory management and backorder handling. The results
demonstrate the effectiveness of the predictive model in enhancing inventory
system service levels, which leads to customer satisfaction and overall
organizational performance. Considering interpretability is a significant
aspect of using AI in commercial applications, permutation importance is
applied to the selected model to determine the importance of features. This
research contributes to the advancement of predictive analytics and offers
valuable insights for future investigations in backorder forecasting and
inventory control optimization for decision-making.
</p>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13841" title="Abstract">arXiv:2309.13841</a> [<a href="/pdf/2309.13841" title="Download PDF">pdf</a>, <a href="/format/2309.13841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Effectiveness of Adversarial Samples against Ensemble  Learning-based Windows PE Malware Detectors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=To%2C+T">Trong-Nghia To</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D+L">Danh Le Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hien%2C+D+T+T">Do Thi Thu Hien</a>, 
<a href="/search/cs?searchtype=author&query=Khoa%2C+N+H">Nghi Hoang Khoa</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+H+D">Hien Do Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Duy%2C+P+T">Phan The Duy</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+V">Van-Hau Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, there has been a growing focus and interest in applying machine
learning (ML) to the field of cybersecurity, particularly in malware detection
and prevention. Several research works on malware analysis have been proposed,
offering promising results for both academic and practical applications. In
these works, the use of Generative Adversarial Networks (GANs) or Reinforcement
Learning (RL) can aid malware creators in crafting metamorphic malware that
evades antivirus software. In this study, we propose a mutation system to
counteract ensemble learning-based detectors by combining GANs and an RL model,
overcoming the limitations of the MalGAN model. Our proposed FeaGAN model is
built based on MalGAN by incorporating an RL model called the Deep Q-network
anti-malware Engines Attacking Framework (DQEAF). The RL model addresses three
key challenges in performing adversarial attacks on Windows Portable Executable
malware, including format preservation, executability preservation, and
maliciousness preservation. In the FeaGAN model, ensemble learning is utilized
to enhance the malware detector's evasion ability, with the generated
adversarial patterns. The experimental results demonstrate that 100\% of the
selected mutant samples preserve the format of executable files, while certain
successes in both executability preservation and maliciousness preservation are
achieved, reaching a stable success rate.
</p>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13842" title="Abstract">arXiv:2309.13842</a> [<a href="/pdf/2309.13842" title="Download PDF">pdf</a>, <a href="/format/2309.13842" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traj-LO: In Defense of LiDAR-Only Odometry Using an Effective  Continuous-Time Trajectory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xin Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jianke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Video <a href="https://youtu.be/hbtKzElYKkQ?si=3KEVy0hlHBsKV8j0">this https URL</a> and Project site <a href="https://github.com/kevin2431/Traj-LO">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">LiDAR Odometry is an essential component in many robotic applications. Unlike
the mainstreamed approaches that focus on improving the accuracy by the
additional inertial sensors, this letter explores the capability of LiDAR-only
odometry through a continuous-time perspective. Firstly, the measurements of
LiDAR are regarded as streaming points continuously captured at high frequency.
Secondly, the LiDAR movement is parameterized by a simple yet effective
continuous-time trajectory. Therefore, our proposed Traj-LO approach tries to
recover the spatial-temporal consistent movement of LiDAR by tightly coupling
the geometric information from LiDAR points and kinematic constraints from
trajectory smoothness. This framework is generalized for different kinds of
LiDAR as well as multi-LiDAR systems. Extensive experiments on the public
datasets demonstrate the robustness and effectiveness of our proposed
LiDAR-only approach, even in scenarios where the kinematic state exceeds the
IMU's measuring range. Our implementation is open-sourced on GitHub.
</p>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13843" title="Abstract">arXiv:2309.13843</a> [<a href="/pdf/2309.13843" title="Download PDF">pdf</a>, <a href="/format/2309.13843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric Decomposition and Efficient Implementation of High Order Face  and Edge Elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+C">Chunyu Chen</a>, 
<a href="/search/math?searchtype=author&query=Chen%2C+L">Long Chen</a>, 
<a href="/search/math?searchtype=author&query=Huang%2C+X">Xuehai Huang</a>, 
<a href="/search/math?searchtype=author&query=Wei%2C+H">Huayi Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This paper delves into the world of high-order curl and div elements within
finite element methods, providing valuable insights into their geometric
properties, indexing management, and practical implementation considerations.
It first explores the decomposition of Lagrange finite elements. The discussion
then extends to H(div)-conforming finite elements and H(curl)-conforming finite
element spaces by choosing different frames at different sub-simplex. The
required tangential continuity or normal continuity will be imposed by
appropriate choices of the tangential and normal basis. The paper concludes
with a focus on efficient indexing management strategies for degrees of
freedom, offering practical guidance to researchers and engineers. It serves as
a comprehensive resource that bridges the gap between theory and practice in
the realm of high-order curl and div elements in finite element methods, which
are vital for solving vector field problems and understanding electromagnetic
phenomena.
</p>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13847" title="Abstract">arXiv:2309.13847</a> [<a href="/pdf/2309.13847" title="Download PDF">pdf</a>, <a href="/format/2309.13847" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tuning Multi-mode Token-level Prompt Alignment across Modalities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongsheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Miaoge Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">MingSheng Xu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hanwang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of NeurIPS2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prompt tuning pre-trained vision-language models have demonstrated
significant potential in improving open-world visual concept understanding.
However, prior works only primarily focus on single-mode (only one prompt for
each modality) and holistic level (image or sentence) semantic alignment, which
fails to capture the sample diversity, leading to sub-optimal prompt discovery.
To address the limitation, we propose a multi-mode token-level tuning framework
that leverages the optimal transportation to learn and align a set of prompt
tokens across modalities. Specifically, we rely on two essential factors: 1)
multi-mode prompts discovery, which guarantees diverse semantic
representations, and 2) token-level alignment, which helps explore fine-grained
similarity. Thus, the similarity can be calculated as a hierarchical
transportation problem between the modality-specific sets. Extensive
experiments on popular image recognition benchmarks show the superior
generalization and few-shot abilities of our approach. The qualitative analysis
demonstrates that the learned prompt tokens have the ability to capture diverse
visual concepts.
</p>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13848" title="Abstract">arXiv:2309.13848</a> [<a href="/pdf/2309.13848" title="Download PDF">pdf</a>, <a href="/format/2309.13848" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A frequency-independent solver for systems of first order linear  ordinary differential equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+T">Tony Hu</a>, 
<a href="/search/math?searchtype=author&query=Bremer%2C+J">James Bremer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2308.03288">arXiv:2308.03288</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">When a system of first order linear ordinary differential equations has
eigenvalues of large magnitude, its solutions exhibit complicated behaviour,
such as high-frequency oscillations, rapid growth or rapid decay. The cost of
representing such solutions using standard techniques typically grows with the
magnitudes of the eigenvalues. As a consequence, the running times of standard
solvers for ordinary differential equations also grow with the size of these
eigenvalues. The solutions of scalar equations with slowly-varying
coefficients, however, can be efficiently represented via slowly-varying phase
functions, regardless of the magnitudes of the eigenvalues of the corresponding
coefficient matrix. Here, we couple an existing solver for scalar equations
which exploits this observation with a well-known technique for transforming a
system of linear ordinary differential equations into scalar form. The result
is a method for solving a large class of systems of linear ordinary
differential equations in time independent of the magnitudes of the eigenvalues
of their coefficient matrices. We discuss the results of numerical experiments
demonstrating the properties of our algorithm.
</p>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13851" title="Abstract">arXiv:2309.13851</a> [<a href="/pdf/2309.13851" title="Download PDF">pdf</a>, <a href="/format/2309.13851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISeR: Designing Imaging Systems with Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klinghoffer%2C+T">Tzofi Klinghoffer</a>, 
<a href="/search/cs?searchtype=author&query=Tiwary%2C+K">Kushagra Tiwary</a>, 
<a href="/search/cs?searchtype=author&query=Behari%2C+N">Nikhil Behari</a>, 
<a href="/search/cs?searchtype=author&query=Agrawalla%2C+B">Bhavya Agrawalla</a>, 
<a href="/search/cs?searchtype=author&query=Raskar%2C+R">Ramesh Raskar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023. Project Page: <a href="https://tzofi.github.io/diser">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Imaging systems consist of cameras to encode visual information about the
world and perception models to interpret this encoding. Cameras contain (1)
illumination sources, (2) optical elements, and (3) sensors, while perception
models use (4) algorithms. Directly searching over all combinations of these
four building blocks to design an imaging system is challenging due to the size
of the search space. Moreover, cameras and perception models are often designed
independently, leading to sub-optimal task performance. In this paper, we
formulate these four building blocks of imaging systems as a context-free
grammar (CFG), which can be automatically searched over with a learned camera
designer to jointly optimize the imaging system with task-specific perception
models. By transforming the CFG to a state-action space, we then show how the
camera designer can be implemented with reinforcement learning to intelligently
search over the combinatorial space of possible imaging system configurations.
We demonstrate our approach on two tasks, depth estimation and camera rig
design for autonomous vehicles, showing that our method yields rigs that
outperform industry-wide standards. We believe that our proposed approach is an
important step towards automating imaging system design.
</p>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13853" title="Abstract">arXiv:2309.13853</a> [<a href="/pdf/2309.13853" title="Download PDF">pdf</a>, <a href="/format/2309.13853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Ferroelectric Compute-in-Memory Annealer for Combinatorial  Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+X">Xunzhao Yin</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+Y">Yu Qian</a>, 
<a href="/search/cs?searchtype=author&query=Vardar%2C+A">Alptekin Vardar</a>, 
<a href="/search/cs?searchtype=author&query=Gunther%2C+M">Marcel Gunther</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+F">Franz Muller</a>, 
<a href="/search/cs?searchtype=author&query=Laleni%2C+N">Nellie Laleni</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zijian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Z">Zhouhang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhiguo Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yiyu Shi</a>, 
<a href="/search/cs?searchtype=author&query=Gong%2C+X">Xiao Gong</a>, 
<a href="/search/cs?searchtype=author&query=Zhuo%2C+C">Cheng Zhuo</a>, 
<a href="/search/cs?searchtype=author&query=Kampfe%2C+T">Thomas Kampfe</a>, 
<a href="/search/cs?searchtype=author&query=Ni%2C+K">Kai Ni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>

</div>
<p class="mathjax">Computationally hard combinatorial optimization problems (COPs) are
ubiquitous in many applications, including logistical planning, resource
allocation, chip design, drug explorations, and more. Due to their critical
significance and the inability of conventional hardware in efficiently handling
scaled COPs, there is a growing interest in developing computing hardware
tailored specifically for COPs, including digital annealers, dynamical Ising
machines, and quantum/photonic systems. However, significant hurdles still
remain, such as the memory access issue, the system scalability and restricted
applicability to certain types of COPs, and VLSI-incompatibility, respectively.
Here, a ferroelectric field effect transistor (FeFET) based compute-in-memory
(CiM) annealer is proposed. After converting COPs into quadratic unconstrained
binary optimization (QUBO) formulations, a hardware-algorithm co-design is
conducted, yielding an energy-efficient, versatile, and scalable hardware for
COPs. To accelerate the core vector-matrix-vector (VMV) multiplication of QUBO
formulations, a FeFET based CiM array is exploited, which can accelerate the
intended operation in-situ due to its unique three-terminal structure. In
particular, a lossless compression technique is proposed to prune typically
sparse QUBO matrix to reduce hardware cost. Furthermore, a multi-epoch
simulated annealing (MESA) algorithm is proposed to replace conventional
simulated annealing for its faster convergence and better solution quality. The
effectiveness of the proposed techniques is validated through the utilization
of developed chip prototypes for successfully solving graph coloring problem,
indicating great promise of FeFET CiM annealer in solving general COPs.
</p>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13857" title="Abstract">arXiv:2309.13857</a> [<a href="/pdf/2309.13857" title="Download PDF">pdf</a>, <a href="/format/2309.13857" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks on Video Object Segmentation with Hard Region  Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Ping Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+L">Li Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xianghua Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqin Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video object segmentation has been applied to various computer vision tasks,
such as video editing, autonomous driving, and human-robot interaction.
However, the methods based on deep neural networks are vulnerable to
adversarial examples, which are the inputs attacked by almost
human-imperceptible perturbations, and the adversary (i.e., attacker) will fool
the segmentation model to make incorrect pixel-level predictions. This will
rise the security issues in highly-demanding tasks because small perturbations
to the input video will result in potential attack risks. Though adversarial
examples have been extensively used for classification, it is rarely studied in
video object segmentation. Existing related methods in computer vision either
require prior knowledge of categories or cannot be directly applied due to the
special design for certain tasks, failing to consider the pixel-wise region
attack. Hence, this work develops an object-agnostic adversary that has
adversarial impacts on VOS by first-frame attacking via hard region discovery.
Particularly, the gradients from the segmentation model are exploited to
discover the easily confused region, in which it is difficult to identify the
pixel-wise objects from the background in a frame. This provides a hardness map
that helps to generate perturbations with a stronger adversarial power for
attacking the first frame. Empirical studies on three benchmarks indicate that
our attacker significantly degrades the performance of several state-of-the-art
video object segmentation models.
</p>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13858" title="Abstract">arXiv:2309.13858</a> [<a href="/pdf/2309.13858" title="Download PDF">pdf</a>, <a href="/format/2309.13858" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Impact of Human-AI Interaction on User Trust and Reliance in AI-Assisted  Qualitative Coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+J">Jie Gao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junming Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+S">ShunYi Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+K+T+W">Kenny Tsu Wei Choo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T+J">Toby Jia-Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+S">Shengdong Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Perrault%2C+S+T">Simon Tangi Perrault</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 27 pages with references, 9 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">While AI shows promise for enhancing the efficiency of qualitative analysis,
the unique human-AI interaction resulting from varied coding strategies makes
it challenging to develop a trustworthy AI-assisted qualitative coding system
(AIQCs) that supports coding tasks effectively. We bridge this gap by exploring
the impact of varying coding strategies on user trust and reliance on AI. We
conducted a mixed-methods split-plot 3x3 study, involving 30 participants, and
a follow-up study with 6 participants, exploring varying text selection and
code length in the use of our AIQCs system for qualitative analysis. Our
results indicate that qualitative open coding should be conceptualized as a
series of distinct subtasks, each with differing levels of complexity, and
therefore, should be given tailored design considerations. We further observed
a discrepancy between perceived and behavioral measures, and emphasized the
potential challenges of under- and over-reliance on AIQCs systems. Additional
design implications were also proposed for consideration.
</p>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13860" title="Abstract">arXiv:2309.13860</a> [<a href="/pdf/2309.13860" title="Download PDF">pdf</a>, <a href="/format/2309.13860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanrou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Z">Ziyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Z">Zhisheng Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yakun Song</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhikang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xie Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent years have witnessed significant advancements in self-supervised
learning (SSL) methods for speech-processing tasks. Various speech-based SSL
models have been developed and present promising performance on a range of
downstream tasks including speech recognition. However, existing speech-based
SSL models face a common dilemma in terms of computational cost, which might
hinder their potential application and in-depth academic research. To address
this issue, we first analyze the computational cost of different modules during
HuBERT pre-training and then introduce a stack of efficiency optimizations,
which is named Fast-HuBERT in this paper. The proposed Fast-HuBERT can be
trained in 1.1 days with 8 V100 GPUs on the Librispeech 960h benchmark, without
performance degradation, resulting in a 5.2x speedup, compared to the original
implementation. Moreover, we explore two well-studied techniques in the
Fast-HuBERT and demonstrate consistent improvements as reported in previous
work.
</p>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13863" title="Abstract">arXiv:2309.13863</a> [<a href="/pdf/2309.13863" title="Download PDF">pdf</a>, <a href="/format/2309.13863" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SuPerPM: A Large Deformation-Robust Surgical Perception Framework Based  on Deep Point Matching Learned from Physical Constrained Simulation Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+A+J">Albert J. Miao</a>, 
<a href="/search/cs?searchtype=author&query=Alabiad%2C+A">Ali Alabiad</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+J">Jingpei Lu</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+F">Florian Richter</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Manipulation of tissue with surgical tools often results in large
deformations that current methods in tracking and reconstructing algorithms
have not effectively addressed. A major source of tracking errors during large
deformations stems from wrong data association between observed sensor
measurements with previously tracked scene. To mitigate this issue, we present
a surgical perception framework, SuPerPM, that leverages learning-based
non-rigid point cloud matching for data association, thus accommodating larger
deformations. The learning models typically require training data with ground
truth point cloud correspondences, which is challenging or even impractical to
collect in surgical environments. Thus, for tuning the learning model, we
gather endoscopic data of soft tissue being manipulated by a surgical robot and
then establish correspondences between point clouds at different time points to
serve as ground truth. This was achieved by employing a position-based dynamics
(PBD) simulation to ensure that the correspondences adhered to physical
constraints. The proposed framework is demonstrated on several challenging
surgical datasets that are characterized by large deformations, achieving
superior performance over state-of-the-art surgical scene tracking algorithms.
</p>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13864" title="Abstract">arXiv:2309.13864</a> [<a href="/pdf/2309.13864" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PA-iMFL: Communication-Efficient Privacy Amplification Method against  Data Reconstruction Attack in Improved Multi-Layer Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianhua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xiaolin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%A1i%C4%87%2C+J">Jelena Mi&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Mi%C5%A1i%C4%87%2C+V+B">Vojislav B. Mi&#x161;i&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Junchao Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Recently, big data has seen explosive growth in the Internet of Things (IoT).
Multi-layer FL (MFL) based on cloud-edge-end architecture can promote model
training efficiency and model accuracy while preserving IoT data privacy. This
paper considers an improved MFL, where edge layer devices own private data and
can join the training process. iMFL can improve edge resource utilization and
also alleviate the strict requirement of end devices, but suffers from the
issues of Data Reconstruction Attack (DRA) and unacceptable communication
overhead. This paper aims to address these issues with iMFL. We propose a
Privacy Amplification scheme on iMFL (PA-iMFL). Differing from standard MFL, we
design privacy operations in end and edge devices after local training,
including three sequential components, local differential privacy with Laplace
mechanism, privacy amplification subsample, and gradient sign reset.
Benefitting from privacy operations, PA-iMFL reduces communication overhead and
achieves privacy-preserving. Extensive results demonstrate that against
State-Of-The-Art (SOTA) DRAs, PA-iMFL can effectively mitigate private data
leakage and reach the same level of protection capability as the SOTA defense
model. Moreover, due to adopting privacy operations in edge devices, PA-iMFL
promotes up to 2.8 times communication efficiency than the SOTA compression
method without compromising model accuracy.
</p>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13866" title="Abstract">arXiv:2309.13866</a> [<a href="/pdf/2309.13866" title="Download PDF">pdf</a>, <a href="/format/2309.13866" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Calibration of Modern Quantized Efficient Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuang%2C+J">Joey Kuang</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ICCV 2023 Workshop on Low-Bit Quantized Neural Networks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We explore calibration properties at various precisions for three
architectures: ShuffleNetv2, GhostNet-VGG, and MobileOne; and two datasets:
CIFAR-100 and PathMNIST. The quality of calibration is observed to track the
quantization quality; it is well-documented that performance worsens with lower
precision, and we observe a similar correlation with poorer calibration. This
becomes especially egregious at 4-bit activation regime. GhostNet-VGG is shown
to be the most robust to overall performance drop at lower precision. We find
that temperature scaling can improve calibration error for quantized networks,
with some caveats. We hope that these preliminary insights can lead to more
opportunities for explainable and reliable EdgeML.
</p>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13869" title="Abstract">arXiv:2309.13869</a> [<a href="/pdf/2309.13869" title="Download PDF">pdf</a>, <a href="/format/2309.13869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with  Relation-Aware Score Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+M">Minseok Choi</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+H">Hyesu Lim</a>, 
<a href="/search/cs?searchtype=author&query=Choo%2C+J">Jaegul Choo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to Findings of IJCNLP-AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Document-level relation extraction (DocRE) aims to extract relations of all
entity pairs in a document. A key challenge in DocRE is the cost of annotating
such data which requires intensive human effort. Thus, we investigate the case
of DocRE in a low-resource setting, and we find that existing models trained on
low data overestimate the NA ("no relation") label, causing limited
performance. In this work, we approach the problem from a calibration
perspective and propose PRiSM, which learns to adapt logits based on relation
semantic information. We evaluate our method on three DocRE datasets and
demonstrate that integrating existing models with PRiSM improves performance by
as much as 26.38 F1 score, while the calibration error drops as much as 36
times when trained with about 3% of data. The code is publicly available at
https://github.com/brightjade/PRiSM.
</p>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13873" title="Abstract">arXiv:2309.13873</a> [<a href="/pdf/2309.13873" title="Download PDF">pdf</a>, <a href="/ps/2309.13873" title="Download PostScript">ps</a>, <a href="/format/2309.13873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guaranteed Privacy-Preserving $\mathcal{H}_{\infty}$-Optimal Interval  Observer Design for Bounded-Error LTI Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khajenejad%2C+M">Mohammad Khajenejad</a>, 
<a href="/search/cs?searchtype=author&query=Martinez%2C+S">Sonia Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper furthers current research into the notion of guaranteed privacy,
which provides a deterministic characterization of the privacy of output
signals of a dynamical system or mechanism. Unlike stochastic differential
privacy, guaranteed privacy offers strict bounds on the proximity between the
ranges of two sets of estimated data. Our approach relies on synthesizing an
interval observer for linear time-invariant (LTI) bounded-error systems. The
design procedure incorporates a bounded noise perturbation factor computation
and an observer gain synthesis. The observer simultaneously provides guaranteed
private and stable interval-valued estimates for the desired variable. We
demonstrate the optimality of our design by minimizing the
$\mathcal{H}_{\infty}$ norm of the observer error system. Lastly, we assess the
accuracy of our proposed mechanism by quantifying the loss incurred when
considering guaranteed privacy specifications, and illustrate our approach
outperformance to differential privacy through simulations.
</p>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13876" title="Abstract">arXiv:2309.13876</a> [<a href="/pdf/2309.13876" title="Download PDF">pdf</a>, <a href="/format/2309.13876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reproducing Whisper-Style Training Using an Open-Source Toolkit and  Publicly Available Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Brian Yan</a>, 
<a href="/search/cs?searchtype=author&query=Berrebbi%2C+D">Dan Berrebbi</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinjian Li</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jiatong Shi</a>, 
<a href="/search/cs?searchtype=author&query=Arora%2C+S">Siddhant Arora</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">William Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+R">Roshan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wangyou Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Sudo%2C+Y">Yui Sudo</a>, 
<a href="/search/cs?searchtype=author&query=Shakeel%2C+M">Muhammad Shakeel</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Pre-training speech models on large volumes of data has achieved remarkable
success. OpenAI Whisper is a multilingual multitask model trained on 680k hours
of supervised speech data. It generalizes well to various speech recognition
and translation benchmarks even in a zero-shot setup. However, the full
pipeline for developing such models (from data collection to training) is not
publicly accessible, which makes it difficult for researchers to further
improve its performance and address training-related issues such as efficiency,
robustness, fairness, and bias. This work presents an Open Whisper-style Speech
Model (OWSM), which reproduces Whisper-style training using an open-source
toolkit and publicly available data. OWSM even supports more translation
directions and can be more efficient to train. We will publicly release all
scripts used for data preparation, training, inference, and scoring as well as
pre-trained models and training logs to promote open science.
</p>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13879" title="Abstract">arXiv:2309.13879</a> [<a href="/pdf/2309.13879" title="Download PDF">pdf</a>, <a href="/format/2309.13879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM-Powered Conversational Voice Assistants: Interaction Patterns,  Opportunities, Challenges, and Design Guidelines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahmood%2C+A">Amama Mahmood</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junxiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+B">Bingsheng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dakuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Conventional Voice Assistants (VAs) rely on traditional language models to
discern user intent and respond to their queries, leading to interactions that
often lack a broader contextual understanding, an area in which Large Language
Models (LLMs) excel. However, current LLMs are largely designed for text-based
interactions, thus making it unclear how user interactions will evolve if their
modality is changed to voice. In this work, we investigate whether LLMs can
enrich VA interactions via an exploratory study with participants (N=20) using
a ChatGPT-powered VA for three scenarios (medical self-diagnosis, creative
planning, and debate) with varied constraints, stakes, and objectivity. We
observe that LLM-powered VA elicits richer interaction patterns that vary
across tasks, showing its versatility. Notably, LLMs absorb the majority of VA
intent recognition failures. We additionally discuss the potential of
harnessing LLMs for more resilient and fluid user-VA interactions and provide
design guidelines for tailoring LLMs for voice assistance.
</p>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13881" title="Abstract">arXiv:2309.13881</a> [<a href="/pdf/2309.13881" title="Download PDF">pdf</a>, <a href="/format/2309.13881" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Skip-Connected Neural Networks with Layout Graphs for Floor Plan  Auto-Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+Y">Yuntae Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+D+Q">Dai Quoc Tran</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seunghee Park</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">With the advent of AI and computer vision techniques, the quest for automated
and efficient floor plan designs has gained momentum. This paper presents a
novel approach using skip-connected neural networks integrated with layout
graphs. The skip-connected layers capture multi-scale floor plan information,
and the encoder-decoder networks with GNN facilitate pixel-level
probability-based generation. Validated on the MSD dataset, our approach
achieved a 56.6 mIoU score in the ICCV 1st CVAAD workshop challenge. Code and
pre-trained models are publicly available at
https://github.com/yuntaeJ/SkipNet-FloorPlanGe.
</p>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13882" title="Abstract">arXiv:2309.13882</a> [<a href="/pdf/2309.13882" title="Download PDF">pdf</a>, <a href="/format/2309.13882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FC-Planner: A Skeleton-guided Planning Framework for Fast Aerial  Coverage of Complex 3D Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haojia Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+J">Jinqi Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+S">Shaojie Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Boyu Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA2024. 6 Pages, 6 Figures, 3 Tables. Code: <a href="https://github.com/HKUST-Aerial-Robotics/FC-Planner.">this https URL</a> Video: <a href="https://www.bilibili.com/video/BV1h84y1D7u5/?spm_id_from=333.999.0.0">this https URL</a>&amp;vd_source=0af61c122e5e37c944053b57e313025a
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">3D coverage path planning for UAVs is a crucial problem in diverse practical
applications. However, existing methods have shown unsatisfactory system
simplicity, computation efficiency, and path quality in large and complex
scenes. To address these challenges, we propose FC-Planner, a skeleton-guided
planning framework that can achieve fast aerial coverage of complex 3D scenes
without pre-processing. We decompose the scene into several simple subspaces by
a skeleton-based space decomposition (SSD). Additionally, the skeleton guides
us to effortlessly determine free space. We utilize the skeleton to efficiently
generate a minimal set of specialized and informative viewpoints for complete
coverage. Based on SSD, a hierarchical planner effectively divides the large
planning problem into independent sub-problems, enabling parallel planning for
each subspace. The carefully designed global and local planning strategies are
then incorporated to guarantee both high quality and efficiency in path
generation. We conduct extensive benchmark and real-world tests, where
FC-Planner computes over 10 times faster compared to state-of-the-art methods
with shorter path and more complete coverage. The source code will be open at
https://github.com/HKUST-Aerial-Robotics/FC-Planner.
</p>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13884" title="Abstract">arXiv:2309.13884</a> [<a href="/pdf/2309.13884" title="Download PDF">pdf</a>, <a href="/format/2309.13884" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimating Treatment Effects Under Heterogeneous Interference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaofeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Guoxi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaotian Lu</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Han Bao</a>, 
<a href="/search/cs?searchtype=author&query=Takeuchi%2C+K">Koh Takeuchi</a>, 
<a href="/search/cs?searchtype=author&query=Kashima%2C+H">Hisashi Kashima</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> September 2023, European Conference on Machine Learning and
  Principles and Practice of Knowledge Discovery in Databases
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Treatment effect estimation can assist in effective decision-making in
e-commerce, medicine, and education. One popular application of this estimation
lies in the prediction of the impact of a treatment (e.g., a promotion) on an
outcome (e.g., sales) of a particular unit (e.g., an item), known as the
individual treatment effect (ITE). In many online applications, the outcome of
a unit can be affected by the treatments of other units, as units are often
associated, which is referred to as interference. For example, on an online
shopping website, sales of an item will be influenced by an advertisement of
its co-purchased item. Prior studies have attempted to model interference to
estimate the ITE accurately, but they often assume a homogeneous interference,
i.e., relationships between units only have a single view. However, in
real-world applications, interference may be heterogeneous, with multi-view
relationships. For instance, the sale of an item is usually affected by the
treatment of its co-purchased and co-viewed items. We hypothesize that ITE
estimation will be inaccurate if this heterogeneous interference is not
properly modeled. Therefore, we propose a novel approach to model heterogeneous
interference by developing a new architecture to aggregate information from
diverse neighbors. Our proposed method contains graph neural networks that
aggregate same-view information, a mechanism that aggregates information from
different views, and attention mechanisms. In our experiments on multiple
datasets with heterogeneous interference, the proposed method significantly
outperforms existing methods for ITE estimation, confirming the importance of
modeling heterogeneous interference.
</p>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13885" title="Abstract">arXiv:2309.13885</a> [<a href="/pdf/2309.13885" title="Download PDF">pdf</a>, <a href="/format/2309.13885" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TouchUp-G: Improving Feature Representation through Graph-Centric  Finetuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jing Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiang Song</a>, 
<a href="/search/cs?searchtype=author&query=Ioannidis%2C+V+N">Vassilis N. Ioannidis</a>, 
<a href="/search/cs?searchtype=author&query=Koutra%2C+D">Danai Koutra</a>, 
<a href="/search/cs?searchtype=author&query=Faloutsos%2C+C">Christos Faloutsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preprint, ongoing work
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">How can we enhance the node features acquired from Pretrained Models (PMs) to
better suit downstream graph learning tasks? Graph Neural Networks (GNNs) have
become the state-of-the-art approach for many high-impact, real-world graph
applications. For feature-rich graphs, a prevalent practice involves utilizing
a PM directly to generate features, without incorporating any domain adaptation
techniques. Nevertheless, this practice is suboptimal because the node features
extracted from PM are graph-agnostic and prevent GNNs from fully utilizing the
potential correlations between the graph structure and node features, leading
to a decline in GNNs performance. In this work, we seek to improve the node
features obtained from a PM for downstream graph tasks and introduce TOUCHUP-G,
which has several advantages. It is (a) General: applicable to any downstream
graph task, including link prediction which is often employed in recommender
systems; (b) Multi-modal: able to improve raw features of any modality (e.g.
images, texts, audio); (c) Principled: it is closely related to a novel metric,
feature homophily, which we propose to quantify the potential correlations
between the graph structure and node features and we show that TOUCHUP-G can
effectively shrink the discrepancy between the graph structure and node
features; (d) Effective: achieving state-of-the-art results on four real-world
datasets spanning different tasks and modalities.
</p>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13886" title="Abstract">arXiv:2309.13886</a> [<a href="/pdf/2309.13886" title="Download PDF">pdf</a>, <a href="/format/2309.13886" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Class-Priors Help Single-Positive Multi-Label Learning?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Biao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+N">Ning Xu</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+X">Xin Geng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Single-positive multi-label learning (SPMLL) is a typical weakly supervised
multi-label learning problem, where each training example is annotated with
only one positive label. Existing SPMLL methods typically assign pseudo-labels
to unannotated labels with the assumption that prior probabilities of all
classes are identical. However, the class-prior of each category may differ
significantly in real-world scenarios, which makes the predictive model not
perform as well as expected due to the unrealistic assumption on real-world
application. To alleviate this issue, a novel framework named {\proposed},
i.e., Class-pRiors Induced Single-Positive multi-label learning, is proposed.
Specifically, a class-priors estimator is introduced, which could estimate the
class-priors that are theoretically guaranteed to converge to the ground-truth
class-priors. In addition, based on the estimated class-priors, an unbiased
risk estimator for classification is derived, and the corresponding risk
minimizer could be guaranteed to approximately converge to the optimal risk
minimizer on fully supervised data. Experimental results on ten MLL benchmark
datasets demonstrate the effectiveness and superiority of our method over
existing SPMLL approaches.
</p>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13888" title="Abstract">arXiv:2309.13888</a> [<a href="/pdf/2309.13888" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Representation Learning Towards Patents Network Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heydari%2C+M">Mohammad Heydari</a>, 
<a href="/search/cs?searchtype=author&query=Teimourpour%2C+B">Babak Teimourpour</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 Pages, 12 Figures, 7 Tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Patent analysis has recently been recognized as a powerful technique for
large companies worldwide to lend them insight into the age of competition
among various industries. This technique is considered a shortcut for
developing countries since it can significantly accelerate their technology
development. Therefore, as an inevitable process, patent analysis can be
utilized to monitor rival companies and diverse industries. This research
employed a graph representation learning approach to create, analyze, and find
similarities in the patent data registered in the Iranian Official Gazette. The
patent records were scrapped and wrangled through the Iranian Official Gazette
portal. Afterward, the key entities were extracted from the scrapped patents
dataset to create the Iranian patents graph from scratch based on novel natural
language processing and entity resolution techniques. Finally, thanks to the
utilization of novel graph algorithms and text mining methods, we identified
new areas of industry and research from Iranian patent data, which can be used
extensively to prevent duplicate patents, familiarity with similar and
connected inventions, Awareness of legal entities supporting patents and
knowledge of researchers and linked stakeholders in a particular research
field.
</p>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13889" title="Abstract">arXiv:2309.13889</a> [<a href="/pdf/2309.13889" title="Download PDF">pdf</a>, <a href="/ps/2309.13889" title="Download PostScript">ps</a>, <a href="/format/2309.13889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resilient State Estimation for Nonlinear Discrete-Time Systems via Input  and State Interval Observer Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khajenejad%2C+M">Mohammad Khajenejad</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Z">Zeyuan Jin</a>, 
<a href="/search/eess?searchtype=author&query=Dinh%2C+T+N">Thach Ngoc Dinh</a>, 
<a href="/search/eess?searchtype=author&query=Yong%2C+S+Z">Sze Zheng Yong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper addresses the problem of resilient state estimation and attack
reconstruction for bounded-error nonlinear discrete-time systems with nonlinear
observations/ constraints, where both sensors and actuators can be compromised
by false data injection attack signals/unknown inputs. By leveraging
mixed-monotone decomposition of nonlinear functions, as well as affine parallel
outer-approximation of the observation functions, along with introducing
auxiliary states to cancel out the effect of the attacks/unknown inputs, our
proposed observer recursively computes interval estimates that by construction,
contain the true states and unknown inputs of the system. Moreover, we provide
several semi-definite programs to synthesize observer gains to ensure
input-to-state stability of the proposed observer and optimality of the design
in the sense of minimum $\mathcal{H}_{\infty}$ gain.
</p>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13890" title="Abstract">arXiv:2309.13890</a> [<a href="/pdf/2309.13890" title="Download PDF">pdf</a>, <a href="/format/2309.13890" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bitstream-Corrupted Video Recovery: A Novel Benchmark Dataset and Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Tianyi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kejun Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yap%2C+K">Kim-Hui Yap</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+L">Lap-Pui Chau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS Dataset and Benchmark Track 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">The past decade has witnessed great strides in video recovery by specialist
technologies, like video inpainting, completion, and error concealment.
However, they typically simulate the missing content by manual-designed error
masks, thus failing to fill in the realistic video loss in video communication
(e.g., telepresence, live streaming, and internet video) and multimedia
forensics. To address this, we introduce the bitstream-corrupted video (BSCV)
benchmark, the first benchmark dataset with more than 28,000 video clips, which
can be used for bitstream-corrupted video recovery in the real world. The BSCV
is a collection of 1) a proposed three-parameter corruption model for video
bitstream, 2) a large-scale dataset containing rich error patterns, multiple
corruption levels, and flexible dataset branches, and 3) a plug-and-play module
in video recovery framework that serves as a benchmark. We evaluate
state-of-the-art video inpainting methods on the BSCV dataset, demonstrating
existing approaches' limitations and our framework's advantages in solving the
bitstream-corrupted video recovery problem. The benchmark and dataset are
released at https://github.com/LIUTIGHE/BSCV-Dataset.
</p>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13893" title="Abstract">arXiv:2309.13893</a> [<a href="/pdf/2309.13893" title="Download PDF">pdf</a>, <a href="/format/2309.13893" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scene Informer: Anchor-based Occlusion Inference and Trajectory  Prediction in Partially Observable Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lange%2C+B">Bernard Lange</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Kochenderfer%2C+M+J">Mykel J. Kochenderfer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Navigating complex and dynamic environments requires autonomous vehicles
(AVs) to reason about both visible and occluded regions. This involves
predicting the future motion of observed agents, inferring occluded ones, and
modeling their interactions based on vectorized scene representations of the
partially observable environment. However, prior work on occlusion inference
and trajectory prediction have developed in isolation, with the former based on
simplified rasterized methods and the latter assuming full environment
observability. We introduce the Scene Informer, a unified approach for
predicting both observed agent trajectories and inferring occlusions in a
partially observable setting. It uses a transformer to aggregate various input
modalities and facilitate selective queries on occlusions that might intersect
with the AV's planned path. The framework estimates occupancy probabilities and
likely trajectories for occlusions, as well as forecast motion for observed
agents. We explore common observability assumptions in both domains and their
performance impact. Our approach outperforms existing methods in both occupancy
prediction and trajectory prediction in partially observable setting on the
Waymo Open Motion Dataset.
</p>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13896" title="Abstract">arXiv:2309.13896</a> [<a href="/pdf/2309.13896" title="Download PDF">pdf</a>, <a href="/format/2309.13896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Follow-ups Also Matter: Improving Contextual Bandits via Post-serving  Contexts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaoqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Ziyu Ye</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zhe Feng</a>, 
<a href="/search/cs?searchtype=author&query=Badanidiyuru%2C+A">Ashwinkumar Badanidiyuru</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Haifeng Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 (Spotlight)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Standard contextual bandit problem assumes that all the relevant contexts are
observed before the algorithm chooses an arm. This modeling paradigm, while
useful, often falls short when dealing with problems in which valuable
additional context can be observed after arm selection. For example, content
recommendation platforms like Youtube, Instagram, Tiktok also observe valuable
follow-up information pertinent to the user's reward after recommendation
(e.g., how long the user stayed, what is the user's watch speed, etc.). To
improve online learning efficiency in these applications, we study a novel
contextual bandit problem with post-serving contexts and design a new
algorithm, poLinUCB, that achieves tight regret under standard assumptions.
Core to our technical proof is a robustified and generalized version of the
well-known Elliptical Potential Lemma (EPL), which can accommodate noise in
data. Such robustification is necessary for tackling our problem, and we
believe it could also be of general interest. Extensive empirical tests on both
synthetic and real-world datasets demonstrate the significant benefit of
utilizing post-serving contexts as well as the superior performance of our
algorithm over the state-of-the-art approaches.
</p>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13897" title="Abstract">arXiv:2309.13897</a> [<a href="/pdf/2309.13897" title="Download PDF">pdf</a>, <a href="/format/2309.13897" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Error Distribution for One-Dimensional Stochastic Differential Equation  Driven By Fractional Brownian Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ueda%2C+K">Kento Ueda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 55 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Probability (math.PR)

</div>
<p class="mathjax">We can define the error distribution as the limiting distribution of the
error between the solution $Y$ of a given stochastic differential equation
(SDE) and its numerical approximation $\hat{Y}^{(m)}$, weighted by the
convergence rate between the two. A goal when studying the error distribution
is to provide a way of determination for error distributions for any SDE and
numerical scheme that converge to the exact solution. By dividing the error
into a main term and a remainder term in a particular way, the author shows
that the remainder term can be negligible compared to the main term under
certain suitable conditions. Under these conditions, deriving the error
distribution reduces to deriving the limiting distribution of the main term.
Even if the dimension is one, there are unsolved problems about the asymptotic
behavior of the error when the SDE has a drift term and $0&lt;H\leq 1/3$, but our
result in the one-dimensional case can be adapted to any Hurst exponent. The
main idea of the proof is to define a stochastic process $Y^{m, \rho}$ with the
parameter $\rho$ interpolating between $Y$ and $\hat{Y}^{(m)}$ and to estimate
the asymptotic expansion for it. Using this estimate, we determine the error
distribution of the ($k$)-Milstein scheme and of the Crank-Nicholson scheme in
unsolved cases.
</p>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13903" title="Abstract">arXiv:2309.13903</a> [<a href="/pdf/2309.13903" title="Download PDF">pdf</a>, <a href="/format/2309.13903" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invariant Smoothing for Localization: Including the IMU Biases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chauchat%2C+P">Paul Chauchat</a> (AMU SCI, AMU, LIS), 
<a href="/search/cs?searchtype=author&query=Bonnabel%2C+S">Silv&#xe8;re Bonnabel</a> (CAOR), 
<a href="/search/cs?searchtype=author&query=Barrau%2C+A">Axel Barrau</a> (CAOR)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this article we investigate smoothing (i.e., optimisation-based)
estimation techniques for robot localization using an IMU aided by other
localization sensors. We more particularly focus on Invariant Smoothing (IS), a
variant based on the use of nontrivial Lie groups from robotics. We study the
recently introduced Two Frames Group (TFG), and prove it can fit into the
framework of Invariant Smoothing in order to better take into account the IMU
biases, as compared to the state-of-the-art in robotics. Experiments based on
the KITTI dataset show the proposed framework compares favorably to the
state-of-the-art smoothing methods in terms of robustness in some challenging
situations.
</p>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13904" title="Abstract">arXiv:2309.13904</a> [<a href="/pdf/2309.13904" title="Download PDF">pdf</a>, <a href="/format/2309.13904" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Subspace-Aware Feature Reconstruction for Unsupervised Anomaly  Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hotta%2C+K">Katsuya Hotta</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hagihara%2C+Y">Yoshihiro Hagihara</a>, 
<a href="/search/cs?searchtype=author&query=Akashi%2C+T">Takuya Akashi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised anomaly localization, which plays a critical role in industrial
manufacturing, is to identify anomalous regions that deviate from patterns
established exclusively from nominal samples. Recent mainstream methods focus
on approximating the target feature distribution by leveraging embeddings from
ImageNet models. However, a common issue in many anomaly localization methods
is the lack of adaptability of the feature approximations to specific targets.
Consequently, their ability to effectively identify anomalous regions relies
significantly on the data coverage provided by the finite resources in a memory
bank. In this paper, we propose a novel subspace-aware feature reconstruction
framework for anomaly localization. To achieve adaptive feature approximation,
our proposed method involves the reconstruction of the feature representation
through the self-expressive model designed to learn low-dimensional subspaces.
Importantly, the sparsity of the subspace representation contributes to
covering feature patterns from the same subspace with fewer resources, leading
to a reduction in the memory bank. Extensive experiments across three
industrial benchmark datasets demonstrate that our approach achieves
competitive anomaly localization performance compared to state-of-the-art
methods by adaptively reconstructing target features with a small number of
samples.
</p>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13907" title="Abstract">arXiv:2309.13907</a> [<a href="/pdf/2309.13907" title="Download PDF">pdf</a>, <a href="/format/2309.13907" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for  Expressive Long-form TTS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Dake Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xinfa Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+L">Liumeng Xue</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tao Li</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+Y">Yuanjun Lv</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuepeng Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+L">Lei Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent advances in text-to-speech, particularly those based on Graph Neural
Networks (GNNs), have significantly improved the expressiveness of short-form
synthetic speech. However, generating human-parity long-form speech with high
dynamic prosodic variations is still challenging. To address this problem, we
expand the capabilities of GNNs with a hierarchical prosody modeling approach,
named HiGNN-TTS. Specifically, we add a virtual global node in the graph to
strengthen the interconnection of word nodes and introduce a contextual
attention mechanism to broaden the prosody modeling scope of GNNs from
intra-sentence to inter-sentence. Additionally, we perform hierarchical
supervision from acoustic prosody on each node of the graph to capture the
prosodic variations with a high dynamic range. Ablation studies show the
effectiveness of HiGNN-TTS in learning hierarchical prosody. Both objective and
subjective evaluations demonstrate that HiGNN-TTS significantly improves the
naturalness and expressiveness of long-form synthetic speech
</p>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13908" title="Abstract">arXiv:2309.13908</a> [<a href="/pdf/2309.13908" title="Download PDF">pdf</a>, <a href="/format/2309.13908" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparison of controller architectures and learning mechanisms for  arbitrary robot morphologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Luo%2C+J">Jie Luo</a>, 
<a href="/search/cs?searchtype=author&query=Tomczak%2C+J">Jakub Tomczak</a>, 
<a href="/search/cs?searchtype=author&query=Miras%2C+K">Karine Miras</a>, 
<a href="/search/cs?searchtype=author&query=Eiben%2C+A+E">Agoston E. Eiben</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">The main question this paper addresses is: What combination of a robot
controller and a learning method should be used, if the morphology of the
learning robot is not known in advance? Our interest is rooted in the context
of morphologically evolving modular robots, but the question is also relevant
in general, for system designers interested in widely applicable solutions. We
perform an experimental comparison of three controller-and-learner
combinations: one approach where controllers are based on modelling animal
locomotion (Central Pattern Generators, CPG) and the learner is an evolutionary
algorithm, a completely different method using Reinforcement Learning (RL) with
a neural network controller architecture, and a combination `in-between' where
controllers are neural networks and the learner is an evolutionary algorithm.
We apply these three combinations to a test suite of modular robots and compare
their efficacy, efficiency, and robustness. Surprisingly, the usual CPG-based
and RL-based options are outperformed by the in-between combination that is
more robust and efficient than the other two setups.
</p>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13909" title="Abstract">arXiv:2309.13909</a> [<a href="/pdf/2309.13909" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinese herb medicine in augmented reality
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Q">Qianyun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yifeng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+F">Fangyang Ye</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhenyuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Che%2C+B">Binjie Che</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhenglin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dongmei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Augmented reality becomes popular in education gradually, which provides a
contextual and adaptive learning experience. Here, we develop a Chinese herb
medicine AR platform based the 3dsMax and the Unity that allows users to
visualize and interact with the herb model and learn the related information.
The users use their mobile camera to scan the 2D herb picture to trigger the
presentation of 3D AR model and corresponding text information on the screen in
real-time. The system shows good performance and has high accuracy for the
identification of herbal medicine after interference test and occlusion test.
Users can interact with the herb AR model by rotating, scaling, and viewing
transformation, which effectively enhances learners' interest in Chinese herb
medicine.
</p>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13914" title="Abstract">arXiv:2309.13914</a> [<a href="/pdf/2309.13914" title="Download PDF">pdf</a>, <a href="/format/2309.13914" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Factorization in Tropical and Mixed Tropical-Linear Algebras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kordonis%2C+I">Ioannis Kordonis</a>, 
<a href="/search/cs?searchtype=author&query=Theodosis%2C+E">Emmanouil Theodosis</a>, 
<a href="/search/cs?searchtype=author&query=Retsinas%2C+G">George Retsinas</a>, 
<a href="/search/cs?searchtype=author&query=Maragos%2C+P">Petros Maragos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Matrix Factorization (MF) has found numerous applications in Machine Learning
and Data Mining, including collaborative filtering recommendation systems,
dimensionality reduction, data visualization, and community detection.
Motivated by the recent successes of tropical algebra and geometry in machine
learning, we investigate two problems involving matrix factorization over the
tropical algebra. For the first problem, Tropical Matrix Factorization (TMF),
which has been studied already in the literature, we propose an improved
algorithm that avoids many of the local optima. The second formulation
considers the approximate decomposition of a given matrix into the product of
three matrices where a usual matrix product is followed by a tropical product.
This formulation has a very interesting interpretation in terms of the learning
of the utility functions of multiple users. We also present numerical results
illustrating the effectiveness of the proposed algorithms, as well as an
application to recommendation systems with promising results.
</p>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13915" title="Abstract">arXiv:2309.13915</a> [<a href="/pdf/2309.13915" title="Download PDF">pdf</a>, <a href="/format/2309.13915" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sample Complexity of Neural Policy Mirror Descent for Policy  Optimization on Low-Dimensional Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhenghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+X">Xiang Ji</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Minshuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+T">Tuo Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Policy-based algorithms equipped with deep neural networks have achieved
great success in solving high-dimensional policy optimization problems in
reinforcement learning. However, current analyses cannot explain why they are
resistant to the curse of dimensionality. In this work, we study the sample
complexity of the neural policy mirror descent (NPMD) algorithm with
convolutional neural networks (CNN) as function approximators. Motivated by the
empirical observation that many high-dimensional environments have state spaces
possessing low-dimensional structures, such as those taking images as states,
we consider the state space to be a $d$-dimensional manifold embedded in the
$D$-dimensional Euclidean space with intrinsic dimension $d\ll D$. We show that
in each iteration of NPMD, both the value function and the policy can be well
approximated by CNNs. The approximation errors are controlled by the size of
the networks, and the smoothness of the previous networks can be inherited. As
a result, by properly choosing the network size and hyperparameters, NPMD can
find an $\epsilon$-optimal policy with
$\widetilde{O}(\epsilon^{-\frac{d}{\alpha}-2})$ samples in expectation, where
$\alpha\in(0,1]$ indicates the smoothness of environment. Compared to previous
work, our result exhibits that NPMD can leverage the low-dimensional structure
of state space to escape from the curse of dimensionality, providing an
explanation for the efficacy of deep policy-based algorithms.
</p>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13920" title="Abstract">arXiv:2309.13920</a> [<a href="/pdf/2309.13920" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Real-Time Emergency Vehicle Detection using Mel Spectrograms and Regular  Expressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pacheco-Gonzalez%2C+A">Alberto Pacheco-Gonzalez</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+R">Raymundo Torres</a>, 
<a href="/search/cs?searchtype=author&query=Chacon%2C+R">Raul Chacon</a>, 
<a href="/search/cs?searchtype=author&query=Robledo%2C+I">Isidro Robledo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> in Spanish language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Symbolic Computation (cs.SC); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In emergency situations, the movement of vehicles through city streets can be
problematic due to vehicular traffic. This paper presents a method for
detecting emergency vehicle sirens in real time. To derive a siren Hi-Lo audio
fingerprint it was necessary to apply digital signal processing techniques and
signal symbolization, contrasting against a deep neural network audio
classifier feeding 280 environmental sounds and 38 Hi-Lo sirens. In both
methods, their precision was evaluated based on a confusion matrix and various
metrics. The precision of the developed DSP algorithm presented a greater
ability to discriminate between signal and noise, compared to the CNN model.
</p>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13924" title="Abstract">arXiv:2309.13924</a> [<a href="/pdf/2309.13924" title="Download PDF">pdf</a>, <a href="/format/2309.13924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recursive Counterfactual Deconfounding for Object Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiayin Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Q">Qiulei Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image recognition is a classic and common task in the computer vision field,
which has been widely applied in the past decade. Most existing methods in
literature aim to learn discriminative features from labeled images for
classification, however, they generally neglect confounders that infiltrate
into the learned features, resulting in low performances for discriminating
test images. To address this problem, we propose a Recursive Counterfactual
Deconfounding model for object recognition in both closed-set and open-set
scenarios based on counterfactual analysis, called RCD. The proposed model
consists of a factual graph and a counterfactual graph, where the relationships
among image features, model predictions, and confounders are built and updated
recursively for learning more discriminative features. It performs in a
recursive manner so that subtler counterfactual features could be learned and
eliminated progressively, and both the discriminability and generalization of
the proposed model could be improved accordingly. In addition, a negative
correlation constraint is designed for alleviating the negative effects of the
counterfactual features further at the model training stage. Extensive
experimental results on both closed-set recognition task and open-set
recognition task demonstrate that the proposed RCD model performs better than
11 state-of-the-art baselines significantly in most cases.
</p>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13925" title="Abstract">arXiv:2309.13925</a> [<a href="/pdf/2309.13925" title="Download PDF">pdf</a>, <a href="/format/2309.13925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UCF-Crime Annotation: A Benchmark for Surveillance Video-and-Language  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+T">Tongtong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xuange Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+J">Jian Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+Z">Zhenzhen Jiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Surveillance videos are an essential component of daily life with various
critical applications, particularly in public security. However, current
surveillance video tasks mainly focus on classifying and localizing anomalous
events. Existing methods are limited to detecting and classifying the
predefined events with unsatisfactory generalization ability and semantic
understanding, although they have obtained considerable performance. To address
this issue, we propose constructing the first multimodal surveillance video
dataset by manually annotating the real-world surveillance dataset UCF-Crime
with fine-grained event content and timing. Our newly annotated dataset, UCA
(UCF-Crime Annotation), provides a novel benchmark for multimodal surveillance
video analysis. It not only describes events in detailed descriptions but also
provides precise temporal grounding of the events in 0.1-second intervals. UCA
contains 20,822 sentences, with an average length of 23 words, and its
annotated videos are as long as 102 hours. Furthermore, we benchmark the
state-of-the-art models of multiple multimodal tasks on this newly created
dataset, including temporal sentence grounding in videos, video captioning, and
dense video captioning. Through our experiments, we found that mainstream
models used in previously publicly available datasets perform poorly on
multimodal surveillance video scenarios, which highlights the necessity of
constructing this dataset. The link to our dataset and code is provided at:
https://github.com/Xuange923/UCA-dataset.
</p>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13926" title="Abstract">arXiv:2309.13926</a> [<a href="/pdf/2309.13926" title="Download PDF">pdf</a>, <a href="/ps/2309.13926" title="Download PostScript">ps</a>, <a href="/format/2309.13926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pseudo Label Selection is a Decision Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rodemann%2C+J">Julian Rodemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 46th German Conference on Artificial Intelligence
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME); Machine Learning (stat.ML)

</div>
<p class="mathjax">Pseudo-Labeling is a simple and effective approach to semi-supervised
learning. It requires criteria that guide the selection of pseudo-labeled data.
The latter have been shown to crucially affect pseudo-labeling's generalization
performance. Several such criteria exist and were proven to work reasonably
well in practice. However, their performance often depends on the initial model
fit on labeled data. Early overfitting can be propagated to the final model by
choosing instances with overconfident but wrong predictions, often called
confirmation bias. In two recent works, we demonstrate that pseudo-label
selection (PLS) can be naturally embedded into decision theory. This paves the
way for BPLS, a Bayesian framework for PLS that mitigates the issue of
confirmation bias. At its heart is a novel selection criterion: an analytical
approximation of the posterior predictive of pseudo-samples and labeled data.
We derive this selection criterion by proving Bayes-optimality of this "pseudo
posterior predictive". We empirically assess BPLS for generalized linear,
non-parametric generalized additive models and Bayesian neural networks on
simulated and real-world data. When faced with data prone to overfitting and
thus a high chance of confirmation bias, BPLS outperforms traditional PLS
methods. The decision-theoretic embedding further allows us to render PLS more
robust towards the involved modeling assumptions. To achieve this goal, we
introduce a multi-objective utility function. We demonstrate that the latter
can be constructed to account for different sources of uncertainty and explore
three examples: model selection, accumulation of errors and covariate shift.
</p>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13930" title="Abstract">arXiv:2309.13930</a> [<a href="/pdf/2309.13930" title="Download PDF">pdf</a>, <a href="/format/2309.13930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMN: A Sample Attention Memory Network Combining SVM and NN in One  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Q">Qiaoling Yang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+L">Linkai Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Haoyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hong Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Ziyang Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Support vector machine (SVM) and neural networks (NN) have strong
complementarity. SVM focuses on the inner operation among samples while NN
focuses on the operation among the features within samples. Thus, it is
promising and attractive to combine SVM and NN, as it may provide a more
powerful function than SVM or NN alone. However, current work on combining them
lacks true integration. To address this, we propose a sample attention memory
network (SAMN) that effectively combines SVM and NN by incorporating sample
attention module, class prototypes, and memory block to NN. SVM can be viewed
as a sample attention machine. It allows us to add a sample attention module to
NN to implement the main function of SVM. Class prototypes are representatives
of all classes, which can be viewed as alternatives to support vectors. The
memory block is used for the storage and update of class prototypes. Class
prototypes and memory block effectively reduce the computational cost of sample
attention and make SAMN suitable for multi-classification tasks. Extensive
experiments show that SAMN achieves better classification performance than
single SVM or single NN with similar parameter sizes, as well as the previous
best model for combining SVM and NN. The sample attention mechanism is a
flexible module that can be easily deepened and incorporated into neural
networks that require it.
</p>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13933" title="Abstract">arXiv:2309.13933</a> [<a href="/pdf/2309.13933" title="Download PDF">pdf</a>, <a href="/format/2309.13933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fairness and Bias in Algorithmic Hiring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fabris%2C+A">Alessandro Fabris</a>, 
<a href="/search/cs?searchtype=author&query=Baranowska%2C+N">Nina Baranowska</a>, 
<a href="/search/cs?searchtype=author&query=Dennis%2C+M+J">Matthew J. Dennis</a>, 
<a href="/search/cs?searchtype=author&query=Hacker%2C+P">Philipp Hacker</a>, 
<a href="/search/cs?searchtype=author&query=Saldivar%2C+J">Jorge Saldivar</a>, 
<a href="/search/cs?searchtype=author&query=Borgesius%2C+F+Z">Frederik Zuiderveen Borgesius</a>, 
<a href="/search/cs?searchtype=author&query=Biega%2C+A+J">Asia J. Biega</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Employers are adopting algorithmic hiring technology throughout the
recruitment pipeline. Algorithmic fairness is especially applicable in this
domain due to its high stakes and structural inequalities. Unfortunately, most
work in this space provides partial treatment, often constrained by two
competing narratives, optimistically focused on replacing biased recruiter
decisions or pessimistically pointing to the automation of discrimination.
Whether, and more importantly what types of, algorithmic hiring can be less
biased and more beneficial to society than low-tech alternatives currently
remains unanswered, to the detriment of trustworthiness. This multidisciplinary
survey caters to practitioners and researchers with a balanced and integrated
coverage of systems, biases, measures, mitigation strategies, datasets, and
legal aspects of algorithmic hiring and fairness. Our work supports a
contextualized understanding and governance of this technology by highlighting
current opportunities and limitations, providing recommendations for future
work to ensure shared benefits for all stakeholders.
</p>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13937" title="Abstract">arXiv:2309.13937</a> [<a href="/pdf/2309.13937" title="Download PDF">pdf</a>, <a href="/format/2309.13937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPOTS: Stable Placement of Objects with Reasoning in Semi-Autonomous  Teleoperation Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Joonhyung Lee</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Sangbeom Park</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jeongeun Park</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kyungjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sungjoon Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pick-and-place is one of the fundamental tasks in robotics research. However,
the attention has been mostly focused on the ``pick'' task, leaving the
``place'' task relatively unexplored. In this paper, we address the problem of
placing objects in the context of a teleoperation framework. Particularly, we
focus on two aspects of the place task: stability robustness and contextual
reasonableness of object placements. Our proposed method combines
simulation-driven physical stability verification via real-to-sim and the
semantic reasoning capability of large language models. In other words, given
place context information (e.g., user preferences, object to place, and current
scene information), our proposed method outputs a probability distribution over
the possible placement candidates, considering the robustness and
reasonableness of the place task. Our proposed method is extensively evaluated
in two simulation and one real world environments and we show that our method
can greatly increase the physical plausibility of the placement as well as
contextual soundness while considering user preferences.
</p>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13939" title="Abstract">arXiv:2309.13939</a> [<a href="/pdf/2309.13939" title="Download PDF">pdf</a>, <a href="/format/2309.13939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Time Traveler&#x27;s Guide to Semantic Web Research: Analyzing Fictitious  Research Themes in the ESWC &quot;Next 20 Years&quot; Track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Celino%2C+I">Irene Celino</a>, 
<a href="/search/cs?searchtype=author&query=Paulheim%2C+H">Heiko Paulheim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
<p class="mathjax">What will Semantic Web research focus on in 20 years from now? We asked this
question to the community and collected their visions in the "Next 20 years"
track of ESWC 2023. We challenged the participants to submit "future" research
papers, as if they were submitting to the 2043 edition of the conference. The
submissions - entirely fictitious - were expected to be full scientific papers,
with research questions, state of the art references, experimental results and
future work, with the goal to get an idea of the research agenda for the late
2040s and early 2050s. We received ten submissions, eight of which were
accepted for presentation at the conference, that mixed serious ideas of
potential future research themes and discussion topics with some fun and irony.
<br />In this paper, we intend to provide a survey of those "science fiction"
papers, considering the emerging research themes and topics, analysing the
research methods applied by the authors in these very special submissions, and
investigating also the most fictitious parts (e.g., neologisms, fabricated
references). Our goal is twofold: on the one hand, we investigate what this
special track tells us about the Semantic Web community and, on the other hand,
we aim at getting some insights on future research practices and directions.
</p>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13940" title="Abstract">arXiv:2309.13940</a> [<a href="/pdf/2309.13940" title="Download PDF">pdf</a>, <a href="/format/2309.13940" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight Recurrent Grouping Attention Network for Video  Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yonggui Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guofang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Effective aggregation of temporal information of consecutive frames is the
core of achieving video super-resolution. Many scholars have utilized
structures such as sliding windows and recurrent to gather spatio-temporal
information of frames. However, although the performance of the constructed VSR
models is improving, the size of the models is also increasing, exacerbating
the demand on the equipment. Thus, to reduce the stress on the device, we
propose a novel lightweight recurrent grouping attention network. The
parameters of this model are only 0.878M, which is much lower than the current
mainstream model for studying video super-resolution. We design forward feature
extraction module and backward feature extraction module to collect temporal
information between consecutive frames from two directions. Moreover, a new
grouping mechanism is proposed to efficiently collect spatio-temporal
information of the reference frame and its neighboring frames. The attention
supplementation module is presented to further enhance the information
gathering range of the model. The feature reconstruction module aims to
aggregate information from different directions to reconstruct high-resolution
features. Experiments demonstrate that our model achieves state-of-the-art
performance on multiple datasets.
</p>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13942" title="Abstract">arXiv:2309.13942</a> [<a href="/pdf/2309.13942" title="Download PDF">pdf</a>, <a href="/format/2309.13942" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiangliu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiao%2C+J">Jianbo Jiao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yibing Song</a>, 
<a href="/search/cs?searchtype=author&query=James%2C+S">Stephen James</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+Z">Zhan Tong</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+C">Chongjian Ge</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yun-hui Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the CVPR 2023 Sight and Sound workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This work aims to improve unsupervised audio-visual pre-training. Inspired by
the efficacy of data augmentation in visual contrastive learning, we propose a
novel speed co-augmentation method that randomly changes the playback speeds of
both audio and video data. Despite its simplicity, the speed co-augmentation
method possesses two compelling attributes: (1) it increases the diversity of
audio-visual pairs and doubles the size of negative pairs, resulting in a
significant enhancement in the learned representations, and (2) it changes the
strict correlation between audio-visual pairs but introduces a partial
relationship between the augmented pairs, which is modeled by our proposed
SoftInfoNCE loss to further boost the performance. Experimental results show
that the proposed method significantly improves the learned representations
when compared to vanilla audio-visual contrastive learning.
</p>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13944" title="Abstract">arXiv:2309.13944</a> [<a href="/pdf/2309.13944" title="Download PDF">pdf</a>, <a href="/format/2309.13944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Provable Training for Graph Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yue Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengmei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Nian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chuan Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Graph Contrastive Learning (GCL) has emerged as a popular training approach
for learning node embeddings from augmented graphs without labels. Despite the
key principle that maximizing the similarity between positive node pairs while
minimizing it between negative node pairs is well established, some fundamental
problems are still unclear. Considering the complex graph structure, are some
nodes consistently well-trained and following this principle even with
different graph augmentations? Or are there some nodes more likely to be
untrained across graph augmentations and violate the principle? How to
distinguish these nodes and further guide the training of GCL? To answer these
questions, we first present experimental evidence showing that the training of
GCL is indeed imbalanced across all nodes. To address this problem, we propose
the metric "node compactness", which is the lower bound of how a node follows
the GCL principle related to the range of augmentations. We further derive the
form of node compactness theoretically through bound propagation, which can be
integrated into binary cross-entropy as a regularization. To this end, we
propose the PrOvable Training (POT) for GCL, which regularizes the training of
GCL to encode node embeddings that follows the GCL principle better. Through
extensive experiments on various benchmarks, POT consistently improves the
existing GCL approaches, serving as a friendly plugin.
</p>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13948" title="Abstract">arXiv:2309.13948</a> [<a href="/pdf/2309.13948" title="Download PDF">pdf</a>, <a href="/format/2309.13948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Co-Design Optimisation of Morphing Topology and Control of Winged Drones
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergonti%2C+F">Fabio Bergonti</a>, 
<a href="/search/cs?searchtype=author&query=Nava%2C+G">Gabriele Nava</a>, 
<a href="/search/cs?searchtype=author&query=W%C3%BCest%2C+V">Valentin W&#xfc;est</a>, 
<a href="/search/cs?searchtype=author&query=Paolino%2C+A">Antonello Paolino</a>, 
<a href="/search/cs?searchtype=author&query=L%27Erario%2C+G">Giuseppe L&#x27;Erario</a>, 
<a href="/search/cs?searchtype=author&query=Pucci%2C+D">Daniele Pucci</a>, 
<a href="/search/cs?searchtype=author&query=Floreano%2C+D">Dario Floreano</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The design and control of winged aircraft and drones is an iterative process
aimed at identifying a compromise of mission-specific costs and constraints.
When agility is required, shape-shifting (morphing) drones represent an
efficient solution. However, morphing drones require the addition of actuated
joints that increase the topology and control coupling, making the design
process more complex. We propose a co-design optimisation method that assists
the engineers by proposing a morphing drone's conceptual design that includes
topology, actuation, morphing strategy, and controller parameters. The method
consists of applying multi-objective constraint-based optimisation to a
multi-body winged drone with trajectory optimisation to solve the motion
intelligence problem under diverse flight mission requirements. We show that
co-designed morphing drones outperform fixed-winged drones in terms of energy
efficiency and agility, suggesting that the proposed co-design method could be
a useful addition to the aircraft engineering toolbox.
</p>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13949" title="Abstract">arXiv:2309.13949</a> [<a href="/pdf/2309.13949" title="Download PDF">pdf</a>, <a href="/format/2309.13949" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterising User Transfer Amid Industrial Resource Variation: A  Bayesian Nonparametric Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lei%2C+D">Dongxu Lei</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaotian Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xinghu Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhan Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianbin Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+S">Songlin Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+H">Huijun Gao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In a multitude of industrial fields, a key objective entails optimising
resource management whilst satisfying user requirements. Resource management by
industrial practitioners can result in a passive transfer of user loads across
resource providers, a phenomenon whose accurate characterisation is both
challenging and crucial. This research reveals the existence of user clusters,
which capture macro-level user transfer patterns amid resource variation. We
then propose CLUSTER, an interpretable hierarchical Bayesian nonparametric
model capable of automating cluster identification, and thereby predicting user
transfer in response to resource variation. Furthermore, CLUSTER facilitates
uncertainty quantification for further reliable decision-making. Our method
enables privacy protection by functioning independently of personally
identifiable information. Experiments with simulated and real-world data from
the communications industry reveal a pronounced alignment between prediction
results and empirical observations across a spectrum of resource management
scenarios. This research establishes a solid groundwork for advancing resource
management strategy development.
</p>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13950" title="Abstract">arXiv:2309.13950</a> [<a href="/pdf/2309.13950" title="Download PDF">pdf</a>, <a href="/format/2309.13950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local and Global Trend Bayesian Exponential Smoothing Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smyl%2C+S">Slawek Smyl</a>, 
<a href="/search/cs?searchtype=author&query=Bergmeir%2C+C">Christoph Bergmeir</a>, 
<a href="/search/cs?searchtype=author&query=Dokumentov%2C+A">Alexander Dokumentov</a>, 
<a href="/search/cs?searchtype=author&query=Wibowo%2C+E">Erwin Wibowo</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+D">Daniel Schmidt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">This paper describes a family of seasonal and non-seasonal time series models
that can be viewed as generalisations of additive and multiplicative
exponential smoothing models. Their development is motivated by fast-growing,
volatile time series, and facilitated by state-of-the-art Bayesian fitting
techniques. When applied to the M3 competition data set, they outperform the
best algorithms in the competition as well as other benchmarks, thus achieving
to the best of our knowledge the best results of univariate methods on this
dataset in the literature.
</p>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13952" title="Abstract">arXiv:2309.13952</a> [<a href="/pdf/2309.13952" title="Download PDF">pdf</a>, <a href="/format/2309.13952" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VidChapters-7M: Video Chapters at Scale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+A">Antoine Yang</a>, 
<a href="/search/cs?searchtype=author&query=Nagrani%2C+A">Arsha Nagrani</a>, 
<a href="/search/cs?searchtype=author&query=Laptev%2C+I">Ivan Laptev</a>, 
<a href="/search/cs?searchtype=author&query=Sivic%2C+J">Josef Sivic</a>, 
<a href="/search/cs?searchtype=author&query=Schmid%2C+C">Cordelia Schmid</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Track on Datasets and Benchmarks; Project Webpage: <a href="https://antoyang.github.io/vidchapters.html">this https URL</a> ; 31 pages; 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
<p class="mathjax">Segmenting long videos into chapters enables users to quickly navigate to the
information of their interest. This important topic has been understudied due
to the lack of publicly released datasets. To address this issue, we present
VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters
in total. VidChapters-7M is automatically created from videos online in a
scalable manner by scraping user-annotated chapters and hence without any
additional manual annotation. We introduce the following three tasks based on
this data. First, the video chapter generation task consists of temporally
segmenting the video and generating a chapter title for each segment. To
further dissect the problem, we also define two variants of this task: video
chapter generation given ground-truth boundaries, which requires generating a
chapter title given an annotated video segment, and video chapter grounding,
which requires temporally localizing a chapter given its annotated title. We
benchmark both simple baselines and state-of-the-art video-language models for
these three tasks. We also show that pretraining on VidChapters-7M transfers
well to dense video captioning tasks in both zero-shot and finetuning settings,
largely improving the state of the art on the YouCook2 and ViTT benchmarks.
Finally, our experiments reveal that downstream performance scales well with
the size of the pretraining dataset. Our dataset, code, and models are publicly
available at https://antoyang.github.io/vidchapters.html.
</p>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13954" title="Abstract">arXiv:2309.13954</a> [<a href="/pdf/2309.13954" title="Download PDF">pdf</a>, <a href="/ps/2309.13954" title="Download PostScript">ps</a>, <a href="/format/2309.13954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Implicit-type order-adaptive CAT2 schemes for systems of balance  laws with relaxed source term
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Macca%2C+E">E. Macca</a>, 
<a href="/search/math?searchtype=author&query=Boscarino%2C+S">S. Boscarino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present two semi-implicit-type second order Compact
Approximate Taylor (CAT2) numerical schemes and blend them with a local a
posteriori Multi-dimensional Optimal Order Detection (MOOD) paradigm to solve
hyperbolic systems of balance laws with relaxed source term. The resulting
scheme presents high accuracy when applied to smooth solutions, essentially
non-oscillatory behavior for irregular ones, and offers a nearly fail-safe
property in terms of ensuring positivity. The numerical results obtained from a
variety of test cases, including smooth and non-smooth well-prepared and
unprepared initial condition, assessing the appropriate behavior of the
semi-implicit-type second order CATMOOD schemes. These results have been
compared in accuracy and efficiency with a second order semi-implicit
Runge-Kutta (RK) method.
</p>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13955" title="Abstract">arXiv:2309.13955</a> [<a href="/pdf/2309.13955" title="Download PDF">pdf</a>, <a href="/format/2309.13955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for the Heat Transfer Control of Pulsating  Impinging Jets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Salavatidezfouli%2C+S">Sajad Salavatidezfouli</a>, 
<a href="/search/math?searchtype=author&query=Stabile%2C+G">Giovanni Stabile</a>, 
<a href="/search/math?searchtype=author&query=Rozza%2C+G">Gianluigi Rozza</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This research study explores the applicability of Deep Reinforcement Learning
(DRL) for thermal control based on Computational Fluid Dynamics. To accomplish
that, the forced convection on a hot plate prone to a pulsating cooling jet
with variable velocity has been investigated. We begin with evaluating the
efficiency and viability of a vanilla Deep Q-Network (DQN) method for thermal
control. Subsequently, a comprehensive comparison between different variants of
DRL is conducted. Soft Double and Duel DQN achieved better thermal control
performance among all the variants due to their efficient learning and action
prioritization capabilities. Results demonstrate that the soft Double DQN
outperforms the hard Double DQN. Moreover, soft Double and Duel can maintain
the temperature in the desired threshold for more than 98% of the control
cycle. These findings demonstrate the promising potential of DRL in effectively
addressing thermal control systems.
</p>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13956" title="Abstract">arXiv:2309.13956</a> [<a href="/pdf/2309.13956" title="Download PDF">pdf</a>, <a href="/format/2309.13956" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> In-Domain GAN Inversion for Faithful Reconstruction and Editability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiapeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yinghao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bolei Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Generative Adversarial Networks (GANs) have significantly advanced image
synthesis through mapping randomly sampled latent codes to high-fidelity
synthesized images. However, applying well-trained GANs to real image editing
remains challenging. A common solution is to find an approximate latent code
that can adequately recover the input image to edit, which is also known as GAN
inversion. To invert a GAN model, prior works typically focus on reconstructing
the target image at the pixel level, yet few studies are conducted on whether
the inverted result can well support manipulation at the semantic level. This
work fills in this gap by proposing in-domain GAN inversion, which consists of
a domain-guided encoder and a domain-regularized optimizer, to regularize the
inverted code in the native latent space of the pre-trained GAN model. In this
way, we manage to sufficiently reuse the knowledge learned by GANs for image
reconstruction, facilitating a wide range of editing applications without any
retraining. We further make comprehensive analyses on the effects of the
encoder structure, the starting inversion point, as well as the inversion
parameter space, and observe the trade-off between the reconstruction quality
and the editing property. Such a trade-off sheds light on how a GAN model
represents an image with various semantics encoded in the learned latent
distribution. Code, models, and demo are available at the project page:
https://genforce.github.io/idinvert/.
</p>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13960" title="Abstract">arXiv:2309.13960</a> [<a href="/pdf/2309.13960" title="Download PDF">pdf</a>, <a href="/format/2309.13960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Newton Method-based Subspace Support Vector Data Description
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sohrab%2C+F">Fahad Sohrab</a>, 
<a href="/search/cs?searchtype=author&query=Laakom%2C+F">Firas Laakom</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, 2 tables, 1 Algorithm. Accepted at IEEE Symposium Series on Computational Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">In this paper, we present an adaptation of Newton's method for the
optimization of Subspace Support Vector Data Description (S-SVDD). The
objective of S-SVDD is to map the original data to a subspace optimized for
one-class classification, and the iterative optimization process of data
mapping and description in S-SVDD relies on gradient descent. However, gradient
descent only utilizes first-order information, which may lead to suboptimal
results. To address this limitation, we leverage Newton's method to enhance
data mapping and data description for an improved optimization of subspace
learning-based one-class classification. By incorporating this auxiliary
information, Newton's method offers a more efficient strategy for subspace
learning in one-class classification as compared to gradient-based
optimization. The paper discusses the limitations of gradient descent and the
advantages of using Newton's method in subspace learning for one-class
classification tasks. We provide both linear and nonlinear formulations of
Newton's method-based optimization for S-SVDD. In our experiments, we explored
both the minimization and maximization strategies of the objective. The results
demonstrate that the proposed optimization strategy outperforms the
gradient-based S-SVDD in most cases.
</p>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13962" title="Abstract">arXiv:2309.13962</a> [<a href="/pdf/2309.13962" title="Download PDF">pdf</a>, <a href="/format/2309.13962" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Egocentric RGB+Depth Action Recognition in Industry-Like Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kini%2C+J">Jyoti Kini</a>, 
<a href="/search/cs?searchtype=author&query=Fleischer%2C+S">Sarah Fleischer</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+I">Ishan Dave</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Action recognition from an egocentric viewpoint is a crucial perception task
in robotics and enables a wide range of human-robot interactions. While most
computer vision approaches prioritize the RGB camera, the Depth modality -
which can further amplify the subtleties of actions from an egocentric
perspective - remains underexplored. Our work focuses on recognizing actions
from egocentric RGB and Depth modalities in an industry-like environment. To
study this problem, we consider the recent MECCANO dataset, which provides a
wide range of assembling actions. Our framework is based on the 3D Video SWIN
Transformer to encode both RGB and Depth modalities effectively. To address the
inherent skewness in real-world multimodal action occurrences, we propose a
training strategy using an exponentially decaying variant of the focal loss
modulating factor. Additionally, to leverage the information in both RGB and
Depth modalities, we opt for late fusion to combine the predictions from each
modality. We thoroughly evaluate our method on the action recognition task of
the MECCANO dataset, and it significantly outperforms the prior work. Notably,
our method also secured first place at the multimodal action recognition
challenge at ICIAP 2023.
</p>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13965" title="Abstract">arXiv:2309.13965</a> [<a href="/pdf/2309.13965" title="Download PDF">pdf</a>, <a href="/format/2309.13965" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> May I Ask a Follow-up Question? Understanding the Benefits of  Conversations in Neural Network Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X+J">X. Jessie Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Research in explainable AI (XAI) aims to provide insights into the
decision-making process of opaque AI models. To date, most XAI methods offer
one-off and static explanations, which cannot cater to the diverse backgrounds
and understanding levels of users. With this paper, we investigate if free-form
conversations can enhance users' comprehension of static explanations, improve
acceptance and trust in the explanation methods, and facilitate human-AI
collaboration. Participants are presented with static explanations, followed by
a conversation with a human expert regarding the explanations. We measure the
effect of the conversation on participants' ability to choose, from three
machine learning models, the most accurate one based on explanations and their
self-reported comprehension, acceptance, and trust. Empirical results show that
conversations significantly improve comprehension, acceptance, trust, and
collaboration. Our findings highlight the importance of customized model
explanations in the format of free-form conversations and provide insights for
the future design of conversational explanations.
</p>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13970" title="Abstract">arXiv:2309.13970</a> [<a href="/pdf/2309.13970" title="Download PDF">pdf</a>, <a href="/format/2309.13970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Cyberpunk 2077 perspective on the prediction and understanding of  future technology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+M+B">Miguel Bordallo L&#xf3;pez</a>, 
<a href="/search/cs?searchtype=author&query=Casado%2C+C+%C3%81">Constantino &#xc1;lvarez Casado</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Science fiction and video games have long served as valuable tools for
envisioning and inspiring future technological advancements. This position
paper investigates the potential of Cyberpunk 2077, a popular science fiction
video game, to shed light on the future of technology, particularly in the
areas of artificial intelligence, edge computing, augmented humans, and
biotechnology. By analyzing the game's portrayal of these technologies and
their implications, we aim to understand the possibilities and challenges that
lie ahead. We discuss key themes such as neurolink and brain-computer
interfaces, multimodal recording systems, virtual and simulated reality,
digital representation of the physical world, augmented and AI-based home
appliances, smart clothing, and autonomous vehicles. The paper highlights the
importance of designing technologies that can coexist with existing preferences
and systems, considering the uneven adoption of new technologies. Through this
exploration, we emphasize the potential of science fiction and video games like
Cyberpunk 2077 as tools for guiding future technological advancements and
shaping public perception of emerging innovations.
</p>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13972" title="Abstract">arXiv:2309.13972</a> [<a href="/pdf/2309.13972" title="Download PDF">pdf</a>, <a href="/ps/2309.13972" title="Download PostScript">ps</a>, <a href="/format/2309.13972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio classification with Dilated Convolution with Learnable Spacings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalfaoui-Hassani%2C+I">Ismail Khalfaoui-Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Masquelier%2C+T">Timoth&#xe9;e Masquelier</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrini%2C+T">Thomas Pellegrini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Dilated convolution with learnable spacings (DCLS) is a recent convolution
method in which the positions of the kernel elements are learned throughout
training by backpropagation. Its interest has recently been demonstrated in
computer vision (ImageNet classification and downstream tasks). Here we show
that DCLS is also useful for audio tagging using the AudioSet classification
benchmark. We took two state-of-the-art convolutional architectures using
depthwise separable convolutions (DSC), ConvNeXt and ConvFormer, and a hybrid
one using attention in addition, FastViT, and drop-in replaced all the DSC
layers by DCLS ones. This significantly improved the mean average precision
(mAP) with the three architectures without increasing the number of parameters
and with only a low cost on the throughput. The method code is based on PyTorch
and is available at https://github.com/K-H-Ismail/DCLS-Audio
</p>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13974" title="Abstract">arXiv:2309.13974</a> [<a href="/pdf/2309.13974" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deriving Product Line Requirements: the RED-PL Guidance Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Djebbi%2C+O">Olfa Djebbi</a> (CRI), 
<a href="/search/cs?searchtype=author&query=Salinesi%2C+C">Camille Salinesi</a> (CRI), 
<a href="/search/cs?searchtype=author&query=Diaz%2C+D">Daniel Diaz</a> (CRI)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Software Engineering Conference, 2007. APSEC 2007. 14th
  Asia-Pacific, Dec 2007, Nagoya, Japan. pp.494 - 501
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Product lines (PL) modeling have proven to be an effective approach to reuse
in software development.Several variability approaches were developed to plan
requirements reuse, but only little of them actuallyaddress the issue of
deriving product requirements.This paper presents a method, RED-PL that intends
to support requirements derivation. The originality ofthe proposed approach is
that (i) it is user-oriented, (ii) it guides product requirements elicitation
andderivation as a decision making activity, and (iii) it provides systematic
and interactive guidance assistinganalysts in taking decisions about
requirements. The RED-PL methodological process was validatedin an industrial
setting by considering the requirement engineering phase of a product line of
blood analyzers.
</p>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13975" title="Abstract">arXiv:2309.13975</a> [<a href="/pdf/2309.13975" title="Download PDF">pdf</a>, <a href="/format/2309.13975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Semantic Image Editing with Style Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivuk%2C+H">Hakan Sivuk</a>, 
<a href="/search/cs?searchtype=author&query=Dundar%2C+A">Aysegul Dundar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic image editing requires inpainting pixels following a semantic map.
It is a challenging task since this inpainting requires both harmony with the
context and strict compliance with the semantic maps. The majority of the
previous methods proposed for this task try to encode the whole information
from erased images. However, when an object is added to a scene such as a car,
its style cannot be encoded from the context alone. On the other hand, the
models that can output diverse generations struggle to output images that have
seamless boundaries between the generated and unerased parts. Additionally,
previous methods do not have a mechanism to encode the styles of visible and
partially visible objects differently for better performance. In this work, we
propose a framework that can encode visible and partially visible objects with
a novel mechanism to achieve consistency in the style encoding and final
generations. We extensively compare with previous conditional image generation
and semantic image editing algorithms. Our extensive experiments show that our
method significantly improves over the state-of-the-art. Our method not only
achieves better quantitative results but also provides diverse results. Please
refer to the project web page for the released code and demo:
https://github.com/hakansivuk/DivSem.
</p>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13977" title="Abstract">arXiv:2309.13977</a> [<a href="/pdf/2309.13977" title="Download PDF">pdf</a>, <a href="/format/2309.13977" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Computational Power of Distributed Shared-Memory Models with  Bounded-Size Registers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delporte%2C+C">Carole Delporte</a>, 
<a href="/search/cs?searchtype=author&query=Fauconnier%2C+H">Hugues Fauconnier</a>, 
<a href="/search/cs?searchtype=author&query=Fraigniaud%2C+P">Pierre Fraigniaud</a>, 
<a href="/search/cs?searchtype=author&query=Rajsbaum%2C+S">Sergio Rajsbaum</a>, 
<a href="/search/cs?searchtype=author&query=Travers%2C+C">Corentin Travers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">The celebrated Asynchronous Computability Theorem of Herlihy and Shavit (STOC
1993 and STOC 1994) provided a topological characterization of the tasks that
are solvable in a distributed system where processes are communicating by
writing and reading shared registers, and where any number of processes can
fail by crashing. However, this characterization assumes the use of
full-information protocols, that is, protocols in which each time any of the
processes writes in the shared memory, it communicates everything it learned
since the beginning of the execution. Thus, the characterization implicitly
assumes that each register in the shared memory is of unbounded size. Whether
unbounded size registers are unavoidable for the model of computation to be
universal is the central question studied in this paper. Specifically, is any
task that is solvable using unbounded registers solvable using registers of
bounded size? More generally, when at most $t$ processes can crash, is the
model with bounded size registers universal? These are the questions answered
in this paper.
</p>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13979" title="Abstract">arXiv:2309.13979</a> [<a href="/pdf/2309.13979" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphological Computing as Logic Underlying Cognition in Human, Animal,  and Intelligent Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dodig-Crnkovic%2C+G">Gordana Dodig-Crnkovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, no figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This work examines the interconnections between logic, epistemology, and
sciences within the Naturalist tradition. It presents a scheme that connects
logic, mathematics, physics, chemistry, biology, and cognition, emphasizing
scale-invariant, self-organizing dynamics across organizational tiers of
nature. The inherent logic of agency exists in natural processes at various
levels, under information exchanges. It applies to humans, animals, and
artifactual agents. The common human-centric, natural language-based logic is
an example of complex logic evolved by living organisms that already appears in
the simplest form at the level of basal cognition of unicellular organisms.
Thus, cognitive logic stems from the evolution of physical, chemical, and
biological logic. In a computing nature framework with a self-organizing
agency, innovative computational frameworks grounded in
morphological/physical/natural computation can be used to explain the genesis
of human-centered logic through the steps of naturalized logical processes at
lower levels of organization. The Extended Evolutionary Synthesis of living
agents is essential for understanding the emergence of human-level logic and
the relationship between logic and information processing/computational
epistemology. We conclude that more research is needed to elucidate the details
of the mechanisms linking natural phenomena with the logic of agency in nature.
</p>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13985" title="Abstract">arXiv:2309.13985</a> [<a href="/pdf/2309.13985" title="Download PDF">pdf</a>, <a href="/format/2309.13985" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-Driven ML-Based Modelling for Correcting Inverse Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+R">Ruiyuan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+T">Tingting Mu</a>, 
<a href="/search/cs?searchtype=author&query=Liatsis%2C+P">Panos Liatsis</a>, 
<a href="/search/cs?searchtype=author&query=Kyritsis%2C+D+C">Dimitrios C. Kyritsis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, the paper is accepted by Neurips 2023 as a spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">When deploying machine learning estimators in science and engineering (SAE)
domains, it is critical to avoid failed estimations that can have disastrous
consequences, e.g., in aero engine design. This work focuses on detecting and
correcting failed state estimations before adopting them in SAE inverse
problems, by utilizing simulations and performance metrics guided by physical
laws. We suggest to flag a machine learning estimation when its physical model
error exceeds a feasible threshold, and propose a novel approach, GEESE, to
correct it through optimization, aiming at delivering both low error and high
efficiency. The key designs of GEESE include (1) a hybrid surrogate error model
to provide fast error estimations to reduce simulation cost and to enable
gradient based backpropagation of error feedback, and (2) two generative models
to approximate the probability distributions of the candidate states for
simulating the exploitation and exploration behaviours. All three models are
constructed as neural networks. GEESE is tested on three real-world SAE inverse
problems and compared to a number of state-of-the-art optimization/search
approaches. Results show that it fails the least number of times in terms of
finding a feasible state correction, and requires physical evaluations less
frequently in general.
</p>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13989" title="Abstract">arXiv:2309.13989</a> [<a href="/pdf/2309.13989" title="Download PDF">pdf</a>, <a href="/format/2309.13989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Approach for Effective Multi-View Clustering with  Information-Theoretic Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cui%2C+C">Chenhang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yazhou Ren</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jingyu Pu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiawei Li</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+X">Xiaorong Pu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianyi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yutao Shi</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+L">Lifang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Multi-view clustering (MVC) is a popular technique for improving clustering
performance using various data sources. However, existing methods primarily
focus on acquiring consistent information while often neglecting the issue of
redundancy across multiple views. This study presents a new approach called
Sufficient Multi-View Clustering (SUMVC) that examines the multi-view
clustering framework from an information-theoretic standpoint. Our proposed
method consists of two parts. Firstly, we develop a simple and reliable
multi-view clustering method SCMVC (simple consistent multi-view clustering)
that employs variational analysis to generate consistent information. Secondly,
we propose a sufficient representation lower bound to enhance consistent
information and minimise unnecessary information among views. The proposed
SUMVC method offers a promising solution to the problem of multi-view
clustering and provides a new perspective for analyzing multi-view data.
<br />To verify the effectiveness of our model, we conducted a theoretical analysis
based on the Bayes Error Rate, and experiments on multiple multi-view datasets
demonstrate the superior performance of SUMVC.
</p>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13993" title="Abstract">arXiv:2309.13993</a> [<a href="/pdf/2309.13993" title="Download PDF">pdf</a>, <a href="/ps/2309.13993" title="Download PostScript">ps</a>, <a href="/format/2309.13993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identification of Mixtures of Discrete Product Distributions in  Near-Optimal Sample and Time Complexity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gordon%2C+S+L">Spencer L. Gordon</a>, 
<a href="/search/cs?searchtype=author&query=Jahn%2C+E">Erik Jahn</a>, 
<a href="/search/cs?searchtype=author&query=Mazaheri%2C+B">Bijan Mazaheri</a>, 
<a href="/search/cs?searchtype=author&query=Rabani%2C+Y">Yuval Rabani</a>, 
<a href="/search/cs?searchtype=author&query=Schulman%2C+L+J">Leonard J. Schulman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Data Structures and Algorithms (cs.DS); Signal Processing (eess.SP); Machine Learning (stat.ML)

</div>
<p class="mathjax">We consider the problem of identifying, from statistics, a distribution of
discrete random variables $X_1,\ldots,X_n$ that is a mixture of $k$ product
distributions. The best previous sample complexity for $n \in O(k)$ was
$(1/\zeta)^{O(k^2 \log k)}$ (under a mild separation assumption parameterized
by $\zeta$). The best known lower bound was $\exp(\Omega(k))$. It is known that
$n\geq 2k-1$ is necessary and sufficient for identification. We show, for any
$n\geq 2k-1$, how to achieve sample complexity and run-time complexity
$(1/\zeta)^{O(k)}$. We also extend the known lower bound of $e^{\Omega(k)}$ to
match our upper bound across a broad range of $\zeta$. Our results are obtained
by combining (a) a classic method for robust tensor decomposition, (b) a novel
way of bounding the condition number of key matrices called Hadamard
extensions, by studying their action only on flattened rank-1 tensors.
</p>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14003" title="Abstract">arXiv:2309.14003</a> [<a href="/pdf/2309.14003" title="Download PDF">pdf</a>, <a href="/format/2309.14003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Imitation Learning for Stochastic Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Igl%2C+M">Maximilian Igl</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+P">Punit Shah</a>, 
<a href="/search/cs?searchtype=author&query=Mougin%2C+P">Paul Mougin</a>, 
<a href="/search/cs?searchtype=author&query=Srinivasan%2C+S">Sirish Srinivasan</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+T">Tarun Gupta</a>, 
<a href="/search/cs?searchtype=author&query=White%2C+B">Brandyn White</a>, 
<a href="/search/cs?searchtype=author&query=Shiarlis%2C+K">Kyriacos Shiarlis</a>, 
<a href="/search/cs?searchtype=author&query=Whiteson%2C+S">Shimon Whiteson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at IROS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Many applications of imitation learning require the agent to generate the
full distribution of behaviour observed in the training data. For example, to
evaluate the safety of autonomous vehicles in simulation, accurate and diverse
behaviour models of other road users are paramount. Existing methods that
improve this distributional realism typically rely on hierarchical policies.
These condition the policy on types such as goals or personas that give rise to
multi-modal behaviour. However, such methods are often inappropriate for
stochastic environments where the agent must also react to external factors:
because agent types are inferred from the observed future trajectory during
training, these environments require that the contributions of internal and
external factors to the agent behaviour are disentangled and only internal
factors, i.e., those under the agent's control, are encoded in the type.
Encoding future information about external factors leads to inappropriate agent
reactions during testing, when the future is unknown and types must be drawn
independently from the actual future. We formalize this challenge as
distribution shift in the conditional distribution of agent types under
environmental stochasticity. We propose Robust Type Conditioning (RTC), which
eliminates this shift with adversarial training under randomly sampled types.
Experiments on two domains, including the large-scale Waymo Open Motion
Dataset, show improved distributional realism while maintaining or improving
task performance compared to state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14006" title="Abstract">arXiv:2309.14006</a> [<a href="/pdf/2309.14006" title="Download PDF">pdf</a>, <a href="/format/2309.14006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple evolutionary pressures shape identical consonant avoidance in  the world&#x27;s languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cathcart%2C+C+A">Chundra A. Cathcart</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 33 pp
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Languages disfavor word forms containing sequences of similar or identical
consonants, due to the biomechanical and cognitive difficulties posed by
patterns of this sort. However, the specific evolutionary processes responsible
for this phenomenon are not fully understood. Words containing sequences of
identical consonants may be more likely to arise than those without; processes
of word form mutation may be more likely to remove than create sequences of
identical consonants in word forms; finally, words containing identical
consonants may die out more frequently than those without. Phylogenetic
analyses of the evolution of homologous word forms indicate that words with
identical consonants arise less frequently than those without, and processes
which mutate word forms are more likely to remove sequences of identical
consonants than introduce them. However, words with identical consonants do not
die out more frequently than those without. Further analyses reveal that forms
with identical consonants are replaced in basic meaning functions more
frequently than words without. Taken together, results suggest that the under
representation of sequences of identical consonants is overwhelmingly a
byproduct of constraints on word form coinage, though processes related to word
usage also serve to ensure that such patterns are infrequent in more salient
vocabulary items. These findings clarify previously unknown aspects of
processes of lexical evolution and competition that take place during language
change, optimizing communicative systems.
</p>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14010" title="Abstract">arXiv:2309.14010</a> [<a href="/pdf/2309.14010" title="Download PDF">pdf</a>, <a href="/format/2309.14010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Variational Inference for Scalable 3D Object-centric Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+K+S">Kee Siong Ng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Miaomiao Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We tackle the task of scalable unsupervised object-centric representation
learning on 3D scenes. Existing approaches to object-centric representation
learning show limitations in generalizing to larger scenes as their learning
processes rely on a fixed global coordinate system. In contrast, we propose to
learn view-invariant 3D object representations in localized object coordinate
systems. To this end, we estimate the object pose and appearance representation
separately and explicitly map object representations across views while
maintaining object identities. We adopt an amortized variational inference
pipeline that can process sequential input and scalably update object latent
distributions online. To handle large-scale scenes with a varying number of
objects, we further introduce a Cognitive Map that allows the registration and
query of objects on a per-scene global map to achieve scalable representation
learning. We explore the object-centric neural radiance field (NeRF) as our 3D
scene representation, which is jointly modeled within our unsupervised
object-centric learning framework. Experimental results on synthetic and real
datasets show that our proposed method can infer and maintain object-centric
representations of 3D scenes and outperforms previous models.
</p>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14011" title="Abstract">arXiv:2309.14011</a> [<a href="/pdf/2309.14011" title="Download PDF">pdf</a>, <a href="/ps/2309.14011" title="Download PostScript">ps</a>, <a href="/format/2309.14011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Truly Concurrent Semantics for Reversible CCS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Melgratti%2C+H">Herm&#xe1;n Melgratti</a>, 
<a href="/search/cs?searchtype=author&query=Mezzina%2C+C+A">Claudio Antares Mezzina</a>, 
<a href="/search/cs?searchtype=author&query=Pinna%2C+G+M">G. Michele Pinna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Reversible CCS (RCCS) is a well-established, formal model for reversible
communicating systems, which has been built on top of the classical Calculus of
Communicating Systems (CCS). In its original formulation, each CCS process is
equipped with a memory that records its performed actions, which is then used
to reverse computations. More recently, abstract models for RCCS have been
proposed in the literature, basically, by directly associating RCCS processes
with (reversible versions of) event structures. In this paper we propose a
different abstract model: starting from one of the well-known encoding of CCS
into Petri nets we apply a recently proposed approach to incorporate
causally-consistent reversibility to Petri nets, obtaining as result the
(reversible) net counterpart of every RCCS term.
</p>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14013" title="Abstract">arXiv:2309.14013</a> [<a href="/pdf/2309.14013" title="Download PDF">pdf</a>, <a href="/format/2309.14013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Academic Midas Touch: An Unconventional Scientometric for Evaluating  Academic Excellence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosenfled%2C+A">Ariel Rosenfled</a>, 
<a href="/search/cs?searchtype=author&query=Alexi%2C+A">Ariel Alexi</a>, 
<a href="/search/cs?searchtype=author&query=Mushiev%2C+L">Liel Mushiev</a>, 
<a href="/search/cs?searchtype=author&query=Lazebnik%2C+T">Teddy Lazebnik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">The recognition of academic excellence is fundamental to the scientific and
academic endeavor. In particular, academic scientometrics that are able to
computationally capture academic excellence are of great interest. In this
work, we propose and investigate an unconventional scientometric termed the
Academic Midas Touch (AMT) that refers to a researcher's tendency to produce
outstanding publications (i.e., golden publications). Using an extensive
dataset of mathematicians, both award-winning and otherwise, we show that the
AMT scientometric is a valid and arguably valuable scientometric for the
distinction of academic excellence.
</p>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14016" title="Abstract">arXiv:2309.14016</a> [<a href="/pdf/2309.14016" title="Download PDF">pdf</a>, <a href="/format/2309.14016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtuoso: High Resource Utilization and &#x3bc;s-scale Performance  Isolation in a Shared Virtual Machine TCP Network Stack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stolet%2C+M">Matheus Stolet</a>, 
<a href="/search/cs?searchtype=author&query=Arzola%2C+L">Liam Arzola</a>, 
<a href="/search/cs?searchtype=author&query=Peter%2C+S">Simon Peter</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+A">Antoine Kaufmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under submission for conference peer review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Operating Systems (cs.OS)

</div>
<p class="mathjax">Virtualization improves resource efficiency and ensures security and
performance isolation for cloud applications. To that end, operators today use
a layered architecture that runs a separate network stack instance in each VM
and container connected to a separate virtual switch. Decoupling through
layering reduces complexity, but induces performance and resource overheads
that are at odds with increasing demands for network bandwidth, communication
requirements for large distributed applications, and low latency.
<br />We present Virtuoso, a new software networking stack for VMs and containers.
Virtuoso performs a fundamental re-organization of the networking stack to
maximize CPU utilization, enforce isolation, and minimize networking stack
overheads. We maximize utilization by running one elastically shared network
stack instance on dedicated cores; we enforce isolation by performing central
and fine-grained per-packet resource accounting and scheduling; we reduce
overheads by building a single-layer data path with a one-shot fast-path
incorporating all processing from the TCP transport layer through network
virtualization and virtual switching. Virtuoso improves resource utilization by
up to 50%, latencies by up to 42% compared to other virtualized network stacks
without sacrificing isolation, and keeps processing overhead within 11.5% of
unvirtualized network stacks.
</p>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14021" title="Abstract">arXiv:2309.14021</a> [<a href="/pdf/2309.14021" title="Download PDF">pdf</a>, <a href="/format/2309.14021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot  Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kaushal%2C+A">Ayush Kaushal</a>, 
<a href="/search/cs?searchtype=author&query=Vaidhya%2C+T">Tejas Vaidhya</a>, 
<a href="/search/cs?searchtype=author&query=Rish%2C+I">Irina Rish</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Low Rank Decomposition of matrix - splitting a large matrix into a product of
two smaller matrix offers a means for compression that reduces the parameters
of a model without sparsification, and hence delivering more speedup on modern
hardware. Moreover, unlike quantization, the compressed linear layers remain
fully differentiable and all the parameters trainable, while being able to
leverage the existing highly efficient kernels over floating point matrices. We
study the potential to compress Large Language Models (LLMs) for monolingual
Code generation via Low Rank Decomposition (LoRD) and observe that ranks for
the linear layers in these models can be reduced by upto 39.58% with less than
1% increase in perplexity. We then use Low Rank Decomposition (LoRD) to
compress StarCoder 16B to 13.2B parameter with no drop and to 12.3B with
minimal drop in HumanEval Pass@1 score, in less than 10 minutes on a single
A100. The compressed models speeds up inference by up to 22.35% with just a
single line of change in code over huggingface's implementation with pytorch
backend. Low Rank Decomposition (LoRD) models remain compatible with state of
the art near-lossless quantization method such as SpQR, which allows leveraging
further compression gains of quantization. Lastly, QLoRA over Low Rank
Decomposition (LoRD) model further reduces memory requirements by as much as
21.2% over vanilla QLoRA while offering similar gains from parameter efficient
fine tuning. Our work shows Low Rank Decomposition (LoRD) as a promising new
paradigm for LLM compression.
</p>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14022" title="Abstract">arXiv:2309.14022</a> [<a href="/pdf/2309.14022" title="Download PDF">pdf</a>, <a href="/format/2309.14022" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hashing Neural Video Decomposition with Multiplicative Residuals in  Space-Time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Cheng-Hung Chan</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+C">Cheng-Yang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+C">Cheng Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hwann-Tzong Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We present a video decomposition method that facilitates layer-based editing
of videos with spatiotemporally varying lighting and motion effects. Our neural
model decomposes an input video into multiple layered representations, each
comprising a 2D texture map, a mask for the original video, and a
multiplicative residual characterizing the spatiotemporal variations in
lighting conditions. A single edit on the texture maps can be propagated to the
corresponding locations in the entire video frames while preserving other
contents' consistencies. Our method efficiently learns the layer-based neural
representations of a 1080p video in 25s per frame via coordinate hashing and
allows real-time rendering of the edited result at 71 fps on a single GPU.
Qualitatively, we run our method on various videos to show its effectiveness in
generating high-quality editing effects. Quantitatively, we propose to adopt
feature-tracking evaluation metrics for objectively assessing the consistency
of video editing. Project page: https://lightbulb12294.github.io/hashing-nvd/
</p>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14028" title="Abstract">arXiv:2309.14028</a> [<a href="/pdf/2309.14028" title="Download PDF">pdf</a>, <a href="/ps/2309.14028" title="Download PostScript">ps</a>, <a href="/format/2309.14028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Upper-Bound on the Decoding Failure Probability of the LRPC Decoder
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burle%2C+%C3%89">&#xc9;tienne Burle</a>, 
<a href="/search/cs?searchtype=author&query=Otmani%2C+A">Ayoub Otmani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Low Rank Parity Check (LRPC) codes form a class of rank-metric
error-correcting codes that was purposely introduced to design public-key
encryption schemes. An LRPC code is defined from a parity check matrix whose
entries belong to a relatively low dimensional vector subspace of a large
finite field. This particular algebraic feature can then be exploited to
correct with high probability rank errors when the parameters are appropriately
chosen. In this paper, we present theoretical upper-bounds on the probability
that the LRPC decoding algorithm fails.
</p>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14029" title="Abstract">arXiv:2309.14029</a> [<a href="/pdf/2309.14029" title="Download PDF">pdf</a>, <a href="/format/2309.14029" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffeomorphic Transformations for Time Series Analysis: An Efficient  Approach to Nonlinear Warping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Martinez%2C+I">I&#xf1;igo Martinez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis, defended at the University of Navarra on July 17, 2023. 277 pages, 8 chapters, 1 appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The proliferation and ubiquity of temporal data across many disciplines has
sparked interest for similarity, classification and clustering methods
specifically designed to handle time series data. A core issue when dealing
with time series is determining their pairwise similarity, i.e., the degree to
which a given time series resembles another. Traditional distance measures such
as the Euclidean are not well-suited due to the time-dependent nature of the
data. Elastic metrics such as dynamic time warping (DTW) offer a promising
approach, but are limited by their computational complexity,
non-differentiability and sensitivity to noise and outliers. This thesis
proposes novel elastic alignment methods that use parametric \&amp; diffeomorphic
warping transformations as a means of overcoming the shortcomings of DTW-based
metrics. The proposed method is differentiable \&amp; invertible, well-suited for
deep learning architectures, robust to noise and outliers, computationally
efficient, and is expressive and flexible enough to capture complex patterns.
Furthermore, a closed-form solution was developed for the gradient of these
diffeomorphic transformations, which allows an efficient search in the
parameter space, leading to better solutions at convergence. Leveraging the
benefits of these closed-form diffeomorphic transformations, this thesis
proposes a suite of advancements that include: (a) an enhanced temporal
transformer network for time series alignment and averaging, (b) a
deep-learning based time series classification model to simultaneously align
and classify signals with high accuracy, (c) an incremental time series
clustering algorithm that is warping-invariant, scalable and can operate under
limited computational and time resources, and finally, (d) a normalizing flow
model that enhances the flexibility of affine transformations in coupling and
autoregressive layers.
</p>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14030" title="Abstract">arXiv:2309.14030</a> [<a href="/pdf/2309.14030" title="Download PDF">pdf</a>, <a href="/format/2309.14030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeWave: Discrete EEG Waves Encoding for Brain Dynamics to Text  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duan%2C+Y">Yiqun Duan</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jinzhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Kai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Chin-Teng Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">The translation of brain dynamics into natural language is pivotal for
brain-computer interfaces (BCIs), a field that has seen substantial growth in
recent years. With the swift advancement of large language models, such as
ChatGPT, the need to bridge the gap between the brain and languages becomes
increasingly pressing. Current methods, however, require eye-tracking fixations
or event markers to segment brain dynamics into word-level features, which can
restrict the practical application of these systems. These event markers may
not be readily available or could be challenging to acquire during real-time
inference, and the sequence of eye fixations may not align with the order of
spoken words. To tackle these issues, we introduce a novel framework, DeWave,
that integrates discrete encoding sequences into open-vocabulary EEG-to-text
translation tasks. DeWave uses a quantized variational encoder to derive
discrete codex encoding and align it with pre-trained language models. This
discrete codex representation brings forth two advantages: 1) it alleviates the
order mismatch between eye fixations and spoken words by introducing text-EEG
contrastive alignment training, and 2) it minimizes the interference caused by
individual differences in EEG waves through an invariant discrete codex. Our
model surpasses the previous baseline (40.1 and 31.7) by 3.06% and 6.34%,
respectively, achieving 41.35 BLEU-1 and 33.71 Rouge-F on the ZuCo Dataset.
Furthermore, this work is the first to facilitate the translation of entire EEG
signal periods without needing word-level order markers (e.g., eye fixations),
scoring 20.5 BLEU-1 and 29.5 Rouge-1 on the ZuCo Dataset, respectively. Codes
and the final paper will be public soon.
</p>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14031" title="Abstract">arXiv:2309.14031</a> [<a href="/pdf/2309.14031" title="Download PDF">pdf</a>, <a href="/format/2309.14031" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase-space iterative solvers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Garcia-Suarez%2C+J">Joaquin Garcia-Suarez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 7 tables, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">I introduce a new iterative method to solve problems in small-strain
non-linear elasticity. The method is inspired by recent work in data-driven
computational mechanics, which reformulated the classic boundary value problem
of continuum mechanics using the concept of "phase space". The latter is an
abstract metric space, whose coordinates are indexed by strains and stress
components, where each possible state of the discretized body corresponds to a
point. Since the phase space is associated to the discretized body, it is
finite dimensional. Two subsets are then defined: an affine space termed
"physically-admissible set" made up by those points that satisfy equilibrium
and a "materially-admissible set" containing points that satisfy the
constitutive law. Solving the boundary-value problem amounts to finding the
intersection between these two subdomains. In the linear-elastic setting, this
can be achieved through the solution of a set of linear equations; when
material non-linearity enters the picture, such is not the case anymore and
iterative solution approaches are necessary. Our iterative method consists on
projecting points alternatively from one set to the other, until convergence.
The method is similar in spirit to the "method of alternative projections" and
to the "method of projections onto convex sets", for which there is a solid
mathematical foundation that furnishes conditions for existence and uniqueness
of solutions, upon which we rely to uphold our new method's performance. We
present two examples to illustrate the applicability of the method, and to
showcase its strengths when compared to the classic Newton-Raphson method, the
usual tool of choice in non-linear continuum mechanics.
</p>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14032" title="Abstract">arXiv:2309.14032</a> [<a href="/pdf/2309.14032" title="Download PDF">pdf</a>, <a href="/format/2309.14032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Haoran Ye</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiarui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Zhiguang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+H">Helan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Ant Colony Optimization (ACO) is a meta-heuristic algorithm that has been
successfully applied to various Combinatorial Optimization Problems (COPs).
Traditionally, customizing ACO for a specific problem requires the expert
design of knowledge-driven heuristics. In this paper, we propose DeepACO, a
generic framework that leverages deep reinforcement learning to automate
heuristic designs. DeepACO serves to strengthen the heuristic measures of
existing ACO algorithms and dispense with laborious manual design in future ACO
applications. As a neural-enhanced meta-heuristic, DeepACO consistently
outperforms its ACO counterparts on eight COPs using a single neural model and
a single set of hyperparameters. As a Neural Combinatorial Optimization method,
DeepACO performs better than or on par with problem-specific methods on
canonical routing problems. Our code is publicly available at
https://github.com/henry-yeh/DeepACO.
</p>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14034" title="Abstract">arXiv:2309.14034</a> [<a href="/pdf/2309.14034" title="Download PDF">pdf</a>, <a href="/format/2309.14034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A unified worst case for classical simplex and policy iteration pivot  rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Disser%2C+Y">Yann Disser</a>, 
<a href="/search/cs?searchtype=author&query=Mosis%2C+N">Nils Mosis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Discrete Mathematics (cs.DM)</span>; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Combinatorics (math.CO)

</div>
<p class="mathjax">We construct a family of Markov decision processes for which the policy
iteration algorithm needs an exponential number of improving switches with
Dantzig's rule, with Bland's rule, and with the Largest Increase pivot rule.
This immediately translates to a family of linear programs for which the
simplex algorithm needs an exponential number of pivot steps with the same
three pivot rules. Our results yield a unified construction that simultaneously
reproduces well-known lower bounds for these classical pivot rules, and we are
able to infer that any (deterministic or randomized) combination of them cannot
avoid an exponential worst-case behavior. Regarding the policy iteration
algorithm, pivot rules typically switch multiple edges simultaneously and our
lower bound for Dantzig's rule and the Largest Increase rule, which perform
only single switches, seem novel. Regarding the simplex algorithm, the
individual lower bounds were previously obtained separately via deformed
hypercube constructions. In contrast to previous bounds for the simplex
algorithm via Markov decision processes, our rigorous analysis is reasonably
concise.
</p>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14037" title="Abstract">arXiv:2309.14037</a> [<a href="/pdf/2309.14037" title="Download PDF">pdf</a>, <a href="/format/2309.14037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An automatic selection of optimal recurrent neural network architecture  for processes dynamics modelling purposes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laddach%2C+K">Krzysztof Laddach</a>, 
<a href="/search/cs?searchtype=author&query=%C5%81angowski%2C+R">Rafa&#x142; &#x141;angowski</a>, 
<a href="/search/cs?searchtype=author&query=Rutkowski%2C+T+A">Tomasz A. Rutkowski</a>, 
<a href="/search/cs?searchtype=author&query=Puchalski%2C+B">Bartosz Puchalski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 17 figures, code available
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Applied Soft Computing, Volume 116, 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">A problem related to the development of algorithms designed to find the
structure of artificial neural network used for behavioural (black-box)
modelling of selected dynamic processes has been addressed in this paper. The
research has included four original proposals of algorithms dedicated to neural
network architecture search. Algorithms have been based on well-known
optimisation techniques such as evolutionary algorithms and gradient descent
methods. In the presented research an artificial neural network of recurrent
type has been used, whose architecture has been selected in an optimised way
based on the above-mentioned algorithms. The optimality has been understood as
achieving a trade-off between the size of the neural network and its accuracy
in capturing the response of the mathematical model under which it has been
learnt. During the optimisation, original specialised evolutionary operators
have been proposed. The research involved an extended validation study based on
data generated from a mathematical model of the fast processes occurring in a
pressurised water nuclear reactor.
</p>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14046" title="Abstract">arXiv:2309.14046</a> [<a href="/pdf/2309.14046" title="Download PDF">pdf</a>, <a href="/format/2309.14046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversify and Conquer: Bandits and Diversity for an Enhanced E-commerce  Homepage Experience
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jaiswal%2C+S">Sangeet Jaiswal</a>, 
<a href="/search/cs?searchtype=author&query=Malayil%2C+K+T">Korah T Malayil</a>, 
<a href="/search/cs?searchtype=author&query=Jawaid%2C+S">Saif Jawaid</a>, 
<a href="/search/cs?searchtype=author&query=Vempati%2C+S">Sreekanth Vempati</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in Proceedings of Fashionxrecys Workshop, 17th ACM Conference on Recommender Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In the realm of e-commerce, popular platforms utilize widgets to recommend
advertisements and products to their users. However, the prevalence of mobile
device usage on these platforms introduces a unique challenge due to the
limited screen real estate available. Consequently, the positioning of relevant
widgets becomes pivotal in capturing and maintaining customer engagement. Given
the restricted screen size of mobile devices, widgets placed at the top of the
interface are more prominently displayed and thus attract greater user
attention. Conversely, widgets positioned further down the page require users
to scroll, resulting in reduced visibility and subsequent lower impression
rates. Therefore it becomes imperative to place relevant widgets on top.
However, selecting relevant widgets to display is a challenging task as the
widgets can be heterogeneous, widgets can be introduced or removed at any given
time from the platform. In this work, we model the vertical widget reordering
as a contextual multi-arm bandit problem with delayed batch feedback. The
objective is to rank the vertical widgets in a personalized manner. We present
a two-stage ranking framework that combines contextual bandits with a diversity
layer to improve the overall ranking. We demonstrate its effectiveness through
offline and online A/B results, conducted on proprietary data from Myntra, a
major fashion e-commerce platform in India.
</p>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14048" title="Abstract">arXiv:2309.14048</a> [<a href="/pdf/2309.14048" title="Download PDF">pdf</a>, <a href="/format/2309.14048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Synchronous Agents, Verification, and Blame -- A Deontic View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kharraz%2C+K">Karam Kharraz</a>, 
<a href="/search/cs?searchtype=author&query=Azzopardi%2C+S">Shaun Azzopardi</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+G">Gerardo Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Leucker%2C+M">Martin Leucker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in ICTAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">A question we can ask of multi-agent systems is whether the agents'
collective interaction satisfies particular goals or specifications, which can
be either individual or collective. When a collaborative goal is not reached,
or a specification is violated, a pertinent question is whether any agent is to
blame. This paper considers a two-agent synchronous setting and a formal
language to specify when agents' collaboration is required. We take a deontic
approach and use obligations, permissions, and prohibitions to capture notions
of non-interference between agents. We also handle reparations, allowing
violations to be corrected or compensated. We give trace semantics to our
logic, and use it to define blame assignment for violations. We give an
automaton construction for the logic, which we use as the base for model
checking and blame analysis. We also further provide quantitative semantics
that is able to compare different interactions in terms of the required
reparations.
</p>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14049" title="Abstract">arXiv:2309.14049</a> [<a href="/pdf/2309.14049" title="Download PDF">pdf</a>, <a href="/format/2309.14049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Novices Use LLM-Based Code Generators to Solve CS1 Coding Tasks in a  Self-Paced Learning Environment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kazemitabaar%2C+M">Majeed Kazemitabaar</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinying Hou</a>, 
<a href="/search/cs?searchtype=author&query=Henley%2C+A">Austin Henley</a>, 
<a href="/search/cs?searchtype=author&query=Ericson%2C+B+J">Barbara J. Ericson</a>, 
<a href="/search/cs?searchtype=author&query=Weintrop%2C+D">David Weintrop</a>, 
<a href="/search/cs?searchtype=author&query=Grossman%2C+T">Tovi Grossman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, Peer-Reviewed, Accepted for publication in the proceedings of the 2023 ACM Koli Calling International Conference on Computing Education Research
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As Large Language Models (LLMs) gain in popularity, it is important to
understand how novice programmers use them. We present a thematic analysis of
33 learners, aged 10-17, independently learning Python through 45
code-authoring tasks using Codex, an LLM-based code generator. We explore
several questions related to how learners used these code generators and
provide an analysis of the properties of the written prompts and the generated
code. Specifically, we explore (A) the context in which learners use Codex, (B)
what learners are asking from Codex, (C) properties of their prompts in terms
of relation to task description, language, and clarity, and prompt crafting
patterns, (D) the correctness, complexity, and accuracy of the AI-generated
code, and (E) how learners utilize AI-generated code in terms of placement,
verification, and manual modifications. Furthermore, our analysis reveals four
distinct coding approaches when writing code with an AI code generator: AI
Single Prompt, where learners prompted Codex once to generate the entire
solution to a task; AI Step-by-Step, where learners divided the problem into
parts and used Codex to generate each part; Hybrid, where learners wrote some
of the code themselves and used Codex to generate others; and Manual coding,
where learners wrote the code themselves. The AI Single Prompt approach
resulted in the highest correctness scores on code-authoring tasks, but the
lowest correctness scores on subsequent code-modification tasks during
training. Our results provide initial insight into how novice learners use AI
code generators and the challenges and opportunities associated with
integrating them into self-paced learning environments. We conclude with
various signs of over-reliance and self-regulation, as well as opportunities
for curriculum and tool development.
</p>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14050" title="Abstract">arXiv:2309.14050</a> [<a href="/pdf/2309.14050" title="Download PDF">pdf</a>, <a href="/format/2309.14050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NNgTL: Neural Network Guided Optimal Temporal Logic Task Planning for  Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+R">Ruijia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Shaoyuan Li</a>, 
<a href="/search/eess?searchtype=author&query=Yin%2C+X">Xiang Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICRA2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this work, we investigate task planning for mobile robots under linear
temporal logic (LTL) specifications. This problem is particularly challenging
when robots navigate in continuous workspaces due to the high computational
complexity involved. Sampling-based methods have emerged as a promising avenue
for addressing this challenge by incrementally constructing random trees,
thereby sidestepping the need to explicitly explore the entire state-space.
However, the performance of this sampling-based approach hinges crucially on
the chosen sampling strategy, and a well-informed heuristic can notably enhance
sample efficiency. In this work, we propose a novel neural-network guided
(NN-guided) sampling strategy tailored for LTL planning. Specifically, we
employ a multi-modal neural network capable of extracting features concurrently
from both the workspace and the B\"{u}chi automaton. This neural network
generates predictions that serve as guidance for random tree construction,
directing the sampling process toward more optimal directions. Through
numerical experiments, we compare our approach with existing methods and
demonstrate its superior efficiency, requiring less than 15% of the time of the
existing methods to find a feasible solution.
</p>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14052" title="Abstract">arXiv:2309.14052</a> [<a href="/pdf/2309.14052" title="Download PDF">pdf</a>, <a href="/format/2309.14052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single Image Test-Time Adaptation for Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Janouskova%2C+K">Klara Janouskova</a>, 
<a href="/search/cs?searchtype=author&query=Shor%2C+T">Tamir Shor</a>, 
<a href="/search/cs?searchtype=author&query=Baskin%2C+C">Chaim Baskin</a>, 
<a href="/search/cs?searchtype=author&query=Matas%2C+J">Jiri Matas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Test-Time Adaptation (TTA) methods improve the robustness of deep neural
networks to domain shift on a variety of tasks such as image classification or
segmentation. This work explores adapting segmentation models to a single
unlabelled image with no other data available at test-time. In particular, this
work focuses on adaptation by optimizing self-supervised losses at test-time.
Multiple baselines based on different principles are evaluated under diverse
conditions and a novel adversarial training is introduced for adaptation with
mask refinement. Our additions to the baselines result in a 3.51 and 3.28 %
increase over non-adapted baselines, without these improvements, the increase
would be 1.7 and 2.16 % only.
</p>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14053" title="Abstract">arXiv:2309.14053</a> [<a href="/pdf/2309.14053" title="Download PDF">pdf</a>, <a href="/format/2309.14053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Revisiting LARS for Large Batch Training Generalization of Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Do%2C+K">Khoi Do</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duong Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+H">Hoa Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tran-Thanh%2C+L">Long Tran-Thanh</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+Q">Quoc-Viet Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">LARS and LAMB have emerged as prominent techniques in Large Batch Learning
(LBL), ensuring the stability of AI training. One of the primary challenges in
LBL is convergence stability, where the AI agent usually gets trapped into the
sharp minimizer. Addressing this challenge, a relatively recent technique,
known as warm-up, has been employed. However, warm-up lacks a strong
theoretical foundation, leaving the door open for further exploration of more
efficacious algorithms. In light of this situation, we conduct empirical
experiments to analyze the behaviors of the two most popular optimizers in the
LARS family: LARS and LAMB, with and without a warm-up strategy. Our analyses
give us a comprehension of the novel LARS, LAMB, and the necessity of a warm-up
technique in LBL. Building upon these insights, we propose a novel algorithm
called Time Varying LARS (TVLARS), which facilitates robust training in the
initial phase without the need for warm-up. Experimental evaluation
demonstrates that TVLARS achieves competitive results with LARS and LAMB when
warm-up is utilized while surpassing their performance without the warm-up
technique.
</p>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14054" title="Abstract">arXiv:2309.14054</a> [<a href="/pdf/2309.14054" title="Download PDF">pdf</a>, <a href="/format/2309.14054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adapt then Unlearn: Exploiting Parameter Space Semantics for Unlearning  in Generative Adversarial Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwary%2C+P">Piyush Tiwary</a>, 
<a href="/search/cs?searchtype=author&query=Guha%2C+A">Atri Guha</a>, 
<a href="/search/cs?searchtype=author&query=Panda%2C+S">Subhodip Panda</a>, 
<a href="/search/cs?searchtype=author&query=P%2C+P+A">Prathosh A.P</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The increased attention to regulating the outputs of deep generative models,
driven by growing concerns about privacy and regulatory compliance, has
highlighted the need for effective control over these models. This necessity
arises from instances where generative models produce outputs containing
undesirable, offensive, or potentially harmful content. To tackle this
challenge, the concept of machine unlearning has emerged, aiming to forget
specific learned information or to erase the influence of undesired data
subsets from a trained model. The objective of this work is to prevent the
generation of outputs containing undesired features from a pre-trained GAN
where the underlying training data set is inaccessible. Our approach is
inspired by a crucial observation: the parameter space of GANs exhibits
meaningful directions that can be leveraged to suppress specific undesired
features. However, such directions usually result in the degradation of the
quality of generated samples. Our proposed method, known as
'Adapt-then-Unlearn,' excels at unlearning such undesirable features while also
maintaining the quality of generated samples. This method unfolds in two
stages: in the initial stage, we adapt the pre-trained GAN using negative
samples provided by the user, while in the subsequent stage, we focus on
unlearning the undesired feature. During the latter phase, we train the
pre-trained GAN using positive samples, incorporating a repulsion regularizer.
This regularizer encourages the model's parameters to be away from the
parameters associated with the adapted model from the first stage while also
maintaining the quality of generated samples. To the best of our knowledge, our
approach stands as first method addressing unlearning in GANs. We validate the
effectiveness of our method through comprehensive experiments.
</p>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14057" title="Abstract">arXiv:2309.14057</a> [<a href="/pdf/2309.14057" title="Download PDF">pdf</a>, <a href="/format/2309.14057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weakly Supervised Semantic Segmentation by Knowledge Graph Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+B">Bo Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Currently, existing efforts in Weakly Supervised Semantic Segmentation (WSSS)
based on Convolutional Neural Networks (CNNs) have predominantly focused on
enhancing the multi-label classification network stage, with limited attention
given to the equally important downstream segmentation network. Furthermore,
CNN-based local convolutions lack the ability to model the extensive
inter-category dependencies. Therefore, this paper introduces a graph
reasoning-based approach to enhance WSSS. The aim is to improve WSSS
holistically by simultaneously enhancing both the multi-label classification
and segmentation network stages. In the multi-label classification network
segment, external knowledge is integrated, coupled with GCNs, to globally
reason about inter-class dependencies. This encourages the network to uncover
features in non-salient regions of images, thereby refining the completeness of
generated pseudo-labels. In the segmentation network segment, the proposed
Graph Reasoning Mapping (GRM) module is employed to leverage knowledge obtained
from textual databases, facilitating contextual reasoning for class
representation within image regions. This GRM module enhances feature
representation in high-level semantics of the segmentation network's local
convolutions, while dynamically learning semantic coherence for individual
samples. Using solely image-level supervision, we have achieved
state-of-the-art performance in WSSS on the PASCAL VOC 2012 and MS-COCO
datasets. Extensive experimentation on both the multi-label classification and
segmentation network stages underscores the effectiveness of the proposed graph
reasoning approach for advancing WSSS.
</p>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14059" title="Abstract">arXiv:2309.14059</a> [<a href="/pdf/2309.14059" title="Download PDF">pdf</a>, <a href="/format/2309.14059" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Single-Antenna Jammers in MIMO-OFDM Can Resemble Multi-Antenna Jammers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Marti%2C+G">Gian Marti</a>, 
<a href="/search/cs?searchtype=author&query=Studer%2C+C">Christoph Studer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IEEE Communications Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">In multiple-input multiple-output (MIMO) wireless systems with frequency-flat
channels, a single-antenna jammer causes receive interference that is confined
to a one-dimensional subspace. Such a jammer can thus be nulled using linear
spatial filtering at the cost of one degree of freedom. Frequency-selective
channels are often transformed into multiple frequency-flat subcarriers with
orthogonal frequency-division multiplexing (OFDM). We show that when a
single-antenna jammer violates the OFDM protocol by not sending a cyclic
prefix, the interference received on each subcarrier by a multi-antenna
receiver is, in general, not confined to a subspace of dimension one (as a
single-antenna jammer in a frequency-flat scenario would be), but of dimension
L, where L is the jammer's number of channel taps. In MIMO-OFDM systems, a
single-antenna jammer can therefore resemble an L-antenna jammer. Simulations
corroborate our theoretical results. These findings imply that mitigating
jammers with large delay spread through linear spatial filtering is infeasible.
We discuss some (im)possibilities for the way forward.
</p>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14062" title="Abstract">arXiv:2309.14062</a> [<a href="/pdf/2309.14062" title="Download PDF">pdf</a>, <a href="/format/2309.14062" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FeCAM: Exploiting the Heterogeneity of Class Distributions in  Exemplar-Free Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goswami%2C+D">Dipam Goswami</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yuyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Twardowski%2C+B">Bart&#x142;omiej Twardowski</a>, 
<a href="/search/cs?searchtype=author&query=van+de+Weijer%2C+J">Joost van de Weijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Exemplar-free class-incremental learning (CIL) poses several challenges since
it prohibits the rehearsal of data from previous tasks and thus suffers from
catastrophic forgetting. Recent approaches to incrementally learning the
classifier by freezing the feature extractor after the first task have gained
much attention. In this paper, we explore prototypical networks for CIL, which
generate new class prototypes using the frozen feature extractor and classify
the features based on the Euclidean distance to the prototypes. In an analysis
of the feature distributions of classes, we show that classification based on
Euclidean metrics is successful for jointly trained features. However, when
learning from non-stationary data, we observe that the Euclidean metric is
suboptimal and that feature distributions are heterogeneous. To address this
challenge, we revisit the anisotropic Mahalanobis distance for CIL. In
addition, we empirically show that modeling the feature covariance relations is
better than previous attempts at sampling features from normal distributions
and training a linear classifier. Unlike existing methods, our approach
generalizes to both many- and few-shot CIL settings, as well as to
domain-incremental settings. Interestingly, without updating the backbone
network, our method obtains state-of-the-art results on several standard
continual learning benchmarks. Code is available at
https://github.com/dipamgoswami/FeCAM.
</p>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14063" title="Abstract">arXiv:2309.14063</a> [<a href="/pdf/2309.14063" title="Download PDF">pdf</a>, <a href="/format/2309.14063" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Preferential Multi-Target Search in Indoor Environments using Semantic  SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chikhalikar%2C+A">Akash Chikhalikar</a>, 
<a href="/search/cs?searchtype=author&query=Ravankar%2C+A+A">Ankit A. Ravankar</a>, 
<a href="/search/cs?searchtype=author&query=Luces%2C+J+V+S">Jose Victorio Salazar Luces</a>, 
<a href="/search/cs?searchtype=author&query=Hirata%2C+Y">Yasuhisa Hirata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In recent years, the demand for service robots capable of executing tasks
beyond autonomous navigation has grown. In the future, service robots will be
expected to perform complex tasks like 'Set table for dinner'. High-level tasks
like these, require, among other capabilities, the ability to retrieve multiple
targets. This paper delves into the challenge of locating multiple targets in
an environment, termed 'Find my Objects.' We present a novel heuristic designed
to facilitate robots in conducting a preferential search for multiple targets
in indoor spaces. Our approach involves a Semantic SLAM framework that combines
semantic object recognition with geometric data to generate a multi-layered
map. We fuse the semantic maps with probabilistic priors for efficient
inferencing. Recognizing the challenges introduced by obstacles that might
obscure a navigation goal and render standard point-to-point navigation
strategies less viable, our methodology offers resilience to such factors.
Importantly, our method is adaptable to various object detectors, RGB-D SLAM
techniques, and local navigation planners. We demonstrate the 'Find my Objects'
task in real-world indoor environments, yielding quantitative results that
attest to the effectiveness of our methodology. This strategy can be applied in
scenarios where service robots need to locate, grasp, and transport objects,
taking into account user preferences.
</p>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14065" title="Abstract">arXiv:2309.14065</a> [<a href="/pdf/2309.14065" title="Download PDF">pdf</a>, <a href="/format/2309.14065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+S">Siqi Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weixi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Renzhong Guo</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+S">Shengjun Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the realm of robotic intelligence, achieving efficient and precise RGB-D
semantic segmentation is a key cornerstone. State-of-the-art multimodal
semantic segmentation methods, primarily rooted in symmetrical skeleton
networks, find it challenging to harmonize computational efficiency and
precision. In this work, we propose AsymFormer, a novel network for real-time
RGB-D semantic segmentation, which targets the minimization of superfluous
parameters by optimizing the distribution of computational resources and
introduces an asymmetrical backbone to allow for the effective fusion of
multimodal features. Furthermore, we explore techniques to bolster network
accuracy by redefining feature selection and extracting multi-modal
self-similarity features without a substantial increase in the parameter count,
thereby ensuring real-time execution on robotic platforms. Additionally, a
Local Attention-Guided Feature Selection (LAFS) module is used to selectively
fuse features from different modalities by leveraging their dependencies.
Subsequently, a Cross-Modal Attention-Guided Feature Correlation Embedding
(CMA) module is introduced to further extract cross-modal representations. This
method is evaluated on NYUv2 and SUNRGBD datasets, with AsymFormer
demonstrating competitive results with 52.0\% mIoU on NYUv2 and 49.1\% mIoU on
SUNRGBD. Notably, AsymFormer achieves an inference speed of 65 FPS and after
implementing mixed precision quantization, it attains an impressive inference
speed of 79 FPS on RTX3090. This significantly outperforms existing multi-modal
methods, thereby demonstrating that AsymFormer can strike a balance between
high accuracy and efficiency for RGB-D semantic segmentation.
</p>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14068" title="Abstract">arXiv:2309.14068</a> [<a href="/pdf/2309.14068" title="Download PDF">pdf</a>, <a href="/format/2309.14068" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Soft Mixture Denoising: Beyond the Expressive Bottleneck of Diffusion  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yangming Li</a>, 
<a href="/search/cs?searchtype=author&query=van+Breugel%2C+B">Boris van Breugel</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Schaar%2C+M">Mihaela van der Schaar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICLR-2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Because diffusion models have shown impressive performances in a number of
tasks, such as image synthesis, there is a trend in recent works to prove (with
certain assumptions) that these models have strong approximation capabilities.
In this paper, we show that current diffusion models actually have an
expressive bottleneck in backward denoising and some assumption made by
existing theoretical guarantees is too strong. Based on this finding, we prove
that diffusion models have unbounded errors in both local denoising and global
approximation. In light of our theoretical studies, we introduce soft mixture
denoising (SMD), an expressive and efficient model for backward denoising. SMD
not only permits diffusion models to well approximate any Gaussian mixture
distributions in theory, but also is simple and efficient for implementation.
Our experiments on multiple image datasets show that SMD significantly improves
different types of diffusion models (e.g., DDPM), especially in the situation
of few backward iterations.
</p>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14072" title="Abstract">arXiv:2309.14072</a> [<a href="/pdf/2309.14072" title="Download PDF">pdf</a>, <a href="/format/2309.14072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BoIR: Box-Supervised Instance Representation for Multi-Person Pose  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeong%2C+U">Uyoung Jeong</a>, 
<a href="/search/cs?searchtype=author&query=Baek%2C+S">Seungryul Baek</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+H+J">Hyung Jin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+K+I">Kwang In Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023, 19 pages including the appendix, 6 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Single-stage multi-person human pose estimation (MPPE) methods have shown
great performance improvements, but existing methods fail to disentangle
features by individual instances under crowded scenes. In this paper, we
propose a bounding box-level instance representation learning called BoIR,
which simultaneously solves instance detection, instance disentanglement, and
instance-keypoint association problems. Our new instance embedding loss
provides a learning signal on the entire area of the image with bounding box
annotations, achieving globally consistent and disentangled instance
representation. Our method exploits multi-task learning of bottom-up keypoint
estimation, bounding box regression, and contrastive instance embedding
learning, without additional computational cost during inference. BoIR is
effective for crowded scenes, outperforming state-of-the-art on COCO val (0.8
AP), COCO test-dev (0.5 AP), CrowdPose (4.9 AP), and OCHuman (3.5 AP). Code
will be available at https://github.com/uyoung-jeong/BoIR
</p>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14074" title="Abstract">arXiv:2309.14074</a> [<a href="/pdf/2309.14074" title="Download PDF">pdf</a>, <a href="/format/2309.14074" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FlexCast: genuine overlay-based atomic multicast
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Batista%2C+E">Eli&#xe3; Batista</a>, 
<a href="/search/cs?searchtype=author&query=Coelho%2C+P">Paulo Coelho</a>, 
<a href="/search/cs?searchtype=author&query=Alchieri%2C+E">Eduardo Alchieri</a>, 
<a href="/search/cs?searchtype=author&query=Dotti%2C+F">Fernando Dotti</a>, 
<a href="/search/cs?searchtype=author&query=Pedone%2C+F">Fernando Pedone</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">Atomic multicast is a communication abstraction where messages are propagated
to groups of processes with reliability and order guarantees. Atomic multicast
is at the core of strongly consistent storage and transactional systems. This
paper presents FlexCast, the first genuine overlay-based atomic multicast
protocol. Genuineness captures the essence of atomic multicast in that only the
sender of a message and the message's destinations coordinate to order the
message, leading to efficient protocols. Overlay-based protocols restrict how
process groups can communicate. Limiting communication leads to simpler
protocols and reduces the amount of information each process must keep about
the rest of the system. FlexCast implements genuine atomic multicast using a
complete DAG overlay. We experimentally evaluate FlexCast in a geographically
distributed environment using gTPC-C, a variation of the TPC-C benchmark that
takes into account geographical distribution and locality. We show that, by
exploiting genuineness and workload locality, FlexCast outperforms
well-established atomic multicast protocols without the inherent communication
overhead of state-of-the-art non-genuine multicast protocols.
</p>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14078" title="Abstract">arXiv:2309.14078</a> [<a href="/pdf/2309.14078" title="Download PDF">pdf</a>, <a href="/format/2309.14078" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ODE-based Recurrent Model-free Reinforcement Learning for POMDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xuanle Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Duzhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+L">Liyuan Han</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tielin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bo Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Neural ordinary differential equations (ODEs) are widely recognized as the
standard for modeling physical mechanisms, which help to perform approximate
inference in unknown physical or biological environments. In partially
observable (PO) environments, how to infer unseen information from raw
observations puzzled the agents. By using a recurrent policy with a compact
context, context-based reinforcement learning provides a flexible way to
extract unobservable information from historical transitions. To help the agent
extract more dynamics-related information, we present a novel ODE-based
recurrent model combines with model-free reinforcement learning (RL) framework
to solve partially observable Markov decision processes (POMDPs). We
experimentally demonstrate the efficacy of our methods across various PO
continuous control and meta-RL tasks. Furthermore, our experiments illustrate
that our method is robust against irregular observations, owing to the ability
of ODEs to model irregularly-sampled time series.
</p>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14084" title="Abstract">arXiv:2309.14084</a> [<a href="/pdf/2309.14084" title="Download PDF">pdf</a>, <a href="/format/2309.14084" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comprehensive Overview of Named Entity Recognition: Models,  Domain-Specific Applications and Challenges
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pakhale%2C+K">Kalyani Pakhale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)

</div>
<p class="mathjax">In the domain of Natural Language Processing (NLP), Named Entity Recognition
(NER) stands out as a pivotal mechanism for extracting structured insights from
unstructured text. This manuscript offers an exhaustive exploration into the
evolving landscape of NER methodologies, blending foundational principles with
contemporary AI advancements. Beginning with the rudimentary concepts of NER,
the study spans a spectrum of techniques from traditional rule-based strategies
to the contemporary marvels of transformer architectures, particularly
highlighting integrations such as BERT with LSTM and CNN. The narrative
accentuates domain-specific NER models, tailored for intricate areas like
finance, legal, and healthcare, emphasizing their specialized adaptability.
Additionally, the research delves into cutting-edge paradigms including
reinforcement learning, innovative constructs like E-NER, and the interplay of
Optical Character Recognition (OCR) in augmenting NER capabilities. Grounding
its insights in practical realms, the paper sheds light on the indispensable
role of NER in sectors like finance and biomedicine, addressing the unique
challenges they present. The conclusion outlines open challenges and avenues,
marking this work as a comprehensive guide for those delving into NER research
and applications.
</p>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14085" title="Abstract">arXiv:2309.14085</a> [<a href="/pdf/2309.14085" title="Download PDF">pdf</a>, <a href="/format/2309.14085" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New algebraic fast algorithms for $N$-body problems in two and three  dimensions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Khan%2C+R">Ritesh Khan</a>, 
<a href="/search/math?searchtype=author&query=Ambikasaran%2C+S">Sivaram Ambikasaran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Mathematical Physics (math-ph)

</div>
<p class="mathjax">This article presents two new algebraic algorithms to perform fast
matrix-vector product for $N$-body problems in $d$ dimensions, namely
nHODLR$d$D (nested algorithm) and s-nHODLR$d$D (semi-nested or partially nested
algorithm). The nHODLR$d$D and s-nHODLR$d$D algorithms are the nested and
semi-nested version of our previously proposed fast algorithm, the
hierarchically off-diagonal low-rank matrix in $d$ dimensions (HODLR$d$D),
respectively, where the admissible clusters are the certain far-field and the
vertex-sharing clusters. We rely on algebraic low-rank approximation techniques
(ACA and NCA) and develop both algorithms in a black-box (kernel-independent)
fashion. The initialization time of the proposed hierarchical structures scales
quasi-linearly. Using the nHODLR$d$D and s-nHODLR$d$D hierarchical structures,
one can perform the multiplication of a dense matrix (arising out of $N$-body
problems) with a vector that scales as $\mathcal{O}(pN)$ and $\mathcal{O}(pN
\log(N))$, respectively, where $p$ grows at most poly logarithmically with $N$.
The numerical results in $2$D and $3$D $(d=2,3)$ show that the proposed
nHODLR$d$D algorithm is competitive to the algebraic Fast Multipole Method in
$d$ dimensions with respect to the matrix-vector product time and space
complexity. The C++ implementation with OpenMP parallelization of the proposed
algorithms is available at \url{https://github.com/riteshkhan/nHODLRdD/}.
</p>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14086" title="Abstract">arXiv:2309.14086</a> [<a href="/pdf/2309.14086" title="Download PDF">pdf</a>, <a href="/format/2309.14086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A selection of PID type controller settings via LQR approach for  two-wheeled balancing robot
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Laddach%2C+K">Krzysztof Laddach</a>, 
<a href="/search/eess?searchtype=author&query=Czy%C5%BCniewski%2C+M">Mateusz Czy&#x17c;niewski</a>, 
<a href="/search/eess?searchtype=author&query=%C5%81angowski%2C+R">Rafa&#x142; &#x141;angowski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference paper
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2021 25th International Conference MMAR, Mi\k{e}dzyzdroje, Poland,
  2021, pp. 378-383
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The problem of PID type controller tuning has been addressed in this paper.
In particular, a method of selection of PD settings based on the solution of
linear-quadratic optimisation problem using the energy criterion has been
investigated. Thus, the possibility of transforming optimal settings of the
linear-quadratic regulator into the settings of the controller in the classical
control system has been given. The presented methodology has been used during
synthesis of control system for a two-wheeled balancing robot. Finally, the
performance of the proposed control system has been validated by simulation in
Matlab-Simulink environment with the use of a two-wheeled balancing robot
model.
</p>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14088" title="Abstract">arXiv:2309.14088</a> [<a href="/pdf/2309.14088" title="Download PDF">pdf</a>, <a href="/format/2309.14088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REPA: Client Clustering without Training and Data Labels for Improved  Federated Learning in Non-IID Settings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Radovi%C4%8D%2C+B">Boris Radovi&#x10d;</a>, 
<a href="/search/cs?searchtype=author&query=Pejovi%C4%87%2C+V">Veljko Pejovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Clustering clients into groups that exhibit relatively homogeneous data
distributions represents one of the major means of improving the performance of
federated learning (FL) in non-independent and identically distributed
(non-IID) data settings. Yet, the applicability of current state-of-the-art
approaches remains limited as these approaches cluster clients based on
information, such as the evolution of local model parameters, that is only
obtainable through actual on-client training. On the other hand, there is a
need to make FL models available to clients who are not able to perform the
training themselves, as they do not have the processing capabilities required
for training, or simply want to use the model without participating in the
training. Furthermore, the existing alternative approaches that avert the
training still require that individual clients have a sufficient amount of
labeled data upon which the clustering is based, essentially assuming that each
client is a data annotator. In this paper, we present REPA, an approach to
client clustering in non-IID FL settings that requires neither training nor
labeled data collection. REPA uses a novel supervised autoencoder-based method
to create embeddings that profile a client's underlying data-generating
processes without exposing the data to the server and without requiring local
training. Our experimental analysis over three different datasets demonstrates
that REPA delivers state-of-the-art model performance while expanding the
applicability of cluster-based FL to previously uncovered use cases.
</p>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14090" title="Abstract">arXiv:2309.14090</a> [<a href="/pdf/2309.14090" title="Download PDF">pdf</a>, <a href="/format/2309.14090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional autoencoder-based multimodal one-class classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Laakom%2C+F">Firas Laakom</a>, 
<a href="/search/cs?searchtype=author&query=Sohrab%2C+F">Fahad Sohrab</a>, 
<a href="/search/cs?searchtype=author&query=Raitoharju%2C+J">Jenni Raitoharju</a>, 
<a href="/search/cs?searchtype=author&query=Iosifidis%2C+A">Alexandros Iosifidis</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 1 figure, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">One-class classification refers to approaches of learning using data from a
single class only. In this paper, we propose a deep learning one-class
classification method suitable for multimodal data, which relies on two
convolutional autoencoders jointly trained to reconstruct the positive input
data while obtaining the data representations in the latent space as compact as
possible. During inference, the distance of the latent representation of an
input to the origin can be used as an anomaly score. Experimental results using
a multimodal macroinvertebrate image classification dataset show that the
proposed multimodal method yields better results as compared to the unimodal
approach. Furthermore, study the effect of different input image sizes, and we
investigate how recently proposed feature diversity regularizers affect the
performance of our approach. We show that such regularizers improve
performance.
</p>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14091" title="Abstract">arXiv:2309.14091</a> [<a href="/pdf/2309.14091" title="Download PDF">pdf</a>, <a href="/format/2309.14091" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Benefit of Optimal Transport for Curriculum Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klink%2C+P">Pascal Klink</a>, 
<a href="/search/cs?searchtype=author&query=D%27Eramo%2C+C">Carlo D&#x27;Eramo</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Curriculum reinforcement learning (CRL) allows solving complex tasks by
generating a tailored sequence of learning tasks, starting from easy ones and
subsequently increasing their difficulty. Although the potential of curricula
in RL has been clearly shown in various works, it is less clear how to generate
them for a given learning environment, resulting in various methods aiming to
automate this task. In this work, we focus on framing curricula as
interpolations between task distributions, which has previously been shown to
be a viable approach to CRL. Identifying key issues of existing methods, we
frame the generation of a curriculum as a constrained optimal transport problem
between task distributions. Benchmarks show that this way of curriculum
generation can improve upon existing CRL methods, yielding high performance in
various tasks with different characteristics.
</p>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14092" title="Abstract">arXiv:2309.14092</a> [<a href="/pdf/2309.14092" title="Download PDF">pdf</a>, <a href="/format/2309.14092" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From OCEL to DOCEL -- Datasets and Automated Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Goossens%2C+A">Alexandre Goossens</a>, 
<a href="/search/cs?searchtype=author&query=Rebmann%2C+A">Adrian Rebmann</a>, 
<a href="/search/cs?searchtype=author&query=De+Smedt%2C+J">Johannes De Smedt</a>, 
<a href="/search/cs?searchtype=author&query=Vanthienen%2C+J">Jan Vanthienen</a>, 
<a href="/search/cs?searchtype=author&query=van+der+Aa%2C+H">Han van der Aa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">Object-centric event data represent processes from the point of view of all
the involved object types. This perspective has gained interest in recent years
as it supports the analysis of processes that previously could not be
adequately captured, due to the lack of a clear case notion as well as an
increasing amount of output data that needs to be stored. Although publicly
available event logs are crucial artifacts for researchers to develop and
evaluate novel process mining techniques, the currently available
object-centric event logs have limitations in this regard. Specifically, they
mainly focus on control-flow and rarely contain objects with attributes that
change over time, even though this is not realistic, as the attribute values of
objects can be altered during their lifecycle. This paper addresses this gap by
providing two means of establishing object-centric datasets with dynamically
evolving attributes. First, we provide event log generators, which allow
researchers to generate customized, artificial logs with dynamic attributes in
the recently proposed DOCEL format. Second, we propose and evaluate an
algorithm to convert OCEL logs into DOCEL logs, which involves the detection of
event attributes that capture evolving object information and the creation of
dynamic attributes from these. Through these contributions, this paper supports
the advancement of object-centric process analysis by providing researchers
with new means to obtain relevant data to use during the development of new
techniques.
</p>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14094" title="Abstract">arXiv:2309.14094</a> [<a href="/pdf/2309.14094" title="Download PDF">pdf</a>, <a href="/format/2309.14094" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoiceLens: Controllable Speaker Generation and Editing with Flow
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Currently, many multi-speaker speech synthesis and voice conversion systems
address speaker variations with an embedding vector. Modeling it directly
allows new voices outside of training data to be synthesized. GMM based
approaches such as Tacospawn are favored in literature for this generation
task, but there are still some limitations when difficult conditionings are
involved. In this paper, we propose VoiceLens, a semi-supervised flow-based
approach, to model speaker embedding distributions for multi-conditional
speaker generation. VoiceLens maps speaker embeddings into a combination of
independent attributes and residual information. It allows new voices
associated with certain attributes to be \textit{generated} for existing TTS
models, and attributes of known voices to be meaningfully \textit{edited}. We
show in this paper, VoiceLens displays an unconditional generation capacity
that is similar to Tacospawn while obtaining higher controllability and
flexibility when used in a conditional manner. In addition, we show
synthesizing less noisy speech from known noisy speakers without re-training
the TTS model is possible via solely editing their embeddings with a SNR
conditioned VoiceLens model. Demos are available at
sos1sos2sixteen.github.io/voicelens.
</p>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14096" title="Abstract">arXiv:2309.14096</a> [<a href="/pdf/2309.14096" title="Download PDF">pdf</a>, <a href="/format/2309.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tracking Control for a Spherical Pendulum via Curriculum Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Klink%2C+P">Pascal Klink</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+F">Florian Wolf</a>, 
<a href="/search/cs?searchtype=author&query=Ploeger%2C+K">Kai Ploeger</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>, 
<a href="/search/cs?searchtype=author&query=Pajarinen%2C+J">Joni Pajarinen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Reinforcement Learning (RL) allows learning non-trivial robot control laws
purely from data. However, many successful applications of RL have relied on
ad-hoc regularizations, such as hand-crafted curricula, to regularize the
learning performance. In this paper, we pair a recent algorithm for
automatically building curricula with RL on massively parallelized simulations
to learn a tracking controller for a spherical pendulum on a robotic arm via
RL. Through an improved optimization scheme that better respects the
non-Euclidean task structure, we allow the method to reliably generate
curricula of trajectories to be tracked, resulting in faster and more robust
learning compared to an RL baseline that does not exploit this form of
structured learning. The learned policy matches the performance of an optimal
control baseline on the real system, demonstrating the potential of curriculum
RL to jointly learn state estimation and control for non-linear tracking tasks.
</p>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14097" title="Abstract">arXiv:2309.14097</a> [<a href="/pdf/2309.14097" title="Download PDF">pdf</a>, <a href="/format/2309.14097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How do users design scientific workflows? The Case of Snakemake
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pohl%2C+S">Sebastian Pohl</a>, 
<a href="/search/cs?searchtype=author&query=Elfaramawy%2C+N">Nourhan Elfaramawy</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+K">Kedi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Kehr%2C+B">Birte Kehr</a>, 
<a href="/search/cs?searchtype=author&query=Weidlich%2C+M">Matthias Weidlich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
<p class="mathjax">Scientific workflows automate the analysis of large-scale scientific data,
fostering the reuse of data processing operators as well as the reproducibility
and traceability of analysis results. In exploratory research, however,
workflows are continuously adapted, utilizing a wide range of tools and
software libraries, to test scientific hypotheses. Script-based workflow
engines cater to the required flexibility through direct integration of
programming primitives but lack abstractions for interactive exploration of the
workflow design by a user during workflow execution. To derive requirements for
such interactive workflows, we conduct an empirical study on the use of
Snakemake, a popular Python-based workflow engine. Based on workflows collected
from 1602 GitHub repositories, we present insights on common structures of
Snakemake workflows, as well as the language features typically adopted in
their specification.
</p>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14098" title="Abstract">arXiv:2309.14098</a> [<a href="/pdf/2309.14098" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computer Science Framework to Teach Community-Based Environmental  Literacy and Data Literacy to Diverse Students
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baek%2C+C">Clare Baek</a>, 
<a href="/search/cs?searchtype=author&query=Saito-Stehberger%2C+D">Dana Saito-Stehberger</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+S">Sharin Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Nam%2C+A">Adam Nam</a>, 
<a href="/search/cs?searchtype=author&query=Warschauer%2C+M">Mark Warschauer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">This study introduces an integrated curriculum designed to empower
underrepresented students by combining environmental literacy, data literacy,
and computer science. The framework promotes environmental awareness, data
literacy, and civic engagement using a culturally sustaining approach. This
integrated curriculum is embedded with resources to support language
development, technology skills, and coding skills to accommodate the diverse
needs of students. To evaluate the effectiveness of this curriculum, we
conducted a pilot study in a 5th-grade special education classroom with
multilingual Latinx students. During the pilot, students utilized Scratch, a
block-based coding language, to create interactive projects that showcased
locally collected data, which they used to communicate environmental challenges
and propose solutions to community leaders. This approach allowed students to
engage with environmental literacy at a deeper level, harnessing their
creativity and community knowledge in the digital learning environment.
Moreover, this curriculum equipped students with the skills to critically
analyze political and socio-cultural factors impacting environmental
sustainability. Students not only gained knowledge within the classroom but
also applied their learning to address real environmental issues within their
community. The results of the pilot study underscore the efficacy of this
integrated approach.
</p>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14102" title="Abstract">arXiv:2309.14102</a> [<a href="/pdf/2309.14102" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Normalization of direct citations in publication-level networks:  Evaluation of six approaches
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sj%C3%B6g%C3%A5rdea%2C+P">Peter Sj&#xf6;g&#xe5;rdea</a>, 
<a href="/search/cs?searchtype=author&query=Ahlgren%2C+P">Per Ahlgren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
<p class="mathjax">Clustering of publication networks is an efficient way to obtain
classifications of large collections of research publications. Such
classifications can be used to, e.g., detect research topics, normalize
citation relations, or explore the publication output of a unit. Citation
networks can be created using a variety of approaches. Best practices to obtain
classifications using clustering have been investigated, in particular the
performance of different publication-publication relatedness measures. However,
evaluation of different approaches to normalization of citation relations have
not been explored to the same extent. In this paper, we evaluate five
approaches to normalization of direct citation relations with respect to
clustering solution quality in four data sets. A sixth approach is evaluated
using no normalization. To assess the quality of clustering solutions, we use
three measures. (1) We compare the clustering solution to the reference lists
of a set of publications using the Adjusted Rand Index. (2) Using the Sihouette
width measure, we quantity to which extent the publications have relations to
other clusters than the one they have been assigned to. (3) We propose a
measure that captures publications that have probably been inaccurately
assigned. The results clearly show that normalization is preferred over
unnormalized direct citation relations. Furthermore, the results indicate that
the fractional normalization approach, which can be considered the standard
approach, causes inaccurate assignments. The geometric normalization approach
has a similar performance as the fractional approach regarding Adjusted Rand
Index and Silhouette width but leads to fewer inaccurate assignments. We
therefore believe that the geometric approach may be preferred over the
fractional approach.
</p>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14104" title="Abstract">arXiv:2309.14104</a> [<a href="/pdf/2309.14104" title="Download PDF">pdf</a>, <a href="/format/2309.14104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Affective Game Computing: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yannakakis%2C+G+N">Georgios N. Yannakakis</a>, 
<a href="/search/cs?searchtype=author&query=Melhart%2C+D">David Melhart</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the IEEE, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
<p class="mathjax">This paper surveys the current state of the art in affective computing
principles, methods and tools as applied to games. We review this emerging
field, namely affective game computing, through the lens of the four core
phases of the affective loop: game affect elicitation, game affect sensing,
game affect detection and game affect adaptation. In addition, we provide a
taxonomy of terms, methods and approaches used across the four phases of the
affective game loop and situate the field within this taxonomy. We continue
with a comprehensive review of available affect data collection methods with
regards to gaming interfaces, sensors, annotation protocols, and available
corpora. The paper concludes with a discussion on the current limitations of
affective game computing and our vision for the most promising future research
directions in the field.
</p>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14112" title="Abstract">arXiv:2309.14112</a> [<a href="/pdf/2309.14112" title="Download PDF">pdf</a>, <a href="/format/2309.14112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-Abstract Value-Based Argumentation Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeromela%2C+J">Jovan Jeromela</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted as a Bachelor Thesis at TU Wien on 2019-11-07. Advisor: Christian Ferm\"uller. 49 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">In his seminal paper, Phan Minh Dung (1995) proposed abstract argumentation
framework, which models argumentation using directed graphs where structureless
arguments are the nodes and attacks among the arguments are the edges. In the
following years, many extensions of this framework were introduced. These
extensions typically add a certain form of structure to the arguments. This
thesis showcases two such extensions -- value-based argumentation framework by
Trevor Bench-Capon (2002) and semi-abstract argumentation framework by Esther
Anna Corsi and Christian Ferm\"uller (2017). The former introduces a mapping
function that links individual arguments to a set of ordered values, enabling a
distinction between objectively and subjectively acceptable arguments. The
latter links claims of individual arguments to propositional formulae and then
applies newly-introduced attack principles in order to make implicit attacks
explicit and to enable a definition of a consequence relation that relies on
neither the truth values nor the interpretations in the usual sense.
<br />The contribution of this thesis is two-fold. Firstly, the new semi-abstract
value-based argumentation framework is introduced. This framework maps
propositional formulae associated with individual arguments to a set of ordered
values. Secondly, a complex moral dilemma is formulated using the original and
the value-based argumentation frameworks showcasing the expressivity of these
formalisms.
</p>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14117" title="Abstract">arXiv:2309.14117</a> [<a href="/pdf/2309.14117" title="Download PDF">pdf</a>, <a href="/format/2309.14117" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small Objects Matters in Weakly-supervised Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mun%2C+C">Cheolhyun Mun</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+S">Sanghuk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Uh%2C+Y">Youngjung Uh</a>, 
<a href="/search/cs?searchtype=author&query=Choe%2C+J">Junsuk Choe</a>, 
<a href="/search/cs?searchtype=author&query=Byun%2C+H">Hyeran Byun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to WACV 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Weakly-supervised semantic segmentation (WSSS) performs pixel-wise
classification given only image-level labels for training. Despite the
difficulty of this task, the research community has achieved promising results
over the last five years. Still, current WSSS literature misses the detailed
sense of how well the methods perform on different sizes of objects. Thus we
propose a novel evaluation metric to provide a comprehensive assessment across
different object sizes and collect a size-balanced evaluation set to complement
PASCAL VOC. With these two gadgets, we reveal that the existing WSSS methods
struggle in capturing small objects. Furthermore, we propose a size-balanced
cross-entropy loss coupled with a proper training strategy. It generally
improves existing WSSS methods as validated upon ten baselines on three
different datasets.
</p>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14118" title="Abstract">arXiv:2309.14118</a> [<a href="/pdf/2309.14118" title="Download PDF">pdf</a>, <a href="/format/2309.14118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MultiModN- Multimodal, Multi-Task, Interpretable Modular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Swamy%2C+V">Vinitra Swamy</a>, 
<a href="/search/cs?searchtype=author&query=Satayeva%2C+M">Malika Satayeva</a>, 
<a href="/search/cs?searchtype=author&query=Frej%2C+J">Jibril Frej</a>, 
<a href="/search/cs?searchtype=author&query=Bossy%2C+T">Thierry Bossy</a>, 
<a href="/search/cs?searchtype=author&query=Vogels%2C+T">Thijs Vogels</a>, 
<a href="/search/cs?searchtype=author&query=Jaggi%2C+M">Martin Jaggi</a>, 
<a href="/search/cs?searchtype=author&query=K%C3%A4ser%2C+T">Tanja K&#xe4;ser</a>, 
<a href="/search/cs?searchtype=author&query=Hartley%2C+M">Mary-Anne Hartley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a full paper at NeurIPS 2023 in New Orleans, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Predicting multiple real-world tasks in a single model often requires a
particularly diverse feature space. Multimodal (MM) models aim to extract the
synergistic predictive potential of multiple data types to create a shared
feature space with aligned semantic meaning across inputs of drastically
varying sizes (i.e. images, text, sound). Most current MM architectures fuse
these representations in parallel, which not only limits their interpretability
but also creates a dependency on modality availability. We present MultiModN, a
multimodal, modular network that fuses latent representations in a sequence of
any number, combination, or type of modality while providing granular real-time
predictive feedback on any number or combination of predictive tasks.
MultiModN's composable pipeline is interpretable-by-design, as well as innately
multi-task and robust to the fundamental issue of biased missingness. We
perform four experiments on several benchmark MM datasets across 10 real-world
tasks (predicting medical diagnoses, academic performance, and weather), and
show that MultiModN's sequential MM fusion does not compromise performance
compared with a baseline of parallel fusion. By simulating the challenging bias
of missing not-at-random (MNAR), this work shows that, contrary to MultiModN,
parallel fusion baselines erroneously learn MNAR and suffer catastrophic
failure when faced with different patterns of MNAR at inference. To the best of
our knowledge, this is the first inherently MNAR-resistant approach to MM
modeling. In conclusion, MultiModN provides granular insights, robustness, and
flexibility without compromising performance.
</p>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14122" title="Abstract">arXiv:2309.14122</a> [<a href="/pdf/2309.14122" title="Download PDF">pdf</a>, <a href="/format/2309.14122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via  Substitution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ba%2C+Z">Zhongjie Ba</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+J">Jieming Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jiachen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Peng Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qinglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+K">Kui Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Advanced text-to-image models such as DALL-E 2 and Midjourney possess the
capacity to generate highly realistic images, raising significant concerns
regarding the potential proliferation of unsafe content. This includes adult,
violent, or deceptive imagery of political figures. Despite claims of rigorous
safety mechanisms implemented in these models to restrict the generation of
not-safe-for-work (NSFW) content, we successfully devise and exhibit the first
prompt attacks on Midjourney, resulting in the production of abundant
photorealistic NSFW images. We reveal the fundamental principles of such prompt
attacks and suggest strategically substituting high-risk sections within a
suspect prompt to evade closed-source safety measures. Our novel framework,
SurrogatePrompt, systematically generates attack prompts, utilizing large
language models, image-to-text, and image-to-image modules to automate attack
prompt creation at scale. Evaluation results disclose an 88% success rate in
bypassing Midjourney's proprietary safety filter with our attack prompts,
leading to the generation of counterfeit images depicting political figures in
violent scenarios. Both subjective and objective assessments validate that the
images generated from our attack prompts present considerable safety hazards.
</p>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14123" title="Abstract">arXiv:2309.14123</a> [<a href="/pdf/2309.14123" title="Download PDF">pdf</a>, <a href="/format/2309.14123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Harnessing Supervised Learning for Adaptive Beamforming in Multibeam  Satellite Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ortiz%2C+F">Flor Ortiz</a>, 
<a href="/search/eess?searchtype=author&query=Vasquez-Peralvo%2C+J+A">Juan A. Vasquez-Peralvo</a>, 
<a href="/search/eess?searchtype=author&query=Querol%2C+J">Jorge Querol</a>, 
<a href="/search/eess?searchtype=author&query=Lagunas%2C+E">Eva Lagunas</a>, 
<a href="/search/eess?searchtype=author&query=Rios%2C+J+L+G">Jorge L. Gonzalez Rios</a>, 
<a href="/search/eess?searchtype=author&query=Garces%2C+L">Luis Garces</a>, 
<a href="/search/eess?searchtype=author&query=Monzon-Baeza%2C+V">Victor Monzon-Baeza</a>, 
<a href="/search/eess?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> under review for conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In today's ever-connected world, the demand for fast and widespread
connectivity is insatiable, making multibeam satellite systems an indispensable
pillar of modern telecommunications infrastructure. However, the evolving
communication landscape necessitates a high degree of adaptability. This
adaptability is particularly crucial for beamforming, as it enables the
adjustment of peak throughput and beamwidth to meet fluctuating traffic demands
by varying the beamwidth, side lobe level (SLL), and effective isotropic
radiated power (EIRP). This paper introduces an innovative approach rooted in
supervised learning to efficiently derive the requisite beamforming matrix,
aligning it with system requirements. Significantly reducing computation time,
this method is uniquely tailored for real-time adaptation, enhancing the
agility and responsiveness of satellite multibeam systems. Exploiting the power
of supervised learning, this research enables multibeam satellites to respond
quickly and intelligently to changing communication needs, ultimately ensuring
uninterrupted and optimized connectivity in a dynamic world.
</p>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14125" title="Abstract">arXiv:2309.14125</a> [<a href="/pdf/2309.14125" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Driving behavior-guided battery health monitoring for electric vehicles  using machine learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Jiang%2C+N">Nanhua Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jiawei Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Weiran Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Ren%2C+Y">Yao Ren</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+J">Jing Lin</a>, 
<a href="/search/eess?searchtype=author&query=Khoo%2C+E">Edwin Khoo</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Ziyou Song</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">An accurate estimation of the state of health (SOH) of batteries is critical
to ensuring the safe and reliable operation of electric vehicles (EVs).
Feature-based machine learning methods have exhibited enormous potential for
rapidly and precisely monitoring battery health status. However, simultaneously
using various health indicators (HIs) may weaken estimation performance due to
feature redundancy. Furthermore, ignoring real-world driving behaviors can lead
to inaccurate estimation results as some features are rarely accessible in
practical scenarios. To address these issues, we proposed a feature-based
machine learning pipeline for reliable battery health monitoring, enabled by
evaluating the acquisition probability of features under real-world driving
conditions. We first summarized and analyzed various individual HIs with
mechanism-related interpretations, which provide insightful guidance on how
these features relate to battery degradation modes. Moreover, all features were
carefully evaluated and screened based on estimation accuracy and correlation
analysis on three public battery degradation datasets. Finally, the
scenario-based feature fusion and acquisition probability-based practicality
evaluation method construct a useful tool for feature extraction with
consideration of driving behaviors. This work highlights the importance of
balancing the performance and practicality of HIs during the development of
feature-based battery health monitoring algorithms.
</p>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14130" title="Abstract">arXiv:2309.14130</a> [<a href="/pdf/2309.14130" title="Download PDF">pdf</a>, <a href="/ps/2309.14130" title="Download PostScript">ps</a>, <a href="/format/2309.14130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Relation between Internal Language Model and Sequence  Discriminative Training for Neural Transducers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zijian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Wei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Schl%C3%BCter%2C+R">Ralf Schl&#xfc;ter</a>, 
<a href="/search/cs?searchtype=author&query=Ney%2C+H">Hermann Ney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Internal language model (ILM) subtraction has been widely applied to improve
the performance of the RNN-Transducer with external language model (LM) fusion
for speech recognition. In this work, we show that sequence discriminative
training has a strong correlation with ILM subtraction from both theoretical
and empirical points of view. Theoretically, we derive that the global optimum
of maximum mutual information (MMI) training shares a similar formula as ILM
subtraction. Empirically, we show that ILM subtraction and sequence
discriminative training achieve similar performance across a wide range of
experiments on Librispeech, including both MMI and minimum Bayes risk (MBR)
criteria, as well as neural transducers and LMs of both full and limited
context. The benefit of ILM subtraction also becomes much smaller after
sequence discriminative training. We also provide an in-depth study to show
that sequence discriminative training has a minimal effect on the commonly used
zero-encoder ILM estimation, but a joint effect on both encoder and prediction
+ joint network for posterior probability reshaping including both ILM and
blank suppression.
</p>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14134" title="Abstract">arXiv:2309.14134</a> [<a href="/pdf/2309.14134" title="Download PDF">pdf</a>, <a href="/format/2309.14134" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Class Classification for Intrusion Detection on Vehicular Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guidry%2C+J">Jake Guidry</a>, 
<a href="/search/cs?searchtype=author&query=Sohrab%2C+F">Fahad Sohrab</a>, 
<a href="/search/cs?searchtype=author&query=Gottumukkala%2C+R">Raju Gottumukkala</a>, 
<a href="/search/cs?searchtype=author&query=Katragadda%2C+S">Satya Katragadda</a>, 
<a href="/search/cs?searchtype=author&query=Gabbouj%2C+M">Moncef Gabbouj</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 2 figures, 4 tables. Accepted at IEEE Symposium Series on Computational Intelligence 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Controller Area Network bus systems within vehicular networks are not
equipped with the tools necessary to ward off and protect themselves from
modern cyber-security threats. Work has been done on using machine learning
methods to detect and report these attacks, but common methods are not robust
towards unknown attacks. These methods usually rely on there being a sufficient
representation of attack data, which may not be available due to there either
not being enough data present to adequately represent its distribution or the
distribution itself is too diverse in nature for there to be a sufficient
representation of it. With the use of one-class classification methods, this
issue can be mitigated as only normal data is required to train a model for the
detection of anomalous instances. Research has been done on the efficacy of
these methods, most notably One-Class Support Vector Machine and Support Vector
Data Description, but many new extensions of these works have been proposed and
have yet to be tested for injection attacks in vehicular networks. In this
paper, we investigate the performance of various state-of-the-art one-class
classification methods for detecting injection attacks on Controller Area
Network bus traffic. We investigate the effectiveness of these techniques on
attacks launched on Controller Area Network buses from two different vehicles
during normal operation and while being attacked. We observe that the Subspace
Support Vector Data Description method outperformed all other tested methods
with a Gmean of about 85%.
</p>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14136" title="Abstract">arXiv:2309.14136</a> [<a href="/pdf/2309.14136" title="Download PDF">pdf</a>, <a href="/format/2309.14136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Image Residual Learning for Scaling Deeper Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guoxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Hongtao Fu</a>, 
<a href="/search/cs?searchtype=author&query=Bors%2C+A+G">Adrian G. Bors</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Deeper Vision Transformers (ViTs) are more challenging to train. We expose a
degradation problem in deeper layers of ViT when using masked image modeling
(MIM) for pre-training. To ease the training of deeper ViTs, we introduce a
self-supervised learning framework called \textbf{M}asked \textbf{I}mage
\textbf{R}esidual \textbf{L}earning (\textbf{MIRL}), which significantly
alleviates the degradation problem, making scaling ViT along depth a promising
direction for performance upgrade. We reformulate the pre-training objective
for deeper layers of ViT as learning to recover the residual of the masked
image. We provide extensive empirical evidence showing that deeper ViTs can be
effectively optimized using MIRL and easily gain accuracy from increased depth.
With the same level of computational complexity as ViT-Base and ViT-Large, we
instantiate 4.5{$\times$} and 2{$\times$} deeper ViTs, dubbed ViT-S-54 and
ViT-B-48. The deeper ViT-S-54, costing 3{$\times$} less than ViT-Large,
achieves performance on par with ViT-Large. ViT-B-48 achieves 86.2\% top-1
accuracy on ImageNet. On one hand, deeper ViTs pre-trained with MIRL exhibit
excellent generalization capabilities on downstream tasks, such as object
detection and semantic segmentation. On the other hand, MIRL demonstrates high
pre-training efficiency. With less pre-training time, MIRL yields competitive
performance compared to other approaches.
</p>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14137" title="Abstract">arXiv:2309.14137</a> [<a href="/pdf/2309.14137" title="Download PDF">pdf</a>, <a href="/format/2309.14137" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IEBins: Iterative Elastic Bins for Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Z">Zhongcai Pei</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Monocular depth estimation (MDE) is a fundamental topic of geometric computer
vision and a core technique for many downstream applications. Recently, several
methods reframe the MDE as a classification-regression problem where a linear
combination of probabilistic distribution and bin centers is used to predict
depth. In this paper, we propose a novel concept of iterative elastic bins
(IEBins) for the classification-regression-based MDE. The proposed IEBins aims
to search for high-quality depth by progressively optimizing the search range,
which involves multiple stages and each stage performs a finer-grained depth
search in the target bin on top of its previous stage. To alleviate the
possible error accumulation during the iterative process, we utilize a novel
elastic target bin to replace the original target bin, the width of which is
adjusted elastically based on the depth uncertainty. Furthermore, we develop a
dedicated framework composed of a feature extractor and an iterative optimizer
that has powerful temporal context modeling capabilities benefiting from the
GRU-based architecture. Extensive experiments on the KITTI, NYU-Depth-v2 and
SUN RGB-D datasets demonstrate that the proposed method surpasses prior
state-of-the-art competitors. The source code is publicly available at
https://github.com/ShuweiShao/IEBins.
</p>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14139" title="Abstract">arXiv:2309.14139</a> [<a href="/pdf/2309.14139" title="Download PDF">pdf</a>, <a href="/format/2309.14139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Serverless Computing on Peer To Peer Training  Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barral%2C+A">Amine Barral</a>, 
<a href="/search/cs?searchtype=author&query=Trabelsi%2C+R">Ranim Trabelsi</a>, 
<a href="/search/cs?searchtype=author&query=Jaafar%2C+F">Fehmi Jaafar</a>, 
<a href="/search/cs?searchtype=author&query=Petrillo%2C+F">Fabio Petrillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The increasing demand for computational power in big data and machine
learning has driven the development of distributed training methodologies.
Among these, peer-to-peer (P2P) networks provide advantages such as enhanced
scalability and fault tolerance. However, they also encounter challenges
related to resource consumption, costs, and communication overhead as the
number of participating peers grows. In this paper, we introduce a novel
architecture that combines serverless computing with P2P networks for
distributed training and present a method for efficient parallel gradient
computation under resource constraints.
<br />Our findings show a significant enhancement in gradient computation time,
with up to a 97.34\% improvement compared to conventional P2P distributed
training methods. As for costs, our examination confirmed that the serverless
architecture could incur higher expenses, reaching up to 5.4 times more than
instance-based architectures. It is essential to consider that these higher
costs are associated with marked improvements in computation time, particularly
under resource-constrained scenarios. Despite the cost-time trade-off, the
serverless approach still holds promise due to its pay-as-you-go model.
Utilizing dynamic resource allocation, it enables faster training times and
optimized resource utilization, making it a promising candidate for a wide
range of machine learning applications.
</p>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14145" title="Abstract">arXiv:2309.14145</a> [<a href="/pdf/2309.14145" title="Download PDF">pdf</a>, <a href="/ps/2309.14145" title="Download PostScript">ps</a>, <a href="/format/2309.14145" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feedback Increases the Capacity of Queues with Bounded Service Times
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahasranand%2C+K+R">K.R.Sahasranand</a>, 
<a href="/search/cs?searchtype=author&query=Tchamkerten%2C+A">Aslan Tchamkerten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages; two-column
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In the "Bits Through Queues" paper, it was conjectured that full feedback
always increases the capacity of first-in-first-out queues, except when the
service time distribution is memoryless. More recently, a non-explicit
sufficient condition on the service time under which feedback increases
capacity was provided, along with simple examples of service times satisfying
this condition.
<br />In this paper, it is shown that full feedback increases the capacity of
queues with bounded service times. This result is obtained by investigating a
generalized notion of feedback, with full feedback and weak feedback as
particular cases.
</p>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14146" title="Abstract">arXiv:2309.14146</a> [<a href="/pdf/2309.14146" title="Download PDF">pdf</a>, <a href="/format/2309.14146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Examining Temporal Bias in Abusive Language Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jin%2C+M">Mali Jin</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+Y">Yida Mu</a>, 
<a href="/search/cs?searchtype=author&query=Maynard%2C+D">Diana Maynard</a>, 
<a href="/search/cs?searchtype=author&query=Bontcheva%2C+K">Kalina Bontcheva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The use of abusive language online has become an increasingly pervasive
problem that damages both individuals and society, with effects ranging from
psychological harm right through to escalation to real-life violence and even
death. Machine learning models have been developed to automatically detect
abusive language, but these models can suffer from temporal bias, the
phenomenon in which topics, language use or social norms change over time. This
study aims to investigate the nature and impact of temporal bias in abusive
language detection across various languages and explore mitigation methods. We
evaluate the performance of models on abusive data sets from different time
periods. Our results demonstrate that temporal bias is a significant challenge
for abusive language detection, with models trained on historical data showing
a significant drop in performance over time. We also present an extensive
linguistic analysis of these abusive data sets from a diachronic perspective,
aiming to explore the reasons for language evolution and performance decline.
This study sheds light on the pervasive issue of temporal bias in abusive
language detection across languages, offering crucial insights into language
evolution and temporal bias mitigation.
</p>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14148" title="Abstract">arXiv:2309.14148</a> [<a href="/pdf/2309.14148" title="Download PDF">pdf</a>, <a href="/format/2309.14148" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPIRT: A Fault-Tolerant and Reliable Peer-to-Peer Serverless ML Training  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Barrak%2C+A">Amine Barrak</a>, 
<a href="/search/cs?searchtype=author&query=Jaziri%2C+M">Mayssa Jaziri</a>, 
<a href="/search/cs?searchtype=author&query=Trabelsi%2C+R">Ranim Trabelsi</a>, 
<a href="/search/cs?searchtype=author&query=Jaafar%2C+F">Fehmi Jaafar</a>, 
<a href="/search/cs?searchtype=author&query=Petrillo%2C+F">Fabio Petrillo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The advent of serverless computing has ushered in notable advancements in
distributed machine learning, particularly within parameter server-based
architectures. Yet, the integration of serverless features within peer-to-peer
(P2P) distributed networks remains largely uncharted. In this paper, we
introduce SPIRT, a fault-tolerant, reliable, and secure serverless P2P ML
training architecture. designed to bridge this existing gap.
<br />Capitalizing on the inherent robustness and reliability innate to P2P
systems, SPIRT employs RedisAI for in-database operations, leading to an 82\%
reduction in the time required for model updates and gradient averaging across
a variety of models and batch sizes. This architecture showcases resilience
against peer failures and adeptly manages the integration of new peers, thereby
highlighting its fault-tolerant characteristics and scalability. Furthermore,
SPIRT ensures secure communication between peers, enhancing the reliability of
distributed machine learning tasks. Even in the face of Byzantine attacks, the
system's robust aggregation algorithms maintain high levels of accuracy. These
findings illuminate the promising potential of serverless architectures in P2P
distributed machine learning, offering a significant stride towards the
development of more efficient, scalable, and resilient applications.
</p>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14149" title="Abstract">arXiv:2309.14149</a> [<a href="/pdf/2309.14149" title="Download PDF">pdf</a>, <a href="/format/2309.14149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Domain Adaptation by Self-Supervised Learning for Speaker  Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Wan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lantian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">In real-world applications, speaker recognition models often face various
domain-mismatch challenges, leading to a significant drop in performance.
Although numerous domain adaptation techniques have been developed to address
this issue, almost all present methods focus on a simple configuration where
the model is trained in one domain and deployed in another. However, real-world
environments are often complex and may contain multiple domains, making the
methods designed for one-to-one adaptation suboptimal. In our paper, we propose
a self-supervised learning method to tackle this multi-domain adaptation
problem. Building upon the basic self-supervised adaptation algorithm, we
designed three strategies to make it suitable for multi-domain adaptation: an
in-domain negative sampling strategy, a MoCo-like memory bank scheme, and a
CORAL-like distribution alignment. We conducted experiments using VoxCeleb2 as
the source domain dataset and CN-Celeb1 as the target multi-domain dataset. Our
results demonstrate that our method clearly outperforms the basic
self-supervised adaptation method, which simply treats the data of CN-Celeb1 as
a single domain. Importantly, the improvement is consistent in nearly all
in-domain tests and cross-domain tests, demonstrating the effectiveness of our
proposed method.
</p>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14150" title="Abstract">arXiv:2309.14150</a> [<a href="/pdf/2309.14150" title="Download PDF">pdf</a>, <a href="/format/2309.14150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learned Contextual LiDAR Informed Visual Search in Unseen Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+R">Ryan Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Morgenstein%2C+K">Kyle Morgenstein</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+S">Steven Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Sentis%2C+L">Luis Sentis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages + references. 6 figures. 1 algorithm. 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents LIVES: LiDAR Informed Visual Search, an autonomous
planner for unknown environments. We consider the pixel-wise environment
perception problem where one is given 2D range data from LiDAR scans and must
label points contextually as map or non-map in the surroundings for visual
planning. LIVES classifies incoming 2D scans from the wide Field of View (FoV)
LiDAR in unseen environments without prior map information. The
map-generalizable classifier is trained from expert data collected using a
simple cart platform equipped with a map-based classifier in real environments.
A visual planner takes contextual data from scans and uses this information to
plan viewpoints more likely to yield detection of the search target. While
conventional frontier based methods for LiDAR and multi sensor exploration
effectively map environments, they are not tailored to search for people
indoors, which we investigate in this paper. LIVES is baselined against several
existing exploration methods in simulation to verify its performance. Finally,
it is validated in real-world experiments with a Spot robot in a 20x30m indoor
apartment setting. Videos of experimental validation can be found on our
project website at https://sites.google.com/view/lives-icra-2024/home.
</p>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14153" title="Abstract">arXiv:2309.14153</a> [<a href="/pdf/2309.14153" title="Download PDF">pdf</a>, <a href="/format/2309.14153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An optimized quantum minimum searching algorithm with sure-success  probability and its experiment simulation with Cirq
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qingshan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiahao Shen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiaojiao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zidan%2C+M">Mohammed Zidan</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+L">Lian Tong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 8 figures. arXiv admin note: text overlap with <a href="/abs/1908.07943">arXiv:1908.07943</a> by other authors
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Journal of Ambient Intelligence and Humanized Computing, 2021.
  12(11): p. 10425-10434
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Data Structures and Algorithms (cs.DS); Quantum Physics (quant-ph)

</div>
<p class="mathjax">Finding a minimum is an essential part of mathematical models, and it plays
an important role in some optimization problems. Durr and Hoyer proposed a
quantum searching algorithm (DHA), with a certain probability of success, to
achieve quadratic speed than classical ones. In this paper, we propose an
optimized quantum minimum searching algorithm with sure-success probability,
which utilizes Grover-Long searching to implement the optimal exact searching,
and the dynamic strategy to reduce the iterations of our algorithm. Besides, we
optimize the oracle circuit to reduce the number of gates by the simplified
rules. The performance evaluation including the theoretical success rate and
computational complexity shows that our algorithm has higher accuracy and
efficiency than DHA algorithm. Finally, a simulation experiment based on Cirq
is performed to verify its feasibility.
</p>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14156" title="Abstract">arXiv:2309.14156</a> [<a href="/pdf/2309.14156" title="Download PDF">pdf</a>, <a href="/format/2309.14156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Designing and evaluating an online reinforcement learning agent for  physical exercise recommendations in N-of-1 trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meier%2C+D">Dominik Meier</a>, 
<a href="/search/cs?searchtype=author&query=Ensari%2C+I">Ipek Ensari</a>, 
<a href="/search/cs?searchtype=author&query=Konigorski%2C+S">Stefan Konigorski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applications (stat.AP); Methodology (stat.ME)

</div>
<p class="mathjax">Personalized adaptive interventions offer the opportunity to increase patient
benefits, however, there are challenges in their planning and implementation.
Once implemented, it is an important question whether personalized adaptive
interventions are indeed clinically more effective compared to a fixed gold
standard intervention. In this paper, we present an innovative N-of-1 trial
study design testing whether implementing a personalized intervention by an
online reinforcement learning agent is feasible and effective. Throughout, we
use a new study on physical exercise recommendations to reduce pain in
endometriosis for illustration. We describe the design of a contextual bandit
recommendation agent and evaluate the agent in simulation studies. The results
show that adaptive interventions add complexity to the design and
implementation process, but have the potential to improve patients' benefits
even if only few observations are available. In order to quantify the expected
benefit, data from previous interventional studies is required. We expect our
approach to be transferable to other interventions and clinical interventions.
</p>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14157" title="Abstract">arXiv:2309.14157</a> [<a href="/pdf/2309.14157" title="Download PDF">pdf</a>, <a href="/format/2309.14157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LAPP: Layer Adaptive Progressive Pruning for Compressing CNNs from  Scratch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhai%2C+P">Pucheng Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+K">Kailing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+X">Xiaofen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiangmin Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 8 tables, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Structured pruning is a commonly used convolutional neural network (CNN)
compression approach. Pruning rate setting is a fundamental problem in
structured pruning. Most existing works introduce too many additional learnable
parameters to assign different pruning rates across different layers in CNN or
cannot control the compression rate explicitly. Since too narrow network blocks
information flow for training, automatic pruning rate setting cannot explore a
high pruning rate for a specific layer. To overcome these limitations, we
propose a novel framework named Layer Adaptive Progressive Pruning (LAPP),
which gradually compresses the network during initial training of a few epochs
from scratch. In particular, LAPP designs an effective and efficient pruning
strategy that introduces a learnable threshold for each layer and FLOPs
constraints for network. Guided by both task loss and FLOPs constraints, the
learnable thresholds are dynamically and gradually updated to accommodate
changes of importance scores during training. Therefore the pruning strategy
can gradually prune the network and automatically determine the appropriate
pruning rates for each layer. What's more, in order to maintain the expressive
power of the pruned layer, before training starts, we introduce an additional
lightweight bypass for each convolutional layer to be pruned, which only adds
relatively few additional burdens. Our method demonstrates superior performance
gains over previous compression methods on various datasets and backbone
architectures. For example, on CIFAR-10, our method compresses ResNet-20 to
40.3% without accuracy drop. 55.6% of FLOPs of ResNet-18 are reduced with 0.21%
top-1 accuracy increase and 0.40% top-5 accuracy increase on ImageNet.
</p>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14158" title="Abstract">arXiv:2309.14158</a> [<a href="/pdf/2309.14158" title="Download PDF">pdf</a>, <a href="/format/2309.14158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Investigation of Distribution Alignment in Multi-Genre Speaker  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Z">Zhenyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Junhui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Namin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lantian Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Multi-genre speaker recognition is becoming increasingly popular due to its
ability to better represent the complexities of real-world applications.
However, a major challenge is the significant shift in the distribution of
speaker vectors across different genres. While distribution alignment is a
common approach to address this challenge, previous studies have mainly focused
on aligning a source domain with a target domain, and the performance of
multi-genre data is unknown.
<br />This paper presents a comprehensive study of mainstream distribution
alignment methods on multi-genre data, where multiple distributions need to be
aligned. We analyze various methods both qualitatively and quantitatively. Our
experiments on the CN-Celeb dataset show that within-between distribution
alignment (WBDA) performs relatively better. However, we also found that none
of the investigated methods consistently improved performance in all test
cases. This suggests that solely aligning the distributions of speaker vectors
may not fully address the challenges posed by multi-genre speaker recognition.
Further investigation is necessary to develop a more comprehensive solution.
</p>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14162" title="Abstract">arXiv:2309.14162</a> [<a href="/pdf/2309.14162" title="Download PDF">pdf</a>, <a href="/format/2309.14162" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Upcycling Knowledge Distillation for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Simiao Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jie Hu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hanting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hailing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+Z">Zhijun Tu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjia Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+B">Bingyi Jing</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Knowledge distillation (KD) emerges as a challenging yet promising technique
for compressing deep learning models, characterized by the transmission of
extensive learning representations from proficient and computationally
intensive teacher models to compact student models. However, only a handful of
studies have endeavored to compress the models for single image
super-resolution (SISR) through KD, with their effects on student model
enhancement remaining marginal. In this paper, we put forth an approach from
the perspective of efficient data utilization, namely, the Data Upcycling
Knowledge Distillation (DUKD) which facilitates the student model by the prior
knowledge teacher provided via upcycled in-domain data derived from their
inputs. This upcycling process is realized through two efficient image zooming
operations and invertible data augmentations which introduce the label
consistency regularization to the field of KD for SISR and substantially boosts
student model's generalization. The DUKD, due to its versatility, can be
applied across a broad spectrum of teacher-student architectures. Comprehensive
experiments across diverse benchmarks demonstrate that our proposed DUKD method
significantly outperforms previous art, exemplified by an increase of up to
0.5dB in PSNR over baselines methods, and a 67% parameters reduced RCAN model's
performance remaining on par with that of the RCAN teacher model.
</p>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14163" title="Abstract">arXiv:2309.14163</a> [<a href="/pdf/2309.14163" title="Download PDF">pdf</a>, <a href="/format/2309.14163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uniform multi-penalty regularization for linear ill-posed inverse  problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bortolotti%2C+V">Villiam Bortolotti</a>, 
<a href="/search/math?searchtype=author&query=Landi%2C+G">Germana Landi</a>, 
<a href="/search/math?searchtype=author&query=Zama%2C+F">Fabiana Zama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">This study examines, in the framework of variational regularization methods,
a multi-penalty regularization approach which builds upon the Uniform PENalty
(UPEN) method, previously proposed by the authors for Nuclear Magnetic
Resonance (NMR) data processing. The paper introduces two iterative methods,
UpenMM and GUpenMM, formulated within the Majorization-Minimization (MM)
framework. These methods are designed to identify appropriate regularization
parameters and solutions for linear inverse problems utilizing multi-penalty
regularization. The paper demonstrates the convergence of these methods and
illustrates their potential through numerical examples in one and
two-dimensional scenarios, showing the practical utility of point-wise
regularization terms in solving various inverse problems.
</p>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14164" title="Abstract">arXiv:2309.14164</a> [<a href="/pdf/2309.14164" title="Download PDF">pdf</a>, <a href="/format/2309.14164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> What rationales drive architectural decisions? An empirical inquiry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borowa%2C+K">Klara Borowa</a>, 
<a href="/search/cs?searchtype=author&query=Lewanczyk%2C+R">Rafa&#x142; Lewanczyk</a>, 
<a href="/search/cs?searchtype=author&query=Stpiczy%C5%84ska%2C+K">Klaudia Stpiczy&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Stradomski%2C+P">Patryk Stradomski</a>, 
<a href="/search/cs?searchtype=author&query=Zalewski%2C+A">Andrzej Zalewski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Architectural decision-making is a crucial concern for researchers and
practitioners alike. There is a rationale behind every architectural decision
that motivates an architect to choose one architectural solution out of a set
of options. This study aims to identify which categories of rationale most
frequently impact architectural decisions and investigates why these are
important to practitioners. Our research comprises two steps of empirical
inquiry: a questionnaire (63 participants) and 13 interviews. As a result, we
obtained a set of rationales that motivated architects' decisions in practice.
Out of them, we extracted a list of software quality attributes that
practitioners were the most concerned about. We found that, overall, architects
prefer to choose solutions which are familiar to them or that guarantee fast
software implementation. Mid-career architects (5 to 15 years of experience)
are more open to new solutions than senior and junior practitioners.
Additionally, we found that most practitioners are not concerned about the
quality attributes of compatibility and portability due to modern software
development practices, such as the prevalence of using specific standards and
virtualisation/containerization.
</p>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14165" title="Abstract">arXiv:2309.14165</a> [<a href="/pdf/2309.14165" title="Download PDF">pdf</a>, <a href="/format/2309.14165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards End-User Development for IoT: A Case Study on Semantic Parsing  of Cooking Recipes for Programming Kitchen Devices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ventirozos%2C+F">Filippos Ventirozos</a>, 
<a href="/search/cs?searchtype=author&query=Clinch%2C+S">Sarah Clinch</a>, 
<a href="/search/cs?searchtype=author&query=Batista-Navarro%2C+R">Riza Batista-Navarro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure, 2 tables. Work completed in January 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Semantic parsing of user-generated instructional text, in the way of enabling
end-users to program the Internet of Things (IoT), is an underexplored area. In
this study, we provide a unique annotated corpus which aims to support the
transformation of cooking recipe instructions to machine-understandable
commands for IoT devices in the kitchen. Each of these commands is a tuple
capturing the semantics of an instruction involving a kitchen device in terms
of "What", "Where", "Why" and "How". Based on this corpus, we developed machine
learning-based sequence labelling methods, namely conditional random fields
(CRF) and a neural network model, in order to parse recipe instructions and
extract our tuples of interest from them. Our results show that while it is
feasible to train semantic parsers based on our annotations, most
natural-language instructions are incomplete, and thus transforming them into
formal meaning representation, is not straightforward.
</p>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14166" title="Abstract">arXiv:2309.14166</a> [<a href="/pdf/2309.14166" title="Download PDF">pdf</a>, <a href="/ps/2309.14166" title="Download PostScript">ps</a>, <a href="/format/2309.14166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted Attacks: Redefining Spear Phishing and Business Email  Compromise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wassermann%2C+S">Sarah Wassermann</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+M">Maxime Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Goutal%2C+S">S&#xe9;bastien Goutal</a>, 
<a href="/search/cs?searchtype=author&query=Riquet%2C+D">Damien Riquet</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">In today's digital world, cybercrime is responsible for significant damage to
organizations, including financial losses, operational disruptions, or
intellectual property theft. Cyberattacks often start with an email, the major
means of corporate communication. Some rare, severely damaging email threats -
known as spear phishing or Business Email Compromise - have emerged. However,
the literature disagrees on their definition, impeding security vendors and
researchers from mitigating targeted attacks. Therefore, we introduce targeted
attacks. We describe targeted-attack-detection techniques as well as
social-engineering methods used by fraudsters. Additionally, we present
text-based attacks - with textual content as malicious payload - and compare
non-targeted and targeted variants.
</p>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14169" title="Abstract">arXiv:2309.14169</a> [<a href="/pdf/2309.14169" title="Download PDF">pdf</a>, <a href="/ps/2309.14169" title="Download PostScript">ps</a>, <a href="/format/2309.14169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extrapolated regularization of nearly singular integrals on surfaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Beale%2C+J+T">J. Thomas Beale</a>, 
<a href="/search/math?searchtype=author&query=Tlupova%2C+S">Svetlana Tlupova</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to Adv. Comput. Math
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We present a method for computing nearly singular integrals that occur when
single or double layer surface integrals, for harmonic potentials or Stokes
flow, are evaluated at points nearby. Such values could be needed in solving an
integral equation when one surface is close to another or to obtain values at
grid points. We replace the singular kernel with a regularized version having a
length parameter $\delta$ in order to control discretization error. Analysis
near the singularity leads to an expression for the error due to regularization
which has terms with unknown coefficients multiplying known quantities. By
computing the integral with three choices of $\delta$ we can solve for an
extrapolated value that has regularization error reduced to $O(\delta^5)$. In
examples with $\delta/h$ constant and moderate resolution we observe total
error about $O(h^5)$. For convergence as $h \to 0$ we can choose $\delta$
proportional to $h^q$ with $q &lt; 1$ to ensure the discretization error is
dominated by the regularization error. With $q = 4/5$ we find errors about
$O(h^4)$. For harmonic potentials we extend the approach to a version with
$O(\delta^7)$ regularization; it typically has smaller errors but the order of
accuracy is less predictable.
</p>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14174" title="Abstract">arXiv:2309.14174</a> [<a href="/pdf/2309.14174" title="Download PDF">pdf</a>, <a href="/format/2309.14174" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Only 5\% Attention Is All You Need: Efficient Long-range Document-level  Neural Machine Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zihan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zewei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Shanbo Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shujian Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mingxuan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by AACL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Document-level Neural Machine Translation (DocNMT) has been proven crucial
for handling discourse phenomena by introducing document-level context
information. One of the most important directions is to input the whole
document directly to the standard Transformer model. In this case, efficiency
becomes a critical concern due to the quadratic complexity of the attention
module. Existing studies either focus on the encoder part, which cannot be
deployed on sequence-to-sequence generation tasks, e.g., Machine Translation
(MT), or suffer from a significant performance drop. In this work, we keep the
translation performance while gaining 20\% speed up by introducing extra
selection layer based on lightweight attention that selects a small portion of
tokens to be attended. It takes advantage of the original attention to ensure
performance and dimension reduction to accelerate inference. Experimental
results show that our method could achieve up to 95\% sparsity (only 5\% tokens
attended) approximately, and save 93\% computation cost on the attention module
compared with the original Transformer, while maintaining the performance.
</p>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14175" title="Abstract">arXiv:2309.14175</a> [<a href="/pdf/2309.14175" title="Download PDF">pdf</a>, <a href="/ps/2309.14175" title="Download PostScript">ps</a>, <a href="/format/2309.14175" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Influence of Cognitive Biases on Architectural Technical Debt
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Borowa%2C+K">Klara Borowa</a>, 
<a href="/search/cs?searchtype=author&query=Zalewski%2C+A">Andrzej Zalewski</a>, 
<a href="/search/cs?searchtype=author&query=Kijas%2C+S">Szymon Kijas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at 2021 IEEE 18th International Conference on Software Architecture (ICSA) 2021
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Cognitive biases exert a significant influence on human thinking and
decision-making. In order to identify how they influence the occurrence of
architectural technical debt, a series of semi-structured interviews with
software architects was performed. The results show which classes of
architectural technical debt originate from cognitive biases, and reveal the
antecedents of technical debt items (classes) through biases. This way, we
analysed how and when cognitive biases lead to the creation of technical debt.
We also identified a set of debiasing techniques that can be used in order to
prevent the negative influence of cognitive biases. The observations of the
role of organisational culture in the avoidance of inadvertent technical debt
throw a new light on that issue.
</p>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14176" title="Abstract">arXiv:2309.14176</a> [<a href="/pdf/2309.14176" title="Download PDF">pdf</a>, <a href="/format/2309.14176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning Under Restricted User Availability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Theodoropoulos%2C+P">Periklis Theodoropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Nikolakakis%2C+K+E">Konstantinos E. Nikolakakis</a>, 
<a href="/search/cs?searchtype=author&query=Kalogerias%2C+D">Dionysis Kalogerias</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
<p class="mathjax">Federated Learning (FL) is a decentralized machine learning framework that
enables collaborative model training while respecting data privacy. In various
applications, non-uniform availability or participation of users is unavoidable
due to an adverse or stochastic environment, the latter often being
uncontrollable during learning. Here, we posit a generic user selection
mechanism implementing a possibly randomized, stationary selection policy,
suggestively termed as a Random Access Model (RAM). We propose a new
formulation of the FL problem which effectively captures and mitigates limited
participation of data originating from infrequent, or restricted users, at the
presence of a RAM. By employing the Conditional Value-at-Risk (CVaR) over the
(unknown) RAM distribution, we extend the expected loss FL objective to a
risk-aware objective, enabling the design of an efficient training algorithm
that is completely oblivious to the RAM, and with essentially identical
complexity as FedAvg. Our experiments on synthetic and benchmark datasets show
that the proposed approach achieves significantly improved performance as
compared with standard FL, under a variety of setups.
</p>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14178" title="Abstract">arXiv:2309.14178</a> [<a href="/pdf/2309.14178" title="Download PDF">pdf</a>, <a href="/format/2309.14178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse grid based Chebyshev HOPGD for parameterized linear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Correnty%2C+S">Siobh&#xe1;n Correnty</a>, 
<a href="/search/math?searchtype=author&query=Freitag%2C+M+A">Melina A. Freitag</a>, 
<a href="/search/math?searchtype=author&query=Soodhalter%2C+K+M">Kirk M. Soodhalter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider approximating solutions to parameterized linear systems of the
form $A(\mu_1,\mu_2) x(\mu_1,\mu_2) = b$, where $(\mu_1, \mu_2) \in
\mathbb{R}^2$. Here the matrix $A(\mu_1,\mu_2) \in \mathbb{R}^{n \times n}$ is
nonsingular, large, and sparse and depends nonlinearly on the parameters
$\mu_1$ and $\mu_2$. Specifically, the system arises from a discretization of a
partial differential equation and $x(\mu_1,\mu_2) \in \mathbb{R}^n$, $b \in
\mathbb{R}^n$. This work combines companion linearization with the Krylov
subspace method preconditioned bi-conjugate gradient (BiCG) and a decomposition
of a tensor matrix of precomputed solutions, called snapshots. As a result, a
reduced order model of $x(\mu_1,\mu_2)$ is constructed, and this model can be
evaluated in a cheap way for many values of the parameters. The decomposition
is performed efficiently using the sparse grid based higher-order proper
generalized decomposition (HOPGD), and the snapshots are generated as one
variable functions of $\mu_1$ or of $\mu_2$. Tensor decompositions performed on
a set of snapshots can fail to reach a certain level of accuracy, and it is not
possible to know a priori if the decomposition will be successful. This method
offers a way to generate a new set of solutions on the same parameter space at
little additional cost. An interpolation of the model is used to produce
approximations on the entire parameter space, and this method can be used to
solve a parameter estimation problem. Numerical examples of a parameterized
Helmholtz equation show the competitiveness of our approach. The simulations
are reproducible, and the software is available online.
</p>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14181" title="Abstract">arXiv:2309.14181</a> [<a href="/pdf/2309.14181" title="Download PDF">pdf</a>, <a href="/format/2309.14181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level  Vision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Haoning Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zicheng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+E">Erli Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chaofeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+L">Liang Liao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+A">Annan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chunyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wenxiu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+Q">Qiong Yan</a>, 
<a href="/search/cs?searchtype=author&query=Zhai%2C+G">Guangtao Zhai</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+W">Weisi Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, preprint version, may hot update
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
<p class="mathjax">The rapid evolution of Multi-modality Large Language Models (MLLMs) has
catalyzed a shift in computer vision from specialized models to general-purpose
foundation models. Nevertheless, there is still an inadequacy in assessing the
abilities of MLLMs on low-level visual perception and understanding. To address
this gap, we present Q-Bench, a holistic benchmark crafted to systematically
evaluate potential abilities of MLLMs on three realms: low-level visual
perception, low-level visual description, and overall visual quality
assessment. a) To evaluate the low-level perception ability, we construct the
LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped
with a human-asked question focusing on its low-level attributes. We then
measure the correctness of MLLMs on answering these questions. b) To examine
the description ability of MLLMs on low-level information, we propose the
LLDescribe dataset consisting of long expert-labelled golden low-level text
descriptions on 499 images, and a GPT-involved comparison pipeline between
outputs of MLLMs and the golden descriptions. c) Besides these two tasks, we
further measure their visual quality assessment ability to align with human
opinion scores. Specifically, we design a softmax-based strategy that enables
MLLMs to predict quantifiable quality scores, and evaluate them on various
existing image quality assessment (IQA) datasets. Our evaluation across the
three abilities confirms that MLLMs possess fundamental low-level visual
skills. However, these skills are still unstable and relatively imprecise,
indicating the need for specific enhancements on MLLMs towards these abilities.
We hope that our benchmark can encourage the research community to delve deeper
to discover and enhance these untapped potentials of MLLMs.
</p>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14183" title="Abstract">arXiv:2309.14183</a> [<a href="/pdf/2309.14183" title="Download PDF">pdf</a>, <a href="/format/2309.14183" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Species196: A One-Million Semi-supervised Dataset for Fine-grained  Species Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Ying Nie</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Track Datasets and Benchmarks
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The development of foundation vision models has pushed the general visual
recognition to a high level, but cannot well address the fine-grained
recognition in specialized domain such as invasive species classification.
Identifying and managing invasive species has strong social and ecological
value. Currently, most invasive species datasets are limited in scale and cover
a narrow range of species, which restricts the development of deep-learning
based invasion biometrics systems. To fill the gap of this area, we introduced
Species196, a large-scale semi-supervised dataset of 196-category invasive
species. It collects over 19K images with expert-level accurate annotations
Species196-L, and 1.2M unlabeled images of invasive species Species196-U. The
dataset provides four experimental settings for benchmarking the existing
models and algorithms, namely, supervised learning, semi-supervised learning,
self-supervised pretraining and zero-shot inference ability of large
multi-modal models. To facilitate future research on these four learning
paradigms, we conduct an empirical study of the representative methods on the
introduced dataset. The dataset is publicly available at
https://species-dataset.github.io/.
</p>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14184" title="Abstract">arXiv:2309.14184</a> [<a href="/pdf/2309.14184" title="Download PDF">pdf</a>, <a href="/format/2309.14184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Linearly implicit exponential integrators for damped Hamiltonian PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Uzunca%2C+M">Murat Uzunca</a>, 
<a href="/search/math?searchtype=author&query=Karas%C3%B6zen%2C+B">B&#xfc;lent Karas&#xf6;zen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Structure-preserving linearly implicit exponential integrators are
constructed for Hamiltonian partial differential equations with linear constant
damping. Linearly implicit integrators are derived by polarizing the polynomial
terms of the Hamiltonian function and portioning out the nonlinearly of
consecutive time steps. They require only a solution of one linear system at
each time step. Therefore they are computationally more advantageous than
implicit integrators. We also construct an exponential version of the
well-known one-step Kahan's method by polarizing the quadratic vector field.
These integrators are applied to one-dimensional damped Burger's,
Korteweg-de-Vries, and nonlinear Schr\"odinger equations. Preservation of the
dissipation rate of linear and quadratic conformal invariants and the
Hamiltonian is illustrated by numerical experiments.
</p>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14185" title="Abstract">arXiv:2309.14185</a> [<a href="/pdf/2309.14185" title="Download PDF">pdf</a>, <a href="/format/2309.14185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Separators with Deadlines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Harutyunyan%2C+H+A">Hovhannes A. Harutyunyan</a>, 
<a href="/search/cs?searchtype=author&query=Koupayi%2C+K">Kamran Koupayi</a>, 
<a href="/search/cs?searchtype=author&query=Pankratov%2C+D">Denis Pankratov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
<p class="mathjax">We study temporal analogues of the Unrestricted Vertex Separator problem from
the static world. An $(s,z)$-temporal separator is a set of vertices whose
removal disconnects vertex $s$ from vertex $z$ for every time step in a
temporal graph. The $(s,z)$-Temporal Separator problem asks to find the minimum
size of an $(s,z)$-temporal separator for the given temporal graph. We
introduce a generalization of this problem called the $(s,z,t)$-Temporal
Separator problem, where the goal is to find a smallest subset of vertices
whose removal eliminates all temporal paths from $s$ to $z$ which take less
than $t$ time steps. Let $\tau$ denote the number of time steps over which the
temporal graph is defined (we consider discrete time steps). We characterize
the set of parameters $\tau$ and $t$ when the problem is $\mathcal{NP}$-hard
and when it is polynomial time solvable. Then we present a $\tau$-approximation
algorithm for the $(s,z)$-Temporal Separator problem and convert it to a
$\tau^2$-approximation algorithm for the $(s,z,t)$-Temporal Separator problem.
We also present an inapproximability lower bound of $\Omega(\ln(n) +
\ln(\tau))$ for the $(s,z,t)$-Temporal Separator problem assuming that
$\mathcal{NP}\not\subset\mbox{\sc Dtime}(n^{\log\log n})$. Then we consider
three special families of graphs: (1) graphs of branchwidth at most $2$, (2)
graphs $G$ such that the removal of $s$ and $z$ leaves a tree, and (3) graphs
of bounded pathwidth. We present polynomial-time algorithms to find a minimum
$(s,z,t)$-temporal separator for (1) and (2). As for (3), we show a
polynomial-time reduction from the Discrete Segment Covering problem with
bounded-length segments to the $(s,z,t)$-Temporal Separator problem where the
temporal graph has bounded pathwidth.
</p>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14187" title="Abstract">arXiv:2309.14187</a> [<a href="/pdf/2309.14187" title="Download PDF">pdf</a>, <a href="/ps/2309.14187" title="Download PostScript">ps</a>, <a href="/format/2309.14187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two tricks to trivialize higher-indexed families
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tesla Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">The conventional general syntax of indexed families in dependent type
theories follow the style of "constructors returning a special case", as in
Agda, Lean, Idris, Coq, and probably many other systems. Fording is a method to
encode indexed families of this style with index-free inductive types and an
identity type. There is another trick that merges interleaved higher
inductive-inductive types into a single big family of types. It makes use of a
small universe as the index to distinguish the original types. In this paper,
we show that these two methods can trivialize some very fancy-looking indexed
families with higher inductive indices (which we refer to as higher indexed
families).
</p>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14189" title="Abstract">arXiv:2309.14189</a> [<a href="/pdf/2309.14189" title="Download PDF">pdf</a>, <a href="/ps/2309.14189" title="Download PostScript">ps</a>, <a href="/format/2309.14189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic optimality of the edge finite element approximation of the  time-harmonic Maxwell&#x27;s equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chaumont-Frelet%2C+T">T. Chaumont-Frelet</a>, 
<a href="/search/math?searchtype=author&query=Ern%2C+A">A. Ern</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
<p class="mathjax">We analyze the conforming approximation of the time-harmonic Maxwell's
equations using N\'ed\'elec (edge) finite elements. We prove that the
approximation is asymptotically optimal, i.e., the approximation error in the
energy norm is bounded by the best-approximation error times a constant that
tends to one as the mesh is refined and/or the polynomial degree is increased.
Moreover, under the same conditions on the mesh and/or the polynomial degree,
we establish discrete inf-sup stability with a constant that corresponds to the
continuous constant up to a factor of two at most. Our proofs apply under
minimal regularity assumptions on the exact solution, so that general domains,
material coefficients, and right-hand sides are allowed.
</p>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14198" title="Abstract">arXiv:2309.14198</a> [<a href="/pdf/2309.14198" title="Download PDF">pdf</a>, <a href="/format/2309.14198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> (Predictable) Performance Bias in Unsupervised Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meissen%2C+F">Felix Meissen</a>, 
<a href="/search/cs?searchtype=author&query=Breuer%2C+S">Svenja Breuer</a>, 
<a href="/search/cs?searchtype=author&query=Knolle%2C+M">Moritz Knolle</a>, 
<a href="/search/cs?searchtype=author&query=Buyx%2C+A">Alena Buyx</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+R">Ruth M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Kaissis%2C+G">Georgios Kaissis</a>, 
<a href="/search/cs?searchtype=author&query=Wiestler%2C+B">Benedikt Wiestler</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BCckert%2C+D">Daniel R&#xfc;ckert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 5 Figures, 1 panel
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Background: With the ever-increasing amount of medical imaging data, the
demand for algorithms to assist clinicians has amplified. Unsupervised anomaly
detection (UAD) models promise to aid in the crucial first step of disease
detection. While previous studies have thoroughly explored fairness in
supervised models in healthcare, for UAD, this has so far been unexplored.
<br />Methods: In this study, we evaluated how dataset composition regarding
subgroups manifests in disparate performance of UAD models along multiple
protected variables on three large-scale publicly available chest X-ray
datasets. Our experiments were validated using two state-of-the-art UAD models
for medical images. Finally, we introduced a novel subgroup-AUROC (sAUROC)
metric, which aids in quantifying fairness in machine learning.
<br />Findings: Our experiments revealed empirical "fairness laws" (similar to
"scaling laws" for Transformers) for training-dataset composition: Linear
relationships between anomaly detection performance within a subpopulation and
its representation in the training data. Our study further revealed performance
disparities, even in the case of balanced training data, and compound effects
that exacerbate the drop in performance for subjects associated with multiple
adversely affected groups.
<br />Interpretation: Our study quantified the disparate performance of UAD models
against certain demographic subgroups. Importantly, we showed that this
unfairness cannot be mitigated by balanced representation alone. Instead, the
representation of some subgroups seems harder to learn by UAD models than that
of others. The empirical fairness laws discovered in our study make disparate
performance in UAD models easier to estimate and aid in determining the most
desirable dataset composition.
</p>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14201" title="Abstract">arXiv:2309.14201</a> [<a href="/pdf/2309.14201" title="Download PDF">pdf</a>, <a href="/ps/2309.14201" title="Download PostScript">ps</a>, <a href="/format/2309.14201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards a Theory of Maximal Extractable Value II: Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chitra%2C+T">Tarun Chitra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Cryptography and Security (cs.CR); Computational Finance (q-fin.CP)

</div>
<p class="mathjax">Maximal Extractable Value (MEV) is value extractable by temporary monopoly
power commonly found in decentralized systems. This extraction stems from a
lack of user privacy upon transaction submission and the ability of a
monopolist validator to reorder, add, and/or censor transactions. There are two
main directions to reduce MEV: reduce the flexibility of the miner to reorder
transactions by enforcing ordering rules and/or introduce a competitive market
for the right to reorder, add, and/or censor transactions. In this work, we
unify these approaches via \emph{uncertainty principles}, akin to those found
in harmonic analysis and physics. This provides a quantitative trade-off
between the freedom to reorder transactions and the complexity of an economic
payoff to a user in a decentralized network. This trade off is analogous to the
Nyquist-Shannon sampling theorem and demonstrates that sequencing rules in
blockchains need to be application specific. Our results suggest that neither
so-called fair ordering techniques nor economic mechanisms can individually
mitigate MEV for arbitrary payoff functions.
</p>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14203" title="Abstract">arXiv:2309.14203</a> [<a href="/pdf/2309.14203" title="Download PDF">pdf</a>, <a href="/format/2309.14203" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detecting and Grounding Multi-Modal Media Manipulation and Beyond
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+R">Rui Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxing Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jianlong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+L">Liqiang Nie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of our CVPR 2023 paper: <a href="/abs/2304.02556">arXiv:2304.02556</a> Code: <a href="https://github.com/rshaojimmy/MultiModal-DeepFake">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Misinformation has become a pressing issue. Fake media, in both visual and
textual forms, is widespread on the web. While various deepfake detection and
text fake news detection methods have been proposed, they are only designed for
single-modality forgery based on binary classification, let alone analyzing and
reasoning subtle forgery traces across different modalities. In this paper, we
highlight a new research problem for multi-modal fake media, namely Detecting
and Grounding Multi-Modal Media Manipulation (DGM^4). DGM^4 aims to not only
detect the authenticity of multi-modal media, but also ground the manipulated
content, which requires deeper reasoning of multi-modal media manipulation. To
support a large-scale investigation, we construct the first DGM^4 dataset,
where image-text pairs are manipulated by various approaches, with rich
annotation of diverse manipulations. Moreover, we propose a novel HierArchical
Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the
fine-grained interaction between different modalities. HAMMER performs 1)
manipulation-aware contrastive learning between two uni-modal encoders as
shallow manipulation reasoning, and 2) modality-aware cross-attention by
multi-modal aggregator as deep manipulation reasoning. Dedicated manipulation
detection and grounding heads are integrated from shallow to deep levels based
on the interacted multi-modal information. To exploit more fine-grained
contrastive learning for cross-modal semantic alignment, we further integrate
Manipulation-Aware Contrastive Loss with Local View and construct a more
advanced model HAMMER++. Finally, we build an extensive benchmark and set up
rigorous evaluation metrics for this new research problem. Comprehensive
experiments demonstrate the superiority of HAMMER and HAMMER++.
</p>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14207" title="Abstract">arXiv:2309.14207</a> [<a href="/pdf/2309.14207" title="Download PDF">pdf</a>, <a href="/format/2309.14207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automatic Animation of Hair Blowing in Still Portrait Photos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+W">Wenpeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wentao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yitong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ghanem%2C+B">Bernard Ghanem</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">We propose a novel approach to animate human hair in a still portrait photo.
Existing work has largely studied the animation of fluid elements such as water
and fire. However, hair animation for a real image remains underexplored, which
is a challenging problem, due to the high complexity of hair structure and
dynamics. Considering the complexity of hair structure, we innovatively treat
hair wisp extraction as an instance segmentation problem, where a hair wisp is
referred to as an instance. With advanced instance segmentation networks, our
method extracts meaningful and natural hair wisps. Furthermore, we propose a
wisp-aware animation module that animates hair wisps with pleasing motions
without noticeable artifacts. The extensive experiments show the superiority of
our method. Our method provides the most pleasing and compelling viewing
experience in the qualitative experiments and outperforms state-of-the-art
still-image animation methods by a large margin in the quantitative evaluation.
Project url: \url{https://nevergiveu.github.io/AutomaticHairBlowing/}
</p>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14208" title="Abstract">arXiv:2309.14208</a> [<a href="/pdf/2309.14208" title="Download PDF">pdf</a>, <a href="/format/2309.14208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framework based on complex networks to model and mine patient pathways
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de+Oliveira+Costa+Souza+Rosa%2C+C">Caroline de Oliveira Costa Souza Rosa</a>, 
<a href="/search/cs?searchtype=author&query=Ito%2C+M">M&#xe1;rcia Ito</a>, 
<a href="/search/cs?searchtype=author&query=Vieira%2C+A+B">Alex Borges Vieira</a>, 
<a href="/search/cs?searchtype=author&query=Wehmuth%2C+K">Klaus Wehmuth</a>, 
<a href="/search/cs?searchtype=author&query=Gomes%2C+A+T+A">Ant&#xf4;nio Tadeu Azevedo Gomes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 11 figures, 2 appendices
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The automatic discovery of a model to represent the history of encounters of
a group of patients with the healthcare system -- the so-called ``pathway of
patients'' -- is a new field of research that supports clinical and
organisational decisions to improve the quality and efficiency of the treatment
provided. The pathways of patients with chronic conditions tend to vary
significantly from one person to another, have repetitive tasks, and demand the
analysis of multiple perspectives (interventions, diagnoses, medical
specialities, among others) influencing the results. Therefore, modelling and
mining those pathways is still a challenging task. In this work, we propose a
framework comprising: (i) a pathway model based on a multi-aspect graph, (ii) a
novel dissimilarity measurement to compare pathways taking the elapsed time
into account, and (iii) a mining method based on traditional centrality
measures to discover the most relevant steps of the pathways. We evaluated the
framework using the study cases of pregnancy and diabetes, which revealed its
usefulness in finding clusters of similar pathways, representing them in an
easy-to-interpret way, and highlighting the most significant patterns according
to multiple perspectives.
</p>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14209" title="Abstract">arXiv:2309.14209</a> [<a href="/pdf/2309.14209" title="Download PDF">pdf</a>, <a href="/format/2309.14209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Driving Policy Optimization with Closed-Loop Individualized  Curricula
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yizhou Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+X">Xingjian Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianming Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The safety of autonomous vehicles (AV) has been a long-standing top concern,
stemming from the absence of rare and safety-critical scenarios in the
long-tail naturalistic driving distribution. To tackle this challenge, a surge
of research in scenario-based autonomous driving has emerged, with a focus on
generating high-risk driving scenarios and applying them to conduct
safety-critical testing of AV models. However, limited work has been explored
on the reuse of these extensive scenarios to iteratively improve AV models.
Moreover, it remains intractable and challenging to filter through gigantic
scenario libraries collected from other AV models with distinct behaviors,
attempting to extract transferable information for current AV improvement.
Therefore, we develop a continual driving policy optimization framework
featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into
a set of standardized sub-modules for flexible implementation choices: AV
Evaluation, Scenario Selection, and AV Training. CLIC frames AV Evaluation as a
collision prediction task, where it estimates the chance of AV failures in
these scenarios at each iteration. Subsequently, by re-sampling from historical
scenarios based on these failure probabilities, CLIC tailors individualized
curricula for downstream training, aligning them with the evaluated capability
of AV. Accordingly, CLIC not only maximizes the utilization of the vast
pre-collected scenario library for closed-loop driving policy optimization but
also facilitates AV improvement by individualizing its training with more
challenging cases out of those poorly organized scenarios. Experimental results
clearly indicate that CLIC surpasses other curriculum-based training
strategies, showing substantial improvement in managing risky scenarios, while
still maintaining proficiency in handling simpler cases.
</p>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14211" title="Abstract">arXiv:2309.14211</a> [<a href="/pdf/2309.14211" title="Download PDF">pdf</a>, <a href="/format/2309.14211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QuadricsNet: Learning Concise Representation for Geometric Primitives in  Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Ji Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Huai Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wen Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+G">Gui-Song Xia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024. 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper presents a novel framework to learn a concise geometric primitive
representation for 3D point clouds. Different from representing each type of
primitive individually, we focus on the challenging problem of how to achieve a
concise and uniform representation robustly. We employ quadrics to represent
diverse primitives with only 10 parameters and propose the first end-to-end
learning-based framework, namely QuadricsNet, to parse quadrics in point
clouds. The relationships between quadrics mathematical formulation and
geometric attributes, including the type, scale and pose, are insightfully
integrated for effective supervision of QuaidricsNet. Besides, a novel
pattern-comprehensive dataset with quadrics segments and objects is collected
for training and evaluation. Experiments demonstrate the effectiveness of our
concise representation and the robustness of QuadricsNet. Our code is available
at \url{https://github.com/MichaelWu99-lab/QuadricsNet}
</p>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14213" title="Abstract">arXiv:2309.14213</a> [<a href="/pdf/2309.14213" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Autonomous Vehicles an overview on system, cyber security, risks,  issues, and a way forward
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Islam%2C+M+A">Md Aminul Islam</a> (1), 
<a href="/search/cs?searchtype=author&query=Alqahtani%2C+S">Sarah Alqahtani</a>,  (2) ((1) Oxford Brookes University, UK, (2) Oxford Brookes University, UK)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This chapter explores the complex realm of autonomous cars, analyzing their
fundamental components and operational characteristics. The initial phase of
the discussion is elucidating the internal mechanics of these automobiles,
encompassing the crucial involvement of sensors, artificial intelligence (AI)
identification systems, control mechanisms, and their integration with
cloud-based servers within the framework of the Internet of Things (IoT). It
delves into practical implementations of autonomous cars, emphasizing their
utilization in forecasting traffic patterns and transforming the dynamics of
transportation. The text also explores the topic of Robotic Process Automation
(RPA), illustrating the impact of autonomous cars on different businesses
through the automation of tasks. The primary focus of this investigation lies
in the realm of cybersecurity, specifically in the context of autonomous
vehicles. A comprehensive analysis will be conducted to explore various risk
management solutions aimed at protecting these vehicles from potential threats
including ethical, environmental, legal, professional, and social dimensions,
offering a comprehensive perspective on their societal implications. A
strategic plan for addressing the challenges and proposing strategies for
effectively traversing the complex terrain of autonomous car systems,
cybersecurity, hazards, and other concerns are some resources for acquiring an
understanding of the intricate realm of autonomous cars and their ramifications
in contemporary society, supported by a comprehensive compilation of resources
for additional investigation.
<br />Keywords: RPA, Cyber Security, AV, Risk, Smart Cars
</p>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14216" title="Abstract">arXiv:2309.14216</a> [<a href="/pdf/2309.14216" title="Download PDF">pdf</a>, <a href="/format/2309.14216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MemDA: Forecasting Urban Time Series with Memory-based Drift Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Z">Zekun Cai</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Renhe Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xinyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhaonan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+D">Diansheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+H">Hiroki Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xuan Song</a>, 
<a href="/search/cs?searchtype=author&query=Shibasaki%2C+R">Ryosuke Shibasaki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by CIKM 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Urban time series data forecasting featuring significant contributions to
sustainable development is widely studied as an essential task of the smart
city. However, with the dramatic and rapid changes in the world environment,
the assumption that data obey Independent Identically Distribution is
undermined by the subsequent changes in data distribution, known as concept
drift, leading to weak replicability and transferability of the model over
unseen data. To address the issue, previous approaches typically retrain the
model, forcing it to fit the most recent observed data. However, retraining is
problematic in that it leads to model lag, consumption of resources, and model
re-invalidation, causing the drift problem to be not well solved in realistic
scenarios. In this study, we propose a new urban time series prediction model
for the concept drift problem, which encodes the drift by considering the
periodicity in the data and makes on-the-fly adjustments to the model based on
the drift using a meta-dynamic network. Experiments on real-world datasets show
that our design significantly outperforms state-of-the-art methods and can be
well generalized to existing prediction backbones by reducing their sensitivity
to distribution changes.
</p>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14217" title="Abstract">arXiv:2309.14217</a> [<a href="/pdf/2309.14217" title="Download PDF">pdf</a>, <a href="/ps/2309.14217" title="Download PostScript">ps</a>, <a href="/format/2309.14217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On LCP codes over a mixed ring alphabet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bajalan%2C+M">Maryam Bajalan</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Cruz%2C+J">Javier de la Cruz</a>, 
<a href="/search/cs?searchtype=author&query=Fotue-Tabue%2C+A">Alexandre Fotue-Tabue</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Moro%2C+E">Edgar Mart&#xed;nez-Moro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Discrete Mathematics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Rings and Algebras (math.RA)

</div>
<p class="mathjax">In this paper, we introduce a standard generator matrix for mixed-alphabet
linear codes over finite chain rings. Furthermore, we show that, when one has a
linear complementary pair (LCP) of mixed-alphabet linear codes, both codes are
weakly-free. Additionally, we establish that any mixed-alphabet product group
code is separable. Thus, if one has a pair $\{C, D\}$ of mixed-alphabet product
group codes over a finite chain ring that forms a LCP, it follows that $C$ and
the Euclidean dual of $D$ are permutation equivalent.
</p>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14221" title="Abstract">arXiv:2309.14221</a> [<a href="/pdf/2309.14221" title="Download PDF">pdf</a>, <a href="/ps/2309.14221" title="Download PostScript">ps</a>, <a href="/format/2309.14221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Machine Learning Algorithms with Adaptive Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tiwari%2C+M">Mo Tiwari</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> PhD Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The era of huge data necessitates highly efficient machine learning
algorithms. Many common machine learning algorithms, however, rely on
computationally intensive subroutines that are prohibitively expensive on large
datasets. Oftentimes, existing techniques subsample the data or use other
methods to improve computational efficiency, at the expense of incurring some
approximation error. This thesis demonstrates that it is often sufficient,
instead, to substitute computationally intensive subroutines with a special
kind of randomized counterparts that results in almost no degradation in
quality.
</p>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14225" title="Abstract">arXiv:2309.14225</a> [<a href="/pdf/2309.14225" title="Download PDF">pdf</a>, <a href="/format/2309.14225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HumanMimic: Learning Natural Locomotion and Transitions for Humanoid  Robot via Wasserstein Adversarial Imitation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+A">Annan Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+T">Takuma Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Hiraoka%2C+N">Naoki Hiraoka</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Fan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Kojima%2C+K">Kunio Kojima</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Transferring human motion skills to humanoid robots remains a significant
challenge. In this study, we introduce a Wasserstein adversarial imitation
learning system, allowing humanoid robots to replicate natural whole-body
locomotion patterns and execute seamless transitions by mimicking human
motions. First, we present a unified primitive-skeleton motion retargeting to
mitigate morphological differences between arbitrary human demonstrators and
humanoid robots. An adversarial critic component is integrated with
Reinforcement Learning (RL) to guide the control policy to produce behaviors
aligned with the data distribution of mixed reference motions. Additionally, we
employ a specific Integral Probabilistic Metric (IPM), namely the Wasserstein-1
distance with a novel soft boundary constraint to stabilize the training
process and prevent model collapse. Our system is evaluated on a full-sized
humanoid JAXON in the simulator. The resulting control policy demonstrates a
wide range of locomotion patterns, including standing, push-recovery, squat
walking, human-like straight-leg walking, and dynamic running. Notably, even in
the absence of transition motions in the demonstration dataset, robots showcase
an emerging ability to transit naturally between distinct locomotion patterns
as desired speed changes.
</p>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14226" title="Abstract">arXiv:2309.14226</a> [<a href="/pdf/2309.14226" title="Download PDF">pdf</a>, <a href="/format/2309.14226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Daily Assistive Modular Robot Design Based on Multi-Objective Black-Box  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kawaharazuka%2C+K">Kento Kawaharazuka</a>, 
<a href="/search/cs?searchtype=author&query=Makabe%2C+T">Tasuku Makabe</a>, 
<a href="/search/cs?searchtype=author&query=Okada%2C+K">Kei Okada</a>, 
<a href="/search/cs?searchtype=author&query=Inaba%2C+M">Masayuki Inaba</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IROS2023, website - <a href="https://haraduka.github.io/auto-modular-design/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The range of robot activities is expanding from industries with fixed
environments to diverse and changing environments, such as nursing care support
and daily life support. In particular, autonomous construction of robots that
are personalized for each user and task is required. Therefore, we develop an
actuator module that can be reconfigured to various link configurations, can
carry heavy objects using a locking mechanism, and can be easily operated by
human teaching using a releasing mechanism. Given multiple target coordinates,
a modular robot configuration that satisfies these coordinates and minimizes
the required torque is automatically generated by Tree-structured Parzen
Estimator (TPE), a type of black-box optimization. Based on the obtained
results, we show that the robot can be reconfigured to perform various
functions such as moving monitors and lights, serving food, and so on.
</p>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14228" title="Abstract">arXiv:2309.14228</a> [<a href="/pdf/2309.14228" title="Download PDF">pdf</a>, <a href="/format/2309.14228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ID.8: Co-Creating Visual Stories with Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Antony%2C+V+N">Victor Nikhil Antony</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chien-Ming Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Storytelling is an integral part of human culture and significantly impacts
cognitive and socio-emotional development and connection. Despite the
importance of interactive visual storytelling, the process of creating such
content requires specialized skills and is labor-intensive. This paper
introduces ID.8, an open-source system designed for the co-creation of visual
stories with generative AI. We focus on enabling an inclusive storytelling
experience by simplifying the content creation process and allowing for
customization. Our user evaluation confirms a generally positive user
experience in domains such as enjoyment and exploration, while highlighting
areas for improvement, particularly in immersiveness, alignment, and
partnership between the user and the AI system. Overall, our findings indicate
promising possibilities for empowering people to create visual stories with
generative AI. This work contributes a novel content authoring system, ID.8,
and insights into the challenges and potential of using generative AI for
multimedia content creation.
</p>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14230" title="Abstract">arXiv:2309.14230</a> [<a href="/pdf/2309.14230" title="Download PDF">pdf</a>, <a href="/format/2309.14230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Competitive Networked Bivirus SIS spread over Hypergraphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gracy%2C+S">Sebin Gracy</a>, 
<a href="/search/eess?searchtype=author&query=Anderson%2C+B+D+O">Brian D.O. Anderson</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+M">Mengbin Ye</a>, 
<a href="/search/eess?searchtype=author&query=Uribe%2C+C+A">Cesar A. Uribe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The paper deals with the spread of two competing viruses over a network of
population nodes, accounting for pairwise interactions and higher-order
interactions (HOI) within and between the population nodes. We study the
competitive networked bivirus susceptible-infected-susceptible (SIS) model on a
hypergraph introduced in Cui et al. [1]. We show that the system has, in a
generic sense, a finite number of equilibria, and the Jacobian associated with
each equilibrium point is nonsingular; the key tool is the Parametric
Transversality Theorem of differential topology. Since the system is also
monotone, it turns out that the typical behavior of the system is convergence
to some equilibrium point. Thereafter, we exhibit a tri-stable domain with
three locally exponentially stable equilibria. For different parameter regimes,
we establish conditions for the existence of a coexistence equilibrium (both
viruses infect separate fractions of each population node).
</p>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14232" title="Abstract">arXiv:2309.14232</a> [<a href="/pdf/2309.14232" title="Download PDF">pdf</a>, <a href="/format/2309.14232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Governance of Distributed Autonomous Organizations: A Study of  Contributors&#x27; Influence, Networks, and Shifts in Voting Power
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kitzler%2C+S">Stefan Kitzler</a>, 
<a href="/search/cs?searchtype=author&query=Balietti%2C+S">Stefano Balietti</a>, 
<a href="/search/cs?searchtype=author&query=Saggese%2C+P">Pietro Saggese</a>, 
<a href="/search/cs?searchtype=author&query=Haslhofer%2C+B">Bernhard Haslhofer</a>, 
<a href="/search/cs?searchtype=author&query=Strohmaier%2C+M">Markus Strohmaier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">We present a study analyzing the voting behavior of contributors, or vested
users, in Decentralized Autonomous Organizations (DAOs). We evaluate their
involvement in decision-making processes, discovering that in at least 7.54% of
all DAOs, contributors, on average, held the necessary majority to control
governance decisions. Furthermore, contributors have singularly decided at
least one proposal in 20.41% of DAOs. Notably, contributors tend to be
centrally positioned within the DAO governance ecosystem, suggesting the
presence of inner power circles. Additionally, we observed a tendency for
shifts in governance token ownership shortly before governance polls take place
in 1202 (14.81%) of 8116 evaluated proposals. Our findings highlight the
central role of contributors across a spectrum of DAOs, including Decentralized
Finance protocols. Our research also offers important empirical insights
pertinent to ongoing regulatory activities aimed at increasing transparency to
DAO governance frameworks.
</p>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14233" title="Abstract">arXiv:2309.14233</a> [<a href="/pdf/2309.14233" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Urdu Poetry Generated by Using Deep Learning Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farooq%2C+M+S">Muhammad Shoaib Farooq</a>, 
<a href="/search/cs?searchtype=author&query=Abbas%2C+A">Ali Abbas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">This study provides Urdu poetry generated using different deep-learning
techniques and algorithms. The data was collected through the Rekhta website,
containing 1341 text files with several couplets. The data on poetry was not
from any specific genre or poet. Instead, it was a collection of mixed Urdu
poems and Ghazals. Different deep learning techniques, such as the model
applied Long Short-term Memory Networks (LSTM) and Gated Recurrent Unit (GRU),
have been used. Natural Language Processing (NLP) may be used in machine
learning to understand, analyze, and generate a language humans may use and
understand. Much work has been done on generating poetry for different
languages using different techniques. The collection and use of data were also
different for different researchers. The primary purpose of this project is to
provide a model that generates Urdu poems by using data completely, not by
sampling data. Also, this may generate poems in pure Urdu, not Roman Urdu, as
in the base paper. The results have shown good accuracy in the poems generated
by the model.
</p>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14235" title="Abstract">arXiv:2309.14235</a> [<a href="/pdf/2309.14235" title="Download PDF">pdf</a>, <a href="/format/2309.14235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stackelberg Driver Model for Continual Policy Improvement in  Scenario-Based Closed-Loop Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+H">Haoyi Niu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qimao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yingyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jianming Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">The deployment of autonomous vehicles (AVs) has faced hurdles due to the
dominance of rare but critical corner cases within the long-tail distribution
of driving scenarios, which negatively affects their overall performance. To
address this challenge, adversarial generation methods have emerged as a class
of efficient approaches to synthesize safety-critical scenarios for AV testing.
However, these generated scenarios are often underutilized for AV training,
resulting in the potential for continual AV policy improvement remaining
untapped, along with a deficiency in the closed-loop design needed to achieve
it. Therefore, we tailor the Stackelberg Driver Model (SDM) to accurately
characterize the hierarchical nature of vehicle interaction dynamics,
facilitating iterative improvement by engaging background vehicles (BVs) and AV
in a sequential game-like interaction paradigm. With AV acting as the leader
and BVs as followers, this leader-follower modeling ensures that AV would
consistently refine its policy, always taking into account the additional
information that BVs play the best response to challenge AV. Extensive
experiments have shown that our algorithm exhibits superior performance
compared to several baselines especially in higher dimensional scenarios,
leading to substantial advancements in AV capabilities while continually
generating progressively challenging scenarios.
</p>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14236" title="Abstract">arXiv:2309.14236</a> [<a href="/pdf/2309.14236" title="Download PDF">pdf</a>, <a href="/format/2309.14236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lancaster%2C+P">Patrick Lancaster</a>, 
<a href="/search/cs?searchtype=author&query=Hansen%2C+N">Nicklas Hansen</a>, 
<a href="/search/cs?searchtype=author&query=Rajeswaran%2C+A">Aravind Rajeswaran</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikash Kumar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Robotic systems that aspire to operate in uninstrumented real-world
environments must perceive the world directly via onboard sensing. Vision-based
learning systems aim to eliminate the need for environment instrumentation by
building an implicit understanding of the world based on raw pixels, but
navigating the contact-rich high-dimensional search space from solely sparse
visual reward signals significantly exacerbates the challenge of exploration.
The applicability of such systems is thus typically restricted to simulated or
heavily engineered environments since agent exploration in the real-world
without the guidance of explicit state estimation and dense rewards can lead to
unsafe behavior and safety faults that are catastrophic. In this study, we
isolate the root causes behind these limitations to develop a system, called
MoDem-V2, capable of learning contact-rich manipulation directly in the
uninstrumented real world. Building on the latest algorithmic advancements in
model-based reinforcement learning (MBRL), demo-bootstrapping, and effective
exploration, MoDem-V2 can acquire contact-rich dexterous manipulation skills
directly in the real world. We identify key ingredients for leveraging
demonstrations in model learning while respecting real-world safety
considerations -- exploration centering, agency handover, and actor-critic
ensembles. We empirically demonstrate the contribution of these ingredients in
four complex visuo-motor manipulation problems in both simulation and the real
world. To the best of our knowledge, our work presents the first successful
system for demonstration-augmented visual MBRL trained directly in the real
world. Visit https://sites.google.com/view/modem-v2 for videos and more
details.
</p>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14237" title="Abstract">arXiv:2309.14237</a> [<a href="/pdf/2309.14237" title="Download PDF">pdf</a>, <a href="/format/2309.14237" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Reinforcement Learning based on Planning Operators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ramirez-Amaro%2C+K">Karinne Ramirez-Amaro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Long-horizon manipulation tasks such as stacking represent a longstanding
challenge in the field of robotic manipulation, particularly when using
reinforcement learning (RL) methods which often struggle to learn the correct
sequence of actions for achieving these complex goals. To learn this sequence,
symbolic planning methods offer a good solution based on high-level reasoning,
however, planners often fall short in addressing the low-level control
specificity needed for precise execution. This paper introduces a novel
framework that integrates symbolic planning with hierarchical RL through the
cooperation of high-level operators and low-level policies. Our contribution
integrates planning operators (e.g. preconditions and effects) as part of the
hierarchical RL algorithm based on the Scheduled Auxiliary Control (SAC-X)
method. We developed a dual-purpose high-level operator, which can be used both
in holistic planning and as independent, reusable policies. Our approach offers
a flexible solution for long-horizon tasks, e.g., stacking a cube. The
experimental results show that our proposed method obtained an average of 97.2%
success rate for learning and executing the whole stack sequence, and the
success rate for learning independent policies, e.g. reach (98.9%), lift
(99.7%), stack (85%), etc. The training time is also reduced by 68% when using
our proposed approach.
</p>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14240" title="Abstract">arXiv:2309.14240</a> [<a href="/pdf/2309.14240" title="Download PDF">pdf</a>, <a href="/format/2309.14240" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Abstain From Uninformative Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yikai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Songzhu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Dalirrooyfard%2C+M">Mina Dalirrooyfard</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Pengxiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+A">Anderson Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Anant Raj</a>, 
<a href="/search/cs?searchtype=author&query=Nevmyvaka%2C+Y">Yuriy Nevmyvaka</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+C">Chao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Learning and decision-making in domains with naturally high noise-to-signal
ratio, such as Finance or Healthcare, is often challenging, while the stakes
are very high. In this paper, we study the problem of learning and acting under
a general noisy generative process. In this problem, the data distribution has
a significant proportion of uninformative samples with high noise in the label,
while part of the data contains useful information represented by low label
noise. This dichotomy is present during both training and inference, which
requires the proper handling of uninformative data during both training and
testing. We propose a novel approach to learning under these conditions via a
loss inspired by the selective learning theory. By minimizing this loss, the
model is guaranteed to make a near-optimal decision by distinguishing
informative data from uninformative data and making predictions. We build upon
the strength of our theoretical guarantees by describing an iterative
algorithm, which jointly optimizes both a predictor and a selector, and
evaluates its empirical performance in a variety of settings.
</p>
</div>
</dd>
<dt><a name="item543">[543]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14241" title="Abstract">arXiv:2309.14241</a> [<a href="/pdf/2309.14241" title="Download PDF">pdf</a>, <a href="/format/2309.14241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Informative Data Mining for One-Shot Cross-Domain Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuxi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jian Liang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Jun Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Shuqi Mei</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yuran Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhaoxiang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Contemporary domain adaptation offers a practical solution for achieving
cross-domain transfer of semantic segmentation between labeled source data and
unlabeled target data. These solutions have gained significant popularity;
however, they require the model to be retrained when the test environment
changes. This can result in unbearable costs in certain applications due to the
time-consuming training process and concerns regarding data privacy. One-shot
domain adaptation methods attempt to overcome these challenges by transferring
the pre-trained source model to the target domain using only one target data.
Despite this, the referring style transfer module still faces issues with
computation cost and over-fitting problems. To address this problem, we propose
a novel framework called Informative Data Mining (IDM) that enables efficient
one-shot domain adaptation for semantic segmentation. Specifically, IDM
provides an uncertainty-based selection criterion to identify the most
informative samples, which facilitates quick adaptation and reduces redundant
training. We then perform a model adaptation method using these selected
samples, which includes patch-wise mixing and prototype-based information
maximization to update the model. This approach effectively enhances adaptation
and mitigates the overfitting problem. In general, we provide empirical
evidence of the effectiveness and efficiency of IDM. Our approach outperforms
existing methods and achieves a new state-of-the-art one-shot performance of
56.7\%/55.4\% on the GTA5/SYNTHIA to Cityscapes adaptation tasks, respectively.
The code will be released at \url{https://github.com/yxiwang/IDM}.
</p>
</div>
</dd>
<dt><a name="item544">[544]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14243" title="Abstract">arXiv:2309.14243</a> [<a href="/pdf/2309.14243" title="Download PDF">pdf</a>, <a href="/format/2309.14243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing data efficiency in reinforcement learning: a novel imagination  mechanism based on mesh information propagation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+M">Maowei Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages. arXiv admin note: text overlap with <a href="/abs/2007.05929">arXiv:2007.05929</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Reinforcement learning (RL) algorithms face the challenge of limited data
efficiency, particularly when dealing with high-dimensional state spaces and
large-scale problems. Most RL methods often rely solely on state transition
information within the same episode when updating the agent's Critic, which can
lead to low data efficiency and sub-optimal training time consumption. Inspired
by human-like analogical reasoning abilities, we introduce a novel mesh
information propagation mechanism, termed the 'Imagination Mechanism (IM)',
designed to significantly enhance the data efficiency of RL algorithms.
Specifically, IM enables information generated by a single sample to be
effectively broadcasted to different states, instead of simply transmitting in
the same episode and it allows the model to better understand the
interdependencies between states and learn scarce sample information more
efficiently. To promote versatility, we extend the imagination mechanism to
function as a plug-and-play module that can be seamlessly and fluidly
integrated into other widely adopted RL models. Our experiments demonstrate
that Imagination mechanism consistently boosts four mainstream SOTA
RL-algorithms, such as SAC, PPO, DDPG, and DQN, by a considerable margin,
ultimately leading to superior performance than before across various tasks.
For access to our code and data, please visit
https://github.com/Zero-coder/FECAM.
</p>
</div>
</dd>
<dt><a name="item545">[545]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14245" title="Abstract">arXiv:2309.14245</a> [<a href="/pdf/2309.14245" title="Download PDF">pdf</a>, <a href="/format/2309.14245" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do We Run How We Say We Run? Formalization and Practice of Governance in  OSS Communities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakraborti%2C+M">Mahasweta Chakraborti</a>, 
<a href="/search/cs?searchtype=author&query=Atkisson%2C+C">Curtis Atkisson</a>, 
<a href="/search/cs?searchtype=author&query=Stanciulescu%2C+S">Stefan Stanciulescu</a>, 
<a href="/search/cs?searchtype=author&query=Filkov%2C+V">Vladimir Filkov</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+S">Seth Frey</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY); Software Engineering (cs.SE)

</div>
<p class="mathjax">Open Source Software (OSS) communities often resist regulation typical of
traditional organizations. Yet formal governance systems are being increasingly
adopted among communities, particularly through non-profit mentor foundations.
Our study looks at the Apache Software Foundation Incubator program and 208
projects it supports. We assemble a scalable, semantic pipeline to discover and
analyze the governance behavior of projects from their mailing lists. We then
investigate the reception of formal policies among communities, through their
own governance priorities and internalization of the policies. Our findings
indicate that while communities observe formal requirements and policies as
extensively as they are defined, their day-to-day governance focus does not
dwell on topics that see most formal policy-making. Moreover formalization, be
it dedicating governance focus or adopting policy, has limited association with
project sustenance.
</p>
</div>
</dd>
<dt><a name="item546">[546]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14246" title="Abstract">arXiv:2309.14246</a> [<a href="/pdf/2309.14246" title="Download PDF">pdf</a>, <a href="/format/2309.14246" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Risk-Aware Quadrupedal Locomotion using Distributional  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schneider%2C+L">Lukas Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Frey%2C+J">Jonas Frey</a>, 
<a href="/search/cs?searchtype=author&query=Miki%2C+T">Takahiro Miki</a>, 
<a href="/search/cs?searchtype=author&query=Hutter%2C+M">Marco Hutter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Deployment in hazardous environments requires robots to understand the risks
associated with their actions and movements to prevent accidents. Despite its
importance, these risks are not explicitly modeled by currently deployed
locomotion controllers for legged robots. In this work, we propose a risk
sensitive locomotion training method employing distributional reinforcement
learning to consider safety explicitly. Instead of relying on a value
expectation, we estimate the complete value distribution to account for
uncertainty in the robot's interaction with the environment. The value
distribution is consumed by a risk metric to extract risk sensitive value
estimates. These are integrated into Proximal Policy Optimization (PPO) to
derive our method, Distributional Proximal Policy Optimization (DPPO). The risk
preference, ranging from risk-averse to risk-seeking, can be controlled by a
single parameter, which enables to adjust the robot's behavior dynamically.
Importantly, our approach removes the need for additional reward function
tuning to achieve risk sensitivity. We show emergent risk sensitive locomotion
behavior in simulation and on the quadrupedal robot ANYmal.
</p>
</div>
</dd>
<dt><a name="item547">[547]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14247" title="Abstract">arXiv:2309.14247</a> [<a href="/pdf/2309.14247" title="Download PDF">pdf</a>, <a href="/format/2309.14247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Internet Communication Through LLMs: How Close Are We?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taki%2C+S+U">Sifat Ut Taki</a>, 
<a href="/search/cs?searchtype=author&query=Mastorakis%2C+S">Spyridon Mastorakis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">In this paper, we rethink the way that communication among users over the
Internet, one of the fundamental outcomes of the Internet evolution, takes
place. Instead of users communicating directly over the Internet, we explore an
architecture that enables users to communicate with (query) Large Language
Models (LLMs) that capture the cognition of users on the other end of the
communication channel. We present an architecture to achieve such LLM-based
communication and we perform a reality check to assess how close we are today
to realizing such a communication architecture from a technical point of view.
Finally, we discuss several research challenges and identify interesting
directions for future research.
</p>
</div>
</dd>
<dt><a name="item548">[548]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14248" title="Abstract">arXiv:2309.14248</a> [<a href="/pdf/2309.14248" title="Download PDF">pdf</a>, <a href="/format/2309.14248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transcending the Acceleration-Bandwidth Trade-off: Lightweight Precision  Stages with Active Control of Flexible Dynamics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jingjie Wu</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+L">Lei Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2301.04208">arXiv:2301.04208</a>; text overlap with <a href="/abs/2309.11735">arXiv:2309.11735</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Micro/Nano-positioning stages are of great importance in a wide range of
manufacturing machines and instruments. In recent years, the drastically
growing demand for higher throughput and reduced power consumption in various
IC manufacturing equipment calls for the development of next-generation
precision positioning systems with unprecedented acceleration capability while
maintaining exceptional positioning accuracy and high control bandwidth.
Reducing the stage's weight is an effective approach to achieving this goal.
However, the reduction of stages' weight tends to decrease its structural
resonance frequency, which limits the closed-loop control bandwidth and can
even cause stability issues. Aiming to overcome the aforementioned challenge
and thus create new lightweight precision stages with substantially improved
acceleration capability without sacrificing stage control performance, this
research presents a novel sequential structure and control design framework for
lightweight stages with low-frequency flexible modes of the stage being
actively controlled. Additional actuators and sensors are placed to actively
control the flexible structural dynamics of the lightweight stage to attain
high control bandwidth. A case study is simulated to evaluate the effectiveness
of the proposed approach, where a stage weight reduction of 24% is demonstrated
compared to a baseline case, which demonstrates the potential of the proposed
design framework. Experimental evaluation of the designed stage's motion
performance will be performed on a magnetically levitated linear motor platform
for performance demonstration.
</p>
</div>
</dd>
<dt><a name="item549">[549]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14258" title="Abstract">arXiv:2309.14258</a> [<a href="/pdf/2309.14258" title="Download PDF">pdf</a>, <a href="/format/2309.14258" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OmniEvent: A Comprehensive, Fair, and Easy-to-Use Toolkit for Event  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hao Peng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaozhi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Feng Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zimu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+C">Chuzhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+K">Kaisheng Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Lei Hou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Juanzi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Event understanding aims at understanding the content and relationship of
events within texts, which covers multiple complicated information extraction
tasks: event detection, event argument extraction, and event relation
extraction. To facilitate related research and application, we present an event
understanding toolkit OmniEvent, which features three desiderata: (1)
Comprehensive. OmniEvent supports mainstream modeling paradigms of all the
event understanding tasks and the processing of 15 widely-used English and
Chinese datasets. (2) Fair. OmniEvent carefully handles the inconspicuous
evaluation pitfalls reported in Peng et al. (2023), which ensures fair
comparisons between different models. (3) Easy-to-use. OmniEvent is designed to
be easily used by users with varying needs. We provide off-the-shelf models
that can be directly deployed as web services. The modular framework also
enables users to easily implement and evaluate new event understanding models
with OmniEvent. The toolkit (https://github.com/THU-KEG/OmniEvent) is publicly
released along with the demonstration website and video
(https://omnievent.xlore.cn/).
</p>
</div>
</dd>
<dt><a name="item550">[550]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14259" title="Abstract">arXiv:2309.14259</a> [<a href="/pdf/2309.14259" title="Download PDF">pdf</a>, <a href="/format/2309.14259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Table of Contents for the Front Page of the Internet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Partridge%2C+V">Virginia Partridge</a>, 
<a href="/search/cs?searchtype=author&query=Mangat%2C+J">Jasmine Mangat</a>, 
<a href="/search/cs?searchtype=author&query=Curran%2C+R">Rebecca Curran</a>, 
<a href="/search/cs?searchtype=author&query=McGrady%2C+R">Ryan McGrady</a>, 
<a href="/search/cs?searchtype=author&query=Zuckerman%2C+E">Ethan Zuckerman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">We create monthly snapshot community embeddings that infer relationships
between subreddits, allowing clustering as an intuitive way to explore
subreddit communities. Through two annotation tasks, we validate that these
subreddit clusterings align well with expert judgements. Although embeddings
are created independently from different time periods of data, clusterings
produced from monthly snapshots change gradually over time, and the stability
of a subreddit's nearest neighbors can be analyzed to understand how that
subreddit fits in or evolves relative to other communities on Reddit.
</p>
</div>
</dd>
<dt><a name="item551">[551]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14263" title="Abstract">arXiv:2309.14263</a> [<a href="/pdf/2309.14263" title="Download PDF">pdf</a>, <a href="/format/2309.14263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Target Controllability and Target Observability of Structured Network  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Montanari%2C+A+N">Arthur N. Montanari</a>, 
<a href="/search/eess?searchtype=author&query=Duan%2C+C">Chao Duan</a>, 
<a href="/search/eess?searchtype=author&query=Motter%2C+A+E">Adilson E. Motter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Codes are available in GitHub (<a href="https://github.com/montanariarthur/TargetCtrb">this https URL</a>)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Control Systems Letters, vol. 7, pp. 3060-3065 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Optimization and Control (math.OC); Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">The duality between controllability and observability enables methods
developed for full-state control to be applied to full-state estimation, and
vice versa. In applications in which control or estimation of all state
variables is unfeasible, the generalized notions of output controllability and
functional observability establish the minimal conditions for the control and
estimation of a target subset of state variables, respectively. Given the
seemly unrelated nature of these properties, thus far methods for target
control and target estimation have been developed independently in the
literature. Here, we characterize the graph-theoretic conditions for target
controllability and target observability (which are, respectively, special
cases of output controllability and functional observability for structured
systems). This allow us to rigorously establish a weak and strong duality
between these generalized properties. When both properties are equivalent
(strongly dual), we show that efficient algorithms developed for target
controllability can be used for target observability, and vice versa, for the
optimal placement of sensors and drivers. These results are applicable to
large-scale networks, in which control and monitoring are often sought for
small subsets of nodes.
</p>
</div>
</dd>
<dt><a name="item552">[552]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14265" title="Abstract">arXiv:2309.14265</a> [<a href="/pdf/2309.14265" title="Download PDF">pdf</a>, <a href="/format/2309.14265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Industrial Application of 6D Pose Estimation for Robotic Manipulation in  Automotive Internal Logistics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Quentin%2C+P">Philipp Quentin</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+D">Dino Knoll</a>, 
<a href="/search/cs?searchtype=author&query=Goehring%2C+D">Daniel Goehring</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at IEEE International Conference on Automation Science and Engineering (CASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Despite the advances in robotics a large proportion of the of parts handling
tasks in the automotive industry's internal logistics are not automated but
still performed by humans. A key component to competitively automate these
processes is a 6D pose estimation that can handle a large number of different
parts, is adaptable to new parts with little manual effort, and is sufficiently
accurate and robust with respect to industry requirements. In this context, the
question arises as to the current status quo with respect to these measures. To
address this we built a representative 6D pose estimation pipeline with
state-of-the-art components from economically scalable real to synthetic data
generation to pose estimators and evaluated it on automotive parts with regards
to a realistic sequencing process. We found that using the data generation
approaches, the performance of the trained 6D pose estimators are promising,
but do not meet industry requirements. We reveal that the reason for this is
the inability of the estimators to provide reliable uncertainties for their
poses, rather than the ability of to provide sufficiently accurate poses. In
this context we further analyzed how RGB- and RGB-D-based approaches compare
against this background and show that they are differently vulnerable to the
domain gap induced by synthetic data.
</p>
</div>
</dd>
<dt><a name="item553">[553]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14266" title="Abstract">arXiv:2309.14266</a> [<a href="/pdf/2309.14266" title="Download PDF">pdf</a>, <a href="/format/2309.14266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Hydra Hand: A Mode-Switching Underactuated Gripper with Precision  and Power Grasping Modes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chappell%2C+D">Digby Chappell</a>, 
<a href="/search/cs?searchtype=author&query=Bello%2C+F">Fernando Bello</a>, 
<a href="/search/cs?searchtype=author&query=Kormushev%2C+P">Petar Kormushev</a>, 
<a href="/search/cs?searchtype=author&query=Rojas%2C+N">Nicolas Rojas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Human hands are able to grasp a wide range of object sizes, shapes, and
weights, achieved via reshaping and altering their apparent grasping stiffness
between compliant power and rigid precision. Achieving similar versatility in
robotic hands remains a challenge, which has often been addressed by adding
extra controllable degrees of freedom, tactile sensors, or specialised extra
grasping hardware, at the cost of control complexity and robustness. We
introduce a novel reconfigurable four-fingered two-actuator underactuated
gripper -- the Hydra Hand -- that switches between compliant power and rigid
precision grasps using a single motor, while generating grasps via a single
hydraulic actuator -- exhibiting adaptive grasping between finger pairs,
enabling the power grasping of two objects simultaneously. The mode switching
mechanism and the hand's kinematics are presented and analysed, and performance
is tested on two grasping benchmarks: one focused on rigid objects, and the
other on items of clothing. The Hydra Hand is shown to excel at grasping large
and irregular objects, and small objects with its respective compliant power
and rigid precision configurations. The hand's versatility is then showcased by
executing the challenging manipulation task of safely grasping and placing a
bunch of grapes, and then plucking a single grape from the bunch.
</p>
</div>
</dd>
<dt><a name="item554">[554]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14267" title="Abstract">arXiv:2309.14267</a> [<a href="/pdf/2309.14267" title="Download PDF">pdf</a>, <a href="/format/2309.14267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identity-preserving Editing of Multiple Facial Attributes by Learning  Global Edit Directions and Local Adjustments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mohammadbagheri%2C+N">Najmeh Mohammadbagheri</a>, 
<a href="/search/cs?searchtype=author&query=Ayar%2C+F">Fardin Ayar</a>, 
<a href="/search/cs?searchtype=author&query=Nickabadi%2C+A">Ahmad Nickabadi</a>, 
<a href="/search/cs?searchtype=author&query=Safabakhsh%2C+R">Reza Safabakhsh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Semantic facial attribute editing using pre-trained Generative Adversarial
Networks (GANs) has attracted a great deal of attention and effort from
researchers in recent years. Due to the high quality of face images generated
by StyleGANs, much work has focused on the StyleGANs' latent space and the
proposed methods for facial image editing. Although these methods have achieved
satisfying results for manipulating user-intended attributes, they have not
fulfilled the goal of preserving the identity, which is an important challenge.
We present ID-Style, a new architecture capable of addressing the problem of
identity loss during attribute manipulation. The key components of ID-Style
include Learnable Global Direction (LGD), which finds a shared and semi-sparse
direction for each attribute, and an Instance-Aware Intensity Predictor (IAIP)
network, which finetunes the global direction according to the input instance.
Furthermore, we introduce two losses during training to enforce the LGD to find
semi-sparse semantic directions, which along with the IAIP, preserve the
identity of the input instance. Despite reducing the size of the network by
roughly 95% as compared to similar state-of-the-art works, it outperforms
baselines by 10% and 7% in Identity preserving metric (FRS) and average
accuracy of manipulation (mACC), respectively.
</p>
</div>
</dd>
<dt><a name="item555">[555]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14269" title="Abstract">arXiv:2309.14269</a> [<a href="/pdf/2309.14269" title="Download PDF">pdf</a>, <a href="/format/2309.14269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised correspondence with combined geometric learning and imaging  for radiotherapy applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henderson%2C+E+G+A">Edward G. A. Henderson</a>, 
<a href="/search/cs?searchtype=author&query=van+Herk%2C+M">Marcel van Herk</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+A+F">Andrew F. Green</a>, 
<a href="/search/cs?searchtype=author&query=Osorio%2C+E+M+V">Eliana M. Vasquez Osorio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in 3rd Workshop on Shape in Medical Imaging (ShapeMI 2023). This preprint has not undergone peer review or any post-submission improvements or corrections
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The aim of this study was to develop a model to accurately identify
corresponding points between organ segmentations of different patients for
radiotherapy applications. A model for simultaneous correspondence and
interpolation estimation in 3D shapes was trained with head and neck organ
segmentations from planning CT scans. We then extended the original model to
incorporate imaging information using two approaches: 1) extracting features
directly from image patches, and 2) including the mean square error between
patches as part of the loss function. The correspondence and interpolation
performance were evaluated using the geodesic error, chamfer distance and
conformal distortion metrics, as well as distances between anatomical
landmarks. Each of the models produced significantly better correspondences
than the baseline non-rigid registration approach. The original model performed
similarly to the model with direct inclusion of image features. The best
performing model configuration incorporated imaging information as part of the
loss function which produced more anatomically plausible correspondences. We
will use the best performing model to identify corresponding anatomical points
on organs to improve spatial normalisation, an important step in outcome
modelling, or as an initialisation for anatomically informed registrations. All
our code is publicly available at
https://github.com/rrr-uom-projects/Unsup-RT-Corr-Net
</p>
</div>
</dd>
<dt><a name="item556">[556]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14272" title="Abstract">arXiv:2309.14272</a> [<a href="/pdf/2309.14272" title="Download PDF">pdf</a>, <a href="/ps/2309.14272" title="Download PostScript">ps</a>, <a href="/format/2309.14272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Perception-and-Energy-aware Motion Planning for UAV using Learning-based  Model under Heteroscedastic Uncertainty
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takemura%2C+R">Reiya Takemura</a>, 
<a href="/search/cs?searchtype=author&query=Ishigami%2C+G">Genya Ishigami</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, 2 tables. Submitted article for presentation at the 2024 IEEE International Conference on Robotics and Automation (ICRA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Global navigation satellite systems (GNSS) denied environments/conditions
require unmanned aerial vehicles (UAVs) to energy-efficiently and reliably fly.
To this end, this study presents perception-and-energy-aware motion planning
for UAVs in GNSS-denied environments. The proposed planner solves the
trajectory planning problem by optimizing a cost function consisting of two
indices: the total energy consumption of a UAV and the perception quality of
light detection and ranging (LiDAR) sensor mounted on the UAV. Before online
navigation, a high-fidelity simulator acquires a flight dataset to learn energy
consumption for the UAV and heteroscedastic uncertainty associated with LiDAR
measurements, both as functions of the horizontal velocity of the UAV. The
learned models enable the online planner to estimate energy consumption and
perception quality, reducing UAV battery usage and localization errors.
Simulation experiments in a photorealistic environment confirm that the
proposed planner can address the trade-off between energy efficiency and
perception quality under heteroscedastic uncertainty. The open-source code is
released at https://gitlab.com/ReI08/perception-energy-planner.
</p>
</div>
</dd>
<dt><a name="item557">[557]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14273" title="Abstract">arXiv:2309.14273</a> [<a href="/pdf/2309.14273" title="Download PDF">pdf</a>, <a href="/format/2309.14273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECN with QUIC: Challenges in the Wild
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sander%2C+C">Constantin Sander</a>, 
<a href="/search/cs?searchtype=author&query=Kunze%2C+I">Ike Kunze</a>, 
<a href="/search/cs?searchtype=author&query=Bl%C3%B6cher%2C+L">Leo Bl&#xf6;cher</a>, 
<a href="/search/cs?searchtype=author&query=Kosek%2C+M">Mike Kosek</a>, 
<a href="/search/cs?searchtype=author&query=Wehrle%2C+K">Klaus Wehrle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at the ACM Internet Measurement Conference 2023 (IMC'23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
<p class="mathjax">TCP and QUIC can both leverage ECN to avoid congestion loss and its
retransmission overhead. However, both protocols require support of their
remote endpoints and it took two decades since the initial standardization of
ECN for TCP to reach 80% ECN support and more in the wild. In contrast, the
QUIC standard mandates ECN support, but there are notable ambiguities that make
it unclear if and how ECN can actually be used with QUIC on the Internet.
Hence, in this paper, we analyze ECN support with QUIC in the wild: We conduct
repeated measurements on more than 180M domains to identify HTTP/3 websites and
analyze the underlying QUIC connections w.r.t. ECN support. We only find 20% of
QUIC hosts, providing 6% of HTTP/3 websites, to mirror client ECN codepoints.
Yet, mirroring ECN is only half of what is required for ECN with QUIC, as QUIC
validates mirrored ECN codepoints to detect network impairments: We observe
that less than 2% of QUIC hosts, providing less than 0.3% of HTTP/3 websites,
pass this validation. We identify possible root causes in content providers not
supporting ECN via QUIC and network impairments hindering ECN. We thus also
characterize ECN with QUIC distributedly to traverse other paths and discuss
our results w.r.t. QUIC and ECN innovations beyond QUIC.
</p>
</div>
</dd>
<dt><a name="item558">[558]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14274" title="Abstract">arXiv:2309.14274</a> [<a href="/pdf/2309.14274" title="Download PDF">pdf</a>, <a href="/format/2309.14274" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrodirective Antenna Array Approach to Achieve Maximum Theoretical  Beam Efficiency in Microwave Wireless Power Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ambatali%2C+C+D+M">Charleston Dale M. Ambatali</a>, 
<a href="/search/eess?searchtype=author&query=Nakasuka%2C+S">Shinichi Nakasuka</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+B">Bo Yang</a>, 
<a href="/search/eess?searchtype=author&query=Shinohara%2C+N">Naoki Shinohara</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 9 pages, 11 figures, 1 table, submitted to the IEEE Transactions on Theory and Techniques on September 22, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">Efficient long range wireless power transfer (WPT) is realized if the
distance between the source and receiver is less than the Fraunhoffer distance.
This distance increases proportionally to the square root of the antenna size
so to achieve efficient long range WPT, larger antennas are mandatory, but that
comes with difficulty in implementing both the feeding network and beamforming
control of the antenna. Several proposed implementations require power-hungry
processors rendering implementation impractical. An alternative to reduce usage
of digital processing is in the form of retrodirective antenna arrays. Its core
operation is to track an incoming signal's direction of arrival and resend it
to the same direction. This can be implemented by analog circuits.
Retrodirective capability on both the generator and rectenna arrays creates a
feedback loop that produces a high efficiency WPT channel. In this paper, we
characterize the dynamics of this phenomenon using a discrete-time state-space
model based on S-parameters and show that the system can naturally achieve
maximum theoretical WPT efficiency. We further confirmed the theoretical
analysis through a hardware experiment using a 12-port circuit board with
measurable S-parameters mimicking a deterministic wireless channel. The results
of the hardware experiment show agreement with the proposed theoretical
framework.
</p>
</div>
</dd>
<dt><a name="item559">[559]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14277" title="Abstract">arXiv:2309.14277</a> [<a href="/pdf/2309.14277" title="Download PDF">pdf</a>, <a href="/format/2309.14277" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SINCERE: Supervised Information Noise-Contrastive Estimation REvisited
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feeney%2C+P">Patrick Feeney</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+M+C">Michael C. Hughes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The information noise-contrastive estimation (InfoNCE) loss function provides
the basis of many self-supervised deep learning methods due to its strong
empirical results and theoretic motivation. Previous work suggests a supervised
contrastive (SupCon) loss to extend InfoNCE to learn from available class
labels. This SupCon loss has been widely-used due to reports of good empirical
performance. However, in this work we suggest that the specific SupCon loss
formulated by prior work has questionable theoretic justification, because it
can encourage images from the same class to repel one another in the learned
embedding space. This problematic behavior gets worse as the number of inputs
sharing one class label increases. We propose the Supervised InfoNCE REvisited
(SINCERE) loss as a remedy. SINCERE is a theoretically justified solution for a
supervised extension of InfoNCE that never causes images from the same class to
repel one another. We further show that minimizing our new loss is equivalent
to maximizing a bound on the KL divergence between class conditional embedding
distributions. We compare SINCERE and SupCon losses in terms of learning
trajectories during pretraining and in ultimate linear classifier performance
after finetuning. Our proposed SINCERE loss better separates embeddings from
different classes during pretraining while delivering competitive accuracy.
</p>
</div>
</dd>
<dt><a name="item560">[560]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14279" title="Abstract">arXiv:2309.14279</a> [<a href="/pdf/2309.14279" title="Download PDF">pdf</a>, <a href="/format/2309.14279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spring-IMU Fusion Based Proprioception for Feedback Control of Soft  Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+Y">Yinan Meng</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+G">Guoxin Fang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiong Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuhu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C+C+L">Charlie C.L. Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a novel framework to realize proprioception and
closed-loop control for soft manipulators. Deformations with large elongation
and large bending can be precisely predicted using geometry-based sensor
signals obtained from the inductive springs and the inertial measurement units
(IMUs) with the help of machine learning techniques. Multiple geometric signals
are fused into robust pose estimations, and a data-efficient training process
is achieved after applying the strategy of sim-to-real transfer. As a result,
we can achieve proprioception that is robust to the variation of external
loading and has an average error of 0.7% across the workspace on a
pneumatic-driven soft manipulator. The realized proprioception on soft
manipulator is then contributed to building a sensor-space based algorithm for
closed-loop control. A gradient descent solver is developed to drive the
end-effector to achieve the required poses by iteratively computing a sequence
of reference sensor signals. A conventional controller is employed in the inner
loop of our algorithm to update actuators (i.e., the pressures in chambers) for
approaching a reference signal in the sensor-space. The systematic function of
closed-loop control has been demonstrated in tasks like path following and
pick-and-place under different external loads.
</p>
</div>
</dd>
<dt><a name="item561">[561]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14282" title="Abstract">arXiv:2309.14282</a> [<a href="/pdf/2309.14282" title="Download PDF">pdf</a>, <a href="/format/2309.14282" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Calibration-based Dual Prototypical Contrastive Learning Approach for  Domain Generalization Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liao%2C+M">Muxin Liao</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+S">Shishun Tian</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+G">Guoguang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+W">Wenbin Zou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xia Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM MM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Prototypical contrastive learning (PCL) has been widely used to learn
class-wise domain-invariant features recently. These methods are based on the
assumption that the prototypes, which are represented as the central value of
the same class in a certain domain, are domain-invariant. Since the prototypes
of different domains have discrepancies as well, the class-wise
domain-invariant features learned from the source domain by PCL need to be
aligned with the prototypes of other domains simultaneously. However, the
prototypes of the same class in different domains may be different while the
prototypes of different classes may be similar, which may affect the learning
of class-wise domain-invariant features. Based on these observations, a
calibration-based dual prototypical contrastive learning (CDPCL) approach is
proposed to reduce the domain discrepancy between the learned class-wise
features and the prototypes of different domains for domain generalization
semantic segmentation. It contains an uncertainty-guided PCL (UPCL) and a
hard-weighted PCL (HPCL). Since the domain discrepancies of the prototypes of
different classes may be different, we propose an uncertainty probability
matrix to represent the domain discrepancies of the prototypes of all the
classes. The UPCL estimates the uncertainty probability matrix to calibrate the
weights of the prototypes during the PCL. Moreover, considering that the
prototypes of different classes may be similar in some circumstances, which
means these prototypes are hard-aligned, the HPCL is proposed to generate a
hard-weighted matrix to calibrate the weights of the hard-aligned prototypes
during the PCL. Extensive experiments demonstrate that our approach achieves
superior performance over current approaches on domain generalization semantic
segmentation tasks.
</p>
</div>
</dd>
<dt><a name="item562">[562]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14289" title="Abstract">arXiv:2309.14289</a> [<a href="/pdf/2309.14289" title="Download PDF">pdf</a>, <a href="/format/2309.14289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CLIP-DIY: CLIP Dense Inference Yields Open-Vocabulary Semantic  Segmentation For-Free
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wysocza%C5%84ska%2C+M">Monika Wysocza&#x144;ska</a>, 
<a href="/search/cs?searchtype=author&query=Ramamonjisoa%2C+M">Micha&#xeb;l Ramamonjisoa</a>, 
<a href="/search/cs?searchtype=author&query=Trzci%C5%84ski%2C+T">Tomasz Trzci&#x144;ski</a>, 
<a href="/search/cs?searchtype=author&query=Sim%C3%A9oni%2C+O">Oriane Sim&#xe9;oni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The emergence of CLIP has opened the way for open-world image perception. The
zero-shot classification capabilities of the model are impressive but are
harder to use for dense tasks such as image segmentation. Several methods have
proposed different modifications and learning schemes to produce dense output.
Instead, we propose in this work an open-vocabulary semantic segmentation
method, dubbed CLIP-DIY, which does not require any additional training or
annotations, but instead leverages existing unsupervised object localization
approaches. In particular, CLIP-DIY is a multi-scale approach that directly
exploits CLIP classification abilities on patches of different sizes and
aggregates the decision in a single map. We further guide the segmentation
using foreground/background scores obtained using unsupervised object
localization methods. With our method, we obtain state-of-the-art zero-shot
semantic segmentation results on PASCAL VOC and perform on par with the best
methods on COCO.
</p>
</div>
</dd>
<dt><a name="item563">[563]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14290" title="Abstract">arXiv:2309.14290</a> [<a href="/pdf/2309.14290" title="Download PDF">pdf</a>, <a href="/format/2309.14290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Market Makers for Cross-chain DeFi and Sharded Blockchains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pourpouneh%2C+M">Mohsen Pourpouneh</a>, 
<a href="/search/cs?searchtype=author&query=Nielsen%2C+K">Kurt Nielsen</a>, 
<a href="/search/cs?searchtype=author&query=Gravgaard%2C+e+B">esper Balman Gravgaard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
<p class="mathjax">In this paper we provide an execution framework for Automated Market Maker
(AMM) to be deployed across independent blockchain platforms as well as
concurrent sharding within the same blockchain platform. The framework provides
economic incentives to participate through a mechanism that guarantee fixed
prices across pairwise liquidity pools.
</p>
</div>
</dd>
<dt><a name="item564">[564]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14291" title="Abstract">arXiv:2309.14291</a> [<a href="/pdf/2309.14291" title="Download PDF">pdf</a>, <a href="/format/2309.14291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tiled Multiplane Images for Practical 3D Photography
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+N">Numair Khan</a>, 
<a href="/search/cs?searchtype=author&query=Lanman%2C+D">Douglas Lanman</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lei Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The task of synthesizing novel views from a single image has useful
applications in virtual reality and mobile computing, and a number of
approaches to the problem have been proposed in recent years. A Multiplane
Image (MPI) estimates the scene as a stack of RGBA layers, and can model
complex appearance effects, anti-alias depth errors and synthesize soft edges
better than methods that use textured meshes or layered depth images. And
unlike neural radiance fields, an MPI can be efficiently rendered on graphics
hardware. However, MPIs are highly redundant and require a large number of
depth layers to achieve plausible results. Based on the observation that the
depth complexity in local image regions is lower than that over the entire
image, we split an MPI into many small, tiled regions, each with only a few
depth planes. We call this representation a Tiled Multiplane Image (TMPI). We
propose a method for generating a TMPI with adaptive depth planes for
single-view 3D photography in the wild. Our synthesized results are comparable
to state-of-the-art single-view MPI methods while having lower computational
overhead.
</p>
</div>
</dd>
<dt><a name="item565">[565]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14292" title="Abstract">arXiv:2309.14292</a> [<a href="/pdf/2309.14292" title="Download PDF">pdf</a>, <a href="/format/2309.14292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Non-Associativity of Analog Computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kuhn%2C+L">Lisa Kuhn</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+B">Bernhard Klein</a>, 
<a href="/search/cs?searchtype=author&query=Fr%C3%B6ning%2C+H">Holger Fr&#xf6;ning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the ECML PKDD Conference 2023, at the 4th Workshop on IoT, Edge, and Mobile for Embedded Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Emerging Technologies (cs.ET); Machine Learning (cs.LG)

</div>
<p class="mathjax">The energy efficiency of analog forms of computing makes it one of the most
promising candidates to deploy resource-hungry machine learning tasks on
resource-constrained system such as mobile or embedded devices. However, it is
well known that for analog computations the safety net of discretization is
missing, thus all analog computations are exposed to a variety of imperfections
of corresponding implementations. Examples include non-linearities, saturation
effect and various forms of noise. In this work, we observe that the ordering
of input operands of an analog operation also has an impact on the output
result, which essentially makes analog computations non-associative, even
though the underlying operation might be mathematically associative. We conduct
a simple test by creating a model of a real analog processor which captures
such ordering effects. With this model we assess the importance of ordering by
comparing the test accuracy of a neural network for keyword spotting, which is
trained based either on an ordered model, on a non-ordered variant, and on real
hardware. The results prove the existence of ordering effects as well as their
high impact, as neglecting ordering results in substantial accuracy drops.
</p>
</div>
</dd>
<dt><a name="item566">[566]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14293" title="Abstract">arXiv:2309.14293</a> [<a href="/pdf/2309.14293" title="Download PDF">pdf</a>, <a href="/format/2309.14293" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NAS-NeRF: Generative Neural Architecture Search for Neural Radiance  Fields
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nair%2C+S">Saeejith Nair</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuhao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shafiee%2C+M+J">Mohammad Javad Shafiee</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+A">Alexander Wong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Neural radiance fields (NeRFs) enable high-quality novel view synthesis, but
their prohibitively high computational complexity limits deployability,
especially on resource-constrained platforms. To enable practical usage of
NeRFs, quality tuning is essential to reduce computational complexity, akin to
adjustable graphics settings in video games. However while existing solutions
strive for efficiency, they use one-size-fits-all architectures regardless of
scene complexity, although the same architecture may be unnecessarily large for
simple scenes but insufficient for complex ones. Thus as NeRFs become more
widely used for 3D visualization, there is a need to dynamically optimize the
neural network component of NeRFs to achieve a balance between computational
complexity and specific targets for synthesis quality. Addressing this gap, we
introduce NAS-NeRF: a generative neural architecture search strategy uniquely
tailored to generate NeRF architectures on a per-scene basis by optimizing the
trade-off between complexity and performance, while adhering to constraints on
computational budget and minimum synthesis quality. Our experiments on the
Blender synthetic dataset show the proposed NAS-NeRF can generate architectures
up to 5.74$\times$ smaller, with 4.19$\times$ fewer FLOPs, and 1.93$\times$
faster on a GPU than baseline NeRFs, without suffering a drop in SSIM.
Furthermore, we illustrate that NAS-NeRF can also achieve architectures up to
23$\times$ smaller, 22$\times$ fewer FLOPs, and 4.7$\times$ faster than
baseline NeRFs with only a 5.3\% average SSIM drop. The source code for our
work is also made publicly available at
https://saeejithnair.github.io/NAS-NeRF.
</p>
</div>
</dd>
<dt><a name="item567">[567]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14295" title="Abstract">arXiv:2309.14295</a> [<a href="/pdf/2309.14295" title="Download PDF">pdf</a>, <a href="/format/2309.14295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unwieldy Object Delivery with Nonholonomic Mobile Base: A Stable Pushing  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yujie Tang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Hai Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Potters%2C+S">Susan Potters</a>, 
<a href="/search/cs?searchtype=author&query=Wisse%2C+M">Martijn Wisse</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+W">Wei Pan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The short version of the paper is accepted by RAL
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper addresses the problem of pushing manipulation with nonholonomic
mobile robots. Pushing is a fundamental skill that enables robots to move
unwieldy objects that cannot be grasped. We propose a stable pushing method
that maintains stiff contact between the robot and the object to avoid
consuming repositioning actions. We prove that a line contact, rather than a
single point contact, is necessary for nonholonomic robots to achieve stable
pushing. We also show that the stable pushing constraint and the nonholonomic
constraint of the robot can be simplified as a concise linear motion
constraint. Then the pushing planning problem can be formulated as a
constrained optimization problem using nonlinear model predictive control
(NMPC). According to the experiments, our NMPC-based planner outperforms a
reactive pushing strategy in terms of efficiency, reducing the robot's traveled
distance by 23.8\% and time by 77.4\%. Furthermore, our method requires four
fewer hyperparameters and decision variables than the Linear Time-Varying (LTV)
MPC approach, making it easier to implement. Real-world experiments are carried
out to validate the proposed method with two differential-drive robots, Husky
and Boxer, under different friction conditions.
</p>
</div>
</dd>
<dt><a name="item568">[568]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14300" title="Abstract">arXiv:2309.14300</a> [<a href="/pdf/2309.14300" title="Download PDF">pdf</a>, <a href="/format/2309.14300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive least-squares space-time finite element methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=K%C3%B6the%2C+C">Christian K&#xf6;the</a>, 
<a href="/search/math?searchtype=author&query=L%C3%B6scher%2C+R">Richard L&#xf6;scher</a>, 
<a href="/search/math?searchtype=author&query=Steinbach%2C+O">Olaf Steinbach</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We consider the numerical solution of an abstract operator equation $Bu=f$ by
using a least-squares approach. We assume that $B: X \to Y^*$ is an
isomorphism, and that $A : Y \to Y^*$ implies a norm in $Y$, where $X$ and $Y$
are Hilbert spaces. The minimizer of the least-squares functional $\frac{1}{2}
\, \| Bu-f \|_{A^{-1}}^2$, i.e., the solution of the operator equation, is then
characterized by the gradient equation $Su=B^* A^{-1}f$ with an elliptic and
self-adjoint operator $S:=B^* A^{-1} B : X \to X^*$. When introducing the
adjoint $p = A^{-1}(f-Bu)$ we end up with a saddle point formulation to be
solved numerically by using a mixed finite element method. Based on a discrete
inf-sup stability condition we derive related a priori error estimates. While
the adjoint $p$ is zero by construction, its approximation $p_h$ serves as a
posteriori error indicator to drive an adaptive scheme when discretized
appropriately. While this approach can be applied to rather general equations,
here we consider second order linear partial differential equations, including
the Poisson equation, the heat equation, and the wave equation, in order to
demonstrate its potential, which allows to use almost arbitrary space-time
finite element methods for the adaptive solution of time-dependent partial
differential equations.
</p>
</div>
</dd>
<dt><a name="item569">[569]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14303" title="Abstract">arXiv:2309.14303</a> [<a href="/pdf/2309.14303" title="Download PDF">pdf</a>, <a href="/format/2309.14303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dataset Diffusion: Diffusion-based Synthetic Dataset Generation for  Pixel-Level Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+Q">Quang Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Truong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+A">Anh Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+K">Khoi Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 poster
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Preparing training data for deep vision models is a labor-intensive task. To
address this, generative models have emerged as an effective solution for
generating synthetic data. While current generative models produce image-level
category labels, we propose a novel method for generating pixel-level semantic
segmentation labels using the text-to-image generative model Stable Diffusion
(SD). By utilizing the text prompts, cross-attention, and self-attention of SD,
we introduce three new techniques: \textit{class-prompt appending},
\textit{class-prompt cross-attention}, and \textit{self-attention
exponentiation}. These techniques enable us to generate segmentation maps
corresponding to synthetic images. These maps serve as pseudo-labels for
training semantic segmenters, eliminating the need for labor-intensive
pixel-wise annotation. To account for the imperfections in our pseudo-labels,
we incorporate uncertainty regions into the segmentation, allowing us to
disregard loss from those regions. We conduct evaluations on two datasets,
PASCAL VOC and MSCOCO, and our approach significantly outperforms concurrent
work. Our benchmarks and code will be released at
https://github.com/VinAIResearch/Dataset-Diffusion
</p>
</div>
</dd>
<dt><a name="item570">[570]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14304" title="Abstract">arXiv:2309.14304</a> [<a href="/pdf/2309.14304" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of Class Activation Maps for Visualization Explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Minh%2C+A+P+T">Anh Pham Thi Minh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent research in deep learning methodology has led to a variety of complex
modelling techniques in computer vision (CV) that reach or even outperform
human performance. Although these black-box deep learning models have obtained
astounding results, they are limited in their interpretability and transparency
which are critical to take learning machines to the next step to include them
in sensitive decision-support systems involving human supervision. Hence, the
development of explainable techniques for computer vision (XCV) has recently
attracted increasing attention. In the realm of XCV, Class Activation Maps
(CAMs) have become widely recognized and utilized for enhancing
interpretability and insights into the decision-making process of deep learning
models. This work presents a comprehensive overview of the evolution of Class
Activation Map methods over time. It also explores the metrics used for
evaluating CAMs and introduces auxiliary techniques to improve the saliency of
these methods. The overview concludes by proposing potential avenues for future
research in this evolving field.
</p>
</div>
</dd>
<dt><a name="item571">[571]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14307" title="Abstract">arXiv:2309.14307</a> [<a href="/pdf/2309.14307" title="Download PDF">pdf</a>, <a href="/ps/2309.14307" title="Download PostScript">ps</a>, <a href="/format/2309.14307" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A post-selection algorithm for improving dynamic ensemble selection  methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cordeiro%2C+P+R+G">Paulo R.G. Cordeiro</a>, 
<a href="/search/cs?searchtype=author&query=Cavalcanti%2C+G+D+C">George D.C. Cavalcanti</a>, 
<a href="/search/cs?searchtype=author&query=Cruz%2C+R+M+O">Rafael M.O. Cruz</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Systems, Man, and
  Cybernetics (SMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Dynamic Ensemble Selection (DES) is a Multiple Classifier Systems (MCS)
approach that aims to select an ensemble for each query sample during the
selection phase. Even with the proposal of several DES approaches, no
particular DES technique is the best choice for different problems. Thus, we
hypothesize that selecting the best DES approach per query instance can lead to
better accuracy. To evaluate this idea, we introduce the Post-Selection Dynamic
Ensemble Selection (PS-DES) approach, a post-selection scheme that evaluates
ensembles selected by several DES techniques using different metrics.
Experimental results show that using accuracy as a metric to select the
ensembles, PS-DES performs better than individual DES techniques. PS-DES source
code is available in a GitHub repository
</p>
</div>
</dd>
<dt><a name="item572">[572]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14309" title="Abstract">arXiv:2309.14309</a> [<a href="/pdf/2309.14309" title="Download PDF">pdf</a>, <a href="/format/2309.14309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiple Different Explanations for Image Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chockler%2C+H">Hana Chockler</a>, 
<a href="/search/cs?searchtype=author&query=Kelly%2C+D+A">David A. Kelly</a>, 
<a href="/search/cs?searchtype=author&query=Kroening%2C+D">Daniel Kroening</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Existing explanation tools for image classifiers usually give only one single
explanation for an image. For many images, however, both humans and image
classifiers accept more than one explanation for the image label. Thus,
restricting the number of explanations to just one severely limits the insight
into the behavior of the classifier. In this paper, we describe an algorithm
and a tool, REX, for computing multiple explanations of the output of a
black-box image classifier for a given image. Our algorithm uses a principled
approach based on causal theory. We analyse its theoretical complexity and
provide experimental results showing that REX finds multiple explanations on 7
times more images than the previous work on the ImageNet-mini benchmark.
</p>
</div>
</dd>
<dt><a name="item573">[573]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14311" title="Abstract">arXiv:2309.14311</a> [<a href="/pdf/2309.14311" title="Download PDF">pdf</a>, <a href="/format/2309.14311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Parallelizing a 1-Dim Nagel-Schreckenberg Traffic Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Zon%2C+R">Ramses van Zon</a>, 
<a href="/search/cs?searchtype=author&query=Ponce%2C+M">Marcelo Ponce</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be presented at the "EduHPC-23: Workshop on Education for High-Performance Computing" to be held in conjunction with SC23. Starter code and handout can be found in the "complimentary" material section or the GitHub repository <a href="https://github.com/Practical-Scientific-and-HPC-Computing/Traffic_EduHPC-23">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Computers and Society (cs.CY); Numerical Analysis (math.NA)

</div>
<p class="mathjax">The Nagel-Schreckenberg model is a stochastic one-dimensional traffic model.
In this assignment, we guide students through the process of implementing a
shared-memory parallel and reproducible version of an existing serial code that
implements this model, and to analyze its scaling behavior. One of the key
elements in this traffic model is the presence of randomness, without which it
would lack realistic phenomena such as traffic jams. Its implementation thus
requires techniques associated with Monte Carlo simulations and pseudo-random
number generation (PRNG). PRNGs are notoriously tricky to deal with in parallel
when combined with the requirement of reproducibility.
<br />This assignment was created for the graduate course PHY1610 Scientific
Computing for Physicists at the University of Toronto, which had its origin in
the training program of the SciNet HPC Consortium, and is also very suitable
for other scientific disciplines. Several variations of the assignment have
been used over the years.
</p>
</div>
</dd>
<dt><a name="item574">[574]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14316" title="Abstract">arXiv:2309.14316</a> [<a href="/pdf/2309.14316" title="Download PDF">pdf</a>, <a href="/format/2309.14316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics of Language Models: Part 3.1, Knowledge Storage and Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z+A">Zeyuan Allen Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuanzhi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Large language models can store extensive world knowledge, often extractable
through question-answering (e.g., "What is Abraham Lincoln's birthday?").
However, it's unclear whether the model answers questions based on exposure to
exact/similar questions during training, or if it genuinely extracts knowledge
from the source (e.g., Wikipedia biographies).
<br />In this paper, we conduct an in-depth study of this problem using a
controlled set of semi-synthetic biography data. We uncover a relationship
between the model's knowledge extraction ability and different diversity
measures of the training data. We conduct (nearly) linear probing, revealing a
strong correlation between this relationship and whether the model (nearly)
linearly encodes the knowledge attributes at the hidden embedding of the entity
names, or across the embeddings of other tokens in the training text.
</p>
</div>
</dd>
<dt><a name="item575">[575]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14317" title="Abstract">arXiv:2309.14317</a> [<a href="/pdf/2309.14317" title="Download PDF">pdf</a>, <a href="/ps/2309.14317" title="Download PostScript">ps</a>, <a href="/format/2309.14317" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Online and Offline Dynamic Influence Maximization Games Over Social  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bastopcu%2C+M">Melih Bastopcu</a>, 
<a href="/search/cs?searchtype=author&query=Etesami%2C+S+R">S. Rasoul Etesami</a>, 
<a href="/search/cs?searchtype=author&query=Ba%C5%9Far%2C+T">Tamer Ba&#x15f;ar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Multiagent Systems (cs.MA); Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
<p class="mathjax">In this work, we consider dynamic influence maximization games over social
networks with multiple players (influencers). The goal of each influencer is to
maximize their own reward subject to their limited total budget rate
constraints. Thus, influencers need to carefully design their investment
policies considering individuals' opinion dynamics and other influencers'
investment strategies, leading to a dynamic game problem. We first consider the
case of a single influencer who wants to maximize its utility subject to a
total budget rate constraint. We study both offline and online versions of the
problem where the opinion dynamics are either known or not known a priori. In
the singe-influencer case, we propose an online no-regret algorithm, meaning
that as the number of campaign opportunities grows, the average utilities
obtained by the offline and online solutions converge. Then, we consider the
game formulation with multiple influencers in offline and online settings. For
the offline setting, we show that the dynamic game admits a unique Nash
equilibrium policy and provide a method to compute it. For the online setting
and with two influencers, we show that if each influencer applies the same
no-regret online algorithm proposed for the single-influencer maximization
problem, they will converge to the set of $\epsilon$-Nash equilibrium policies
where $\epsilon=O(\frac{1}{\sqrt{K}})$ scales in average inversely with the
number of campaign times $K$ considering the average utilities of the
influencers. Moreover, we extend this result to any finite number of
influencers under more strict requirements on the information structure.
Finally, we provide numerical analysis to validate our results under various
settings.
</p>
</div>
</dd>
<dt><a name="item576">[576]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14320" title="Abstract">arXiv:2309.14320</a> [<a href="/pdf/2309.14320" title="Download PDF">pdf</a>, <a href="/format/2309.14320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MUTEX: Learning Unified Policies from Multimodal Task Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+R">Rutav Shah</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADn-Mart%C3%ADn%2C+R">Roberto Mart&#xed;n-Mart&#xed;n</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yuke Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 7th Conference on Robot Learning (CoRL 2023), Atlanta, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Humans use different modalities, such as speech, text, images, videos, etc.,
to communicate their intent and goals with teammates. For robots to become
better assistants, we aim to endow them with the ability to follow instructions
and understand tasks specified by their human partners. Most robotic policy
learning methods have focused on one single modality of task specification
while ignoring the rich cross-modal information. We present MUTEX, a unified
approach to policy learning from multimodal task specifications. It trains a
transformer-based architecture to facilitate cross-modal reasoning, combining
masked modeling and cross-modal matching objectives in a two-stage training
procedure. After training, MUTEX can follow a task specification in any of the
six learned modalities (video demonstrations, goal images, text goal
descriptions, text instructions, speech goal descriptions, and speech
instructions) or a combination of them. We systematically evaluate the benefits
of MUTEX in a newly designed dataset with 100 tasks in simulation and 50 tasks
in the real world, annotated with multiple instances of task specifications in
different modalities, and observe improved performance over methods trained
specifically for any single modality. More information at
https://ut-austin-rpl.github.io/MUTEX/
</p>
</div>
</dd>
<dt><a name="item577">[577]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14321" title="Abstract">arXiv:2309.14321</a> [<a href="/pdf/2309.14321" title="Download PDF">pdf</a>, <a href="/format/2309.14321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Assisted Continual Robot Learning with Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parakh%2C+M">Meenal Parakh</a>, 
<a href="/search/cs?searchtype=author&query=Fong%2C+A">Alisha Fong</a>, 
<a href="/search/cs?searchtype=author&query=Simeonov%2C+A">Anthony Simeonov</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Large Language Models (LLMs) have been shown to act like planners that can
decompose high-level instructions into a sequence of executable instructions.
However, current LLM-based planners are only able to operate with a fixed set
of skills. We overcome this critical limitation and present a method for using
LLM-based planners to query new skills and teach robots these skills in a data
and time-efficient manner for rigid object manipulation. Our system can re-use
newly acquired skills for future tasks, demonstrating the potential of open
world and lifelong learning. We evaluate the proposed framework on multiple
tasks in simulation and the real world. Videos are available at:
https://sites.google.com/mit.edu/halp-robot-learning.
</p>
</div>
</dd>
<dt><a name="item578">[578]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14322" title="Abstract">arXiv:2309.14322</a> [<a href="/pdf/2309.14322" title="Download PDF">pdf</a>, <a href="/format/2309.14322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small-scale proxies for large-scale Transformer training instabilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+P+J">Peter J. Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Lechao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Everett%2C+K">Katie Everett</a>, 
<a href="/search/cs?searchtype=author&query=Alemi%2C+A">Alex Alemi</a>, 
<a href="/search/cs?searchtype=author&query=Adlam%2C+B">Ben Adlam</a>, 
<a href="/search/cs?searchtype=author&query=Co-Reyes%2C+J+D">John D. Co-Reyes</a>, 
<a href="/search/cs?searchtype=author&query=Gur%2C+I">Izzeddin Gur</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Novak%2C+R">Roman Novak</a>, 
<a href="/search/cs?searchtype=author&query=Pennington%2C+J">Jeffrey Pennington</a>, 
<a href="/search/cs?searchtype=author&query=Sohl-dickstein%2C+J">Jascha Sohl-dickstein</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kelvin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gilmer%2C+J">Justin Gilmer</a>, 
<a href="/search/cs?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Teams that have trained large Transformer-based models have reported training
instabilities at large scale that did not appear when training with the same
hyperparameters at smaller scales. Although the causes of such instabilities
are of scientific interest, the amount of resources required to reproduce them
has made investigation difficult. In this work, we seek ways to reproduce and
study training stability and instability at smaller scales. First, we focus on
two sources of training instability described in previous work: the growth of
logits in attention layers (Dehghani et al., 2023) and divergence of the output
logits from the log probabilities (Chowdhery et al., 2022). By measuring the
relationship between learning rate and loss across scales, we show that these
instabilities also appear in small models when training at high learning rates,
and that mitigations previously employed at large scales are equally effective
in this regime. This prompts us to investigate the extent to which other known
optimizer and model interventions influence the sensitivity of the final loss
to changes in the learning rate. To this end, we study methods such as warm-up,
weight decay, and the $\mu$Param (Yang et al., 2022), and combine techniques to
train small models that achieve similar losses across orders of magnitude of
learning rate variation. Finally, to conclude our exploration we study two
cases where instabilities can be predicted before they emerge by examining the
scaling behavior of model activation and gradient norms.
</p>
</div>
</dd>
<dt><a name="item579">[579]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14323" title="Abstract">arXiv:2309.14323</a> [<a href="/pdf/2309.14323" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cluster Language Model for Improved E-Commerce Retrieval and Ranking:  Leveraging Query Similarity and Fine-Tuning for Personalized Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Don%2C+D+R">Duleep Rathgamage Don</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Ying Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>, 
<a href="/search/cs?searchtype=author&query=Hughes%2C+S">Simon Hughes</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 6th Workshop on e-Commerce and NLP (ECNLP 6), KDD'23, Long Beach, CA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">This paper proposes a novel method to improve the accuracy of product search
in e-commerce by utilizing a cluster language model. The method aims to address
the limitations of the bi-encoder architecture while maintaining a minimal
additional training burden. The approach involves labeling top products for
each query, generating semantically similar query clusters using the K-Means
clustering algorithm, and fine-tuning a global language model into cluster
language models on individual clusters. The parameters of each cluster language
model are fine-tuned to learn local manifolds in the feature space efficiently,
capturing the nuances of various query types within each cluster. The inference
is performed by assigning a new query to its respective cluster and utilizing
the corresponding cluster language model for retrieval. The proposed method
results in more accurate and personalized retrieval results, offering a
superior alternative to the popular bi-encoder based retrieval models in
semantic search.
</p>
</div>
</dd>
<dt><a name="item580">[580]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14327" title="Abstract">arXiv:2309.14327</a> [<a href="/pdf/2309.14327" title="Download PDF">pdf</a>, <a href="/format/2309.14327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yao%2C+Z">Zhewei Yao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoxia Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Conglong Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Minjia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+H">Heyang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Ruwase%2C+O">Olatunji Ruwase</a>, 
<a href="/search/cs?searchtype=author&query=Awan%2C+A+A">Ammar Ahmad Awan</a>, 
<a href="/search/cs?searchtype=author&query=Rajbhandari%2C+S">Samyam Rajbhandari</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yuxiong He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">Most of the existing multi-modal models, hindered by their incapacity to
adeptly manage interleaved image-and-text inputs in multi-image, multi-round
dialogues, face substantial constraints in resource allocation for training and
data accessibility, impacting their adaptability and scalability across varied
interaction realms. To address this, we present the DeepSpeed-VisualChat
framework, designed to optimize Large Language Models (LLMs) by incorporating
multi-modal capabilities, with a focus on enhancing the proficiency of Large
Vision and Language Models in handling interleaved inputs. Our framework is
notable for (1) its open-source support for multi-round and multi-image
dialogues, (2) introducing an innovative multi-modal causal attention
mechanism, and (3) utilizing data blending techniques on existing datasets to
assure seamless interactions in multi-round, multi-image conversations.
Compared to existing frameworks, DeepSpeed-VisualChat shows superior
scalability up to 70B parameter language model size, representing a significant
advancement in multi-modal language models and setting a solid foundation for
future explorations.
</p>
</div>
</dd>
<dt><a name="item581">[581]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14328" title="Abstract">arXiv:2309.14328</a> [<a href="/pdf/2309.14328" title="Download PDF">pdf</a>, <a href="/format/2309.14328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pyParaOcean: A System for Visual Analysis of Ocean Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jain%2C+T">Toshit Jain</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+V">Varun Singh</a>, 
<a href="/search/cs?searchtype=author&query=Boda%2C+V+K">Vijay Kumar Boda</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Upkar Singh</a>, 
<a href="/search/cs?searchtype=author&query=Hotz%2C+I">Ingrid Hotz</a>, 
<a href="/search/cs?searchtype=author&query=Vinayachandran%2C+P+N">P. N. Vinayachandran</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+V">Vijay Natarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, EnvirVis2023
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> envirvis2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Visual analysis is well adopted within the field of oceanography for the
analysis of model simulations, detection of different phenomena and events, and
tracking of dynamic processes. With increasing data sizes and the availability
of multivariate dynamic data, there is a growing need for scalable and
extensible tools for visualization and interactive exploration. We describe
pyParaOcean, a visualization system that supports several tasks routinely used
in the visual analysis of ocean data. The system is available as a plugin to
Paraview and is hence able to leverage its distributed computing capabilities
and its rich set of generic analysis and visualization functionalities.
pyParaOcean provides modules to support different visual analysis tasks
specific to ocean data, such as eddy identification and salinity movement
tracking. These modules are available as Paraview filters and this seamless
integration results in a system that is easy to install and use. A case study
on the Bay of Bengal illustrates the utility of the system for the study of
ocean phenomena and processes.
</p>
</div>
</dd>
<dt><a name="item582">[582]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14329" title="Abstract">arXiv:2309.14329</a> [<a href="/pdf/2309.14329" title="Download PDF">pdf</a>, <a href="/format/2309.14329" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Innovative Digital Storytelling with AIGC: Exploration and Discussion of  Recent Advances
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gu%2C+R">Rongzhang Gu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hui Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+C">Changyue Su</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenyan Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Digital storytelling, as an art form, has struggled with cost-quality
balance. The emergence of AI-generated Content (AIGC) is considered as a
potential solution for efficient digital storytelling production. However, the
specific form, effects, and impacts of this fusion remain unclear, leaving the
boundaries of AIGC combined with storytelling undefined. This work explores the
current integration state of AIGC and digital storytelling, investigates the
artistic value of their fusion in a sample project, and addresses common issues
through interviews. Through our study, we conclude that AIGC, while proficient
in image creation, voiceover production, and music composition, falls short of
replacing humans due to the irreplaceable elements of human creativity and
aesthetic sensibilities at present, especially in complex character animations,
facial expressions, and sound effects. The research objective is to increase
public awareness of the current state, limitations, and challenges arising from
combining AIGC and digital storytelling.
</p>
</div>
</dd>
<dt><a name="item583">[583]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14330" title="Abstract">arXiv:2309.14330</a> [<a href="/pdf/2309.14330" title="Download PDF">pdf</a>, <a href="/format/2309.14330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Noise-in, Bias-out: Balanced and Real-time MoCap Solving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Albanis%2C+G">Georgios Albanis</a>, 
<a href="/search/cs?searchtype=author&query=Zioulis%2C+N">Nikolaos Zioulis</a>, 
<a href="/search/cs?searchtype=author&query=Thermos%2C+S">Spyridon Thermos</a>, 
<a href="/search/cs?searchtype=author&query=Chatzitofis%2C+A">Anargyros Chatzitofis</a>, 
<a href="/search/cs?searchtype=author&query=Kolomvatsos%2C+K">Kostas Kolomvatsos</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://moverseai.github.io/noise-tail">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Real-time optical Motion Capture (MoCap) systems have not benefited from the
advances in modern data-driven modeling. In this work we apply machine learning
to solve noisy unstructured marker estimates in real-time and deliver robust
marker-based MoCap even when using sparse affordable sensors. To achieve this
we focus on a number of challenges related to model training, namely the
sourcing of training data and their long-tailed distribution. Leveraging
representation learning we design a technique for imbalanced regression that
requires no additional data or labels and improves the performance of our model
in rare and challenging poses. By relying on a unified representation, we show
that training such a model is not bound to high-end MoCap training data
acquisition, and exploit the advances in marker-less MoCap to acquire the
necessary data. Finally, we take a step towards richer and affordable MoCap by
adapting a body model-based inverse kinematics solution to account for
measurement and inference uncertainty, further improving performance and
robustness. Project page: https://moverseai.github.io/noise-tail
</p>
</div>
</dd>
<dt><a name="item584">[584]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14331" title="Abstract">arXiv:2309.14331</a> [<a href="/pdf/2309.14331" title="Download PDF">pdf</a>, <a href="/format/2309.14331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinGCN: Structural Linearized Graph Convolutional Network for  Homomorphically Encrypted Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Hongwu Peng</a>, 
<a href="/search/cs?searchtype=author&query=Ran%2C+R">Ran Ran</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yukui Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jiahui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoyi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Thorat%2C+K">Kiran Thorat</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+T">Tong Geng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenghong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiaolin Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wen%2C+W">Wujie Wen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+C">Caiwen Ding</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 accepted publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">The growth of Graph Convolution Network (GCN) model sizes has revolutionized
numerous applications, surpassing human performance in areas such as personal
healthcare and financial systems. The deployment of GCNs in the cloud raises
privacy concerns due to potential adversarial attacks on client data. To
address security concerns, Privacy-Preserving Machine Learning (PPML) using
Homomorphic Encryption (HE) secures sensitive client data. However, it
introduces substantial computational overhead in practical applications. To
tackle those challenges, we present LinGCN, a framework designed to reduce
multiplication depth and optimize the performance of HE based GCN inference.
LinGCN is structured around three key elements: (1) A differentiable structural
linearization algorithm, complemented by a parameterized discrete indicator
function, co-trained with model weights to meet the optimization goal. This
strategy promotes fine-grained node-level non-linear location selection,
resulting in a model with minimized multiplication depth. (2) A compact
node-wise polynomial replacement policy with a second-order trainable
activation function, steered towards superior convergence by a two-level
distillation approach from an all-ReLU based teacher model. (3) an enhanced HE
solution that enables finer-grained operator fusion for node-wise activation
functions, further reducing multiplication level consumption in HE-based
inference. Our experiments on the NTU-XVIEW skeleton joint dataset reveal that
LinGCN excels in latency, accuracy, and scalability for homomorphically
encrypted inference, outperforming solutions such as CryptoGCN. Remarkably,
LinGCN achieves a 14.2x latency speedup relative to CryptoGCN, while preserving
an inference accuracy of 75% and notably reducing multiplication depth.
</p>
</div>
</dd>
<dt><a name="item585">[585]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14334" title="Abstract">arXiv:2309.14334</a> [<a href="/pdf/2309.14334" title="Download PDF">pdf</a>, <a href="/format/2309.14334" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tasks Makyth Models: Machine Learning Assisted Surrogates for Tipping  Points
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fabiani%2C+G">Gianluca Fabiani</a>, 
<a href="/search/cs?searchtype=author&query=Evangelou%2C+N">Nikolaos Evangelou</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+T">Tianqi Cui</a>, 
<a href="/search/cs?searchtype=author&query=Bello-Rivas%2C+J+M">Juan M. Bello-Rivas</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Linares%2C+C+P">Cristina P. Martin-Linares</a>, 
<a href="/search/cs?searchtype=author&query=Siettos%2C+C">Constantinos Siettos</a>, 
<a href="/search/cs?searchtype=author&query=Kevrekidis%2C+I+G">Ioannis G. Kevrekidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 8 figures, 6 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA); Trading and Market Microstructure (q-fin.TR)

</div>
<p class="mathjax">We present a machine learning (ML)-assisted framework bridging manifold
learning, neural networks, Gaussian processes, and Equation-Free multiscale
modeling, for (a) detecting tipping points in the emergent behavior of complex
systems, and (b) characterizing probabilities of rare events (here,
catastrophic shifts) near them. Our illustrative example is an event-driven,
stochastic agent-based model (ABM) describing the mimetic behavior of traders
in a simple financial market. Given high-dimensional spatiotemporal data --
generated by the stochastic ABM -- we construct reduced-order models for the
emergent dynamics at different scales: (a) mesoscopic Integro-Partial
Differential Equations (IPDEs); and (b) mean-field-type Stochastic Differential
Equations (SDEs) embedded in a low-dimensional latent space, targeted to the
neighborhood of the tipping point. We contrast the uses of the different models
and the effort involved in learning them.
</p>
</div>
</dd>
<dt><a name="item586">[586]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14335" title="Abstract">arXiv:2309.14335</a> [<a href="/pdf/2309.14335" title="Download PDF">pdf</a>, <a href="/format/2309.14335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fu%2C+J">Jianglin Fu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuming Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kwan-Yee Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023. Project page: <a href="https://unitedhuman.github.io/">this https URL</a> Github: <a href="https://github.com/UnitedHuman/UnitedHuman">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Human generation has achieved significant progress. Nonetheless, existing
methods still struggle to synthesize specific regions such as faces and hands.
We argue that the main reason is rooted in the training data. A holistic human
dataset inevitably has insufficient and low-resolution information on local
parts. Therefore, we propose to use multi-source datasets with various
resolution images to jointly learn a high-resolution human generative model.
However, multi-source data inherently a) contains different parts that do not
spatially align into a coherent human, and b) comes with different scales. To
tackle these challenges, we propose an end-to-end framework, UnitedHuman, that
empowers continuous GAN with the ability to effectively utilize multi-source
data for high-resolution human generation. Specifically, 1) we design a
Multi-Source Spatial Transformer that spatially aligns multi-source images to
full-body space with a human parametric model. 2) Next, a continuous GAN is
proposed with global-structural guidance and CutMix consistency. Patches from
different datasets are then sampled and transformed to supervise the training
of this scale-invariant generative model. Extensive experiments demonstrate
that our model jointly learned from multi-source data achieves superior quality
than those learned from a holistic dataset.
</p>
</div>
</dd>
<dt><a name="item587">[587]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14338" title="Abstract">arXiv:2309.14338</a> [<a href="/pdf/2309.14338" title="Download PDF">pdf</a>, <a href="/format/2309.14338" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Indoor Instance Segmentation in an Open-World
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boudjoghra%2C+M+E+A">Mohamed El Amine Boudjoghra</a>, 
<a href="/search/cs?searchtype=author&query=Khatib%2C+S+K+A">Salwa K. Al Khatib</a>, 
<a href="/search/cs?searchtype=author&query=Lahoud%2C+J">Jean Lahoud</a>, 
<a href="/search/cs?searchtype=author&query=Cholakkal%2C+H">Hisham Cholakkal</a>, 
<a href="/search/cs?searchtype=author&query=Anwer%2C+R+M">Rao Muhammad Anwer</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+S">Salman Khan</a>, 
<a href="/search/cs?searchtype=author&query=Khan%2C+F">Fahad Khan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing 3D instance segmentation methods typically assume that all semantic
classes to be segmented would be available during training and only seen
categories are segmented at inference. We argue that such a closed-world
assumption is restrictive and explore for the first time 3D indoor instance
segmentation in an open-world setting, where the model is allowed to
distinguish a set of known classes as well as identify an unknown object as
unknown and then later incrementally learning the semantic category of the
unknown when the corresponding category labels are available. To this end, we
introduce an open-world 3D indoor instance segmentation method, where an
auto-labeling scheme is employed to produce pseudo-labels during training and
induce separation to separate known and unknown category labels. We further
improve the pseudo-labels quality at inference by adjusting the unknown class
probability based on the objectness score distribution. We also introduce
carefully curated open-world splits leveraging realistic scenarios based on
inherent object distribution, region-based indoor scene exploration and
randomness aspect of open-world classes. Extensive experiments reveal the
efficacy of the proposed contributions leading to promising open-world 3D
instance segmentation performance.
</p>
</div>
</dd>
<dt><a name="item588">[588]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14339" title="Abstract">arXiv:2309.14339</a> [<a href="/pdf/2309.14339" title="Download PDF">pdf</a>, <a href="/format/2309.14339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chop &amp; Learn: Recognizing and Generating Object-State Compositions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saini%2C+N">Nirat Saini</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Swaminathan%2C+A">Archana Swaminathan</a>, 
<a href="/search/cs?searchtype=author&query=Jayasundara%2C+V">Vinoj Jayasundara</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+B">Bo He</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+K">Kamal Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Shrivastava%2C+A">Abhinav Shrivastava</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recognizing and generating object-state compositions has been a challenging
task, especially when generalizing to unseen compositions. In this paper, we
study the task of cutting objects in different styles and the resulting object
state changes. We propose a new benchmark suite Chop &amp; Learn, to accommodate
the needs of learning objects and different cut styles using multiple
viewpoints. We also propose a new task of Compositional Image Generation, which
can transfer learned cut styles to different objects, by generating novel
object-state images. Moreover, we also use the videos for Compositional Action
Recognition, and show valuable uses of this dataset for multiple video tasks.
Project website: https://chopnlearn.github.io.
</p>
</div>
</dd>
<dt><a name="item589">[589]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14341" title="Abstract">arXiv:2309.14341</a> [<a href="/pdf/2309.14341" title="Download PDF">pdf</a>, <a href="/format/2309.14341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme Parkour with Legged Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xuxin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+K">Kexin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Agarwal%2C+A">Ananye Agarwal</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website and videos at <a href="https://extreme-parkour.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
<p class="mathjax">Humans can perform parkour by traversing obstacles in a highly dynamic
fashion requiring precise eye-muscle coordination and movement. Getting robots
to do the same task requires overcoming similar challenges. Classically, this
is done by independently engineering perception, actuation, and control systems
to very low tolerances. This restricts them to tightly controlled settings such
as a predetermined obstacle course in labs. In contrast, humans are able to
learn parkour through practice without significantly changing their underlying
biology. In this paper, we take a similar approach to developing robot parkour
on a small low-cost robot with imprecise actuation and a single front-facing
depth camera for perception which is low-frequency, jittery, and prone to
artifacts. We show how a single neural net policy operating directly from a
camera image, trained in simulation with large-scale RL, can overcome imprecise
sensing and actuation to output highly precise control behavior end-to-end. We
show our robot can perform a high jump on obstacles 2x its height, long jump
across gaps 2x its length, do a handstand and run across tilted ramps, and
generalize to novel obstacle courses with different physical properties.
Parkour videos at https://extreme-parkour.github.io/
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Tue, 26 Sep 23</h3>
<dl>
<dt><a name="item590">[590]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14512" title="Abstract">arXiv:2308.14512</a> (cross-list from eess.SP) [<a href="/pdf/2308.14512" title="Download PDF">pdf</a>, <a href="/format/2308.14512" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A time-causal and time-recursive analogue of the Gabor transform
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lindeberg%2C+T">Tony Lindeberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Sound (cs.SD); Functional Analysis (math.FA)

</div>
<p class="mathjax">This paper presents a time-causal analogue of the Gabor filter, as well as a
both time-causal and time-recursive analogue of the Gabor transform, where the
proposed time-causal representations obey both temporal scale covariance and a
cascade property with a simplifying kernel over temporal scales. The motivation
behind these constructions is to enable theoretically well-founded
time-frequency analysis over multiple temporal scales for real-time situations,
or for physical or biological modelling situations, when the future cannot be
accessed, and the non-causal access to future in Gabor filtering is therefore
not viable for a time-frequency analysis of the system.
<br />We develop the theory for these representations, obtained by replacing the
Gaussian kernel in Gabor filtering with a time-causal kernel, referred to as
the time-causal limit kernel, which guarantees simplification properties from
finer to coarser levels of scales in a time-causal situation, similar as the
Gaussian kernel can be shown to guarantee over a non-causal temporal domain. In
these ways, the proposed time-frequency representations guarantee well-founded
treatment over multiple scales, in situations when the characteristic scales in
the signals, or physical or biological phenomena, to be analyzed may vary
substantially, and additionally all steps in the time-frequency analysis have
to be fully time-causal.
</p>
</div>
</dd>
<dt><a name="item591">[591]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13047" title="Abstract">arXiv:2309.13047</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.13047" title="Download PDF">pdf</a>, <a href="/format/2309.13047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NeuroCADR: Drug Repurposing to Reveal Novel Anti-Epileptic Drug  Candidates Through an Integrated Computational Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Mamidala%2C+S">Srilekha Mamidala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Drug repurposing is an emerging approach for drug discovery involving the
reassignment of existing drugs for novel purposes. An alternative to the
traditional de novo process of drug development, repurposed drugs are faster,
cheaper, and less failure prone than drugs developed from traditional methods.
Recently, drug repurposing has been performed in silico, in which databases of
drugs and chemical information are used to determine interactions between
target proteins and drug molecules to identify potential drug candidates. A
proposed algorithm is NeuroCADR, a novel system for drug repurposing via a
multi-pronged approach consisting of k-nearest neighbor algorithms (KNN),
random forest classification, and decision trees. Data was sourced from several
databases consisting of interactions between diseases, symptoms, genes, and
affiliated drug molecules, which were then compiled into datasets expressed in
binary. The proposed method displayed a high level of accuracy, outperforming
nearly all in silico approaches. NeuroCADR was performed on epilepsy, a
condition characterized by seizures, periods of time with bursts of
uncontrolled electrical activity in brain cells. Existing drugs for epilepsy
can be ineffective and expensive, revealing a need for new antiepileptic drugs.
NeuroCADR identified novel drug candidates for epilepsy that can be further
approved through clinical trials. The algorithm has the potential to determine
possible drug combinations to prescribe a patient based on a patient's prior
medical history. This project examines NeuroCADR, a novel approach to
computational drug repurposing capable of revealing potential drug candidates
in neurological diseases such as epilepsy.
</p>
</div>
</dd>
<dt><a name="item592">[592]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13064" title="Abstract">arXiv:2309.13064</a> (cross-list from q-fin.GN) [<a href="/pdf/2309.13064" title="Download PDF">pdf</a>, <a href="/format/2309.13064" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> InvestLM: A Large Language Model for Investment using Financial Domain  Instruction Tuning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Yang%2C+Y">Yi Yang</a>, 
<a href="/search/q-fin?searchtype=author&query=Tang%2C+Y">Yixuan Tang</a>, 
<a href="/search/q-fin?searchtype=author&query=Tam%2C+K+Y">Kar Yan Tam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Link: <a href="https://github.com/AbaciNLP/InvestLM">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">We present a new financial domain large language model, InvestLM, tuned on
LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset
related to financial investment. Inspired by less-is-more-for-alignment (Zhou
et al., 2023), we manually curate a small yet diverse instruction dataset,
covering a wide range of financial related topics, from Chartered Financial
Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative
finance discussions. InvestLM shows strong capabilities in understanding
financial text and provides helpful responses to investment related questions.
Financial experts, including hedge fund managers and research analysts, rate
InvestLM's response as comparable to those of state-of-the-art commercial
models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of
financial NLP benchmarks demonstrates strong generalizability. From a research
perspective, this work suggests that a high-quality domain specific LLM can be
tuned using a small set of carefully curated instructions on a well-trained
foundation model, which is consistent with the Superficial Alignment Hypothesis
(Zhou et al., 2023). From a practical perspective, this work develops a
state-of-the-art financial domain LLM with superior capability in understanding
financial texts and providing helpful investment advice, potentially enhancing
the work efficiency of financial professionals. We release the model parameters
to the research community.
</p>
</div>
</dd>
<dt><a name="item593">[593]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13102" title="Abstract">arXiv:2309.13102</a> (cross-list from eess.AS) [<a href="/pdf/2309.13102" title="Download PDF">pdf</a>, <a href="/format/2309.13102" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Importance of Smoothness Induced by Optimizers in FL4ASR: Towards  Understanding Federated Learning for End-to-End ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Azam%2C+S+S">Sheikh Shams Azam</a>, 
<a href="/search/eess?searchtype=author&query=Likhomanenko%2C+T">Tatiana Likhomanenko</a>, 
<a href="/search/eess?searchtype=author&query=Pelikan%2C+M">Martin Pelikan</a>, 
<a href="/search/eess?searchtype=author&query=Silovsky%2C+J+%22">Jan &quot;Honza&quot; Silovsky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we start by training End-to-End Automatic Speech Recognition
(ASR) models using Federated Learning (FL) and examining the fundamental
considerations that can be pivotal in minimizing the performance gap in terms
of word error rate between models trained using FL versus their centralized
counterpart. Specifically, we study the effect of (i) adaptive optimizers, (ii)
loss characteristics via altering Connectionist Temporal Classification (CTC)
weight, (iii) model initialization through seed start, (iv) carrying over
modeling setup from experiences in centralized training to FL, e.g., pre-layer
or post-layer normalization, and (v) FL-specific hyperparameters, such as
number of local epochs, client sampling size, and learning rate scheduler,
specifically for ASR under heterogeneous data distribution. We shed light on
how some optimizers work better than others via inducing smoothness. We also
summarize the applicability of algorithms, trends, and propose best practices
from prior works in FL (in general) toward End-to-End ASR models.
</p>
</div>
</dd>
<dt><a name="item594">[594]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13108" title="Abstract">arXiv:2309.13108</a> (cross-list from quant-ph) [<a href="/pdf/2309.13108" title="Download PDF">pdf</a>, <a href="/format/2309.13108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data is often loadable in short depth: Quantum circuits from tensor  networks for finance, images, fluids, and proteins
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Jumade%2C+R">Raghav Jumade</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sawaya%2C+N+P">Nicolas PD Sawaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)

</div>
<p class="mathjax">Though there has been substantial progress in developing quantum algorithms
to study classical datasets, the cost of simply loading classical data is an
obstacle to quantum advantage. When the amplitude encoding is used, loading an
arbitrary classical vector requires up to exponential circuit depths with
respect to the number of qubits. Here, we address this ``input problem'' with
two contributions. First, we introduce a circuit compilation method based on
tensor network (TN) theory. Our method -- AMLET (Automatic Multi-layer Loader
Exploiting TNs) -- proceeds via careful construction of a specific TN topology
and can be tailored to arbitrary circuit depths. Second, we perform numerical
experiments on real-world classical data from four distinct areas: finance,
images, fluid mechanics, and proteins. To the best of our knowledge, this is
the broadest numerical analysis to date of loading classical data into a
quantum computer. Consistent with other recent work in this area, the required
circuit depths are often several orders of magnitude lower than the
exponentially-scaling general loading algorithm would require. Besides
introducing a more efficient loading algorithm, this work demonstrates that
many classical datasets are loadable in depths that are much shorter than
previously expected, which has positive implications for speeding up classical
workloads on quantum computers.
</p>
</div>
</dd>
<dt><a name="item595">[595]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13129" title="Abstract">arXiv:2309.13129</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.13129" title="Download PDF">pdf</a>, <a href="/format/2309.13129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AntiBARTy Diffusion for Property Guided Antibody Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Venderley%2C+J">Jordan Venderley</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Over the past decade, antibodies have steadily grown in therapeutic
importance thanks to their high specificity and low risk of adverse effects
compared to other drug modalities. While traditional antibody discovery is
primarily wet lab driven, the rapid improvement of ML-based generative modeling
has made in-silico approaches an increasingly viable route for discovery and
engineering. To this end, we train an antibody-specific language model,
AntiBARTy, based on BART (Bidirectional and Auto-Regressive Transformer) and
use its latent space to train a property-conditional diffusion model for guided
IgG de novo design. As a test case, we show that we can effectively generate
novel antibodies with improved in-silico solubility while maintaining antibody
validity and controlling sequence diversity.
</p>
</div>
</dd>
<dt><a name="item596">[596]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13133" title="Abstract">arXiv:2309.13133</a> (cross-list from math.PR) [<a href="/pdf/2309.13133" title="Download PDF">pdf</a>, <a href="/ps/2309.13133" title="Download PostScript">ps</a>, <a href="/format/2309.13133" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-One Laws for Random Feasibility Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Altschuler%2C+D+J">Dylan J. Altschuler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Discrete Mathematics (cs.DM); Combinatorics (math.CO)

</div>
<p class="mathjax">We introduce a general random model of a combinatorial optimization problem
with geometric structure that encapsulates both linear programming and integer
linear programming. Let $Q$ be a bounded set called the feasible set, $E$ be an
arbitrary set called the constraint set, and $A$ be a random linear transform.
We introduce and study the $\ell^q$-\textit{margin},$M_q := d_q(AQ, E)$. The
margin quantifies the feasibility of finding $y \in AQ$ satisfying the
constraint $y \in E$. Our contribution is to establish strong concentration of
the margin for any $q \in (2,\infty]$, assuming only that $E$ has permutation
symmetry. The case of $q = \infty$ is of particular interest in applications --
specifically to combinatorial ``balancing'' problems -- and is markedly out of
the reach of the classical isoperimetric and concentration-of-measure tools
that suffice for $q \le 2$.
<br />Generality is a key feature of this result: we assume permutation symmetry of
the constraint set and nothing else. This allows us to encode many optimization
problems in terms of the margin, including random versions of: the closest
vector problem, integer linear feasibility, perceptron-type problems,
$\ell^q$-combinatorial discrepancy for $2 \le q \le \infty$, and matrix
balancing. Concentration of the margin implies a host of new sharp threshold
results in these models, and also greatly simplifies and extends some key known
results.
</p>
</div>
</dd>
<dt><a name="item597">[597]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13143" title="Abstract">arXiv:2309.13143</a> (cross-list from quant-ph) [<a href="/pdf/2309.13143" title="Download PDF">pdf</a>, <a href="/format/2309.13143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ERASER: Towards Adaptive Leakage Suppression for Fault-Tolerant Quantum  Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Vittal%2C+S">Suhas Vittal</a> (1), 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+P">Poulami Das</a> (2), 
<a href="/search/quant-ph?searchtype=author&query=Qureshi%2C+M">Moinuddin Qureshi</a> (1) ((1) Georgia Institute of Technology, (2) The University of Texas at Austin)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear in the International Symposium on Microarchitecture (MICRO) 2023 in October
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Hardware Architecture (cs.AR)

</div>
<p class="mathjax">Quantum error correction (QEC) codes can tolerate hardware errors by encoding
fault-tolerant logical qubits using redundant physical qubits and detecting
errors using parity checks. Leakage errors occur in quantum systems when a
qubit leaves its computational basis and enters higher energy states. These
errors severely limit the performance of QEC due to two reasons. First, they
lead to erroneous parity checks that obfuscate the accurate detection of
errors. Second, the leakage spreads to other qubits and creates a pathway for
more errors over time. Prior works tolerate leakage errors by using leakage
reduction circuits (LRCs) that modify the parity check circuitry of QEC codes.
Unfortunately, naively using LRCs always throughout a program is sub-optimal
because LRCs incur additional two-qubit operations that (1) facilitate leakage
transport, and (2) serve as new sources of errors. Ideally, LRCs should only be
used if leakage occurs, so that errors from both leakage as well as additional
LRC operations are simultaneously minimized. However, identifying leakage
errors in real-time is challenging. To enable the robust and efficient usage of
LRCs, we propose ERASER that speculates the subset of qubits that may have
leaked and only uses LRCs for those qubits. Our studies show that the majority
of leakage errors typically impact the parity checks. We leverage this insight
to identify the leaked qubits by analyzing the patterns in the failed parity
checks. We propose ERASER+M that enhances ERASER by detecting leakage more
accurately using qubit measurement protocols that can classify qubits into
$|0\rangle, |1\rangle$ and $|L\rangle$ states. ERASER and ERASER+M improve the
logical error rate by up to $4.3\times$ and $23\times$ respectively compared to
always using LRC.
</p>
</div>
</dd>
<dt><a name="item598">[598]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13186" title="Abstract">arXiv:2309.13186</a> (cross-list from physics.optics) [<a href="/pdf/2309.13186" title="Download PDF">pdf</a>, <a href="/format/2309.13186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning with Photonic Neural Cellular Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Li%2C+G+H+Y">Gordon H.Y. Li</a>, 
<a href="/search/physics?searchtype=author&query=Leefmans%2C+C+R">Christian R. Leefmans</a>, 
<a href="/search/physics?searchtype=author&query=Williams%2C+J">James Williams</a>, 
<a href="/search/physics?searchtype=author&query=Gray%2C+R+M">Robert M. Gray</a>, 
<a href="/search/physics?searchtype=author&query=Parto%2C+M">Midya Parto</a>, 
<a href="/search/physics?searchtype=author&query=Marandi%2C+A">Alireza Marandi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optics (physics.optics)</span>; Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Rapid advancements in deep learning over the past decade have fueled an
insatiable demand for efficient and scalable hardware. Photonics offers a
promising solution by leveraging the unique properties of light. However,
conventional neural network architectures, which typically require dense
programmable connections, pose several practical challenges for photonic
realizations. To overcome these limitations, we propose and experimentally
demonstrate Photonic Neural Cellular Automata (PNCA) for photonic deep learning
with sparse connectivity. PNCA harnesses the speed and interconnectivity of
photonics, as well as the self-organizing nature of cellular automata through
local interactions to achieve robust, reliable, and efficient processing. We
utilize linear light interference and parametric nonlinear optics for
all-optical computations in a time-multiplexed photonic network to
experimentally perform self-organized image classification. We demonstrate
binary classification of images in the fashion-MNIST dataset using as few as 3
programmable photonic parameters, achieving an experimental accuracy of 98.0%
with the ability to also recognize out-of-distribution data. The proposed PNCA
approach can be adapted to a wide range of existing photonic hardware and
provides a compelling alternative to conventional photonic neural networks by
maximizing the advantages of light-based computing whilst mitigating their
practical challenges. Our results showcase the potential of PNCA in advancing
photonic deep learning and highlights a path for next-generation photonic
computers.
</p>
</div>
</dd>
<dt><a name="item599">[599]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13213" title="Abstract">arXiv:2309.13213</a> (cross-list from hep-ex) [<a href="/pdf/2309.13213" title="Download PDF">pdf</a>, <a href="/format/2309.13213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The LHCb ultra-fast simulation option, Lamarr: design and validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Anderlini%2C+L">Lucio Anderlini</a>, 
<a href="/search/hep-ex?searchtype=author&query=Barbetti%2C+M">Matteo Barbetti</a>, 
<a href="/search/hep-ex?searchtype=author&query=Capelli%2C+S">Simone Capelli</a>, 
<a href="/search/hep-ex?searchtype=author&query=Corti%2C+G">Gloria Corti</a>, 
<a href="/search/hep-ex?searchtype=author&query=Davis%2C+A">Adam Davis</a>, 
<a href="/search/hep-ex?searchtype=author&query=Derkach%2C+D">Denis Derkach</a>, 
<a href="/search/hep-ex?searchtype=author&query=Kazeev%2C+N">Nikita Kazeev</a>, 
<a href="/search/hep-ex?searchtype=author&query=Maevskiy%2C+A">Artem Maevskiy</a>, 
<a href="/search/hep-ex?searchtype=author&query=Martinelli%2C+M">Maurizio Martinelli</a>, 
<a href="/search/hep-ex?searchtype=author&query=Mokonenko%2C+S">Sergei Mokonenko</a>, 
<a href="/search/hep-ex?searchtype=author&query=Siddi%2C+B+G">Benedetto Gianluca Siddi</a>, 
<a href="/search/hep-ex?searchtype=author&query=Xu%2C+Z">Zehua Xu</a> (for the LHCb Simulation Project)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in EPJ Web of Conferences (CHEP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
<p class="mathjax">Detailed detector simulation is the major consumer of CPU resources at LHCb,
having used more than 90% of the total computing budget during Run 2 of the
Large Hadron Collider at CERN. As data is collected by the upgraded LHCb
detector during Run 3 of the LHC, larger requests for simulated data samples
are necessary, and will far exceed the pledged resources of the experiment,
even with existing fast simulation options. An evolution of technologies and
techniques to produce simulated samples is mandatory to meet the upcoming needs
of analysis to interpret signal versus background and measure efficiencies. In
this context, we propose Lamarr, a Gaudi-based framework designed to offer the
fastest solution for the simulation of the LHCb detector. Lamarr consists of a
pipeline of modules parameterizing both the detector response and the
reconstruction algorithms of the LHCb experiment. Most of the parameterizations
are made of Deep Generative Models and Gradient Boosted Decision Trees trained
on simulated samples or alternatively, where possible, on real data. Embedding
Lamarr in the general LHCb Gauss Simulation framework allows combining its
execution with any of the available generators in a seamless way. Lamarr has
been validated by comparing key reconstructed quantities with Detailed
Simulation. Good agreement of the simulated distributions is obtained with
two-order-of-magnitude speed-up of the simulation phase.
</p>
</div>
</dd>
<dt><a name="item600">[600]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13253" title="Abstract">arXiv:2309.13253</a> (cross-list from eess.AS) [<a href="/pdf/2309.13253" title="Download PDF">pdf</a>, <a href="/format/2309.13253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Contrastive Speaker Embedding With Sequential Disentanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Tu%2C+Y">Youzhi Tu</a>, 
<a href="/search/eess?searchtype=author&query=Mak%2C+M">Man-Wai Mak</a>, 
<a href="/search/eess?searchtype=author&query=Chien%2C+J">Jen-Tzung Chien</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Contrastive speaker embedding assumes that the contrast between the positive
and negative pairs of speech segments is attributed to speaker identity only.
However, this assumption is incorrect because speech signals contain not only
speaker identity but also linguistic content. In this paper, we propose a
contrastive learning framework with sequential disentanglement to remove
linguistic content by incorporating a disentangled sequential variational
autoencoder (DSVAE) into the conventional SimCLR framework. The DSVAE aims to
disentangle speaker factors from content factors in an embedding space so that
only the speaker factors are used for constructing a contrastive loss
objective. Because content factors have been removed from the contrastive
learning, the resulting speaker embeddings will be content-invariant.
Experimental results on VoxCeleb1-test show that the proposed method
consistently outperforms SimCLR. This suggests that applying sequential
disentanglement is beneficial to learning speaker-discriminative embeddings.
</p>
</div>
</dd>
<dt><a name="item601">[601]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13278" title="Abstract">arXiv:2309.13278</a> (cross-list from stat.ML) [<a href="/pdf/2309.13278" title="Download PDF">pdf</a>, <a href="/format/2309.13278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Shift-Aware Off-Policy Interval Estimation: A Unified  Error Quantification Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+W">Wenzhuo Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yuhan Li</a>, 
<a href="/search/stat?searchtype=author&query=Zhu%2C+R">Ruoqing Zhu</a>, 
<a href="/search/stat?searchtype=author&query=Qu%2C+A">Annie Qu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We study high-confidence off-policy evaluation in the context of
infinite-horizon Markov decision processes, where the objective is to establish
a confidence interval (CI) for the target policy value using only offline data
pre-collected from unknown behavior policies. This task faces two primary
challenges: providing a comprehensive and rigorous error quantification in CI
estimation, and addressing the distributional shift that results from
discrepancies between the distribution induced by the target policy and the
offline data-generating process. Motivated by an innovative unified error
analysis, we jointly quantify the two sources of estimation errors: the
misspecification error on modeling marginalized importance weights and the
statistical uncertainty due to sampling, within a single interval. This unified
framework reveals a previously hidden tradeoff between the errors, which
undermines the tightness of the CI. Relying on a carefully designed
discriminator function, the proposed estimator achieves a dual purpose:
breaking the curse of the tradeoff to attain the tightest possible CI, and
adapting the CI to ensure robustness against distributional shifts. Our method
is applicable to time-dependent data without assuming any weak dependence
conditions via leveraging a local supermartingale/martingale structure.
Theoretically, we show that our algorithm is sample-efficient, error-robust,
and provably convergent even in non-linear function approximation settings. The
numerical performance of the proposed method is examined in synthetic datasets
and an OhioT1DM mobile health study.
</p>
</div>
</dd>
<dt><a name="item602">[602]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13348" title="Abstract">arXiv:2309.13348</a> (cross-list from physics.geo-ph) [<a href="/pdf/2309.13348" title="Download PDF">pdf</a>, <a href="/format/2309.13348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Accelerating Particle and Fluid Simulations with Differentiable Graph  Networks for Solving Forward and Inverse Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Kumar%2C+K">Krishna Kumar</a>, 
<a href="/search/physics?searchtype=author&query=Choi%2C+Y">Yongjin Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, The 4th workshop on Artificial Intelligence and Machine Learning for Scientific Applications, Super Computing '23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">We leverage physics-embedded differentiable graph network simulators (GNS) to
accelerate particulate and fluid simulations to solve forward and inverse
problems. GNS represents the domain as a graph with particles as nodes and
learned interactions as edges. Compared to modeling global dynamics, GNS
enables learning local interaction laws through edge messages, improving its
generalization to new environments. GNS achieves over 165x speedup for granular
flow prediction compared to parallel CPU numerical simulations. We propose a
novel hybrid GNS/Material Point Method (MPM) to accelerate forward simulations
by minimizing error on a pure surrogate model by interleaving MPM in GNS
rollouts to satisfy conservation laws and minimize errors achieving 24x speedup
compared to pure numerical simulations. The differentiable GNS enables solving
inverse problems through automatic differentiation, identifying material
parameters that result in target runout distances. We demonstrate the ability
of GNS to solve inverse problems by iteratively updating the friction angle (a
material property) by computing the gradient of a loss function based on the
final and target runouts, thereby identifying the friction angle that best
matches the observed runout. The physics-embedded and differentiable simulators
open an exciting new paradigm for AI-accelerated design, control, and
optimization.
</p>
</div>
</dd>
<dt><a name="item603">[603]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13385" title="Abstract">arXiv:2309.13385</a> (cross-list from eess.IV) [<a href="/pdf/2309.13385" title="Download PDF">pdf</a>, <a href="/format/2309.13385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cine cardiac MRI reconstruction using a convolutional recurrent network  with refinement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xue%2C+Y">Yuyang Xue</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+Y">Yuning Du</a>, 
<a href="/search/eess?searchtype=author&query=Carloni%2C+G">Gianluca Carloni</a>, 
<a href="/search/eess?searchtype=author&query=Pachetti%2C+E">Eva Pachetti</a>, 
<a href="/search/eess?searchtype=author&query=Jordan%2C+C">Connor Jordan</a>, 
<a href="/search/eess?searchtype=author&query=Tsaftaris%2C+S+A">Sotirios A. Tsaftaris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> MICCAI STACOM workshop 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Cine Magnetic Resonance Imaging (MRI) allows for understanding of the heart's
function and condition in a non-invasive manner. Undersampling of the $k$-space
is employed to reduce the scan duration, thus increasing patient comfort and
reducing the risk of motion artefacts, at the cost of reduced image quality. In
this challenge paper, we investigate the use of a convolutional recurrent
neural network (CRNN) architecture to exploit temporal correlations in
supervised cine cardiac MRI reconstruction. This is combined with a
single-image super-resolution refinement module to improve single coil
reconstruction by 4.4\% in structural similarity and 3.9\% in normalised mean
square error compared to a plain CRNN implementation. We deploy a high-pass
filter to our $\ell_1$ loss to allow greater emphasis on high-frequency details
which are missing in the original data. The proposed model demonstrates
considerable enhancements compared to the baseline case and holds promising
potential for further improving cardiac MRI reconstruction.
</p>
</div>
</dd>
<dt><a name="item604">[604]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13398" title="Abstract">arXiv:2309.13398</a> (cross-list from eess.IV) [<a href="/pdf/2309.13398" title="Download PDF">pdf</a>, <a href="/format/2309.13398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A mirror-Unet architecture for PET/CT lesion segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Habarnau%2C+Y+R">Yamila Rotstein Habarnau</a>, 
<a href="/search/eess?searchtype=author&query=Nam%C3%ADas%2C+M">Mauro Nam&#xed;as</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Automatic lesion detection and segmentation from [${}^{18}$F]FDG PET/CT scans
is a challenging task, due to the diversity of shapes, sizes, FDG uptake and
location they may present, besides the fact that physiological uptake is also
present on healthy tissues. In this work, we propose a deep learning method
aimed at the segmentation of oncologic lesions, based on a combination of two
UNet-3D branches. First, one of the network's branches is trained to segment a
group of tissues from CT images. The other branch is trained to segment the
lesions from PET images, combining on the bottleneck the embedded information
of CT branch, already trained. We trained and validated our networks on the
AutoPET MICCAI 2023 Challenge dataset. Our code is available at:
https://github.com/yrotstein/AutoPET2023_Mv1.
</p>
</div>
</dd>
<dt><a name="item605">[605]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13404" title="Abstract">arXiv:2309.13404</a> (cross-list from eess.IV) [<a href="/pdf/2309.13404" title="Download PDF">pdf</a>, <a href="/format/2309.13404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WS-YOLO: Weakly Supervised Yolo Network for Surgical Tool Localization  in Endoscopic Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+R">Rongfeng Wei</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jinlin Wu</a>, 
<a href="/search/eess?searchtype=author&query=Pang%2C+Y">You Pang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhen Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Surgical Tool Localization in Endoscopic Videos Challenge of MICCAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Being able to automatically detect and track surgical instruments in
endoscopic video recordings would allow for many useful applications that could
transform different aspects of surgery. In robot-assisted surgery, the
potentially informative data like categories of surgical tool can be captured,
which is sparse, full of noise and without spatial information. We proposed a
Weakly Supervised Yolo Network (WS-YOLO) for Surgical Tool Localization in
Endoscopic Videos, to generate fine-grained semantic information with location
and category from coarse-grained semantic information outputted by the da Vinci
surgical robot, which significantly diminished the necessary human annotation
labor while striking an optimal balance between the quantity of manually
annotated data and detection performance. The source code is available at
https://github.com/Breezewrf/Weakly-Supervised-Yolov8.
</p>
</div>
</dd>
<dt><a name="item606">[606]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13421" title="Abstract">arXiv:2309.13421</a> (cross-list from math.OC) [<a href="/pdf/2309.13421" title="Download PDF">pdf</a>, <a href="/format/2309.13421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalties and Rewards for Fair Learning in Paired Kidney Exchange  Programs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carvalho%2C+M">Margarida Carvalho</a>, 
<a href="/search/math?searchtype=author&query=Caulfield%2C+A">Alison Caulfield</a>, 
<a href="/search/math?searchtype=author&query=Lin%2C+Y">Yi Lin</a>, 
<a href="/search/math?searchtype=author&query=Vetta%2C+A">Adrian Vetta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shorter version accepted in WINE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">A kidney exchange program, also called a kidney paired donation program, can
be viewed as a repeated, dynamic trading and allocation mechanism. This
suggests that a dynamic algorithm for transplant exchange selection may have
superior performance in comparison to the repeated use of a static algorithm.
We confirm this hypothesis using a full scale simulation of the Canadian Kidney
Paired Donation Program: learning algorithms, that attempt to learn optimal
patient-donor weights in advance via dynamic simulations, do lead to improved
outcomes. Specifically, our learning algorithms, designed with the objective of
fairness (that is, equity in terms of transplant accessibility across cPRA
groups), also lead to an increased number of transplants and shorter average
waiting times. Indeed, our highest performing learning algorithm improves
egalitarian fairness by 10% whilst also increasing the number of transplants by
6% and decreasing waiting times by 24%. However, our main result is much more
surprising. We find that the most critical factor in determining the
performance of a kidney exchange program is not the judicious assignment of
positive weights (rewards) to patient-donor pairs. Rather, the key factor in
increasing the number of transplants, decreasing waiting times and improving
group fairness is the judicious assignment of a negative weight (penalty) to
the small number of non-directed donors in the kidney exchange program.
</p>
</div>
</dd>
<dt><a name="item607">[607]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13459" title="Abstract">arXiv:2309.13459</a> (cross-list from stat.ML) [<a href="/pdf/2309.13459" title="Download PDF">pdf</a>, <a href="/format/2309.13459" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Model-Agnostic Graph Neural Network for Integrating Local and Global  Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Zhou%2C+W">Wenzhuo Zhou</a>, 
<a href="/search/stat?searchtype=author&query=Qu%2C+A">Annie Qu</a>, 
<a href="/search/stat?searchtype=author&query=Cooper%2C+K+W">Keiland W. Cooper</a>, 
<a href="/search/stat?searchtype=author&query=Fortin%2C+N">Norbert Fortin</a>, 
<a href="/search/stat?searchtype=author&query=Shahbaba%2C+B">Babak Shahbaba</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Graph Neural Networks (GNNs) have achieved promising performance in a variety
of graph-focused tasks. Despite their success, existing GNNs suffer from two
significant limitations: a lack of interpretability in results due to their
black-box nature, and an inability to learn representations of varying orders.
To tackle these issues, we propose a novel Model-agnostic Graph Neural Network
(MaGNet) framework, which is able to sequentially integrate information of
various orders, extract knowledge from high-order neighbors, and provide
meaningful and interpretable results by identifying influential compact graph
structures. In particular, MaGNet consists of two components: an estimation
model for the latent representation of complex relationships under graph
topology, and an interpretation model that identifies influential nodes, edges,
and important node features. Theoretically, we establish the generalization
error bound for MaGNet via empirical Rademacher complexity, and showcase its
power to represent layer-wise neighborhood mixing. We conduct comprehensive
numerical studies using simulated data to demonstrate the superior performance
of MaGNet in comparison to several state-of-the-art alternatives. Furthermore,
we apply MaGNet to a real-world case study aimed at extracting task-critical
information from brain activity data, thereby highlighting its effectiveness in
advancing scientific research.
</p>
</div>
</dd>
<dt><a name="item608">[608]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13461" title="Abstract">arXiv:2309.13461</a> (cross-list from quant-ph) [<a href="/pdf/2309.13461" title="Download PDF">pdf</a>, <a href="/format/2309.13461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tight bounds on Pauli channel learning without entanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+S">Senrui Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Oh%2C+C">Changhun Oh</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhou%2C+S">Sisi Zhou</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huang%2C+H">Hsin-Yuan Huang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Jiang%2C+L">Liang Jiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 1 figure. Comments welcome!
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">Entanglement is a useful resource for learning, but a precise
characterization of its advantage can be challenging. In this work, we consider
learning algorithms without entanglement to be those that only utilize
separable states, measurements, and operations between the main system of
interest and an ancillary system. These algorithms are equivalent to those that
apply quantum circuits on the main system interleaved with mid-circuit
measurements and classical feedforward. We prove a tight lower bound for
learning Pauli channels without entanglement that closes a cubic gap between
the best-known upper and lower bound. In particular, we show that
$\Theta(2^n\varepsilon^{-2})$ rounds of measurements are required to estimate
each eigenvalue of an $n$-qubit Pauli channel to $\varepsilon$ error with high
probability when learning without entanglement. In contrast, a learning
algorithm with entanglement only needs $\Theta(\varepsilon^{-2})$ rounds of
measurements. The tight lower bound strengthens the foundation for an
experimental demonstration of entanglement-enhanced advantages for
characterizing Pauli noise.
</p>
</div>
</dd>
<dt><a name="item609">[609]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13478" title="Abstract">arXiv:2309.13478</a> (cross-list from stat.ML) [<a href="/pdf/2309.13478" title="Download PDF">pdf</a>, <a href="/format/2309.13478" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CA-PCA: Manifold Dimension Estimation, Adapted for Curvature
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Gilbert%2C+A+C">Anna C. Gilbert</a>, 
<a href="/search/stat?searchtype=author&query=O%27Neill%2C+K">Kevin O&#x27;Neill</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The success of algorithms in the analysis of high-dimensional data is often
attributed to the manifold hypothesis, which supposes that this data lie on or
near a manifold of much lower dimension. It is often useful to determine or
estimate the dimension of this manifold before performing dimension reduction,
for instance. Existing methods for dimension estimation are calibrated using a
flat unit ball. In this paper, we develop CA-PCA, a version of local PCA based
instead on a calibration of a quadratic embedding, acknowledging the curvature
of the underlying manifold. Numerous careful experiments show that this
adaptation improves the estimator in a wide range of settings.
</p>
</div>
</dd>
<dt><a name="item610">[610]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13483" title="Abstract">arXiv:2309.13483</a> (cross-list from stat.ML) [<a href="/pdf/2309.13483" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Prediction and Analysis of UK Road Traffic Accident Severity  Using AI: Integration of Machine Learning, Econometric Techniques, and Time  Series Forecasting in Public Health Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sufian%2C+M+A">Md Abu Sufian</a>, 
<a href="/search/stat?searchtype=author&query=Varadarajan%2C+J">Jayasree Varadarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">This research investigates road traffic accident severity in the UK, using a
combination of machine learning, econometric, and statistical methods on
historical data. We employed various techniques, including correlation
analysis, regression models, GMM for error term issues, and time-series
forecasting with VAR and ARIMA models. Our approach outperforms naive
forecasting with an MASE of 0.800 and ME of -73.80. We also built a random
forest classifier with 73% precision, 78% recall, and a 73% F1-score.
Optimizing with H2O AutoML led to an XGBoost model with an RMSE of 0.176 and
MAE of 0.087. Factor Analysis identified key variables, and we used SHAP for
Explainable AI, highlighting influential factors like Driver_Home_Area_Type and
Road_Type. Our study enhances understanding of accident severity and offers
insights for evidence-based road safety policies.
</p>
</div>
</dd>
<dt><a name="item611">[611]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13504" title="Abstract">arXiv:2309.13504</a> (cross-list from eess.AS) [<a href="/pdf/2309.13504" title="Download PDF">pdf</a>, <a href="/format/2309.13504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention Is All You Need For Blind Room Volume Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chunxi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Jia%2C+M">Maoshen Jia</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Meiran Li</a>, 
<a href="/search/eess?searchtype=author&query=Bao%2C+C">Changchun Bao</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+W">Wenyu Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures, submitted ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In recent years, dynamic parameterization of acoustic environments has raised
increasing attention in the field of audio processing. One of the key
parameters that characterize the local room acoustics in isolation from
orientation and directivity of sources and receivers is the geometric room
volume. Convolutional neural networks (CNNs) have been widely selected as the
main models for conducting blind room acoustic parameter estimation, which aims
to learn a direct mapping from audio spectrograms to corresponding labels. With
the recent trend of self-attention mechanisms, this paper introduces a purely
attention-based model to blindly estimate room volumes based on single-channel
noisy speech signals. We demonstrate the feasibility of eliminating the
reliance on CNN for this task and the proposed Transformer architecture takes
Gammatone magnitude spectral coefficients and phase spectrograms as inputs. To
enhance the model performance given the task-specific dataset, cross-modality
transfer learning is also applied. Experimental results demonstrate that the
proposed model outperforms traditional CNN models across a wide range of
real-world acoustics spaces, especially with the help of the dedicated
pretraining and data augmentation schemes.
</p>
</div>
</dd>
<dt><a name="item612">[612]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13537" title="Abstract">arXiv:2309.13537</a> (cross-list from eess.AS) [<a href="/pdf/2309.13537" title="Download PDF">pdf</a>, <a href="/format/2309.13537" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech enhancement with frequency domain auto-regressive modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Purushothaman%2C+A">Anurenjan Purushothaman</a>, 
<a href="/search/eess?searchtype=author&query=Dutta%2C+D">Debottam Dutta</a>, 
<a href="/search/eess?searchtype=author&query=Kumar%2C+R">Rohit Kumar</a>, 
<a href="/search/eess?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE/ACM Transactions on Audio, Speech and Language Processing
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Sound (cs.SD)

</div>
<p class="mathjax">Speech applications in far-field real world settings often deal with signals
that are corrupted by reverberation. The task of dereverberation constitutes an
important step to improve the audible quality and to reduce the error rates in
applications like automatic speech recognition (ASR). We propose a unified
framework of speech dereverberation for improving the speech quality and the
ASR performance using the approach of envelope-carrier decomposition provided
by an autoregressive (AR) model. The AR model is applied in the frequency
domain of the sub-band speech signals to separate the envelope and carrier
parts. A novel neural architecture based on dual path long short term memory
(DPLSTM) model is proposed, which jointly enhances the sub-band envelope and
carrier components. The dereverberated envelope-carrier signals are modulated
and the sub-band signals are synthesized to reconstruct the audio signal back.
The DPLSTM model for dereverberation of envelope and carrier components also
allows the joint learning of the network weights for the down stream ASR task.
In the ASR tasks on the REVERB challenge dataset as well as on the VOiCES
dataset, we illustrate that the joint learning of speech dereverberation
network and the E2E ASR model yields significant performance improvements over
the baseline ASR system trained on log-mel spectrogram as well as other
benchmarks for dereverberation (average relative improvements of 10-24% over
the baseline system). The speech quality improvements, evaluated using
subjective listening tests, further highlight the improved quality of the
reconstructed audio.
</p>
</div>
</dd>
<dt><a name="item613">[613]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13548" title="Abstract">arXiv:2309.13548</a> (cross-list from quant-ph) [<a href="/pdf/2309.13548" title="Download PDF">pdf</a>, <a href="/format/2309.13548" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum All-Subkeys-Recovery Attacks on 6-round Feistel-2* Structure  Based on Multi-Equations Quantum Claw Finding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+M">Mengting Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+Z">Zixian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Quantum Information Processing, 2023. 22(3): p. 142
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Exploiting quantum mechanisms, quantum attacks have the potential ability to
break the cipher structure. Recently, Ito et al. proposed a quantum attack on
Feistel-2* structure (Ito et al.'s attack) based onthe Q2 model. However, it is
not realistic since the quantum oracle needs to be accessed by the adversary,
and the data complexityis high. To solve this problem, a quantum
all-subkeys-recovery (ASR) attack based on multi-equations quantum claw-finding
is proposed, which takes a more realistic model, the Q1 model, as the scenario,
and only requires 3 plain-ciphertext pairs to quickly crack the 6-round
Feistel-2* structure. First, we proposed a multi-equations quantum claw-finding
algorithm to solve the claw problem of finding multiple equations. In addition,
Grover's algorithm is used to speedup the rest subkeys recovery. Compared with
Ito et al.'s attack, the data complexity of our attack is reduced from O(2^n)
to O(1), while the time complexity and memory complexity are also significantly
reduced.
</p>
</div>
</dd>
<dt><a name="item614">[614]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13553" title="Abstract">arXiv:2309.13553</a> (cross-list from eess.IV) [<a href="/pdf/2309.13553" title="Download PDF">pdf</a>, <a href="/ps/2309.13553" title="Download PostScript">ps</a>, <a href="/format/2309.13553" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Dice Focal Loss trained 3D Residual UNet for Automated  Lesion Segmentation in Whole-Body FDG PET/CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ahamed%2C+S">Shadab Ahamed</a>, 
<a href="/search/eess?searchtype=author&query=Rahmim%2C+A">Arman Rahmim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AutoPET-II challenge (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Automated segmentation of cancerous lesions in PET/CT images is a vital
initial task for quantitative analysis. However, it is often challenging to
train deep learning-based segmentation methods to high degree of accuracy due
to the diversity of lesions in terms of their shapes, sizes, and radiotracer
uptake levels. These lesions can be found in various parts of the body, often
close to healthy organs that also show significant uptake. Consequently,
developing a comprehensive PET/CT lesion segmentation model is a demanding
endeavor for routine quantitative image analysis. In this work, we train a 3D
Residual UNet using Generalized Dice Focal Loss function on the AutoPET
challenge 2023 training dataset. We develop our models in a 5-fold
cross-validation setting and ensemble the five models via average and
weighted-average ensembling. On the preliminary test phase, the average
ensemble achieved a Dice similarity coefficient (DSC), false-positive volume
(FPV) and false negative volume (FNV) of 0.5417, 0.8261 ml, and 0.2538 ml,
respectively, while the weighted-average ensemble achieved 0.5417, 0.8186 ml,
and 0.2538 ml, respectively. Our algorithm can be accessed via this link:
https://github.com/ahxmeds/autosegnet.
</p>
</div>
</dd>
<dt><a name="item615">[615]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13557" title="Abstract">arXiv:2309.13557</a> (cross-list from stat.CO) [<a href="/pdf/2309.13557" title="Download PDF">pdf</a>, <a href="/format/2309.13557" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayesian Parameter Inference for Partially Observed Diffusions using  Multilevel Stochastic Runge-Kutta Methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Del+Moral%2C+P">Pierre Del Moral</a>, 
<a href="/search/stat?searchtype=author&query=Hu%2C+S">Shulan Hu</a>, 
<a href="/search/stat?searchtype=author&query=Jasra%2C+A">Ajay Jasra</a>, 
<a href="/search/stat?searchtype=author&query=Ruzayqat%2C+H">Hamza Ruzayqat</a>, 
<a href="/search/stat?searchtype=author&query=Wang%2C+X">Xinyu Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation (stat.CO)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider the problem of Bayesian estimation of static parameters
associated to a partially and discretely observed diffusion process. We assume
that the exact transition dynamics of the diffusion process are unavailable,
even up-to an unbiased estimator and that one must time-discretize the
diffusion process. In such scenarios it has been shown how one can introduce
the multilevel Monte Carlo method to reduce the cost to compute posterior
expected values of the parameters for a pre-specified mean square error (MSE).
These afore-mentioned methods rely on upon the Euler-Maruyama discretization
scheme which is well-known in numerical analysis to have slow convergence
properties. We adapt stochastic Runge-Kutta (SRK) methods for Bayesian
parameter estimation of static parameters for diffusions. This can be
implemented in high-dimensions of the diffusion and seemingly under-appreciated
in the uncertainty quantification and statistics fields. For a class of
diffusions and SRK methods, we consider the estimation of the posterior
expectation of the parameters. We prove that to achieve a MSE of
$\mathcal{O}(\epsilon^2)$, for $\epsilon&gt;0$ given, the associated work is
$\mathcal{O}(\epsilon^{-2})$. Whilst the latter is achievable for the Milstein
scheme, this method is often not applicable for diffusions in dimension larger
than two. We also illustrate our methodology in several numerical examples.
</p>
</div>
</dd>
<dt><a name="item616">[616]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13571" title="Abstract">arXiv:2309.13571</a> (cross-list from eess.IV) [<a href="/pdf/2309.13571" title="Download PDF">pdf</a>, <a href="/format/2309.13571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Matrix Completion-Informed Deep Unfolded Equilibrium Models for  Self-Supervised k-Space Interpolation in MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Luo%2C+C">Chen Luo</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Huayu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+T">Taofeng Xie</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+Q">Qiyu Jin</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+G">Guoqing Chen</a>, 
<a href="/search/eess?searchtype=author&query=Cui%2C+Z">Zhuo-Xu Cui</a>, 
<a href="/search/eess?searchtype=author&query=Liang%2C+D">Dong Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, regularization model-driven deep learning (DL) has gained
significant attention due to its ability to leverage the potent
representational capabilities of DL while retaining the theoretical guarantees
of regularization models. However, most of these methods are tailored for
supervised learning scenarios that necessitate fully sampled labels, which can
pose challenges in practical MRI applications. To tackle this challenge, we
propose a self-supervised DL approach for accelerated MRI that is theoretically
guaranteed and does not rely on fully sampled labels. Specifically, we achieve
neural network structure regularization by exploiting the inherent structural
low-rankness of the $k$-space data. Simultaneously, we constrain the network
structure to resemble a nonexpansive mapping, ensuring the network's
convergence to a fixed point. Thanks to this well-defined network structure,
this fixed point can completely reconstruct the missing $k$-space data based on
matrix completion theory, even in situations where full-sampled labels are
unavailable. Experiments validate the effectiveness of our proposed method and
demonstrate its superiority over existing self-supervised approaches and
traditional regularization methods, achieving performance comparable to that of
supervised learning methods in certain scenarios.
</p>
</div>
</dd>
<dt><a name="item617">[617]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13582" title="Abstract">arXiv:2309.13582</a> (cross-list from nlin.SI) [<a href="/pdf/2309.13582" title="Download PDF">pdf</a>, <a href="/ps/2309.13582" title="Download PostScript">ps</a>, <a href="/format/2309.13582" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solvable difference equations similar to the Newton-Raphson iteration  for algebraic equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Maeda%2C+K">Kazuki Maeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Exactly Solvable and Integrable Systems (nlin.SI)</span>; Dynamical Systems (math.DS); Numerical Analysis (math.NA)

</div>
<p class="mathjax">It is known that difference equations generated as the Newton-Raphson
iteration for quadratic equations are solvable in closed form, and the solution
can be constructed from linear three-term recurrence relations with constant
coefficients. We show that the same construction for four-term recurrence
relations gives the solution to the initial value problem of difference
equations similar to the Newton-Raphson iteration for cubic equations. In many
cases, the solution converges to a root of the cubic equation and the
convergence rate is quadratic.
</p>
</div>
</dd>
<dt><a name="item618">[618]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13584" title="Abstract">arXiv:2309.13584</a> (cross-list from eess.IV) [<a href="/pdf/2309.13584" title="Download PDF">pdf</a>, <a href="/format/2309.13584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving Low-Dose CT Reconstruction via GAN with Local Coherence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">The Computed Tomography (CT) for diagnosis of lesions in human internal
organs is one of the most fundamental topics in medical imaging. Low-dose CT,
which offers reduced radiation exposure, is preferred over standard-dose CT,
and therefore its reconstruction approaches have been extensively studied.
However, current low-dose CT reconstruction techniques mainly rely on
model-based methods or deep-learning-based techniques, which often ignore the
coherence and smoothness for sequential CT slices. To address this issue, we
propose a novel approach using generative adversarial networks (GANs) with
enhanced local coherence. The proposed method can capture the local coherence
of adjacent images by optical flow, which yields significant improvements in
the precision and stability of the constructed images. We evaluate our proposed
method on real datasets and the experimental results suggest that it can
outperform existing state-of-the-art reconstruction approaches significantly.
</p>
</div>
</dd>
<dt><a name="item619">[619]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13587" title="Abstract">arXiv:2309.13587</a> (cross-list from eess.IV) [<a href="/pdf/2309.13587" title="Download PDF">pdf</a>, <a href="/format/2309.13587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Encoder-Decoder Architectures for Biplanar X-ray to 3D  Shape Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shakya%2C+M">Mahesh Shakya</a> (1), 
<a href="/search/eess?searchtype=author&query=Khanal%2C+B">Bishesh Khanal</a> (1) ((1) NepAl Applied Mathematics and Informatics Institute for research)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Various deep learning models have been proposed for 3D bone shape
reconstruction from two orthogonal (biplanar) X-ray images. However, it is
unclear how these models compare against each other since they are evaluated on
different anatomy, cohort and (often privately held) datasets. Moreover, the
impact of the commonly optimized image-based segmentation metrics such as dice
score on the estimation of clinical parameters relevant in 2D-3D bone shape
reconstruction is not well known. To move closer toward clinical translation,
we propose a benchmarking framework that evaluates tasks relevant to real-world
clinical scenarios, including reconstruction of fractured bones, bones with
implants, robustness to population shift, and error in estimating clinical
parameters. Our open-source platform provides reference implementations of 8
models (many of whose implementations were not publicly available), APIs to
easily collect and preprocess 6 public datasets, and the implementation of
automatic clinical parameter and landmark extraction methods. We present an
extensive evaluation of 8 2D-3D models on equal footing using 6 public datasets
comprising images for four different anatomies. Our results show that
attention-based methods that capture global spatial relationships tend to
perform better across all anatomies and datasets; performance on clinically
relevant subgroups may be overestimated without disaggregated reporting; ribs
are substantially more difficult to reconstruct compared to femur, hip and
spine; and the dice score improvement does not always bring a corresponding
improvement in the automatic estimation of clinically relevant parameters.
</p>
</div>
</dd>
<dt><a name="item620">[620]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13593" title="Abstract">arXiv:2309.13593</a> (cross-list from physics.comp-ph) [<a href="/pdf/2309.13593" title="Download PDF">pdf</a>, <a href="/format/2309.13593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Tuning Hamiltonian Monte Carlo for Accelerated Sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Christiansen%2C+H">Henrik Christiansen</a>, 
<a href="/search/physics?searchtype=author&query=Errica%2C+F">Federico Errica</a>, 
<a href="/search/physics?searchtype=author&query=Alesiani%2C+F">Francesco Alesiani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Soft Condensed Matter (cond-mat.soft); Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">The performance of Hamiltonian Monte Carlo crucially depends on its
parameters, in particular the integration timestep and the number of
integration steps. We present an adaptive general-purpose framework to
automatically tune these parameters based on a loss function which promotes the
fast exploration of phase-space. For this, we make use of a
fully-differentiable set-up and use backpropagation for optimization. An
attention-like loss is defined which allows for the gradient driven learning of
the distribution of integration steps. We also highlight the importance of
jittering for a smooth loss-surface. Our approach is demonstrated for the
one-dimensional harmonic oscillator and alanine dipeptide, a small protein
common as a test-case for simulation methods. We find a good correspondence
between our loss and the autocorrelation times, resulting in well-tuned
parameters for Hamiltonian Monte Carlo.
</p>
</div>
</dd>
<dt><a name="item621">[621]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13602" title="Abstract">arXiv:2309.13602</a> (cross-list from eess.SP) [<a href="/pdf/2309.13602" title="Download PDF">pdf</a>, <a href="/format/2309.13602" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 6G Positioning and Sensing Through the Lens of Sustainability,  Inclusiveness, and Trustworthiness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wymeersch%2C+H">Henk Wymeersch</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hui Chen</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+H">Hao Guo</a>, 
<a href="/search/eess?searchtype=author&query=Keskin%2C+M+F">Musa Furkan Keskin</a>, 
<a href="/search/eess?searchtype=author&query=Khorsandi%2C+B+M">Bahare M. Khorsandi</a>, 
<a href="/search/eess?searchtype=author&query=Moghaddam%2C+M+H">Mohammad H. Moghaddam</a>, 
<a href="/search/eess?searchtype=author&query=Ramirez%2C+A">Alejandro Ramirez</a>, 
<a href="/search/eess?searchtype=author&query=Schindhelm%2C+K">Kim Schindhelm</a>, 
<a href="/search/eess?searchtype=author&query=Stavridis%2C+A">Athanasios Stavridis</a>, 
<a href="/search/eess?searchtype=author&query=Svensson%2C+T">Tommy Svensson</a>, 
<a href="/search/eess?searchtype=author&query=Yajnanarayana%2C+V">Vijaya Yajnanarayana</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">6G promises a paradigm shift in which positioning and sensing are inherently
integrated, enhancing not only the communication performance but also enabling
location- and context-aware services. Historically, positioning and sensing
have been viewed through the lens of cost and performance trade-offs, implying
an escalated demand for resources, such as radio, physical, and computational
resources, for improved performance. However, 6G goes beyond this traditional
perspective to encompass a set of broader values, namely sustainability,
inclusiveness, and trustworthiness. This paper aims to: (i) shed light on these
important value indicators and their relationship with the conventional key
performance indicators, and (ii) unveil the dual nature of 6G in relation to
these key value indicators (i.e., ensuring operation according to the values
and enabling services that affect the values).
</p>
</div>
</dd>
<dt><a name="item622">[622]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13605" title="Abstract">arXiv:2309.13605</a> (cross-list from eess.AS) [<a href="/pdf/2309.13605" title="Download PDF">pdf</a>, <a href="/format/2309.13605" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Black-Box Speaker Verification Model Adaptation with  Reprogramming and Backend Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jingyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+T">Tan Lee</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The development of deep neural networks (DNN) has significantly enhanced the
performance of speaker verification (SV) systems in recent years. However, a
critical issue that persists when applying DNN-based SV systems in practical
applications is domain mismatch. To mitigate the performance degradation caused
by the mismatch, domain adaptation becomes necessary. This paper introduces an
approach to adapt DNN-based SV models by manipulating the learnable model
inputs, inspired by the concept of adversarial reprogramming. The pre-trained
SV model remains fixed and functions solely in the forward process, resembling
a black-box model. A lightweight network is utilized to estimate the gradients
for the learnable parameters at the input, which bypasses the gradient
backpropagation through the black-box model. The reprogrammed output is
processed by a two-layer backend learning module as the final adapted speaker
embedding. The number of parameters involved in the gradient calculation is
small in our design. With few additional parameters, the proposed method
achieves both memory and parameter efficiency. The experiments are conducted in
language mismatch scenarios. Using much less computation cost, the proposed
method obtains close or superior performance to the fully finetuned models in
our experiments, which demonstrates its effectiveness.
</p>
</div>
</dd>
<dt><a name="item623">[623]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13611" title="Abstract">arXiv:2309.13611</a> (cross-list from eess.IV) [<a href="/pdf/2309.13611" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparsity-regularized coded ptychography for robust and efficient  lensless microscopy on a chip
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+N">Ninghe Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Q">Qianhao Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Zheng%2C+G">Guoan Zheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Information Retrieval (cs.IR); Optics (physics.optics)

</div>
<p class="mathjax">In ptychographic imaging, the trade-off between the number of acquisitions
and the resultant imaging quality presents a complex optimization problem.
Increasing the number of acquisitions typically yields reconstructions with
higher spatial resolution and finer details. Conversely, a reduction in
measurement frequency often compromises the quality of the reconstructed
images, manifesting as increased noise and coarser details. To address this
challenge, we employ sparsity priors to reformulate the ptychographic
reconstruction task as a total variation regularized optimization problem. We
introduce a new computational framework, termed the ptychographic proximal
total-variation (PPTV) solver, designed to integrate into existing ptychography
settings without necessitating hardware modifications. Through comprehensive
numerical simulations, we validate that PPTV-driven coded ptychography is
capable of producing highly accurate reconstructions with a minimal set of
eight intensity measurements. Convergence analysis further substantiates the
robustness, stability, and computational feasibility of the proposed PPTV
algorithm. Experimental results obtained from optical setups unequivocally
demonstrate that the PPTV algorithm facilitates high-throughput,
high-resolution imaging while significantly reducing the measurement burden.
These findings indicate that the PPTV algorithm has the potential to
substantially mitigate the resource-intensive requirements traditionally
associated with high-quality ptychographic imaging, thereby offering a pathway
toward the development of more compact and efficient ptychographic microscopy
systems.
</p>
</div>
</dd>
<dt><a name="item624">[624]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13626" title="Abstract">arXiv:2309.13626</a> (cross-list from cond-mat.mtrl-sci) [<a href="/pdf/2309.13626" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crack-Net: Prediction of Crack Propagation in Composites
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xu%2C+H">Hao Xu</a>, 
<a href="/search/cond-mat?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Taylor%2C+A+C">Ambrose C. Taylor</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+D">Dongxiao Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Ruan%2C+L">Lecheng Ruan</a>, 
<a href="/search/cond-mat?searchtype=author&query=Shi%2C+R">Rundong Shi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Statistical Mechanics (cond-mat.stat-mech); Machine Learning (cs.LG); Chaotic Dynamics (nlin.CD)

</div>
<p class="mathjax">Computational solid mechanics has become an indispensable approach in
engineering, and numerical investigation of fracture in composites is essential
as composites are widely used in structural applications. Crack evolution in
composites is the bridge to elucidate the relationship between the
microstructure and fracture performance, but crack-based finite element methods
are computationally expensive and time-consuming, limiting their application in
computation-intensive scenarios. Here we propose a deep learning framework
called Crack-Net, which incorporates the relationship between crack evolution
and stress response to predict the fracture process in composites. Trained on a
high-precision fracture development dataset generated using the phase field
method, Crack-Net demonstrates a remarkable capability to accurately forecast
the long-term evolution of crack growth patterns and the stress-strain curve
for a given composite design. The Crack-Net captures the essential principle of
crack growth, which enables it to handle more complex microstructures such as
binary co-continuous structures. Moreover, transfer learning is adopted to
further improve the generalization ability of Crack-Net for composite materials
with reinforcements of different strengths. The proposed Crack-Net holds great
promise for practical applications in engineering and materials science, in
which accurate and efficient fracture prediction is crucial for optimizing
material performance and microstructural design.
</p>
</div>
</dd>
<dt><a name="item625">[625]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13650" title="Abstract">arXiv:2309.13650</a> (cross-list from eess.AS) [<a href="/pdf/2309.13650" title="Download PDF">pdf</a>, <a href="/ps/2309.13650" title="Download PostScript">ps</a>, <a href="/format/2309.13650" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-modal Alignment with Optimal Transport for CTC-based ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+X">Xugang Lu</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+P">Peng Shen</a>, 
<a href="/search/eess?searchtype=author&query=Tsao%2C+Y">Yu Tsao</a>, 
<a href="/search/eess?searchtype=author&query=Kawai%2C+H">Hisashi Kawai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Temporal connectionist temporal classification (CTC)-based automatic speech
recognition (ASR) is one of the most successful end to end (E2E) ASR
frameworks. However, due to the token independence assumption in decoding, an
external language model (LM) is required which destroys its fast parallel
decoding property. Several studies have been proposed to transfer linguistic
knowledge from a pretrained LM (PLM) to the CTC based ASR. Since the PLM is
built from text while the acoustic model is trained with speech, a cross-modal
alignment is required in order to transfer the context dependent linguistic
knowledge from the PLM to acoustic encoding. In this study, we propose a novel
cross-modal alignment algorithm based on optimal transport (OT). In the
alignment process, a transport coupling matrix is obtained using OT, which is
then utilized to transform a latent acoustic representation for matching the
context-dependent linguistic features encoded by the PLM. Based on the
alignment, the latent acoustic feature is forced to encode context dependent
linguistic information. We integrate this latent acoustic feature to build
conformer encoder-based CTC ASR system. On the AISHELL-1 data corpus, our
system achieved 3.96% and 4.27% character error rate (CER) for dev and test
sets, respectively, which corresponds to relative improvements of 28.39% and
29.42% compared to the baseline conformer CTC ASR system without cross-modal
knowledge transfer.
</p>
</div>
</dd>
<dt><a name="item626">[626]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13659" title="Abstract">arXiv:2309.13659</a> (cross-list from quant-ph) [<a href="/pdf/2309.13659" title="Download PDF">pdf</a>, <a href="/format/2309.13659" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Novel Quantum Visual Secret Sharing Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wenjie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+Y">Yinsong Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+M">Maojun Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+J">Junxiu Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+C">Ching-Nung Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 13 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Access, 2019. 7: p. 114374-114384
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Inspired by Naor et al.'s visual secret sharing (VSS) scheme, a novel n out
of n quantum visual secret sharing (QVSS) scheme is proposed, which consists of
two phases: sharing process and recovering process. In the first process, the
color information of each pixel from the original secret image is encoded into
an n-qubit superposition state by using the strategy of quantum expansion
instead of classical pixel expansion, and then these n qubits are distributed
as shares to n participants, respectively. During the recovering process, all
participants cooperate to collect these n shares of each pixel together, then
perform the corresponding measurement on them, and execute the n-qubit XOR
operation to recover each pixel of the secret image. The proposed scheme has
the advantage of single-pixel parallel processing that is not available in the
existing analogous quantum schemes and perfectly solves the problem that in the
classic VSS schemes the recovered image has the loss in resolution. Moreover,
its experiment implementation with the IBM Q is conducted to demonstrate the
practical feasibility.
</p>
</div>
</dd>
<dt><a name="item627">[627]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13664" title="Abstract">arXiv:2309.13664</a> (cross-list from eess.AS) [<a href="/pdf/2309.13664" title="Download PDF">pdf</a>, <a href="/format/2309.13664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoiceLDM: Text-to-Speech with Environmental Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lee%2C+Y">Yeonghyeon Lee</a>, 
<a href="/search/eess?searchtype=author&query=Yeon%2C+I">Inmo Yeon</a>, 
<a href="/search/eess?searchtype=author&query=Nam%2C+J">Juhan Nam</a>, 
<a href="/search/eess?searchtype=author&query=Chung%2C+J+S">Joon Son Chung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Demos and code are available at <a href="https://voiceldm.github.io">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This paper presents VoiceLDM, a model designed to produce audio that
accurately follows two distinct natural language text prompts: the description
prompt and the content prompt. The former provides information about the
overall environmental context of the audio, while the latter conveys the
linguistic content. To achieve this, we adopt a text-to-audio (TTA) model based
on latent diffusion models and extend its functionality to incorporate an
additional content prompt as a conditional input. By utilizing pretrained
contrastive language-audio pretraining (CLAP) and Whisper, VoiceLDM is trained
on large amounts of real-world audio without manual annotations or
transcriptions. Additionally, we employ dual classifier-free guidance to
further enhance the controllability of VoiceLDM. Experimental results
demonstrate that VoiceLDM is capable of generating plausible audio that aligns
well with both input conditions, even surpassing the speech intelligibility of
the ground truth audio on the AudioCaps test set. Furthermore, we explore the
text-to-speech (TTS) and zero-shot text-to-audio capabilities of VoiceLDM and
show that it achieves competitive results. Demos and code are available at
https://voiceldm.github.io.
</p>
</div>
</dd>
<dt><a name="item628">[628]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13668" title="Abstract">arXiv:2309.13668</a> (cross-list from quant-ph) [<a href="/pdf/2309.13668" title="Download PDF">pdf</a>, <a href="/format/2309.13668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantum Privacy-Preserving Price E-Negotiation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+W">Wen-Jie Liu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+C">Chun-Tang Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zheng%2C+Y">Yu Zheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+Y">Yong Xu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Xu%2C+Y">Yin-Song Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Theoretical Physics, 2019. 58(10): p.
  3259-3270
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Emerging Technologies (cs.ET)

</div>
<p class="mathjax">Privacy-preserving price e-negotiation (3PEN) is an important topic of secure
multi-party computation (SMC) in the electronic commerce field, and the key
point of its security is to guarantee the privacy of seller's and buyer's
prices. In this study, a novel and efficient quantum solution to the 3PEN
problem is proposed, where the oracle operation and the qubit comparator are
utilized to obtain the comparative results of buyer's and seller's prices, and
then quantum counting is executed to summarize the total number of products
which meets the trading conditions. Analysis shows that our solution not only
guarantees the correctness and the privacy of 3PEN, but also has lower
communication complexity than those classical ones.
</p>
</div>
</dd>
<dt><a name="item629">[629]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13691" title="Abstract">arXiv:2309.13691</a> (cross-list from quant-ph) [<a href="/pdf/2309.13691" title="Download PDF">pdf</a>, <a href="/format/2309.13691" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Simultaneous Information and Energy Transmission through Quantum  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Das%2C+B+K">Bishal Kumar Das</a>, 
<a href="/search/quant-ph?searchtype=author&query=Varshney%2C+L+R">Lav R. Varshney</a>, 
<a href="/search/quant-ph?searchtype=author&query=Madhok%2C+V">Vaibhav Madhok</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 15 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The optimal rate at which information can be sent through a quantum channel
when the transmitted signal must simultaneously carry some minimum amount of
energy is characterized. To do so, we introduce the quantum-classical analogue
of the capacity-power function and generalize results in classical information
theory for transmitting classical information through noisy channels. We show
that the capacity-power function for a quantum channel, for both unassisted and
private protocol, is concave and also prove additivity for unentangled and
uncorrelated ensembles of input signals. This implies we do not need
regularized formulas for calculation. We numerically demonstrate these
properties for some standard channel models. We obtain analytical expressions
for the capacity-power function for the case of noiseless channels using
properties of random quantum states and concentration phenomenon in large
Hilbert spaces.
</p>
</div>
</dd>
<dt><a name="item630">[630]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13696" title="Abstract">arXiv:2309.13696</a> (cross-list from q-fin.PM) [<a href="/pdf/2309.13696" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Performance Evaluation of Equal-Weight Portfolio and Optimum Risk  Portfolio on Indian Stocks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sen%2C+A">Abhiraj Sen</a>, 
<a href="/search/q-fin?searchtype=author&query=Sen%2C+J">Jaydip Sen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is the preprint of our paper that has been accepted for publication in the Inderscience journal "International Journal of Business Forecasting and Marketing Intelligence". The preprint consist of 63 pages and contains 26 figures and 66 tables. This is not the final published version of the paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Portfolio Management (q-fin.PM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Designing an optimum portfolio for allocating suitable weights to its
constituent assets so that the return and risk associated with the portfolio
are optimized is a computationally hard problem. The seminal work of Markowitz
that attempted to solve the problem by estimating the future returns of the
stocks is found to perform sub-optimally on real-world stock market data. This
is because the estimation task becomes extremely challenging due to the
stochastic and volatile nature of stock prices. This work illustrates three
approaches to portfolio design minimizing the risk, optimizing the risk, and
assigning equal weights to the stocks of a portfolio. Thirteen critical sectors
listed on the National Stock Exchange (NSE) of India are first chosen. Three
portfolios are designed following the above approaches choosing the top ten
stocks from each sector based on their free-float market capitalization. The
portfolios are designed using the historical prices of the stocks from Jan 1,
2017, to Dec 31, 2022. The portfolios are evaluated on the stock price data
from Jan 1, 2022, to Dec 31, 2022. The performances of the portfolios are
compared, and the portfolio yielding the higher return for each sector is
identified.
</p>
</div>
</dd>
<dt><a name="item631">[631]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13712" title="Abstract">arXiv:2309.13712</a> (cross-list from math.OC) [<a href="/pdf/2309.13712" title="Download PDF">pdf</a>, <a href="/format/2309.13712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Superstabilization of Linear Systems under Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Miller%2C+J">Jared Miller</a>, 
<a href="/search/math?searchtype=author&query=Zheng%2C+J">Jian Zheng</a>, 
<a href="/search/math?searchtype=author&query=Sznaier%2C+M">Mario Sznaier</a>, 
<a href="/search/math?searchtype=author&query=Hixenbaugh%2C+C">Chris Hixenbaugh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 2 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">This paper focuses on the stabilization and regulation of linear systems
affected by quantization in state-transition data and actuated input. The
observed data are composed of tuples of current state, input, and the next
state's interval ranges based on sensor quantization. Using an established
characterization of input-logarithmically-quantized stabilization based on
robustness to sector-bounded uncertainty, we formulate a nonconservative
infinite-dimensional linear program that enforces superstabilization of all
possible consistent systems under assumed priors. We solve this problem by
posing a pair of exponentially-scaling linear programs, and demonstrate the
success of our method on example quantized systems.
</p>
</div>
</dd>
<dt><a name="item632">[632]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13713" title="Abstract">arXiv:2309.13713</a> (cross-list from math.AP) [<a href="/pdf/2309.13713" title="Download PDF">pdf</a>, <a href="/format/2309.13713" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beginner&#x27;s guide to Aggregation-Diffusion Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=G%C3%B3mez-Castro%2C+D">David G&#xf3;mez-Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">The aim of this survey is to serve as an introduction to the different
techniques available in the broad field of Aggregation-Diffusion Equations. We
aim to provide historical context, key literature, and main ideas in the field.
We start by discussing the modelling and famous particular cases: Heat
equation, Fokker-Plank, Porous medium, Keller-Segel,
Chapman-Rubinstein-Schatzman, Newtonian vortex, Caffarelli-V\'azquez,
McKean-Vlasov, Kuramoto, and one-layer neural networks. In Section 4 we present
the well-posedness frameworks given as PDEs in Sobolev spaces, and
gradient-flow in Wasserstein. Then we discuss the asymptotic behaviour in time,
for which we need to understand minimisers of a free energy. We then present
some numerical methods which have been developed. We conclude the paper
mentioning some related problems.
</p>
</div>
</dd>
<dt><a name="item633">[633]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13733" title="Abstract">arXiv:2309.13733</a> (cross-list from stat.ML) [<a href="/pdf/2309.13733" title="Download PDF">pdf</a>, <a href="/format/2309.13733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Tuning-Free Minimum-Volume Nonnegative Matrix Factorization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+D+T">Duc Toan Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Chi%2C+E+C">Eric C. Chi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Computation (stat.CO)

</div>
<p class="mathjax">Nonnegative Matrix Factorization (NMF) is a versatile and powerful tool for
discovering latent structures in data matrices, with many variations proposed
in the literature. Recently, Leplat et al.\@ (2019) introduced a minimum-volume
NMF for the identifiable recovery of rank-deficient matrices in the presence of
noise. The performance of their formulation, however, requires the selection of
a tuning parameter whose optimal value depends on the unknown noise level. In
this work, we propose an alternative formulation of minimum-volume NMF inspired
by the square-root lasso and its tuning-free properties. Our formulation also
requires the selection of a tuning parameter, but its optimal value does not
depend on the noise level. To fit our NMF model, we propose a
majorization-minimization (MM) algorithm that comes with global convergence
guarantees. We show empirically that the optimal choice of our tuning parameter
is insensitive to the noise level in the data.
</p>
</div>
</dd>
<dt><a name="item634">[634]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13747" title="Abstract">arXiv:2309.13747</a> (cross-list from eess.IV) [<a href="/pdf/2309.13747" title="Download PDF">pdf</a>, <a href="/format/2309.13747" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Look Ma, no code: fine tuning nnU-Net for the AutoPET II challenge by  only adjusting its JSON plans
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Isensee%2C+F">Fabian Isensee</a>, 
<a href="/search/eess?searchtype=author&query=Maier-Hein%2C+K+H">Klaus H.Maier-Hein</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">We participate in the AutoPET II challenge by modifying nnU-Net only through
its easy to understand and modify 'nnUNetPlans.json' file. By switching to a
UNet with residual encoder, increasing the batch size and increasing the patch
size we obtain a configuration that substantially outperforms the automatically
configured nnU-Net baseline (5-fold cross-validation Dice score of 65.14 vs
33.28) at the expense of increased compute requirements for model training. Our
final submission ensembles the two most promising configurations. At the time
of submission our method ranks first on the preliminary test set.
</p>
</div>
</dd>
<dt><a name="item635">[635]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13766" title="Abstract">arXiv:2309.13766</a> (cross-list from econ.TH) [<a href="/pdf/2309.13766" title="Download PDF">pdf</a>, <a href="/ps/2309.13766" title="Download PostScript">ps</a>, <a href="/format/2309.13766" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reserve Matching with Thresholds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Evren%2C+S">Suat Evren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2 figures, 4 algorithms/mechanisms, 19 pages without appendix and references, 30 pages in total
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Reserve systems are used to accommodate multiple essential or
underrepresented groups in allocating indivisible scarce resources by creating
categories that prioritize their respective beneficiaries. Some applications
include the optimal allocation of vaccines, or assignment of minority students
to elite colleges in India. An allocation is called smart if it optimizes the
number of units distributed. Previous literature mostly assumed baseline
priorities, which impose significant interdependencies between the priority
ordering of different categories. It also assumes either everybody is eligible
for receiving a unit from any category, or only the beneficiaries are eligible.
The comprehensive Threshold Model we propose allows independent priority
orderings among categories and arbitrary beneficiary and eligibility
thresholds, enabling policymakers to avoid comparing incomparables in
affirmative action systems. We present a new smart reserve system that
optimizes two objectives simultaneously to allocate scarce resources. Our Smart
Pipeline Matching Mechanism achieves all desirable properties in the most
general domain possible. Our results apply to any resource allocation market,
but we focus our attention on the vaccine allocation problem.
</p>
</div>
</dd>
<dt><a name="item636">[636]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13767" title="Abstract">arXiv:2309.13767</a> (cross-list from physics.med-ph) [<a href="/pdf/2309.13767" title="Download PDF">pdf</a>, <a href="/format/2309.13767" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> pyPPG: A Python toolbox for comprehensive photoplethysmography signal  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Goda%2C+M+A">Marton A. Goda</a>, 
<a href="/search/physics?searchtype=author&query=Charlton%2C+P+H">Peter H. Charlton</a>, 
<a href="/search/physics?searchtype=author&query=Behar%2C+J+A">Joachim A. Behar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript was submitted to "Physiological Measurement" on September 5, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Mathematical Software (cs.MS)

</div>
<p class="mathjax">Photoplethysmography is a non-invasive optical technique that measures
changes in blood volume within tissues. It is commonly and increasingly used
for in a variety of research and clinical application to assess vascular
dynamics and physiological parameters. Yet, contrary to heart rate variability
measures, a field which has seen the development of stable standards and
advanced toolboxes and software, no such standards and open tools exist for
continuous photoplethysmogram (PPG) analysis. Consequently, the primary
objective of this research was to identify, standardize, implement and validate
key digital PPG biomarkers. This work describes the creation of a standard
Python toolbox, denoted pyPPG, for long-term continuous PPG time series
analysis recorded using a standard finger-based transmission pulse oximeter.
The improved PPG peak detector had an F1-score of 88.19% for the
state-of-the-art benchmark when evaluated on 2,054 adult polysomnography
recordings totaling over 91 million reference beats. This algorithm
outperformed the open-source original Matlab implementation by ~5% when
benchmarked on a subset of 100 randomly selected MESA recordings. More than
3,000 fiducial points were manually annotated by two annotators in order to
validate the fiducial points detector. The detector consistently demonstrated
high performance, with a mean absolute error of less than 10 ms for all
fiducial points. Based on these fiducial points, pyPPG engineers a set of 74
PPG biomarkers. Studying the PPG time series variability using pyPPG can
enhance our understanding of the manifestations and etiology of diseases. This
toolbox can also be used for biomarker engineering in training data-driven
models. pyPPG is available on physiozoo.org
</p>
</div>
</dd>
<dt><a name="item637">[637]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13777" title="Abstract">arXiv:2309.13777</a> (cross-list from eess.IV) [<a href="/pdf/2309.13777" title="Download PDF">pdf</a>, <a href="/format/2309.13777" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffeomorphic Multi-Resolution Deep Learning Registration for  Applications in Breast MRI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=French%2C+M+G">Matthew G. French</a>, 
<a href="/search/eess?searchtype=author&query=Talou%2C+G+D+M">Gonzalo D. Maso Talou</a>, 
<a href="/search/eess?searchtype=author&query=Gamage%2C+T+P+B">Thiranja P. Babarenda Gamage</a>, 
<a href="/search/eess?searchtype=author&query=Nash%2C+M+P">Martyn P. Nash</a>, 
<a href="/search/eess?searchtype=author&query=Nielsen%2C+P+M">Poul M. Nielsen</a>, 
<a href="/search/eess?searchtype=author&query=Doyle%2C+A+J">Anthony J. Doyle</a>, 
<a href="/search/eess?searchtype=author&query=Iglesias%2C+J+E">Juan Eugenio Iglesias</a>, 
<a href="/search/eess?searchtype=author&query=Balbastre%2C+Y">Ya&#xeb;l Balbastre</a>, 
<a href="/search/eess?searchtype=author&query=Young%2C+S+I">Sean I. Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">In breast surgical planning, accurate registration of MR images across
patient positions has the potential to improve the localisation of tumours
during breast cancer treatment. While learning-based registration methods have
recently become the state-of-the-art approach for most medical image
registration tasks, these methods have yet to make inroads into breast image
registration due to certain difficulties-the lack of rich texture information
in breast MR images and the need for the deformations to be diffeomophic. In
this work, we propose learning strategies for breast MR image registration that
are amenable to diffeomorphic constraints, together with early experimental
results from in-silico and in-vivo experiments. One key contribution of this
work is a registration network which produces superior registration outcomes
for breast images in addition to providing diffeomorphic guarantees.
</p>
</div>
</dd>
<dt><a name="item638">[638]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13780" title="Abstract">arXiv:2309.13780</a> (cross-list from physics.ins-det) [<a href="/pdf/2309.13780" title="Download PDF">pdf</a>, <a href="/format/2309.13780" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modern Software Development for JUNO offline software
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Lin%2C+T">Tao Lin</a> (on behalf of the JUNO collaboration)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 2 figures, CHEP2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Instrumentation and Detectors (physics.ins-det)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">The Jiangmen Underground Neutrino Observatory (JUNO), under construction in
South China, primarily aims to determine the neutrino mass hierarchy and to
precise measure the neutrino oscillation parameters. The data-taking is
expected to start in 2024 and the detector plans to run for more than 20 years.
The development of the JUNO offline software (JUNOSW) started in 2012, and it
is quite challenging to maintain the JUNOSW for such a long time. In the last
ten years, tools such as Subversion, Trac, and CMT had been adopted for
software development. However, new stringent requirements came out, such as how
to reduce the building time for the whole project, how to deploy offline
algorithms to an online environment, and how to improve the code quality with
code review and continuous integration. To meet the further requirements of
software development, modern development tools are evaluated for JUNOSW, such
as Git, GitLab, CMake, Docker, and Kubernetes. This contribution will present
the software development system based on these modern tools for JUNOSW and the
functionalities achieved: CMake macros are developed to simplify the build
instructions for users; CMake generator expressions are used to control the
build flags for the online and offline environments; a tool named git-junoenv
is developed to help users partially checkout and build the software; a script
is used to build and deploy the software on the CVMFS server; a Docker image
with CVMFS client installed is created for continuous integration; a GitLab
agent is set up to manage GitLab runners in Kubernetes with all the
configurations in a GitLab repository.
</p>
</div>
</dd>
<dt><a name="item639">[639]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13817" title="Abstract">arXiv:2309.13817</a> (cross-list from eess.IV) [<a href="/pdf/2309.13817" title="Download PDF">pdf</a>, <a href="/format/2309.13817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MMA-Net: Multiple Morphology-Aware Network for Automated Cobb Angle  Measurement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiu%2C+Z">Zhengxuan Qiu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jie Yang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiankun Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Scoliosis diagnosis and assessment depend largely on the measurement of the
Cobb angle in spine X-ray images. With the emergence of deep learning
techniques that employ landmark detection, tilt prediction, and spine
segmentation, automated Cobb angle measurement has become increasingly popular.
However, these methods encounter difficulties such as high noise sensitivity,
intricate computational procedures, and exclusive reliance on a single type of
morphological information. In this paper, we introduce the Multiple
Morphology-Aware Network (MMA-Net), a novel framework that improves Cobb angle
measurement accuracy by integrating multiple spine morphology as attention
information. In the MMA-Net, we first feed spine X-ray images into the
segmentation network to produce multiple morphological information (spine
region, centerline, and boundary) and then concatenate the original X-ray image
with the resulting segmentation maps as input for the regression module to
perform precise Cobb angle measurement. Furthermore, we devise joint loss
functions for our segmentation and regression network training, respectively.
We evaluate our method on the AASCE challenge dataset and achieve superior
performance with the SMAPE of 7.28% and the MAE of 3.18{\deg}, indicating a
strong competitiveness compared to other outstanding methods. Consequently, we
can offer clinicians automated, efficient, and reliable Cobb angle measurement.
</p>
</div>
</dd>
<dt><a name="item640">[640]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13819" title="Abstract">arXiv:2309.13819</a> (cross-list from eess.AS) [<a href="/pdf/2309.13819" title="Download PDF">pdf</a>, <a href="/format/2309.13819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Step Approach for Narrowband Source Localization in Reverberant  Rooms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lai%2C+W">Wei-Ting Lai</a>, 
<a href="/search/eess?searchtype=author&query=Birnie%2C+L">Lachlan Birnie</a>, 
<a href="/search/eess?searchtype=author&query=Abhayapala%2C+T">Thushara Abhayapala</a>, 
<a href="/search/eess?searchtype=author&query=Bastine%2C+A">Amy Bastine</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+S">Shaoheng Xu</a>, 
<a href="/search/eess?searchtype=author&query=Samarasinghe%2C+P">Prasanga Samarasinghe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This paper presents a two-step approach for narrowband source localization
within reverberant rooms. The first step involves dereverberation by modeling
the homogeneous component of the sound field by an equivalent decomposition of
planewaves using Iteratively Reweighted Least Squares (IRLS), while the second
step focuses on source localization by modeling the dereverberated component as
a sparse representation of point-source distribution using Orthogonal Matching
Pursuit (OMP). The proposed method enhances localization accuracy with fewer
measurements, particularly in environments with strong reverberation. A
numerical simulation in a conference room scenario, using a uniform microphone
array affixed to the wall, demonstrates real-world feasibility. Notably, the
proposed method and microphone placement effectively localize sound sources
within the 2D-horizontal plane without requiring prior knowledge of boundary
conditions and room geometry, making it versatile for application in different
room types.
</p>
</div>
</dd>
<dt><a name="item641">[641]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13825" title="Abstract">arXiv:2309.13825</a> (cross-list from stat.ML) [<a href="/pdf/2309.13825" title="Download PDF">pdf</a>, <a href="/format/2309.13825" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NSOTree: Neural Survival Oblique Tree
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sun%2C+X">Xiaotong Sun</a>, 
<a href="/search/stat?searchtype=author&query=Qiu%2C+P">Peijie Qiu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Methodology (stat.ME)

</div>
<p class="mathjax">Survival analysis is a statistical method employed to scrutinize the duration
until a specific event of interest transpires, known as time-to-event
information characterized by censorship. Recently, deep learning-based methods
have dominated this field due to their representational capacity and
state-of-the-art performance. However, the black-box nature of the deep neural
network hinders its interpretability, which is desired in real-world survival
applications but has been largely neglected by previous works. In contrast,
conventional tree-based methods are advantageous with respect to
interpretability, while consistently grappling with an inability to approximate
the global optima due to greedy expansion. In this paper, we leverage the
strengths of both neural networks and tree-based methods, capitalizing on their
ability to approximate intricate functions while maintaining interpretability.
To this end, we propose a Neural Survival Oblique Tree (NSOTree) for survival
analysis. Specifically, the NSOTree was derived from the ReLU network and can
be easily incorporated into existing survival models in a plug-and-play
fashion. Evaluations on both simulated and real survival datasets demonstrated
the effectiveness of the proposed method in terms of performance and
interpretability.
</p>
</div>
</dd>
<dt><a name="item642">[642]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13835" title="Abstract">arXiv:2309.13835</a> (cross-list from eess.IV) [<a href="/pdf/2309.13835" title="Download PDF">pdf</a>, <a href="/format/2309.13835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> IBVC: Interpolation-driven B-frame Video Compression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Meiqin Liu</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+C">Chenming Xu</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+C">Chao Yao</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+W">Weisi Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+Y">Yao Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE TCSVT
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Learned B-frame video compression aims to adopt bi-directional motion
estimation and motion compensation (MEMC) coding for middle frame
reconstruction. However, previous learned approaches often directly extend
neural P-frame codecs to B-frame relying on bi-directional optical-flow
estimation or video frame interpolation. They suffer from inaccurate quantized
motions and inefficient motion compensation. To address these issues, we
propose a simple yet effective structure called Interpolation-driven B-frame
Video Compression (IBVC). Our approach only involves two major operations:
video frame interpolation and artifact reduction compression. IBVC introduces a
bit-rate free MEMC based on interpolation, which avoids optical-flow
quantization and additional compression distortions. Later, to reduce duplicate
bit-rate consumption and focus on unaligned artifacts, a residual guided
masking encoder is deployed to adaptively select the meaningful contexts with
interpolated multi-scale dependencies. In addition, a conditional
spatio-temporal decoder is proposed to eliminate location errors and artifacts
instead of using MEMC coding in other methods. The experimental results on
B-frame coding demonstrate that IBVC has significant improvements compared to
the relevant state-of-the-art methods. Meanwhile, our approach can save bit
rates compared with the random access (RA) configuration of H.266 (VTM). The
code will be available at https://github.com/ruhig6/IBVC.
</p>
</div>
</dd>
<dt><a name="item643">[643]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13838" title="Abstract">arXiv:2309.13838</a> (cross-list from stat.AP) [<a href="/pdf/2309.13838" title="Download PDF">pdf</a>, <a href="/format/2309.13838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalized Principal Component Analysis using Nesterov Smoothing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hurwitz%2C+R+M">Rebecca M. Hurwitz</a>, 
<a href="/search/stat?searchtype=author&query=Hahn%2C+G">Georg Hahn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures (10 files)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA); Genomics (q-bio.GN); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Principal components computed via PCA (principal component analysis) are
traditionally used to reduce dimensionality in genomic data or to correct for
population stratification. In this paper, we explore the penalized eigenvalue
problem (PEP) which reformulates the computation of the first eigenvector as an
optimization problem and adds an L1 penalty constraint. The contribution of our
article is threefold. First, we extend PEP by applying Nesterov smoothing to
the original LASSO-type L1 penalty. This allows one to compute analytical
gradients which enable faster and more efficient minimization of the objective
function associated with the optimization problem. Second, we demonstrate how
higher order eigenvectors can be calculated with PEP using established results
from singular value decomposition (SVD). Third, using data from the 1000 Genome
Project dataset, we empirically demonstrate that our proposed smoothed PEP
allows one to increase numerical stability and obtain meaningful eigenvectors.
We further investigate the utility of the penalized eigenvector approach over
traditional PCA.
</p>
</div>
</dd>
<dt><a name="item644">[644]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13839" title="Abstract">arXiv:2309.13839</a> (cross-list from eess.IV) [<a href="/pdf/2309.13839" title="Download PDF">pdf</a>, <a href="/format/2309.13839" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fill the K-Space and Refine the Image: Prompting for Dynamic and  Multi-Contrast MRI Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xin%2C+B">Bingyu Xin</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+M">Meng Ye</a>, 
<a href="/search/eess?searchtype=author&query=Axel%2C+L">Leon Axel</a>, 
<a href="/search/eess?searchtype=author&query=Metaxas%2C+D+N">Dimitris N. Metaxas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> STACOM 2023; Code is available at <a href="https://github.com/hellopipu/PromptMR">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The key to dynamic or multi-contrast magnetic resonance imaging (MRI)
reconstruction lies in exploring inter-frame or inter-contrast information.
Currently, the unrolled model, an approach combining iterative MRI
reconstruction steps with learnable neural network layers, stands as the
best-performing method for MRI reconstruction. However, there are two main
limitations to overcome: firstly, the unrolled model structure and GPU memory
constraints restrict the capacity of each denoising block in the network,
impeding the effective extraction of detailed features for reconstruction;
secondly, the existing model lacks the flexibility to adapt to variations in
the input, such as different contrasts, resolutions or views, necessitating the
training of separate models for each input type, which is inefficient and may
lead to insufficient reconstruction. In this paper, we propose a two-stage MRI
reconstruction pipeline to address these limitations. The first stage involves
filling the missing k-space data, which we approach as a physics-based
reconstruction problem. We first propose a simple yet efficient baseline model,
which utilizes adjacent frames/contrasts and channel attention to capture the
inherent inter-frame/-contrast correlation. Then, we extend the baseline model
to a prompt-based learning approach, PromptMR, for all-in-one MRI
reconstruction from different views, contrasts, adjacent types, and
acceleration factors. The second stage is to refine the reconstruction from the
first stage, which we treat as a general video restoration problem to further
fuse features from neighboring frames/contrasts in the image domain. Extensive
experiments show that our proposed method significantly outperforms previous
state-of-the-art accelerated MRI reconstruction methods.
</p>
</div>
</dd>
<dt><a name="item645">[645]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13850" title="Abstract">arXiv:2309.13850</a> (cross-list from stat.ML) [<a href="/pdf/2309.13850" title="Download PDF">pdf</a>, <a href="/ps/2309.13850" title="Download PostScript">ps</a>, <a href="/format/2309.13850" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Statistical Perspective of Top-K Sparse Softmax Gating Mixture of  Experts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+H">Huy Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=Akbarian%2C+P">Pedram Akbarian</a>, 
<a href="/search/stat?searchtype=author&query=Yan%2C+F">Fanqi Yan</a>, 
<a href="/search/stat?searchtype=author&query=Ho%2C+N">Nhat Ho</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Top-K sparse softmax gating mixture of experts has been widely used for
scaling up massive deep-learning architectures without increasing the
computational cost. Despite its popularity in real-world applications, the
theoretical understanding of that gating function has remained an open problem.
The main challenge comes from the structure of the top-K sparse softmax gating
function, which partitions the input space into multiple regions with distinct
behaviors. By focusing on a Gaussian mixture of experts, we establish
theoretical results on the effects of the top-K sparse softmax gating function
on both density and parameter estimations. Our results hinge upon defining
novel loss functions among parameters to capture different behaviors of the
input regions. When the true number of experts $k_{\ast}$ is known, we
demonstrate that the convergence rates of density and parameter estimations are
both parametric on the sample size. However, when $k_{\ast}$ becomes unknown
and the true model is over-specified by a Gaussian mixture of $k$ experts where
$k &gt; k_{\ast}$, our findings suggest that the number of experts selected from
the top-K sparse softmax gating function must exceed the total cardinality of a
certain number of Voronoi cells associated with the true parameters to
guarantee the convergence of the density estimation. Moreover, while the
density estimation rate remains parametric under this setting, the parameter
estimation rates become substantially slow due to an intrinsic interaction
between the softmax gating and expert functions.
</p>
</div>
</dd>
<dt><a name="item646">[646]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13872" title="Abstract">arXiv:2309.13872</a> (cross-list from eess.IV) [<a href="/pdf/2309.13872" title="Download PDF">pdf</a>, <a href="/format/2309.13872" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention and Pooling based Sigmoid Colon Segmentation in 3D CT images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rahman%2C+M+A">Md Akizur Rahman</a>, 
<a href="/search/eess?searchtype=author&query=Singh%2C+S">Sonit Singh</a>, 
<a href="/search/eess?searchtype=author&query=Shanmugalingam%2C+K">Kuruparan Shanmugalingam</a>, 
<a href="/search/eess?searchtype=author&query=Iyer%2C+S">Sankaran Iyer</a>, 
<a href="/search/eess?searchtype=author&query=Blair%2C+A">Alan Blair</a>, 
<a href="/search/eess?searchtype=author&query=Ravindran%2C+P">Praveen Ravindran</a>, 
<a href="/search/eess?searchtype=author&query=Sowmya%2C+A">Arcot Sowmya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 Pages, 6 figures, Accepted at IEEE DICTA 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Segmentation of the sigmoid colon is a crucial aspect of treating
diverticulitis. It enables accurate identification and localisation of
inflammation, which in turn helps healthcare professionals make informed
decisions about the most appropriate treatment options. This research presents
a novel deep learning architecture for segmenting the sigmoid colon from
Computed Tomography (CT) images using a modified 3D U-Net architecture. Several
variations of the 3D U-Net model with modified hyper-parameters were examined
in this study. Pyramid pooling (PyP) and channel-spatial Squeeze and Excitation
(csSE) were also used to improve the model performance. The networks were
trained using manually annotated sigmoid colon. A five-fold cross-validation
procedure was used on a test dataset to evaluate the network's performance. As
indicated by the maximum Dice similarity coefficient (DSC) of 56.92+/-1.42%,
the application of PyP and csSE techniques improves segmentation precision. We
explored ensemble methods including averaging, weighted averaging, majority
voting, and max ensemble. The results show that average and majority voting
approaches with a threshold value of 0.5 and consistent weight distribution
among the top three models produced comparable and optimal results with DSC of
88.11+/-3.52%. The results indicate that the application of a modified 3D U-Net
architecture is effective for segmenting the sigmoid colon in Computed
Tomography (CT) images. In addition, the study highlights the potential
benefits of integrating ensemble methods to improve segmentation precision.
</p>
</div>
</dd>
<dt><a name="item647">[647]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13874" title="Abstract">arXiv:2309.13874</a> (cross-list from eess.AS) [<a href="/pdf/2309.13874" title="Download PDF">pdf</a>, <a href="/format/2309.13874" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion Conditional Expectation Model for Efficient and Robust Target  Speech Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Leying Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yao Qian</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+L">Linfeng Yu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Heming Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xinkai Wang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+H">Hemin Yang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+L">Long Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Shujie Liu</a>, 
<a href="/search/eess?searchtype=author&query=Qian%2C+Y">Yanmin Qian</a>, 
<a href="/search/eess?searchtype=author&query=Zeng%2C+M">Michael Zeng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Target Speech Extraction (TSE) is a crucial task in speech processing that
focuses on isolating the clean speech of a specific speaker from complex
mixtures. While discriminative methods are commonly used for TSE, they can
introduce distortion in terms of speech perception quality. On the other hand,
generative approaches, particularly diffusion-based methods, can enhance speech
quality perceptually but suffer from slower inference speed. We propose an
efficient generative approach named Diffusion Conditional Expectation Model
(DCEM) for TSE. It can handle multi- and single-speaker scenarios in both noisy
and clean conditions. Additionally, we introduce Regenerate-DCEM (R-DCEM) that
can regenerate and optimize speech quality based on pre-processed speech from a
discriminative model. Our method outperforms conventional methods in terms of
both intrusive and non-intrusive metrics and demonstrates notable strengths in
inference efficiency and robustness to unseen tasks. Audio examples are
available online (https://vivian556123.github.io/dcem).
</p>
</div>
</dd>
<dt><a name="item648">[648]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13905" title="Abstract">arXiv:2309.13905</a> (cross-list from eess.AS) [<a href="/pdf/2309.13905" title="Download PDF">pdf</a>, <a href="/format/2309.13905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoPrep: An Automatic Preprocessing Framework for In-the-Wild Speech  Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jianwei Yu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hangting Chen</a>, 
<a href="/search/eess?searchtype=author&query=Bian%2C+Y">Yanyao Bian</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/eess?searchtype=author&query=Luo%2C+Y">Yi Luo</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+J">Jinchuan Tian</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengyang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+J">Jiayi Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shuai Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Recently, the utilization of extensive open-sourced text data has
significantly advanced the performance of text-based large language models
(LLMs). However, the use of in-the-wild large-scale speech data in the speech
technology community remains constrained. One reason for this limitation is
that a considerable amount of the publicly available speech data is compromised
by background noise, speech overlapping, lack of speech segmentation
information, missing speaker labels, and incomplete transcriptions, which can
largely hinder their usefulness. On the other hand, human annotation of speech
data is both time-consuming and costly. To address this issue, we introduce an
automatic in-the-wild speech data preprocessing framework (AutoPrep) in this
paper, which is designed to enhance speech quality, generate speaker labels,
and produce transcriptions automatically. The proposed AutoPrep framework
comprises six components: speech enhancement, speech segmentation, speaker
clustering, target speech extraction, quality filtering and automatic speech
recognition. Experiments conducted on the open-sourced WenetSpeech and our
self-collected AutoPrepWild corpora demonstrate that the proposed AutoPrep
framework can generate preprocessed data with similar DNSMOS and PDNSMOS scores
compared to several open-sourced TTS datasets. The corresponding TTS system can
achieve up to 0.68 in-domain speaker similarity.
</p>
</div>
</dd>
<dt><a name="item649">[649]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13916" title="Abstract">arXiv:2309.13916</a> (cross-list from eess.AS) [<a href="/pdf/2309.13916" title="Download PDF">pdf</a>, <a href="/format/2309.13916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frame-wise streaming end-to-end speaker diarization with  non-autoregressive self-attention-based attractors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liang%2C+D">Di Liang</a>, 
<a href="/search/eess?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">This work proposes a frame-wise online/streaming end-to-end neural
diarization (FS-EEND) method in a frame-in-frame-out fashion. To frame-wisely
detect a flexible number of speakers and extract/update their corresponding
attractors, we propose to leverage a causal speaker embedding encoder and an
online non-autoregressive self-attention-based attractor decoder. A look-ahead
mechanism is adopted to allow leveraging some future frames for effectively
detecting new speakers in real time and adaptively updating speaker attractors.
The proposed method processes the audio stream frame by frame, and has a low
inference latency caused by the look-ahead frames. Experiments show that,
compared with the recently proposed block-wise online methods, our method
FS-EEND achieves state-of-the-art diarization results, with a low inference
latency and computational cost.
</p>
</div>
</dd>
<dt><a name="item650">[650]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13928" title="Abstract">arXiv:2309.13928</a> (cross-list from math.GR) [<a href="/pdf/2309.13928" title="Download PDF">pdf</a>, <a href="/ps/2309.13928" title="Download PostScript">ps</a>, <a href="/format/2309.13928" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cryptanalysis of protocols using (Simultaneous) Conjugacy Search Problem  in certain Metabelian Platform Groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kahrobaei%2C+D">Delaram Kahrobaei</a>, 
<a href="/search/math?searchtype=author&query=Monetta%2C+C">Carmine Monetta</a>, 
<a href="/search/math?searchtype=author&query=Perret%2C+L">Ludovic Perret</a>, 
<a href="/search/math?searchtype=author&query=Tota%2C+M">Maria Tota</a>, 
<a href="/search/math?searchtype=author&query=Vigorito%2C+M">Martina Vigorito</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Group Theory (math.GR)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">There are many group-based cryptosystems in which the security relies on the
difficulty of solving Conjugacy Search Problem (CSP) and Simultaneous Conjugacy
Search Problem (SCSP) in their underlying platform groups. In this paper we
give a cryptanalysis of these systems which use certain semidirect product of
abelian groups.
</p>
</div>
</dd>
<dt><a name="item651">[651]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13938" title="Abstract">arXiv:2309.13938</a> (cross-list from eess.AS) [<a href="/pdf/2309.13938" title="Download PDF">pdf</a>, <a href="/ps/2309.13938" title="Download PostScript">ps</a>, <a href="/format/2309.13938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Evaluating Classification Systems Against Soft Labels with Fuzzy  Precision and Recall
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Harju%2C+M">Manu Harju</a>, 
<a href="/search/eess?searchtype=author&query=Mesaros%2C+A">Annamaria Mesaros</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> published in DCASE 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Classification systems are normally trained by minimizing the cross-entropy
between system outputs and reference labels, which makes the Kullback-Leibler
divergence a natural choice for measuring how closely the system can follow the
data. Precision and recall provide another perspective for measuring the
performance of a classification system. Non-binary references can arise from
various sources, and it is often beneficial to use the soft labels for training
instead of the binarized data. However, the existing definitions for precision
and recall require binary reference labels, and binarizing the data can cause
erroneous interpretations. We present a novel method to calculate precision,
recall and F-score without quantizing the data. The proposed metrics extend the
well established metrics as the definitions coincide when used with binary
labels. To understand the behavior of the metrics we show simple example cases
and an evaluation of different sound event detection models trained on real
data with soft labels.
</p>
</div>
</dd>
<dt><a name="item652">[652]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13957" title="Abstract">arXiv:2309.13957</a> (cross-list from q-bio.BM) [<a href="/pdf/2309.13957" title="Download PDF">pdf</a>, <a href="/format/2309.13957" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beam Enumeration: Probabilistic Explainability For Sample Efficient  Self-conditioned Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+J">Jeff Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Schwaller%2C+P">Philippe Schwaller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Generative molecular design has moved from proof-of-concept to real-world
applicability, as marked by the surge in very recent papers reporting
experimental validation. Key challenges in explainability and sample efficiency
present opportunities to enhance generative design to directly optimize
expensive high-fidelity oracles and provide actionable insights to domain
experts. Here, we propose Beam Enumeration to exhaustively enumerate the most
probable sub-sequences from language-based molecular generative models and show
that molecular substructures can be extracted. When coupled with reinforcement
learning, extracted substructures become meaningful, providing a source of
explainability and improving sample efficiency through self-conditioned
generation. Beam Enumeration is generally applicable to any language-based
molecular generative model and notably further improves the performance of the
recently reported Augmented Memory algorithm, which achieved the new
state-of-the-art on the Practical Molecular Optimization benchmark for sample
efficiency. The combined algorithm generates more high reward molecules and
faster, given a fixed oracle budget. Beam Enumeration is the first method to
jointly address explainability and sample efficiency for molecular design.
</p>
</div>
</dd>
<dt><a name="item653">[653]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13963" title="Abstract">arXiv:2309.13963</a> (cross-list from eess.AS) [<a href="/pdf/2309.13963" title="Download PDF">pdf</a>, <a href="/format/2309.13963" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting Speech Encoder and Large Language Model for ASR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+W">Wenyi Yu</a>, 
<a href="/search/eess?searchtype=author&query=Tang%2C+C">Changli Tang</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+G">Guangzhi Sun</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xianzhao Chen</a>, 
<a href="/search/eess?searchtype=author&query=Tan%2C+T">Tian Tan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+L">Lu Lu</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+Z">Zejun Ma</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">The impressive capability and versatility of large language models (LLMs)
have aroused increasing attention in automatic speech recognition (ASR), with
several pioneering studies attempting to build integrated ASR models by
connecting a speech encoder with an LLM. This paper presents a comparative
study of three commonly used structures as connectors, including fully
connected layers, multi-head cross-attention, and Q-Former. Speech encoders
from the Whisper model series as well as LLMs from the Vicuna model series with
different model sizes were studied. Experiments were performed on the commonly
used LibriSpeech, Common Voice, and GigaSpeech datasets, where the LLMs with
Q-Formers demonstrated consistent and considerable word error rate (WER)
reductions over LLMs with other connector structures. Q-Former-based LLMs can
generalise well to out-of-domain datasets, where 12% relative WER reductions
over the Whisper baseline ASR model were achieved on the Eval2000 test set
without using any in-domain training data from Switchboard. Moreover, a novel
segment-level Q-Former is proposed to enable LLMs to recognise speech segments
with a duration exceeding the limitation of the encoders, which results in 17%
relative WER reductions over other connector structures on 90-second-long
speech data.
</p>
</div>
</dd>
<dt><a name="item654">[654]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13980" title="Abstract">arXiv:2309.13980</a> (cross-list from eess.IV) [<a href="/pdf/2309.13980" title="Download PDF">pdf</a>, <a href="/format/2309.13980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Better Generalization of White Matter Tract Segmentation to Arbitrary  Datasets with Scaled Residual Bootstrap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wan Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ye%2C+C">Chuyang Ye</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">White matter (WM) tract segmentation is a crucial step for brain connectivity
studies. It is performed on diffusion magnetic resonance imaging (dMRI), and
deep neural networks (DNNs) have achieved promising segmentation accuracy.
Existing DNN-based methods use an annotated dataset for model training.
However, the performance of the trained model on a different test dataset may
not be optimal due to distribution shift, and it is desirable to design WM
tract segmentation approaches that allow better generalization of the
segmentation model to arbitrary test datasets. In this work, we propose a WM
tract segmentation approach that improves the generalization with scaled
residual bootstrap. The difference between dMRI scans in training and test
datasets is most noticeably caused by the different numbers of diffusion
gradients and noise levels. Since both of them lead to different
signal-to-noise ratios (SNRs) between the training and test data, we propose to
augment the training scans by adjusting the noise magnitude and develop an
adapted residual bootstrap strategy for the augmentation. To validate the
proposed approach, two dMRI datasets were used, and the experimental results
show that our method consistently improved the generalization of WM tract
segmentation under various settings.
</p>
</div>
</dd>
<dt><a name="item655">[655]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13984" title="Abstract">arXiv:2309.13984</a> (cross-list from eess.SP) [<a href="/pdf/2309.13984" title="Download PDF">pdf</a>, <a href="/format/2309.13984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Near-field Hybrid Beamforming for Terahertz-band Integrated Sensing and  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elbir%2C+A+M">Ahmet M. Elbir</a>, 
<a href="/search/eess?searchtype=author&query=Celik%2C+A">Abdulkadir Celik</a>, 
<a href="/search/eess?searchtype=author&query=Eltawil%2C+A+M">Ahmed M. Eltawil</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted Paper in 2023 IEEE Global Communications Conference (GLOBECOM), Kuala Lumpur, Malaysia, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Terahertz (THz) band communications and integrated sensing and communications
(ISAC) are two main facets of the sixth generation wireless networks. In order
to compensate the severe attenuation, the THz wireless systems employ large
arrays, wherein the near-field beam-squint severely degrades the beamforming
accuracy. Contrary to prior works that examine only either narrowband ISAC
beamforming or far-field models, we introduce an alternating optimization
technique for hybrid beamforming design in near-field THz-ISAC scenario. We
also propose an efficient approach to compensate near-field beam-squint via
baseband beamformers. Via numerical simulations, we show that the proposed
approach achieves satisfactory spectral efficiency performance while accurately
estimating the near-field beamformers and mitigating the beam-squint without
additional hardware components.
</p>
</div>
</dd>
<dt><a name="item656">[656]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13994" title="Abstract">arXiv:2309.13994</a> (cross-list from eess.AS) [<a href="/pdf/2309.13994" title="Download PDF">pdf</a>, <a href="/format/2309.13994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Accent Adaptation Through Masked Language Model Correction  Of Discrete Self-Supervised Speech Units
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Poncelet%2C+J">Jakob Poncelet</a>, 
<a href="/search/eess?searchtype=author&query=Van+hamme%2C+H">Hugo Van hamme</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Self-supervised pre-trained speech models have strongly improved speech
recognition, yet they are still sensitive to domain shifts and accented or
atypical speech. Many of these models rely on quantisation or clustering to
learn discrete acoustic units. We propose to correct the discovered discrete
units for accented speech back to a standard pronunciation in an unsupervised
manner. A masked language model is trained on discrete units from a standard
accent and iteratively corrects an accented token sequence by masking
unexpected cluster sequences and predicting their common variant. Small accent
adapter blocks are inserted in the pre-trained model and fine-tuned by
predicting the corrected clusters, which leads to an increased robustness of
the pre-trained model towards a target accent, and this without supervision. We
are able to improve a state-of-the-art HuBERT Large model on a downstream
accented speech recognition task by altering the training regime with the
proposed method.
</p>
</div>
</dd>
<dt><a name="item657">[657]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14008" title="Abstract">arXiv:2309.14008</a> (cross-list from eess.SP) [<a href="/pdf/2309.14008" title="Download PDF">pdf</a>, <a href="/format/2309.14008" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Carrier Aggregation Enabled Integrated Sensing and Communication Signal  Design and Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wei%2C+Z">Zhiqing Wei</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Haotian Liu</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xinyi Yang</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+W">Wangjun Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+H">Huici Wu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xingwang Li</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+Z">Zhiyong Feng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The future mobile communication systems will support intelligent applications
such as Internet of Vehicles (IoV) and Extended Reality (XR). Integrated
Sensing and Communication (ISAC) is regarded as one of the key technologies
satisfying the high data rate communication and highly accurate sensing for
these intelligent applications in future mobile communication systems. With the
explosive growth of wireless devices and services, the shortage of spectrum
resources leads to the fragmentation of available frequency bands for ISAC
systems, which degrades sensing performance. Facing the above challenges, this
paper proposes a Carrier Aggregation (CA)-based ISAC signal aggregating high
and low-frequency bands to improve the sensing performance, where the CA-based
ISAC signal can use four different aggregated pilot structures for sensing.
Then, an ISAC signal processing algorithm with Compressed Sensing (CS) is
proposed and the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) is
used to solve the reconfiguration convex optimization problem. Finally, the
Cram'er-Rao Lower Bounds (CRLBs) are derived for the CA-based ISAC signal.
Simulation results show that CA efficiently improves the accuracy of range and
velocity estimation.
</p>
</div>
</dd>
<dt><a name="item658">[658]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14019" title="Abstract">arXiv:2309.14019</a> (cross-list from math.CO) [<a href="/pdf/2309.14019" title="Download PDF">pdf</a>, <a href="/format/2309.14019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a class of strong valid inequalities for the connected matching  polytope
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Samer%2C+P">Phillippe Samer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 1 figure. Submitted for publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
<p class="mathjax">We identify a family of $O(|E(G)|^2)$ nontrivial facets of the connected
matching polytope of a graph $G$, that is, the convex hull of incidence vectors
of matchings in $G$ whose covered vertices induce a connected subgraph.
Accompanying software to further inspect the polytope of an input graph is
available.
</p>
</div>
</dd>
<dt><a name="item659">[659]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14047" title="Abstract">arXiv:2309.14047</a> (cross-list from cond-mat.dis-nn) [<a href="/pdf/2309.14047" title="Download PDF">pdf</a>, <a href="/format/2309.14047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random-Energy Secret Sharing via Extreme Synergy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Ngampruetikorn%2C+V">Vudtiwat Ngampruetikorn</a>, 
<a href="/search/cond-mat?searchtype=author&query=Schwab%2C+D+J">David J. Schwab</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Disordered Systems and Neural Networks (cond-mat.dis-nn)</span>; Statistical Mechanics (cond-mat.stat-mech); Cryptography and Security (cs.CR); Information Theory (cs.IT)

</div>
<p class="mathjax">The random-energy model (REM), a solvable spin-glass model, has impacted an
incredibly diverse set of problems, from protein folding to combinatorial
optimization to many-body localization. Here, we explore a new connection to
secret sharing. We formulate a secret-sharing scheme, based on the REM, and
analyze its information-theoretic properties. Our analyses reveal that the
correlations between subsystems of the REM are highly synergistic and form the
basis for secure secret-sharing schemes. We derive the ranges of temperatures
and secret lengths over which the REM satisfies the requirement of secure
secret sharing. We show further that a special point in the phase diagram
exists at which the REM-based scheme is optimal in its information encoding.
Our analytical results for the thermodynamic limit are in good qualitative
agreement with numerical simulations of finite systems, for which the strict
security requirement is replaced by a tradeoff between secrecy and
recoverability. Our work offers a further example of information theory as a
unifying concept, connecting problems in statistical physics to those in
computation.
</p>
</div>
</dd>
<dt><a name="item660">[660]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14073" title="Abstract">arXiv:2309.14073</a> (cross-list from stat.ML) [<a href="/pdf/2309.14073" title="Download PDF">pdf</a>, <a href="/ps/2309.14073" title="Download PostScript">ps</a>, <a href="/format/2309.14073" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Maximum Likelihood Estimation of Latent Variable Structural Equation  Models: A Neural Network Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Saremi%2C+M">Mehrzad Saremi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Probability (math.PR)

</div>
<p class="mathjax">We propose a graphical structure for structural equation models that is
stable under marginalization under linearity and Gaussianity assumptions. We
show that computing the maximum likelihood estimation of this model is
equivalent to training a neural network. We implement a GPU-based algorithm
that computes the maximum likelihood estimation of these models.
</p>
</div>
</dd>
<dt><a name="item661">[661]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14080" title="Abstract">arXiv:2309.14080</a> (cross-list from eess.AS) [<a href="/pdf/2309.14080" title="Download PDF">pdf</a>, <a href="/format/2309.14080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Detection of Pathological Voice using Glottal Source  Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kadiri%2C+S+R">Sudarsana Reddy Kadiri</a>, 
<a href="/search/eess?searchtype=author&query=Alku%2C+P">Paavo Alku</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Journal of Selected Topics in Signal Processing, Vol. 14, No.
  2, pp. 367-379, February 2020
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Automatic detection of voice pathology enables objective assessment and
earlier intervention for the diagnosis. This study provides a systematic
analysis of glottal source features and investigates their effectiveness in
voice pathology detection. Glottal source features are extracted using glottal
flows estimated with the quasi-closed phase (QCP) glottal inverse filtering
method, using approximate glottal source signals computed with the zero
frequency filtering (ZFF) method, and using acoustic voice signals directly. In
addition, we propose to derive mel-frequency cepstral coefficients (MFCCs) from
the glottal source waveforms computed by QCP and ZFF to effectively capture the
variations in glottal source spectra of pathological voice. Experiments were
carried out using two databases, the Hospital Universitario Principe de
Asturias (HUPA) database and the Saarbrucken Voice Disorders (SVD) database.
Analysis of features revealed that the glottal source contains information that
discriminates normal and pathological voice. Pathology detection experiments
were carried out using support vector machine (SVM). From the detection
experiments it was observed that the performance achieved with the studied
glottal source features is comparable or better than that of conventional MFCCs
and perceptual linear prediction (PLP) features. The best detection performance
was achieved when the glottal source features were combined with the
conventional MFCCs and PLP features, which indicates the complementary nature
of the features.
</p>
</div>
</dd>
<dt><a name="item662">[662]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14089" title="Abstract">arXiv:2309.14089</a> (cross-list from eess.AS) [<a href="/pdf/2309.14089" title="Download PDF">pdf</a>, <a href="/format/2309.14089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BiSinger: Bilingual Singing Voice Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Huali Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yueqian Lin</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+Y">Yao Shi</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+P">Peng Sun</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASRU2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Although Singing Voice Synthesis (SVS) has made great strides with
Text-to-Speech (TTS) techniques, multilingual singing voice modeling remains
relatively unexplored. This paper presents BiSinger, a bilingual SVS system for
English and Chinese Mandarin. Current systems require separate models per
language and cannot accurately represent both Chinese and English, hindering
code-switch SVS. To address this gap, we design a shared representation between
Chinese and English singing voices, achieved by using the CMU dictionary with
mapping rules. We fuse monolingual singing datasets with established singing
voice conversion techniques to generate bilingual singing voices while also
exploring the potential use of bilingual speech data. Experiments affirm that
our language-independent representation and incorporation of related datasets
enable a single model with enhanced performance in English and code-switch SVS
while maintaining Chinese song performance. Audio samples are available at
https://bisinger-svs.github.io.
</p>
</div>
</dd>
<dt><a name="item663">[663]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14103" title="Abstract">arXiv:2309.14103</a> (cross-list from math.CO) [<a href="/pdf/2309.14103" title="Download PDF">pdf</a>, <a href="/format/2309.14103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Upper clique transversals in graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Milani%C4%8D%2C+M">Martin Milani&#x10d;</a>, 
<a href="/search/math?searchtype=author&query=Uno%2C+Y">Yushi Uno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Full version of a WG 2023 paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">A clique transversal in a graph is a set of vertices intersecting all maximal
cliques. The problem of determining the minimum size of a clique transversal
has received considerable attention in the literature. In this paper, we
initiate the study of the "upper" variant of this parameter, the upper clique
transversal number, defined as the maximum size of a minimal clique
transversal. We investigate this parameter from the algorithmic and complexity
points of view, with a focus on various graph classes. We show that the
corresponding decision problem is NP-complete in the classes of chordal graphs,
chordal bipartite graphs, and line graphs of bipartite graphs, but solvable in
linear time in the classes of split graphs and proper interval graphs.
</p>
</div>
</dd>
<dt><a name="item664">[664]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14107" title="Abstract">arXiv:2309.14107</a> (cross-list from eess.AS) [<a href="/pdf/2309.14107" title="Download PDF">pdf</a>, <a href="/format/2309.14107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wav2vec-based Detection and Severity Level Classification of Dysarthria  from Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Javanmardi%2C+F">Farhad Javanmardi</a>, 
<a href="/search/eess?searchtype=author&query=Tirronen%2C+S">Saska Tirronen</a>, 
<a href="/search/eess?searchtype=author&query=Kodali%2C+M">Manila Kodali</a>, 
<a href="/search/eess?searchtype=author&query=Kadiri%2C+S+R">Sudarsana Reddy Kadiri</a>, 
<a href="/search/eess?searchtype=author&query=Alku%2C+P">Paavo Alku</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> in Proc. ICASSP, Rhodes Island, Greece, June 4-10, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">Automatic detection and severity level classification of dysarthria directly
from acoustic speech signals can be used as a tool in medical diagnosis. In
this work, the pre-trained wav2vec 2.0 model is studied as a feature extractor
to build detection and severity level classification systems for dysarthric
speech. The experiments were carried out with the popularly used UA-speech
database. In the detection experiments, the results revealed that the best
performance was obtained using the embeddings from the first layer of the
wav2vec model that yielded an absolute improvement of 1.23% in accuracy
compared to the best performing baseline feature (spectrogram). In the studied
severity level classification task, the results revealed that the embeddings
from the final layer gave an absolute improvement of 10.62% in accuracy
compared to the best baseline features (mel-frequency cepstral coefficients).
</p>
</div>
</dd>
<dt><a name="item665">[665]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14109" title="Abstract">arXiv:2309.14109</a> (cross-list from eess.AS) [<a href="/pdf/2309.14109" title="Download PDF">pdf</a>, <a href="/format/2309.14109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Haha-Pod: An Attempt for Laughter-based Non-Verbal Speaker Verification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuke Lin</a>, 
<a href="/search/eess?searchtype=author&query=Qin%2C+X">Xiaoyi Qin</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+N">Ning Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guoqing Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">It is widely acknowledged that discriminative representation for speaker
verification can be extracted from verbal speech. However, how much speaker
information that non-verbal vocalization carries is still a puzzle. This paper
explores speaker verification based on the most ubiquitous form of non-verbal
voice, laughter. First, we use a semi-automatic pipeline to collect a new
Haha-Pod dataset from open-source podcast media. The dataset contains over 240
speakers' laughter clips with corresponding high-quality verbal speech. Second,
we propose a Two-Stage Teacher-Student (2S-TS) framework to minimize the
within-speaker embedding distance between verbal and non-verbal (laughter)
signals. Considering Haha-Pod as a test set, two trials (S2L-Eval) are designed
to verify the speaker's identity through laugh sounds. Experimental results
demonstrate that our method can significantly improve the performance of the
S2L-Eval test set with only a minor degradation on the VoxCeleb1 test set. The
Haha-Pod dataset is open to access on
https://drive.google.com/file/d/1J-HBRTsm_yWrcbkXupy-tiWRt5gE2LzG/view?usp=drive_link.
</p>
</div>
</dd>
<dt><a name="item666">[666]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14113" title="Abstract">arXiv:2309.14113</a> (cross-list from hep-ph) [<a href="/pdf/2309.14113" title="Download PDF">pdf</a>, <a href="/format/2309.14113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HyperTrack: Neural Combinatorics for High Energy Physics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ph?searchtype=author&query=Mieskolainen%2C+M">Mikael Mieskolainen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CHEP 2023 proceedings. 8 pages (max)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Phenomenology (hep-ph)</span>; Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex)

</div>
<p class="mathjax">Combinatorial inverse problems in high energy physics span enormous
algorithmic challenges. This work presents a new deep learning driven
clustering algorithm that utilizes a space-time non-local trainable graph
constructor, a graph neural network, and a set transformer. The model is
trained with loss functions at the graph node, edge and object level, including
contrastive learning and meta-supervision. The algorithm can be applied to
problems such as charged particle tracking, calorimetry, pile-up
discrimination, jet physics, and beyond. We showcase the effectiveness of this
cutting-edge AI approach through particle tracking simulations. The code is
available online.
</p>
</div>
</dd>
<dt><a name="item667">[667]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14129" title="Abstract">arXiv:2309.14129</a> (cross-list from eess.AS) [<a href="/pdf/2309.14129" title="Download PDF">pdf</a>, <a href="/format/2309.14129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speaker anonymization using neural audio codec language models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Panariello%2C+M">Michele Panariello</a>, 
<a href="/search/eess?searchtype=author&query=Nespoli%2C+F">Francesco Nespoli</a>, 
<a href="/search/eess?searchtype=author&query=Todisco%2C+M">Massimiliano Todisco</a>, 
<a href="/search/eess?searchtype=author&query=Evans%2C+N">Nicholas Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The vast majority of approaches to speaker anonymization involve the
extraction of fundamental frequency estimates, linguistic features and a
speaker embedding which is perturbed to obfuscate the speaker identity before
an anonymized speech waveform is resynthesized using a vocoder. Recent work has
shown that x-vector transformations are difficult to control consistently:
other sources of speaker information contained within fundamental frequency and
linguistic features are re-entangled upon vocoding, meaning that anonymized
speech signals still contain speaker information. We propose an approach based
upon neural audio codecs (NACs), which are known to generate high-quality
synthetic speech when combined with language models. NACs use quantized codes,
which are known to effectively bottleneck speaker-related information: we
demonstrate the potential of speaker anonymization systems based on NAC
language modeling by applying the evaluation framework of the Voice Privacy
Challenge 2022.
</p>
</div>
</dd>
<dt><a name="item668">[668]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14141" title="Abstract">arXiv:2309.14141</a> (cross-list from quant-ph) [<a href="/pdf/2309.14141" title="Download PDF">pdf</a>, <a href="/format/2309.14141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Generalized Capacity of a Quantum Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Khanian%2C+Z+B">Zahra Baghali Khanian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">The transmission of classical information over a classical channel gave rise
to the classical capacity theorem with the optimal rate in terms of the
classical mutual information. Despite classical information being a subset of
quantum information, the rate of the quantum capacity problem is expressed in
terms of the coherent information, which does not mathematically generalize the
classical mutual information. Additionally, there are multiple capacity
theorems with distinct formulas when dealing with transmitting information over
a noisy quantum channel. This leads to the question of what constitutes a
mathematically accurate quantum generalization of classical mutual information
and whether there exists a quantum task that directly extends the classical
capacity problem. In this paper, we address these inquiries by introducing a
quantity called the generalized information, which serves as a mathematical
extension encompassing both classical mutual information and coherent
information. We define a transmission task, which includes as specific
instances both classical information and quantum information capacity problems,
and show that the transmission capacity of this task is characterized by the
generalized information.
</p>
</div>
</dd>
<dt><a name="item669">[669]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14155" title="Abstract">arXiv:2309.14155</a> (cross-list from math.OC) [<a href="/pdf/2309.14155" title="Download PDF">pdf</a>, <a href="/format/2309.14155" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extragradient Type Methods for Riemannian Variational Inequality  Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hu%2C+Z">Zihao Hu</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+G">Guanghui Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+X">Xi Wang</a>, 
<a href="/search/math?searchtype=author&query=Wibisono%2C+A">Andre Wibisono</a>, 
<a href="/search/math?searchtype=author&query=Abernethy%2C+J">Jacob Abernethy</a>, 
<a href="/search/math?searchtype=author&query=Tao%2C+M">Molei Tao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Riemannian convex optimization and minimax optimization have recently drawn
considerable attention. Their appeal lies in their capacity to adeptly manage
the non-convexity of the objective function as well as constraints inherent in
the feasible set in the Euclidean sense. In this work, we delve into monotone
Riemannian Variational Inequality Problems (RVIPs), which encompass both
Riemannian convex optimization and minimax optimization as particular cases. In
the context of Euclidean space, it is established that the last-iterates of
both the extragradient (EG) and past extragradient (PEG) methods converge to
the solution of monotone variational inequality problems at a rate of
$O\left(\frac{1}{\sqrt{T}}\right)$ (Cai et al., 2022). However, analogous
behavior on Riemannian manifolds remains an open question. To bridge this gap,
we introduce the Riemannian extragradient (REG) and Riemannian past
extragradient (RPEG) methods. We demonstrate that both exhibit
$O\left(\frac{1}{\sqrt{T}}\right)$ last-iterate convergence. Additionally, we
show that the average-iterate convergence of both REG and RPEG is
$O\left(\frac{1}{{T}}\right)$, aligning with observations in the Euclidean case
(Mokhtari et al., 2020). These results are enabled by judiciously addressing
the holonomy effect so that additional complications in Riemannian cases can be
reduced and the Euclidean proof inspired by the performance estimation problem
(PEP) technique or the sum-of-squares (SOS) technique can be applied again.
</p>
</div>
</dd>
<dt><a name="item670">[670]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14196" title="Abstract">arXiv:2309.14196</a> (cross-list from quant-ph) [<a href="/pdf/2309.14196" title="Download PDF">pdf</a>, <a href="/format/2309.14196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Restricted Boltzmann Machines with greedy quantum search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhao%2C+L">Liming Zhao</a>, 
<a href="/search/quant-ph?searchtype=author&query=Agrawal%2C+A">Aman Agrawal</a>, 
<a href="/search/quant-ph?searchtype=author&query=Rebentrost%2C+P">Patrick Rebentrost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Restricted Boltzmann Machines (RBMs) are widely used probabilistic undirected
graphical models with visible and latent nodes, playing an important role in
statistics and machine learning. The task of structure learning for RBMs
involves inferring the underlying graph by using samples from the visible
nodes. Specifically, learning the two-hop neighbors of each visible node allows
for the inference of the graph structure. Prior research has addressed the
structure learning problem for specific classes of RBMs, namely ferromagnetic
and locally consistent RBMs. In this paper, we extend the scope to the quantum
computing domain and propose corresponding quantum algorithms for this problem.
Our study demonstrates that the proposed quantum algorithms yield a polynomial
speedup compared to the classical algorithms for learning the structure of
these two classes of RBMs.
</p>
</div>
</dd>
<dt><a name="item671">[671]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14229" title="Abstract">arXiv:2309.14229</a> (cross-list from math.CO) [<a href="/pdf/2309.14229" title="Download PDF">pdf</a>, <a href="/ps/2309.14229" title="Download PostScript">ps</a>, <a href="/format/2309.14229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the expressive power of mod-$p$ linear forms on the Boolean cube
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Karam%2C+T">Thomas Karam</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT); Number Theory (math.NT)

</div>
<p class="mathjax">Let $(\mathcal{A}_i)_{i \in [s]}$ be a sequence of dense subsets of the
Boolean cube $\{0,1\}^n$ and let $p$ be a prime. We show that if $s$ is assumed
to be superpolynomial in $n$ then we can find distinct $i,j$ such that the two
distributions of every mod-$p$ linear form on $\mathcal{A}_i$ and
$\mathcal{A}_j$ are almost positively correlated. We also prove that if $s$ is
merely assumed to be sufficiently large independently of $n$ then we may
require the two distributions to have overlap bounded below by a positive
quantity depending on $p$ only.
</p>
</div>
</dd>
<dt><a name="item672">[672]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14231" title="Abstract">arXiv:2309.14231</a> (cross-list from math.OC) [<a href="/pdf/2309.14231" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Combined sizing and layout optimization of truss structures via update  Monte Carlo tree search (UMCTS) algorithm
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ko%2C+F">Fu-Yao Ko</a>, 
<a href="/search/math?searchtype=author&query=Suzuki%2C+K">Katsuyuki Suzuki</a>, 
<a href="/search/math?searchtype=author&query=Yonekura%2C+K">Kazuo Yonekura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 19 figures, 7 tables. arXiv admin note: text overlap with <a href="/abs/2309.06045">arXiv:2309.06045</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The main concern of this study is to find the optimal design of truss
structures considering sizing and layout variables simultaneously. As compared
to purely sizing optimization problems, this problem is more challenging since
the two types of variables involved are fundamentally different in nature. In
this paper, a reinforcement learning method combining the update process and
Monte Carlo tree search called the update Monte Carlo tree search (UMCTS) for
sizing optimization problems is applied to solve combined sizing and layout
optimization for truss structures. This study proposes a novel update process
for nodal coordinates with two features. (1) The allowed range of each
coordinate varies in each round. (2) Accelerators for the number of entries in
the allowed range and iteration numbers are introduced to reduce the
computation time. Furthermore, nodal coordinates and member areas are
determined at the same time with only one search tree in each round. The
validation and efficiency of the UMCTS are tested on benchmark problems of
planar and spatial trusses with discrete sizing variables and continuous layout
variables. It is shown that the CPU time of the UMCTS is two times faster than
the branch and bound method. The numerical results demonstrate that the
proposed method stably achieves a better solution than other traditional
methods.
</p>
</div>
</dd>
<dt><a name="item673">[673]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14250" title="Abstract">arXiv:2309.14250</a> (cross-list from stat.AP) [<a href="/pdf/2309.14250" title="Download PDF">pdf</a>, <a href="/format/2309.14250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prediction Model For Wordle Game Results With High Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Weng%2C+J">Jiaqi Weng</a>, 
<a href="/search/stat?searchtype=author&query=Feng%2C+C">Chunlin Feng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 Pages, 28 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Applications (stat.AP)</span>; Artificial Intelligence (cs.AI); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this study, we delve into the dynamics of Wordle using data analysis and
machine learning. Our analysis initially focused on the correlation between the
date and the number of submitted results. Due to initial popularity bias, we
modeled stable data using an ARIMAX model with coefficient values of 9, 0, 2,
and weekdays/weekends as the exogenous variable. We found no significant
relationship between word attributes and hard mode results.
<br />To predict word difficulty, we employed a Backpropagation Neural Network,
overcoming overfitting via feature engineering. We also used K-means
clustering, optimized at five clusters, to categorize word difficulty
numerically. Our findings indicate that on March 1st, 2023, around 12,884
results will be submitted and the word "eerie" averages 4.8 attempts, falling
into the hardest difficulty cluster.
<br />We further examined the percentage of loyal players and their propensity to
undertake daily challenges. Our models underwent rigorous sensitivity analyses,
including ADF, ACF, PACF tests, and cross-validation, confirming their
robustness. Overall, our study provides a predictive framework for Wordle
gameplay based on date or a given five-letter word. Results have been
summarized and submitted to the Puzzle Editor of the New York Times.
</p>
</div>
</dd>
<dt><a name="item674">[674]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14284" title="Abstract">arXiv:2309.14284</a> (cross-list from math.OC) [<a href="/pdf/2309.14284" title="Download PDF">pdf</a>, <a href="/format/2309.14284" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Navigation with shadow prices to optimize multi-commodity flow rates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boero%2C+I">Ignacio Boero</a>, 
<a href="/search/math?searchtype=author&query=Spasojevic%2C+I">Igor Spasojevic</a>, 
<a href="/search/math?searchtype=author&query=del+Castillo%2C+M">Mariana del Castillo</a>, 
<a href="/search/math?searchtype=author&query=Pappas%2C+G">George Pappas</a>, 
<a href="/search/math?searchtype=author&query=Kumar%2C+V">Vijay Kumar</a>, 
<a href="/search/math?searchtype=author&query=Ribeiro%2C+A">Alejandro Ribeiro</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (c) 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We propose a method for providing communication network infrastructure in
autonomous multi-agent teams. In particular, we consider a set of communication
agents that are placed alongside regular agents from the system in order to
improve the rate of information transfer between the latter. In order to find
the optimal positions to place such agents, we define a flexible performance
function that adapts to network requirements for different systems. We provide
an algorithm based on shadow prices of a related convex optimization problem in
order to drive the configuration of the complete system towards a local
maximum. We apply our method to three different performance functions
associated with three practical scenarios in which we show both the performance
of the algorithm and the flexibility it allows for optimizing different network
requirements.
</p>
</div>
</dd>
<dt><a name="item675">[675]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14298" title="Abstract">arXiv:2309.14298</a> (cross-list from stat.ML) [<a href="/pdf/2309.14298" title="Download PDF">pdf</a>, <a href="/format/2309.14298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for  Martingale Mixtures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Flynn%2C+H">Hamish Flynn</a>, 
<a href="/search/stat?searchtype=author&query=Reeb%2C+D">David Reeb</a>, 
<a href="/search/stat?searchtype=author&query=Kandemir%2C+M">Melih Kandemir</a>, 
<a href="/search/stat?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. 35 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We present improved algorithms with worst-case regret guarantees for the
stochastic linear bandit problem. The widely used "optimism in the face of
uncertainty" principle reduces a stochastic bandit problem to the construction
of a confidence sequence for the unknown reward function. The performance of
the resulting bandit algorithm depends on the size of the confidence sequence,
with smaller confidence sets yielding better empirical performance and stronger
regret guarantees. In this work, we use a novel tail bound for adaptive
martingale mixtures to construct confidence sequences which are suitable for
stochastic bandits. These confidence sequences allow for efficient action
selection via convex programming. We prove that a linear bandit algorithm based
on our confidence sequences is guaranteed to achieve competitive worst-case
regret. We show that our confidence sequences are tighter than competitors,
both empirically and theoretically. Finally, we demonstrate that our tighter
confidence sequences give improved performance in several hyperparameter tuning
tasks.
</p>
</div>
</dd>
<dt><a name="item676">[676]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14306" title="Abstract">arXiv:2309.14306</a> (cross-list from eess.IV) [<a href="/pdf/2309.14306" title="Download PDF">pdf</a>, <a href="/format/2309.14306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepMesh: Mesh-based Cardiac Motion Tracking using Deep Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Meng%2C+Q">Qingjie Meng</a>, 
<a href="/search/eess?searchtype=author&query=Bai%2C+W">Wenjia Bai</a>, 
<a href="/search/eess?searchtype=author&query=O%27Regan%2C+D+P">Declan P O&#x27;Regan</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+a+D">and Daniel Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">3D motion estimation from cine cardiac magnetic resonance (CMR) images is
important for the assessment of cardiac function and the diagnosis of
cardiovascular diseases. Current state-of-the art methods focus on estimating
dense pixel-/voxel-wise motion fields in image space, which ignores the fact
that motion estimation is only relevant and useful within the anatomical
objects of interest, e.g., the heart. In this work, we model the heart as a 3D
mesh consisting of epi- and endocardial surfaces. We propose a novel learning
framework, DeepMesh, which propagates a template heart mesh to a subject space
and estimates the 3D motion of the heart mesh from CMR images for individual
subjects. In DeepMesh, the heart mesh of the end-diastolic frame of an
individual subject is first reconstructed from the template mesh. Mesh-based 3D
motion fields with respect to the end-diastolic frame are then estimated from
2D short- and long-axis CMR images. By developing a differentiable
mesh-to-image rasterizer, DeepMesh is able to leverage 2D shape information
from multiple anatomical views for 3D mesh reconstruction and mesh motion
estimation. The proposed method estimates vertex-wise displacement and thus
maintains vertex correspondences between time frames, which is important for
the quantitative assessment of cardiac function across different subjects and
populations. We evaluate DeepMesh on CMR images acquired from the UK Biobank.
We focus on 3D motion estimation of the left ventricle in this work.
Experimental results show that the proposed method quantitatively and
qualitatively outperforms other image-based and mesh-based cardiac motion
tracking methods.
</p>
</div>
</dd>
<dt><a name="item677">[677]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14324" title="Abstract">arXiv:2309.14324</a> (cross-list from eess.AS) [<a href="/pdf/2309.14324" title="Download PDF">pdf</a>, <a href="/format/2309.14324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards General-Purpose Text-Instruction-Guided Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kuan%2C+C">Chun-Yi Kuan</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+C+A">Chen An Li</a>, 
<a href="/search/eess?searchtype=author&query=Hsu%2C+T">Tsu-Yuan Hsu</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+T">Tse-Yang Lin</a>, 
<a href="/search/eess?searchtype=author&query=Chung%2C+H">Ho-Lam Chung</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+K">Kai-Wei Chang</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+S">Shuo-yiin Chang</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+H">Hung-yi Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">This paper introduces a novel voice conversion (VC) model, guided by text
instructions such as "articulate slowly with a deep tone" or "speak in a
cheerful boyish voice". Unlike traditional methods that rely on reference
utterances to determine the attributes of the converted speech, our model adds
versatility and specificity to voice conversion. The proposed VC model is a
neural codec language model which processes a sequence of discrete codes,
resulting in the code sequence of converted speech. It utilizes text
instructions as style prompts to modify the prosody and emotional information
of the given speech. In contrast to previous approaches, which often rely on
employing separate encoders like prosody and content encoders to handle
different aspects of the source speech, our model handles various information
of speech in an end-to-end manner. Experiments have demonstrated the impressive
capabilities of our model in comprehending instructions and delivering
reasonable results.
</p>
</div>
</dd>
<dt><a name="item678">[678]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.14326" title="Abstract">arXiv:2309.14326</a> (cross-list from quant-ph) [<a href="/pdf/2309.14326" title="Download PDF">pdf</a>, <a href="/format/2309.14326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Futility and utility of a few ancillas for Pauli channel learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Chen%2C+S">Sitan Chen</a>, 
<a href="/search/quant-ph?searchtype=author&query=Gong%2C+W">Weiyuan Gong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Computational Complexity (cs.CC); Information Theory (cs.IT); Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
<p class="mathjax">In this paper we revisit one of the prototypical tasks for characterizing the
structure of noise in quantum devices, estimating the eigenvalues of an
$n$-qubit Pauli noise channel. Prior work (Chen et al., 2022) established
exponential lower bounds for this task for algorithms with limited quantum
memory. We first improve upon their lower bounds and show:
<br />(1) Any algorithm without quantum memory must make $\Omega(2^n/\epsilon^2)$
measurements to estimate each eigenvalue within error $\epsilon$. This is tight
and implies the randomized benchmarking protocol is optimal, resolving an open
question of (Flammia and Wallman, 2020).
<br />(2) Any algorithm with $\le k$ ancilla qubits of quantum memory must make
$\Omega(2^{(n-k)/3})$ queries to the unknown channel. Crucially, unlike in
(Chen et al., 2022), our bound holds even if arbitrary adaptive control and
channel concatenation are allowed.
<br />In fact these lower bounds, like those of (Chen et al., 2022), hold even for
the easier hypothesis testing problem of determining whether the underlying
channel is completely depolarizing or has exactly one other nontrivial
eigenvalue. Surprisingly, we show that:
<br />(3) With only $k=2$ ancilla qubits of quantum memory, there is an algorithm
that solves this hypothesis testing task with high probability using a single
measurement.
<br />Note that (3) does not contradict (2) as the protocol concatenates
exponentially many queries to the channel before the measurement. This result
suggests a novel mechanism by which channel concatenation and $O(1)$ qubits of
quantum memory could work in tandem to yield striking speedups for quantum
process learning that are not possible for quantum state learning.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Tue, 26 Sep 23</h3>
<dl>
<dt><a name="item679">[679]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1809.06044" title="Abstract">arXiv:1809.06044</a> (replaced) [<a href="/pdf/1809.06044" title="Download PDF">pdf</a>, <a href="/format/1809.06044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BlockTag: Design and applications of a tagging system for blockchain  analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Boshmaf%2C+Y">Yazan Boshmaf</a>, 
<a href="/search/cs?searchtype=author&query=Jawaheri%2C+H+A">Husam Al Jawaheri</a>, 
<a href="/search/cs?searchtype=author&query=Sabah%2C+M+A">Mashael Al Sabah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item680">[680]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1910.09455" title="Abstract">arXiv:1910.09455</a> (replaced) [<a href="/pdf/1910.09455" title="Download PDF">pdf</a>, <a href="/format/1910.09455" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth-wise Decomposition for Accelerating Separable Convolutions in  Efficient Convolutional Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yihui He</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+J">Jianing Qian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jianren Wang</a>, 
<a href="/search/cs?searchtype=author&query=Le%2C+C+X">Cindy X. Le</a>, 
<a href="/search/cs?searchtype=author&query=Hetang%2C+C">Congrui Hetang</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Q">Qi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenping Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+T">Tianwei Yue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item681">[681]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2002.00306" title="Abstract">arXiv:2002.00306</a> (replaced) [<a href="/pdf/2002.00306" title="Download PDF">pdf</a>, <a href="/format/2002.00306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Brainstorming Generative Adversarial Networks (BGANs): Towards  Multi-Agent Generative Models with Distributed Private Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferdowsi%2C+A">Aidin Ferdowsi</a>, 
<a href="/search/cs?searchtype=author&query=Saad%2C+W">Walid Saad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 16 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item682">[682]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2006.09565" title="Abstract">arXiv:2006.09565</a> (replaced) [<a href="/pdf/2006.09565" title="Download PDF">pdf</a>, <a href="/format/2006.09565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mining Label Distribution Drift in Unsupervised Domain Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Peizhao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Z">Zhengming Ding</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongfu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to AJCAI'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item683">[683]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2008.11852" title="Abstract">arXiv:2008.11852</a> (replaced) [<a href="/pdf/2008.11852" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement  Learning with Continuous Action Horizon
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+X">Xiaolin Tang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+T">Teng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item684">[684]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2011.15122" title="Abstract">arXiv:2011.15122</a> (replaced) [<a href="/pdf/2011.15122" title="Download PDF">pdf</a>, <a href="/format/2011.15122" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Controlled Learning for Inventory Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Temiz%C3%B6z%2C+T">Tarkan Temiz&#xf6;z</a>, 
<a href="/search/cs?searchtype=author&query=Imdahl%2C+C">Christina Imdahl</a>, 
<a href="/search/cs?searchtype=author&query=Dijkman%2C+R">Remco Dijkman</a>, 
<a href="/search/cs?searchtype=author&query=Lamghari-Idrissi%2C+D">Douniel Lamghari-Idrissi</a>, 
<a href="/search/cs?searchtype=author&query=van+Jaarsveld%2C+W">Willem van Jaarsveld</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item685">[685]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2012.14426" title="Abstract">arXiv:2012.14426</a> (replaced) [<a href="/pdf/2012.14426" title="Download PDF">pdf</a>, <a href="/format/2012.14426" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNNs for JPEGs: A Study in Computational Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+S+F+d">Samuel Felipe dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+J">Jurandy Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2012.13726">arXiv:2012.13726</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item686">[686]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2102.01412" title="Abstract">arXiv:2102.01412</a> (replaced) [<a href="/pdf/2102.01412" title="Download PDF">pdf</a>, <a href="/ps/2102.01412" title="Download PostScript">ps</a>, <a href="/format/2102.01412" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Codes for the Noisy Substring Channel
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yehezkeally%2C+Y">Yonatan Yehezkeally</a>, 
<a href="/search/cs?searchtype=author&query=Polyanskii%2C+N">Nikita Polyanskii</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Journal submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item687">[687]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2103.11247" title="Abstract">arXiv:2103.11247</a> (replaced) [<a href="/pdf/2103.11247" title="Download PDF">pdf</a>, <a href="/format/2103.11247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Based Multimodal Image Matching
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Moreshet%2C+A">Aviad Moreshet</a>, 
<a href="/search/cs?searchtype=author&query=Keller%2C+Y">Yosi Keller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item688">[688]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12570" title="Abstract">arXiv:2104.12570</a> (replaced) [<a href="/pdf/2104.12570" title="Download PDF">pdf</a>, <a href="/format/2104.12570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithmic Solution for Systems of Linear Equations, in  $\mathcal{O}(mn)$ time
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bakas%2C+N+P">Nikolaos P. Bakas</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item689">[689]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12856" title="Abstract">arXiv:2104.12856</a> (replaced) [<a href="/pdf/2104.12856" title="Download PDF">pdf</a>, <a href="/format/2104.12856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Free Vibration analysis of Curvilinearly Stiffened Composite plates with  an arbitrarily shaped cutout using Isogeometric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devarajan%2C+B">Balakrishnan Devarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2104.05132">arXiv:2104.05132</a>; Citation format changed to IEEE
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item690">[690]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.12860" title="Abstract">arXiv:2104.12860</a> (replaced) [<a href="/pdf/2104.12860" title="Download PDF">pdf</a>, <a href="/format/2104.12860" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vibration Analysis of Timoshenko Beams using Isogeometric Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devarajan%2C+B">Balakrishnan Devarajan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Citation changed to IEEE format
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item691">[691]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.01241" title="Abstract">arXiv:2105.01241</a> (replaced) [<a href="/pdf/2105.01241" title="Download PDF">pdf</a>, <a href="/format/2105.01241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-end One-shot Human Parsing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyu He</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+B">Bohan Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Trans. Pattern Analysis and Machine Intelligence (TPAMI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item692">[692]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.01331" title="Abstract">arXiv:2105.01331</a> (replaced) [<a href="/pdf/2105.01331" title="Download PDF">pdf</a>, <a href="/format/2105.01331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on  Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kemik%2C+H">Hasan Kemik</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zate%C5%9F%2C+N">Nusret &#xd6;zate&#x15f;</a>, 
<a href="/search/cs?searchtype=author&query=Asgari-Chenaghlu%2C+M">Meysam Asgari-Chenaghlu</a>, 
<a href="/search/cs?searchtype=author&query=Cambria%2C+E">Erik Cambria</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item693">[693]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2105.13015" title="Abstract">arXiv:2105.13015</a> (replaced) [<a href="/pdf/2105.13015" title="Download PDF">pdf</a>, <a href="/format/2105.13015" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A recursive representation for decoupling time-state dependent jumps  from jump-diffusion processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Qiu%2C+Q">Qinjing Qiu</a>, 
<a href="/search/math?searchtype=author&query=Kawai%2C+R">Reiichiro Kawai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item694">[694]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.06801" title="Abstract">arXiv:2107.06801</a> (replaced) [<a href="/pdf/2107.06801" title="Download PDF">pdf</a>, <a href="/format/2107.06801" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Implementation and Experimental Evaluation of Reed-Solomon  Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrara%2C+R">Roberto Ferrara</a>, 
<a href="/search/cs?searchtype=author&query=Torres-Figueroa%2C+L">Luis Torres-Figueroa</a>, 
<a href="/search/cs?searchtype=author&query=Boche%2C+H">Holger Boche</a>, 
<a href="/search/cs?searchtype=author&query=Deppe%2C+C">Christian Deppe</a>, 
<a href="/search/cs?searchtype=author&query=Labidi%2C+W">Wafa Labidi</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%B6nich%2C+U">Ullrich M&#xf6;nich</a>, 
<a href="/search/cs?searchtype=author&query=Vlad-Costin%2C+A">Andrei Vlad-Costin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> European Wireless 2022; 27th European Wireless Conference,
  Dresden, Germany, 2022, https://ieeexplore.ieee.org/document/10071924
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item695">[695]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2108.00309" title="Abstract">arXiv:2108.00309</a> (replaced) [<a href="/pdf/2108.00309" title="Download PDF">pdf</a>, <a href="/format/2108.00309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Motion Planning for Variable Topology Trusses: Reconfiguration and  Locomotion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Sencheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Yim%2C+M">Mark Yim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 36 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> IEEE Transactions on Robotics, vol. 39, no. 3, pp. 2020-2039, June
  2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item696">[696]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2109.07212" title="Abstract">arXiv:2109.07212</a> (replaced) [<a href="/pdf/2109.07212" title="Download PDF">pdf</a>, <a href="/format/2109.07212" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimising Rolling Stock Planning including Maintenance with Constraint  Programming and Quantum Annealing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bickert%2C+P">Patricia Bickert</a>, 
<a href="/search/cs?searchtype=author&query=Grozea%2C+C">Cristian Grozea</a>, 
<a href="/search/cs?searchtype=author&query=Hans%2C+R">Ronny Hans</a>, 
<a href="/search/cs?searchtype=author&query=Koch%2C+M">Matthias Koch</a>, 
<a href="/search/cs?searchtype=author&query=Riehn%2C+C">Christina Riehn</a>, 
<a href="/search/cs?searchtype=author&query=Wolf%2C+A">Armin Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Statistical Finance (q-fin.ST)

</div>
</div>
</dd>
<dt><a name="item697">[697]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.06357" title="Abstract">arXiv:2110.06357</a> (replaced) [<a href="/pdf/2110.06357" title="Download PDF">pdf</a>, <a href="/format/2110.06357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tangent Space and Dimension Estimation with the Wasserstein Distance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lim%2C+U">Uzu Lim</a>, 
<a href="/search/math?searchtype=author&query=Oberhauser%2C+H">Harald Oberhauser</a>, 
<a href="/search/math?searchtype=author&query=Nanda%2C+V">Vidit Nanda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Main theorems rewritten. Introduction is written more compactly
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item698">[698]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.15310" title="Abstract">arXiv:2110.15310</a> (replaced) [<a href="/pdf/2110.15310" title="Download PDF">pdf</a>, <a href="/format/2110.15310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Fairness of Machine-Assisted Human Decisions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gillis%2C+T">Talia Gillis</a>, 
<a href="/search/cs?searchtype=author&query=McLaughlin%2C+B">Bryce McLaughlin</a>, 
<a href="/search/cs?searchtype=author&query=Spiess%2C+J">Jann Spiess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); General Economics (econ.GN); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item699">[699]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.08313" title="Abstract">arXiv:2111.08313</a> (replaced) [<a href="/pdf/2111.08313" title="Download PDF">pdf</a>, <a href="/format/2111.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Comprehensive Monocular Depth Estimation: Multiple Heads Are  Better Than One
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Ran Li</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Z">Zhongcai Pei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Baochang Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by TMM 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item700">[700]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03051" title="Abstract">arXiv:2112.03051</a> (replaced) [<a href="/pdf/2112.03051" title="Download PDF">pdf</a>, <a href="/format/2112.03051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Animation of Fluid Elements in Still Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mahapatra%2C+A">Aniruddha Mahapatra</a>, 
<a href="/search/cs?searchtype=author&query=Kulkarni%2C+K">Kuldeep Kulkarni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item701">[701]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.13097" title="Abstract">arXiv:2112.13097</a> (replaced) [<a href="/pdf/2112.13097" title="Download PDF">pdf</a>, <a href="/format/2112.13097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Faster Rates for Compressed Federated Learning with Client-Variance  Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haoyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Burlachenko%2C+K">Konstantin Burlachenko</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhize Li</a>, 
<a href="/search/cs?searchtype=author&query=Richt%C3%A1rik%2C+P">Peter Richt&#xe1;rik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIAM Journal on Mathematics of Data Science (SIMODS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Data Structures and Algorithms (cs.DS); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item702">[702]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.00006" title="Abstract">arXiv:2201.00006</a> (replaced) [<a href="/pdf/2201.00006" title="Download PDF">pdf</a>, <a href="/ps/2201.00006" title="Download PostScript">ps</a>, <a href="/format/2201.00006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic  Signal Control Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shubin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+J">Jianming Deng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item703">[703]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2201.11935" title="Abstract">arXiv:2201.11935</a> (replaced) [<a href="/pdf/2201.11935" title="Download PDF">pdf</a>, <a href="/format/2201.11935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequential Decoding of Convolutional Codes for Synchronization Errors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A">Anisha Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Lenz%2C+A">Andreas Lenz</a>, 
<a href="/search/cs?searchtype=author&query=Wachter-Zeh%2C+A">Antonia Wachter-Zeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item704">[704]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.03356" title="Abstract">arXiv:2202.03356</a> (replaced) [<a href="/pdf/2202.03356" title="Download PDF">pdf</a>, <a href="/format/2202.03356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Direct-Connect Topologies for Collective Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Liangyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Pal%2C+S">Siddharth Pal</a>, 
<a href="/search/cs?searchtype=author&query=Chugh%2C+T">Tapan Chugh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Fantl%2C+J">Jason Fantl</a>, 
<a href="/search/cs?searchtype=author&query=Basu%2C+P">Prithwish Basu</a>, 
<a href="/search/cs?searchtype=author&query=Khoury%2C+J">Joud Khoury</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Arvind Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item705">[705]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.04176" title="Abstract">arXiv:2202.04176</a> (replaced) [<a href="/pdf/2202.04176" title="Download PDF">pdf</a>, <a href="/format/2202.04176" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Crime Hot-Spot Modeling via Topic Modeling and Relative Density  Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Jonathan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huestis-Mitchell%2C+S">Sarah Huestis-Mitchell</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xiuyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yao Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item706">[706]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.13670" title="Abstract">arXiv:2202.13670</a> (replaced) [<a href="/pdf/2202.13670" title="Download PDF">pdf</a>, <a href="/format/2202.13670" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDrive: Generalizing Federated Learning to Semantic Segmentation in  Autonomous Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fantauzzo%2C+L">Lidia Fantauzzo</a>, 
<a href="/search/cs?searchtype=author&query=Fan%C3%AC%2C+E">Eros Fan&#xec;</a>, 
<a href="/search/cs?searchtype=author&query=Caldarola%2C+D">Debora Caldarola</a>, 
<a href="/search/cs?searchtype=author&query=Tavera%2C+A">Antonio Tavera</a>, 
<a href="/search/cs?searchtype=author&query=Cermelli%2C+F">Fabio Cermelli</a>, 
<a href="/search/cs?searchtype=author&query=Ciccone%2C+M">Marco Ciccone</a>, 
<a href="/search/cs?searchtype=author&query=Caputo%2C+B">Barbara Caputo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item707">[707]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.02496" title="Abstract">arXiv:2203.02496</a> (replaced) [<a href="/pdf/2203.02496" title="Download PDF">pdf</a>, <a href="/format/2203.02496" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning from Label Proportions by Learning with Label Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianxin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yutong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Scott%2C+C">Clayton Scott</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item708">[708]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.03906" title="Abstract">arXiv:2203.03906</a> (replaced) [<a href="/pdf/2203.03906" title="Download PDF">pdf</a>, <a href="/format/2203.03906" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Reinforcement Learning for Radio Resource Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jianyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Chenyang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item709">[709]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.13517" title="Abstract">arXiv:2203.13517</a> (replaced) [<a href="/pdf/2203.13517" title="Download PDF">pdf</a>, <a href="/format/2203.13517" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Federated Learning with Hierarchical Personalized Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaofeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+Y">Yunfeng Shao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinchuan Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2107.05330">arXiv:2107.05330</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item710">[710]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.00751" title="Abstract">arXiv:2204.00751</a> (replaced) [<a href="/pdf/2204.00751" title="Download PDF">pdf</a>, <a href="/format/2204.00751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robotic Process Automation Using Process Mining $\unicode{x2013}$ A  Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Gharib%2C+N+M">Najah Mary El-Gharib</a>, 
<a href="/search/cs?searchtype=author&query=Amyot%2C+D">Daniel Amyot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 51 pages, 5 figures, 7 tables
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Data &amp; Knowledge Engineering (2023) 102229
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item711">[711]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04431" title="Abstract">arXiv:2204.04431</a> (replaced) [<a href="/pdf/2204.04431" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spiking Neural Network Structure Implementing Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselev%2C+M">Mikhail Kiselev</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item712">[712]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.10607" title="Abstract">arXiv:2204.10607</a> (replaced) [<a href="/pdf/2204.10607" title="Download PDF">pdf</a>, <a href="/format/2204.10607" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning via Inexact ADMM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhou%2C+S">Shenglong Zhou</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+G+Y">Geoffrey Ye Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item713">[713]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.04561" title="Abstract">arXiv:2205.04561</a> (replaced) [<a href="/pdf/2205.04561" title="Download PDF">pdf</a>, <a href="/format/2205.04561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scim: Intelligent Skimming Support for Scientific Papers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fok%2C+R">Raymond Fok</a>, 
<a href="/search/cs?searchtype=author&query=Kambhamettu%2C+H">Hita Kambhamettu</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Bragg%2C+J">Jonathan Bragg</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Head%2C+A">Andrew Head</a>, 
<a href="/search/cs?searchtype=author&query=Hearst%2C+M+A">Marti A. Hearst</a>, 
<a href="/search/cs?searchtype=author&query=Weld%2C+D+S">Daniel S. Weld</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated to reflect version published in proceedings of IUI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item714">[714]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.00469" title="Abstract">arXiv:2206.00469</a> (replaced) [<a href="/pdf/2206.00469" title="Download PDF">pdf</a>, <a href="/format/2206.00469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A barycentric trigonometric Hermite interpolant via an iterative  approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Elefante%2C+G">Giacomo Elefante</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item715">[715]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.02014" title="Abstract">arXiv:2206.02014</a> (replaced) [<a href="/pdf/2206.02014" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Actuarial Applications of Natural Language Processing Using  Transformers: Case Studies for Using Text Features in an Actuarial Context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Troxler%2C+A">Andreas Troxler</a> (AT Analytics), 
<a href="/search/cs?searchtype=author&query=Schelldorfer%2C+J">J&#xfc;rg Schelldorfer</a> (Swiss Re)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 47 pages, 33 figures. v3: Added new Section 10 on the use of ChatGPT for unsupervised information extraction
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item716">[716]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09090" title="Abstract">arXiv:2206.09090</a> (replaced) [<a href="/pdf/2206.09090" title="Download PDF">pdf</a>, <a href="/ps/2206.09090" title="Download PostScript">ps</a>, <a href="/format/2206.09090" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> From Understanding Genetic Drift to a Smart-Restart Mechanism for  Estimation-of-Distribution Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Weijie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Doerr%2C+B">Benjamin Doerr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in "Journal of Machine Learning Research". Extended version of our GECCO 2020 paper. This article supersedes <a href="/abs/2004.07141">arXiv:2004.07141</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item717">[717]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.09563" title="Abstract">arXiv:2206.09563</a> (replaced) [<a href="/pdf/2206.09563" title="Download PDF">pdf</a>, <a href="/format/2206.09563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Distributed Algorithms for Size-Constrained Submodular  Maximization in the MapReduce and Adaptive Complexity Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dey%2C+T">Tonmoy Dey</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kuhnle%2C+A">Alan Kuhnle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 45 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item718">[718]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.11948" title="Abstract">arXiv:2206.11948</a> (replaced) [<a href="/pdf/2206.11948" title="Download PDF">pdf</a>, <a href="/ps/2206.11948" title="Download PostScript">ps</a>, <a href="/format/2206.11948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Strong Duality in Risk-Constrained Nonconvex Functional Programming
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kalogerias%2C+D">Dionysis Kalogerias</a>, 
<a href="/search/math?searchtype=author&query=Pougkakiotis%2C+S">Spyridon Pougkakiotis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 pages, to be submitted. Full Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Information Theory (cs.IT); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item719">[719]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12983" title="Abstract">arXiv:2206.12983</a> (replaced) [<a href="/pdf/2206.12983" title="Download PDF">pdf</a>, <a href="/format/2206.12983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable and High-Performance Hate and Offensive Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Babaeianjelodar%2C+M">Marzieh Babaeianjelodar</a>, 
<a href="/search/cs?searchtype=author&query=Prudhvi%2C+G+P">Gurram Poorna Prudhvi</a>, 
<a href="/search/cs?searchtype=author&query=Lorenz%2C+S">Stephen Lorenz</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Keyu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mondal%2C+S">Sumona Mondal</a>, 
<a href="/search/cs?searchtype=author&query=Dey%2C+S">Soumyabrata Dey</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+N">Navin Kumar</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 24th International Conference on Human-Computer Interaction 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item720">[720]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.13778" title="Abstract">arXiv:2206.13778</a> (replaced) [<a href="/pdf/2206.13778" title="Download PDF">pdf</a>, <a href="/format/2206.13778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CC-Riddle: A Question Answering Dataset of Chinese Character Riddles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+F">Fan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yunxiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+X">Xiaojun Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item721">[721]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.00479" title="Abstract">arXiv:2207.00479</a> (replaced) [<a href="/pdf/2207.00479" title="Download PDF">pdf</a>, <a href="/format/2207.00479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Decentralized Bayesian Optimization for Large Scale  Hyperparameter Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Egele%2C+R">Romain Egele</a>, 
<a href="/search/cs?searchtype=author&query=Guyon%2C+I">Isabelle Guyon</a>, 
<a href="/search/cs?searchtype=author&query=Vishwanath%2C+V">Venkatram Vishwanath</a>, 
<a href="/search/cs?searchtype=author&query=Balaprakash%2C+P">Prasanna Balaprakash</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item722">[722]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.01200" title="Abstract">arXiv:2207.01200</a> (replaced) [<a href="/pdf/2207.01200" title="Download PDF">pdf</a>, <a href="/format/2207.01200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> S$^{5}$Mars: Semi-Supervised Learning for Mars Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiahang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+L">Lilang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zejia Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiaying Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item723">[723]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.12369" title="Abstract">arXiv:2207.12369</a> (replaced) [<a href="/pdf/2207.12369" title="Download PDF">pdf</a>, <a href="/format/2207.12369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward reliable signals decoding for electroencephalogram: A benchmark  study to EEGNeX
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+X">Xia Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Teng%2C+X">Xiangbin Teng</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+H">Han Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Pan%2C+Y">Yafeng Pan</a>, 
<a href="/search/q-bio?searchtype=author&query=Geyer%2C+P">Philipp Geyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Biomedical Signal Processing and Control, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Human-Computer Interaction (cs.HC); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item724">[724]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01819" title="Abstract">arXiv:2208.01819</a> (replaced) [<a href="/pdf/2208.01819" title="Download PDF">pdf</a>, <a href="/format/2208.01819" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Camouflage for Node Injection Attack on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shuchang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunfan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+F">Fei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Information Sciences. Code: <a href="https://github.com/TaoShuchang/CANA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item725">[725]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.01913" title="Abstract">arXiv:2208.01913</a> (replaced) [<a href="/pdf/2208.01913" title="Download PDF">pdf</a>, <a href="/format/2208.01913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> EgPDE-Net: Building Continuous Neural Networks for Time Series  Prediction with Exogenous Variables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Penglei Gao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Ping Guo</a>, 
<a href="/search/cs?searchtype=author&query=Goulermas%2C+J+Y">John Y. Goulermas</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaizhu Huang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item726">[726]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06838" title="Abstract">arXiv:2208.06838</a> (replaced) [<a href="/pdf/2208.06838" title="Download PDF">pdf</a>, <a href="/format/2208.06838" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+H">Haoyuan He</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+W">Wangzhou Dai</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACML'2023 Journal Track(Accepted by Machine Learning Journal)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item727">[727]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.06900" title="Abstract">arXiv:2208.06900</a> (replaced) [<a href="/pdf/2208.06900" title="Download PDF">pdf</a>, <a href="/format/2208.06900" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convolutional Spiking Neural Networks for Detecting Anticipatory Brain  Potentials Using Electroencephalogram
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lutes%2C+N">Nathan Lutes</a>, 
<a href="/search/cs?searchtype=author&query=Nadendla%2C+V+S+S">Venkata Sriram Siddhardh Nadendla</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+K">K. Krishnamurthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 6 figures, Scientific Reports submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
</div>
</dd>
<dt><a name="item728">[728]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09708" title="Abstract">arXiv:2208.09708</a> (replaced) [<a href="/pdf/2208.09708" title="Download PDF">pdf</a>, <a href="/format/2208.09708" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xinlin Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+B">Bang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R+H">Rui Heng Yang</a>, 
<a href="/search/cs?searchtype=author&query=Courville%2C+V">Vanessa Courville</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+C">Chao Xing</a>, 
<a href="/search/cs?searchtype=author&query=Nia%2C+V+P">Vahid Partovi Nia</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item729">[729]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.11247" title="Abstract">arXiv:2208.11247</a> (replaced) [<a href="/pdf/2208.11247" title="Download PDF">pdf</a>, <a href="/format/2208.11247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SwinFIR: Revisiting the SwinIR with Fast Fourier Convolution and  Improved Training for Image Super-Resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dafeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Feiyu Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shizhuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaobing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhezhu Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item730">[730]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12106" title="Abstract">arXiv:2208.12106</a> (replaced) [<a href="/pdf/2208.12106" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Apptainer Without Setuid
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dykstra%2C+D">Dave Dykstra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item731">[731]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12370" title="Abstract">arXiv:2208.12370</a> (replaced) [<a href="/pdf/2208.12370" title="Download PDF">pdf</a>, <a href="/format/2208.12370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COOKIEGRAPH: Understanding and Detecting First-Party Tracking Cookies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Munir%2C+S">Shaoor Munir</a>, 
<a href="/search/cs?searchtype=author&query=Siby%2C+S">Sandra Siby</a>, 
<a href="/search/cs?searchtype=author&query=Iqbal%2C+U">Umar Iqbal</a>, 
<a href="/search/cs?searchtype=author&query=Englehardt%2C+S">Steven Englehardt</a>, 
<a href="/search/cs?searchtype=author&query=Shafiq%2C+Z">Zubair Shafiq</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item732">[732]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.12587" title="Abstract">arXiv:2208.12587</a> (replaced) [<a href="/pdf/2208.12587" title="Download PDF">pdf</a>, <a href="/format/2208.12587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mitosis Detection, Fast and Slow: Robust and Efficient Detection of  Mitotic Figures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahanifar%2C+M">Mostafa Jahanifar</a>, 
<a href="/search/cs?searchtype=author&query=Shephard%2C+A">Adam Shephard</a>, 
<a href="/search/cs?searchtype=author&query=Zamanitajeddin%2C+N">Neda Zamanitajeddin</a>, 
<a href="/search/cs?searchtype=author&query=Graham%2C+S">Simon Graham</a>, 
<a href="/search/cs?searchtype=author&query=Raza%2C+S+E+A">Shan E Ahmed Raza</a>, 
<a href="/search/cs?searchtype=author&query=Minhas%2C+F">Fayyaz Minhas</a>, 
<a href="/search/cs?searchtype=author&query=Rajpoot%2C+N">Nasir Rajpoot</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the work done for MIDOG challenge submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item733">[733]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.14417" title="Abstract">arXiv:2208.14417</a> (replaced) [<a href="/pdf/2208.14417" title="Download PDF">pdf</a>, <a href="/format/2208.14417" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fraud Dataset Benchmark and Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Grover%2C+P">Prince Grover</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Julia Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tittelfitz%2C+J">Justin Tittelfitz</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Anqi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zheng Li</a>, 
<a href="/search/cs?searchtype=author&query=Zablocki%2C+J">Jakub Zablocki</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jianbo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+H">Hao Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item734">[734]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.00714" title="Abstract">arXiv:2209.00714</a> (replaced) [<a href="/pdf/2209.00714" title="Download PDF">pdf</a>, <a href="/format/2209.00714" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unifying Framework for Interpolatory $\mathcal{L}_2$-optimal  Reduced-order Modeling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mlinari%C4%87%2C+P">Petar Mlinari&#x107;</a>, 
<a href="/search/math?searchtype=author&query=Gugercin%2C+S">Serkan Gugercin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Systems and Control (eess.SY); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item735">[735]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05013" title="Abstract">arXiv:2209.05013</a> (replaced) [<a href="/pdf/2209.05013" title="Download PDF">pdf</a>, <a href="/format/2209.05013" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning A Locally Unified 3D Point Cloud for View Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=You%2C+M">Meng You</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Mantang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xianqiang Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+J">Junhui Hou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item736">[736]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.05567" title="Abstract">arXiv:2209.05567</a> (replaced) [<a href="/pdf/2209.05567" title="Download PDF">pdf</a>, <a href="/format/2209.05567" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixed formulation for the computation of Miura surfaces with essential  boundary conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Marazzato%2C+F">Frederic Marazzato</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP)

</div>
</div>
</dd>
<dt><a name="item737">[737]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06095" title="Abstract">arXiv:2209.06095</a> (replaced) [<a href="/pdf/2209.06095" title="Download PDF">pdf</a>, <a href="/format/2209.06095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Variational Free Energy Approach to Dense Hydrogen
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Xie%2C+H">Hao Xie</a>, 
<a href="/search/cond-mat?searchtype=author&query=Li%2C+Z">Zi-Hang Li</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+H">Han Wang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Zhang%2C+L">Linfeng Zhang</a>, 
<a href="/search/cond-mat?searchtype=author&query=Wang%2C+L">Lei Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7+5 pages, 3+4 figures, code: <a href="https://github.com/fermiflow/hydrogen">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Phys. Rev. Lett. 131, 126501 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Strongly Correlated Electrons (cond-mat.str-el)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item738">[738]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.08983" title="Abstract">arXiv:2209.08983</a> (replaced) [<a href="/pdf/2209.08983" title="Download PDF">pdf</a>, <a href="/format/2209.08983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal phase shift design for fair allocation in RIS aided uplink  network using statistical CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Subhash%2C+A">Athira Subhash</a>, 
<a href="/search/cs?searchtype=author&query=Kammoun%2C+A">Abla Kammoun</a>, 
<a href="/search/cs?searchtype=author&query=Elzanaty%2C+A">Ahmed Elzanaty</a>, 
<a href="/search/cs?searchtype=author&query=Kalyani%2C+S">Sheetal Kalyani</a>, 
<a href="/search/cs?searchtype=author&query=Al-Badarneh%2C+Y+H">Yazan H.Al-Badarneh</a>, 
<a href="/search/cs?searchtype=author&query=Alouini%2C+M">Mohamed-Slim Alouini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item739">[739]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.11461" title="Abstract">arXiv:2209.11461</a> (replaced) [<a href="/pdf/2209.11461" title="Download PDF">pdf</a>, <a href="/format/2209.11461" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spatio-Temporal Contrastive Learning Enhanced GNNs for Session-based  Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+Z">Zhongwei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Benyou Wang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiezhong Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Boyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+T">Ting Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangyong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yang Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ACM Transaction on Information Systems (ACM TOIS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item740">[740]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12487" title="Abstract">arXiv:2209.12487</a> (replaced) [<a href="/pdf/2209.12487" title="Download PDF">pdf</a>, <a href="/format/2209.12487" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tartarus: A Benchmarking Platform for Realistic And Practical Inverse  Molecular Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nigam%2C+A">AkshatKumar Nigam</a>, 
<a href="/search/cs?searchtype=author&query=Pollice%2C+R">Robert Pollice</a>, 
<a href="/search/cs?searchtype=author&query=Tom%2C+G">Gary Tom</a>, 
<a href="/search/cs?searchtype=author&query=Jorner%2C+K">Kjell Jorner</a>, 
<a href="/search/cs?searchtype=author&query=Thiede%2C+L+A">Luca A. Thiede</a>, 
<a href="/search/cs?searchtype=author&query=Kundaje%2C+A">Anshul Kundaje</a>, 
<a href="/search/cs?searchtype=author&query=Aspuru-Guzik%2C+A">Alan Aspuru-Guzik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29+21 pages, 6+19 figures, 6+2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item741">[741]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.14978" title="Abstract">arXiv:2209.14978</a> (replaced) [<a href="/pdf/2209.14978" title="Download PDF">pdf</a>, <a href="/format/2209.14978" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enumeration of max-pooling responses with generalized permutohedra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Escobar%2C+L">Laura Escobar</a>, 
<a href="/search/math?searchtype=author&query=Gallardo%2C+P">Patricio Gallardo</a>, 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez-Anaya%2C+J">Javier Gonz&#xe1;lez-Anaya</a>, 
<a href="/search/math?searchtype=author&query=Gonz%C3%A1lez%2C+J+L">Jos&#xe9; L. Gonz&#xe1;lez</a>, 
<a href="/search/math?searchtype=author&query=Mont%C3%BAfar%2C+G">Guido Mont&#xfa;far</a>, 
<a href="/search/math?searchtype=author&query=Morales%2C+A+H">Alejandro H. Morales</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 11 figures, 4 tables. V2: Improved exposition, added computations in Section 4, and expanded analysis of data
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item742">[742]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.15505" title="Abstract">arXiv:2209.15505</a> (replaced) [<a href="/pdf/2209.15505" title="Download PDF">pdf</a>, <a href="/format/2209.15505" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Momentum Tracking: Momentum Acceleration for Decentralized Deep Learning  on Heterogeneous Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Takezawa%2C+Y">Yuki Takezawa</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+H">Han Bao</a>, 
<a href="/search/cs?searchtype=author&query=Niwa%2C+K">Kenta Niwa</a>, 
<a href="/search/cs?searchtype=author&query=Sato%2C+R">Ryoma Sato</a>, 
<a href="/search/cs?searchtype=author&query=Yamada%2C+M">Makoto Yamada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Transactions on Machine Learning Research 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item743">[743]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.05178" title="Abstract">arXiv:2210.05178</a> (replaced) [<a href="/pdf/2210.05178" title="Download PDF">pdf</a>, <a href="/format/2210.05178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-Training for Robots: Offline RL Enables Learning New Tasks from a  Handful of Trials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Aviral Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anikait Singh</a>, 
<a href="/search/cs?searchtype=author&query=Ebert%2C+F">Frederik Ebert</a>, 
<a href="/search/cs?searchtype=author&query=Nakamoto%2C+M">Mitsuhiko Nakamoto</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yanlai Yang</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>, 
<a href="/search/cs?searchtype=author&query=Levine%2C+S">Sergey Levine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item744">[744]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.06366" title="Abstract">arXiv:2210.06366</a> (replaced) [<a href="/pdf/2210.06366" title="Download PDF">pdf</a>, <a href="/format/2210.06366" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalist Framework for Panoptic Segmentation of Images and Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Ting Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lala Li</a>, 
<a href="/search/cs?searchtype=author&query=Saxena%2C+S">Saurabh Saxena</a>, 
<a href="/search/cs?searchtype=author&query=Hinton%2C+G">Geoffrey Hinton</a>, 
<a href="/search/cs?searchtype=author&query=Fleet%2C+D+J">David J. Fleet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV'23. Code at <a href="https://github.com/google-research/pix2seq">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item745">[745]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.08298" title="Abstract">arXiv:2210.08298</a> (replaced) [<a href="/pdf/2210.08298" title="Download PDF">pdf</a>, <a href="/ps/2210.08298" title="Download PostScript">ps</a>, <a href="/format/2210.08298" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Myhill-Nerode Theorem for Higher-Dimensional Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fahrenberg%2C+U">Uli Fahrenberg</a>, 
<a href="/search/cs?searchtype=author&query=Ziemia%C5%84ski%2C+K">Krzysztof Ziemia&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item746">[746]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10418" title="Abstract">arXiv:2210.10418</a> (replaced) [<a href="/pdf/2210.10418" title="Download PDF">pdf</a>, <a href="/format/2210.10418" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> p$^3$VAE: a physics-integrated generative model. Application to the  pixel-wise classification of airborne hyperspectral images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thoreau%2C+R">Romain Thoreau</a>, 
<a href="/search/cs?searchtype=author&query=Risser%2C+L">Laurent Risser</a>, 
<a href="/search/cs?searchtype=author&query=Achard%2C+V">V&#xe9;ronique Achard</a>, 
<a href="/search/cs?searchtype=author&query=Berthelot%2C+B">B&#xe9;atrice Berthelot</a>, 
<a href="/search/cs?searchtype=author&query=Briottet%2C+X">Xavier Briottet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 14 figures, submitted to Springer Machine Learning
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item747">[747]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.11174" title="Abstract">arXiv:2210.11174</a> (replaced) [<a href="/e-print/2210.11174" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overlapping Community Detection using Dynamic Dilated Aggregation in  Deep Residual GCN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Muttakin%2C+M+N">Md Nurul Muttakin</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+I">Md Iqbal Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+S">Md Saidur Rahman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will resubmit later
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item748">[748]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.17326" title="Abstract">arXiv:2210.17326</a> (replaced) [<a href="/pdf/2210.17326" title="Download PDF">pdf</a>, <a href="/format/2210.17326" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model Compression for DNN-based Speaker Verification Using Weight  Quantization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jingyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zhaoyang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+J">Jiong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+T">Tan Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by INTERSPEECH2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item749">[749]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.01712" title="Abstract">arXiv:2211.01712</a> (replaced) [<a href="/pdf/2211.01712" title="Download PDF">pdf</a>, <a href="/format/2211.01712" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust Management for Internet of Things: A Systematic Literature Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konsta%2C+A+M">Alyzia Maria Konsta</a>, 
<a href="/search/cs?searchtype=author&query=Lafuente%2C+A+L">Alberto Lluch Lafuente</a>, 
<a href="/search/cs?searchtype=author&query=Dragoni%2C+N">Nicola Dragoni</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item750">[750]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03311" title="Abstract">arXiv:2211.03311</a> (replaced) [<a href="/pdf/2211.03311" title="Download PDF">pdf</a>, <a href="/format/2211.03311" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Complexity of Recognizing Facets for the Knapsack Polytope
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+R">Rui Chen</a>, 
<a href="/search/math?searchtype=author&query=Zhu%2C+H">Haoran Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item751">[751]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.03550" title="Abstract">arXiv:2211.03550</a> (replaced) [<a href="/pdf/2211.03550" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Underwater Image Super-Resolution using Generative Adversarial  Network-based Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aghelan%2C+A">Alireza Aghelan</a>, 
<a href="/search/cs?searchtype=author&query=Rouhani%2C+M">Modjtaba Rouhani</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item752">[752]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.05750" title="Abstract">arXiv:2211.05750</a> (replaced) [<a href="/pdf/2211.05750" title="Download PDF">pdf</a>, <a href="/format/2211.05750" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language  Model Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yiwei Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+P+P">Paul Pu Liang</a>, 
<a href="/search/cs?searchtype=author&query=Salakhutdinov%2C+R">Ruslan Salakhutdinov</a>, 
<a href="/search/cs?searchtype=author&query=Morency%2C+L">Louis-Philippe Morency</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACL Findings 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item753">[753]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08403" title="Abstract">arXiv:2211.08403</a> (replaced) [<a href="/pdf/2211.08403" title="Download PDF">pdf</a>, <a href="/format/2211.08403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REPAIR: REnormalizing Permuted Activations for Interpolation Repair
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jordan%2C+K">Keller Jordan</a>, 
<a href="/search/cs?searchtype=author&query=Sedghi%2C+H">Hanie Sedghi</a>, 
<a href="/search/cs?searchtype=author&query=Saukh%2C+O">Olga Saukh</a>, 
<a href="/search/cs?searchtype=author&query=Entezari%2C+R">Rahim Entezari</a>, 
<a href="/search/cs?searchtype=author&query=Neyshabur%2C+B">Behnam Neyshabur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item754">[754]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.09558" title="Abstract">arXiv:2211.09558</a> (replaced) [<a href="/pdf/2211.09558" title="Download PDF">pdf</a>, <a href="/format/2211.09558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReLER@ZJU Submission to the Ego4D Moment Queries Challenge 2022
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiayi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ECCV 2022 Ego4D Workshop; 3rd place in Ego4D Moment Query Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item755">[755]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.11896" title="Abstract">arXiv:2211.11896</a> (replaced) [<a href="/pdf/2211.11896" title="Download PDF">pdf</a>, <a href="/format/2211.11896" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Private Ad Modeling with DP-SGD
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Denison%2C+C">Carson Denison</a>, 
<a href="/search/cs?searchtype=author&query=Ghazi%2C+B">Badih Ghazi</a>, 
<a href="/search/cs?searchtype=author&query=Kamath%2C+P">Pritish Kamath</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+R">Ravi Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Manurangsi%2C+P">Pasin Manurangsi</a>, 
<a href="/search/cs?searchtype=author&query=Narra%2C+K+G">Krishna Giri Narra</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Amer Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Varadarajan%2C+A">Avinash Varadarajan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+C">Chiyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AdKDD 2023, 8 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item756">[756]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12711" title="Abstract">arXiv:2211.12711</a> (replaced) [<a href="/pdf/2211.12711" title="Download PDF">pdf</a>, <a href="/format/2211.12711" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SnCQA: A hardware-efficient equivariant quantum convolutional circuit  architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zheng%2C+H">Han Zheng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Kang%2C+C">Christopher Kang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Ravi%2C+G+S">Gokul Subramanian Ravi</a>, 
<a href="/search/quant-ph?searchtype=author&query=Wang%2C+H">Hanrui Wang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Setia%2C+K">Kanav Setia</a>, 
<a href="/search/quant-ph?searchtype=author&query=Chong%2C+F+T">Frederic T. Chong</a>, 
<a href="/search/quant-ph?searchtype=author&query=Liu%2C+J">Junyu Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, many figures. IEEE QCE 2023, 1st best paper award in quantum algorithms
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Machine Learning (cs.LG); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item757">[757]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.13775" title="Abstract">arXiv:2211.13775</a> (replaced) [<a href="/pdf/2211.13775" title="Download PDF">pdf</a>, <a href="/format/2211.13775" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAGA: Spectral Adversarial Geometric Attack on 3D Meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stolik%2C+T">Tomer Stolik</a>, 
<a href="/search/cs?searchtype=author&query=Lang%2C+I">Itai Lang</a>, 
<a href="/search/cs?searchtype=author&query=Avidan%2C+S">Shai Avidan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at ICCV 2023. Project page: <a href="https://stoliktomer.github.io/SAGA/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item758">[758]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.16721" title="Abstract">arXiv:2211.16721</a> (replaced) [<a href="/pdf/2211.16721" title="Download PDF">pdf</a>, <a href="/format/2211.16721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Where Am I Now? Dynamically Finding Optimal Sensor States to Minimize  Localization Uncertainty for a Perception-Denied Rover
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Williams%2C+T">Troi Williams</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+P">Po-Lun Chen</a>, 
<a href="/search/cs?searchtype=author&query=Bhogavilli%2C+S">Sparsh Bhogavilli</a>, 
<a href="/search/cs?searchtype=author&query=Sanjay%2C+V">Vaibhav Sanjay</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures, Accepted to 2023 IEEE International Symposium on Multi-Robot &amp; Multi-Agent Systems (MRS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item759">[759]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.00979" title="Abstract">arXiv:2212.00979</a> (replaced) [<a href="/pdf/2212.00979" title="Download PDF">pdf</a>, <a href="/format/2212.00979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PASTA: Proportional Amplitude Spectrum Training Augmentation for  Syn-to-Real Domain Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Sarangmath%2C+K">Kartik Sarangmath</a>, 
<a href="/search/cs?searchtype=author&query=Vijaykumar%2C+V">Vivek Vijaykumar</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023, Code: <a href="https://github.com/prithv1/PASTA">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item760">[760]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01165" title="Abstract">arXiv:2212.01165</a> (replaced) [<a href="/pdf/2212.01165" title="Download PDF">pdf</a>, <a href="/format/2212.01165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Active Learning for Multi-Label Classification of Remote Sensing  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%C3%B6llenbrok%2C+L">Lars M&#xf6;llenbrok</a>, 
<a href="/search/cs?searchtype=author&query=Sumbul%2C+G">Gencer Sumbul</a>, 
<a href="/search/cs?searchtype=author&query=Demir%2C+B">Beg&#xfc;m Demir</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to IEEE Geoscience and Remote Sensing Letters
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item761">[761]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01518" title="Abstract">arXiv:2212.01518</a> (replaced) [<a href="/pdf/2212.01518" title="Download PDF">pdf</a>, <a href="/format/2212.01518" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hedging Complexity in Generalization via a Parametric Distributionally  Robust Optimization Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Iyengar%2C+G">Garud Iyengar</a>, 
<a href="/search/math?searchtype=author&query=Lam%2C+H">Henry Lam</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+T">Tianyu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preliminary version appeared in AISTATS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item762">[762]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02771" title="Abstract">arXiv:2212.02771</a> (replaced) [<a href="/pdf/2212.02771" title="Download PDF">pdf</a>, <a href="/format/2212.02771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detection of large exact subgraph isomorphisms with a topology-only  graphlet index built using deterministic walks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Patrick Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+H">Henry Ye</a>, 
<a href="/search/cs?searchtype=author&query=Hayes%2C+W">Wayne Hayes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 11 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
</div>
</dd>
<dt><a name="item763">[763]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.03394" title="Abstract">arXiv:2212.03394</a> (replaced) [<a href="/pdf/2212.03394" title="Download PDF">pdf</a>, <a href="/ps/2212.03394" title="Download PostScript">ps</a>, <a href="/format/2212.03394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extending Utility Functions on Arbitrary Sets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chebotarev%2C+P">Pavel Chebotarev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 1 figure. A revised version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Data Structures and Algorithms (cs.DS); General Topology (math.GN)

</div>
</div>
</dd>
<dt><a name="item764">[764]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05250" title="Abstract">arXiv:2212.05250</a> (replaced) [<a href="/pdf/2212.05250" title="Download PDF">pdf</a>, <a href="/format/2212.05250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phases, Modalities, Temporal and Spatial Locality: Domain Specific ML  Prefetcher for Accelerating Graph Analytics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Pengmiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+R">Rajgopal Kannan</a>, 
<a href="/search/cs?searchtype=author&query=Prasanna%2C+V+K">Viktor K. Prasanna</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item765">[765]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.05370" title="Abstract">arXiv:2212.05370</a> (replaced) [<a href="/pdf/2212.05370" title="Download PDF">pdf</a>, <a href="/format/2212.05370" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Source-free Depth for Object Pop-out
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+D">Deng-Ping Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jingjing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Demonceaux%2C+C">C&#xe9;dric Demonceaux</a>, 
<a href="/search/cs?searchtype=author&query=Timofte%2C+R">Radu Timofte</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item766">[766]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07378" title="Abstract">arXiv:2212.07378</a> (replaced) [<a href="/pdf/2212.07378" title="Download PDF">pdf</a>, <a href="/format/2212.07378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhuoqian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shikai Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wayne Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item767">[767]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07425" title="Abstract">arXiv:2212.07425</a> (replaced) [<a href="/pdf/2212.07425" title="Download PDF">pdf</a>, <a href="/format/2212.07425" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust and Explainable Identification of Logical Fallacies in Natural  Language Arguments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sourati%2C+Z">Zhivar Sourati</a>, 
<a href="/search/cs?searchtype=author&query=Venkatesh%2C+V+P+P">Vishnu Priya Prasanna Venkatesh</a>, 
<a href="/search/cs?searchtype=author&query=Deshpande%2C+D">Darshan Deshpande</a>, 
<a href="/search/cs?searchtype=author&query=Rawlani%2C+H">Himanshu Rawlani</a>, 
<a href="/search/cs?searchtype=author&query=Ilievski%2C+F">Filip Ilievski</a>, 
<a href="/search/cs?searchtype=author&query=Sandlin%2C+H">H&#xf4;ng-&#xc2;n Sandlin</a>, 
<a href="/search/cs?searchtype=author&query=Mermoud%2C+A">Alain Mermoud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item768">[768]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.10614" title="Abstract">arXiv:2212.10614</a> (replaced) [<a href="/pdf/2212.10614" title="Download PDF">pdf</a>, <a href="/format/2212.10614" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MolCPT: Molecule Continuous Prompt Tuning to Generalize Molecular  Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Diao%2C+C">Cameron Diao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaixiong Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zirui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiao Huang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xia Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item769">[769]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11473" title="Abstract">arXiv:2212.11473</a> (replaced) [<a href="/pdf/2212.11473" title="Download PDF">pdf</a>, <a href="/format/2212.11473" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Restoring Vision in Hazy Weather with Hierarchical Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+G">Guangpin Tao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">Wanglong Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kaihao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+W">Wenhan Luo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaoqin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+T">Tong Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 10 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Pattern Recognition, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item770">[770]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.14142" title="Abstract">arXiv:2212.14142</a> (replaced) [<a href="/pdf/2212.14142" title="Download PDF">pdf</a>, <a href="/format/2212.14142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint User Association and Bandwidth Allocation in Semantic  Communication Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+L">Le Xia</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaoqian Li</a>, 
<a href="/search/eess?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication by IEEE Transactions on Vehicular Technology. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item771">[771]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.00362" title="Abstract">arXiv:2301.00362</a> (replaced) [<a href="/pdf/2301.00362" title="Download PDF">pdf</a>, <a href="/format/2301.00362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Goal-Guided Transformer-Enabled Reinforcement Learning for Efficient  Autonomous Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenhui Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yanxin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+X">Xiangkun He</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+C">Chen Lv</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item772">[772]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01095" title="Abstract">arXiv:2301.01095</a> (replaced) [<a href="/pdf/2301.01095" title="Download PDF">pdf</a>, <a href="/format/2301.01095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Database management system performance comparisons: A systematic  literature review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taipalus%2C+T">Toni Taipalus</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Performance (cs.PF)</span>; Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item773">[773]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01947" title="Abstract">arXiv:2301.01947</a> (replaced) [<a href="/pdf/2301.01947" title="Download PDF">pdf</a>, <a href="/ps/2301.01947" title="Download PostScript">ps</a>, <a href="/format/2301.01947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StitchNet: Composing Neural Networks from Pre-Trained Fragments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teerapittayanon%2C+S">Surat Teerapittayanon</a>, 
<a href="/search/cs?searchtype=author&query=Comiter%2C+M">Marcus Comiter</a>, 
<a href="/search/cs?searchtype=author&query=McDanel%2C+B">Brad McDanel</a>, 
<a href="/search/cs?searchtype=author&query=Kung%2C+H+T">H.T. Kung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item774">[774]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.02136" title="Abstract">arXiv:2301.02136</a> (replaced) [<a href="/pdf/2301.02136" title="Download PDF">pdf</a>, <a href="/format/2301.02136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale Transforms for Signals on Simplicial Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saito%2C+N">Naoki Saito</a>, 
<a href="/search/cs?searchtype=author&query=Schonsheck%2C+S+C">Stefan C. Schonsheck</a>, 
<a href="/search/cs?searchtype=author&query=Shvarts%2C+E">Eugene Shvarts</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 Pages, Comments welcome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Signal Processing (eess.SP); Combinatorics (math.CO); Numerical Analysis (math.NA); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item775">[775]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03283" title="Abstract">arXiv:2301.03283</a> (replaced) [<a href="/pdf/2301.03283" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Robust Multilabel Method Integrating Rule-based Transparent Model,  Soft Label Correlation Learning and Label Noise Resistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lou%2C+Q">Qiongdan Lou</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zhaohong Deng</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+K">Kup-Sze Choi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shitong Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IEEE Transactions on Fuzzy Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item776">[776]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.03403" title="Abstract">arXiv:2301.03403</a> (replaced) [<a href="/pdf/2301.03403" title="Download PDF">pdf</a>, <a href="/ps/2301.03403" title="Download PostScript">ps</a>, <a href="/format/2301.03403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comprehensive review of automatic text summarization techniques:  method, data, evaluation and coding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cajueiro%2C+D+O">Daniel O. Cajueiro</a>, 
<a href="/search/cs?searchtype=author&query=Nery%2C+A+G">Arthur G. Nery</a>, 
<a href="/search/cs?searchtype=author&query=Tavares%2C+I">Igor Tavares</a>, 
<a href="/search/cs?searchtype=author&query=De+Melo%2C+M+K">Ma&#xed;sa K. De Melo</a>, 
<a href="/search/cs?searchtype=author&query=Reis%2C+S+A+d">Silvia A. dos Reis</a>, 
<a href="/search/cs?searchtype=author&query=Weigang%2C+L">Li Weigang</a>, 
<a href="/search/cs?searchtype=author&query=Celestino%2C+V+R+R">Victor R. R. Celestino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item777">[777]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.04604" title="Abstract">arXiv:2301.04604</a> (replaced) [<a href="/pdf/2301.04604" title="Download PDF">pdf</a>, <a href="/format/2301.04604" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiapeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+C">Ceyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yujun Shen</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zifan Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bo Dai</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Deli Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qifeng Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item778">[778]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.05843" title="Abstract">arXiv:2301.05843</a> (replaced) [<a href="/pdf/2301.05843" title="Download PDF">pdf</a>, <a href="/format/2301.05843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Large Language Models to Power Chatbots for Collecting User  Self-Reported Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jing Wei</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Sungdong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+H">Hyunhoon Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y">Young-Ho Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages including Appendix, 7 figures, 7 tables. Accepted to PACM HCI (CSCW 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item779">[779]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.06052" title="Abstract">arXiv:2301.06052</a> (replaced) [<a href="/pdf/2301.06052" title="Download PDF">pdf</a>, <a href="/format/2301.06052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete  Representations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianrong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yangsong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cun%2C+X">Xiaodong Cun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+S">Shaoli Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Hongwei Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Hongtao Lu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+X">Xi Shen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023. Project page: <a href="https://mael-zys.github.io/T2M-GPT/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item780">[780]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08038" title="Abstract">arXiv:2301.08038</a> (replaced) [<a href="/pdf/2301.08038" title="Download PDF">pdf</a>, <a href="/format/2301.08038" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified Architecture for Dynamic Role Allocation and Collaborative  Task Planning in Mixed Human-Robot Teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lamon%2C+E">Edoardo Lamon</a> (1,2), 
<a href="/search/cs?searchtype=author&query=Fusaro%2C+F">Fabio Fusaro</a> (1,3), 
<a href="/search/cs?searchtype=author&query=De+Momi%2C+E">Elena De Momi</a> (1,3), 
<a href="/search/cs?searchtype=author&query=Ajoudani%2C+A">Arash Ajoudani</a> (1) ((1) Human-Robot Interfaces and Interaction, Istituto Italiano di Tecnologia, Genoa, Italy, (2) Department of Information Engineering and Computer Science, Universit&#xe0; di Trento, Trento, Italy, (3) Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 20 figures, 2nd round review at Transaction on Robotics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item781">[781]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08688" title="Abstract">arXiv:2301.08688</a> (replaced) [<a href="/pdf/2301.08688" title="Download PDF">pdf</a>, <a href="/format/2301.08688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asynchronous Deep Double Duelling Q-Learning for Trading-Signal  Execution in Limit Order Book Markets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Nagy%2C+P">Peer Nagy</a>, 
<a href="/search/q-fin?searchtype=author&query=Calliess%2C+J">Jan-Peter Calliess</a>, 
<a href="/search/q-fin?searchtype=author&query=Zohren%2C+S">Stefan Zohren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Trading and Market Microstructure (q-fin.TR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item782">[782]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.08807" title="Abstract">arXiv:2301.08807</a> (replaced) [<a href="/pdf/2301.08807" title="Download PDF">pdf</a>, <a href="/format/2301.08807" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 4-clique Network Minor Embedding for Quantum Annealers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pelofske%2C+E">Elijah Pelofske</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET); Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item783">[783]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10100" title="Abstract">arXiv:2301.10100</a> (replaced) [<a href="/pdf/2301.10100" title="Download PDF">pdf</a>, <a href="/format/2301.10100" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using a Waffle Iron for Automotive Point Cloud Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Puy%2C+G">Gilles Puy</a>, 
<a href="/search/cs?searchtype=author&query=Boulch%2C+A">Alexandre Boulch</a>, 
<a href="/search/cs?searchtype=author&query=Marlet%2C+R">Renaud Marlet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV23. Code available at <a href="https://github.com/valeoai/WaffleIron">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item784">[784]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.10859" title="Abstract">arXiv:2301.10859</a> (replaced) [<a href="/pdf/2301.10859" title="Download PDF">pdf</a>, <a href="/format/2301.10859" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Salesforce CausalAI Library: A Fast and Scalable Framework for Causal  Analysis of Time Series and Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arpit%2C+D">Devansh Arpit</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+M">Matthew Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Feigenbaum%2C+I">Itai Feigenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+W">Weiran Yao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenghao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenzhuo Yang</a>, 
<a href="/search/cs?searchtype=author&query=Josel%2C+P">Paul Josel</a>, 
<a href="/search/cs?searchtype=author&query=Heinecke%2C+S">Shelby Heinecke</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+E">Eric Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Huan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Hoi%2C+S">Stephen Hoi</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+C">Caiming Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Niebles%2C+J+C">Juan Carlos Niebles</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item785">[785]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.11056" title="Abstract">arXiv:2301.11056</a> (replaced) [<a href="/pdf/2301.11056" title="Download PDF">pdf</a>, <a href="/format/2301.11056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Lower Bound in the $abc$ Conjecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bright%2C+C">Curtis Bright</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item786">[786]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12184" title="Abstract">arXiv:2301.12184</a> (replaced) [<a href="/pdf/2301.12184" title="Download PDF">pdf</a>, <a href="/ps/2301.12184" title="Download PostScript">ps</a>, <a href="/format/2301.12184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Laplacian-based Semi-Supervised Learning in Multilayer Hypergraphs by  Coordinate Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Venturini%2C+S">Sara Venturini</a>, 
<a href="/search/cs?searchtype=author&query=Cristofari%2C+A">Andrea Cristofari</a>, 
<a href="/search/cs?searchtype=author&query=Rinaldi%2C+F">Francesco Rinaldi</a>, 
<a href="/search/cs?searchtype=author&query=Tudisco%2C+F">Francesco Tudisco</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item787">[787]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00521" title="Abstract">arXiv:2302.00521</a> (replaced) [<a href="/pdf/2302.00521" title="Download PDF">pdf</a>, <a href="/format/2302.00521" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Formanek%2C+C">Claude Formanek</a>, 
<a href="/search/cs?searchtype=author&query=Jeewa%2C+A">Asad Jeewa</a>, 
<a href="/search/cs?searchtype=author&query=Shock%2C+J">Jonathan Shock</a>, 
<a href="/search/cs?searchtype=author&query=Pretorius%2C+A">Arnu Pretorius</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended Abstract at Autonomous Agents and Multi-Agent Systems Conference 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item788">[788]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00869" title="Abstract">arXiv:2302.00869</a> (replaced) [<a href="/pdf/2302.00869" title="Download PDF">pdf</a>, <a href="/format/2302.00869" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disentanglement of Latent Representations via Causal Interventions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gendron%2C+G">Ga&#xeb;l Gendron</a>, 
<a href="/search/cs?searchtype=author&query=Witbrock%2C+M">Michael Witbrock</a>, 
<a href="/search/cs?searchtype=author&query=Dobbie%2C+G">Gillian Dobbie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages, 10 pages for the main paper and 6 pages for the supplement, 14 figures, accepted to IJCAI 2023. V3: content matches the IJCAI version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the Thirty-Second International Joint Conference on
  Artificial Intelligence. IJCAI 2023. Main Track. Pages 3239-3247
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Discrete Mathematics (cs.DM); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item789">[789]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01733" title="Abstract">arXiv:2302.01733</a> (replaced) [<a href="/pdf/2302.01733" title="Download PDF">pdf</a>, <a href="/format/2302.01733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Committed Private Information Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Quang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+H+Y">Hong Yen Tran</a>, 
<a href="/search/cs?searchtype=author&query=Dau%2C+S+H">Son Hoang Dau</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+X">Xun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Viterbo%2C+E">Emanuele Viterbo</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+C">Chen Feng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yu-Chih Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jingge Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Kruglik%2C+S">Stanislav Kruglik</a>, 
<a href="/search/cs?searchtype=author&query=Kiah%2C+H+M">Han Mao Kiah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ESORICS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Databases (cs.DB); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item790">[790]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.01790" title="Abstract">arXiv:2302.01790</a> (replaced) [<a href="/pdf/2302.01790" title="Download PDF">pdf</a>, <a href="/format/2302.01790" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding metric-related pitfalls in image analysis validation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reinke%2C+A">Annika Reinke</a>, 
<a href="/search/cs?searchtype=author&query=Tizabi%2C+M+D">Minu D. Tizabi</a>, 
<a href="/search/cs?searchtype=author&query=Baumgartner%2C+M">Michael Baumgartner</a>, 
<a href="/search/cs?searchtype=author&query=Eisenmann%2C+M">Matthias Eisenmann</a>, 
<a href="/search/cs?searchtype=author&query=Heckmann-N%C3%B6tzel%2C+D">Doreen Heckmann-N&#xf6;tzel</a>, 
<a href="/search/cs?searchtype=author&query=Kavur%2C+A+E">A. Emre Kavur</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%A4dsch%2C+T">Tim R&#xe4;dsch</a>, 
<a href="/search/cs?searchtype=author&query=Sudre%2C+C+H">Carole H. Sudre</a>, 
<a href="/search/cs?searchtype=author&query=Acion%2C+L">Laura Acion</a>, 
<a href="/search/cs?searchtype=author&query=Antonelli%2C+M">Michela Antonelli</a>, 
<a href="/search/cs?searchtype=author&query=Arbel%2C+T">Tal Arbel</a>, 
<a href="/search/cs?searchtype=author&query=Bakas%2C+S">Spyridon Bakas</a>, 
<a href="/search/cs?searchtype=author&query=Benis%2C+A">Arriel Benis</a>, 
<a href="/search/cs?searchtype=author&query=Blaschko%2C+M">Matthew Blaschko</a>, 
<a href="/search/cs?searchtype=author&query=Buettner%2C+F">Florian Buettner</a>, 
<a href="/search/cs?searchtype=author&query=Cardoso%2C+M+J">M. Jorge Cardoso</a>, 
<a href="/search/cs?searchtype=author&query=Cheplygina%2C+V">Veronika Cheplygina</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianxu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Christodoulou%2C+E">Evangelia Christodoulou</a>, 
<a href="/search/cs?searchtype=author&query=Cimini%2C+B+A">Beth A. Cimini</a>, 
<a href="/search/cs?searchtype=author&query=Collins%2C+G+S">Gary S. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Farahani%2C+K">Keyvan Farahani</a>, 
<a href="/search/cs?searchtype=author&query=Ferrer%2C+L">Luciana Ferrer</a>, 
<a href="/search/cs?searchtype=author&query=Galdran%2C+A">Adrian Galdran</a>, 
<a href="/search/cs?searchtype=author&query=van+Ginneken%2C+B">Bram van Ginneken</a>, 
<a href="/search/cs?searchtype=author&query=Glocker%2C+B">Ben Glocker</a>, 
<a href="/search/cs?searchtype=author&query=Godau%2C+P">Patrick Godau</a>, 
<a href="/search/cs?searchtype=author&query=Haase%2C+R">Robert Haase</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+D+A">Daniel A. Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+M+M">Michael M. Hoffman</a>, 
<a href="/search/cs?searchtype=author&query=Huisman%2C+M">Merel Huisman</a>, 
<a href="/search/cs?searchtype=author&query=Isensee%2C+F">Fabian Isensee</a>, 
<a href="/search/cs?searchtype=author&query=Jannin%2C+P">Pierre Jannin</a>, 
<a href="/search/cs?searchtype=author&query=Kahn%2C+C+E">Charles E. Kahn</a>, 
<a href="/search/cs?searchtype=author&query=Kainmueller%2C+D">Dagmar Kainmueller</a>, 
<a href="/search/cs?searchtype=author&query=Kainz%2C+B">Bernhard Kainz</a>, 
<a href="/search/cs?searchtype=author&query=Karargyris%2C+A">Alexandros Karargyris</a>, 
<a href="/search/cs?searchtype=author&query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, 
<a href="/search/cs?searchtype=author&query=Kenngott%2C+H">Hannes Kenngott</a>, 
<a href="/search/cs?searchtype=author&query=Kleesiek%2C+J">Jens Kleesiek</a>, 
<a href="/search/cs?searchtype=author&query=Kofler%2C+F">Florian Kofler</a>, 
<a href="/search/cs?searchtype=author&query=Kooi%2C+T">Thijs Kooi</a>, 
<a href="/search/cs?searchtype=author&query=Kopp-Schneider%2C+A">Annette Kopp-Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Kozubek%2C+M">Michal Kozubek</a>, 
<a href="/search/cs?searchtype=author&query=Kreshuk%2C+A">Anna Kreshuk</a>, 
<a href="/search/cs?searchtype=author&query=Kurc%2C+T">Tahsin Kurc</a>, 
<a href="/search/cs?searchtype=author&query=Landman%2C+B+A">Bennett A. Landman</a>,  et al. (31 additional authors not shown)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Shared first authors: Annika Reinke, Minu D. Tizabi; shared senior authors: Paul F. J\"ager, Lena Maier-Hein
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item791">[791]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02012" title="Abstract">arXiv:2302.02012</a> (replaced) [<a href="/pdf/2302.02012" title="Download PDF">pdf</a>, <a href="/format/2302.02012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeTorrent: An Adversarial Padding-only Traffic Analysis Defense
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Holland%2C+J+K">James K Holland</a>, 
<a href="/search/cs?searchtype=author&query=Carpenter%2C+J">Jason Carpenter</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+S+E">Se Eun Oh</a>, 
<a href="/search/cs?searchtype=author&query=Hopper%2C+N">Nicholas Hopper</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 24th Privacy Enhancing Technologies Symposium (PETS 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item792">[792]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04668" title="Abstract">arXiv:2302.04668</a> (replaced) [<a href="/pdf/2302.04668" title="Download PDF">pdf</a>, <a href="/ps/2302.04668" title="Download PostScript">ps</a>, <a href="/format/2302.04668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deciding Equations in the Time Warp Algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Gool%2C+S">Sam van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Guatto%2C+A">Adrien Guatto</a>, 
<a href="/search/cs?searchtype=author&query=Metcalfe%2C+G">George Metcalfe</a>, 
<a href="/search/cs?searchtype=author&query=Santschi%2C+S">Simon Santschi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item793">[793]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.04991" title="Abstract">arXiv:2302.04991</a> (replaced) [<a href="/pdf/2302.04991" title="Download PDF">pdf</a>, <a href="/format/2302.04991" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Graph-Based Modeling Framework for Tracing Hydrological Pollutant  Transport in Surface Waters
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cole%2C+D+L">David L. Cole</a>, 
<a href="/search/cs?searchtype=author&query=Ruiz-Mercado%2C+G+J">Gerardo J. Ruiz-Mercado</a>, 
<a href="/search/cs?searchtype=author&query=Zavala%2C+V+M">Victor M. Zavala</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 41 pages, 9 figures; minor update to analysis (e.g., urban land cover to case studies; overall results remain unchanged)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item794">[794]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05364" title="Abstract">arXiv:2302.05364</a> (replaced) [<a href="/pdf/2302.05364" title="Download PDF">pdf</a>, <a href="/format/2302.05364" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predicting the cardinality and maximum degree of a reduced Gr&#xf6;bner  basis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Jamshidi%2C+S">Shahrzad Jamshidi</a>, 
<a href="/search/math?searchtype=author&query=Kang%2C+E">Eric Kang</a>, 
<a href="/search/math?searchtype=author&query=Petrovi%C4%87%2C+S">Sonja Petrovi&#x107;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Commutative Algebra (math.AC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item795">[795]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05797" title="Abstract">arXiv:2302.05797</a> (replaced) [<a href="/pdf/2302.05797" title="Download PDF">pdf</a>, <a href="/ps/2302.05797" title="Download PostScript">ps</a>, <a href="/format/2302.05797" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Global Convergence Rate of Deep Equilibrium Models with General  Activations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Truong%2C+L+V">Lan V. Truong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages. arXiv admin note: text overlap with <a href="/abs/2205.13814">arXiv:2205.13814</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item796">[796]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05865" title="Abstract">arXiv:2302.05865</a> (replaced) [<a href="/pdf/2302.05865" title="Download PDF">pdf</a>, <a href="/format/2302.05865" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flag Aggregator: Scalable Distributed Training under Failures and  Augmented Losses using Convex Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Almasi%2C+H">Hamidreza Almasi</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+H">Harsh Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Vamanan%2C+B">Balajee Vamanan</a>, 
<a href="/search/cs?searchtype=author&query=Ravi%2C+S+N">Sathya N. Ravi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item797">[797]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08051" title="Abstract">arXiv:2302.08051</a> (replaced) [<a href="/pdf/2302.08051" title="Download PDF">pdf</a>, <a href="/format/2302.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph Adversarial Immunization for Certifiable Robustness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tao%2C+S">Shuchang Tao</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+H">Huawei Shen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+Q">Qi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yunfan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+L">Liang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xueqi Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in TKDE. Code: <a href="https://github.com/TaoShuchang/AdvImmune_node">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item798">[798]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08924" title="Abstract">arXiv:2302.08924</a> (replaced) [<a href="/pdf/2302.08924" title="Download PDF">pdf</a>, <a href="/format/2302.08924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-unit Auction over a Social Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yuan Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Mengxiao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jiamou Liu</a>, 
<a href="/search/cs?searchtype=author&query=Khoussainov%2C+B">Bakh Khoussainov</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Mingyu Xiao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>

</div>
</div>
</dd>
<dt><a name="item799">[799]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11637" title="Abstract">arXiv:2302.11637</a> (replaced) [<a href="/pdf/2302.11637" title="Download PDF">pdf</a>, <a href="/ps/2302.11637" title="Download PostScript">ps</a>, <a href="/format/2302.11637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hitting Sets when the Shallow Cell Complexity is Small
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aarts%2C+S">Sander Aarts</a>, 
<a href="/search/cs?searchtype=author&query=Shmoys%2C+D+B">David B. Shmoys</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by WAOA2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item800">[800]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11939" title="Abstract">arXiv:2302.11939</a> (replaced) [<a href="/pdf/2302.11939" title="Download PDF">pdf</a>, <a href="/format/2302.11939" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One Fits All:Power General Time Series Analysis by Pretrained LM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+T">Tian Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+P">PeiSong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Liang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+R">Rong Jin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Neurips 2023 Spotlight
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item801">[801]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.11993" title="Abstract">arXiv:2302.11993</a> (replaced) [<a href="/pdf/2302.11993" title="Download PDF">pdf</a>, <a href="/format/2302.11993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> xURLLC-Aware Service Provisioning in Vehicular Networks: A Semantic  Communication Perspective
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Xia%2C+L">Le Xia</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/eess?searchtype=author&query=Niyato%2C+D">Dusit Niyato</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+D">Daquan Feng</a>, 
<a href="/search/eess?searchtype=author&query=Feng%2C+L">Lei Feng</a>, 
<a href="/search/eess?searchtype=author&query=Imran%2C+M+A">Muhammad Ali Imran</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication by IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item802">[802]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12168" title="Abstract">arXiv:2302.12168</a> (replaced) [<a href="/pdf/2302.12168" title="Download PDF">pdf</a>, <a href="/format/2302.12168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A comparative assessment of deep learning models for day-ahead load  forecasting: Investigating key accuracy drivers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelekis%2C+S">Sotiris Pelekis</a>, 
<a href="/search/cs?searchtype=author&query=Seisopoulos%2C+I">Ioannis-Konstantinos Seisopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Spiliotis%2C+E">Evangelos Spiliotis</a>, 
<a href="/search/cs?searchtype=author&query=Pountridis%2C+T">Theodosios Pountridis</a>, 
<a href="/search/cs?searchtype=author&query=Karakolis%2C+E">Evangelos Karakolis</a>, 
<a href="/search/cs?searchtype=author&query=Mouzakitis%2C+S">Spiros Mouzakitis</a>, 
<a href="/search/cs?searchtype=author&query=Askounis%2C+D">Dimitris Askounis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Short-Term Load Forecasting, Deep Learning, Ensemble, N-BEATS, Temporal Convolution, Forecasting Accuracy
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sustainable Energy, Grids and Networks, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item803">[803]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.12189" title="Abstract">arXiv:2302.12189</a> (replaced) [<a href="/pdf/2302.12189" title="Download PDF">pdf</a>, <a href="/format/2302.12189" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HL Dataset: Visually-grounded Description of Scenes, Actions and  Rationales
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cafagna%2C+M">Michele Cafagna</a>, 
<a href="/search/cs?searchtype=author&query=van+Deemter%2C+K">Kees van Deemter</a>, 
<a href="/search/cs?searchtype=author&query=Gatt%2C+A">Albert Gatt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item804">[804]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13057" title="Abstract">arXiv:2302.13057</a> (replaced) [<a href="/pdf/2302.13057" title="Download PDF">pdf</a>, <a href="/format/2302.13057" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeepBrainPrint: A Novel Contrastive Framework for Brain MRI  Re-Identification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Puglisi%2C+L">Lemuel Puglisi</a> (for the Alzheimer&#x27;s Disease Neuroimaging Initiative), 
<a href="/search/eess?searchtype=author&query=Barkhof%2C+F">Frederik Barkhof</a>, 
<a href="/search/eess?searchtype=author&query=Alexander%2C+D+C">Daniel C. Alexander</a>, 
<a href="/search/eess?searchtype=author&query=Parker%2C+G+J">Geoffrey JM Parker</a>, 
<a href="/search/eess?searchtype=author&query=Eshaghi%2C+A">Arman Eshaghi</a>, 
<a href="/search/eess?searchtype=author&query=Rav%C3%AC%2C+D">Daniele Rav&#xec;</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item805">[805]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14007" title="Abstract">arXiv:2302.14007</a> (replaced) [<a href="/pdf/2302.14007" title="Download PDF">pdf</a>, <a href="/format/2302.14007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud  Pre-training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Ziyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Renrui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+L">Longtian Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xianzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Heng%2C+P">Pheng-Ann Heng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by IJCAI 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item806">[806]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14040" title="Abstract">arXiv:2302.14040</a> (replaced) [<a href="/pdf/2302.14040" title="Download PDF">pdf</a>, <a href="/format/2302.14040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation Equivariant Neural Functionals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+A">Allan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kaien Yang</a>, 
<a href="/search/cs?searchtype=author&query=Burns%2C+K">Kaylee Burns</a>, 
<a href="/search/cs?searchtype=author&query=Cardace%2C+A">Adriano Cardace</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yiding Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Sokota%2C+S">Samuel Sokota</a>, 
<a href="/search/cs?searchtype=author&query=Kolter%2C+J+Z">J. Zico Kolter</a>, 
<a href="/search/cs?searchtype=author&query=Finn%2C+C">Chelsea Finn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in Neural Information Processing Systems (NeurIPS), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item807">[807]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14479" title="Abstract">arXiv:2302.14479</a> (replaced) [<a href="/pdf/2302.14479" title="Download PDF">pdf</a>, <a href="/format/2302.14479" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey of Automatic Generation of Attack Trees and Attack Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Konsta%2C+A">Alyzia-Maria Konsta</a>, 
<a href="/search/cs?searchtype=author&query=Spiga%2C+B">Beatrice Spiga</a>, 
<a href="/search/cs?searchtype=author&query=Lafuente%2C+A+L">Alberto Lluch Lafuente</a>, 
<a href="/search/cs?searchtype=author&query=Dragoni%2C+N">Nicola Dragoni</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item808">[808]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.14762" title="Abstract">arXiv:2302.14762</a> (replaced) [<a href="/pdf/2302.14762" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kartezio: Evolutionary Design of Explainable Pipelines for Biomedical  Image Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cortacero%2C+K">K&#xe9;vin Cortacero</a>, 
<a href="/search/cs?searchtype=author&query=McKenzie%2C+B">Brienne McKenzie</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%BCller%2C+S">Sabina M&#xfc;ller</a>, 
<a href="/search/cs?searchtype=author&query=Khazen%2C+R">Roxana Khazen</a>, 
<a href="/search/cs?searchtype=author&query=Lafouresse%2C+F">Fanny Lafouresse</a>, 
<a href="/search/cs?searchtype=author&query=Corsaut%2C+G">Ga&#xeb;lle Corsaut</a>, 
<a href="/search/cs?searchtype=author&query=Van+Acker%2C+N">Nathalie Van Acker</a>, 
<a href="/search/cs?searchtype=author&query=Frenois%2C+F">Fran&#xe7;ois-Xavier Frenois</a>, 
<a href="/search/cs?searchtype=author&query=Lamant%2C+L">Laurence Lamant</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+N">Nicolas Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Vergier%2C+B">B&#xe9;atrice Vergier</a>, 
<a href="/search/cs?searchtype=author&query=Wilson%2C+D+G">Dennis G. Wilson</a>, 
<a href="/search/cs?searchtype=author&query=Luga%2C+H">Herv&#xe9; Luga</a>, 
<a href="/search/cs?searchtype=author&query=Staufer%2C+O">Oskar Staufer</a>, 
<a href="/search/cs?searchtype=author&query=Dustin%2C+M+L">Michael L. Dustin</a>, 
<a href="/search/cs?searchtype=author&query=Valitutti%2C+S">Salvatore Valitutti</a>, 
<a href="/search/cs?searchtype=author&query=Cussat-Blanc%2C+S">Sylvain Cussat-Blanc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 6 main Figures. The Extended Data Movie is available at the following link: <a href="https://www.youtube.com/watch?v=r74gdzb6hdA.">this https URL</a> The source code is available on Github: <a href="https://github.com/KevinCortacero/Kartezio">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item809">[809]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00186" title="Abstract">arXiv:2303.00186</a> (replaced) [<a href="/pdf/2303.00186" title="Download PDF">pdf</a>, <a href="/format/2303.00186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Targeted demand response for flexible energy communities using  clustering techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pelekis%2C+S">Sotiris Pelekis</a>, 
<a href="/search/cs?searchtype=author&query=Pipergias%2C+A">Angelos Pipergias</a>, 
<a href="/search/cs?searchtype=author&query=Karakolis%2C+E">Evangelos Karakolis</a>, 
<a href="/search/cs?searchtype=author&query=Mouzakitis%2C+S">Spiros Mouzakitis</a>, 
<a href="/search/cs?searchtype=author&query=Santori%2C+F">Francesca Santori</a>, 
<a href="/search/cs?searchtype=author&query=Ghoreishi%2C+M">Mohammad Ghoreishi</a>, 
<a href="/search/cs?searchtype=author&query=Askounis%2C+D">Dimitris Askounis</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Sustainable Energy, Grids and Networks Volume 36, December 2023,
  101134
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item810">[810]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.00998" title="Abstract">arXiv:2303.00998</a> (replaced) [<a href="/pdf/2303.00998" title="Download PDF">pdf</a>, <a href="/format/2303.00998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward Wheeled Mobility on Vertically Challenging Terrain: Platforms,  Datasets, and Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datar%2C+A">Aniket Datar</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chenhui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Nazeri%2C+M">Mohammad Nazeri</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://www.youtube.com/watch?v=uk62ITBGoTI">this https URL</a> <a href="https://cs.gmu.edu/~xiao/Research/Verti-Wheelers/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item811">[811]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01037" title="Abstract">arXiv:2303.01037</a> (replaced) [<a href="/pdf/2303.01037" title="Download PDF">pdf</a>, <a href="/format/2303.01037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+W">Wei Han</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+J">James Qin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Bapna%2C+A">Ankur Bapna</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhehuai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+N">Nanxin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Axelrod%2C+V">Vera Axelrod</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gary Wang</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+K">Ke Hu</a>, 
<a href="/search/cs?searchtype=author&query=Rosenberg%2C+A">Andrew Rosenberg</a>, 
<a href="/search/cs?searchtype=author&query=Prabhavalkar%2C+R">Rohit Prabhavalkar</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+D+S">Daniel S. Park</a>, 
<a href="/search/cs?searchtype=author&query=Haghani%2C+P">Parisa Haghani</a>, 
<a href="/search/cs?searchtype=author&query=Riesa%2C+J">Jason Riesa</a>, 
<a href="/search/cs?searchtype=author&query=Perng%2C+G">Ginger Perng</a>, 
<a href="/search/cs?searchtype=author&query=Soltau%2C+H">Hagen Soltau</a>, 
<a href="/search/cs?searchtype=author&query=Strohman%2C+T">Trevor Strohman</a>, 
<a href="/search/cs?searchtype=author&query=Ramabhadran%2C+B">Bhuvana Ramabhadran</a>, 
<a href="/search/cs?searchtype=author&query=Sainath%2C+T">Tara Sainath</a>, 
<a href="/search/cs?searchtype=author&query=Moreno%2C+P">Pedro Moreno</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+C">Chung-Cheng Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Schalkwyk%2C+J">Johan Schalkwyk</a>, 
<a href="/search/cs?searchtype=author&query=Beaufays%2C+F">Fran&#xe7;oise Beaufays</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yonghui Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages, 7 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item812">[812]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01543" title="Abstract">arXiv:2303.01543</a> (replaced) [<a href="/pdf/2303.01543" title="Download PDF">pdf</a>, <a href="/format/2303.01543" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decision-Oriented Learning with Differentiable Submodular Maximization  for Vehicle Routing Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+G">Guangyao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> camera-ready version for IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item813">[813]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01619" title="Abstract">arXiv:2303.01619</a> (replaced) [<a href="/pdf/2303.01619" title="Download PDF">pdf</a>, <a href="/format/2303.01619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Conflict-Based Model Predictive Control for Scalable Multi-Robot Motion  Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tajbakhsh%2C+A">Ardalan Tajbakhsh</a>, 
<a href="/search/cs?searchtype=author&query=Biegler%2C+L+T">Lorenz T. Biegler</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item814">[814]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.01692" title="Abstract">arXiv:2303.01692</a> (replaced) [<a href="/pdf/2303.01692" title="Download PDF">pdf</a>, <a href="/format/2303.01692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Travel Demand Forecasting: A Fair AI Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xiaojian Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ke%2C+Q">Qian Ke</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xilei Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> improved the methodology; updated new contents
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item815">[815]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02549" title="Abstract">arXiv:2303.02549</a> (replaced) [<a href="/pdf/2303.02549" title="Download PDF">pdf</a>, <a href="/format/2303.02549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Computing Connection Matrices via Persistence-like Reductions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Dey%2C+T+K">Tamal K. Dey</a>, 
<a href="/search/math?searchtype=author&query=Lipi%C5%84ski%2C+M">Micha&#x142; Lipi&#x144;ski</a>, 
<a href="/search/math?searchtype=author&query=Mrozek%2C+M">Marian Mrozek</a>, 
<a href="/search/math?searchtype=author&query=Slechta%2C+R">Ryan Slechta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Algebraic Topology (math.AT)</span>; Computational Geometry (cs.CG); Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item816">[816]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03339" title="Abstract">arXiv:2303.03339</a> (replaced) [<a href="/pdf/2303.03339" title="Download PDF">pdf</a>, <a href="/format/2303.03339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reducing Safety Interventions in Provably Safe Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thumm%2C+J">Jakob Thumm</a>, 
<a href="/search/cs?searchtype=author&query=Pelat%2C+G">Guillaume Pelat</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item817">[817]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.03547" title="Abstract">arXiv:2303.03547</a> (replaced) [<a href="/pdf/2303.03547" title="Download PDF">pdf</a>, <a href="/format/2303.03547" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Small singular values can increase in lower precision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Boutsikas%2C+C">Christos Boutsikas</a>, 
<a href="/search/math?searchtype=author&query=Drineas%2C+P">Petros Drineas</a>, 
<a href="/search/math?searchtype=author&query=Ipsen%2C+I+C+F">Ilse C.F. Ipsen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item818">[818]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04968" title="Abstract">arXiv:2303.04968</a> (replaced) [<a href="/pdf/2303.04968" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconstruction of Cardiac Cine MRI under Free-breathing using  Motion-guided Deformable Alignment and Multi-resolution Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+X">Xiaoxiang Han</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Q">Qiaohong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yiman Liu</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+K">Keyan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+Y">Yuanjie Lin</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+W">Weikun Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 5 tables, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item819">[819]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05193" title="Abstract">arXiv:2303.05193</a> (replaced) [<a href="/pdf/2303.05193" title="Download PDF">pdf</a>, <a href="/format/2303.05193" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GOATS: Goal Sampling Adaptation for Scooping with Curriculum  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Niu%2C+Y">Yaru Niu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Shiyu Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jiacheng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+D">Ding Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangjun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item820">[820]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05341" title="Abstract">arXiv:2303.05341</a> (replaced) [<a href="/pdf/2303.05341" title="Download PDF">pdf</a>, <a href="/format/2303.05341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Penalized Deep Partially Linear Cox Models with Application to CT Scans  of Lung Cancer Patients
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sun%2C+Y">Yuming Sun</a>, 
<a href="/search/stat?searchtype=author&query=Kang%2C+J">Jian Kang</a>, 
<a href="/search/stat?searchtype=author&query=Haridas%2C+C">Chinmay Haridas</a>, 
<a href="/search/stat?searchtype=author&query=Mayne%2C+N+R">Nicholas R. Mayne</a>, 
<a href="/search/stat?searchtype=author&query=Potter%2C+A+L">Alexandra L. Potter</a>, 
<a href="/search/stat?searchtype=author&query=Yang%2C+C+J">Chi-Fu Jeffrey Yang</a>, 
<a href="/search/stat?searchtype=author&query=Christiani%2C+D+C">David C. Christiani</a>, 
<a href="/search/stat?searchtype=author&query=Li%2C+Y">Yi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item821">[821]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.05916" title="Abstract">arXiv:2303.05916</a> (replaced) [<a href="/pdf/2303.05916" title="Download PDF">pdf</a>, <a href="/format/2303.05916" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GECCO: Geometrically-Conditioned Point Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tyszkiewicz%2C+M+J">Micha&#x142; J. Tyszkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Fua%2C+P">Pascal Fua</a>, 
<a href="/search/cs?searchtype=author&query=Trulls%2C+E">Eduard Trulls</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item822">[822]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06945" title="Abstract">arXiv:2303.06945</a> (replaced) [<a href="/pdf/2303.06945" title="Download PDF">pdf</a>, <a href="/format/2303.06945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoGANPPIS: A Coevolution-enhanced Global Attention Neural Network for  Protein-Protein Interaction Site Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Guo%2C+J">Jiaxing Guo</a>, 
<a href="/search/q-bio?searchtype=author&query=Zhu%2C+X">Xuening Zhu</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+Z">Zixin Hu</a>, 
<a href="/search/q-bio?searchtype=author&query=Hu%2C+X">Xiaoxi Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item823">[823]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06950" title="Abstract">arXiv:2303.06950</a> (replaced) [<a href="/pdf/2303.06950" title="Download PDF">pdf</a>, <a href="/format/2303.06950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconfigurable Distributed Antennas and Reflecting Surface: A New  Architecture for Wireless Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chengzhi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jintao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guanghua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+S">Shaodan Ma</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item824">[824]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07356" title="Abstract">arXiv:2303.07356</a> (replaced) [<a href="/pdf/2303.07356" title="Download PDF">pdf</a>, <a href="/format/2303.07356" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering Zipf&#x27;s law in intercontinental scientific collaboration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krawczyk%2C+M+J">Malgorzata J. Krawczyk</a>, 
<a href="/search/cs?searchtype=author&query=Malarz%2C+K">Krzysztof Malarz</a> (AGH University of Krak&#xf3;w)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item825">[825]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07551" title="Abstract">arXiv:2303.07551</a> (replaced) [<a href="/pdf/2303.07551" title="Download PDF">pdf</a>, <a href="/format/2303.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Merging Decision Transformers: Weight Averaging for Forming Multi-Task  Policies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawson%2C+D">Daniel Lawson</a>, 
<a href="/search/cs?searchtype=author&query=Qureshi%2C+A+H">Ahmed H. Qureshi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item826">[826]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09075" title="Abstract">arXiv:2303.09075</a> (replaced) [<a href="/pdf/2303.09075" title="Download PDF">pdf</a>, <a href="/format/2303.09075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Text Generation with Cooperative Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+Z">Zhongshen Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jiaxing Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accept by ECAI2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item827">[827]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.09744" title="Abstract">arXiv:2303.09744</a> (replaced) [<a href="/pdf/2303.09744" title="Download PDF">pdf</a>, <a href="/format/2303.09744" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inferring Occluded Agent Behavior in Dynamic Games with Noise-Corrupted  Observations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+T">Tianyu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Fridovich-Keil%2C+D">David Fridovich-Keil</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Multiagent Systems (cs.MA)</span>

</div>
</div>
</dd>
<dt><a name="item828">[828]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10523" title="Abstract">arXiv:2303.10523</a> (replaced) [<a href="/pdf/2303.10523" title="Download PDF">pdf</a>, <a href="/format/2303.10523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Interpretable Basis Extraction for Concept-Based Visual  Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Doumanoglou%2C+A">Alexandros Doumanoglou</a>, 
<a href="/search/cs?searchtype=author&query=Asteriadis%2C+S">Stylianos Asteriadis</a>, 
<a href="/search/cs?searchtype=author&query=Zarpalas%2C+D">Dimitrios Zarpalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, Accepted in IEEE Transactions on Artificial Intelligence, Special Issue on New Developments in Explainable and Interpretable AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item829">[829]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11428" title="Abstract">arXiv:2303.11428</a> (replaced) [<a href="/pdf/2303.11428" title="Download PDF">pdf</a>, <a href="/format/2303.11428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lamarr: LHCb ultra-fast simulation based on machine learning models  deployed within Gauss
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/hep-ex?searchtype=author&query=Barbetti%2C+M">Matteo Barbetti</a> (for the LHCb Simulation Project)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review in Journal of Physics: Conference Series (ACAT 2022)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">High Energy Physics - Experiment (hep-ex)</span>; Machine Learning (cs.LG); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item830">[830]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11568" title="Abstract">arXiv:2303.11568</a> (replaced) [<a href="/pdf/2303.11568" title="Download PDF">pdf</a>, <a href="/ps/2303.11568" title="Download PostScript">ps</a>, <a href="/format/2303.11568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large AI Models in Health Informatics: Applications, Challenges, and the  Future
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jianing Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jiankai Sun</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jiachuan Peng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+P">Peilun Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruiyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yinzhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lam%2C+K">Kyle Lam</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+F+P+-">Frank P.-W. Lo</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+B">Bo Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+W">Wu Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+N">Ningli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+B">Benny Lo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This article has been accepted for publication in IEEE Journal of Biomedical and Health Informatics
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> JBHI, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item831">[831]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12233" title="Abstract">arXiv:2303.12233</a> (replaced) [<a href="/pdf/2303.12233" title="Download PDF">pdf</a>, <a href="/format/2303.12233" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LOKI: Large-scale Data Reconstruction Attack against Federated Learning  through Model Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J+C">Joshua C. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+A">Atul Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Elkordy%2C+A+R">Ahmed Roushdy Elkordy</a>, 
<a href="/search/cs?searchtype=author&query=Ezzeldin%2C+Y+H">Yahya H. Ezzeldin</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>, 
<a href="/search/cs?searchtype=author&query=Bagchi%2C+S">Saurabh Bagchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the IEEE Symposium on Security &amp; Privacy (S&amp;P) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item832">[832]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13047" title="Abstract">arXiv:2303.13047</a> (replaced) [<a href="/pdf/2303.13047" title="Download PDF">pdf</a>, <a href="/format/2303.13047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Better Dynamic Graph Learning: New Architecture and Unified  Library
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+L">Le Yu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Leilei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bowen Du</a>, 
<a href="/search/cs?searchtype=author&query=Lv%2C+W">Weifeng Lv</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item833">[833]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13696" title="Abstract">arXiv:2303.13696</a> (replaced) [<a href="/pdf/2303.13696" title="Download PDF">pdf</a>, <a href="/format/2303.13696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Multi-scale Online Likelihood Network for AI-assisted  Interactive Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Asad%2C+M">Muhammad Asad</a>, 
<a href="/search/eess?searchtype=author&query=Williams%2C+H">Helena Williams</a>, 
<a href="/search/eess?searchtype=author&query=Mandal%2C+I">Indrajeet Mandal</a>, 
<a href="/search/eess?searchtype=author&query=Ather%2C+S">Sarim Ather</a>, 
<a href="/search/eess?searchtype=author&query=Deprest%2C+J">Jan Deprest</a>, 
<a href="/search/eess?searchtype=author&query=D%27hooge%2C+J">Jan D&#x27;hooge</a>, 
<a href="/search/eess?searchtype=author&query=Vercauteren%2C+T">Tom Vercauteren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item834">[834]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13748" title="Abstract">arXiv:2303.13748</a> (replaced) [<a href="/pdf/2303.13748" title="Download PDF">pdf</a>, <a href="/format/2303.13748" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Initial State Encoding via Reverse Quantum Annealing and h-gain Features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Pelofske%2C+E">Elijah Pelofske</a>, 
<a href="/search/quant-ph?searchtype=author&query=Hahn%2C+G">Georg Hahn</a>, 
<a href="/search/quant-ph?searchtype=author&query=Djidjev%2C+H">Hristo Djidjev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2009.05008">arXiv:2009.05008</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Disordered Systems and Neural Networks (cond-mat.dis-nn); Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item835">[835]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.14540" title="Abstract">arXiv:2303.14540</a> (replaced) [<a href="/pdf/2303.14540" title="Download PDF">pdf</a>, <a href="/format/2303.14540" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicarrier Rate-Splitting Multiple Access: Superiority of OFDM-RSMA  over OFDMA and OFDM-NOMA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sahin%2C+M+M">Mehmet Mert Sahin</a>, 
<a href="/search/cs?searchtype=author&query=Dizdar%2C+O">Onur Dizdar</a>, 
<a href="/search/cs?searchtype=author&query=Clerckx%2C+B">Bruno Clerckx</a>, 
<a href="/search/cs?searchtype=author&query=Arslan%2C+H">Huseyin Arslan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Updated version of published paper in IEEE Communications Letters with correction in optimization problem (17b)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item836">[836]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16047" title="Abstract">arXiv:2303.16047</a> (replaced) [<a href="/pdf/2303.16047" title="Download PDF">pdf</a>, <a href="/format/2303.16047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring and Interacting with the Set of Good Sparse Generalized  Additive Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+C">Chudi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhi Chen</a>, 
<a href="/search/cs?searchtype=author&query=Seltzer%2C+M">Margo Seltzer</a>, 
<a href="/search/cs?searchtype=author&query=Rudin%2C+C">Cynthia Rudin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item837">[837]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16280" title="Abstract">arXiv:2303.16280</a> (replaced) [<a href="/pdf/2303.16280" title="Download PDF">pdf</a>, <a href="/format/2303.16280" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UVCGAN v2: An Improved Cycle-Consistent GAN for Unpaired Image-to-Image  Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Torbunov%2C+D">Dmitrii Torbunov</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Tseng%2C+H">Huan-Hsin Tseng</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haiwang Yu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Meifeng Lin</a>, 
<a href="/search/cs?searchtype=author&query=Viren%2C+B">Brett Viren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yihui Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item838">[838]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16342" title="Abstract">arXiv:2303.16342</a> (replaced) [<a href="/pdf/2303.16342" title="Download PDF">pdf</a>, <a href="/format/2303.16342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-Guided Audio-Visual Source Separation via Trimodal Consistency
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tan%2C+R">Reuben Tan</a>, 
<a href="/search/cs?searchtype=author&query=Ray%2C+A">Arijit Ray</a>, 
<a href="/search/cs?searchtype=author&query=Burns%2C+A">Andrea Burns</a>, 
<a href="/search/cs?searchtype=author&query=Plummer%2C+B+A">Bryan A. Plummer</a>, 
<a href="/search/cs?searchtype=author&query=Salamon%2C+J">Justin Salamon</a>, 
<a href="/search/cs?searchtype=author&query=Nieto%2C+O">Oriol Nieto</a>, 
<a href="/search/cs?searchtype=author&query=Russell%2C+B">Bryan Russell</a>, 
<a href="/search/cs?searchtype=author&query=Saenko%2C+K">Kate Saenko</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at CVPR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item839">[839]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.16355" title="Abstract">arXiv:2303.16355</a> (replaced) [<a href="/pdf/2303.16355" title="Download PDF">pdf</a>, <a href="/format/2303.16355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the impact of Byzantine attacks on coupled phase oscillators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/nlin?searchtype=author&query=Tyloo%2C+M">Melvyn Tyloo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Adaptation and Self-Organizing Systems (nlin.AO)</span>; Systems and Control (eess.SY); Physics and Society (physics.soc-ph)

</div>
</div>
</dd>
<dt><a name="item840">[840]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00821" title="Abstract">arXiv:2304.00821</a> (replaced) [<a href="/pdf/2304.00821" title="Download PDF">pdf</a>, <a href="/format/2304.00821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explanation: from ethics to logic
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dowek%2C+G">Gilles Dowek</a> (DEDUCTEAM)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item841">[841]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01899" title="Abstract">arXiv:2304.01899</a> (replaced) [<a href="/pdf/2304.01899" title="Download PDF">pdf</a>, <a href="/format/2304.01899" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Class Feature Augmentation for Class Incremental Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Taehoon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jaeyoo Park</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+B">Bohyung Han</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item842">[842]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03535" title="Abstract">arXiv:2304.03535</a> (replaced) [<a href="/pdf/2304.03535" title="Download PDF">pdf</a>, <a href="/format/2304.03535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRISP: Curriculum inducing Primitive Informed Subgoal Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Utsav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V+P">Vinay P Namboodiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item843">[843]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03593" title="Abstract">arXiv:2304.03593</a> (replaced) [<a href="/pdf/2304.03593" title="Download PDF">pdf</a>, <a href="/format/2304.03593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning-Based Mapless Crowd Navigation with  Perceived Risk of the Moving Crowd for Mobile Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Anas%2C+H">Hafiq Anas</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+O+W">Ong Wee Hong</a>, 
<a href="/search/cs?searchtype=author&query=Malik%2C+O+A">Owais Ahmed Malik</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item844">[844]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04135" title="Abstract">arXiv:2304.04135</a> (replaced) [<a href="/pdf/2304.04135" title="Download PDF">pdf</a>, <a href="/format/2304.04135" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Propheter: Prophetic Teacher Guided Long-Tailed Distribution Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wenxiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Jing%2C+Y">Yongcheng Jing</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+L">Linyun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wenqi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lechao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zunlei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+M">Mingli Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item845">[845]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04531" title="Abstract">arXiv:2304.04531</a> (replaced) [<a href="/pdf/2304.04531" title="Download PDF">pdf</a>, <a href="/ps/2304.04531" title="Download PostScript">ps</a>, <a href="/format/2304.04531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Alon-Tarsi Number of Some Regular Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=S%2C+P">Prajnanaswaroopa S</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item846">[846]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.04665" title="Abstract">arXiv:2304.04665</a> (replaced) [<a href="/pdf/2304.04665" title="Download PDF">pdf</a>, <a href="/format/2304.04665" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On algorithmically boosting fixed-point computations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Avramopoulos%2C+I">Ioannis Avramopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Vasiloglou%2C+N">Nikolaos Vasiloglou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Science and Game Theory (cs.GT)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item847">[847]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05028" title="Abstract">arXiv:2304.05028</a> (replaced) [<a href="/pdf/2304.05028" title="Download PDF">pdf</a>, <a href="/format/2304.05028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Columnar Storage Formats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zeng%2C+X">Xinyu Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Hui%2C+Y">Yulong Hui</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jiahong Shen</a>, 
<a href="/search/cs?searchtype=author&query=Pavlo%2C+A">Andrew Pavlo</a>, 
<a href="/search/cs?searchtype=author&query=McKinney%2C+W">Wes McKinney</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Huanchen Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item848">[848]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05265" title="Abstract">arXiv:2304.05265</a> (replaced) [<a href="/pdf/2304.05265" title="Download PDF">pdf</a>, <a href="/format/2304.05265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Textual Inversion for Personalized Text-to-Image Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Haobo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+R">Ruixuan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Sai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junbo Zhao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures, 2 tables. Project Page: <a href="https://github.com/jnzju/COTI">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item849">[849]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06264" title="Abstract">arXiv:2304.06264</a> (replaced) [<a href="/pdf/2304.06264" title="Download PDF">pdf</a>, <a href="/format/2304.06264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fusing Odometry, UWB Ranging, and Spatial Detections for Relative  Multi-Robot Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+X">Xianjia Yu</a>, 
<a href="/search/cs?searchtype=author&query=Catalano%2C+I">Iacopo Catalano</a>, 
<a href="/search/cs?searchtype=author&query=Mor%C3%B3n%2C+P+T">Paola Torrico Mor&#xf3;n</a>, 
<a href="/search/cs?searchtype=author&query=Salimpour%2C+S">Sahar Salimpour</a>, 
<a href="/search/cs?searchtype=author&query=Westerlund%2C+T">Tomi Westerlund</a>, 
<a href="/search/cs?searchtype=author&query=Queralta%2C+J+P">Jorge Pe&#xf1;a Queralta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item850">[850]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06267" title="Abstract">arXiv:2304.06267</a> (replaced) [<a href="/pdf/2304.06267" title="Download PDF">pdf</a>, <a href="/format/2304.06267" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Piggyback on Idle Ride-Sourcing Drivers for Integrated On-Demand and  Flexible Intracity Parcel Delivery Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yang Liu</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+S">Sen Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item851">[851]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06787" title="Abstract">arXiv:2304.06787</a> (replaced) [<a href="/pdf/2304.06787" title="Download PDF">pdf</a>, <a href="/ps/2304.06787" title="Download PostScript">ps</a>, <a href="/format/2304.06787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Polynomial Time, Pure Differentially Private Estimator for Binary  Product Distributions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singhal%2C+V">Vikrant Singhal</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item852">[852]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06876" title="Abstract">arXiv:2304.06876</a> (replaced) [<a href="/pdf/2304.06876" title="Download PDF">pdf</a>, <a href="/format/2304.06876" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ho%2C+Q+H">Qi Heng Ho</a>, 
<a href="/search/eess?searchtype=author&query=Sunberg%2C+Z+N">Zachary N. Sunberg</a>, 
<a href="/search/eess?searchtype=author&query=Lahijanian%2C+M">Morteza Lahijanian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item853">[853]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07666" title="Abstract">arXiv:2304.07666</a> (replaced) [<a href="/pdf/2304.07666" title="Download PDF">pdf</a>, <a href="/format/2304.07666" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ArguGPT: evaluating, understanding and identifying argumentative essays  generated by GPT models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yikang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Ziyin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wanyang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shisen Yue</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xiaojing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+X">Xinyuan Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yiwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hai Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item854">[854]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.08332" title="Abstract">arXiv:2304.08332</a> (replaced) [<a href="/pdf/2304.08332" title="Download PDF">pdf</a>, <a href="/format/2304.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multiscale hierarchical decomposition methods for ill-posed problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kindermann%2C+S">Stefan Kindermann</a>, 
<a href="/search/math?searchtype=author&query=Resmerita%2C+E">Elena Resmerita</a>, 
<a href="/search/math?searchtype=author&query=Wolf%2C+T">Tobias Wolf</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item855">[855]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.09720" title="Abstract">arXiv:2304.09720</a> (replaced) [<a href="/pdf/2304.09720" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Genetic Algorithm Based Combinatorial Optimization for the Optimal  Design of Water Distribution Network of Gurudeniya Service Zone, Sri Lanka
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Senavirathna%2C+K+H+M+R+N">K. H. M. R. N. Senavirathna</a>, 
<a href="/search/cs?searchtype=author&query=Walgampaya%2C+C+K">C. K. Walgampaya</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the journal ENGINEER - IESL Sri Lanka. Revised on Sep 22, 2023. arXiv admin note: text overlap with <a href="/abs/2209.11993">arXiv:2209.11993</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item856">[856]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10740" title="Abstract">arXiv:2304.10740</a> (replaced) [<a href="/pdf/2304.10740" title="Download PDF">pdf</a>, <a href="/format/2304.10740" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Deep Learning for Credit Rating Prediction Using Text and  Numerical Data Streams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Tavakoli%2C+M">Mahsa Tavakoli</a>, 
<a href="/search/q-fin?searchtype=author&query=Chandra%2C+R">Rohitash Chandra</a>, 
<a href="/search/q-fin?searchtype=author&query=Tian%2C+F">Fengrui Tian</a>, 
<a href="/search/q-fin?searchtype=author&query=Bravo%2C+C">Cristi&#xe1;n Bravo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item857">[857]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.11263" title="Abstract">arXiv:2304.11263</a> (replaced) [<a href="/pdf/2304.11263" title="Download PDF">pdf</a>, <a href="/format/2304.11263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Benchmarking Low-Shot Robustness to Natural Distribution Shifts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Aaditya Singh</a>, 
<a href="/search/cs?searchtype=author&query=Sarangmath%2C+K">Kartik Sarangmath</a>, 
<a href="/search/cs?searchtype=author&query=Chattopadhyay%2C+P">Prithvijit Chattopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Hoffman%2C+J">Judy Hoffman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 Pages, 18 Tables, 12 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item858">[858]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12046" title="Abstract">arXiv:2304.12046</a> (replaced) [<a href="/pdf/2304.12046" title="Download PDF">pdf</a>, <a href="/format/2304.12046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When to Replan? An Adaptive Replanning Strategy for Autonomous  Navigation using Deep Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Honda%2C+K">Kohei Honda</a>, 
<a href="/search/cs?searchtype=author&query=Yonetani%2C+R">Ryo Yonetani</a>, 
<a href="/search/cs?searchtype=author&query=Nishimura%2C+M">Mai Nishimura</a>, 
<a href="/search/cs?searchtype=author&query=Kozuno%2C+T">Tadashi Kozuno</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item859">[859]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12367" title="Abstract">arXiv:2304.12367</a> (replaced) [<a href="/pdf/2304.12367" title="Download PDF">pdf</a>, <a href="/format/2304.12367" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Overview of the TREC 2022 NeuCLIR Track
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lawrie%2C+D">Dawn Lawrie</a>, 
<a href="/search/cs?searchtype=author&query=MacAvaney%2C+S">Sean MacAvaney</a>, 
<a href="/search/cs?searchtype=author&query=Mayfield%2C+J">James Mayfield</a>, 
<a href="/search/cs?searchtype=author&query=McNamee%2C+P">Paul McNamee</a>, 
<a href="/search/cs?searchtype=author&query=Oard%2C+D+W">Douglas W. Oard</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+E">Eugene Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, 13 figures, 10 tables. Part of the Thirty-First Text REtrieval Conference (TREC 2022) Proceedings. Replace the misplaced Russian result table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item860">[860]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.12597" title="Abstract">arXiv:2304.12597</a> (replaced) [<a href="/pdf/2304.12597" title="Download PDF">pdf</a>, <a href="/format/2304.12597" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new ParaDiag time-parallel time integration method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gander%2C+M+J">Martin J. Gander</a>, 
<a href="/search/math?searchtype=author&query=Palitta%2C+D">Davide Palitta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item861">[861]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13023" title="Abstract">arXiv:2304.13023</a> (replaced) [<a href="/pdf/2304.13023" title="Download PDF">pdf</a>, <a href="/format/2304.13023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Seeing is not always believing: Benchmarking Human and Model Perception  of AI-Generated Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zeyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+D">Di Huang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+L">Lei Bai</a>, 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jingjing Qu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chengyue Wu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xihui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+W">Wanli Ouyang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item862">[862]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13829" title="Abstract">arXiv:2304.13829</a> (replaced) [<a href="/pdf/2304.13829" title="Download PDF">pdf</a>, <a href="/format/2304.13829" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controlled density transport using Perron Frobenius generators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Buzhardt%2C+J">Jake Buzhardt</a>, 
<a href="/search/eess?searchtype=author&query=Tallapragada%2C+P">Phanindra Tallapragada</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 9 figures, accepted to CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Fluid Dynamics (physics.flu-dyn)

</div>
</div>
</dd>
<dt><a name="item863">[863]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14361" title="Abstract">arXiv:2304.14361</a> (replaced) [<a href="/pdf/2304.14361" title="Download PDF">pdf</a>, <a href="/ps/2304.14361" title="Download PostScript">ps</a>, <a href="/format/2304.14361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Quantitative Algebra for Fuzzy Relations and Generalised  Metric Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mio%2C+M">Matteo Mio</a>, 
<a href="/search/cs?searchtype=author&query=Sarkis%2C+R">Ralph Sarkis</a>, 
<a href="/search/cs?searchtype=author&query=Vignudelli%2C+V">Valeria Vignudelli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appendix removed
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item864">[864]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14774" title="Abstract">arXiv:2304.14774</a> (replaced) [<a href="/pdf/2304.14774" title="Download PDF">pdf</a>, <a href="/format/2304.14774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A feature selection method based on Shapley values robust to concept  shift in regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Sebasti%C3%A1n%2C+C">Carlos Sebasti&#xe1;n</a>, 
<a href="/search/stat?searchtype=author&query=Gonz%C3%A1lez-Guill%C3%A9n%2C+C+E">Carlos E. Gonz&#xe1;lez-Guill&#xe9;n</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item865">[865]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00799" title="Abstract">arXiv:2305.00799</a> (replaced) [<a href="/pdf/2305.00799" title="Download PDF">pdf</a>, <a href="/ps/2305.00799" title="Download PostScript">ps</a>, <a href="/format/2305.00799" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to address monotonicity for model risk management?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+D">Dangxing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+W">Weicheng Ye</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> In Proceedings of the 40th International Conference on Machine
  Learning, 2023, (Proceedings of Machine Learning Research, Vol. 202). PMLR,
  5282-5295
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item866">[866]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02034" title="Abstract">arXiv:2305.02034</a> (replaced) [<a href="/pdf/2305.02034" title="Download PDF">pdf</a>, <a href="/format/2305.02034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment  Anything Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Di Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+B">Bo Du</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Minqiang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+D">Dacheng Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+L">Liangpei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023 Datasets and Benchmarks Track. The code and dataset will be available at <a href="https://github.com/ViTAE-Transformer/SAMRS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item867">[867]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.02873" title="Abstract">arXiv:2305.02873</a> (replaced) [<a href="/pdf/2305.02873" title="Download PDF">pdf</a>, <a href="/ps/2305.02873" title="Download PostScript">ps</a>, <a href="/format/2305.02873" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closure and Decision Properties for Higher-Dimensional Automata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Amrane%2C+A">Amazigh Amrane</a>, 
<a href="/search/cs?searchtype=author&query=Bazille%2C+H">Hugo Bazille</a>, 
<a href="/search/cs?searchtype=author&query=Fahrenberg%2C+U">Uli Fahrenberg</a>, 
<a href="/search/cs?searchtype=author&query=Ziemia%C5%84ski%2C+K">Krzysztof Ziemia&#x144;ski</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item868">[868]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03271" title="Abstract">arXiv:2305.03271</a> (replaced) [<a href="/pdf/2305.03271" title="Download PDF">pdf</a>, <a href="/format/2305.03271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Is It a Trap? A Large-scale Empirical Study And Comprehensive Assessment  of Online Automated Privacy Policy Generators for Mobile Apps
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pan%2C+S">Shidong Pan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+D">Dawen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Staples%2C+M">Mark Staples</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhenchang Xing</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jieshan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+J">James Hoang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> USENIX Security 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item869">[869]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03935" title="Abstract">arXiv:2305.03935</a> (replaced) [<a href="/pdf/2305.03935" title="Download PDF">pdf</a>, <a href="/format/2305.03935" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kaiwen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cheng Lu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jianfei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICML2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item870">[870]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04107" title="Abstract">arXiv:2305.04107</a> (replaced) [<a href="/pdf/2305.04107" title="Download PDF">pdf</a>, <a href="/format/2305.04107" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DMF-TONN: Direct Mesh-free Topology Optimization using Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Joglekar%2C+A">Aditya Joglekar</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hongrui Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kara%2C+L+B">Levent Burak Kara</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item871">[871]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04222" title="Abstract">arXiv:2305.04222</a> (replaced) [<a href="/pdf/2305.04222" title="Download PDF">pdf</a>, <a href="/ps/2305.04222" title="Download PostScript">ps</a>, <a href="/format/2305.04222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Branching Place Bisimilarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gorrieri%2C+R">Roberto Gorrieri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2104.01392">arXiv:2104.01392</a>, <a href="/abs/2104.14859">arXiv:2104.14859</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
</div>
</dd>
<dt><a name="item872">[872]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.05065" title="Abstract">arXiv:2305.05065</a> (replaced) [<a href="/pdf/2305.05065" title="Download PDF">pdf</a>, <a href="/format/2305.05065" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recommender Systems with Generative Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajput%2C+S">Shashank Rajput</a>, 
<a href="/search/cs?searchtype=author&query=Mehta%2C+N">Nikhil Mehta</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A">Anima Singh</a>, 
<a href="/search/cs?searchtype=author&query=Keshavan%2C+R+H">Raghunandan H. Keshavan</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T">Trung Vu</a>, 
<a href="/search/cs?searchtype=author&query=Heldt%2C+L">Lukasz Heldt</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+L">Lichan Hong</a>, 
<a href="/search/cs?searchtype=author&query=Tay%2C+Y">Yi Tay</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+V+Q">Vinh Q. Tran</a>, 
<a href="/search/cs?searchtype=author&query=Samost%2C+J">Jonah Samost</a>, 
<a href="/search/cs?searchtype=author&query=Kula%2C+M">Maciej Kula</a>, 
<a href="/search/cs?searchtype=author&query=Chi%2C+E+H">Ed H. Chi</a>, 
<a href="/search/cs?searchtype=author&query=Sathiamoorthy%2C+M">Maheswaran Sathiamoorthy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item873">[873]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06360" title="Abstract">arXiv:2305.06360</a> (replaced) [<a href="/pdf/2305.06360" title="Download PDF">pdf</a>, <a href="/format/2305.06360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Landscape of Machine Unlearning: A Comprehensive Survey  and Taxonomy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+T">Thanveer Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item874">[874]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06739" title="Abstract">arXiv:2305.06739</a> (replaced) [<a href="/pdf/2305.06739" title="Download PDF">pdf</a>, <a href="/format/2305.06739" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Retrospective Motion Correction in MRI: A  Comprehensive Review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Spieker%2C+V">Veronika Spieker</a>, 
<a href="/search/eess?searchtype=author&query=Eichhorn%2C+H">Hannah Eichhorn</a>, 
<a href="/search/eess?searchtype=author&query=Hammernik%2C+K">Kerstin Hammernik</a>, 
<a href="/search/eess?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>, 
<a href="/search/eess?searchtype=author&query=Preibisch%2C+C">Christine Preibisch</a>, 
<a href="/search/eess?searchtype=author&query=Karampinos%2C+D+C">Dimitrios C. Karampinos</a>, 
<a href="/search/eess?searchtype=author&query=Schnabel%2C+J+A">Julia A. Schnabel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
</div>
</dd>
<dt><a name="item875">[875]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.09105" title="Abstract">arXiv:2305.09105</a> (replaced) [<a href="/pdf/2305.09105" title="Download PDF">pdf</a>, <a href="/format/2305.09105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing pre-scheduled, intermittently-observed MDPs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+P">Patrick Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+F">Federico Rossi</a>, 
<a href="/search/cs?searchtype=author&query=Shell%2C+D+A">Dylan A. Shell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item876">[876]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10345" title="Abstract">arXiv:2305.10345</a> (replaced) [<a href="/pdf/2305.10345" title="Download PDF">pdf</a>, <a href="/format/2305.10345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MM-Fi: Multi-Modal Non-Intrusive 4D Human Dataset for Versatile Wireless  Sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+J">Jianfei Yang</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+H">He Huang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+Y">Yunjiao Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xinyan Chen</a>, 
<a href="/search/eess?searchtype=author&query=Xu%2C+Y">Yuecong Xu</a>, 
<a href="/search/eess?searchtype=author&query=Yuan%2C+S">Shenghai Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Zou%2C+H">Han Zou</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+C+X">Chris Xiaoxuan Lu</a>, 
<a href="/search/eess?searchtype=author&query=Xie%2C+L">Lihua Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper has been accepted by NeurIPS 2023 Datasets and Benchmarks Track. Project page: <a href="https://ntu-aiot-lab.github.io/mm-fi">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item877">[877]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10468" title="Abstract">arXiv:2305.10468</a> (replaced) [<a href="/pdf/2305.10468" title="Download PDF">pdf</a>, <a href="/format/2305.10468" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connected Hidden Neurons (CHNNet): An Artificial Neural Network for  Rapid Convergence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahir%2C+R+S">Rafiad Sadat Shahir</a>, 
<a href="/search/cs?searchtype=author&query=Humayun%2C+Z">Zayed Humayun</a>, 
<a href="/search/cs?searchtype=author&query=Tamim%2C+M+A">Mashrufa Akter Tamim</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+S">Shouri Saha</a>, 
<a href="/search/cs?searchtype=author&query=Alam%2C+M+G+R">Md. Golam Rabiul Alam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item878">[878]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.10912" title="Abstract">arXiv:2305.10912</a> (replaced) [<a href="/pdf/2305.10912" title="Download PDF">pdf</a>, <a href="/format/2305.10912" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Generalist Dynamics Model for Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schubert%2C+I">Ingmar Schubert</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jingwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Bruce%2C+J">Jake Bruce</a>, 
<a href="/search/cs?searchtype=author&query=Bechtle%2C+S">Sarah Bechtle</a>, 
<a href="/search/cs?searchtype=author&query=Parisotto%2C+E">Emilio Parisotto</a>, 
<a href="/search/cs?searchtype=author&query=Riedmiller%2C+M">Martin Riedmiller</a>, 
<a href="/search/cs?searchtype=author&query=Springenberg%2C+J+T">Jost Tobias Springenberg</a>, 
<a href="/search/cs?searchtype=author&query=Byravan%2C+A">Arunkumar Byravan</a>, 
<a href="/search/cs?searchtype=author&query=Hasenclever%2C+L">Leonard Hasenclever</a>, 
<a href="/search/cs?searchtype=author&query=Heess%2C+N">Nicolas Heess</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item879">[879]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11283" title="Abstract">arXiv:2305.11283</a> (replaced) [<a href="/pdf/2305.11283" title="Download PDF">pdf</a>, <a href="/ps/2305.11283" title="Download PostScript">ps</a>, <a href="/format/2305.11283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Statistical Efficiency of Mean Field Reinforcement Learning with  General Function Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+J">Jiawei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yardim%2C+B">Batuhan Yardim</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+N">Niao He</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 37 Pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item880">[880]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11400" title="Abstract">arXiv:2305.11400</a> (replaced) [<a href="/pdf/2305.11400" title="Download PDF">pdf</a>, <a href="/format/2305.11400" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mode-Aware Continual Learning for Conditional Generative Adversarial  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Le%2C+C+P">Cat P. Le</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+J">Juncheng Dong</a>, 
<a href="/search/cs?searchtype=author&query=Aloui%2C+A">Ahmed Aloui</a>, 
<a href="/search/cs?searchtype=author&query=Tarokh%2C+V">Vahid Tarokh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item881">[881]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12021" title="Abstract">arXiv:2305.12021</a> (replaced) [<a href="/pdf/2305.12021" title="Download PDF">pdf</a>, <a href="/format/2305.12021" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Secure and Robust Approach for Distance-Based Mutual Positioning of  Unmanned Aerial Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+B">Bin Han</a>, 
<a href="/search/eess?searchtype=author&query=Schotten%2C+H+D">Hans D. Schotten</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE WCNC 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Multiagent Systems (cs.MA)

</div>
</div>
</dd>
<dt><a name="item882">[882]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12823" title="Abstract">arXiv:2305.12823</a> (replaced) [<a href="/pdf/2305.12823" title="Download PDF">pdf</a>, <a href="/format/2305.12823" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> READMem: Robust Embedding Association for a Diverse Memory in  Unconstrained Video Object Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vujasinovi%C4%87%2C+S">St&#xe9;phane Vujasinovi&#x107;</a>, 
<a href="/search/cs?searchtype=author&query=Bullinger%2C+S">Sebastian Bullinger</a>, 
<a href="/search/cs?searchtype=author&query=Becker%2C+S">Stefan Becker</a>, 
<a href="/search/cs?searchtype=author&query=Scherer-Negenborn%2C+N">Norbert Scherer-Negenborn</a>, 
<a href="/search/cs?searchtype=author&query=Arens%2C+M">Michael Arens</a>, 
<a href="/search/cs?searchtype=author&query=Stiefelhagen%2C+R">Rainer Stiefelhagen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023. Code @ <a href="https://github.com/Vujas-Eteph/READMem">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item883">[883]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12966" title="Abstract">arXiv:2305.12966</a> (replaced) [<a href="/pdf/2305.12966" title="Download PDF">pdf</a>, <a href="/format/2305.12966" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Integration Diffusion Model for Realistic Image Deblurring
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zheng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Ding Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+B">Bin Xia</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jinjin Gu</a>, 
<a href="/search/cs?searchtype=author&query=Kong%2C+L">Linghe Kong</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xin Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS 2023 (Spotlight). Code is available at <a href="https://github.com/zhengchen1999/HI-Diff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item884">[884]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.13494" title="Abstract">arXiv:2305.13494</a> (replaced) [<a href="/pdf/2305.13494" title="Download PDF">pdf</a>, <a href="/format/2305.13494" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Clustering for Data Cleaning and Integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rauf%2C+H+T">Hafiz Tayyab Rauf</a>, 
<a href="/search/cs?searchtype=author&query=Freitas%2C+A">Andre Freitas</a>, 
<a href="/search/cs?searchtype=author&query=Paton%2C+N+W">Norman W. Paton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The following enhancements have been carried out in the updated version of the manuscript: *Evaluated each data integration problem on additional datasets. *Added more DC and SC methods to the evaluation *Discussed algorithmic-specific observations
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
</div>
</dd>
<dt><a name="item885">[885]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14097" title="Abstract">arXiv:2305.14097</a> (replaced) [<a href="/pdf/2305.14097" title="Download PDF">pdf</a>, <a href="/format/2305.14097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhe Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 32nd USENIX Security Symposium (2023 USENIX Security); Full Version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item886">[886]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14243" title="Abstract">arXiv:2305.14243</a> (replaced) [<a href="/pdf/2305.14243" title="Download PDF">pdf</a>, <a href="/format/2305.14243" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training Transitive and Commutative Multimodal Transformers with LoReTTa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+M">Manuel Tran</a>, 
<a href="/search/cs?searchtype=author&query=Lahiani%2C+A">Amal Lahiani</a>, 
<a href="/search/cs?searchtype=author&query=Cid%2C+Y+D">Yashin Dicente Cid</a>, 
<a href="/search/cs?searchtype=author&query=Theis%2C+F+J">Fabian J. Theis</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+T">Tingying Peng</a>, 
<a href="/search/cs?searchtype=author&query=Klaiman%2C+E">Eldad Klaiman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Improved paper based on peer-reviews
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item887">[887]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14270" title="Abstract">arXiv:2305.14270</a> (replaced) [<a href="/pdf/2305.14270" title="Download PDF">pdf</a>, <a href="/format/2305.14270" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NCC: Natural Concurrency Control for Strictly Serializable Datastores by  Avoiding the Timestamp-Inversion Pitfall
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Mu%2C+S">Shuai Mu</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Siddhartha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Lloyd%2C+W">Wyatt Lloyd</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item888">[888]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14375" title="Abstract">arXiv:2305.14375</a> (replaced) [<a href="/pdf/2305.14375" title="Download PDF">pdf</a>, <a href="/format/2305.14375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MGL2Rank: Learning to Rank the Importance of Nodes in Road Networks  Based on Multi-Graph Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+M">Ming Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jing Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item889">[889]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15121" title="Abstract">arXiv:2305.15121</a> (replaced) [<a href="/pdf/2305.15121" title="Download PDF">pdf</a>, <a href="/format/2305.15121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Individual Input for Deep Anomaly Detection on Tabular Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thimonier%2C+H">Hugo Thimonier</a>, 
<a href="/search/cs?searchtype=author&query=Popineau%2C+F">Fabrice Popineau</a>, 
<a href="/search/cs?searchtype=author&query=Rimmel%2C+A">Arpad Rimmel</a>, 
<a href="/search/cs?searchtype=author&query=Doan%2C+B">Bich-Li&#xea;n Doan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item890">[890]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15324" title="Abstract">arXiv:2305.15324</a> (replaced) [<a href="/pdf/2305.15324" title="Download PDF">pdf</a>, <a href="/format/2305.15324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model evaluation for extreme risks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shevlane%2C+T">Toby Shevlane</a>, 
<a href="/search/cs?searchtype=author&query=Farquhar%2C+S">Sebastian Farquhar</a>, 
<a href="/search/cs?searchtype=author&query=Garfinkel%2C+B">Ben Garfinkel</a>, 
<a href="/search/cs?searchtype=author&query=Phuong%2C+M">Mary Phuong</a>, 
<a href="/search/cs?searchtype=author&query=Whittlestone%2C+J">Jess Whittlestone</a>, 
<a href="/search/cs?searchtype=author&query=Leung%2C+J">Jade Leung</a>, 
<a href="/search/cs?searchtype=author&query=Kokotajlo%2C+D">Daniel Kokotajlo</a>, 
<a href="/search/cs?searchtype=author&query=Marchal%2C+N">Nahema Marchal</a>, 
<a href="/search/cs?searchtype=author&query=Anderljung%2C+M">Markus Anderljung</a>, 
<a href="/search/cs?searchtype=author&query=Kolt%2C+N">Noam Kolt</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+L">Lewis Ho</a>, 
<a href="/search/cs?searchtype=author&query=Siddarth%2C+D">Divya Siddarth</a>, 
<a href="/search/cs?searchtype=author&query=Avin%2C+S">Shahar Avin</a>, 
<a href="/search/cs?searchtype=author&query=Hawkins%2C+W">Will Hawkins</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Been Kim</a>, 
<a href="/search/cs?searchtype=author&query=Gabriel%2C+I">Iason Gabriel</a>, 
<a href="/search/cs?searchtype=author&query=Bolina%2C+V">Vijay Bolina</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+J">Jack Clark</a>, 
<a href="/search/cs?searchtype=author&query=Bengio%2C+Y">Yoshua Bengio</a>, 
<a href="/search/cs?searchtype=author&query=Christiano%2C+P">Paul Christiano</a>, 
<a href="/search/cs?searchtype=author&query=Dafoe%2C+A">Allan Dafoe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Fixed typos; added citation
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item891">[891]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15349" title="Abstract">arXiv:2305.15349</a> (replaced) [<a href="/pdf/2305.15349" title="Download PDF">pdf</a>, <a href="/format/2305.15349" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Convergence and Scale Parameterizations of Black-Box Variational  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+K">Kyurae Kim</a>, 
<a href="/search/cs?searchtype=author&query=Oh%2C+J">Jisu Oh</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+K">Kaiwen Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yi-An Ma</a>, 
<a href="/search/cs?searchtype=author&query=Gardner%2C+J+R">Jacob R. Gardner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to NeurIPS'23; previous title: "Black-Box Variational Inference Converges"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC); Computation (stat.CO); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item892">[892]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15703" title="Abstract">arXiv:2305.15703</a> (replaced) [<a href="/pdf/2305.15703" title="Download PDF">pdf</a>, <a href="/ps/2305.15703" title="Download PostScript">ps</a>, <a href="/format/2305.15703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Benefits of Being Distributional: Small-Loss Bounds for  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiwen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kevin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Runzhe Wu</a>, 
<a href="/search/cs?searchtype=author&query=Kallus%2C+N">Nathan Kallus</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Wen Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item893">[893]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15930" title="Abstract">arXiv:2305.15930</a> (replaced) [<a href="/pdf/2305.15930" title="Download PDF">pdf</a>, <a href="/format/2305.15930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Maraval%2C+A">Alexandre Maraval</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+M">Matthieu Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Grosnit%2C+A">Antoine Grosnit</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H+B">Haitham Bou Ammar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item894">[894]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16437" title="Abstract">arXiv:2305.16437</a> (replaced) [<a href="/pdf/2305.16437" title="Download PDF">pdf</a>, <a href="/format/2305.16437" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired  True-Range Multilateration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bao%2C+X">Xu Bao</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+Z">Zhi-Qi Cheng</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun-Yan He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+W">Wangmeng Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jingdong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hanbing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Wei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Geng%2C+Y">Yifeng Geng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xuansong Xie</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ACM Multimedia 2023; 10 pages, 7 figures, 6 tables; the code is at <a href="https://github.com/zhiqic/KeyPosS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item895">[895]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.16809" title="Abstract">arXiv:2305.16809</a> (replaced) [<a href="/pdf/2305.16809" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GenQ: Automated Question Generation to Support Caregivers While Reading  Stories with Children
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+A+B+L">Arun Balajiee Lekshmi Narayanan</a>, 
<a href="/search/cs?searchtype=author&query=Gomez%2C+L+E">Ligia E. Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Fernandez%2C+M+M+S">Martha Michelle Soto Fernandez</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+T">Tri Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Blais%2C+C">Chris Blais</a>, 
<a href="/search/cs?searchtype=author&query=Restrepo%2C+M+A">M. Adelaida Restrepo</a>, 
<a href="/search/cs?searchtype=author&query=Glenberg%2C+A">Art Glenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item896">[896]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18009" title="Abstract">arXiv:2305.18009</a> (replaced) [<a href="/pdf/2305.18009" title="Download PDF">pdf</a>, <a href="/format/2305.18009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Modal Face Stylization with a Generative Prior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mengtian Li</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Y">Yi Dong</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Minxuan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+H">Haibin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+P">Pengfei Wan</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+C">Chongyang Ma</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item897">[897]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18668" title="Abstract">arXiv:2305.18668</a> (replaced) [<a href="/pdf/2305.18668" title="Download PDF">pdf</a>, <a href="/format/2305.18668" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-Grained is Too Coarse: A Novel Data-Centric Approach for Efficient  Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%C3%ABlic%2C+N">Neau Ma&#xeb;lic</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+P+E">Paulo E. Santos</a>, 
<a href="/search/cs?searchtype=author&query=Bosser%2C+A">Anne-Gwenn Bosser</a>, 
<a href="/search/cs?searchtype=author&query=Buche%2C+C">C&#xe9;dric Buche</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item898">[898]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18743" title="Abstract">arXiv:2305.18743</a> (replaced) [<a href="/pdf/2305.18743" title="Download PDF">pdf</a>, <a href="/format/2305.18743" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposed Human Motion Prior for Video Pose Estimation via Adversarial  Training
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenshuo Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xiang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengdi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+W">Weixi Gu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item899">[899]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.18772" title="Abstract">arXiv:2305.18772</a> (replaced) [<a href="/pdf/2305.18772" title="Download PDF">pdf</a>, <a href="/ps/2305.18772" title="Download PostScript">ps</a>, <a href="/format/2305.18772" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Remarks on Yablo Like Structures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schlechta%2C+K">Karl Schlechta</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item900">[900]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19037" title="Abstract">arXiv:2305.19037</a> (replaced) [<a href="/pdf/2305.19037" title="Download PDF">pdf</a>, <a href="/format/2305.19037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ethereum&#x27;s Proposer-Builder Separation: Promises and Realities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heimbach%2C+L">Lioba Heimbach</a>, 
<a href="/search/cs?searchtype=author&query=Kiffer%2C+L">Lucianna Kiffer</a>, 
<a href="/search/cs?searchtype=author&query=Torres%2C+C+F">Christof Ferreira Torres</a>, 
<a href="/search/cs?searchtype=author&query=Wattenhofer%2C+R">Roger Wattenhofer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings of 2023 Internet Measurement Conference (IMC)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item901">[901]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.19201" title="Abstract">arXiv:2305.19201</a> (replaced) [<a href="/pdf/2305.19201" title="Download PDF">pdf</a>, <a href="/format/2305.19201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DaRF: Boosting Radiance Fields from Sparse Inputs with Monocular Depth  Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+J">Jiuhn Song</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+S">Seonghoon Park</a>, 
<a href="/search/cs?searchtype=author&query=An%2C+H">Honggyu An</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Seokju Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kwak%2C+M">Min-Seop Kwak</a>, 
<a href="/search/cs?searchtype=author&query=Cho%2C+S">Sungjin Cho</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Seungryong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at NeurIPS 2023. Project Page: <a href="https://ku-cvlab.github.io/DaRF/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item902">[902]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00306" title="Abstract">arXiv:2306.00306</a> (replaced) [<a href="/pdf/2306.00306" title="Download PDF">pdf</a>, <a href="/format/2306.00306" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-Light Image Enhancement with Wavelet-based Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+H">Hai Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+A">Ao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Songchen Han</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+H">Haoqiang Fan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuaicheng Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by Siggraph Aisa 2023 (ACM Transactions on Graphics)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item903">[903]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00817" title="Abstract">arXiv:2306.00817</a> (replaced) [<a href="/pdf/2306.00817" title="Download PDF">pdf</a>, <a href="/format/2306.00817" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dilated Convolution with Learnable Spacings: beyond bilinear  interpolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khalfaoui-Hassani%2C+I">Ismail Khalfaoui-Hassani</a>, 
<a href="/search/cs?searchtype=author&query=Pellegrini%2C+T">Thomas Pellegrini</a>, 
<a href="/search/cs?searchtype=author&query=Masquelier%2C+T">Timoth&#xe9;e Masquelier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICML 2023 Workshop on Differentiable Almost Everything: Differentiable Relaxations, Algorithms, Operators, and Simulators. 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item904">[904]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01382" title="Abstract">arXiv:2306.01382</a> (replaced) [<a href="/pdf/2306.01382" title="Download PDF">pdf</a>, <a href="/format/2306.01382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Auxiliary Domain Parallel Data in Intermediate Task  Fine-tuning for Low-resource Translation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nayak%2C+S">Shravan Nayak</a>, 
<a href="/search/cs?searchtype=author&query=Ranathunga%2C+S">Surangika Ranathunga</a>, 
<a href="/search/cs?searchtype=author&query=Thillainathan%2C+S">Sarubi Thillainathan</a>, 
<a href="/search/cs?searchtype=author&query=Hung%2C+R">Rikki Hung</a>, 
<a href="/search/cs?searchtype=author&query=Rinaldi%2C+A">Anthony Rinaldi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yining Wang</a>, 
<a href="/search/cs?searchtype=author&query=Mackey%2C+J">Jonah Mackey</a>, 
<a href="/search/cs?searchtype=author&query=Ho%2C+A">Andrew Ho</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+E+A">En-Shiun Annie Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for poster presentation at the Practical Machine Learning for Developing Countries (PML4DC) workshop, ICLR 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item905">[905]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.01913" title="Abstract">arXiv:2306.01913</a> (replaced) [<a href="/pdf/2306.01913" title="Download PDF">pdf</a>, <a href="/format/2306.01913" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dai%2C+X">Xin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yujie Fan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+Z">Zhongfang Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+S">Shubham Jain</a>, 
<a href="/search/cs?searchtype=author&query=Yeh%2C+C+M">Chin-Chia Michael Yeh</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junpeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Aboagye%2C+P+O">Prince Osei Aboagye</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+W">Wei Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item906">[906]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.02879" title="Abstract">arXiv:2306.02879</a> (replaced) [<a href="/pdf/2306.02879" title="Download PDF">pdf</a>, <a href="/format/2306.02879" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neuron Activation Coverage: Rethinking Out-of-distribution Detection and  Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yibing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+C+X">Chris Xing Tian</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haoliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Lei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shiqi Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 9 figures, 20 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item907">[907]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04054" title="Abstract">arXiv:2306.04054</a> (replaced) [<a href="/pdf/2306.04054" title="Download PDF">pdf</a>, <a href="/format/2306.04054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RescueSpeech: A German Corpus for Speech Recognition in Search and  Rescue Domain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sagar%2C+S">Sangeet Sagar</a>, 
<a href="/search/eess?searchtype=author&query=Ravanelli%2C+M">Mirco Ravanelli</a>, 
<a href="/search/eess?searchtype=author&query=Kiefer%2C+B">Bernd Kiefer</a>, 
<a href="/search/eess?searchtype=author&query=Korbayova%2C+I+K">Ivana Kruijff Korbayova</a>, 
<a href="/search/eess?searchtype=author&query=van+Genabith%2C+J">Josef van Genabith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item908">[908]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.04959" title="Abstract">arXiv:2306.04959</a> (replaced) [<a href="/pdf/2306.04959" title="Download PDF">pdf</a>, <a href="/format/2306.04959" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedMLSecurity: A Benchmark for Attacks and Defenses in Federated  Learning and LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Shanshan Han</a>, 
<a href="/search/cs?searchtype=author&query=Buyukates%2C+B">Baturalp Buyukates</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zijian Hu</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+H">Han Jin</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+W">Weizhao Jin</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lichao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaoyang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+W">Wenxuan Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+C">Chulin Xie</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+Y">Yuhang Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kai Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qifan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yuhui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Avestimehr%2C+S">Salman Avestimehr</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+C">Chaoyang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item909">[909]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06123" title="Abstract">arXiv:2306.06123</a> (replaced) [<a href="/pdf/2306.06123" title="Download PDF">pdf</a>, <a href="/format/2306.06123" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adversarial Attacks and Defenses in Explainable Artificial Intelligence:  A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baniecki%2C+H">Hubert Baniecki</a>, 
<a href="/search/cs?searchtype=author&query=Biecek%2C+P">Przemyslaw Biecek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shorter version of this paper was presented at the IJCAI 2023 Workshop on Explainable AI
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item910">[910]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06198" title="Abstract">arXiv:2306.06198</a> (replaced) [<a href="/pdf/2306.06198" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spoofing Against Spoofing: Towards Caller ID Verification In  Heterogeneous Telecommunication Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Delavar%2C+M">Mahshid Delavar</a>, 
<a href="/search/cs?searchtype=author&query=Azad%2C+M+A">Muhammad Ajmal Azad</a>, 
<a href="/search/cs?searchtype=author&query=Nabizadeh%2C+F">Farshad Nabizadeh</a>, 
<a href="/search/cs?searchtype=author&query=Smith%2C+S">Steve Smith</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+F">Feng Hao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 12 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item911">[911]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06394" title="Abstract">arXiv:2306.06394</a> (replaced) [<a href="/pdf/2306.06394" title="Download PDF">pdf</a>, <a href="/format/2306.06394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PEAR: Primitive enabled Adaptive Relabeling for boosting Hierarchical  Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Singh%2C+U">Utsav Singh</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V+P">Vinay P Namboodiri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item912">[912]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.06925" title="Abstract">arXiv:2306.06925</a> (replaced) [<a href="/pdf/2306.06925" title="Download PDF">pdf</a>, <a href="/format/2306.06925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Analysis and Synthesis of Digital Dyadic Sequences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+A+G+M">Abdalla G. M. Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Skopenkov%2C+M">Mikhail Skopenkov</a>, 
<a href="/search/cs?searchtype=author&query=Hadwiger%2C+M">Markus Hadwiger</a>, 
<a href="/search/cs?searchtype=author&query=Wonka%2C+P">Peter Wonka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 11 figures. Minor improvement of exposition; references to earlier proofs of Theorems 3.1 and 3.3 added
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Combinatorics (math.CO)

</div>
</div>
</dd>
<dt><a name="item913">[913]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.07215" title="Abstract">arXiv:2306.07215</a> (replaced) [<a href="/pdf/2306.07215" title="Download PDF">pdf</a>, <a href="/format/2306.07215" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Quantization-aware Training with Adaptive Coreset Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xijie Huang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zechun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shih-Yang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kwang-Ting Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code: <a href="https://github.com/HuangOwen/QAT-ACS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item914">[914]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08323" title="Abstract">arXiv:2306.08323</a> (replaced) [<a href="/pdf/2306.08323" title="Download PDF">pdf</a>, <a href="/format/2306.08323" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How to estimate carbon footprint when training deep learning models? A  guide and review
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heguerte%2C+L+B">Lucia Bouza Heguerte</a> (MAP5 - UMR 8145), 
<a href="/search/cs?searchtype=author&query=Bugeau%2C+A">Aur&#xe9;lie Bugeau</a> (IUF, LaBRI, UB), 
<a href="/search/cs?searchtype=author&query=Lannelongue%2C+L">Lo&#xef;c Lannelongue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Environmental Research Communications, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item915">[915]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08954" title="Abstract">arXiv:2306.08954</a> (replaced) [<a href="/pdf/2306.08954" title="Download PDF">pdf</a>, <a href="/format/2306.08954" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Re-Benchmarking Pool-Based Active Learning for Binary Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+P">Po-Yi Lu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chun-Liang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Hsuan-Tien Lin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item916">[916]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09172" title="Abstract">arXiv:2306.09172</a> (replaced) [<a href="/pdf/2306.09172" title="Download PDF">pdf</a>, <a href="/format/2306.09172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Action Sensitivity Learning for the Ego4D Episodic Memory Challenge 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+J">Jiayi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaohan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Quan%2C+R">Ruijie Quan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yi Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to CVPR 2023 Ego4D Workshop; 1st in Ego4D Moment Queries Challenge; 2nd in Ego4D Natural Language Queries Challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item917">[917]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09341" title="Abstract">arXiv:2306.09341</a> (replaced) [<a href="/pdf/2306.09341" title="Download PDF">pdf</a>, <a href="/format/2306.09341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Preference Score v2: A Solid Benchmark for Evaluating Human  Preferences of Text-to-Image Synthesis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoshi Wu</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+Y">Yiming Hao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+K">Keqiang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yixiong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Feng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongsheng Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revision
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Databases (cs.DB)

</div>
</div>
</dd>
<dt><a name="item918">[918]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09376" title="Abstract">arXiv:2306.09376</a> (replaced) [<a href="/pdf/2306.09376" title="Download PDF">pdf</a>, <a href="/format/2306.09376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularizing while Training: A New Paradigm for Modularizing DNN Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qi%2C+B">Binhang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">Hailong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruobing Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiang Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICSE'24
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Software Engineering (cs.SE)

</div>
</div>
</dd>
<dt><a name="item919">[919]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.09803" title="Abstract">arXiv:2306.09803</a> (replaced) [<a href="/pdf/2306.09803" title="Download PDF">pdf</a>, <a href="/format/2306.09803" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Framework and Benchmarks for Combinatorial and Mixed-variable Bayesian  Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dreczkowski%2C+K">Kamil Dreczkowski</a>, 
<a href="/search/cs?searchtype=author&query=Grosnit%2C+A">Antoine Grosnit</a>, 
<a href="/search/cs?searchtype=author&query=Ammar%2C+H+B">Haitham Bou Ammar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item920">[920]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10158" title="Abstract">arXiv:2306.10158</a> (replaced) [<a href="/pdf/2306.10158" title="Download PDF">pdf</a>, <a href="/format/2306.10158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning-Augmented Decentralized Online Convex Optimization in Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pengfei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jianyi Yang</a>, 
<a href="/search/cs?searchtype=author&query=Wierman%2C+A">Adam Wierman</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+S">Shaolei Ren</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item921">[921]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10598" title="Abstract">arXiv:2306.10598</a> (replaced) [<a href="/pdf/2306.10598" title="Download PDF">pdf</a>, <a href="/format/2306.10598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DropCompute: simple and more robust distributed synchronous training via  compute variance reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Giladi%2C+N">Niv Giladi</a>, 
<a href="/search/cs?searchtype=author&query=Gottlieb%2C+S">Shahar Gottlieb</a>, 
<a href="/search/cs?searchtype=author&query=Shkolnik%2C+M">Moran Shkolnik</a>, 
<a href="/search/cs?searchtype=author&query=Karnieli%2C+A">Asaf Karnieli</a>, 
<a href="/search/cs?searchtype=author&query=Banner%2C+R">Ron Banner</a>, 
<a href="/search/cs?searchtype=author&query=Hoffer%2C+E">Elad Hoffer</a>, 
<a href="/search/cs?searchtype=author&query=Levy%2C+K+Y">Kfir Yehuda Levy</a>, 
<a href="/search/cs?searchtype=author&query=Soudry%2C+D">Daniel Soudry</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://github.com/paper-submissions/dropcompute">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 37th Conference on Neural Information Processing Systems (NeurIPS
  2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item922">[922]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.11611" title="Abstract">arXiv:2306.11611</a> (replaced) [<a href="/pdf/2306.11611" title="Download PDF">pdf</a>, <a href="/format/2306.11611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Model and Plan for Wheeled Mobility on Vertically  Challenging Terrain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datar%2C+A">Aniket Datar</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chenhui Pan</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> <a href="https://www.youtube.com/watch?v=VzpRoEZeyWk">this https URL</a> <a href="https://cs.gmu.edu/~xiao/Research/Verti-Wheelers/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item923">[923]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12045" title="Abstract">arXiv:2306.12045</a> (replaced) [<a href="/pdf/2306.12045" title="Download PDF">pdf</a>, <a href="/format/2306.12045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Conditioning Spiking Latent Variable Models of the Neural  Response to Natural Visual Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Ma%2C+G">Gehua Ma</a>, 
<a href="/search/q-bio?searchtype=author&query=Jiang%2C+R">Runhao Jiang</a>, 
<a href="/search/q-bio?searchtype=author&query=Yan%2C+R">Rui Yan</a>, 
<a href="/search/q-bio?searchtype=author&query=Tang%2C+H">Huajin Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023. 22 pages, 7 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neurons and Cognition (q-bio.NC)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item924">[924]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12321" title="Abstract">arXiv:2306.12321</a> (replaced) [<a href="/pdf/2306.12321" title="Download PDF">pdf</a>, <a href="/format/2306.12321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Implicit Image Function for Efficient Arbitrary-Scale Image  Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zongyao He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhi Jin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item925">[925]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13216" title="Abstract">arXiv:2306.13216</a> (replaced) [<a href="/pdf/2306.13216" title="Download PDF">pdf</a>, <a href="/format/2306.13216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diverse Community Data for Benchmarking Data Privacy Algorithms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sen%2C+A">Aniruddha Sen</a>, 
<a href="/search/cs?searchtype=author&query=Task%2C+C">Christine Task</a>, 
<a href="/search/cs?searchtype=author&query=Kapur%2C+D">Dhruv Kapur</a>, 
<a href="/search/cs?searchtype=author&query=Howarth%2C+G">Gary Howarth</a>, 
<a href="/search/cs?searchtype=author&query=Bhagat%2C+K">Karan Bhagat</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item926">[926]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14718" title="Abstract">arXiv:2306.14718</a> (replaced) [<a href="/pdf/2306.14718" title="Download PDF">pdf</a>, <a href="/format/2306.14718" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A short proof of the G&#xe1;cs--K&#xf6;rner theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Csirmaz%2C+L">Laszlo Csirmaz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item927">[927]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15328" title="Abstract">arXiv:2306.15328</a> (replaced) [<a href="/pdf/2306.15328" title="Download PDF">pdf</a>, <a href="/ps/2306.15328" title="Download PostScript">ps</a>, <a href="/format/2306.15328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulating counterfactuals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Karvanen%2C+J">Juha Karvanen</a>, 
<a href="/search/stat?searchtype=author&query=Tikka%2C+S">Santtu Tikka</a>, 
<a href="/search/stat?searchtype=author&query=Vihola%2C+M">Matti Vihola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG); Computation (stat.CO)

</div>
</div>
</dd>
<dt><a name="item928">[928]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15354" title="Abstract">arXiv:2306.15354</a> (replaced) [<a href="/pdf/2306.15354" title="Download PDF">pdf</a>, <a href="/format/2306.15354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and  Multi-Dialect Corpus for Speech Representation Disentanglement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+S">Siqi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Luyao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yafeng Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qian Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item929">[929]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15681" title="Abstract">arXiv:2306.15681</a> (replaced) [<a href="/pdf/2306.15681" title="Download PDF">pdf</a>, <a href="/format/2306.15681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECG-QA: A Comprehensive Question Answering Dataset Combined With  Electrocardiogram
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Oh%2C+J">Jungwoo Oh</a>, 
<a href="/search/q-bio?searchtype=author&query=Lee%2C+G">Gyubok Lee</a>, 
<a href="/search/q-bio?searchtype=author&query=Bae%2C+S">Seongsu Bae</a>, 
<a href="/search/q-bio?searchtype=author&query=Kwon%2C+J">Joon-myoung Kwon</a>, 
<a href="/search/q-bio?searchtype=author&query=Choi%2C+E">Edward Choi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at NeurIPS 2023 Datasets and Benchmarks Track (10 pages for main text, 2 pages for references, 28 pages for supplementary materials)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantitative Methods (q-bio.QM)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item930">[930]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15988" title="Abstract">arXiv:2306.15988</a> (replaced) [<a href="/pdf/2306.15988" title="Download PDF">pdf</a>, <a href="/format/2306.15988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AFPN: Asymptotic Feature Pyramid Network for Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+G">Guoyu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+J">Jie Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Z">Zhikuan Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+S">Siyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Zunlei Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+R">Ronghua Liang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item931">[931]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00972" title="Abstract">arXiv:2307.00972</a> (replaced) [<a href="/pdf/2307.00972" title="Download PDF">pdf</a>, <a href="/format/2307.00972" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MoVie: Visual Model-Based Policy Adaptation for View Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+S">Sizhe Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ze%2C+Y">Yanjie Ze</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+H">Huazhe Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in NeurIPS 2023. The first two authors contribute equally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item932">[932]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01403" title="Abstract">arXiv:2307.01403</a> (replaced) [<a href="/pdf/2307.01403" title="Download PDF">pdf</a>, <a href="/format/2307.01403" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Communicate using Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+Y+L">Yat Long Lo</a>, 
<a href="/search/cs?searchtype=author&query=Sengupta%2C+B">Biswa Sengupta</a>, 
<a href="/search/cs?searchtype=author&query=Foerster%2C+J">Jakob Foerster</a>, 
<a href="/search/cs?searchtype=author&query=Noukhovitch%2C+M">Michael Noukhovitch</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item933">[933]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01458" title="Abstract">arXiv:2307.01458</a> (replaced) [<a href="/pdf/2307.01458" title="Download PDF">pdf</a>, <a href="/format/2307.01458" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity  and Infant Care
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tong Xiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Liangzhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wangyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+M">Mingbai Bai</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+L">Lu Wei</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bowen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+N">Noa Garcia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023 Datasets and Benchmarks Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item934">[934]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04358" title="Abstract">arXiv:2307.04358</a> (replaced) [<a href="/pdf/2307.04358" title="Download PDF">pdf</a>, <a href="/format/2307.04358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> False Sense of Security: Leveraging XAI to Analyze the Reasoning and  True Performance of Context-less DGA Classifiers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Drichel%2C+A">Arthur Drichel</a>, 
<a href="/search/cs?searchtype=author&query=Meyer%2C+U">Ulrike Meyer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at The 26th International Symposium on Research in Attacks, Intrusions and Defenses (RAID '23)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item935">[935]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04870" title="Abstract">arXiv:2307.04870</a> (replaced) [<a href="/pdf/2307.04870" title="Download PDF">pdf</a>, <a href="/ps/2307.04870" title="Download PostScript">ps</a>, <a href="/format/2307.04870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Onion Universe Algorithm: Applications in Weakly Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Na%2C+W">Woojoo Na</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item936">[936]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.06422" title="Abstract">arXiv:2307.06422</a> (replaced) [<a href="/pdf/2307.06422" title="Download PDF">pdf</a>, <a href="/format/2307.06422" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Decoupled Graph Convolutions for Multigranular  Topology Protection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chien%2C+E">Eli Chien</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei-Ning Chen</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+C">Chao Pan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+P">Pan Li</a>, 
<a href="/search/cs?searchtype=author&query=%C3%96zg%C3%BCr%2C+A">Ayfer &#xd6;zg&#xfc;r</a>, 
<a href="/search/cs?searchtype=author&query=Milenkovic%2C+O">Olgica Milenkovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item937">[937]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07420" title="Abstract">arXiv:2307.07420</a> (replaced) [<a href="/pdf/2307.07420" title="Download PDF">pdf</a>, <a href="/format/2307.07420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Named entity recognition using GPT for identifying comparable companies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Covas%2C+E">Eurico Covas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 1 figure, to be submited to a journal
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item938">[938]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07851" title="Abstract">arXiv:2307.07851</a> (replaced) [<a href="/pdf/2307.07851" title="Download PDF">pdf</a>, <a href="/format/2307.07851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual  Similarity Using Contrastive Learning and Structured Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Gerber%2C+E">Emanuel Gerber</a>, 
<a href="/search/cs?searchtype=author&query=Ostendorff%2C+M">Malte Ostendorff</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item939">[939]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09715" title="Abstract">arXiv:2307.09715</a> (replaced) [<a href="/pdf/2307.09715" title="Download PDF">pdf</a>, <a href="/format/2307.09715" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantic-Aware Dual Contrastive Learning for Multi-label Image  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+L">Leilei Ma</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Dengdi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H">Haifeng Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures, accepted by European Conference on Artificial Intelligence (2023 ECAI)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item940">[940]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10089" title="Abstract">arXiv:2307.10089</a> (replaced) [<a href="/pdf/2307.10089" title="Download PDF">pdf</a>, <a href="/format/2307.10089" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design Characterization for Black-and-White Textures in Visualization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+T">Tingying He</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yuanyang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+P">Petra Isenberg</a>, 
<a href="/search/cs?searchtype=author&query=Isenberg%2C+T">Tobias Isenberg</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item941">[941]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10185" title="Abstract">arXiv:2307.10185</a> (replaced) [<a href="/pdf/2307.10185" title="Download PDF">pdf</a>, <a href="/format/2307.10185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BigDipper: A hyperscale BFT system with short term censorship resistance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xue%2C+B">Bowen Xue</a>, 
<a href="/search/cs?searchtype=author&query=Deb%2C+S">Soubhik Deb</a>, 
<a href="/search/cs?searchtype=author&query=Kannan%2C+S">Sreeram Kannan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item942">[942]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10652" title="Abstract">arXiv:2307.10652</a> (replaced) [<a href="/pdf/2307.10652" title="Download PDF">pdf</a>, <a href="/format/2307.10652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Landscape of Natural Language Processing Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schopf%2C+T">Tim Schopf</a>, 
<a href="/search/cs?searchtype=author&query=Arabi%2C+K">Karim Arabi</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of the paper accepted to the 14th International Conference on Recent Advances in Natural Language Processing (RANLP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item943">[943]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.10982" title="Abstract">arXiv:2307.10982</a> (replaced) [<a href="/pdf/2307.10982" title="Download PDF">pdf</a>, <a href="/format/2307.10982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MASR: Multi-label Aware Speech Representation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raj%2C+A">Anjali Raj</a>, 
<a href="/search/cs?searchtype=author&query=Bharadwaj%2C+S">Shikhar Bharadwaj</a>, 
<a href="/search/cs?searchtype=author&query=Ganapathy%2C+S">Sriram Ganapathy</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Min Ma</a>, 
<a href="/search/cs?searchtype=author&query=Vashishth%2C+S">Shikhar Vashishth</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ASRU 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item944">[944]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11058" title="Abstract">arXiv:2307.11058</a> (replaced) [<a href="/pdf/2307.11058" title="Download PDF">pdf</a>, <a href="/format/2307.11058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Anticipating Driving Behavior through Deep Learning-Based Policy  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+A">Alexander Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item945">[945]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12032" title="Abstract">arXiv:2307.12032</a> (replaced) [<a href="/pdf/2307.12032" title="Download PDF">pdf</a>, <a href="/format/2307.12032" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flight Contrail Segmentation via Augmented Transfer Learning with Novel  SR Loss Function in Hough Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Junzi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Roosenbrand%2C+E">Esther Roosenbrand</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Source code available at: <a href="https://github.com/junzis/contrail-net">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item946">[946]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12626" title="Abstract">arXiv:2307.12626</a> (replaced) [<a href="/pdf/2307.12626" title="Download PDF">pdf</a>, <a href="/format/2307.12626" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset  and Comprehensive Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+J">Jingxuan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+C">Cheng Tan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Z">Zhangyang Gao</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Linzhuang Sun</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Siyuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+B">Bihui Yu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+R">Ruifeng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S+Z">Stan Z. Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item947">[947]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13292" title="Abstract">arXiv:2307.13292</a> (replaced) [<a href="/pdf/2307.13292" title="Download PDF">pdf</a>, <a href="/format/2307.13292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sequence-Selection-Based Constellation Shaping for Nonlinear Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Civelli%2C+S">Stella Civelli</a>, 
<a href="/search/cs?searchtype=author&query=Forestieri%2C+E">Enrico Forestieri</a>, 
<a href="/search/cs?searchtype=author&query=Secondini%2C+M">Marco Secondini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The manuscript has been submitted for publication to the Journal of Lightwave Technology
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item948">[948]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14619" title="Abstract">arXiv:2307.14619</a> (replaced) [<a href="/pdf/2307.14619" title="Download PDF">pdf</a>, <a href="/format/2307.14619" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Imitating Complex Trajectories: Bridging Low-Level Stability and  High-Level Behavior
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Block%2C+A">Adam Block</a>, 
<a href="/search/cs?searchtype=author&query=Pfrommer%2C+D">Daniel Pfrommer</a>, 
<a href="/search/cs?searchtype=author&query=Simchowitz%2C+M">Max Simchowitz</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> updated figures, minor notational change for readability
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Statistics Theory (math.ST); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item949">[949]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.14751" title="Abstract">arXiv:2307.14751</a> (replaced) [<a href="/pdf/2307.14751" title="Download PDF">pdf</a>, <a href="/format/2307.14751" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLARE: Fingerprinting Deep Reinforcement Learning Agents using Universal  Adversarial Masks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tekgul%2C+B+G+A">Buse G. A. Tekgul</a>, 
<a href="/search/cs?searchtype=author&query=Asokan%2C+N">N. Asokan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear in the proceedings of ACSAC 2023; 14 pages, 6 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item950">[950]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01058" title="Abstract">arXiv:2308.01058</a> (replaced) [<a href="/pdf/2308.01058" title="Download PDF">pdf</a>, <a href="/format/2308.01058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Generalization of Synthetically Trained Sonar Image  Descriptors for Underwater Place Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Donadi%2C+I">Ivano Donadi</a>, 
<a href="/search/cs?searchtype=author&query=Olivastri%2C+E">Emilio Olivastri</a>, 
<a href="/search/cs?searchtype=author&query=Fusaro%2C+D">Daniel Fusaro</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wanmeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Evangelista%2C+D">Daniele Evangelista</a>, 
<a href="/search/cs?searchtype=author&query=Pretto%2C+A">Alberto Pretto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted for publication at the 14th International Conference on Computer Vision Systems (ICVS 2023)
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of the 14th International Conference on Computer
  Vision Systems (ICVS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item951">[951]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01661" title="Abstract">arXiv:2308.01661</a> (replaced) [<a href="/pdf/2308.01661" title="Download PDF">pdf</a>, <a href="/format/2308.01661" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEVControl: Accurately Controlling Street-view Elements with  Multi-perspective Consistency via BEV Sketch Layout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+K">Kairui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+E">Enhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+J">Jibin Peng</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qing Guo</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Di Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+K">Kaicheng Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item952">[952]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.02681" title="Abstract">arXiv:2308.02681</a> (replaced) [<a href="/pdf/2308.02681" title="Download PDF">pdf</a>, <a href="/format/2308.02681" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MARTA Reach: Piloting an On-Demand Multimodal Transit System in Atlanta
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van+Hentenryck%2C+P">Pascal Van Hentenryck</a>, 
<a href="/search/cs?searchtype=author&query=Riley%2C+C">Connor Riley</a>, 
<a href="/search/cs?searchtype=author&query=Trasatti%2C+A">Anthony Trasatti</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Hongzhao Guan</a>, 
<a href="/search/cs?searchtype=author&query=Santanam%2C+T">Tejas Santanam</a>, 
<a href="/search/cs?searchtype=author&query=Huertas%2C+J+A">Jorge A. Huertas</a>, 
<a href="/search/cs?searchtype=author&query=Dalmeijer%2C+K">Kevin Dalmeijer</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+K">Kari Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Drake%2C+J">Juwon Drake</a>, 
<a href="/search/cs?searchtype=author&query=Baskin%2C+S">Samson Baskin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item953">[953]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03527" title="Abstract">arXiv:2308.03527</a> (replaced) [<a href="/pdf/2308.03527" title="Download PDF">pdf</a>, <a href="/format/2308.03527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring ChatGPT&#x27;s Empathic Abilities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Schaaff%2C+K">Kristina Schaaff</a>, 
<a href="/search/cs?searchtype=author&query=Reinig%2C+C">Caroline Reinig</a>, 
<a href="/search/cs?searchtype=author&query=Schlippe%2C+T">Tim Schlippe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item954">[954]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03801" title="Abstract">arXiv:2308.03801</a> (replaced) [<a href="/pdf/2308.03801" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On problematic practice of using normalization in  Self-modeling/Multivariate Curve Resolution (S/MCR)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rajk%C3%B3%2C+R">R&#xf3;bert Rajk&#xf3;</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Using more polished/polite tone, sectioned, figured
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item955">[955]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03882" title="Abstract">arXiv:2308.03882</a> (replaced) [<a href="/pdf/2308.03882" title="Download PDF">pdf</a>, <a href="/format/2308.03882" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploiting Generalization in Offline Reinforcement Learning via Unseen  State Augmentations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Modhe%2C+N">Nirbhay Modhe</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Q">Qiaozi Gao</a>, 
<a href="/search/cs?searchtype=author&query=Kalyan%2C+A">Ashwin Kalyan</a>, 
<a href="/search/cs?searchtype=author&query=Batra%2C+D">Dhruv Batra</a>, 
<a href="/search/cs?searchtype=author&query=Thattai%2C+G">Govind Thattai</a>, 
<a href="/search/cs?searchtype=author&query=Sukhatme%2C+G">Gaurav Sukhatme</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item956">[956]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03929" title="Abstract">arXiv:2308.03929</a> (replaced) [<a href="/pdf/2308.03929" title="Download PDF">pdf</a>, <a href="/format/2308.03929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Challenging the Machinery of Generative AI with Fact-Checking:  Ontology-Driven Biological Graphs for Verifying Human Disease-Gene Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamed%2C+A+A">Ahmed Abdeen Hamed</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Crimi%2C+A">Alessandro Crimi</a>, 
<a href="/search/cs?searchtype=author&query=Misiak%2C+M+M">Magdalena M. Misiak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 Pages, 4 algorithms, 6 tables, and 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item957">[957]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04321" title="Abstract">arXiv:2308.04321</a> (replaced) [<a href="/pdf/2308.04321" title="Download PDF">pdf</a>, <a href="/format/2308.04321" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> All-pairs Consistency Learning for Weakly Supervised Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weixuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yanhao Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+Z">Zhen Qin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zheyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+L">Lin Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fanyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yiran Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Barnes%2C+N">Nick Barnes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023 workshop, code released at: <a href="https://github.com/OpenNLPLab/ACR_WSSS">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item958">[958]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.04736" title="Abstract">arXiv:2308.04736</a> (replaced) [<a href="/pdf/2308.04736" title="Download PDF">pdf</a>, <a href="/format/2308.04736" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Case Study: Using AI-Assisted Code Generation In Mobile Teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vasiliniuc%2C+M">Mircea-Serban Vasiliniuc</a>, 
<a href="/search/cs?searchtype=author&query=Groza%2C+A">Adrian Groza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 10 figures, 1 table, ICCP conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item959">[959]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05103" title="Abstract">arXiv:2308.05103</a> (replaced) [<a href="/pdf/2308.05103" title="Download PDF">pdf</a>, <a href="/format/2308.05103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Multi-Shot Diffusion-Weighted MRI with Zero-Shot  Self-Supervised Learning Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Cho%2C+J">Jaejin Cho</a>, 
<a href="/search/eess?searchtype=author&query=Jun%2C+Y">Yohan Jun</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaoqing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Kobayashi%2C+C">Caique Kobayashi</a>, 
<a href="/search/eess?searchtype=author&query=Bilgic%2C+B">Berkin Bilgic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item960">[960]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05274" title="Abstract">arXiv:2308.05274</a> (replaced) [<a href="/e-print/2308.05274" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local-Global Information Interaction Debiasing for Dynamic Scene Graph  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lyu%2C+X">Xinyu Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Jingwei Liu</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yuyu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+L">Lianli Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The author has withdrawn this paper due to a critical definitional error in multi-task learning for dynamic SGG debiasing. This error aligned with the definition of dynamic SGG tasks, resulting in an unfair comparison with state-of-the-art (SOTA) methods, which in turn, hindered the ability to evaluate the paper's contributions
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item961">[961]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05430" title="Abstract">arXiv:2308.05430</a> (replaced) [<a href="/pdf/2308.05430" title="Download PDF">pdf</a>, <a href="/format/2308.05430" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensemble Modeling for Multimodal Visual Action Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kini%2C+J">Jyoti Kini</a>, 
<a href="/search/cs?searchtype=author&query=Fleischer%2C+S">Sarah Fleischer</a>, 
<a href="/search/cs?searchtype=author&query=Dave%2C+I">Ishan Dave</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22nd International Conference on Image Analysis and Processing Workshops - Multimodal Action Recognition on the MECCANO Dataset, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item962">[962]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05673" title="Abstract">arXiv:2308.05673</a> (replaced) [<a href="/pdf/2308.05673" title="Download PDF">pdf</a>, <a href="/format/2308.05673" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algorithms for Encoding and Decoding 3D Hilbert Orderings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Walker%2C+D">David Walker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item963">[963]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07337" title="Abstract">arXiv:2308.07337</a> (replaced) [<a href="/pdf/2308.07337" title="Download PDF">pdf</a>, <a href="/format/2308.07337" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Descriptor Framework for On-the-Fly Anatomical Location  Matching between Longitudinal Studies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yerebakan%2C+H+Z">Halid Ziya Yerebakan</a>, 
<a href="/search/eess?searchtype=author&query=Shinagawa%2C+Y">Yoshihisa Shinagawa</a>, 
<a href="/search/eess?searchtype=author&query=Ranganath%2C+M">Mahesh Ranganath</a>, 
<a href="/search/eess?searchtype=author&query=Allen-Raffl%2C+S">Simon Allen-Raffl</a>, 
<a href="/search/eess?searchtype=author&query=Valadez%2C+G+H">Gerardo Hermosillo Valadez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Registration Methods, 9 pages, MTSAIL &amp; LEAF 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item964">[964]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07551" title="Abstract">arXiv:2308.07551</a> (replaced) [<a href="/pdf/2308.07551" title="Download PDF">pdf</a>, <a href="/format/2308.07551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FLAME-based Multi-View 3D Face Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenzhuo Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Junhao Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaohong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Y">Yongyang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Z">Zhenghao Gan</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+H">Haozhe Han</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+N">Ning Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item965">[965]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08143" title="Abstract">arXiv:2308.08143</a> (replaced) [<a href="/pdf/2308.08143" title="Download PDF">pdf</a>, <a href="/format/2308.08143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCANet: A Self- and Cross-Attention Network for Audio-Visual Speech  Separation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kai Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+R">Runxuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaolin Hu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item966">[966]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09103" title="Abstract">arXiv:2308.09103</a> (replaced) [<a href="/pdf/2308.09103" title="Download PDF">pdf</a>, <a href="/format/2308.09103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient collision avoidance for autonomous vehicles in polygonal  domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fan%2C+J">Jiayu Fan</a>, 
<a href="/search/cs?searchtype=author&query=Murgovski%2C+N">Nikolce Murgovski</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jun Liang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages,2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item967">[967]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09474" title="Abstract">arXiv:2308.09474</a> (replaced) [<a href="/pdf/2308.09474" title="Download PDF">pdf</a>, <a href="/format/2308.09474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI Hilbert: A New Paradigm for Scientific Discovery by Unifying Data and  Background Knowledge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cory-Wright%2C+R">Ryan Cory-Wright</a>, 
<a href="/search/cs?searchtype=author&query=Khadir%2C+B+E">Bachir El Khadir</a>, 
<a href="/search/cs?searchtype=author&query=Cornelio%2C+C">Cristina Cornelio</a>, 
<a href="/search/cs?searchtype=author&query=Dash%2C+S">Sanjeeb Dash</a>, 
<a href="/search/cs?searchtype=author&query=Horesh%2C+L">Lior Horesh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Slightly revised from version 1, in particular polished the figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Symbolic Computation (cs.SC); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item968">[968]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10087" title="Abstract">arXiv:2308.10087</a> (replaced) [<a href="/pdf/2308.10087" title="Download PDF">pdf</a>, <a href="/format/2308.10087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+J">Jingji Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhuoming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+X">Xuehai Qian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item969">[969]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10279" title="Abstract">arXiv:2308.10279</a> (replaced) [<a href="/pdf/2308.10279" title="Download PDF">pdf</a>, <a href="/format/2308.10279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GPFL: Simultaneously Learning Global and Personalized Feature  Information for Personalized Federated Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jianqing Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+Y">Yang Hua</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+T">Tao Song</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Z">Zhengui Xue</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+R">Ruhui Ma</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jian Cao</a>, 
<a href="/search/cs?searchtype=author&query=Guan%2C+H">Haibing Guan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item970">[970]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10328" title="Abstract">arXiv:2308.10328</a> (replaced) [<a href="/pdf/2308.10328" title="Download PDF">pdf</a>, <a href="/format/2308.10328" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Empirical Evaluation on Online Continual Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Soutif--Cormerais%2C+A">Albin Soutif--Cormerais</a>, 
<a href="/search/cs?searchtype=author&query=Carta%2C+A">Antonio Carta</a>, 
<a href="/search/cs?searchtype=author&query=Cossu%2C+A">Andrea Cossu</a>, 
<a href="/search/cs?searchtype=author&query=Hurtado%2C+J">Julio Hurtado</a>, 
<a href="/search/cs?searchtype=author&query=Hemati%2C+H">Hamed Hemati</a>, 
<a href="/search/cs?searchtype=author&query=Lomonaco%2C+V">Vincenzo Lomonaco</a>, 
<a href="/search/cs?searchtype=author&query=Van+de+Weijer%2C+J">Joost Van de Weijer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV Visual Continual Learning Workshop 2023 accepted paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item971">[971]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10510" title="Abstract">arXiv:2308.10510</a> (replaced) [<a href="/pdf/2308.10510" title="Download PDF">pdf</a>, <a href="/format/2308.10510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Compensated Diffusion Model for Real-scene Dehazing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jing Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Songtao Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+K">Kuanhong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zhiqiang Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item972">[972]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11020" title="Abstract">arXiv:2308.11020</a> (replaced) [<a href="/pdf/2308.11020" title="Download PDF">pdf</a>, <a href="/format/2308.11020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Objective Evaluation of Socially-Situated Conversational Robots:  Assessing Human-Likeness through Multimodal User Behaviors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Inoue%2C+K">Koji Inoue</a>, 
<a href="/search/cs?searchtype=author&query=Lala%2C+D">Divesh Lala</a>, 
<a href="/search/cs?searchtype=author&query=Ochi%2C+K">Keiko Ochi</a>, 
<a href="/search/cs?searchtype=author&query=Kawahara%2C+T">Tatsuya Kawahara</a>, 
<a href="/search/cs?searchtype=author&query=Skantze%2C+G">Gabriel Skantze</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by 25th ACM International Conference on Multimodal Interaction (ICMI '23), Late-Breaking Results
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item973">[973]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11034" title="Abstract">arXiv:2308.11034</a> (replaced) [<a href="/pdf/2308.11034" title="Download PDF">pdf</a>, <a href="/format/2308.11034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Digital Twin-Oriented Complex Networked Systems based on Heterogeneous  Node Features and Interaction Rules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+J">Jiaqi Wen</a>, 
<a href="/search/cs?searchtype=author&query=Gabrys%2C+B">Bogdan Gabrys</a>, 
<a href="/search/cs?searchtype=author&query=Musial%2C+K">Katarzyna Musial</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item974">[974]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11119" title="Abstract">arXiv:2308.11119</a> (replaced) [<a href="/pdf/2308.11119" title="Download PDF">pdf</a>, <a href="/format/2308.11119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Random Word Data Augmentation with CLIP for Zero-Shot Anomaly Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tamura%2C+M">Masato Tamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item975">[975]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11358" title="Abstract">arXiv:2308.11358</a> (replaced) [<a href="/pdf/2308.11358" title="Download PDF">pdf</a>, <a href="/format/2308.11358" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Much Temporal Long-Term Context is Needed for Action Segmentation?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahrami%2C+E">Emad Bahrami</a>, 
<a href="/search/cs?searchtype=author&query=Francesca%2C+G">Gianpiero Francesca</a>, 
<a href="/search/cs?searchtype=author&query=Gall%2C+J">Juergen Gall</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item976">[976]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11444" title="Abstract">arXiv:2308.11444</a> (replaced) [<a href="/pdf/2308.11444" title="Download PDF">pdf</a>, <a href="/format/2308.11444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Graduated Non-Convexity for Pose Graph Optimization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Seungwon Choi</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+W">Wonseok Kang</a>, 
<a href="/search/cs?searchtype=author&query=Chung%2C+J">Jiseong Chung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaehyun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+T">Tae-wan Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 4 pages, 3 figures. Accepted for the workshop on Robotic Perception and Mapping(ROPEM): Frontier Vision &amp; Learning Techniques, organized at the 2023 International Conference on Intelligent Robots and Systems (IROS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item977">[977]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.11551" title="Abstract">arXiv:2308.11551</a> (replaced) [<a href="/pdf/2308.11551" title="Download PDF">pdf</a>, <a href="/format/2308.11551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-event Video-Text Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+G">Gengyuan Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+J">Jisen Ren</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tresp%2C+V">Volker Tresp</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to ICCV2023 Poster; some figures are not supported viewed online, please download the file and view locally
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item978">[978]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13546" title="Abstract">arXiv:2308.13546</a> (replaced) [<a href="/pdf/2308.13546" title="Download PDF">pdf</a>, <a href="/format/2308.13546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Functional Graph Contrastive Learning of Hyperscanning EEG Reveals  Emotional Contagion Evoked by Stereotype-Based Stressors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+J">Jingyun Huang</a>, 
<a href="/search/eess?searchtype=author&query=Amey%2C+R+C">Rachel C. Amey</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengting Liu</a>, 
<a href="/search/eess?searchtype=author&query=Forbes%2C+C+E">Chad E. Forbes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 4 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item979">[979]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13577" title="Abstract">arXiv:2308.13577</a> (replaced) [<a href="/pdf/2308.13577" title="Download PDF">pdf</a>, <a href="/format/2308.13577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text Style Transfer Evaluation Using Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostheimer%2C+P">Phil Ostheimer</a>, 
<a href="/search/cs?searchtype=author&query=Nagda%2C+M">Mayank Nagda</a>, 
<a href="/search/cs?searchtype=author&query=Kloft%2C+M">Marius Kloft</a>, 
<a href="/search/cs?searchtype=author&query=Fellenz%2C+S">Sophie Fellenz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item980">[980]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13758" title="Abstract">arXiv:2308.13758</a> (replaced) [<a href="/pdf/2308.13758" title="Download PDF">pdf</a>, <a href="/format/2308.13758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new unified arc-length method for damage mechanics problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saji%2C+R+P">Roshan Philip Saji</a>, 
<a href="/search/cs?searchtype=author&query=Pantidis%2C+P">Panos Pantidis</a>, 
<a href="/search/cs?searchtype=author&query=Mobasher%2C+M+E">Mostafa E. Mobasher</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item981">[981]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.14035" title="Abstract">arXiv:2308.14035</a> (replaced) [<a href="/pdf/2308.14035" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-plane denoising diffusion-based dimensionality expansion for  2D-to-3D reconstruction of microstructures with harmonized sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cond-mat?searchtype=author&query=Lee%2C+K">Kang-Hyun Lee</a>, 
<a href="/search/cond-mat?searchtype=author&query=Yun%2C+G+J">Gun Jin Yun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Materials Science (cond-mat.mtrl-sci)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item982">[982]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15309" title="Abstract">arXiv:2308.15309</a> (replaced) [<a href="/pdf/2308.15309" title="Download PDF">pdf</a>, <a href="/format/2308.15309" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the Privacy Risks of Popular Search Engine Advertising  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chouaki%2C+S">Salim Chouaki</a>, 
<a href="/search/cs?searchtype=author&query=Goga%2C+O">Oana Goga</a>, 
<a href="/search/cs?searchtype=author&query=Haddadi%2C+H">Hamed Haddadi</a>, 
<a href="/search/cs?searchtype=author&query=Snyder%2C+P">Peter Snyder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item983">[983]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.16157" title="Abstract">arXiv:2308.16157</a> (replaced) [<a href="/pdf/2308.16157" title="Download PDF">pdf</a>, <a href="/ps/2308.16157" title="Download PostScript">ps</a>, <a href="/format/2308.16157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic, Topological, and Mereological Foundations of Existential  Granules
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mani%2C+A">A Mani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 Pages. Accepted IJCRS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic (math.LO); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item984">[984]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00424" title="Abstract">arXiv:2309.00424</a> (replaced) [<a href="/pdf/2309.00424" title="Download PDF">pdf</a>, <a href="/format/2309.00424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CPSP: Learning Speech Concepts From Phoneme Supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Qiang%2C+C">Chunyu Qiang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+H">Hao Li</a>, 
<a href="/search/eess?searchtype=author&query=Tian%2C+Y">Yixin Tian</a>, 
<a href="/search/eess?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Longbiao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+J">Jianwu Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item985">[985]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01082" title="Abstract">arXiv:2309.01082</a> (replaced) [<a href="/pdf/2309.01082" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tropical Geometric Tools for Machine Learning: the TML package
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Barnhill%2C+D">David Barnhill</a>, 
<a href="/search/stat?searchtype=author&query=Yoshida%2C+R">Ruriko Yoshida</a>, 
<a href="/search/stat?searchtype=author&query=Aliatimis%2C+G">Georgios Aliatimis</a>, 
<a href="/search/stat?searchtype=author&query=Miura%2C+K">Keiji Miura</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Algebraic Geometry (math.AG)

</div>
</div>
</dd>
<dt><a name="item986">[986]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01103" title="Abstract">arXiv:2309.01103</a> (replaced) [<a href="/pdf/2309.01103" title="Download PDF">pdf</a>, <a href="/format/2309.01103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Relational Contrastive Learning for Recommendation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+L">Lianghao Xia</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chao Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been published as a full paper at RecSys 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item987">[987]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01219" title="Abstract">arXiv:2309.01219</a> (replaced) [<a href="/pdf/2309.01219" title="Download PDF">pdf</a>, <a href="/format/2309.01219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Siren&#x27;s Song in the AI Ocean: A Survey on Hallucination in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yue Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yafu Li</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+L">Leyang Cui</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+D">Deng Cai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lemao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+T">Tingchen Fu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xinting Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+E">Enbo Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yulong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Longyue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luu%2C+A+T">Anh Tuan Luu</a>, 
<a href="/search/cs?searchtype=author&query=Bi%2C+W">Wei Bi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+F">Freda Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+S">Shuming Shi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> work in progress; 32 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item988">[988]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01700" title="Abstract">arXiv:2309.01700</a> (replaced) [<a href="/pdf/2309.01700" title="Download PDF">pdf</a>, <a href="/format/2309.01700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ControlMat: A Controlled Generative Approach to Material Capture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vecchio%2C+G">Giuseppe Vecchio</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+R">Rosalie Martin</a>, 
<a href="/search/cs?searchtype=author&query=Roullier%2C+A">Arthur Roullier</a>, 
<a href="/search/cs?searchtype=author&query=Kaiser%2C+A">Adrien Kaiser</a>, 
<a href="/search/cs?searchtype=author&query=Rouffet%2C+R">Romain Rouffet</a>, 
<a href="/search/cs?searchtype=author&query=Deschaintre%2C+V">Valentin Deschaintre</a>, 
<a href="/search/cs?searchtype=author&query=Boubekeur%2C+T">Tamy Boubekeur</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item989">[989]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01736" title="Abstract">arXiv:2309.01736</a> (replaced) [<a href="/e-print/2309.01736" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding and Optimizing Serverless Workloads in CXL-Enabled Tiered  Memory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuze Li</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+S">Shunyu Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper will be part of my under-going research, thus me and my advisor agreed on to withdraw this pre-print for now, until the final project is finished
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item990">[990]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02354" title="Abstract">arXiv:2309.02354</a> (replaced) [<a href="/pdf/2309.02354" title="Download PDF">pdf</a>, <a href="/format/2309.02354" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lightweight and Transferable Design for Robust LEGO Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yifan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
</div>
</dd>
<dt><a name="item991">[991]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02608" title="Abstract">arXiv:2309.02608</a> (replaced) [<a href="/pdf/2309.02608" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Iberian Exception: An overview of its effects over its first 100  days
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Robinson%2C+D">David Robinson</a>, 
<a href="/search/econ?searchtype=author&query=Arcos-Vargas%2C+A">Angel Arcos-Vargas</a>, 
<a href="/search/econ?searchtype=author&query=Tennican%2C+M">Micheael Tennican</a>, 
<a href="/search/econ?searchtype=author&query=N%C3%BA%C3%B1ez%2C+F">Fernando N&#xfa;&#xf1;ez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 34 pages, 9 figures and 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Economics (econ.GN)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item992">[992]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02706" title="Abstract">arXiv:2309.02706</a> (replaced) [<a href="/pdf/2309.02706" title="Download PDF">pdf</a>, <a href="/format/2309.02706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+G">Guijin Son</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hanwool Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Suwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Huiseo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaecheol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J+W">Je Won Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jihyu Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Jung Woo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Songseong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised Erros
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item993">[993]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03033" title="Abstract">arXiv:2309.03033</a> (replaced) [<a href="/pdf/2309.03033" title="Download PDF">pdf</a>, <a href="/format/2309.03033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Learning for Polycystic Kidney Disease: Utilizing Neural Networks  for Accurate and Early Detection through Gene Expression Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Panda%2C+K">Kapil Panda</a>, 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+A">Anirudh Mazumder</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantitative Methods (q-bio.QM)

</div>
</div>
</dd>
<dt><a name="item994">[994]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03217" title="Abstract">arXiv:2309.03217</a> (replaced) [<a href="/pdf/2309.03217" title="Download PDF">pdf</a>, <a href="/ps/2309.03217" title="Download PostScript">ps</a>, <a href="/format/2309.03217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Algebraic Models for Qualified Aggregation in General Rough Sets, and  Reasoning Bias Discovery
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mani%2C+A">A Mani</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 Pages. Accepted. IJCRS-2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Logic in Computer Science (cs.LO); Rings and Algebras (math.RA)

</div>
</div>
</dd>
<dt><a name="item995">[995]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03377" title="Abstract">arXiv:2309.03377</a> (replaced) [<a href="/pdf/2309.03377" title="Download PDF">pdf</a>, <a href="/format/2309.03377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StreamBed: capacity planning for stream processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rosinosky%2C+G">Guillaume Rosinosky</a>, 
<a href="/search/cs?searchtype=author&query=Schmitz%2C+D">Donatien Schmitz</a>, 
<a href="/search/cs?searchtype=author&query=Rivi%C3%A8re%2C+E">Etienne Rivi&#xe8;re</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 11 figures. This project has been funded by the Walloon region (Belgium) through the Win2Wal project GEPICIAD
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>

</div>
</div>
</dd>
<dt><a name="item996">[996]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04077" title="Abstract">arXiv:2309.04077</a> (replaced) [<a href="/pdf/2309.04077" title="Download PDF">pdf</a>, <a href="/format/2309.04077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SayNav: Grounding Large Language Models for Dynamic Planning to  Navigation in New Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajvanshi%2C+A">Abhinav Rajvanshi</a>, 
<a href="/search/cs?searchtype=author&query=Sikka%2C+K">Karan Sikka</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B">Bhoram Lee</a>, 
<a href="/search/cs?searchtype=author&query=Chiu%2C+H">Han-Pang Chiu</a>, 
<a href="/search/cs?searchtype=author&query=Velasquez%2C+A">Alvaro Velasquez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item997">[997]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04737" title="Abstract">arXiv:2309.04737</a> (replaced) [<a href="/pdf/2309.04737" title="Download PDF">pdf</a>, <a href="/format/2309.04737" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Training of Spiking Neural Network joint Curriculum Learning Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lingling Tang</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+J">Jiangtao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hua Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Surui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+J">Jielei Chu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item998">[998]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05211" title="Abstract">arXiv:2309.05211</a> (replaced) [<a href="/pdf/2309.05211" title="Download PDF">pdf</a>, <a href="/format/2309.05211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Two-Sided Quaternion Higher-Order Singular Value Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ya%2C+H">Hanxin Ya</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Y">Ying Wang</a>, 
<a href="/search/math?searchtype=author&query=Yang%2C+Y">Yuning Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item999">[999]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05527" title="Abstract">arXiv:2309.05527</a> (replaced) [<a href="/pdf/2309.05527" title="Download PDF">pdf</a>, <a href="/format/2309.05527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReSimAD: Zero-Shot 3D Domain Transfer for Autonomous Driving with Source  Reconstruction and Target Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiakang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+D">Donglin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianfei Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiangchao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+M">Min Dou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tao Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Si Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Code and simulated points are available at <a href="https://github.com/PJLab-ADG/3DTrans#resimad">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1000">[1000]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05950" title="Abstract">arXiv:2309.05950</a> (replaced) [<a href="/pdf/2309.05950" title="Download PDF">pdf</a>, <a href="/format/2309.05950" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Models as Black-Box Optimizers for Vision-Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shihong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Samuel Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhiqiu Lin</a>, 
<a href="/search/cs?searchtype=author&query=Pathak%2C+D">Deepak Pathak</a>, 
<a href="/search/cs?searchtype=author&query=Ramanan%2C+D">Deva Ramanan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item1001">[1001]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06118" title="Abstract">arXiv:2309.06118</a> (replaced) [<a href="/pdf/2309.06118" title="Download PDF">pdf</a>, <a href="/format/2309.06118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CHITNet: A Complementary to Harmonious Information Transfer Network for  Infrared and Visible Image Fusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yafei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+K">Keying Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huafeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhengtao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1002">[1002]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06129" title="Abstract">arXiv:2309.06129</a> (replaced) [<a href="/pdf/2309.06129" title="Download PDF">pdf</a>, <a href="/format/2309.06129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking  using Synthetic Eye Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Byrne%2C+S+A">Sean Anthony Byrne</a>, 
<a href="/search/cs?searchtype=author&query=Maquiling%2C+V">Virmarie Maquiling</a>, 
<a href="/search/cs?searchtype=author&query=Nystr%C3%B6m%2C+M">Marcus Nystr&#xf6;m</a>, 
<a href="/search/cs?searchtype=author&query=Kasneci%2C+E">Enkelejda Kasneci</a>, 
<a href="/search/cs?searchtype=author&query=Niehorster%2C+D+C">Diederick C. Niehorster</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 32 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)

</div>
</div>
</dd>
<dt><a name="item1003">[1003]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06219" title="Abstract">arXiv:2309.06219</a> (replaced) [<a href="/pdf/2309.06219" title="Download PDF">pdf</a>, <a href="/format/2309.06219" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human Action Co-occurrence in Lifestyle Vlogs using Graph Link  Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ignat%2C+O">Oana Ignat</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+S">Santiago Castro</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Weiji Li</a>, 
<a href="/search/cs?searchtype=author&query=Mihalcea%2C+R">Rada Mihalcea</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Computers and Society (cs.CY); Information Retrieval (cs.IR)

</div>
</div>
</dd>
<dt><a name="item1004">[1004]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06577" title="Abstract">arXiv:2309.06577</a> (replaced) [<a href="/pdf/2309.06577" title="Download PDF">pdf</a>, <a href="/format/2309.06577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Finite Initialization for Tensorized Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ali%2C+A+M">Alejandro Mata Ali</a>, 
<a href="/search/cs?searchtype=author&query=Delgado%2C+I+P">I&#xf1;igo Perez Delgado</a>, 
<a href="/search/cs?searchtype=author&query=Roura%2C+M+R">Marina Ristol Roura</a>, 
<a href="/search/cs?searchtype=author&query=de+Leceta%2C+A+M+F">Aitor Moreno Fdez. de Leceta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item1005">[1005]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06664" title="Abstract">arXiv:2309.06664</a> (replaced) [<a href="/pdf/2309.06664" title="Download PDF">pdf</a>, <a href="/format/2309.06664" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A fixed-parameter tractable algorithm for combinatorial filter reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yulin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shell%2C+D+A">Dylan A. Shell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1006">[1006]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06902" title="Abstract">arXiv:2309.06902</a> (replaced) [<a href="/pdf/2309.06902" title="Download PDF">pdf</a>, <a href="/format/2309.06902" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CCSPNet-Joint: Efficient Joint Training Method for Traffic Sign  Detection Under Extreme Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hong%2C+H">Haoqin Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yue Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Shu%2C+X">Xiangyu Shu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xiaofang Hu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1007">[1007]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07416" title="Abstract">arXiv:2309.07416</a> (replaced) [<a href="/pdf/2309.07416" title="Download PDF">pdf</a>, <a href="/format/2309.07416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3-AUDIODEC: Multi-channel multi-speaker multi-spatial audio codec
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ratnarajah%2C+A">Anton Ratnarajah</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shi-Xiong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> More results and source code are available at <a href="https://anton-jeran.github.io/MAD/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item1008">[1008]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07425" title="Abstract">arXiv:2309.07425</a> (replaced) [<a href="/pdf/2309.07425" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation  through Self-Attention and Multiscale
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+S">Shuochen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenxin Zhang</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial
  Information Sciences 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1009">[1009]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07510" title="Abstract">arXiv:2309.07510</a> (replaced) [<a href="/pdf/2309.07510" title="Download PDF">pdf</a>, <a href="/format/2309.07510" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning Environment-Aware Affordance for 3D Articulated Object  Manipulation under Occlusions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+K">Kai Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+R">Ruihai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+Y">Yan Shen</a>, 
<a href="/search/cs?searchtype=author&query=Ning%2C+C">Chuanruo Ning</a>, 
<a href="/search/cs?searchtype=author&query=Zhan%2C+G">Guanqi Zhan</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In 37th Conference on Neural Information Processing Systems (NeurIPS 2023). Website at <a href="https://chengkaiacademycity.github.io/EnvAwareAfford/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item1010">[1010]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07545" title="Abstract">arXiv:2309.07545</a> (replaced) [<a href="/pdf/2309.07545" title="Download PDF">pdf</a>, <a href="/format/2309.07545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+D">Debayan Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Arefa">Arefa</a>, 
<a href="/search/cs?searchtype=author&query=Usbeck%2C+R">Ricardo Usbeck</a>, 
<a href="/search/cs?searchtype=author&query=Biemann%2C+C">Chris Biemann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at International Semantic Web Conference (ISWC) 2023 Posters &amp; Demo Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1011">[1011]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07579" title="Abstract">arXiv:2309.07579</a> (replaced) [<a href="/pdf/2309.07579" title="Download PDF">pdf</a>, <a href="/format/2309.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Transformers for Sequences of SPD Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seraphim%2C+M">Mathieu Seraphim</a>, 
<a href="/search/cs?searchtype=author&query=Lechervy%2C+A">Alexis Lechervy</a>, 
<a href="/search/cs?searchtype=author&query=Yger%2C+F">Florian Yger</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+L">Luc Brun</a>, 
<a href="/search/cs?searchtype=author&query=Etard%2C+O">Olivier Etard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the ICASSP 2024 Conference. v2: error correction relative to v1 - Section 1, changed "less anisotropic" to "less isotropic". v3: updated citation 15 (has since been published)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1012">[1012]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07843" title="Abstract">arXiv:2309.07843</a> (replaced) [<a href="/pdf/2309.07843" title="Download PDF">pdf</a>, <a href="/format/2309.07843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Applying Deep Learning to Calibrate Stochastic Volatility Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sridi%2C+A">Abir Sridi</a>, 
<a href="/search/q-fin?searchtype=author&query=Bilokon%2C+P">Paul Bilokon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Finance (q-fin.CP)</span>; Artificial Intelligence (cs.AI); Mathematical Finance (q-fin.MF); Pricing of Securities (q-fin.PR); Risk Management (q-fin.RM)

</div>
</div>
</dd>
<dt><a name="item1013">[1013]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07875" title="Abstract">arXiv:2309.07875</a> (replaced) [<a href="/pdf/2309.07875" title="Download PDF">pdf</a>, <a href="/format/2309.07875" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safety-Tuned LLaMAs: Lessons From Improving the Safety of Large Language  Models that Follow Instructions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bianchi%2C+F">Federico Bianchi</a>, 
<a href="/search/cs?searchtype=author&query=Suzgun%2C+M">Mirac Suzgun</a>, 
<a href="/search/cs?searchtype=author&query=Attanasio%2C+G">Giuseppe Attanasio</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%B6ttger%2C+P">Paul R&#xf6;ttger</a>, 
<a href="/search/cs?searchtype=author&query=Jurafsky%2C+D">Dan Jurafsky</a>, 
<a href="/search/cs?searchtype=author&query=Hashimoto%2C+T">Tatsunori Hashimoto</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">James Zou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1014">[1014]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08214" title="Abstract">arXiv:2309.08214</a> (replaced) [<a href="/pdf/2309.08214" title="Download PDF">pdf</a>, <a href="/format/2309.08214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTG: Mapless Trajectory Generator with Traversability Coverage for  Outdoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M+C">Ming C. Lin</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1015">[1015]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08339" title="Abstract">arXiv:2309.08339</a> (replaced) [<a href="/pdf/2309.08339" title="Download PDF">pdf</a>, <a href="/format/2309.08339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of ADAM with Constant Step Size in Non-Convex Settings: A  Simple Proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+A">Alokendu Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhartendu Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Rathore%2C+P">Punit Rathore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages including references and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1016">[1016]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08416" title="Abstract">arXiv:2309.08416</a> (replaced) [<a href="/pdf/2309.08416" title="Download PDF">pdf</a>, <a href="/format/2309.08416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Neural Radiance Fields using RGB and Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1017">[1017]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08424" title="Abstract">arXiv:2309.08424</a> (replaced) [<a href="/pdf/2309.08424" title="Download PDF">pdf</a>, <a href="/format/2309.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth  Estimation with Cross-Task Distillation and Boundary Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duc%2C+C+D">Cao Dinh Duc</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">Jongwoo Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1018">[1018]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08628" title="Abstract">arXiv:2309.08628</a> (replaced) [<a href="/pdf/2309.08628" title="Download PDF">pdf</a>, <a href="/format/2309.08628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Recovering from Privacy-Preserving Masking with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vats%2C+A">Arpita Vats</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+P">Peng Su</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+D">Debjyoti Paul</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+Y">Yingyi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Pang%2C+Y">Yutong Pang</a>, 
<a href="/search/cs?searchtype=author&query=Ahmed%2C+Z">Zeeshan Ahmed</a>, 
<a href="/search/cs?searchtype=author&query=Kalinli%2C+O">Ozlem Kalinli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1019">[1019]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08774" title="Abstract">arXiv:2309.08774</a> (replaced) [<a href="/pdf/2309.08774" title="Download PDF">pdf</a>, <a href="/format/2309.08774" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design of Novel Analog Compute Paradigms with Ark
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yu-Neng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Achour%2C+S">Sara Achour</a>, 
<a href="/search/cs?searchtype=author&query=Cowan%2C+G">Glenn Cowan</a>, 
<a href="/search/cs?searchtype=author&query=R%C3%BChrmair%2C+U">Ulrich R&#xfc;hrmair</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1020">[1020]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.09273" title="Abstract">arXiv:2309.09273</a> (replaced) [<a href="/pdf/2309.09273" title="Download PDF">pdf</a>, <a href="/ps/2309.09273" title="Download PostScript">ps</a>, <a href="/format/2309.09273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Asymptotic Analysis of the Downlink in Cooperative Massive MIMO Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bergel%2C+I">Itsik Bergel</a>, 
<a href="/search/cs?searchtype=author&query=Govindasamy%2C+S">Siddhartan Govindasamy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1021">[1021]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10173" title="Abstract">arXiv:2309.10173</a> (replaced) [<a href="/pdf/2309.10173" title="Download PDF">pdf</a>, <a href="/format/2309.10173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GCNIDS: Graph Convolutional Network-Based Intrusion Detection System for  CAN Bus
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Devnath%2C+M+K">Maloy Kumar Devnath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1022">[1022]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10219" title="Abstract">arXiv:2309.10219</a> (replaced) [<a href="/pdf/2309.10219" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-level feature fusion network combining attention mechanisms for  polyp segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+J">Junzhuo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Q">Qiaosong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Ye Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xin%2C+D">Deng Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1023">[1023]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10283" title="Abstract">arXiv:2309.10283</a> (replaced) [<a href="/pdf/2309.10283" title="Download PDF">pdf</a>, <a href="/format/2309.10283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FRAMU: Attention-based Machine Unlearning using Federated Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+T">Thanveer Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+T">Taotao Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X">Xiaofeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item1024">[1024]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10292" title="Abstract">arXiv:2309.10292</a> (replaced) [<a href="/pdf/2309.10292" title="Download PDF">pdf</a>, <a href="/format/2309.10292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Julia as a unifying end-to-end workflow language on the Frontier  exascale system
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godoy%2C+W+F">William F. Godoy</a>, 
<a href="/search/cs?searchtype=author&query=Valero-Lara%2C+P">Pedro Valero-Lara</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+C">Caira Anderson</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K+W">Katrina W. Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gainaru%2C+A">Ana Gainaru</a>, 
<a href="/search/cs?searchtype=author&query=da+Silva%2C+R+F">Rafael Ferreira da Silva</a>, 
<a href="/search/cs?searchtype=author&query=Vetter%2C+J+S">Jeffrey S. Vetter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 8 figures, accepted at the 18th Workshop on Workflows in Support of Large-Scale Science (WORKS23), IEEE/ACM The International Conference for High Performance Computing, Networking, Storage, and Analysis, SC23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Programming Languages (cs.PL)

</div>
</div>
</dd>
<dt><a name="item1025">[1025]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10368" title="Abstract">arXiv:2309.10368</a> (replaced) [<a href="/pdf/2309.10368" title="Download PDF">pdf</a>, <a href="/format/2309.10368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Worst-Case and Smoothed Analysis of Hartigan&#x27;s Method for k-Means  Clustering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Manthey%2C+B">Bodo Manthey</a>, 
<a href="/search/cs?searchtype=author&query=van+Rhijn%2C+J">Jesse van Rhijn</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Geometry (cs.CG); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item1026">[1026]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10438" title="Abstract">arXiv:2309.10438</a> (replaced) [<a href="/pdf/2309.10438" title="Download PDF">pdf</a>, <a href="/format/2309.10438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AutoDiffusion: Training-Free Optimization of Time Steps and  Architectures for Automated Diffusion Model Acceleration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lijiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huixia Li</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+X">Xiawu Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+J">Jie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuefeng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+M">Min Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xin Pan</a>, 
<a href="/search/cs?searchtype=author&query=Chao%2C+F">Fei Chao</a>, 
<a href="/search/cs?searchtype=author&query=Ji%2C+R">Rongrong Ji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1027">[1027]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10475" title="Abstract">arXiv:2309.10475</a> (replaced) [<a href="/pdf/2309.10475" title="Download PDF">pdf</a>, <a href="/format/2309.10475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LineMarkNet: Line Landmark Detection for Valet Parking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zizhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yuanzhu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Rui Tang</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jian Pu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1028">[1028]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10509" title="Abstract">arXiv:2309.10509</a> (replaced) [<a href="/pdf/2309.10509" title="Download PDF">pdf</a>, <a href="/format/2309.10509" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polynomial-time Solver of Tridiagonal QUBO and QUDO problems with Tensor  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Ali%2C+A+M">Alejandro Mata Ali</a>, 
<a href="/search/quant-ph?searchtype=author&query=Delgado%2C+I+P">I&#xf1;igo Perez Delgado</a>, 
<a href="/search/quant-ph?searchtype=author&query=Roura%2C+M+R">Marina Ristol Roura</a>, 
<a href="/search/quant-ph?searchtype=author&query=de+Leceta%2C+A+M+F">Aitor Moreno Fdez. de Leceta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Emerging Technologies (cs.ET)

</div>
</div>
</dd>
<dt><a name="item1029">[1029]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10527" title="Abstract">arXiv:2309.10527</a> (replaced) [<a href="/pdf/2309.10527" title="Download PDF">pdf</a>, <a href="/format/2309.10527" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPOT: Scalable 3D Pre-training via Occupancy Prediction for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xiangchao Yan</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runjian Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jiakang Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Cai%2C+X">Xinyu Cai</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+W">Wenqi Shao</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+P">Ping Luo</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1030">[1030]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10563" title="Abstract">arXiv:2309.10563</a> (replaced) [<a href="/pdf/2309.10563" title="Download PDF">pdf</a>, <a href="/format/2309.10563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Hierarchical Neural Framework for Classification and its Explanation  in Large Unstructured Legal Documents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prasad%2C+N">Nishchal Prasad</a>, 
<a href="/search/cs?searchtype=author&query=Boughanem%2C+M">Mohand Boughanem</a>, 
<a href="/search/cs?searchtype=author&query=Dkaki%2C+T">Taoufik Dkaki</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1031">[1031]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10592" title="Abstract">arXiv:2309.10592</a> (replaced) [<a href="/pdf/2309.10592" title="Download PDF">pdf</a>, <a href="/format/2309.10592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> NDDepth: Normal-Distance Assisted Monocular Depth Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shao%2C+S">Shuwei Shao</a>, 
<a href="/search/cs?searchtype=author&query=Pei%2C+Z">Zhongcai Pei</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Weihai Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xingming Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengguo Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1032">[1032]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10639" title="Abstract">arXiv:2309.10639</a> (replaced) [<a href="/pdf/2309.10639" title="Download PDF">pdf</a>, <a href="/ps/2309.10639" title="Download PostScript">ps</a>, <a href="/format/2309.10639" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Geometric structure of Deep Learning networks and construction of global  ${\mathcal L}^2$ minimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Thomas Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ewald%2C+P+M">Patricia Mu&#xf1;oz Ewald</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> AMS Latex, 21 pages. Typos corrected, slightly extended
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Optimization and Control (math.OC); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item1033">[1033]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10918" title="Abstract">arXiv:2309.10918</a> (replaced) [<a href="/pdf/2309.10918" title="Download PDF">pdf</a>, <a href="/format/2309.10918" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Posterior Contraction Rates for Mat&#xe9;rn Gaussian Processes on  Riemannian Manifolds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Rosa%2C+P">Paul Rosa</a>, 
<a href="/search/stat?searchtype=author&query=Borovitskiy%2C+V">Viacheslav Borovitskiy</a>, 
<a href="/search/stat?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/stat?searchtype=author&query=Rousseau%2C+J">Judith Rousseau</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Statistics Theory (math.ST)

</div>
</div>
</dd>
<dt><a name="item1034">[1034]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.10980" title="Abstract">arXiv:2309.10980</a> (replaced) [<a href="/pdf/2309.10980" title="Download PDF">pdf</a>, <a href="/format/2309.10980" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shaik%2C+T">Thanveer Shaik</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+X">Xiaohui Tao</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Haoran Xie</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lin Li</a>, 
<a href="/search/cs?searchtype=author&query=Yong%2C+J">Jianming Yong</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+H">Hong-Ning Dai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with <a href="/abs/2309.10576">arXiv:2309.10576</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1035">[1035]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11002" title="Abstract">arXiv:2309.11002</a> (replaced) [<a href="/pdf/2309.11002" title="Download PDF">pdf</a>, <a href="/format/2309.11002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PPD: A New Valet Parking Pedestrian Fisheye Dataset for Autonomous  Driving
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zizhang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xinyuan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fan Song</a>, 
<a href="/search/cs?searchtype=author&query=Gan%2C+Y">Yuanzhu Gan</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tianhao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Pu%2C+J">Jian Pu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+R">Rui Tang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1036">[1036]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11010" title="Abstract">arXiv:2309.11010</a> (replaced) [<a href="/pdf/2309.11010" title="Download PDF">pdf</a>, <a href="/format/2309.11010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation-aided Learning from Demonstration for Robotic LEGO  Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+R">Ruixuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A">Alan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+X">Xusheng Luo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changliu Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item1037">[1037]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11012" title="Abstract">arXiv:2309.11012</a> (replaced) [<a href="/pdf/2309.11012" title="Download PDF">pdf</a>, <a href="/format/2309.11012" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Acoustic Side Channel Attacks on Keyboards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taheritajar%2C+A">Alireza Taheritajar</a>, 
<a href="/search/cs?searchtype=author&query=Harris%2C+Z+M">Zahra Mahmoudpour Harris</a>, 
<a href="/search/cs?searchtype=author&query=Rahaeimehr%2C+R">Reza Rahaeimehr</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages, conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1038">[1038]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11056" title="Abstract">arXiv:2309.11056</a> (replaced) [<a href="/pdf/2309.11056" title="Download PDF">pdf</a>, <a href="/ps/2309.11056" title="Download PostScript">ps</a>, <a href="/format/2309.11056" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Verified Cost Analysis of Joinable Red-Black Trees
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+R">Runming Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Grodin%2C+H">Harrison Grodin</a> (1), 
<a href="/search/cs?searchtype=author&query=Harper%2C+R">Robert Harper</a> (1) ((1) Carnegie Mellon University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item1039">[1039]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11109" title="Abstract">arXiv:2309.11109</a> (replaced) [<a href="/pdf/2309.11109" title="Download PDF">pdf</a>, <a href="/format/2309.11109" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-supervised Domain-agnostic Domain Adaptation for Satellite Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+F">Fahong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yilei Shi</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item1040">[1040]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11119" title="Abstract">arXiv:2309.11119</a> (replaced) [<a href="/pdf/2309.11119" title="Download PDF">pdf</a>, <a href="/format/2309.11119" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BroadBEV: Collaborative LiDAR-camera Fusion for Broad-sighted Bird&#x27;s Eye  View Map Construction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+G">Giseop Kim</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+K+H">Kyong Hwan Jin</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+S">Sunwook Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1041">[1041]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11146" title="Abstract">arXiv:2309.11146</a> (replaced) [<a href="/pdf/2309.11146" title="Download PDF">pdf</a>, <a href="/format/2309.11146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Poster: Accountable Processing of Reported Street Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matzutt%2C+R">Roman Matzutt</a>, 
<a href="/search/cs?searchtype=author&query=Pennekamp%2C+J">Jan Pennekamp</a>, 
<a href="/search/cs?searchtype=author&query=Wehrle%2C+K">Klaus Wehrle</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as a poster abstract to CCS'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1042">[1042]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11268" title="Abstract">arXiv:2309.11268</a> (replaced) [<a href="/pdf/2309.11268" title="Download PDF">pdf</a>, <a href="/format/2309.11268" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> StructChart: Perception, Structuring, Reasoning for Visual Chart  Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xia%2C+R">Renqiu Xia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+H">Haoyang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+N">Ning Liao</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+P">Peng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Botian Shi</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+J">Junchi Yan</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SimChart9K is available for downloading at: <a href="https://github.com/UniModal4Reasoning/SimChart9K.">this https URL</a> 21 pages, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1043">[1043]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11281" title="Abstract">arXiv:2309.11281</a> (replaced) [<a href="/pdf/2309.11281" title="Download PDF">pdf</a>, <a href="/format/2309.11281" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language-driven Object Fusion into Neural Radiance Fields with  Pose-Conditioned Dataset Updates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shum%2C+K+C">Ka Chun Shum</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Jaeyeon Kim</a>, 
<a href="/search/cs?searchtype=author&query=Hua%2C+B">Binh-Son Hua</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D+T">Duc Thanh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Sai-Kit Yeung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1044">[1044]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11325" title="Abstract">arXiv:2309.11325</a> (replaced) [<a href="/pdf/2309.11325" title="Download PDF">pdf</a>, <a href="/format/2309.11325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal  Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+S">Shengbin Yue</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Siyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bingxuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shen%2C+C">Chenchen Shen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shujun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuxuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+Y">Yao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Yun%2C+S">Song Yun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+Z">Zhongyu Wei</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1045">[1045]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11327" title="Abstract">arXiv:2309.11327</a> (replaced) [<a href="/pdf/2309.11327" title="Download PDF">pdf</a>, <a href="/format/2309.11327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Data Collection and Unsupervised Learning for Code-switched  Tunisian Arabic Automatic Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Abdallah%2C+A+A+B">Ahmed Amine Ben Abdallah</a>, 
<a href="/search/eess?searchtype=author&query=Kabboudi%2C+A">Ata Kabboudi</a>, 
<a href="/search/eess?searchtype=author&query=Kanoun%2C+A">Amir Kanoun</a>, 
<a href="/search/eess?searchtype=author&query=Zaiem%2C+S">Salah Zaiem</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item1046">[1046]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11331" title="Abstract">arXiv:2309.11331</a> (replaced) [<a href="/pdf/2309.11331" title="Download PDF">pdf</a>, <a href="/format/2309.11331" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chengcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Nie%2C+Y">Ying Nie</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Jianyuan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chuanjian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+K">Kai Han</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yunhe Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by NeurIPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1047">[1047]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11417" title="Abstract">arXiv:2309.11417</a> (replaced) [<a href="/e-print/2309.11417" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CNNs for JPEGs: A Study in Computational Cost
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Santos%2C+S+F+d">Samuel Felipe dos Santos</a>, 
<a href="/search/cs?searchtype=author&query=Sebe%2C+N">Nicu Sebe</a>, 
<a href="/search/cs?searchtype=author&query=Almeida%2C+J">Jurandy Almeida</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A previous version of this work had already been submitted to ArXiv and is available at <a href="/abs/2012.14426">arXiv:2012.14426</a>. Instead of maintaining two different submissions, we decided to submit a replacement for the previous submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1048">[1048]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11452" title="Abstract">arXiv:2309.11452</a> (replaced) [<a href="/pdf/2309.11452" title="Download PDF">pdf</a>, <a href="/format/2309.11452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using deep learning to construct stochastic local search SAT solvers  with performance bounds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kramer%2C+M">Maximilian Kramer</a>, 
<a href="/search/cs?searchtype=author&query=Boes%2C+P">Paul Boes</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 9 figures, code available at <a href="https://github.com/porscheofficial/sls_sat_solving_with_deep_learning">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item1049">[1049]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11495" title="Abstract">arXiv:2309.11495</a> (replaced) [<a href="/pdf/2309.11495" title="Download PDF">pdf</a>, <a href="/format/2309.11495" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Verification Reduces Hallucination in Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dhuliawala%2C+S">Shehzaad Dhuliawala</a>, 
<a href="/search/cs?searchtype=author&query=Komeili%2C+M">Mojtaba Komeili</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+J">Jing Xu</a>, 
<a href="/search/cs?searchtype=author&query=Raileanu%2C+R">Roberta Raileanu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xian Li</a>, 
<a href="/search/cs?searchtype=author&query=Celikyilmaz%2C+A">Asli Celikyilmaz</a>, 
<a href="/search/cs?searchtype=author&query=Weston%2C+J">Jason Weston</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1050">[1050]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11601" title="Abstract">arXiv:2309.11601</a> (replaced) [<a href="/pdf/2309.11601" title="Download PDF">pdf</a>, <a href="/format/2309.11601" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion Models for Structural Component Design
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Herron%2C+E">Ethan Herron</a>, 
<a href="/search/cs?searchtype=author&query=Rade%2C+J">Jaydeep Rade</a>, 
<a href="/search/cs?searchtype=author&query=Jignasu%2C+A">Anushrut Jignasu</a>, 
<a href="/search/cs?searchtype=author&query=Ganapathysubramanian%2C+B">Baskar Ganapathysubramanian</a>, 
<a href="/search/cs?searchtype=author&query=Balu%2C+A">Aditya Balu</a>, 
<a href="/search/cs?searchtype=author&query=Sarkar%2C+S">Soumik Sarkar</a>, 
<a href="/search/cs?searchtype=author&query=Krishnamurthy%2C+A">Adarsh Krishnamurthy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item1051">[1051]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11625" title="Abstract">arXiv:2309.11625</a> (replaced) [<a href="/pdf/2309.11625" title="Download PDF">pdf</a>, <a href="/format/2309.11625" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Legitimate Interest is the New Consent -- Large-Scale Measurement and  Legal Compliance of IAB Europe TCF Paywalls
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Morel%2C+V">Victor Morel</a>, 
<a href="/search/cs?searchtype=author&query=Santos%2C+C">Cristiana Santos</a>, 
<a href="/search/cs?searchtype=author&query=Fredholm%2C+V">Viktor Fredholm</a>, 
<a href="/search/cs?searchtype=author&query=Thunberg%2C+A">Adam Thunberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at WPES2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item1052">[1052]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11721" title="Abstract">arXiv:2309.11721</a> (replaced) [<a href="/pdf/2309.11721" title="Download PDF">pdf</a>, <a href="/ps/2309.11721" title="Download PostScript">ps</a>, <a href="/format/2309.11721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Defining and Preventing Asymmetric Mempool DoS in Ethereum with saferAd
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+W">Wanning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yibo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+Y">Yuzhe Tang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1053">[1053]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11784" title="Abstract">arXiv:2309.11784</a> (replaced) [<a href="/pdf/2309.11784" title="Download PDF">pdf</a>, <a href="/format/2309.11784" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collaborative Fault-Identification &amp; Reconstruction in Multi-Agent  Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Khan%2C+S">Shiraz Khan</a>, 
<a href="/search/eess?searchtype=author&query=Hwang%2C+I">Inseok Hwang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item1054">[1054]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11836" title="Abstract">arXiv:2309.11836</a> (replaced) [<a href="/pdf/2309.11836" title="Download PDF">pdf</a>, <a href="/format/2309.11836" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pre-configured Error Pattern Ordered Statistics Decoding for CRC-Polar  Codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuanyu Li</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+K">Kai Niu</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+Y">Yuxin Han</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+J">Jincheng Dai</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Z">Zhiyuan Tan</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Z">Zhiheng Guo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item1055">[1055]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11851" title="Abstract">arXiv:2309.11851</a> (replaced) [<a href="/pdf/2309.11851" title="Download PDF">pdf</a>, <a href="/format/2309.11851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DEYOv3: DETR with YOLO for Real-time Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+H">Haodong Ouyang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item1056">[1056]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11858" title="Abstract">arXiv:2309.11858</a> (replaced) [<a href="/pdf/2309.11858" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for  Linear Computed Tomography in Multi-Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhisheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+Z">Zihan Deng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+F">Fenglin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Y">Yixing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Haijun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+J">Junning Cui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item1057">[1057]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.11917" title="Abstract">arXiv:2309.11917</a> (replaced) [<a href="/pdf/2309.11917" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Sensor Fusion for Indoor Wireless Localization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zuxuan Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item1058">[1058]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12143" title="Abstract">arXiv:2309.12143</a> (replaced) [<a href="/pdf/2309.12143" title="Download PDF">pdf</a>, <a href="/ps/2309.12143" title="Download PostScript">ps</a>, <a href="/format/2309.12143" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An iterative method to solve Lyapunov equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bezerra%2C+L+H">Licio Hernanes Bezerra</a>, 
<a href="/search/math?searchtype=author&query=Wisniewski%2C+F">Felipe Wisniewski</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item1059">[1059]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12164" title="Abstract">arXiv:2309.12164</a> (replaced) [<a href="/pdf/2309.12164" title="Download PDF">pdf</a>, <a href="/format/2309.12164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Stratified Type Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+J">Jonathan Chan</a>, 
<a href="/search/cs?searchtype=author&query=Weirich%2C+S">Stephanie Weirich</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 3 figures, submitted to CPP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
</div>
</dd>
<dt><a name="item1060">[1060]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12269" title="Abstract">arXiv:2309.12269</a> (replaced) [<a href="/pdf/2309.12269" title="Download PDF">pdf</a>, <a href="/format/2309.12269" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Cambridge Law Corpus: A Corpus for Legal AI Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=%C3%96stling%2C+A">Andreas &#xd6;stling</a>, 
<a href="/search/cs?searchtype=author&query=Sargeant%2C+H">Holli Sargeant</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+H">Huiyuan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Bull%2C+L">Ludwig Bull</a>, 
<a href="/search/cs?searchtype=author&query=Terenin%2C+A">Alexander Terenin</a>, 
<a href="/search/cs?searchtype=author&query=Jonsson%2C+L">Leif Jonsson</a>, 
<a href="/search/cs?searchtype=author&query=Magnusson%2C+M">M&#xe5;ns Magnusson</a>, 
<a href="/search/cs?searchtype=author&query=Steffek%2C+F">Felix Steffek</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advances in Neural Information Processing Systems, Datasets and
  Benchmarks Track, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1061">[1061]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12288" title="Abstract">arXiv:2309.12288</a> (replaced) [<a href="/pdf/2309.12288" title="Download PDF">pdf</a>, <a href="/format/2309.12288" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Reversal Curse: LLMs trained on &quot;A is B&quot; fail to learn &quot;B is A&quot;
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Berglund%2C+L">Lukas Berglund</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+M">Meg Tong</a>, 
<a href="/search/cs?searchtype=author&query=Kaufmann%2C+M">Max Kaufmann</a>, 
<a href="/search/cs?searchtype=author&query=Balesni%2C+M">Mikita Balesni</a>, 
<a href="/search/cs?searchtype=author&query=Stickland%2C+A+C">Asa Cooper Stickland</a>, 
<a href="/search/cs?searchtype=author&query=Korbak%2C+T">Tomasz Korbak</a>, 
<a href="/search/cs?searchtype=author&query=Evans%2C+O">Owain Evans</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1062">[1062]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12295" title="Abstract">arXiv:2309.12295</a> (replaced) [<a href="/pdf/2309.12295" title="Download PDF">pdf</a>, <a href="/format/2309.12295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning to Drive Anywhere
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+R">Ruizhao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+P">Peng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Ohn-Bar%2C+E">Eshed Ohn-Bar</a>, 
<a href="/search/cs?searchtype=author&query=Saligrama%2C+V">Venkatesh Saligrama</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Conference on Robot Learning (CoRL) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item1063">[1063]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12312" title="Abstract">arXiv:2309.12312</a> (replaced) [<a href="/pdf/2309.12312" title="Download PDF">pdf</a>, <a href="/format/2309.12312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Collins%2C+J+A">Jeremy A. Collins</a>, 
<a href="/search/cs?searchtype=author&query=Houff%2C+C">Cody Houff</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y+L">You Liang Tan</a>, 
<a href="/search/cs?searchtype=author&query=Kemp%2C+C+C">Charles C. Kemp</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item1064">[1064]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12330" title="Abstract">arXiv:2309.12330</a> (replaced) [<a href="/pdf/2309.12330" title="Download PDF">pdf</a>, <a href="/format/2309.12330" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decentralized Token Economy Theory (DeTEcT)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-fin?searchtype=author&query=Sadykhov%2C+R">Rem Sadykhov</a>, 
<a href="/search/q-fin?searchtype=author&query=Goodell%2C+G">Geoffrey Goodell</a>, 
<a href="/search/q-fin?searchtype=author&query=de+Montigny%2C+D">Denis de Montigny</a>, 
<a href="/search/q-fin?searchtype=author&query=Schoernig%2C+M">Martin Schoernig</a>, 
<a href="/search/q-fin?searchtype=author&query=Treleaven%2C+P">Philip Treleaven</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">General Finance (q-fin.GN)</span>; Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP)

</div>
</div>
</dd>
<dt><a name="item1065">[1065]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12570" title="Abstract">arXiv:2309.12570</a> (replaced) [<a href="/pdf/2309.12570" title="Download PDF">pdf</a>, <a href="/format/2309.12570" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Creativity Support in the Age of Large Language Models: An Empirical  Study Involving Emerging Writers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chakrabarty%2C+T">Tuhin Chakrabarty</a>, 
<a href="/search/cs?searchtype=author&query=Padmakumar%2C+V">Vishakh Padmakumar</a>, 
<a href="/search/cs?searchtype=author&query=Brahman%2C+F">Faeze Brahman</a>, 
<a href="/search/cs?searchtype=author&query=Muresan%2C+S">Smaranda Muresan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item1066">[1066]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12585" title="Abstract">arXiv:2309.12585</a> (replaced) [<a href="/pdf/2309.12585" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BGF-YOLO: Enhanced YOLOv8 with Multiscale Attentional Feature Fusion for  Brain Tumor Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+M">Ming Kang</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+C">Chee-Ming Ting</a>, 
<a href="/search/cs?searchtype=author&query=Ting%2C+F+F">Fung Fung Ting</a>, 
<a href="/search/cs?searchtype=author&query=Phan%2C+R+C+-">Rapha&#xeb;l C.-W. Phan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Signal Processing (eess.SP); Applications (stat.AP)

</div>
</div>
</dd>
<dt><a name="item1067">[1067]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12808" title="Abstract">arXiv:2309.12808</a> (replaced) [<a href="/e-print/2309.12808" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ChatPRCS: A Personalized Support System for English Reading  Comprehension based on ChatGPT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xizhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Y">Yihua Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Changqin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xiaodi Huang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We are very sorry, we found a problem in the article and will resubmit it after modification
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item1068">[1068]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.12968" title="Abstract">arXiv:2309.12968</a> (replaced) [<a href="/pdf/2309.12968" title="Download PDF">pdf</a>, <a href="/format/2309.12968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PassViz: A Visualisation System for Analysing Leaked Passwords
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Parker%2C+S">Sam Parker</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+H">Haiyue Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shujun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item1069">[1069]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.13002" title="Abstract">arXiv:2309.13002</a> (replaced) [<a href="/pdf/2309.13002" title="Download PDF">pdf</a>, <a href="/format/2309.13002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Expressive variational quantum circuits provide inherent privacy in  federated learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Kumar%2C+N">Niraj Kumar</a>, 
<a href="/search/quant-ph?searchtype=author&query=Heredge%2C+J">Jamie Heredge</a>, 
<a href="/search/quant-ph?searchtype=author&query=Li%2C+C">Changhao Li</a>, 
<a href="/search/quant-ph?searchtype=author&query=Eloul%2C+S">Shaltiel Eloul</a>, 
<a href="/search/quant-ph?searchtype=author&query=Sureshbabu%2C+S+H">Shree Hari Sureshbabu</a>, 
<a href="/search/quant-ph?searchtype=author&query=Pistoia%2C+M">Marco Pistoia</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 13 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item590">Cross-lists</a></li>
<li><a href="#item679">Replacements</a></li>
</ul>
<small>[ total of 1069 entries:  <b>1-1069</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
