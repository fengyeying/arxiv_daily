<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<title>Computer Science  authors/titles &quot;new&quot;</title>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
<link rel="stylesheet" type="text/css" media="screen" href="//static.arxiv.org/static/browse/0.3.2.8/css/arXiv.css?v=20220215" />
<link rel="stylesheet" type="text/css" media="screen" href="/bibex/bibex.css?20181009">
<link rel="stylesheet" type="text/css" media="screen" href="https://static.arxiv.org/static/browse/0.3.8/css/browse_search.css" />
<link rel="alternate" type="application/rss+xml" title="Computer Science " href="http://arxiv.org/rss/cs"/>
<script src="/js/mathjaxToggle.min.js" type="text/javascript"></script>


</head>
<body class="with-cu-identity">

<div id="cu-identity">
<div id="cu-logo">
<a href="https://www.cornell.edu/"><img src="//static.arxiv.org/icons/cu/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" border="0" /></a>
</div>
<div id="support-ack">
<a href="https://confluence.cornell.edu/x/ALlRF">We gratefully acknowledge support from<br /> the Simons Foundation and member institutions.</a>
</div>
</div>
<div id="header">
<h1 class="header-breadcrumbs"><a href="/"><img src="//static.arxiv.org/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;margin-right:8px;"></a> <span>&gt;</span> <a href="/list/cs/recent">cs</a></h1>
<div class="search-block level-right">
<form class="level-item mini-search" method="GET" action="https://arxiv.org/search" _lpchecked="1">
<div class="field has-addons">
<div class="control">
<input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" data-com.agilebits.onepassword.user-edited="yes">
<p class="help"><a href="https://arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
</div>
<div class="control">
<div class="select is-small">
<select name="searchtype" aria-label="Field to search">
<option value="all" selected="selected">All fields</option>
<option value="title">Title</option>
<option value="author">Author</option>
<option value="abstract">Abstract</option>
<option value="comments">Comments</option>
<option value="journal_ref">Journal reference</option>
<option value="acm_class">ACM classification</option>
<option value="msc_class">MSC classification</option>
<option value="report_num">Report number</option>
<option value="paper_id">arXiv identifier</option>
<option value="doi">DOI</option>
<option value="orcid">ORCID</option>
<option value="author_id">arXiv author ID</option>
<option value="help">Help pages</option>
<option value="full_text">Full text</option>
</select>
</div>
</div>
<button class="button is-small is-cul-darker">Search</button>
</div>
</form>
</div>
</div>
<div id="content">
<div id="dlpage">
<h1>Computer Science </h1>
<h2>New submissions</h2>
<div class="list-dateline">Submissions received from  Thu 14 Sep 23  to  Fri 15 Sep 23, announced Mon, 18 Sep 23</div>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item292">Cross-lists</a></li>
<li><a href="#item358">Replacements</a></li>
</ul>
<small>[ total of 542 entries:  <b>1-542</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
<h3>New submissions for Mon, 18 Sep 23</h3>
<dl>
<dt><a name="item1">[1]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07923" title="Abstract">arXiv:2309.07923</a> [<a href="/pdf/2309.07923" title="Download PDF">pdf</a>, <a href="/format/2309.07923" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automated and Efficient Aerodynamic Design and Analysis Framework  Integrated to PANAIR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahid%2C+T">Tahura Shahid</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%BCrkan%2C+C">Ceren G&#xfc;rkan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">Aircraft design is an iterative process that requires an estimation of
aerodynamic characteristics including drag and lift coefficients, stall
behavior, velocity, and pressure profiles repeatedly, especially in the
conceptual design phase. PanAir is a high-order aerodynamic panel method-based
algorithm developed as a part of the Public Domain Aeronautical Software
program mostly with NASA sponsorship. It is based upon potential flow theory
and is used to numerically compute lift, induced drag, and moment coefficients
of the aircraft in both subsonic and supersonic flight regimes. Quoting from
developers it is the most versatile and accurate of all the linear theory panel
codes. PanAir is a classical software that requires geometric data as an input
in the form of a PanAir-compatible format; however, commonly used
Computer-Aided Design Software packages no longer conform to the PanAir input
format. Likewise, PanAir produces its output in a PanAir-specific output file
which is not compatible with commonly used visualization software. The input
geometry required by PanAir and its output, therefore, involves significant
manual preand post-processing using intermediary software. The work proposed
here is an automated pre and post-processor to be used together with PanAir.
With the environment proposed in this work, manipulation of input and output
data using several intermediary software to and from PanAir is bypassed
successfully. The proposed environment is validated over a Cessna 210 aircraft
geometry with a modified NLF (1)-0414 airfoil. The aircraft is numerically
analyzed using PanAir together
</p>
</div>
</dd>
<dt><a name="item2">[2]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07929" title="Abstract">arXiv:2309.07929</a> [<a href="/pdf/2309.07929" title="Download PDF">pdf</a>, <a href="/format/2309.07929" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Prompting Segmentation with Sound is Generalizable Audio-Visual Source  Localizer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yaoting Wang</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+W">Weisong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Guangyao Li</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jian Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+D">Di Hu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xi Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures, submitted to AAAI 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Never having seen an object and heard its sound simultaneously, can the model
still accurately localize its visual position from the input audio? In this
work, we concentrate on the Audio-Visual Localization and Segmentation tasks
but under the demanding zero-shot and few-shot scenarios. To achieve this goal,
different from existing approaches that mostly employ the
encoder-fusion-decoder paradigm to decode localization information from the
fused audio-visual feature, we introduce the encoder-prompt-decoder paradigm,
aiming to better fit the data scarcity and varying data distribution dilemmas
with the help of abundant knowledge from pre-trained models. Specifically, we
first propose to construct Semantic-aware Audio Prompt (SAP) to help the visual
foundation model focus on sounding objects, meanwhile, the semantic gap between
the visual and audio modalities is also encouraged to shrink. Then, we develop
a Correlation Adapter (ColA) to keep minimal training efforts as well as
maintain adequate knowledge of the visual foundation model. By equipping with
these means, extensive experiments demonstrate that this new paradigm
outperforms other fusion-based methods in both the unseen class and
cross-dataset settings. We hope that our work can further promote the
generalization study of Audio-Visual Localization and Segmentation in practical
application scenarios.
</p>
</div>
</dd>
<dt><a name="item3">[3]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07930" title="Abstract">arXiv:2309.07930</a> [<a href="/pdf/2309.07930" title="Download PDF">pdf</a>, <a href="/format/2309.07930" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feuerriegel%2C+S">Stefan Feuerriegel</a>, 
<a href="/search/cs?searchtype=author&query=Hartmann%2C+J">Jochen Hartmann</a>, 
<a href="/search/cs?searchtype=author&query=Janiesch%2C+C">Christian Janiesch</a>, 
<a href="/search/cs?searchtype=author&query=Zschech%2C+P">Patrick Zschech</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in Business &amp; Information Systems Engineering (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">The term "generative AI" refers to computational techniques that are capable
of generating seemingly new, meaningful content such as text, images, or audio
from training data. The widespread diffusion of this technology with examples
such as Dall-E 2, GPT-4, and Copilot is currently revolutionizing the way we
work and communicate with each other. In this article, we provide a
conceptualization of generative AI as an entity in socio-technical systems and
provide examples of models, systems, and applications. Based on that, we
introduce limitations of current generative AI and provide an agenda for
Business &amp; Information Systems Engineering (BISE) research. Different from
previous works, we focus on generative AI in the context of information
systems, and, to this end, we discuss several opportunities and challenges that
are unique to the BISE community and make suggestions for impactful directions
for BISE research.
</p>
</div>
</dd>
<dt><a name="item4">[4]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07933" title="Abstract">arXiv:2309.07933</a> [<a href="/pdf/2309.07933" title="Download PDF">pdf</a>, <a href="/format/2309.07933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Lean-Congruence Format for EP-Bisimilarity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=van+Glabbeek%2C+R">Rob van Glabbeek</a> (University of Edinburgh), 
<a href="/search/cs?searchtype=author&query=H%C3%B6fner%2C+P">Peter H&#xf6;fner</a> (Australian National University, Canberra), 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiyou Wang</a> (Australian National University, Canberra)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In Proceedings EXPRESS/SOS2023, <a href="/abs/2309.05788">arXiv:2309.05788</a>. A full version of this paper, enriched with two appendices, is available at <a href="/abs/2308.16350">arXiv:2308.16350</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> EPTCS 387, 2023, pp. 59-75
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>

</div>
<p class="mathjax">Enabling preserving bisimilarity is a refinement of strong bisimilarity that
preserves safety as well as liveness properties. To define it properly,
labelled transition systems needed to be upgraded with a successor relation,
capturing concurrency between transitions enabled in the same state. We enrich
the well-known De Simone format to handle inductive definitions of this
successor relation. We then establish that ep-bisimilarity is a congruence for
the operators, as well as lean congruence for recursion, for all (enriched) De
Simone languages.
</p>
</div>
</dd>
<dt><a name="item5">[5]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07934" title="Abstract">arXiv:2309.07934</a> [<a href="/pdf/2309.07934" title="Download PDF">pdf</a>, <a href="/format/2309.07934" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Racing Control Variable Genetic Programming for Symbolic Regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+N">Nan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+Y">Yexiang Xue</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Symbolic regression, as one of the most crucial tasks in AI for science,
discovers governing equations from experimental data. Popular approaches based
on genetic programming, Monte Carlo tree search, or deep reinforcement learning
learn symbolic regression from a fixed dataset. They require massive datasets
and long training time especially when learning complex equations involving
many variables. Recently, Control Variable Genetic Programming (CVGP) has been
introduced which accelerates the regression process by discovering equations
from designed control variable experiments. However, the set of experiments is
fixed a-priori in CVGP and we observe that sub-optimal selection of experiment
schedules delay the discovery process significantly. To overcome this
limitation, we propose Racing Control Variable Genetic Programming
(Racing-CVGP), which carries out multiple experiment schedules simultaneously.
A selection scheme similar to that used in selecting good symbolic equations in
the genetic programming process is implemented to ensure that promising
experiment schedules eventually win over the average ones. The unfavorable
schedules are terminated early to save time for the promising ones. We evaluate
Racing-CVGP on several synthetic and real-world datasets corresponding to true
physics laws. We demonstrate that Racing-CVGP outperforms CVGP and a series of
symbolic regressors which discover equations from fixed datasets.
</p>
</div>
</dd>
<dt><a name="item6">[6]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07936" title="Abstract">arXiv:2309.07936</a> [<a href="/pdf/2309.07936" title="Download PDF">pdf</a>, <a href="/format/2309.07936" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Landscape-Sketch-Step: An AI/ML-Based Metaheuristic for Surrogate  Optimization Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Monteiro%2C+R">Rafael Monteiro</a>, 
<a href="/search/cs?searchtype=author&query=Sau%2C+K">Kartik Sau</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Git-hub on <a href="https://github.com/rafael-a-monteiro-math/landscape_sketch_and_step/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Probability (math.PR)

</div>
<p class="mathjax">In this paper, we introduce a new heuristics for global optimization in
scenarios where extensive evaluations of the cost function are expensive,
inaccessible, or even prohibitive. The method, which we call
Landscape-Sketch-and-Step (LSS), combines Machine Learning, Stochastic
Optimization, and Reinforcement Learning techniques, relying on historical
information from previously sampled points to make judicious choices of
parameter values where the cost function should be evaluated at. Unlike
optimization by Replica Exchange Monte Carlo methods, the number of evaluations
of the cost function required in this approach is comparable to that used by
Simulated Annealing, quality that is especially important in contexts like
high-throughput computing or high-performance computing tasks, where
evaluations are either computationally expensive or take a long time to be
performed. The method also differs from standard Surrogate Optimization
techniques, for it does not construct a surrogate model that aims at
approximating or reconstructing the objective function. We illustrate our
method by applying it to low dimensional optimization problems (dimensions 1,
2, 4, and 8) that mimick known difficulties of minimization on rugged energy
landscapes often seen in Condensed Matter Physics, where cost functions are
rugged and plagued with local minima. When compared to classical Simulated
Annealing, the LSS shows an effective acceleration of the optimization process.
</p>
</div>
</dd>
<dt><a name="item7">[7]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07938" title="Abstract">arXiv:2309.07938</a> [<a href="/pdf/2309.07938" title="Download PDF">pdf</a>, <a href="/format/2309.07938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Assessment of ChatGPT on Log Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mudgal%2C+P">Priyanka Mudgal</a>, 
<a href="/search/cs?searchtype=author&query=Wouhaybi%2C+R">Rita Wouhaybi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepeted at AIGC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent development of large language models (LLMs), such as ChatGPT has been
widely applied to a wide range of software engineering tasks. Many papers have
reported their analysis on the potential advantages and limitations of ChatGPT
for writing code, summarization, text generation, etc. However, the analysis of
the current state of ChatGPT for log processing has received little attention.
Logs generated by large-scale software systems are complex and hard to
understand. Despite their complexity, they provide crucial information for
subject matter experts to understand the system status and diagnose problems of
the systems. In this paper, we investigate the current capabilities of ChatGPT
to perform several interesting tasks on log data, while also trying to identify
its main shortcomings. Our findings show that the performance of the current
version of ChatGPT for log processing is limited, with a lack of consistency in
responses and scalability issues. We also outline our views on how we perceive
the role of LLMs in the log processing discipline and possible next steps to
improve the current capabilities of ChatGPT and the future LLMs in this area.
We believe our work can contribute to future academic research to address the
identified issues.
</p>
</div>
</dd>
<dt><a name="item8">[8]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07941" title="Abstract">arXiv:2309.07941</a> [<a href="/pdf/2309.07941" title="Download PDF">pdf</a>, <a href="/ps/2309.07941" title="Download PostScript">ps</a>, <a href="/format/2309.07941" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MDP Abstractions from Data: Large-Scale Stochastic Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lavaei%2C+A">Abolfazl Lavaei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.07459">arXiv:2309.07459</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This work proposes a compositional data-driven technique for the construction
of finite Markov decision processes (MDPs) for large-scale stochastic networks
with unknown mathematical models. Our proposed framework leverages
dissipativity properties of subsystems and their finite MDPs using a notion of
stochastic storage functions (SStF). In our data-driven scheme, we first build
an SStF between each unknown subsystem and its data-driven finite MDP with a
certified probabilistic confidence. We then derive dissipativity-type
compositional conditions to construct a stochastic bisimulation function (SBF)
between an interconnected network and its finite MDP using data-driven SStF of
subsystems. Accordingly, we formally quantify the probabilistic distance
between trajectories of an unknown large-scale stochastic network and those of
its finite MDP with a guaranteed confidence. We illustrate the efficacy of our
data-driven results over a room temperature network composing 100 rooms with
unknown models.
</p>
</div>
</dd>
<dt><a name="item9">[9]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07944" title="Abstract">arXiv:2309.07944</a> [<a href="/pdf/2309.07944" title="Download PDF">pdf</a>, <a href="/format/2309.07944" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-to-Image Models for Counterfactual Explanations: a Black-Box  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeanneret%2C+G">Guillaume Jeanneret</a>, 
<a href="/search/cs?searchtype=author&query=Simon%2C+L">Lo&#xef;c Simon</a>, 
<a href="/search/cs?searchtype=author&query=Jurie%2C+F">Fr&#xe9;d&#xe9;ric Jurie</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">This paper addresses the challenge of generating Counterfactual Explanations
(CEs), involving the identification and modification of the fewest necessary
features to alter a classifier's prediction for a given image. Our proposed
method, Text-to-Image Models for Counterfactual Explanations (TIME), is a
black-box counterfactual technique based on distillation. Unlike previous
methods, this approach requires solely the image and its prediction, omitting
the need for the classifier's structure, parameters, or gradients. Before
generating the counterfactuals, TIME introduces two distinct biases into Stable
Diffusion in the form of textual embeddings: the context bias, associated with
the image's structure, and the class bias, linked to class-specific features
learned by the target classifier. After learning these biases, we find the
optimal latent code applying the classifier's predicted class token and
regenerate the image using the target embedding as conditioning, producing the
counterfactual explanation. Extensive empirical studies validate that TIME can
generate explanations of comparable effectiveness even when operating within a
black-box setting.
</p>
</div>
</dd>
<dt><a name="item10">[10]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07945" title="Abstract">arXiv:2309.07945</a> [<a href="/pdf/2309.07945" title="Download PDF">pdf</a>, <a href="/format/2309.07945" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Masked Generative Modeling with Enhanced Sampling Scheme
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+D">Daesoo Lee</a>, 
<a href="/search/cs?searchtype=author&query=Aune%2C+E">Erlend Aune</a>, 
<a href="/search/cs?searchtype=author&query=Malacarne%2C+S">Sara Malacarne</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Machine Learning (stat.ML)

</div>
<p class="mathjax">This paper presents a novel sampling scheme for masked non-autoregressive
generative modeling. We identify the limitations of TimeVQVAE, MaskGIT, and
Token-Critic in their sampling processes, and propose Enhanced Sampling Scheme
(ESS) to overcome these limitations. ESS explicitly ensures both sample
diversity and fidelity, and consists of three stages: Naive Iterative Decoding,
Critical Reverse Sampling, and Critical Resampling. ESS starts by sampling a
token set using the naive iterative decoding as proposed in MaskGIT, ensuring
sample diversity. Then, the token set undergoes the critical reverse sampling,
masking tokens leading to unrealistic samples. After that, critical resampling
reconstructs masked tokens until the final sampling step is reached to ensure
high fidelity. Critical resampling uses confidence scores obtained from a
self-Token-Critic to better measure the realism of sampled tokens, while
critical reverse sampling uses the structure of the quantized latent vector
space to discover unrealistic sample paths. We demonstrate significant
performance gains of ESS in both unconditional sampling and class-conditional
sampling using all the 128 datasets in the UCR Time Series archive.
</p>
</div>
</dd>
<dt><a name="item11">[11]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07947" title="Abstract">arXiv:2309.07947</a> [<a href="/pdf/2309.07947" title="Download PDF">pdf</a>, <a href="/format/2309.07947" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TiBGL: Template-induced Brain Graph Learning for Functional Neuroimaging  Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meng%2C+X">Xiangzhu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wei Wei</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qiang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S">Shu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Liang Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">In recent years, functional magnetic resonance imaging has emerged as a
powerful tool for investigating the human brain's functional connectivity
networks. Related studies demonstrate that functional connectivity networks in
the human brain can help to improve the efficiency of diagnosing neurological
disorders. However, there still exist two challenges that limit the progress of
functional neuroimaging. Firstly, there exists an abundance of noise and
redundant information in functional connectivity data, resulting in poor
performance. Secondly, existing brain network models have tended to prioritize
either classification performance or the interpretation of neuroscience
findings behind the learned models. To deal with these challenges, this paper
proposes a novel brain graph learning framework called Template-induced Brain
Graph Learning (TiBGL), which has both discriminative and interpretable
abilities. Motivated by the related medical findings on functional
connectivites, TiBGL proposes template-induced brain graph learning to extract
template brain graphs for all groups. The template graph can be regarded as an
augmentation process on brain networks that removes noise information and
highlights important connectivity patterns. To simultaneously support the tasks
of discrimination and interpretation, TiBGL further develops template-induced
convolutional neural network and template-induced brain interpretation
analysis. Especially, the former fuses rich information from brain graphs and
template brain graphs for brain disorder tasks, and the latter can provide
insightful connectivity patterns related to brain disorders based on template
brain graphs. Experimental results on three real-world datasets show that the
proposed TiBGL can achieve superior performance compared with nine
state-of-the-art methods and keep coherent with neuroscience findings in recent
literatures.
</p>
</div>
</dd>
<dt><a name="item12">[12]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07964" title="Abstract">arXiv:2309.07964</a> [<a href="/pdf/2309.07964" title="Download PDF">pdf</a>, <a href="/format/2309.07964" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Shortest Path Restoration Lemmas for Multiple Edge Failures:  Trade-offs Between Fault-tolerance and Subpaths
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bodwin%2C+G">Greg Bodwin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lily Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Combinatorics (math.CO)

</div>
<p class="mathjax">The restoration lemma is a classic result by Afek, Bremler-Barr, Kaplan,
Cohen, and Merritt [PODC '01], which relates the structure of shortest paths in
a graph $G$ before and after some edges in the graph fail. Their work shows
that, after one edge failure, any replacement shortest path avoiding this
failing edge can be partitioned into two pre-failure shortest paths. More
generally, this implies an additive tradeoff between fault tolerance and
subpath count: for any $f, k$, we can partition any $f$-edge-failure
replacement shortest path into $k+1$ subpaths which are each an
$(f-k)$-edge-failure replacement shortest path. This generalized result has
found applications in routing, graph algorithms, fault tolerant network design,
and more.
<br />Our main result improves this to a multiplicative tradeoff between fault
tolerance and subpath count. We show that for all $f, k$, any $f$-edge-failure
replacement path can be partitioned into $O(k)$ subpaths that are each an
$(f/k)$-edge-failure replacement path. We also show an asymptotically matching
lower bound. In particular, our results imply that the original restoration
lemma is exactly tight in the case $k=1$, but can be significantly improved for
larger $k$. We also show an extension of this result to weighted input graphs,
and we give efficient algorithms that compute path decompositions satisfying
our improved restoration lemmas.
</p>
</div>
</dd>
<dt><a name="item13">[13]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07967" title="Abstract">arXiv:2309.07967</a> [<a href="/pdf/2309.07967" title="Download PDF">pdf</a>, <a href="/format/2309.07967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> iHAS: Instance-wise Hierarchical Architecture Search for Deep Learning  Recommendation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+Y">Yakun Yu</a>, 
<a href="/search/cs?searchtype=author&query=Qi%2C+S">Shi-ang Qi</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiuding Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liyao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Di Niu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted as CIKM23 Long paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
<p class="mathjax">Current recommender systems employ large-sized embedding tables with uniform
dimensions for all features, leading to overfitting, high computational cost,
and suboptimal generalizing performance. Many techniques aim to solve this
issue by feature selection or embedding dimension search. However, these
techniques typically select a fixed subset of features or embedding dimensions
for all instances and feed all instances into one recommender model without
considering heterogeneity between items or users. This paper proposes a novel
instance-wise Hierarchical Architecture Search framework, iHAS, which automates
neural architecture search at the instance level. Specifically, iHAS
incorporates three stages: searching, clustering, and retraining. The searching
stage identifies optimal instance-wise embedding dimensions across different
field features via carefully designed Bernoulli gates with stochastic selection
and regularizers. After obtaining these dimensions, the clustering stage
divides samples into distinct groups via a deterministic selection approach of
Bernoulli gates. The retraining stage then constructs different recommender
models, each one designed with optimal dimensions for the corresponding group.
We conduct extensive experiments to evaluate the proposed iHAS on two public
benchmark datasets from a real-world recommender system. The experimental
results demonstrate the effectiveness of iHAS and its outstanding
transferability to widely-used deep recommendation models.
</p>
</div>
</dd>
<dt><a name="item14">[14]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07968" title="Abstract">arXiv:2309.07968</a> [<a href="/pdf/2309.07968" title="Download PDF">pdf</a>, <a href="/ps/2309.07968" title="Download PostScript">ps</a>, <a href="/format/2309.07968" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed formation control of end-effector of mixed planar fully- and  under-actuated manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peng%2C+Z">Zhiyu Peng</a>, 
<a href="/search/eess?searchtype=author&query=Jayawardhana%2C+B">Bayu Jayawardhana</a>, 
<a href="/search/eess?searchtype=author&query=Xin%2C+X">Xin Xin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">This paper addresses the problem of end-effector formation control for a
mixed group of two-link manipulators moving in a horizontal plane that
comprises of fully-actuated manipulators and underactuated manipulators with
only the second joint being actuated (referred to as the passive-active (PA)
manipulators). The problem is solved by extending the distributed end-effector
formation controller for the fully-actuated manipulator to the PA manipulator
moving in a horizontal plane by using its integrability. This paper presents
stability analysis of the closed-loop systems under a given necessary
condition, and we prove that the manipulators' end-effector converge to the
desired formation shape. The proposed method is validated by simulations.
</p>
</div>
</dd>
<dt><a name="item15">[15]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07970" title="Abstract">arXiv:2309.07970</a> [<a href="/pdf/2309.07970" title="Download PDF">pdf</a>, <a href="/format/2309.07970" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Language Embedded Radiance Fields for Zero-Shot Task-Oriented Grasping
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rashid%2C+A">Adam Rashid</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Satvik Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+C+M">Chung Min Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kerr%2C+J">Justin Kerr</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lawrence Chen</a>, 
<a href="/search/cs?searchtype=author&query=Kanazawa%2C+A">Angjoo Kanazawa</a>, 
<a href="/search/cs?searchtype=author&query=Goldberg%2C+K">Ken Goldberg</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> See the project website at: lerftogo.github.io
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Grasping objects by a specific part is often crucial for safety and for
executing downstream tasks. Yet, learning-based grasp planners lack this
behavior unless they are trained on specific object part data, making it a
significant challenge to scale object diversity. Instead, we propose LERF-TOGO,
Language Embedded Radiance Fields for Task-Oriented Grasping of Objects, which
uses vision-language models zero-shot to output a grasp distribution over an
object given a natural language query. To accomplish this, we first reconstruct
a LERF of the scene, which distills CLIP embeddings into a multi-scale 3D
language field queryable with text. However, LERF has no sense of objectness,
meaning its relevancy outputs often return incomplete activations over an
object which are insufficient for subsequent part queries. LERF-TOGO mitigates
this lack of spatial grouping by extracting a 3D object mask via DINO features
and then conditionally querying LERF on this mask to obtain a semantic
distribution over the object with which to rank grasps from an off-the-shelf
grasp planner. We evaluate LERF-TOGO's ability to grasp task-oriented object
parts on 31 different physical objects, and find it selects grasps on the
correct part in 81% of all trials and grasps successfully in 69%. See the
project website at: lerftogo.github.io
</p>
</div>
</dd>
<dt><a name="item16">[16]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07974" title="Abstract">arXiv:2309.07974</a> [<a href="/pdf/2309.07974" title="Download PDF">pdf</a>, <a href="/format/2309.07974" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Data Source for Reasoning Embodied Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lanchantin%2C+J">Jack Lanchantin</a>, 
<a href="/search/cs?searchtype=author&query=Sukhbaatar%2C+S">Sainbayar Sukhbaatar</a>, 
<a href="/search/cs?searchtype=author&query=Synnaeve%2C+G">Gabriel Synnaeve</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yuxuan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Srinet%2C+K">Kavya Srinet</a>, 
<a href="/search/cs?searchtype=author&query=Szlam%2C+A">Arthur Szlam</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Recent progress in using machine learning models for reasoning tasks has been
driven by novel model architectures, large-scale pre-training protocols, and
dedicated reasoning datasets for fine-tuning. In this work, to further pursue
these advances, we introduce a new data generator for machine reasoning that
integrates with an embodied agent. The generated data consists of templated
text queries and answers, matched with world-states encoded into a database.
The world-states are a result of both world dynamics and the actions of the
agent. We show the results of several baseline models on instantiations of
train sets. These include pre-trained language models fine-tuned on a
text-formatted representation of the database, and graph-structured
Transformers operating on a knowledge-graph representation of the database. We
find that these models can answer some questions about the world-state, but
struggle with others. These results hint at new research directions in
designing neural reasoning models and database representations. Code to
generate the data will be released at github.com/facebookresearch/neuralmemory
</p>
</div>
</dd>
<dt><a name="item17">[17]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07975" title="Abstract">arXiv:2309.07975</a> [<a href="/pdf/2309.07975" title="Download PDF">pdf</a>, <a href="/format/2309.07975" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Smart Helper-Aided F-RANs: Improving Delay and Reducing Fronthaul Load
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mokhtarzadeh%2C+H">Hesameddin Mokhtarzadeh</a>, 
<a href="/search/cs?searchtype=author&query=Al-Abiad%2C+M+S">Mohammed S. Al-Abiad</a>, 
<a href="/search/cs?searchtype=author&query=Hossain%2C+M+J">Md Jahangir Hossain</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Julian Cheng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">In traditional Fog-Radio Access Networks (F-RANs), enhanced remote radio
heads (eRRHs) are connected to a macro base station (MBS) through fronthaul
links. Deploying a massive number of eRRHs is not always feasible due to site
constraints and the cost of fronthaul links. This paper introduces an
innovative concept of using smart helpers (SHs) in F-RANs. These SHs do not
require fronthaul links and listen to the nearby eRRHs' communications. Then,
they smartly select and cache popular content. This capability enables SHs to
serve users with frequent on-demand service requests potentially. As such,
network operators have the flexibility to easily deploy SHs in various
scenarios, such as dense urban areas and temporary public events, to expand
their F-RANs and improve the quality of service (QoS). To study the performance
of the proposed SH-aided F-RAN, we formulate an optimization problem of
minimizing the average transmission delay that jointly optimizes cache
resources and user scheduling. To tackle the formulated problem, we develop an
innovative multi-stage algorithm that uses a reinforcement learning (RL)
framework. Various performance measures, e.g., the average transmission delay,
fronthaul load, and cache hit rate of the proposed SH-aided F-RAN are evaluated
numerically and compared with those of traditional F-RANs.
</p>
</div>
</dd>
<dt><a name="item18">[18]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07979" title="Abstract">arXiv:2309.07979</a> [<a href="/pdf/2309.07979" title="Download PDF">pdf</a>, <a href="/format/2309.07979" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast Safe Rectangular Corridor-based Online AGV Trajectory Optimization  with Obstacle Avoidance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Shaoqiang Liang</a>, 
<a href="/search/cs?searchtype=author&query=Fa%2C+S">Songyuan Fa</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yiqun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Automated Guided Vehicles (AGVs) are widely adopted in various industries due
to their efficiency and adaptability. However, safely deploying AGVs in dynamic
environments remains a significant challenge. This paper introduces an online
trajectory optimization framework, the Fast Safe Rectangular Corridor (FSRC),
designed for AGVs in obstacle-rich settings. The primary challenge is
efficiently planning trajectories that prioritize safety and collision
avoidance. To tackle this challenge, the FSRC algorithm constructs convex
regions, represented as rectangular corridors, to address obstacle avoidance
constraints within an optimal control problem. This conversion from non-convex
to box constraints improves the collision avoidance efficiency and quality.
Additionally, the Modified Visibility Graph algorithm speeds up path planning,
and a boundary discretization strategy expedites FSRC construction. The
framework also includes a dynamic obstacle avoidance strategy for real-time
adaptability. Our framework's effectiveness and superiority have been
demonstrated in experiments, particularly in computational efficiency (see Fig.
\ref{fig:case1} and \ref{fig:case23}). Compared to state-of-the-art frameworks,
our trajectory planning framework significantly enhances computational
efficiency, ranging from 1 to 2 orders of magnitude (see Table \ref{tab:res}).
Notably, the FSRC algorithm outperforms other safe convex corridor-based
methods, substantially improving computational efficiency by 1 to 2 orders of
magnitude (see Table \ref{tab:FRSC}).
</p>
</div>
</dd>
<dt><a name="item19">[19]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07980" title="Abstract">arXiv:2309.07980</a> [<a href="/pdf/2309.07980" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Identifying Concerns When Specifying Machine Learning-Enabled Systems: A  Perspective-Based Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Villamizar%2C+H">Hugo Villamizar</a>, 
<a href="/search/cs?searchtype=author&query=Kalinowski%2C+M">Marcos Kalinowski</a>, 
<a href="/search/cs?searchtype=author&query=Lopes%2C+H">Helio Lopes</a>, 
<a href="/search/cs?searchtype=author&query=Mendez%2C+D">Daniel Mendez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Engineering successful machine learning (ML)-enabled systems poses various
challenges from both a theoretical and a practical side. Among those challenges
are how to effectively address unrealistic expectations of ML capabilities from
customers, managers and even other team members, and how to connect business
value to engineering and data science activities composed by interdisciplinary
teams. In this paper, we present PerSpecML, a perspective-based approach for
specifying ML-enabled systems that helps practitioners identify which
attributes, including ML and non-ML components, are important to contribute to
the overall system's quality. The approach involves analyzing 59 concerns
related to typical tasks that practitioners face in ML projects, grouping them
into five perspectives: system objectives, user experience, infrastructure,
model, and data. Together, these perspectives serve to mediate the
communication between business owners, domain experts, designers, software and
ML engineers, and data scientists. The creation of PerSpecML involved a series
of validations conducted in different contexts: (i) in academia, (ii) with
industry representatives, and (iii) in two real industrial case studies. As a
result of the diverse validations and continuous improvements, PerSpecML stands
as a promising approach, poised to positively impact the specification of
ML-enabled systems, particularly helping to reveal key components that would
have been otherwise missed without using PerSpecML.
</p>
</div>
</dd>
<dt><a name="item20">[20]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07981" title="Abstract">arXiv:2309.07981</a> [<a href="/pdf/2309.07981" title="Download PDF">pdf</a>, <a href="/format/2309.07981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficiently Identifying Hotspots in a Spatially Varying Field with  Multiple Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suryan%2C+V">Varun Suryan</a>, 
<a href="/search/cs?searchtype=author&query=Tokekar%2C+P">Pratap Tokekar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">In this paper, we present algorithms to identify environmental hotspots using
mobile sensors. We examine two approaches: one involving a single robot and
another using multiple robots coordinated through a decentralized robot system.
We introduce an adaptive algorithm that does not require precise knowledge of
Gaussian Processes (GPs) hyperparameters, making the modeling process more
flexible. The robots operate for a pre-defined time in the environment. The
multi-robot system uses Voronoi partitioning to divide tasks and a Monte Carlo
Tree Search for optimal path planning. Our tests on synthetic and a real-world
dataset of Chlorophyll density from a Pacific Ocean sub-region suggest that
accurate estimation of GP hyperparameters may not be essential for hotspot
detection, potentially simplifying environmental monitoring tasks.
</p>
</div>
</dd>
<dt><a name="item21">[21]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07983" title="Abstract">arXiv:2309.07983</a> [<a href="/pdf/2309.07983" title="Download PDF">pdf</a>, <a href="/format/2309.07983" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker  Recognition Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Guangke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yedi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+F">Fu Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by the 31st Network and Distributed System Security (NDSS) Symposium, 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Membership inference attacks allow adversaries to determine whether a
particular example was contained in the model's training dataset. While
previous works have confirmed the feasibility of such attacks in various
applications, none has focused on speaker recognition (SR), a promising
voice-based biometric recognition technique. In this work, we propose SLMIA-SR,
the first membership inference attack tailored to SR. In contrast to
conventional example-level attack, our attack features speaker-level membership
inference, i.e., determining if any voices of a given speaker, either the same
as or different from the given inference voices, have been involved in the
training of a model. It is particularly useful and practical since the training
and inference voices are usually distinct, and it is also meaningful
considering the open-set nature of SR, namely, the recognition speakers were
often not present in the training data. We utilize intra-closeness and
inter-farness, two training objectives of SR, to characterize the differences
between training and non-training speakers and quantify them with two groups of
features driven by carefully-established feature engineering to mount the
attack. To improve the generalizability of our attack, we propose a novel
mixing ratio training strategy to train attack models. To enhance the attack
performance, we introduce voice chunk splitting to cope with the limited number
of inference voices and propose to train attack models dependent on the number
of inference voices. Our attack is versatile and can work in both white-box and
black-box scenarios. Additionally, we propose two novel techniques to reduce
the number of black-box queries while maintaining the attack performance.
Extensive experiments demonstrate the effectiveness of SLMIA-SR.
</p>
</div>
</dd>
<dt><a name="item22">[22]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07984" title="Abstract">arXiv:2309.07984</a> [<a href="/pdf/2309.07984" title="Download PDF">pdf</a>, <a href="/format/2309.07984" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inclusive-PIM: Hardware-Software Co-design for Broad Acceleration on  Commercial PIM Architectures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Alsop%2C+J">Johnathan Alsop</a>, 
<a href="/search/cs?searchtype=author&query=Aga%2C+S">Shaizeen Aga</a>, 
<a href="/search/cs?searchtype=author&query=Ibrahim%2C+M">Mohamed Ibrahim</a>, 
<a href="/search/cs?searchtype=author&query=Islam%2C+M">Mahzabeen Islam</a>, 
<a href="/search/cs?searchtype=author&query=Mccrabb%2C+A">Andrew Mccrabb</a>, 
<a href="/search/cs?searchtype=author&query=Jayasena%2C+N">Nuwan Jayasena</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>

</div>
<p class="mathjax">Continual demand for memory bandwidth has made it worthwhile for memory
vendors to reassess processing in memory (PIM), which enables higher bandwidth
by placing compute units in/near-memory. As such, memory vendors have recently
proposed commercially viable PIM designs. However, these proposals are largely
driven by the needs of (a narrow set of) machine learning (ML) primitives.
While such proposals are reasonable given the the growing importance of ML, as
memory is a pervasive component, %in this work, we make there is a case for a
more inclusive PIM design that can accelerate primitives across domains.
<br />In this work, we ascertain the capabilities of commercial PIM proposals to
accelerate various primitives across domains. We first begin with outlining a
set of characteristics, termed PIM-amenability-test, which aid in assessing if
a given primitive is likely to be accelerated by PIM. Next, we apply this test
to primitives under study to ascertain efficient data-placement and
orchestration to map the primitives to underlying PIM architecture. We observe
here that, even though primitives under study are largely PIM-amenable,
existing commercial PIM proposals do not realize their performance potential
for these primitives. To address this, we identify bottlenecks that arise in
PIM execution and propose hardware and software optimizations which stand to
broaden the acceleration reach of commercial PIM designs (improving average PIM
speedups from 1.12x to 2.49x relative to a GPU baseline). Overall, while we
believe emerging commercial PIM proposals add a necessary and complementary
design point in the application acceleration space, hardware-software co-design
is necessary to deliver their benefits broadly.
</p>
</div>
</dd>
<dt><a name="item23">[23]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07986" title="Abstract">arXiv:2309.07986</a> [<a href="/pdf/2309.07986" title="Download PDF">pdf</a>, <a href="/format/2309.07986" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viewpoint Textual Inversion: Unleashing Novel View Synthesis with  Pretrained 2D Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Burgess%2C+J">James Burgess</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kuan-Chieh Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yeung%2C+S">Serena Yeung</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page: <a href="https://jmhb0.github.io/viewneti/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Text-to-image diffusion models understand spatial relationship between
objects, but do they represent the true 3D structure of the world from only 2D
supervision? We demonstrate that yes, 3D knowledge is encoded in 2D image
diffusion models like Stable Diffusion, and we show that this structure can be
exploited for 3D vision tasks. Our method, Viewpoint Neural Textual Inversion
(ViewNeTI), controls the 3D viewpoint of objects in generated images from
frozen diffusion models. We train a small neural mapper to take camera
viewpoint parameters and predict text encoder latents; the latents then
condition the diffusion generation process to produce images with the desired
camera viewpoint.
<br />ViewNeTI naturally addresses Novel View Synthesis (NVS). By leveraging the
frozen diffusion model as a prior, we can solve NVS with very few input views;
we can even do single-view novel view synthesis. Our single-view NVS
predictions have good semantic details and photorealism compared to prior
methods. Our approach is well suited for modeling the uncertainty inherent in
sparse 3D vision problems because it can efficiently generate diverse samples.
Our view-control mechanism is general, and can even change the camera view in
images generated by user-defined prompts.
</p>
</div>
</dd>
<dt><a name="item24">[24]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07988" title="Abstract">arXiv:2309.07988</a> [<a href="/pdf/2309.07988" title="Download PDF">pdf</a>, <a href="/format/2309.07988" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Folding Attention: Memory and Power Optimization for On-Device  Transformer-based Streaming Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+L">Liangzhen Lai</a>, 
<a href="/search/cs?searchtype=author&query=Shangguan%2C+Y">Yuan Shangguan</a>, 
<a href="/search/cs?searchtype=author&query=Iandola%2C+F+N">Forrest N. Iandola</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+E">Ernie Chang</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+Y">Yangyang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chandra%2C+V">Vikas Chandra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Hardware Architecture (cs.AR); Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Transformer-based models excel in speech recognition. Existing efforts to
optimize Transformer inference, typically for long-context applications, center
on simplifying attention score calculations. However, streaming speech
recognition models usually process a limited number of tokens each time, making
attention score calculation less of a bottleneck. Instead, the bottleneck lies
in the linear projection layers of multi-head attention and feedforward
networks, constituting a substantial portion of the model size and contributing
significantly to computation, memory, and power usage.
<br />To address this bottleneck, we propose folding attention, a technique
targeting these linear layers, significantly reducing model size and improving
memory and power efficiency. Experiments on on-device Transformer-based
streaming speech recognition models show that folding attention reduces model
size (and corresponding memory consumption) by up to 24% and power consumption
by up to 23%, all without compromising model accuracy or computation overhead.
</p>
</div>
</dd>
<dt><a name="item25">[25]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07990" title="Abstract">arXiv:2309.07990</a> [<a href="/pdf/2309.07990" title="Download PDF">pdf</a>, <a href="/format/2309.07990" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Contextual Information for Effective Entity Salience  Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhowmik%2C+R">Rajarshi Bhowmik</a>, 
<a href="/search/cs?searchtype=author&query=Ponza%2C+M">Marco Ponza</a>, 
<a href="/search/cs?searchtype=author&query=Tendle%2C+A">Atharva Tendle</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Anant Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+R">Rebecca Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xingyu Lu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Q">Qian Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Preotiuc-Pietro%2C+D">Daniel Preotiuc-Pietro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In text documents such as news articles, the content and key events usually
revolve around a subset of all the entities mentioned in a document. These
entities, often deemed as salient entities, provide useful cues of the
aboutness of a document to a reader. Identifying the salience of entities was
found helpful in several downstream applications such as search, ranking, and
entity-centric summarization, among others. Prior work on salient entity
detection mainly focused on machine learning models that require heavy feature
engineering. We show that fine-tuning medium-sized language models with a
cross-encoder style architecture yields substantial performance gains over
feature engineering approaches. To this end, we conduct a comprehensive
benchmarking of four publicly available datasets using models representative of
the medium-sized pre-trained language model family. Additionally, we show that
zero-shot prompting of instruction-tuned language models yields inferior
results, indicating the task's uniqueness and complexity.
</p>
</div>
</dd>
<dt><a name="item26">[26]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07992" title="Abstract">arXiv:2309.07992</a> [<a href="/pdf/2309.07992" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Automated Machine Learning Approach for Detecting Anomalous Peak  Patterns in Time Series Data from a Research Watershed in the Northeastern  United States Critical Zone
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Haq%2C+I+U">Ijaz Ul Haq</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+B+S">Byung Suk Lee</a>, 
<a href="/search/cs?searchtype=author&query=Rizzo%2C+D+M">Donna M. Rizzo</a>, 
<a href="/search/cs?searchtype=author&query=Perdrial%2C+J+N">Julia N Perdrial</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This document is the results of the research project funded by the National Science Foundation. Preprint submitted to Engineering Applications of Artificial IntelligenceSeptember 14, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents an automated machine learning framework designed to
assist hydrologists in detecting anomalies in time series data generated by
sensors in a research watershed in the northeastern United States critical
zone. The framework specifically focuses on identifying peak-pattern anomalies,
which may arise from sensor malfunctions or natural phenomena. However, the use
of classification methods for anomaly detection poses challenges, such as the
requirement for labeled data as ground truth and the selection of the most
suitable deep learning model for the given task and dataset. To address these
challenges, our framework generates labeled datasets by injecting synthetic
peak patterns into synthetically generated time series data and incorporates an
automated hyperparameter optimization mechanism. This mechanism generates an
optimized model instance with the best architectural and training parameters
from a pool of five selected models, namely Temporal Convolutional Network
(TCN), InceptionTime, MiniRocket, Residual Networks (ResNet), and Long
Short-Term Memory (LSTM). The selection is based on the user's preferences
regarding anomaly detection accuracy and computational cost. The framework
employs Time-series Generative Adversarial Networks (TimeGAN) as the synthetic
dataset generator. The generated model instances are evaluated using a
combination of accuracy and computational cost metrics, including training time
and memory, during the anomaly detection process. Performance evaluation of the
framework was conducted using a dataset from a watershed, demonstrating
consistent selection of the most fitting model instance that satisfies the
user's preferences.
</p>
</div>
</dd>
<dt><a name="item27">[27]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07993" title="Abstract">arXiv:2309.07993</a> [<a href="/pdf/2309.07993" title="Download PDF">pdf</a>, <a href="/format/2309.07993" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bipedal Walking on Constrained Footholds with MPC Footstep Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Acosta%2C+B">Brian Acosta</a>, 
<a href="/search/cs?searchtype=author&query=Posa%2C+M">Michael Posa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Bipedal robots promise the ability to traverse rough terrain quickly and
efficiently, and indeed, humanoid robots can now use strong ankles and careful
foot placement to traverse discontinuous terrain. However, more agile
underactuated bipeds have small feet and weak ankles, and must constantly
adjust their planned footstep position to maintain balance. We introduce a new
model-predictive footstep controller which jointly optimizes over the robot's
discrete choice of stepping surface, impending footstep position sequence,
ankle torque in the sagittal plane, and center of mass trajectory, to track a
velocity command. The controller is formulated as a single Mixed Integer
Quadratic Program (MIQP) which is solved at 50-200 Hz, depending on terrain
complexity. We implement a state of the art real-time elevation mapping and
convex terrain decomposition framework to inform the controller of its
surroundings in the form on convex polygons representing steppable terrain. We
investigate the capabilities and challenges of our approach through hardware
experiments on the underactuated biped Cassie.
</p>
</div>
</dd>
<dt><a name="item28">[28]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07994" title="Abstract">arXiv:2309.07994</a> [<a href="/pdf/2309.07994" title="Download PDF">pdf</a>, <a href="/format/2309.07994" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Test Case Generation and Test Oracle Support for Testing CPSs using  Hybrid Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sadri-Moshkenani%2C+Z">Zahra Sadri-Moshkenani</a>, 
<a href="/search/cs?searchtype=author&query=Bradley%2C+J">Justin Bradley</a>, 
<a href="/search/cs?searchtype=author&query=Rothermel%2C+G">Gregg Rothermel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, Submitted to IEEE Transaction on Software Engineering on 9/14/2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>; Robotics (cs.RO); Systems and Control (eess.SY)

</div>
<p class="mathjax">Cyber-Physical Systems (CPSs) play a central role in the behavior of a wide
range of autonomous physical systems such as medical devices, autonomous
vehicles, and smart homes, many of which are safety-critical. CPSs are often
specified iteratively as a sequence of models at different levels that can be
tested via simulation systems at early stages of their development cycle. One
such model is a hybrid automaton; these are used frequently for CPS
applications and have the advantage of encapsulating both continuous and
discrete CPS behaviors. When testing CPSs, engineers can take advantage of
these models to generate test cases that target both types of these behaviors.
Moreover, since these models are constructed early in the development process
for CPSs, they allow test cases to be generated early in that process for those
CPSs, even before simulation models of the CPSs have been designed. One
challenge when testing CPSs is that these systems may operate differently even
under an identically applied test scenario. In such cases, we cannot employ
test oracles that use predetermined deterministic behaviors; instead, test
oracles should consider sets of desired behaviors in order to determine whether
the CPS has behaved appropriately. In this paper we present a test case
generation technique, HYTEST, that generates test cases based on hybrid models,
accompanied by appropriate test oracles, for use in testing CPSs early in their
development cycle. To evaluate the effectiveness and efficiency of HYTEST, we
conducted an empirical study in which we applied the technique to several CPSs
and measured its ability to detect faults in those CPSs and the amount of time
required to perform the testing process. The results of the study show that
HYTEST was able to detect faults more effectively and efficiently than the
baseline techniques we compare it to.
</p>
</div>
</dd>
<dt><a name="item29">[29]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07996" title="Abstract">arXiv:2309.07996</a> [<a href="/pdf/2309.07996" title="Download PDF">pdf</a>, <a href="/format/2309.07996" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient online update of model predictive control in embedded systems  using first-order methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gracia%2C+V">Victor Gracia</a>, 
<a href="/search/eess?searchtype=author&query=Krupa%2C+P">Pablo Krupa</a>, 
<a href="/search/eess?searchtype=author&query=Alamo%2C+T">Teodoro Alamo</a>, 
<a href="/search/eess?searchtype=author&query=Limon%2C+D">Daniel Limon</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> (6 pages, 2 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">Model Predictive Control (MPC) is typically characterized for being
computationally demanding, as it requires solving optimization problems online;
a particularly relevant point when considering its implementation in embedded
systems. To reduce the computational burden of the optimization algorithm, most
solvers perform as many offline operations as possible, typically performing
the computation and factorization of its expensive matrices offline and then
storing them in the embedded system. This improves the efficiency of the
solver, with the disadvantage that online changes on some of the ingredients of
the MPC formulation require performing these expensive computations online.
This article presents an efficient algorithm for the factorization of the key
matrix used in several first-order optimization methods applied to linear MPC
formulations, allowing its prediction model and cost function matrices to be
updated online at the expense of a small computational cost. We show results
comparing the proposed approach with other solvers from the literature applied
to a linear time-varying system.
</p>
</div>
</dd>
<dt><a name="item30">[30]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07998" title="Abstract">arXiv:2309.07998</a> [<a href="/pdf/2309.07998" title="Download PDF">pdf</a>, <a href="/format/2309.07998" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue  Evaluation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Finch%2C+S+E">Sarah E. Finch</a>, 
<a href="/search/cs?searchtype=author&query=Finch%2C+J+D">James D. Finch</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J+D">Jinho D. Choi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Human evaluation has been widely accepted as the standard for evaluating
chat-oriented dialogue systems. However, there is a significant variation in
previous work regarding who gets recruited as evaluators. Evaluator groups such
as domain experts, university students, and professional annotators have been
used to assess and compare dialogue systems, although it is unclear to what
extent the choice of an evaluator group can affect results. This paper analyzes
the evaluator group impact on dialogue system evaluation by testing 4
state-of-the-art dialogue systems using 4 distinct evaluator groups. Our
analysis reveals a robustness towards evaluator groups for Likert evaluations
that is not seen for Pairwise, with only minor differences observed when
changing evaluator groups. Furthermore, two notable limitations to this
robustness are observed, which reveal discrepancies between evaluators with
different levels of chatbot expertise and indicate that evaluator objectivity
is beneficial for certain dialogue metrics.
</p>
</div>
</dd>
<dt><a name="item31">[31]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08002" title="Abstract">arXiv:2309.08002</a> [<a href="/pdf/2309.08002" title="Download PDF">pdf</a>, <a href="/format/2309.08002" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HIVE: Scalable Hardware-Firmware Co-Verification using Scenario-based  Decomposition and Automated Hint Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jayasena%2C+A">Aruna Jayasena</a>, 
<a href="/search/cs?searchtype=author&query=Mishra%2C+P">Prabhat Mishra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Symbolic Computation (cs.SC)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Hardware-firmware co-verification is critical to design trustworthy systems.
While formal methods can provide verification guarantees, due to the complexity
of firmware and hardware, it can lead to state space explosion. There are
promising avenues to reduce the state space during firmware verification
through manual abstraction of hardware or manual generation of hints. Manual
development of abstraction or hints requires domain expertise and can be
time-consuming and error-prone, leading to incorrect proofs or inaccurate
results. In this paper, we effectively combine the scalability of
simulation-based validation and the completeness of formal verification. Our
proposed approach is applicable to actual firmware and hardware implementations
without requiring any manual intervention during formal model generation or
hint extraction. To reduce the state space complexity, we utilize both static
module-level analysis and dynamic execution of verification scenarios to
automatically generate system-level hints. These hints guide the underlying
solver to perform scalable equivalence checking using proofs. The extracted
hints are validated against the implementation before using them in the proofs.
Experimental evaluation on RISC-V based systems demonstrates that our proposed
framework is scalable due to scenario-based decomposition and automated hint
extraction. Moreover, our fully automated framework can identify complex bugs
in actual firmware-hardware implementations.
</p>
</div>
</dd>
<dt><a name="item32">[32]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08003" title="Abstract">arXiv:2309.08003</a> [<a href="/pdf/2309.08003" title="Download PDF">pdf</a>, <a href="/ps/2309.08003" title="Download PostScript">ps</a>, <a href="/format/2309.08003" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalized Decomposition of Multivariate Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Varley%2C+T+F">Thomas F. Varley</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 39 references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Since its introduction, the partial information decomposition (PID) has
emerged as a powerful, information-theoretic technique useful for studying the
structure of (potentially higher-order) interactions in complex systems.
Despite its utility, the applicability of the PID is restricted by the need to
assign elements as either inputs or targets, as well as the specific structure
of the mutual information itself. Here, we introduce a generalized information
decomposition that relaxes the source/target distinction while still satisfying
the basic intuitions about information. This approach is based on the
decomposition of the Kullback-Leibler divergence, and consequently allows for
the analysis of any information gained when updating from an arbitrary prior to
an arbitrary posterior. Consequently, any information-theoretic measure that
can be written in as a Kullback-Leibler divergence admits a decomposition in
the style of Williams and Beer, including the total correlation, the
negentropy, and the mutual information as special cases. In this paper, we
explore how the generalized information decomposition can reveal novel insights
into existing measures, as well as the nature of higher-order synergies. We
show that synergistic information is intimately related to the well-known
Tononi-Sporns-Edelman (TSE) complexity, and that synergistic information
requires a similar integration/segregation balance as a high TSE complexity.
Finally, we end with a discussion of how this approach fits into other attempts
to generalize the PID and the possibilities for empirical applications.
</p>
</div>
</dd>
<dt><a name="item33">[33]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08006" title="Abstract">arXiv:2309.08006</a> [<a href="/pdf/2309.08006" title="Download PDF">pdf</a>, <a href="/format/2309.08006" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kinship Verification from rPPG using 1DCNN Attention networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoting Wu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+X">Xiaoyi Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lili Liu</a>, 
<a href="/search/cs?searchtype=author&query=Casado%2C+C+%C3%81">Constantino &#xc1;lvarez Casado</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+M+B">Miguel Bordallo L&#xf3;pez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Facial kinship verification aims at automatically determining whether two
subjects have a kinship relation. It has been widely studied from different
modalities, such as faces, voices, gait, and smiling expressions. However, the
potential of bio-signals, such as remote Photoplethysmography (rPPG) extracted
from facial videos, remains largely unexplored in the kinship verification
problem. In this paper, we investigate for the first time the usage of the rPPG
signal for kinship verification. Specifically, we proposed a one-dimensional
Convolutional Neural Network (1DCNN) with a 1DCNN-Attention module and
contrastive loss to learn the kinship similarity from rPPGs. The network takes
multiple rPPG signals extracted from various facial Regions of Interest (ROIs)
as inputs. Additionally, the 1DCNN attention module is designed to learn and
capture the discriminative kin features from feature embeddings. Finally, the
proposed method is evaluated on the UvANEMO Smile Database from different kin
relations, showing the usefulness of rPPG signals in verifying kinship.
</p>
</div>
</dd>
<dt><a name="item34">[34]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08008" title="Abstract">arXiv:2309.08008</a> [<a href="/pdf/2309.08008" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Empirical Evaluation of Prompting Strategies for Large Language  Models in Zero-Shot Clinical Natural Language Processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sivarajkumar%2C+S">Sonish Sivarajkumar</a>, 
<a href="/search/cs?searchtype=author&query=Kelley%2C+M">Mark Kelley</a>, 
<a href="/search/cs?searchtype=author&query=Samolyk-Mazzanti%2C+A">Alyssa Samolyk-Mazzanti</a>, 
<a href="/search/cs?searchtype=author&query=Visweswaran%2C+S">Shyam Visweswaran</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanshan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large language models (LLMs) have shown remarkable capabilities in Natural
Language Processing (NLP), especially in domains where labeled data is scarce
or expensive, such as clinical domain. However, to unlock the clinical
knowledge hidden in these LLMs, we need to design effective prompts that can
guide them to perform specific clinical NLP tasks without any task-specific
training data. This is known as in-context learning, which is an art and
science that requires understanding the strengths and weaknesses of different
LLMs and prompt engineering approaches. In this paper, we present a
comprehensive and systematic experimental study on prompt engineering for five
clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence
Extraction, Coreference Resolution, Medication Status Extraction, and
Medication Attribute Extraction. We assessed the prompts proposed in recent
literature, including simple prefix, simple cloze, chain of thought, and
anticipatory prompts, and introduced two new types of prompts, namely heuristic
prompting and ensemble prompting. We evaluated the performance of these prompts
on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted
zero-shot prompting with few-shot prompting, and provide novel insights and
guidelines for prompt engineering for LLMs in clinical NLP. To the best of our
knowledge, this is one of the first works on the empirical evaluation of
different prompt engineering approaches for clinical NLP in this era of
generative AI, and we hope that it will inspire and inform future research in
this area.
</p>
</div>
</dd>
<dt><a name="item35">[35]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08009" title="Abstract">arXiv:2309.08009</a> [<a href="/pdf/2309.08009" title="Download PDF">pdf</a>, <a href="/format/2309.08009" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Measuring the Quality of Text-to-Video Model Outputs: Metrics and  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chivileva%2C+I">Iya Chivileva</a>, 
<a href="/search/cs?searchtype=author&query=Lynch%2C+P">Philip Lynch</a>, 
<a href="/search/cs?searchtype=author&query=Ward%2C+T+E">Tomas E. Ward</a>, 
<a href="/search/cs?searchtype=author&query=Smeaton%2C+A+F">Alan F. Smeaton</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Evaluating the quality of videos generated from text-to-video (T2V) models is
important if they are to produce plausible outputs that convince a viewer of
their authenticity. We examine some of the metrics used in this area and
highlight their limitations. The paper presents a dataset of more than 1,000
generated videos from 5 very recent T2V models on which some of those commonly
used quality metrics are applied. We also include extensive human quality
evaluations on those videos, allowing the relative strengths and weaknesses of
metrics, including human assessment, to be compared. The contribution is an
assessment of commonly used quality metrics, and a comparison of their
performances and the performance of human evaluations on an open dataset of T2V
videos. Our conclusion is that naturalness and semantic matching with the text
prompt used to generate the T2V output are important but there is no single
measure to capture these subtleties in assessing T2V model output.
</p>
</div>
</dd>
<dt><a name="item36">[36]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08010" title="Abstract">arXiv:2309.08010</a> [<a href="/pdf/2309.08010" title="Download PDF">pdf</a>, <a href="/format/2309.08010" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Malicious Cyber Activity Detection Using Zigzag Persistence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Myers%2C+A">Audun Myers</a>, 
<a href="/search/cs?searchtype=author&query=Bittner%2C+A">Alyson Bittner</a>, 
<a href="/search/cs?searchtype=author&query=Aksoy%2C+S">Sinan Aksoy</a>, 
<a href="/search/cs?searchtype=author&query=Best%2C+D+M">Daniel M. Best</a>, 
<a href="/search/cs?searchtype=author&query=Henselman-Petrusek%2C+G">Gregory Henselman-Petrusek</a>, 
<a href="/search/cs?searchtype=author&query=Jenne%2C+H">Helen Jenne</a>, 
<a href="/search/cs?searchtype=author&query=Joslyn%2C+C">Cliff Joslyn</a>, 
<a href="/search/cs?searchtype=author&query=Kay%2C+B">Bill Kay</a>, 
<a href="/search/cs?searchtype=author&query=Seppala%2C+G">Garret Seppala</a>, 
<a href="/search/cs?searchtype=author&query=Young%2C+S+J">Stephen J. Young</a>, 
<a href="/search/cs?searchtype=author&query=Purvine%2C+E">Emilie Purvine</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">In this study we synthesize zigzag persistence from topological data analysis
with autoencoder-based approaches to detect malicious cyber activity and derive
analytic insights. Cybersecurity aims to safeguard computers, networks, and
servers from various forms of malicious attacks, including network damage, data
theft, and activity monitoring. Here we focus on the detection of malicious
activity using log data. To do this we consider the dynamics of the data by
exploring the changing topology of a hypergraph representation gaining insights
into the underlying activity. Hypergraphs provide a natural representation of
cyber log data by capturing complex interactions between processes. To study
the changing topology we use zigzag persistence which captures how topological
features persist at multiple dimensions over time. We observe that the
resulting barcodes represent malicious activity differently than benign
activity. To automate this detection we implement an autoencoder trained on a
vectorization of the resulting zigzag persistence barcodes. Our experimental
results demonstrate the effectiveness of the autoencoder in detecting malicious
activity in comparison to standard summary statistics. Overall, this study
highlights the potential of zigzag persistence and its combination with
temporal hypergraphs for analyzing cybersecurity log data and detecting
malicious behavior.
</p>
</div>
</dd>
<dt><a name="item37">[37]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08011" title="Abstract">arXiv:2309.08011</a> [<a href="/pdf/2309.08011" title="Download PDF">pdf</a>, <a href="/format/2309.08011" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Subspace Framework for ${\mathcal L}_\infty$ Model Reduction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mengi%2C+E">Emre Mengi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">We consider the problem of locating a nearest descriptor system of prescribed
reduced order to a descriptor system with large order with respect to the
${\mathcal L}_\infty$ norm. Widely employed approaches such as the balanced
truncation and best Hankel norm approximation for this ${\mathcal L}_\infty$
model reduction problem are usually expensive and yield solutions that are not
optimal, not even locally. We propose approaches based on the minimization of
the ${\mathcal L}_\infty$ objective by means of smooth optimization techniques.
As we illustrate, direct applications of smooth optimization techniques are not
feasible, since the optimization techniques converge at best at a linear rate
requiring too many evaluations of the costly ${\mathcal L}_\infty$-norm
objective to be practical. We replace the original large-scale system with a
system of smaller order that interpolates the original system at points on the
imaginary axis, and minimize the ${\mathcal L}_\infty$ objective after this
replacement. The smaller system is refined by interpolating at additional
imaginary points determined based on the local minimizer of the ${\mathcal
L}_\infty$ objective, and the optimization is repeated. We argue the framework
converges at a quadratic rate under smoothness and nondegeneracy assumptions,
and describe how asymptotic stability constraints on the reduced system sought
can be incorporated into our approach. The numerical experiments on benchmark
examples illustrate that the approach leads to locally optimal solutions to the
${\mathcal L}_\infty$ model reduction problem, and the convergence occurs
quickly for descriptors systems of order a few ten thousands.
</p>
</div>
</dd>
<dt><a name="item38">[38]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08018" title="Abstract">arXiv:2309.08018</a> [<a href="/pdf/2309.08018" title="Download PDF">pdf</a>, <a href="/format/2309.08018" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Effect of Smoothing on the Interpretation of Time Series Data: A  COVID-19 Case Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stein%2C+O">Oded Stein</a>, 
<a href="/search/cs?searchtype=author&query=Jacobson%2C+A">Alec Jacobson</a>, 
<a href="/search/cs?searchtype=author&query=Chevalier%2C+F">Fanny Chevalier</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> supplemental data: <a href="http://odedstein.com/projects/perception-of-smoothing/">this http URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">We conduct a controlled crowd-sourced experiment of COVID-19 case data
visualization to study if and how different plotting methods, time windows, and
the nature of the data influence people's interpretation of real-world COVID-19
data and people's prediction of how the data will evolve in the future. We find
that a 7-day backward average smoothed line successfully reduces the
distraction of periodic data patterns compared to just unsmoothed bar data.
Additionally, we find that the presence of a smoothed line helps readers form a
consensus on how the data will evolve in the future. We also find that the
fixed 7-day smoothing window size leads to different amounts of perceived
recurring patterns in the data depending on the time period plotted -- this
suggests that varying the smoothing window size together with the plot window
size might be a promising strategy to influence the perception of spurious
patterns in the plot.
</p>
</div>
</dd>
<dt><a name="item39">[39]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08019" title="Abstract">arXiv:2309.08019</a> [<a href="/pdf/2309.08019" title="Download PDF">pdf</a>, <a href="/format/2309.08019" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CRYPTO-MINE: Cryptanalysis via Mutual Information Neural Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B+D">Benjamin D. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Vasudevan%2C+V+A">Vipindev Adat Vasudevan</a>, 
<a href="/search/cs?searchtype=author&query=Woo%2C+J">Jongchan Woo</a>, 
<a href="/search/cs?searchtype=author&query=Cohen%2C+A">Alejandro Cohen</a>, 
<a href="/search/cs?searchtype=author&query=D%27Oliveira%2C+R+G+L">Rafael G. L. D&#x27;Oliveira</a>, 
<a href="/search/cs?searchtype=author&query=Stahlbuhk%2C+T">Thomas Stahlbuhk</a>, 
<a href="/search/cs?searchtype=author&query=M%C3%A9dard%2C+M">Muriel M&#xe9;dard</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Information Theory (cs.IT); Machine Learning (cs.LG)

</div>
<p class="mathjax">The use of Mutual Information (MI) as a measure to evaluate the efficiency of
cryptosystems has an extensive history. However, estimating MI between unknown
random variables in a high-dimensional space is challenging. Recent advances in
machine learning have enabled progress in estimating MI using neural networks.
This work presents a novel application of MI estimation in the field of
cryptography. We propose applying this methodology directly to estimate the MI
between plaintext and ciphertext in a chosen plaintext attack. The leaked
information, if any, from the encryption could potentially be exploited by
adversaries to compromise the computational security of the cryptosystem. We
evaluate the efficiency of our approach by empirically analyzing multiple
encryption schemes and baseline approaches. Furthermore, we extend the analysis
to novel network coding-based cryptosystems that provide individual secrecy and
study the relationship between information leakage and input distribution.
</p>
</div>
</dd>
<dt><a name="item40">[40]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08020" title="Abstract">arXiv:2309.08020</a> [<a href="/pdf/2309.08020" title="Download PDF">pdf</a>, <a href="/format/2309.08020" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal-aware Hierarchical Mask Classification for Video Semantic  Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=An%2C+Z">Zhaochong An</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+G">Guolei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Zongwei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+H">Hao Tang</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modern approaches have proved the huge potential of addressing semantic
segmentation as a mask classification task which is widely used in
instance-level segmentation. This paradigm trains models by assigning part of
object queries to ground truths via conventional one-to-one matching. However,
we observe that the popular video semantic segmentation (VSS) dataset has
limited categories per video, meaning less than 10% of queries could be matched
to receive meaningful gradient updates during VSS training. This inefficiency
limits the full expressive potential of all queries.Thus, we present a novel
solution THE-Mask for VSS, which introduces temporal-aware hierarchical object
queries for the first time. Specifically, we propose to use a simple two-round
matching mechanism to involve more queries matched with minimal cost during
training while without any extra cost during inference. To support our
more-to-one assignment, in terms of the matching results, we further design a
hierarchical loss to train queries with their corresponding hierarchy of
primary or secondary. Moreover, to effectively capture temporal information
across frames, we propose a temporal aggregation decoder that fits seamlessly
into the mask-classification paradigm for VSS. Utilizing temporal-sensitive
multi-level queries, our method achieves state-of-the-art performance on the
latest challenging VSS benchmark VSPW without bells and whistles.
</p>
</div>
</dd>
<dt><a name="item41">[41]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08021" title="Abstract">arXiv:2309.08021</a> [<a href="/pdf/2309.08021" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Vision-based Analysis of Driver Activity and Driving Performance Under  the Influence of Alcohol
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>, 
<a href="/search/cs?searchtype=author&query=Gopalkrishnan%2C+A">Akshay Gopalkrishnan</a>, 
<a href="/search/cs?searchtype=author&query=Mandadi%2C+S">Sumega Mandadi</a>, 
<a href="/search/cs?searchtype=author&query=Gunaratne%2C+P">Pujitha Gunaratne</a>, 
<a href="/search/cs?searchtype=author&query=Trivedi%2C+M+M">Mohan M. Trivedi</a>, 
<a href="/search/cs?searchtype=author&query=Marcotte%2C+T+D">Thomas D. Marcotte</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">About 30% of all traffic crash fatalities in the United States involve drunk
drivers, making the prevention of drunk driving paramount to vehicle safety in
the US and other locations which have a high prevalence of driving while under
the influence of alcohol. Driving impairment can be monitored through active
use of sensors (when drivers are asked to engage in providing breath samples to
a vehicle instrument or when pulled over by a police officer), but a more
passive and robust mechanism of sensing may allow for wider adoption and
benefit of intelligent systems that reduce drunk driving accidents. This could
assist in identifying impaired drivers before they drive, or early in the
driving process (before a crash or detection by law enforcement). In this
research, we introduce a study which adopts a multi-modal ensemble of visual,
thermal, audio, and chemical sensors to (1) examine the impact of acute alcohol
administration on driving performance in a driving simulator, and (2) identify
data-driven methods for detecting driving under the influence of alcohol. We
describe computer vision and machine learning models for analyzing the driver's
face in thermal imagery, and introduce a pipeline for training models on data
collected from drivers with a range of breath-alcohol content levels, including
discussion of relevant machine learning phenomena which can help in future
experiment design for related studies.
</p>
</div>
</dd>
<dt><a name="item42">[42]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08022" title="Abstract">arXiv:2309.08022</a> [<a href="/pdf/2309.08022" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Visually Impaired Individuals: A Novel Use of Apple Live  Photos and Android Motion Photos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khoshsirat%2C+S">Seyedalireza Khoshsirat</a>, 
<a href="/search/cs?searchtype=author&query=Kambhamettu%2C+C">Chandra Kambhamettu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Numerous applications have been developed to assist visually impaired
individuals that employ a machine learning unit to process visual input.
However, a critical challenge with these applications is the sub-optimal
quality of images captured by the users. Given the complexity of operating a
camera for visually impaired individuals, we advocate for the use of Apple Live
Photos and Android Motion Photos technologies. In this study, we introduce a
straightforward methodology to evaluate and contrast the efficacy of
Live/Motion Photos against traditional image-based approaches. Our findings
reveal that both Live Photos and Motion Photos outperform single-frame images
in common visual assisting tasks, specifically in object classification and
VideoQA. We validate our results through extensive experiments on the ORBIT
dataset, which consists of videos collected by visually impaired individuals.
Furthermore, we conduct a series of ablation studies to delve deeper into the
impact of deblurring and longer temporal crops.
</p>
</div>
</dd>
<dt><a name="item43">[43]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08027" title="Abstract">arXiv:2309.08027</a> [<a href="/pdf/2309.08027" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Comparative Assessment of Markov Models and Recurrent Neural Networks  for Jazz Music Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Conrad Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Greer%2C+R">Ross Greer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">As generative models have risen in popularity, a domain that has risen
alongside is generative models for music. Our study aims to compare the
performance of a simple Markov chain model and a recurrent neural network (RNN)
model, two popular models for sequence generating tasks, in jazz music
improvisation. While music, especially jazz, remains subjective in telling
whether a composition is "good" or "bad", we aim to quantify our results using
metrics of groove pattern similarity and pitch class histogram entropy. We
trained both models using transcriptions of jazz blues choruses from
professional jazz players, and also fed musical jazz seeds to help give our
model some context in beginning the generation. Our results show that the RNN
outperforms the Markov model on both of our metrics, indicating better rhythmic
consistency and tonal stability in the generated music. Through the use of
music21 library, we tokenized our jazz dataset into pitches and durations that
our model could interpret and train on. Our findings contribute to the growing
field of AI-generated music, highlighting the important use of metrics to
assess generation quality. Future work includes expanding the dataset of MIDI
files to a larger scale, conducting human surveys for subjective evaluations,
and incorporating additional metrics to address the challenge of subjectivity
in music evaluation. Our study provides valuable insight into the use of
recurrent neural networks for sequential based tasks like generating music.
</p>
</div>
</dd>
<dt><a name="item44">[44]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08033" title="Abstract">arXiv:2309.08033</a> [<a href="/pdf/2309.08033" title="Download PDF">pdf</a>, <a href="/format/2309.08033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Depth Estimation from a Single Optical Encoded Image using a Learned  Colored-Coded Aperture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lopez%2C+J">Jhon Lopez</a>, 
<a href="/search/cs?searchtype=author&query=Vargas%2C+E">Edwin Vargas</a>, 
<a href="/search/cs?searchtype=author&query=Arguello%2C+H">Henry Arguello</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Depth estimation from a single image of a conventional camera is a
challenging task since depth cues are lost during the acquisition process.
State-of-the-art approaches improve the discrimination between different depths
by introducing a binary-coded aperture (CA) in the lens aperture that generates
different coded blur patterns at different depths. Color-coded apertures (CCA)
can also produce color misalignment in the captured image which can be utilized
to estimate disparity. Leveraging advances in deep learning, more recent works
have explored the data-driven design of a diffractive optical element (DOE) for
encoding depth information through chromatic aberrations. However, compared
with binary CA or CCA, DOEs are more expensive to fabricate and require
high-precision devices. Different from previous CCA-based approaches that
employ few basic colors, in this work we propose a CCA with a greater number of
color filters and richer spectral information to optically encode relevant
depth information in a single snapshot. Furthermore, we propose to jointly
learn the color-coded aperture (CCA) pattern and a convolutional neural network
(CNN) to retrieve depth information by using an end-to-end optimization
approach. We demonstrate through different experiments on three different data
sets that the designed color-encoding has the potential to remove depth
ambiguities and provides better depth estimates compared to state-of-the-art
approaches. Additionally, we build a low-cost prototype of our CCA using a
photographic film and validate the proposed approach in real scenarios.
</p>
</div>
</dd>
<dt><a name="item45">[45]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08035" title="Abstract">arXiv:2309.08035</a> [<a href="/pdf/2309.08035" title="Download PDF">pdf</a>, <a href="/format/2309.08035" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interpretability-Aware Vision Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qiang%2C+Y">Yao Qiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chengyin Li</a>, 
<a href="/search/cs?searchtype=author&query=Khanduri%2C+P">Prashant Khanduri</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongxiao Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 4 figures, 5 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Vision Transformers (ViTs) have become prominent models for solving various
vision tasks. However, the interpretability of ViTs has not kept pace with
their promising performance. While there has been a surge of interest in
developing {\it post hoc} solutions to explain ViTs' outputs, these methods do
not generalize to different downstream tasks and various transformer
architectures. Furthermore, if ViTs are not properly trained with the given
data and do not prioritize the region of interest, the {\it post hoc} methods
would be less effective. Instead of developing another {\it post hoc} approach,
we introduce a novel training procedure that inherently enhances model
interpretability. Our interpretability-aware ViT (IA-ViT) draws inspiration
from a fresh insight: both the class patch and image patches consistently
generate predicted distributions and attention maps. IA-ViT is composed of a
feature extractor, a predictor, and an interpreter, which are trained jointly
with an interpretability-aware training objective. Consequently, the
interpreter simulates the behavior of the predictor and provides a faithful
explanation through its single-head self-attention mechanism. Our comprehensive
experimental results demonstrate the effectiveness of IA-ViT in several image
classification tasks, with both qualitative and quantitative evaluations of
model performance and interpretability. Source code is available from:
https://github.com/qiangyao1988/IA-ViT.
</p>
</div>
</dd>
<dt><a name="item46">[46]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08036" title="Abstract">arXiv:2309.08036</a> [<a href="/pdf/2309.08036" title="Download PDF">pdf</a>, <a href="/format/2309.08036" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BEA: Revisiting anchor-based object detection DNN using Budding Ensemble  Architecture
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qutub%2C+S+S">Syed Sha Qutub</a>, 
<a href="/search/cs?searchtype=author&query=Kose%2C+N">Neslihan Kose</a>, 
<a href="/search/cs?searchtype=author&query=Rosales%2C+R">Rafael Rosales</a>, 
<a href="/search/cs?searchtype=author&query=Paulitsch%2C+M">Michael Paulitsch</a>, 
<a href="/search/cs?searchtype=author&query=Hagn%2C+K">Korbinian Hagn</a>, 
<a href="/search/cs?searchtype=author&query=Geissler%2C+F">Florian Geissler</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yang Peng</a>, 
<a href="/search/cs?searchtype=author&query=Hinz%2C+G">Gereon Hinz</a>, 
<a href="/search/cs?searchtype=author&query=Knoll%2C+A">Alois Knoll</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 5 pages supplementary material. Accepted at BMVC2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper introduces the Budding Ensemble Architecture (BEA), a novel
reduced ensemble architecture for anchor-based object detection models. Object
detection models are crucial in vision-based tasks, particularly in autonomous
systems. They should provide precise bounding box detections while also
calibrating their predicted confidence scores, leading to higher-quality
uncertainty estimates. However, current models may make erroneous decisions due
to false positives receiving high scores or true positives being discarded due
to low scores. BEA aims to address these issues. The proposed loss functions in
BEA improve the confidence score calibration and lower the uncertainty error,
which results in a better distinction of true and false positives and,
eventually, higher accuracy of the object detection models. Both Base-YOLOv3
and SSD models were enhanced using the BEA method and its proposed loss
functions. The BEA on Base-YOLOv3 trained on the KITTI dataset results in a 6%
and 3.7% increase in mAP and AP50, respectively. Utilizing a well-balanced
uncertainty estimation threshold to discard samples in real-time even leads to
a 9.6% higher AP50 than its base model. This is attributed to a 40% increase in
the area under the AP50-based retention curve used to measure the quality of
calibration of confidence scores. Furthermore, BEA-YOLOV3 trained on KITTI
provides superior out-of-distribution detection on Citypersons, BDD100K, and
COCO datasets compared to the ensembles and vanilla models of YOLOv3 and
Gaussian-YOLOv3.
</p>
</div>
</dd>
<dt><a name="item47">[47]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08037" title="Abstract">arXiv:2309.08037</a> [<a href="/pdf/2309.08037" title="Download PDF">pdf</a>, <a href="/format/2309.08037" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gain and Phase: Decentralized Stability Conditions for Power  Electronics-Dominated Power Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+L">Linbin Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+D">Dan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiongfei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xin%2C+H">Huanhai Xin</a>, 
<a href="/search/eess?searchtype=author&query=Ju%2C+P">Ping Ju</a>, 
<a href="/search/eess?searchtype=author&query=Johansson%2C+K+H">Karl H. Johansson</a>, 
<a href="/search/eess?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper proposes decentralized stability conditions for multi-converter
systems based on the combination of the small gain theorem and the small phase
theorem. Instead of directly computing the closed-loop dynamics, e.g.,
eigenvalues of the state-space matrix, or using the generalized Nyquist
stability criterion, the proposed stability conditions are more scalable and
computationally lighter, which aim at evaluating the closed-loop system
stability by comparing the individual converter dynamics with the network
dynamics in a decentralized and open-loop manner. Moreover, our approach can
handle heterogeneous converters' dynamics and is suitable to analyze
large-scale multi-converter systems that contain grid-following (GFL) and
grid-forming (GFM) converters. Compared with other decentralized stability
conditions, e.g., passivity-based stability conditions, the proposed conditions
are significantly less conservative and can be generally satisfied in practice
across the whole frequency range.
</p>
</div>
</dd>
<dt><a name="item48">[48]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08040" title="Abstract">arXiv:2309.08040</a> [<a href="/pdf/2309.08040" title="Download PDF">pdf</a>, <a href="/format/2309.08040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gradient based Grasp Pose Optimization on a NeRF that Approximates Grasp  Success
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%B3ti%2C+G">Gergely S&#xf3;ti</a>, 
<a href="/search/cs?searchtype=author&query=Hein%2C+B">Bj&#xf6;rn Hein</a>, 
<a href="/search/cs?searchtype=author&query=Wurll%2C+C">Christian Wurll</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Current robotic grasping methods often rely on estimating the pose of the
target object, explicitly predicting grasp poses, or implicitly estimating
grasp success probabilities. In this work, we propose a novel approach that
directly maps gripper poses to their corresponding grasp success values,
without considering objectness. Specifically, we leverage a Neural Radiance
Field (NeRF) architecture to learn a scene representation and use it to train a
grasp success estimator that maps each pose in the robot's task space to a
grasp success value. We employ this learned estimator to tune its inputs, i.e.,
grasp poses, by gradient-based optimization to obtain successful grasp poses.
Contrary to other NeRF-based methods which enhance existing grasp pose
estimation approaches by relying on NeRF's rendering capabilities or directly
estimate grasp poses in a discretized space using NeRF's scene representation
capabilities, our approach uniquely sidesteps both the need for rendering and
the limitation of discretization. We demonstrate the effectiveness of our
approach on four simulated 3DoF (Degree of Freedom) robotic grasping tasks and
show that it can generalize to novel objects. Our best model achieves an
average translation error of 3mm from valid grasp poses. This work opens the
door for future research to apply our approach to higher DoF grasps and
real-world scenarios.
</p>
</div>
</dd>
<dt><a name="item49">[49]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08042" title="Abstract">arXiv:2309.08042</a> [<a href="/pdf/2309.08042" title="Download PDF">pdf</a>, <a href="/format/2309.08042" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Large-scale Building Attribute Mapping using Crowdsourced  Images: Scene Text Recognition on Flickr and Problems to be Solved
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yao Sun</a>, 
<a href="/search/cs?searchtype=author&query=Kruspe%2C+A">Anna Kruspe</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+L">Liqiu Meng</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+Y">Yifan Tian</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+E+J">Eike J Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Auer%2C+S">Stefan Auer</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Crowdsourced platforms provide huge amounts of street-view images that
contain valuable building information. This work addresses the challenges in
applying Scene Text Recognition (STR) in crowdsourced street-view images for
building attribute mapping. We use Flickr images, particularly examining texts
on building facades. A Berlin Flickr dataset is created, and pre-trained STR
models are used for text detection and recognition. Manual checking on a subset
of STR-recognized images demonstrates high accuracy. We examined the
correlation between STR results and building functions, and analysed instances
where texts were recognized on residential buildings but not on commercial
ones. Further investigation revealed significant challenges associated with
this task, including small text regions in street-view images, the absence of
ground truth labels, and mismatches in buildings in Flickr images and building
footprints in OpenStreetMap (OSM). To develop city-wide mapping beyond urban
hotspot locations, we suggest differentiating the scenarios where STR proves
effective while developing appropriate algorithms or bringing in additional
data for handling other cases. Furthermore, interdisciplinary collaboration
should be undertaken to understand the motivation behind building photography
and labeling. The STR-on-Flickr results are publicly available at
https://github.com/ya0-sun/STR-Berlin.
</p>
</div>
</dd>
<dt><a name="item50">[50]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08043" title="Abstract">arXiv:2309.08043</a> [<a href="/pdf/2309.08043" title="Download PDF">pdf</a>, <a href="/format/2309.08043" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Prediction Feature Assignment in the Heckman Selection Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+H">Huy Mai</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Under missing-not-at-random (MNAR) sample selection bias, the performance of
a prediction model is often degraded. This paper focuses on one classic
instance of MNAR sample selection bias where a subset of samples have
non-randomly missing outcomes. The Heckman selection model and its variants
have commonly been used to handle this type of sample selection bias. The
Heckman model uses two separate equations to model the prediction and selection
of samples, where the selection features include all prediction features. When
using the Heckman model, the prediction features must be properly chosen from
the set of selection features. However, choosing the proper prediction features
is a challenging task for the Heckman model. This is especially the case when
the number of selection features is large. Existing approaches that use the
Heckman model often provide a manually chosen set of prediction features. In
this paper, we propose Heckman-FA as a novel data-driven framework for
obtaining prediction features for the Heckman model. Heckman-FA first trains an
assignment function that determines whether or not a selection feature is
assigned as a prediction feature. Using the parameters of the trained function,
the framework extracts a suitable set of prediction features based on the
goodness-of-fit of the prediction model given the chosen prediction features
and the correlation between noise terms of the prediction and selection
equations. Experimental results on real-world datasets show that Heckman-FA
produces a robust regression model under MNAR sample selection bias.
</p>
</div>
</dd>
<dt><a name="item51">[51]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08045" title="Abstract">arXiv:2309.08045</a> [<a href="/pdf/2309.08045" title="Download PDF">pdf</a>, <a href="/format/2309.08045" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Traveling Waves Encode the Recent Past and Enhance Sequence Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Keller%2C+T+A">T. Anderson Keller</a>, 
<a href="/search/cs?searchtype=author&query=Muller%2C+L">Lyle Muller</a>, 
<a href="/search/cs?searchtype=author&query=Sejnowski%2C+T">Terrence Sejnowski</a>, 
<a href="/search/cs?searchtype=author&query=Welling%2C+M">Max Welling</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Traveling waves of neural activity have been observed throughout the brain at
a diversity of regions and scales; however, their precise computational role is
still debated. One physically grounded hypothesis suggests that the cortical
sheet may act like a wave-field capable of storing a short-term memory of
sequential stimuli through induced waves traveling across the cortical surface.
To date, however, the computational implications of this idea have remained
hypothetical due to the lack of a simple recurrent neural network architecture
capable of exhibiting such waves. In this work, we introduce a model to fill
this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both
connectivity constraints and initialization play a crucial role in the
emergence of wave-like dynamics. We then empirically show how such an
architecture indeed efficiently encodes the recent past through a suite of
synthetic memory tasks where wRNNs learn faster and perform significantly
better than wave-free counterparts. Finally, we explore the implications of
this memory storage system on more complex sequence modeling tasks such as
sequential image classification and find that wave-based models not only again
outperform comparable wave-free RNNs while using significantly fewer
parameters, but additionally perform comparably to more complex gated
architectures such as LSTMs and GRUs. We conclude with a discussion of the
implications of these results for both neuroscience and machine learning.
</p>
</div>
</dd>
<dt><a name="item52">[52]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08047" title="Abstract">arXiv:2309.08047</a> [<a href="/pdf/2309.08047" title="Download PDF">pdf</a>, <a href="/format/2309.08047" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Gender Bias in News Summarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Steen%2C+J">Julius Steen</a>, 
<a href="/search/cs?searchtype=author&query=Markert%2C+K">Katja Markert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Summarization is an important application of large language models (LLMs).
Most previous evaluation of summarization models has focused on their
performance in content selection, grammaticality and coherence. However, it is
well known that LLMs reproduce and reinforce harmful social biases. This raises
the question: Do these biases affect model outputs in a relatively constrained
setting like summarization?
<br />To help answer this question, we first motivate and introduce a number of
definitions for biased behaviours in summarization models, along with practical
measures to quantify them. Since we find biases inherent to the input document
can confound our analysis, we additionally propose a method to generate input
documents with carefully controlled demographic attributes. This allows us to
sidestep this issue, while still working with somewhat realistic input
documents.
<br />Finally, we apply our measures to summaries generated by both purpose-built
summarization models and general purpose chat models. We find that content
selection in single document summarization seems to be largely unaffected by
bias, while hallucinations exhibit evidence of biases propagating to generated
summaries.
</p>
</div>
</dd>
<dt><a name="item53">[53]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08048" title="Abstract">arXiv:2309.08048</a> [<a href="/pdf/2309.08048" title="Download PDF">pdf</a>, <a href="/format/2309.08048" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Padding Aware Neurons
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Garcia-Gasulla%2C+D">Dario Garcia-Gasulla</a>, 
<a href="/search/cs?searchtype=author&query=Gimenez-Abalos%2C+V">Victor Gimenez-Abalos</a>, 
<a href="/search/cs?searchtype=author&query=Martin-Torres%2C+P">Pablo Martin-Torres</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> In 4th Visual Inductive Priors for Data-Efficient Deep Learning Workshop, ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Convolutional layers are a fundamental component of most image-related
models. These layers often implement by default a static padding policy (\eg
zero padding), to control the scale of the internal representations, and to
allow kernel activations centered on the border regions. In this work we
identify Padding Aware Neurons (PANs), a type of filter that is found in most
(if not all) convolutional models trained with static padding. PANs focus on
the characterization and recognition of input border location, introducing a
spatial inductive bias into the model (e.g., how close to the input's border a
pattern typically is). We propose a method to identify PANs through their
activations, and explore their presence in several popular pre-trained models,
finding PANs on all models explored, from dozens to hundreds. We discuss and
illustrate different types of PANs, their kernels and behaviour. To understand
their relevance, we test their impact on model performance, and find padding
and PANs to induce strong and characteristic biases in the data. Finally, we
discuss whether or not PANs are desirable, as well as the potential side
effects of their presence in the context of model performance, generalisation,
efficiency and safety.
</p>
</div>
</dd>
<dt><a name="item54">[54]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08049" title="Abstract">arXiv:2309.08049</a> [<a href="/pdf/2309.08049" title="Download PDF">pdf</a>, <a href="/format/2309.08049" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VoicePAT: An Efficient Open-source Evaluation Toolkit for Voice Privacy  Research
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Meyer%2C+S">Sarina Meyer</a>, 
<a href="/search/cs?searchtype=author&query=Miao%2C+X">Xiaoxiao Miao</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+N+T">Ngoc Thang Vu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to OJSP-ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Speaker anonymization is the task of modifying a speech recording such that
the original speaker cannot be identified anymore. Since the first Voice
Privacy Challenge in 2020, along with the release of a framework, the
popularity of this research topic is continually increasing. However, the
comparison and combination of different anonymization approaches remains
challenging due to the complexity of evaluation and the absence of
user-friendly research frameworks. We therefore propose an efficient speaker
anonymization and evaluation framework based on a modular and easily extendable
structure, almost fully in Python. The framework facilitates the orchestration
of several anonymization approaches in parallel and allows for interfacing
between different techniques. Furthermore, we propose modifications to common
evaluation methods which make the evaluation more powerful and reduces their
computation time by 65 to 95\%, depending on the metric. Our code is fully open
source.
</p>
</div>
</dd>
<dt><a name="item55">[55]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08050" title="Abstract">arXiv:2309.08050</a> [<a href="/pdf/2309.08050" title="Download PDF">pdf</a>, <a href="/format/2309.08050" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Control Barrier Functions for Sampled-Data Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Oruganti%2C+P+S">Pradeep Sharma Oruganti</a>, 
<a href="/search/eess?searchtype=author&query=Naghizadeh%2C+P">Parinaz Naghizadeh</a>, 
<a href="/search/eess?searchtype=author&query=Ahmed%2C+Q">Qadeer Ahmed</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the problem of safe control of sampled-data systems under
bounded disturbance and measurement errors with piecewise-constant controllers.
To achieve this, we first propose the High-Order Doubly Robust Control Barrier
Function (HO-DRCBF) for continuous-time systems where the safety enforcing
constraint is of relative degree 1 or higher. We then extend this formulation
to sampled-data systems with piecewise-constant controllers by bounding the
evolution of the system state over the sampling period given a state estimate
at the beginning of the sampling period. We demonstrate the proposed approach
on a kinematic obstacle avoidance problem for wheeled robots using a unicycle
model. We verify that with the proposed approach, the system does not violate
the safety constraints in the presence of bounded disturbance and measurement
errors.
</p>
</div>
</dd>
<dt><a name="item56">[56]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08051" title="Abstract">arXiv:2309.08051</a> [<a href="/pdf/2309.08051" title="Download PDF">pdf</a>, <a href="/format/2309.08051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Retrieval-Augmented Text-to-Audio Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+Q">Qiushi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Despite recent progress in text-to-audio (TTA) generation, we show that the
state-of-the-art models, such as AudioLDM, trained on datasets with an
imbalanced class distribution, such as AudioCaps, are biased in their
generation performance. Specifically, they excel in generating common audio
classes while underperforming in the rare ones, thus degrading the overall
generation performance. We refer to this problem as long-tailed text-to-audio
generation. To address this issue, we propose a simple retrieval-augmented
approach for TTA models. Specifically, given an input text prompt, we first
leverage a Contrastive Language Audio Pretraining (CLAP) model to retrieve
relevant text-audio pairs. The features of the retrieved audio-text data are
then used as additional conditions to guide the learning of TTA models. We
enhance AudioLDM with our proposed approach and denote the resulting augmented
system as Re-AudioLDM. On the AudioCaps dataset, Re-AudioLDM achieves a
state-of-the-art Frechet Audio Distance (FAD) of 1.37, outperforming the
existing approaches by a large margin. Furthermore, we show that Re-AudioLDM
can generate realistic audio for complex scenes, rare audio classes, and even
unseen audio types, indicating its potential in TTA tasks.
</p>
</div>
</dd>
<dt><a name="item57">[57]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08052" title="Abstract">arXiv:2309.08052</a> [<a href="/pdf/2309.08052" title="Download PDF">pdf</a>, <a href="/format/2309.08052" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian approach to breaking things: efficiently predicting and  repairing failure modes via sampling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dawson%2C+C">Charles Dawson</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+C">Chuchu Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear at the 2023 Conference on Robot Learning (CoRL)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Before autonomous systems can be deployed in safety-critical applications, we
must be able to understand and verify the safety of these systems. For cases
where the risk or cost of real-world testing is prohibitive, we propose a
simulation-based framework for a) predicting ways in which an autonomous system
is likely to fail and b) automatically adjusting the system's design to
preemptively mitigate those failures. We frame this problem through the lens of
approximate Bayesian inference and use differentiable simulation for efficient
failure case prediction and repair. We apply our approach on a range of
robotics and control problems, including optimizing search patterns for robot
swarms and reducing the severity of outages in power transmission networks.
Compared to optimization-based falsification techniques, our method predicts a
more diverse, representative set of failure modes, and we also find that our
use of differentiable simulation yields solutions that have up to 10x lower
cost and requires up to 2x fewer iterations to converge relative to
gradient-free techniques. Code and videos can be found at
https://mit-realm.github.io/breaking-things/
</p>
</div>
</dd>
<dt><a name="item58">[58]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08054" title="Abstract">arXiv:2309.08054</a> [<a href="/pdf/2309.08054" title="Download PDF">pdf</a>, <a href="/format/2309.08054" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Permutation Capacity Region of Adder Multiple-Access Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+W">William Lu</a>, 
<a href="/search/cs?searchtype=author&query=Makur%2C+A">Anuran Makur</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 42 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Statistics Theory (math.ST)

</div>
<p class="mathjax">Point-to-point permutation channels are useful models of communication
networks and biological storage mechanisms and have received theoretical
attention in recent years. Propelled by relevant advances in this area, we
analyze the permutation adder multiple-access channel (PAMAC) in this work. In
the PAMAC network model, $d$ senders communicate with a single receiver by
transmitting $p$-ary codewords through an adder multiple-access channel whose
output is subsequently shuffled by a random permutation block. We define a
suitable notion of permutation capacity region $\mathcal{C}_\mathsf{perm}$ for
this model, and establish that $\mathcal{C}_\mathsf{perm}$ is the simplex
consisting of all rate $d$-tuples that sum to $d(p - 1) / 2$ or less. We
achieve this sum-rate by encoding messages as i.i.d. samples from categorical
distributions with carefully chosen parameters, and we derive an inner bound on
$\mathcal{C}_\mathsf{perm}$ by extending the concept of time sharing to the
permutation channel setting. Our proof notably illuminates various connections
between mixed-radix numerical systems and coding schemes for multiple-access
channels. Furthermore, we derive an alternative inner bound on
$\mathcal{C}_\mathsf{perm}$ for the binary PAMAC by analyzing the root
stability of the probability generating function of the adder's output
distribution. Using eigenvalue perturbation results, we obtain error bounds on
the spectrum of the probability generating function's companion matrix,
providing quantitative estimates of decoding performance. Finally, we obtain a
converse bound on $\mathcal{C}_\mathsf{perm}$ matching our achievability
result.
</p>
</div>
</dd>
<dt><a name="item59">[59]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08058" title="Abstract">arXiv:2309.08058</a> [<a href="/pdf/2309.08058" title="Download PDF">pdf</a>, <a href="/format/2309.08058" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing the Adversarial Facet of Software Debloating
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+D">Do-Men Su</a>, 
<a href="/search/cs?searchtype=author&query=Alhanahnah%2C+M">Mohannad Alhanahnah</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Software Engineering (cs.SE)

</div>
<p class="mathjax">Software debloating techniques are applied to craft a specialized version of
the program based on the user's requirements and remove irrelevant code
accordingly. The debloated programs presumably maintain better performance and
reduce the attack surface in contrast to the original programs. This work
unleashes the effectiveness of applying software debloating techniques on the
robustness of machine learning systems in the malware classification domain. We
empirically study how an adversarial can leverage software debloating
techniques to mislead machine learning malware classification models. We apply
software debloating techniques to generate adversarial examples and demonstrate
these adversarial examples can reduce the detection rate of VirusTotal. Our
study opens new directions for research into adversarial machine learning not
only in malware detection/classification but also in other software domains.
</p>
</div>
</dd>
<dt><a name="item60">[60]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08066" title="Abstract">arXiv:2309.08066</a> [<a href="/pdf/2309.08066" title="Download PDF">pdf</a>, <a href="/format/2309.08066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Morphologically-Aware Consensus Computation via Heuristics-based  IterATive Optimization (MACCHIatO)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hamzaoui%2C+D">Dimitri Hamzaoui</a>, 
<a href="/search/cs?searchtype=author&query=Montagne%2C+S">Sarah Montagne</a>, 
<a href="/search/cs?searchtype=author&query=Renard-Penna%2C+R">Rapha&#xeb;le Renard-Penna</a>, 
<a href="/search/cs?searchtype=author&query=Ayache%2C+N">Nicholas Ayache</a>, 
<a href="/search/cs?searchtype=author&query=Delingette%2C+H">Herv&#xe9; Delingette</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) <a href="https://melba-journal.org/2023:013">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Machine.Learning.for.Biomedical.Imaging. 2 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
<p class="mathjax">The extraction of consensus segmentations from several binary or
probabilistic masks is important to solve various tasks such as the analysis of
inter-rater variability or the fusion of several neural network outputs. One of
the most widely used methods to obtain such a consensus segmentation is the
STAPLE algorithm. In this paper, we first demonstrate that the output of that
algorithm is heavily impacted by the background size of images and the choice
of the prior. We then propose a new method to construct a binary or a
probabilistic consensus segmentation based on the Fr\'{e}chet means of
carefully chosen distances which makes it totally independent of the image
background size. We provide a heuristic approach to optimize this criterion
such that a voxel's class is fully determined by its voxel-wise distance to the
different masks, the connected component it belongs to and the group of raters
who segmented it. We compared extensively our method on several datasets with
the STAPLE method and the naive segmentation averaging method, showing that it
leads to binary consensus masks of intermediate size between Majority Voting
and STAPLE and to different posterior probabilities than Mask Averaging and
STAPLE methods. Our code is available at
https://gitlab.inria.fr/dhamzaou/jaccardmap .
</p>
</div>
</dd>
<dt><a name="item61">[61]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08069" title="Abstract">arXiv:2309.08069</a> [<a href="/pdf/2309.08069" title="Download PDF">pdf</a>, <a href="/format/2309.08069" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of  Media Bias and Framing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vallejo%2C+G">Gisela Vallejo</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Frermann%2C+L">Lea Frermann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The manifestation and effect of bias in news reporting have been central
topics in the social sciences for decades, and have received increasing
attention in the NLP community recently. While NLP can help to scale up
analyses or contribute automatic procedures to investigate the impact of biased
news in society, we argue that methodologies that are currently dominant fall
short of addressing the complex questions and effects addressed in theoretical
media studies. In this survey paper, we review social science approaches and
draw a comparison with typical task formulations, methods, and evaluation
metrics used in the analysis of media bias in NLP. We discuss open questions
and suggest possible directions to close identified gaps between theory and
predictive models, and their evaluation. These include model transparency,
considering document-external information, and cross-document reasoning rather
than single-label assignment.
</p>
</div>
</dd>
<dt><a name="item62">[62]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08070" title="Abstract">arXiv:2309.08070</a> [<a href="/pdf/2309.08070" title="Download PDF">pdf</a>, <a href="/ps/2309.08070" title="Download PostScript">ps</a>, <a href="/format/2309.08070" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploration into Optimal State Estimation with Event-triggered  Communication
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bian%2C+X">Xiaolei Bian</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Huimin Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X+R">X. Rong Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper deals with the problem of remote estimation of the state of a
discrete-time stochastic linear system observed by a sensor with computational
capacity to calculate local estimates. We design an event-triggered
communication (ETC) scheme and a remote state estimator to optimally calibrate
the tradeoff between system performance and limited communication resources.
The novel communication scheme is the time-varying thresholding version for the
cumulative innovation-driven communication scheme in [1], and its transmission
probability is given. We derive the corresponding remote minimum mean square
error (MMSE) estimator and present a tight upper bound for its MSE matrices. We
also show that by employing a couple of weak assumptions, the optimality
problem becomes (asymptotically) exact and can be addressed in an Markov
Decision Process (MDP) framework, which delivers optimal policy and cost in an
algorithmic procedure. The simulation results illustrate the effectiveness of
our approach.
</p>
</div>
</dd>
<dt><a name="item63">[63]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08072" title="Abstract">arXiv:2309.08072</a> [<a href="/pdf/2309.08072" title="Download PDF">pdf</a>, <a href="/format/2309.08072" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SSL-Net: A Synergistic Spectral and Learning-based Network for Efficient  Bird Sound Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yiyuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaichen Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Trigoni%2C+N">Niki Trigoni</a>, 
<a href="/search/cs?searchtype=author&query=Markham%2C+A">Andrew Markham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Efficient and accurate bird sound classification is of important for ecology,
habitat protection and scientific research, as it plays a central role in
monitoring the distribution and abundance of species. However, prevailing
methods typically demand extensively labeled audio datasets and have highly
customized frameworks, imposing substantial computational and annotation loads.
In this study, we present an efficient and general framework called SSL-Net,
which combines spectral and learned features to identify different bird sounds.
Encouraging empirical results gleaned from a standard field-collected bird
audio dataset validate the efficacy of our method in extracting features
efficiently and achieving heightened performance in bird sound classification,
even when working with limited sample sizes. Furthermore, we present three
feature fusion strategies, aiding engineers and researchers in their selection
through quantitative analysis.
</p>
</div>
</dd>
<dt><a name="item64">[64]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08075" title="Abstract">arXiv:2309.08075</a> [<a href="/pdf/2309.08075" title="Download PDF">pdf</a>, <a href="/format/2309.08075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Social media polarization reflects shifting political alliances in  Pakistan
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baqir%2C+A">Anees Baqir</a>, 
<a href="/search/cs?searchtype=author&query=Galeazzi%2C+A">Alessandro Galeazzi</a>, 
<a href="/search/cs?searchtype=author&query=Drocco%2C+A">Andrea Drocco</a>, 
<a href="/search/cs?searchtype=author&query=Zollo%2C+F">Fabiana Zollo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">The rise of ideological divides in public discourse has received considerable
attention in recent years. However, much of this research has been concentrated
on Western democratic nations, leaving other regions largely unexplored. Here,
we delve into the political landscape of Pakistan, a nation marked by intricate
political dynamics and persistent turbulence. Spanning from 2018 to 2022, our
analysis of Twitter data allows us to capture pivotal shifts and developments
in Pakistan's political arena. By examining interactions and content generated
by politicians affiliated with major political parties, we reveal a consistent
and active presence of politicians on Twitter, with opposition parties
exhibiting particularly robust engagement. We explore the alignment of party
audiences, highlighting a notable convergence among opposition factions over
time. Our analysis also uncovers significant shifts in political affiliations,
including the transition of politicians to the opposition alliance.
Quantitatively, we assess evolving interaction patterns, showcasing the
prevalence of homophilic connections while identifying a growing
interconnection among audiences of opposition parties. Our study, by accurately
reflecting shifts in the political landscape, underscores the reliability of
our methodology and social media data as a valuable tool for monitoring
political polarization and providing a nuanced understanding of macro-level
trends and individual-level transformations.
</p>
</div>
</dd>
<dt><a name="item65">[65]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08077" title="Abstract">arXiv:2309.08077</a> [<a href="/pdf/2309.08077" title="Download PDF">pdf</a>, <a href="/format/2309.08077" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supervised Stochastic Neighbor Embedding Using Contrastive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yi Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Stochastic neighbor embedding (SNE) methods $t$-SNE, UMAP are two most
popular dimensionality reduction methods for data visualization. Contrastive
learning, especially self-supervised contrastive learning (SSCL), has showed
great success in embedding features from unlabeled data. The conceptual
connection between SNE and SSCL has been exploited. In this work, within the
scope of preserving neighboring information of a dataset, we extend the
self-supervised contrastive approach to the fully-supervised setting, allowing
us to effectively leverage label information. Clusters of samples belonging to
the same class are pulled together in low-dimensional embedding space, while
simultaneously pushing apart clusters of samples from different classes.
</p>
</div>
</dd>
<dt><a name="item66">[66]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08079" title="Abstract">arXiv:2309.08079</a> [<a href="/pdf/2309.08079" title="Download PDF">pdf</a>, <a href="/format/2309.08079" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MPCGPU: Real-Time Nonlinear Model Predictive Control through  Preconditioned Conjugate Gradient on the GPU
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Adabag%2C+E">Emre Adabag</a>, 
<a href="/search/cs?searchtype=author&query=Atal%2C+M">Miloni Atal</a>, 
<a href="/search/cs?searchtype=author&query=Gerard%2C+W">William Gerard</a>, 
<a href="/search/cs?searchtype=author&query=Plancher%2C+B">Brian Plancher</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">Nonlinear Model Predictive Control (NMPC) is a state-of-the-art approach for
locomotion and manipulation which leverages trajectory optimization at each
control step. While the performance of this approach is computationally
bounded, implementations of direct trajectory optimization that use iterative
methods to solve the underlying moderately-large and sparse linear systems, are
a natural fit for parallel hardware acceleration. In this work, we introduce
MPCGPU, a GPU-accelerated, real-time NMPC solver that leverages an accelerated
preconditioned conjugate gradient (PCG) linear system solver at its core. We
show that MPCGPU increases the scalability and real-time performance of NMPC,
solving larger problems, at faster rates. In particular, for tracking tasks
using the Kuka IIWA manipulator, MPCGPU is able to scale to kilohertz control
rates with trajectories as long as 512 knot points. This is driven by a custom
PCG solver which outperforms state-of-the-art, CPU-based, linear system solvers
by at least 10x for a majority of solves and 3.6x on average.
</p>
</div>
</dd>
<dt><a name="item67">[67]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08086" title="Abstract">arXiv:2309.08086</a> [<a href="/pdf/2309.08086" title="Download PDF">pdf</a>, <a href="/format/2309.08086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fast and Accurate Deep Loop Closing and Relocalization for Reliable  LiDAR SLAM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+C">Chenghao Shi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xieyuanli Chen</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+J">Junhao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+B">Bin Dai</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huimin Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages 10 figures 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Loop closing and relocalization are crucial techniques to establish reliable
and robust long-term SLAM by addressing pose estimation drift and degeneration.
This article begins by formulating loop closing and relocalization within a
unified framework. Then, we propose a novel multi-head network LCR-Net to
tackle both tasks effectively. It exploits novel feature extraction and
pose-aware attention mechanism to precisely estimate similarities and 6-DoF
poses between pairs of LiDAR scans. In the end, we integrate our LCR-Net into a
SLAM system and achieve robust and accurate online LiDAR SLAM in outdoor
driving environments. We thoroughly evaluate our LCR-Net through three setups
derived from loop closing and relocalization, including candidate retrieval,
closed-loop point cloud registration, and continuous relocalization using
multiple datasets. The results demonstrate that LCR-Net excels in all three
tasks, surpassing the state-of-the-art methods and exhibiting a remarkable
generalization ability. Notably, our LCR-Net outperforms baseline methods
without using a time-consuming robust pose estimator, rendering it suitable for
online SLAM applications. To our best knowledge, the integration of LCR-Net
yields the first LiDAR SLAM with the capability of deep loop closing and
relocalization. The implementation of our methods will be made open-source.
</p>
</div>
</dd>
<dt><a name="item68">[68]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08087" title="Abstract">arXiv:2309.08087</a> [<a href="/pdf/2309.08087" title="Download PDF">pdf</a>, <a href="/format/2309.08087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> hear-your-action: human action recognition by ultrasound active sensing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tanigawa%2C+R">Risako Tanigawa</a>, 
<a href="/search/cs?searchtype=author&query=Ishii%2C+Y">Yasunori Ishii</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Action recognition is a key technology for many industrial applications.
Methods using visual information such as images are very popular. However,
privacy issues prevent widespread usage due to the inclusion of private
information, such as visible faces and scene backgrounds, which are not
necessary for recognizing user action. In this paper, we propose a
privacy-preserving action recognition by ultrasound active sensing. As action
recognition from ultrasound active sensing in a non-invasive manner is not well
investigated, we create a new dataset for action recognition and conduct a
comparison of features for classification. We calculated feature values by
focusing on the temporal variation of the amplitude of ultrasound reflected
waves and performed classification using a support vector machine and VGG for
eight fundamental action classes. We confirmed that our method achieved an
accuracy of 97.9% when trained and evaluated on the same person and in the same
environment. Additionally, our method achieved an accuracy of 89.5% even when
trained and evaluated on different people. We also report the analyses of
accuracies in various conditions and limitations.
</p>
</div>
</dd>
<dt><a name="item69">[69]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08088" title="Abstract">arXiv:2309.08088</a> [<a href="/pdf/2309.08088" title="Download PDF">pdf</a>, <a href="/ps/2309.08088" title="Download PostScript">ps</a>, <a href="/format/2309.08088" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Interactive Model Fusion-Based GM-PHD Filter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+J">Jiacheng He</a>, 
<a href="/search/eess?searchtype=author&query=Zhong%2C+S">Shan Zhong</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+B">Bei Peng</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+G">Gang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qizhen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In multi-target tracking (MTT), non-Gaussian measurement noise from sensors
can diminish the performance of the Gaussian-assumed Gaussian mixture
probability hypothesis density (GM-PHD) filter. In this paper, an approach that
transforms the MTT problem under non-Gaussian conditions into an MTT problem
under Gaussian conditions is developed. Specifically, measurement noise with a
non-Gaussian distribution is modeled as a weighted sum of different Gaussian
distributions. Subsequently, the GM-PHD filter is applied to compute the
multi-target states under these distinct Gaussian distributions. Finally, an
interactive multi-model framework is employed to fuse the diverse multi-target
state information into a unified synthesis. The effectiveness of the proposed
approach is validated through the simulation results.
</p>
</div>
</dd>
<dt><a name="item70">[70]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08093" title="Abstract">arXiv:2309.08093</a> [<a href="/pdf/2309.08093" title="Download PDF">pdf</a>, <a href="/format/2309.08093" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Low-rank Tensor Train Decomposition Using TensorSketch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chen%2C+Z">Zhongming Chen</a>, 
<a href="/search/math?searchtype=author&query=Jiang%2C+H">Huilin Jiang</a>, 
<a href="/search/math?searchtype=author&query=Yu%2C+G">Gaohang Yu</a>, 
<a href="/search/math?searchtype=author&query=Qi%2C+L">Liqun Qi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">Tensor train decomposition is one of the most powerful approaches for
processing high-dimensional data. For low-rank tensor train decomposition of
large tensors, the alternating least squares (ALS) algorithm is widely used by
updating each core tensor alternatively. However, it may suffer from the curse
of dimensionality due to the large scale of subproblems. In this paper, a novel
randomized proximal ALS algorithm is proposed for low-rank tensor train
decomposition by using TensorSketch, which allows for efficient implementation
via fast Fourier transform. The theoretical lower bounds of sketch size are
estimated for approximating the optimal value of subproblems. Numerical
experiments on synthetic and real-world data also demonstrate the effectiveness
and efficiency of the proposed algorithm.
</p>
</div>
</dd>
<dt><a name="item71">[71]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08095" title="Abstract">arXiv:2309.08095</a> [<a href="/pdf/2309.08095" title="Download PDF">pdf</a>, <a href="/format/2309.08095" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RELAX: Reinforcement Learning Enabled 2D-LiDAR Autonomous System for  Parsimonious UAVs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+G">Guanlin Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Z">Zhuokai Zhao</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+Y">Yutao He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Unmanned Aerial Vehicles (UAVs) have gained significant prominence in recent
years for areas including surveillance, search, rescue, and package delivery.
One key aspect in UAV operations shared across all these tasks is the
autonomous path planning, which enables UAV to navigate through complex,
unknown, and dynamic environments while avoiding obstacles without human
control. Despite countless efforts having been devoted to this subject, new
challenges are constantly arisen due to the persistent trade-off between
performance and cost. And new studies are more urgently needed to develop
autonomous system for UAVs with parsimonious sensor setup, which is a major
need for wider adoptions. To this end, we propose an end-to-end autonomous
framework to enable UAVs with only one single 2D-LiDAR sensor to operate in
unknown dynamic environments. More specifically, we break our approach into
three stages: a pre-processing Map Constructor; an offline Mission Planner; and
an online reinforcement learning (RL)-based Dynamic Obstacle Handler.
Experiments show that our approach provides robust and reliable dynamic path
planning and obstacle avoidance with only 1/10 of the cost in sensor
configuration. The code will be made public upon acceptance.
</p>
</div>
</dd>
<dt><a name="item72">[72]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08096" title="Abstract">arXiv:2309.08096</a> [<a href="/pdf/2309.08096" title="Download PDF">pdf</a>, <a href="/format/2309.08096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GelSplitter: Tactile Reconstruction from Near Infrared and Visible  Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuankai Lin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yulin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaiji Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+Q">Qi Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+T">Tao Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hua Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhouping Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">The GelSight-like visual tactile (VT) sensor has gained popularity as a
high-resolution tactile sensing technology for robots, capable of measuring
touch geometry using a single RGB camera. However, the development of
multi-modal perception for VT sensors remains a challenge, limited by the mono
camera. In this paper, we propose the GelSplitter, a new framework approach the
multi-modal VT sensor with synchronized multi-modal cameras and resemble a more
human-like tactile receptor. Furthermore, we focus on 3D tactile reconstruction
and implement a compact sensor structure that maintains a comparable size to
state-of-the-art VT sensors, even with the addition of a prism and a near
infrared (NIR) camera. We also design a photometric fusion stereo neural
network (PFSNN), which estimates surface normals of objects and reconstructs
touch geometry from both infrared and visible images. Our results demonstrate
that the accuracy of RGB and NIR fusion is higher than that of RGB images
alone. Additionally, our GelSplitter framework allows for a flexible
configuration of different camera sensor combinations, such as RGB and thermal
imaging.
</p>
</div>
</dd>
<dt><a name="item73">[73]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08097" title="Abstract">arXiv:2309.08097</a> [<a href="/pdf/2309.08097" title="Download PDF">pdf</a>, <a href="/format/2309.08097" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Detail Reinforcement Diffusion Model: Augmentation Fine-Grained Visual  Categorization in Few-Shot Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shuo Ye</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shuhuang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Q">Qinmu Peng</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xinge You</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">The challenge in fine-grained visual categorization lies in how to explore
the subtle differences between different subclasses and achieve accurate
discrimination. Previous research has relied on large-scale annotated data and
pre-trained deep models to achieve the objective. However, when only a limited
amount of samples is available, similar methods may become less effective.
Diffusion models have been widely adopted in data augmentation due to their
outstanding diversity in data generation. However, the high level of detail
required for fine-grained images makes it challenging for existing methods to
be directly employed. To address this issue, we propose a novel approach termed
the detail reinforcement diffusion model~(DRDM), which leverages the rich
knowledge of large models for fine-grained data augmentation and comprises two
key components including discriminative semantic recombination (DSR) and
spatial knowledge reference~(SKR). Specifically, DSR is designed to extract
implicit similarity relationships from the labels and reconstruct the semantic
mapping between labels and instances, which enables better discrimination of
subtle differences between different subclasses. Furthermore, we introduce the
SKR module, which incorporates the distributions of different datasets as
references in the feature space. This allows the SKR to aggregate the
high-dimensional distribution of subclass features in few-shot FGVC tasks, thus
expanding the decision boundary. Through these two critical components, we
effectively utilize the knowledge from large models to address the issue of
data scarcity, resulting in improved performance for fine-grained visual
recognition tasks. Extensive experiments demonstrate the consistent performance
gain offered by our DRDM.
</p>
</div>
</dd>
<dt><a name="item74">[74]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08099" title="Abstract">arXiv:2309.08099</a> [<a href="/pdf/2309.08099" title="Download PDF">pdf</a>, <a href="/format/2309.08099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Characterizing the temporal dynamics of universal speech representations  for generalizable deepfake detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+Y">Yi Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Powar%2C+S">Saurabh Powar</a>, 
<a href="/search/cs?searchtype=author&query=Falk%2C+T+H">Tiago H. Falk</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Existing deepfake speech detection systems lack generalizability to unseen
attacks (i.e., samples generated by generative algorithms not seen during
training). Recent studies have explored the use of universal speech
representations to tackle this issue and have obtained inspiring results. These
works, however, have focused on innovating downstream classifiers while leaving
the representation itself untouched. In this study, we argue that
characterizing the long-term temporal dynamics of these representations is
crucial for generalizability and propose a new method to assess representation
dynamics. Indeed, we show that different generative models generate similar
representation dynamics patterns with our proposed method. Experiments on the
ASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to
detect deepfakes from methods unseen during training, significantly improving
on several benchmark methods.
</p>
</div>
</dd>
<dt><a name="item75">[75]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08100" title="Abstract">arXiv:2309.08100</a> [<a href="/pdf/2309.08100" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Research on Joint Representation Learning Methods for Entity  Neighborhood Information and Description Information
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Le Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Shan%2C+X">Xin Shan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yuhua Wang</a>, 
<a href="/search/cs?searchtype=author&query=Deng%2C+M">Miaolei Deng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">To address the issue of poor embedding performance in the knowledge graph of
a programming design course, a joint represen-tation learning model that
combines entity neighborhood infor-mation and description information is
proposed. Firstly, a graph at-tention network is employed to obtain the
features of entity neigh-boring nodes, incorporating relationship features to
enrich the structural information. Next, the BERT-WWM model is utilized in
conjunction with attention mechanisms to obtain the representation of entity
description information. Finally, the final entity vector representation is
obtained by combining the vector representations of entity neighborhood
information and description information. Experimental results demonstrate that
the proposed model achieves favorable performance on the knowledge graph
dataset of the pro-gramming design course, outperforming other baseline models.
</p>
</div>
</dd>
<dt><a name="item76">[76]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08104" title="Abstract">arXiv:2309.08104</a> [<a href="/pdf/2309.08104" title="Download PDF">pdf</a>, <a href="/format/2309.08104" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rhythm of Work: Mixed-methods Characterization of Information Workers  Scheduling Preferences and Practices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mok%2C+L">Lillio Mok</a>, 
<a href="/search/cs?searchtype=author&query=Sen%2C+S">Shilad Sen</a>, 
<a href="/search/cs?searchtype=author&query=Sarrafzadeh%2C+B">Bahar Sarrafzadeh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">As processes around hybrid work, spatially distant collaborations, and
work-life boundaries grow increasingly complex, managing workers' schedules for
synchronous meetings has become a critical aspect of building successful global
teams. However, gaps remain in our understanding of workers' scheduling
preferences and practices, which we aim to fill in this large-scale,
mixed-methods study of individuals calendars in a multinational organization.
Using interviews with eight participants, survey data from 165 respondents, and
telemetry data from millions of meetings scheduled by 211 thousand workers, we
characterize scheduling preferences, practices, and their relationship with
each other and organizational factors. We find that temporal preferences can be
broadly classified as either cyclical, such as suitability of certain days, or
relational, such as dispersed meetings, at various time scales. Furthermore,
our results suggest that these preferences are disconnected from actual
practice--albeit with several notable exceptions--and that individual
differences are associated with factors like meeting load, time-zones,
importance of meetings to job function, and job titles. We discuss key themes
for our findings, along with the implications for calendar and scheduling
systems and socio-technical systems more broadly.
</p>
</div>
</dd>
<dt><a name="item77">[77]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08106" title="Abstract">arXiv:2309.08106</a> [<a href="/pdf/2309.08106" title="Download PDF">pdf</a>, <a href="/format/2309.08106" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-Driven Goal Recognition in Transhumeral Prostheses Using Process  Mining Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Su%2C+Z">Zihang Su</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tianshi Yu</a>, 
<a href="/search/cs?searchtype=author&query=Lipovetzky%2C+N">Nir Lipovetzky</a>, 
<a href="/search/cs?searchtype=author&query=Mohammadi%2C+A">Alireza Mohammadi</a>, 
<a href="/search/cs?searchtype=author&query=Oetomo%2C+D">Denny Oetomo</a>, 
<a href="/search/cs?searchtype=author&query=Polyvyanyy%2C+A">Artem Polyvyanyy</a>, 
<a href="/search/cs?searchtype=author&query=Sardina%2C+S">Sebastian Sardina</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+Y">Ying Tan</a>, 
<a href="/search/cs?searchtype=author&query=van+Beest%2C+N">Nick van Beest</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The 5th International Conference on Process Mining (ICPM 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">A transhumeral prosthesis restores missing anatomical segments below the
shoulder, including the hand. Active prostheses utilize real-valued, continuous
sensor data to recognize patient target poses, or goals, and proactively move
the artificial limb. Previous studies have examined how well the data collected
in stationary poses, without considering the time steps, can help discriminate
the goals. In this case study paper, we focus on using time series data from
surface electromyography electrodes and kinematic sensors to sequentially
recognize patients' goals. Our approach involves transforming the data into
discrete events and training an existing process mining-based goal recognition
system. Results from data collected in a virtual reality setting with ten
subjects demonstrate the effectiveness of our proposed goal recognition
approach, which achieves significantly better precision and recall than the
state-of-the-art machine learning techniques and is less confident when wrong,
which is beneficial when approximating smoother movements of prostheses.
</p>
</div>
</dd>
<dt><a name="item78">[78]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08108" title="Abstract">arXiv:2309.08108</a> [<a href="/pdf/2309.08108" title="Download PDF">pdf</a>, <a href="/format/2309.08108" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Foundation Model Assisted Automatic Speech Emotion Recognition:  Transcribing, Annotating, and Augmenting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+T">Tiantian Feng</a>, 
<a href="/search/cs?searchtype=author&query=Narayanan%2C+S">Shrikanth Narayanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Significant advances are being made in speech emotion recognition (SER) using
deep learning models. Nonetheless, training SER systems remains challenging,
requiring both time and costly resources. Like many other machine learning
tasks, acquiring datasets for SER requires substantial data annotation efforts,
including transcription and labeling. These annotation processes present
challenges when attempting to scale up conventional SER systems. Recent
developments in foundational models have had a tremendous impact, giving rise
to applications such as ChatGPT. These models have enhanced human-computer
interactions including bringing unique possibilities for streamlining data
collection in fields like SER. In this research, we explore the use of
foundational models to assist in automating SER from transcription and
annotation to augmentation. Our study demonstrates that these models can
generate transcriptions to enhance the performance of SER systems that rely
solely on speech data. Furthermore, we note that annotating emotions from
transcribed speech remains a challenging task. However, combining outputs from
multiple LLMs enhances the quality of annotations. Lastly, our findings suggest
the feasibility of augmenting existing speech emotion datasets by annotating
unlabeled speech samples.
</p>
</div>
</dd>
<dt><a name="item79">[79]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08112" title="Abstract">arXiv:2309.08112</a> [<a href="/pdf/2309.08112" title="Download PDF">pdf</a>, <a href="/format/2309.08112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Empowering Private Tutoring by Chaining Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yulin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhiyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+M">Maosong Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+B">Bowen Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Artificial intelligence has been applied in various aspects of online
education to facilitate teaching and learning. However, few approaches has been
made toward a complete AI-powered tutoring system. In this work, we explore the
development of a full-fledged intelligent tutoring system powered by
state-of-the-art large language models (LLMs), covering automatic course
planning and adjusting, tailored instruction, and flexible quiz evaluation. To
make the system robust to prolonged interaction and cater to individualized
education, the system is decomposed into three inter-connected core
processes-interaction, reflection, and reaction. Each process is implemented by
chaining LLM-powered tools along with dynamically updated memory modules. Tools
are LLMs prompted to execute one specific task at a time, while memories are
data storage that gets updated during education process. Statistical results
from learning logs demonstrate the effectiveness and mechanism of each tool
usage. Subjective feedback from human users reveal the usability of each
function, and comparison with ablation systems further testify the benefits of
the designed processes in long-term interaction.
</p>
</div>
</dd>
<dt><a name="item80">[80]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08113" title="Abstract">arXiv:2309.08113</a> [<a href="/pdf/2309.08113" title="Download PDF">pdf</a>, <a href="/format/2309.08113" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaF2N: Blind Image Super-Resolution by Learning Efficient Model  Adaptation from Faces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhicun Yin</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoming Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+H">Hui Yang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+L">Longan Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zuo%2C+W">Wangmeng Zuo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to their highly structured characteristics, faces are easier to recover
than natural scenes for blind image super-resolution. Therefore, we can extract
the degradation representation of an image from the low-quality and recovered
face pairs. Using the degradation representation, realistic low-quality images
can then be synthesized to fine-tune the super-resolution model for the
real-world low-quality image. However, such a procedure is time-consuming and
laborious, and the gaps between recovered faces and the ground-truths further
increase the optimization uncertainty. To facilitate efficient model adaptation
towards image-specific degradations, we propose a method dubbed MetaF2N, which
leverages the contained Faces to fine-tune model parameters for adapting to the
whole Natural image in a Meta-learning framework. The degradation extraction
and low-quality image synthesis steps are thus circumvented in our MetaF2N, and
it requires only one fine-tuning step to get decent performance. Considering
the gaps between the recovered faces and ground-truths, we further deploy a
MaskNet for adaptively predicting loss weights at different positions to reduce
the impact of low-confidence areas. To evaluate our proposed MetaF2N, we have
collected a real-world low-quality dataset with one or multiple faces in each
image, and our MetaF2N achieves superior performance on both synthetic and
real-world datasets. Source code, pre-trained models, and collected datasets
are available at https://github.com/yinzhicun/MetaF2N.
</p>
</div>
</dd>
<dt><a name="item81">[81]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08115" title="Abstract">arXiv:2309.08115</a> [<a href="/pdf/2309.08115" title="Download PDF">pdf</a>, <a href="/format/2309.08115" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> REEF: A Framework for Collecting Real-World Vulnerabilities and Fixes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chaozheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zongjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+Y">Yun Peng</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+S">Shuzheng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Sirong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+C">Cuiyun Gao</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+M+R">Michael R. Lyu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ASE 2023 Industry Challenge(Competition) Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Software plays a crucial role in our daily lives, and therefore the quality
and security of software systems have become increasingly important. However,
vulnerabilities in software still pose a significant threat, as they can have
serious consequences. Recent advances in automated program repair have sought
to automatically detect and fix bugs using data-driven techniques.
Sophisticated deep learning methods have been applied to this area and have
achieved promising results. However, existing benchmarks for training and
evaluating these techniques remain limited, as they tend to focus on a single
programming language and have relatively small datasets. Moreover, many
benchmarks tend to be outdated and lack diversity, focusing on a specific
codebase. Worse still, the quality of bug explanations in existing datasets is
low, as they typically use imprecise and uninformative commit messages as
explanations.
<br />To address these issues, we propose an automated collecting framework REEF to
collect REal-world vulnErabilities and Fixes from open-source repositories. We
develop a multi-language crawler to collect vulnerabilities and their fixes,
and design metrics to filter for high-quality vulnerability-fix pairs.
Furthermore, we propose a neural language model-based approach to generate
high-quality vulnerability explanations, which is key to producing informative
fix messages. Through extensive experiments, we demonstrate that our approach
can collect high-quality vulnerability-fix pairs and generate strong
explanations. The dataset we collect contains 4,466 CVEs with 30,987 patches
(including 236 CWE) across 7 programming languages with detailed related
information, which is superior to existing benchmarks in scale, coverage, and
quality. Evaluations by human experts further confirm that our framework
produces high-quality vulnerability explanations.
</p>
</div>
</dd>
<dt><a name="item82">[82]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08118" title="Abstract">arXiv:2309.08118</a> [<a href="/pdf/2309.08118" title="Download PDF">pdf</a>, <a href="/ps/2309.08118" title="Download PostScript">ps</a>, <a href="/format/2309.08118" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Graph IRs for Impure Higher-Order Languages (Technical Report)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bra%C4%8Devac%2C+O">Oliver Bra&#x10d;evac</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+G">Guannan Wei</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+S">Songlin Jia</a>, 
<a href="/search/cs?searchtype=author&query=Abeysinghe%2C+S">Supun Abeysinghe</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yuxuan Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Bao%2C+Y">Yuyan Bao</a>, 
<a href="/search/cs?searchtype=author&query=Rompf%2C+T">Tiark Rompf</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2309.05885">arXiv:2309.05885</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">This is a companion report for the OOPSLA 2023 paper of the same title,
presenting a detailed end-to-end account of the $\lambda^*_{\mathsf{G}}$ graph
IR, at a level of detail beyond a regular conference paper. Our first concern
is adequacy and soundness of $\lambda^*_{\mathsf{G}}$, which we derive from a
direct-style imperative functional language (a variant of Bao et al.'s
$\lambda^*$-calculus with reachability types and a simple effect system) by a
series of type-preserving translations into a calculus in monadic normalform
(MNF). Static reachability types and effects entirely inform
$\lambda^*_{\mathsf{G}}$'s dependency synthesis. We argue for its adequacy by
proving its functional properties along with dependency safety via progress and
preservation lemmas with respect to a notion of call-by-value (CBV) reduction
that checks the observed order of effects.
<br />Our second concern is establishing the correctness of
$\lambda^*_{\mathsf{G}}$'s equational rules that drive compiler optimizations
(e.g., DCE, $\lambda$-hoisting, etc.), by proving contextual equivalence using
logical relations. A key insight is that the functional properties of
dependency synthesis permit a logical relation on $\lambda^*_{\mathsf{G}}$ in
MNF in terms of previously developed logical relations for the direct-style
$\lambda^*$-calculus.
<br />Finally, we also include a longer version of the conference paper's section
on code generation and code motion for $\lambda^*_{\mathsf{G}}$ as implemented
in Scala~LMS.
</p>
</div>
</dd>
<dt><a name="item83">[83]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08121" title="Abstract">arXiv:2309.08121</a> [<a href="/pdf/2309.08121" title="Download PDF">pdf</a>, <a href="/format/2309.08121" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;I&#x27;m Not Confident in Debiasing AI Systems Since I Know Too Little&quot;:  Teaching AI Creators About Gender Bias Through Hands-on Tutorials
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K+Z">Kyrie Zhixuan Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jiaxun Cao</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+X">Xiaowen Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Weissglass%2C+D+E">Daniel E. Weissglass</a>, 
<a href="/search/cs?searchtype=author&query=Kilhoffer%2C+Z">Zachary Kilhoffer</a>, 
<a href="/search/cs?searchtype=author&query=Sanfilippo%2C+M+R">Madelyn Rose Sanfilippo</a>, 
<a href="/search/cs?searchtype=author&query=Tong%2C+X">Xin Tong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Artificial Intelligence (cs.AI); Computers and Society (cs.CY)

</div>
<p class="mathjax">Gender bias is rampant in AI systems, causing bad user experience,
injustices, and mental harm to women. School curricula fail to educate AI
creators on this topic, leaving them unprepared to mitigate gender bias in AI.
In this paper, we designed hands-on tutorials to raise AI creators' awareness
of gender bias in AI and enhance their knowledge of sources of gender bias and
debiasing techniques. The tutorials were evaluated with 18 AI creators,
including AI researchers, AI industrial practitioners (i.e., developers and
product managers), and students who had learned AI. Their improved awareness
and knowledge demonstrated the effectiveness of our tutorials, which have the
potential to complement the insufficient AI gender bias education in CS/AI
courses. Based on the findings, we synthesize design implications and a rubric
to guide future research, education, and design efforts.
</p>
</div>
</dd>
<dt><a name="item84">[84]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08125" title="Abstract">arXiv:2309.08125</a> [<a href="/pdf/2309.08125" title="Download PDF">pdf</a>, <a href="/format/2309.08125" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Oobleck: Resilient Distributed Training of Large Models Using Pipeline  Templates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jang%2C+I">Insu Jang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhenning Yang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+X">Xin Jin</a>, 
<a href="/search/cs?searchtype=author&query=Chowdhury%2C+M">Mosharaf Chowdhury</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> SOSP'23 | Camera-ready
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Oobleck enables resilient distributed training of large DNN models with
guaranteed fault tolerance. It takes a planning-execution co-design approach,
where it first generates a set of heterogeneous pipeline templates and
instantiates at least $f+1$ logically equivalent pipeline replicas to tolerate
any $f$ simultaneous failures. During execution, it relies on
already-replicated model states across the replicas to provide fast recovery.
Oobleck provably guarantees that some combination of the initially created
pipeline templates can be used to cover all available resources after $f$ or
fewer simultaneous failures, thereby avoiding resource idling at all times.
Evaluation on large DNN models with billions of parameters shows that Oobleck
provides consistently high throughput, and it outperforms state-of-the-art
fault tolerance solutions like Bamboo and Varuna by up to $13.9x$.
</p>
</div>
</dd>
<dt><a name="item85">[85]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08127" title="Abstract">arXiv:2309.08127</a> [<a href="/pdf/2309.08127" title="Download PDF">pdf</a>, <a href="/format/2309.08127" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity-based core-set selection for text-to-speech with linguistic  and acoustic features
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seki%2C+K">Kentaro Seki</a>, 
<a href="/search/cs?searchtype=author&query=Takamichi%2C+S">Shinnosuke Takamichi</a>, 
<a href="/search/cs?searchtype=author&query=Saeki%2C+T">Takaaki Saeki</a>, 
<a href="/search/cs?searchtype=author&query=Saruwatari%2C+H">Hiroshi Saruwatari</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes a method for extracting a lightweight subset from a
text-to-speech (TTS) corpus ensuring synthetic speech quality. In recent years,
methods have been proposed for constructing large-scale TTS corpora by
collecting diverse data from massive sources such as audiobooks and YouTube.
Although these methods have gained significant attention for enhancing the
expressive capabilities of TTS systems, they often prioritize collecting vast
amounts of data without considering practical constraints like storage capacity
and computation time in training, which limits the available data quantity.
Consequently, the need arises to efficiently collect data within these volume
constraints. To address this, we propose a method for selecting the core
subset~(known as \textit{core-set}) from a TTS corpus on the basis of a
\textit{diversity metric}, which measures the degree to which a subset
encompasses a wide range. Experimental results demonstrate that our proposed
method performs significantly better than the baseline phoneme-balanced data
selection across language and corpus size.
</p>
</div>
</dd>
<dt><a name="item86">[86]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08128" title="Abstract">arXiv:2309.08128</a> [<a href="/pdf/2309.08128" title="Download PDF">pdf</a>, <a href="/format/2309.08128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multicontinuum homogenization. General theory and applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Chung%2C+E">E. Chung</a>, 
<a href="/search/math?searchtype=author&query=Efendiev%2C+Y">Y. Efendiev</a>, 
<a href="/search/math?searchtype=author&query=Galvis%2C+J">J. Galvis</a>, 
<a href="/search/math?searchtype=author&query=Leung%2C+W+T">W.T. Leung</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper, we discuss a general framework for multicontinuum
homogenization. Multicontinuum models are widely used in many applications and
some derivations for these models are established. In these models, several
macroscopic variables at each macroscale point are defined and the resulting
multicontinuum equations are formulated. In this paper, we propose a general
formulation and associated ingredients that allow performing multicontinuum
homogenization. Our derivation consists of several main parts. In the first
part, we propose a general expansion, where the solution is expressed via the
product of multiple macro variables and associated cell problems. The second
part consists of formulating the cell problems. The cell problems are
formulated as saddle point problems with constraints for each continua.
Defining the continua via test functions, we set the constraints as an integral
representation. Finally, substituting the expansion to the original system, we
obtain multicontinuum systems. We present an application to the mixed
formulation of elliptic equations. This is a challenging system as the system
does not have symmetry. We discuss the local problems and various macroscale
representations for the solution and its gradient. Using various order
approximations, one can obtain different systems of equations. We discuss the
applicability of multicontinuum homogenization and relate this to high contrast
in the cell problem. Numerical results are presented.
</p>
</div>
</dd>
<dt><a name="item87">[87]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08130" title="Abstract">arXiv:2309.08130</a> [<a href="/pdf/2309.08130" title="Download PDF">pdf</a>, <a href="/ps/2309.08130" title="Download PostScript">ps</a>, <a href="/format/2309.08130" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive finite element approximation of sparse optimal control with  integral fractional Laplacian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Wang%2C+F">Fangyuan Wang</a>, 
<a href="/search/math?searchtype=author&query=Wang%2C+Q">Qiming Wang</a>, 
<a href="/search/math?searchtype=author&query=Zhou%2C+Z">Zhaojie Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">In this paper we present and analyze a weighted residual a posteriori error
estimate for an optimal control problem. The problem involves a
nondifferentiable cost functional, a state equation with an integral fractional
Laplacian, and control constraints. We employ subdifferentiation in the context
of nondifferentiable convex analysis to obtain first-order optimality
conditions. Piecewise linear polynomials are utilized to approximate the
solutions of the state and adjoint equations. The control variable is
discretized using the variational discretization method. Upper and lower bounds
for the a posteriori error estimate of the finite element approximation of the
optimal control problem are derived. In the region where 3/2 &lt; alpha &lt; 2, the
residuals do not satisfy the L2(Omega) regularity. To address this issue, an
additional weight is included in the weighted residual estimator, which is
based on a power of the distance from the mesh skeleton. Furthermore, we
propose an h-adaptive algorithm driven by the posterior view error estimator,
utilizing the Dorfler labeling criterion. The convergence analysis results show
that the approximation sequence generated by the adaptive algorithm converges
at the optimal algebraic rate. Finally, numerical experiments are conducted to
validate the theoretical results.
</p>
</div>
</dd>
<dt><a name="item88">[88]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08133" title="Abstract">arXiv:2309.08133</a> [<a href="/pdf/2309.08133" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Talkin&#x27; &#x27;Bout AI Generation: Copyright and the Generative-AI Supply  Chain
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Katherine Lee</a>, 
<a href="/search/cs?searchtype=author&query=Cooper%2C+A+F">A. Feder Cooper</a>, 
<a href="/search/cs?searchtype=author&query=Grimmelmann%2C+J">James Grimmelmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">"Does generative AI infringe copyright?" is an urgent question. It is also a
difficult question, for two reasons. First, "generative AI" is not just one
product from one company. It is a catch-all name for a massive ecosystem of
loosely related technologies, including conversational text chatbots like
ChatGPT, image generators like Midjourney and DALL-E, coding assistants like
GitHub Copilot, and systems that compose music and create videos. These systems
behave differently and raise different legal issues. The second problem is that
copyright law is notoriously complicated, and generative-AI systems manage to
touch on a great many corners of it: authorship, similarity, direct and
indirect liability, fair use, and licensing, among much else. These issues
cannot be analyzed in isolation, because there are connections everywhere.
<br />In this Article, we aim to bring order to the chaos. To do so, we introduce
the generative-AI supply chain: an interconnected set of stages that transform
training data (millions of pictures of cats) into generations (a new,
potentially never-seen-before picture of a cat that has never existed).
Breaking down generative AI into these constituent stages reveals all of the
places at which companies and users make choices that have copyright
consequences. It enables us to trace the effects of upstream technical designs
on downstream uses, and to assess who in these complicated sociotechnical
systems bears responsibility for infringement when it happens. Because we
engage so closely with the technology of generative AI, we are able to shed
more light on the copyright questions. We do not give definitive answers as to
who should and should not be held liable. Instead, we identify the key
decisions that courts will need to make as they grapple with these issues, and
point out the consequences that would likely flow from different liability
regimes.
</p>
</div>
</dd>
<dt><a name="item89">[89]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08134" title="Abstract">arXiv:2309.08134</a> [<a href="/pdf/2309.08134" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AnyOKP: One-Shot and Instance-Aware Object Keypoint Extraction with  Pretrained ViT
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qin%2C+F">Fangbo Qin</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+T">Taogang Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+S">Shan Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+K">Kaiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yip%2C+M+C">Michael C. Yip</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S">Shan Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICRA 2024 as a contributed paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Towards flexible object-centric visual perception, we propose a one-shot
instance-aware object keypoint (OKP) extraction approach, AnyOKP, which
leverages the powerful representation ability of pretrained vision transformer
(ViT), and can obtain keypoints on multiple object instances of arbitrary
category after learning from a support image. An off-the-shelf petrained ViT is
directly deployed for generalizable and transferable feature extraction, which
is followed by training-free feature enhancement. The best-prototype pairs
(BPPs) are searched for in support and query images based on appearance
similarity, to yield instance-unaware candidate keypoints.Then, the entire
graph with all candidate keypoints as vertices are divided to sub-graphs
according to the feature distributions on the graph edges. Finally, each
sub-graph represents an object instance. AnyOKP is evaluated on real object
images collected with the cameras of a robot arm, a mobile robot, and a
surgical robot, which not only demonstrates the cross-category flexibility and
instance awareness, but also show remarkable robustness to domain shift and
viewpoint change.
</p>
</div>
</dd>
<dt><a name="item90">[90]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08136" title="Abstract">arXiv:2309.08136</a> [<a href="/pdf/2309.08136" title="Download PDF">pdf</a>, <a href="/format/2309.08136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Roll: Synthetic Dataset Analysis for Pedestrian Detection Across  Different Shutter Types
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yue Hu</a>, 
<a href="/search/cs?searchtype=author&query=Datta%2C+G">Gourav Datta</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+K">Kira Beerel</a>, 
<a href="/search/cs?searchtype=author&query=Beerel%2C+P">Peter Beerel</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Computer vision (CV) pipelines are typically evaluated on datasets processed
by image signal processing (ISP) pipelines even though, for
resource-constrained applications, an important research goal is to avoid as
many ISP steps as possible. In particular, most CV datasets consist of global
shutter (GS) images even though most cameras today use a rolling shutter (RS).
This paper studies the impact of different shutter mechanisms on machine
learning (ML) object detection models on a synthetic dataset that we generate
using the advanced simulation capabilities of Unreal Engine 5 (UE5). In
particular, we train and evaluate mainstream detection models with our
synthetically-generated paired GS and RS datasets to ascertain whether there
exists a significant difference in detection accuracy between these two shutter
modalities, especially when capturing low-speed objects (e.g., pedestrians).
The results of this emulation framework indicate the performance between them
are remarkably congruent for coarse-grained detection (mean average precision
(mAP) for IOU=0.5), but have significant differences for fine-grained measures
of detection accuracy (mAP for IOU=0.5:0.95). This implies that ML pipelines
might not need explicit correction for RS for many object detection
applications, but mitigating RS effects in ISP-less ML pipelines that target
fine-grained location of the objects may need additional research.
</p>
</div>
</dd>
<dt><a name="item91">[91]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08138" title="Abstract">arXiv:2309.08138</a> [<a href="/pdf/2309.08138" title="Download PDF">pdf</a>, <a href="/format/2309.08138" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Find What You Want: Learning Demand-conditioned Object Attribute Space  for Demand-driven Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongcheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+A+G+H">Andy Guan Hong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaoqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Mingdong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hao Dong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">The task of Visual Object Navigation (VON) involves an agent's ability to
locate a particular object within a given scene. In order to successfully
accomplish the VON task, two essential conditions must be fulfilled:1) the user
must know the name of the desired object; and 2) the user-specified object must
actually be present within the scene. To meet these conditions, a simulator can
incorporate pre-defined object names and positions into the metadata of the
scene. However, in real-world scenarios, it is often challenging to ensure that
these conditions are always met. Human in an unfamiliar environment may not
know which objects are present in the scene, or they may mistakenly specify an
object that is not actually present. Nevertheless, despite these challenges,
human may still have a demand for an object, which could potentially be
fulfilled by other objects present within the scene in an equivalent manner.
Hence, we propose Demand-driven Navigation (DDN), which leverages the user's
demand as the task instruction and prompts the agent to find the object matches
the specified demand. DDN aims to relax the stringent conditions of VON by
focusing on fulfilling the user's demand rather than relying solely on
predefined object categories or names. We propose a method first acquire
textual attribute features of objects by extracting common knowledge from a
large language model. These textual attribute features are subsequently aligned
with visual attribute features using Contrastive Language-Image Pre-training
(CLIP). By incorporating the visual attribute features as prior knowledge, we
enhance the navigation process. Experiments on AI2Thor with the ProcThor
dataset demonstrate the visual attribute features improve the agent's
navigation performance and outperform the baseline methods commonly used in
VON.
</p>
</div>
</dd>
<dt><a name="item92">[92]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08139" title="Abstract">arXiv:2309.08139</a> [<a href="/pdf/2309.08139" title="Download PDF">pdf</a>, <a href="/format/2309.08139" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multi-Scale Estimation for Omni-Directional Saliency Maps Using  Learnable Equator Bias
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yamanaka%2C+T">Takao Yamanaka</a>, 
<a href="/search/cs?searchtype=author&query=Suzuki%2C+T">Tatsuya Suzuki</a>, 
<a href="/search/cs?searchtype=author&query=Nobutsune%2C+T">Taiki Nobutsune</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Chenjunlin Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in IEICE Transactions on Information and Systems, Vol. E106-D, No. 10, 2023. <a href="https://www.jstage.jst.go.jp/browse/transinf">this https URL</a> The code is available at <a href="https://github.com/islab-sophia/odisal">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Omni-directional images have been used in wide range of applications. For the
applications, it would be useful to estimate saliency maps representing
probability distributions of gazing points with a head-mounted display, to
detect important regions in the omni-directional images. This paper proposes a
novel saliency-map estimation model for the omni-directional images by
extracting overlapping 2-dimensional (2D) plane images from omni-directional
images at various directions and angles of view. While 2D saliency maps tend to
have high probability at the center of images (center bias), the
high-probability region appears at horizontal directions in omni-directional
saliency maps when a head-mounted display is used (equator bias). Therefore,
the 2D saliency model with a center-bias layer was fine-tuned with an
omni-directional dataset by replacing the center-bias layer to an equator-bias
layer conditioned on the elevation angle for the extraction of the 2D plane
image. The limited availability of omni-directional images in saliency datasets
can be compensated by using the well-established 2D saliency model pretrained
by a large number of training images with the ground truth of 2D saliency maps.
In addition, this paper proposes a multi-scale estimation method by extracting
2D images in multiple angles of view to detect objects of various sizes with
variable receptive fields. The saliency maps estimated from the multiple angles
of view were integrated by using pixel-wise attention weights calculated in an
integration layer for weighting the optimal scale to each object. The proposed
method was evaluated using a publicly available dataset with evaluation metrics
for omni-directional saliency maps. It was confirmed that the accuracy of the
saliency maps was improved by the proposed method.
</p>
</div>
</dd>
<dt><a name="item93">[93]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08142" title="Abstract">arXiv:2309.08142</a> [<a href="/pdf/2309.08142" title="Download PDF">pdf</a>, <a href="/format/2309.08142" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MAVIS: Multi-Camera Augmented Visual-Inertial SLAM using SE2(3) Based  Exact IMU Pre-integration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+Y">Yonhon Ng</a>, 
<a href="/search/cs?searchtype=author&query=Sa%2C+I">Inkyu Sa</a>, 
<a href="/search/cs?searchtype=author&query=Parra%2C+A">Alvaro Parra</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+C">Cristian Rodriguez</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+T+J">Tao Jun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongdong Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> video link: <a href="https://youtu.be/Q_jZSjhNFfg">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a novel optimization-based Visual-Inertial SLAM system designed
for multiple partially overlapped camera systems, named MAVIS. Our framework
fully exploits the benefits of wide field-of-view from multi-camera systems,
and the metric scale measurements provided by an inertial measurement unit
(IMU). We introduce an improved IMU pre-integration formulation based on the
exponential function of an automorphism of SE_2(3), which can effectively
enhance tracking performance under fast rotational motion and extended
integration time. Furthermore, we extend conventional front-end tracking and
back-end optimization module designed for monocular or stereo setup towards
multi-camera systems, and introduce implementation details that contribute to
the performance of our system in challenging scenarios. The practical validity
of our approach is supported by our experiments on public datasets. Our MAVIS
won the first place in all the vision-IMU tracks (single and multi-session
SLAM) on Hilti SLAM Challenge 2023 with 1.7 times the score compared to the
second place.
</p>
</div>
</dd>
<dt><a name="item94">[94]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08144" title="Abstract">arXiv:2309.08144</a> [<a href="/pdf/2309.08144" title="Download PDF">pdf</a>, <a href="/format/2309.08144" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-Step Knowledge Distillation for Tiny Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nathoo%2C+R+D">Rayan Daod Nathoo</a>, 
<a href="/search/cs?searchtype=author&query=Kegler%2C+M">Mikolaj Kegler</a>, 
<a href="/search/cs?searchtype=author&query=Stamenovic%2C+M">Marko Stamenovic</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Tiny, causal models are crucial for embedded audio machine learning
applications. Model compression can be achieved via distilling knowledge from a
large teacher into a smaller student model. In this work, we propose a novel
two-step approach for tiny speech enhancement model distillation. In contrast
to the standard approach of a weighted mixture of distillation and supervised
losses, we firstly pre-train the student using only the knowledge distillation
(KD) objective, after which we switch to a fully supervised training regime. We
also propose a novel fine-grained similarity-preserving KD loss, which aims to
match the student's intra-activation Gram matrices to that of the teacher. Our
method demonstrates broad improvements, but particularly shines in adverse
conditions including high compression and low signal to noise ratios (SNR),
yielding signal to distortion ratio gains of 0.9 dB and 1.1 dB, respectively,
at -5 dB input SNR and 63x compression compared to baseline.
</p>
</div>
</dd>
<dt><a name="item95">[95]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08146" title="Abstract">arXiv:2309.08146</a> [<a href="/pdf/2309.08146" title="Download PDF">pdf</a>, <a href="/format/2309.08146" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Syn-Att: Synthetic Speech Attribution via Semi-Supervised Unknown  Multi-Class Ensemble of CNNs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+A">Md Awsafur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Paul%2C+B">Bishmoy Paul</a>, 
<a href="/search/cs?searchtype=author&query=Sarker%2C+N+H">Najibul Haque Sarker</a>, 
<a href="/search/cs?searchtype=author&query=Hakim%2C+Z+I+A">Zaber Ibn Abdul Hakim</a>, 
<a href="/search/cs?searchtype=author&query=Fattah%2C+S+A">Shaikh Anowarul Fattah</a>, 
<a href="/search/cs?searchtype=author&query=Saquib%2C+M">Mohammad Saquib</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Winning Solution of IEEE SP Cup at ICASSP 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">With the huge technological advances introduced by deep learning in audio &amp;
speech processing, many novel synthetic speech techniques achieved incredible
realistic results. As these methods generate realistic fake human voices, they
can be used in malicious acts such as people imitation, fake news, spreading,
spoofing, media manipulations, etc. Hence, the ability to detect synthetic or
natural speech has become an urgent necessity. Moreover, being able to tell
which algorithm has been used to generate a synthetic speech track can be of
preeminent importance to track down the culprit. In this paper, a novel
strategy is proposed to attribute a synthetic speech track to the generator
that is used to synthesize it. The proposed detector transforms the audio into
log-mel spectrogram, extracts features using CNN, and classifies it between
five known and unknown algorithms, utilizing semi-supervision and ensemble to
improve its robustness and generalizability significantly. The proposed
detector is validated on two evaluation datasets consisting of a total of
18,000 weakly perturbed (Eval 1) &amp; 10,000 strongly perturbed (Eval 2) synthetic
speeches. The proposed method outperforms other top teams in accuracy by 12-13%
on Eval 2 and 1-2% on Eval 1, in the IEEE SP Cup challenge at ICASSP 2022.
</p>
</div>
</dd>
<dt><a name="item96">[96]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08150" title="Abstract">arXiv:2309.08150</a> [<a href="/pdf/2309.08150" title="Download PDF">pdf</a>, <a href="/format/2309.08150" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unimodal Aggregation for CTC-based Speech Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Ying Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper works on non-autoregressive automatic speech recognition. A
unimodal aggregation (UMA) is proposed to segment and integrate the feature
frames that belong to the same text token, and thus to learn better feature
representations for text tokens. The frame-wise features and weights are both
derived from an encoder. Then, the feature frames with unimodal weights are
integrated and further processed by a decoder. Connectionist temporal
classification (CTC) loss is applied for training. Compared to the regular CTC,
the proposed method learns better feature representations and shortens the
sequence length, resulting in lower recognition error and computational
complexity. Experiments on three Mandarin datasets show that UMA demonstrates
superior or comparable performance to other advanced non-autoregressive
methods, such as self-conditioned CTC. Moreover, by integrating
self-conditioned CTC into the proposed framework, the performance can be
further noticeably improved.
</p>
</div>
</dd>
<dt><a name="item97">[97]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08152" title="Abstract">arXiv:2309.08152</a> [<a href="/pdf/2309.08152" title="Download PDF">pdf</a>, <a href="/format/2309.08152" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DA-RAW: Domain Adaptive Object Detection for Real-World Adverse Weather  Conditions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jeon%2C+M">Minsik Jeon</a>, 
<a href="/search/cs?searchtype=author&query=Seo%2C+J">Junwon Seo</a>, 
<a href="/search/cs?searchtype=author&query=Min%2C+J">Jihong Min</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Our video can be found at <a href="https://youtu.be/vsUSrFsbuu8">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Despite the success of deep learning-based object detection methods in recent
years, it is still challenging to make the object detector reliable in adverse
weather conditions such as rain and snow. For the robust performance of object
detectors, unsupervised domain adaptation has been utilized to adapt the
detection network trained on clear weather images to adverse weather images.
While previous methods do not explicitly address weather corruption during
adaptation, the domain gap between clear and adverse weather can be decomposed
into two factors with distinct characteristics: a style gap and a weather gap.
In this paper, we present an unsupervised domain adaptation framework for
object detection that can more effectively adapt to real-world environments
with adverse weather conditions by addressing these two gaps separately. Our
method resolves the style gap by concentrating on style-related information of
high-level features using an attention module. Using self-supervised
contrastive learning, our framework then reduces the weather gap and acquires
instance features that are robust to weather corruption. Extensive experiments
demonstrate that our method outperforms other methods for object detection in
adverse weather conditions.
</p>
</div>
</dd>
<dt><a name="item98">[98]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08154" title="Abstract">arXiv:2309.08154</a> [<a href="/pdf/2309.08154" title="Download PDF">pdf</a>, <a href="/format/2309.08154" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-Aware Multi-View Visual Semantic Embedding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+W">Wenzhang Wei</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+Z">Zhipeng Gui</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+C">Changguang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">Anqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xingguang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Huayi Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">The key challenge in image-text retrieval is effectively leveraging semantic
information to measure the similarity between vision and language data.
However, using instance-level binary labels, where each image is paired with a
single text, fails to capture multiple correspondences between different
semantic units, leading to uncertainty in multi-modal semantic understanding.
Although recent research has captured fine-grained information through more
complex model structures or pre-training techniques, few studies have directly
modeled uncertainty of correspondence to fully exploit binary labels. To
address this issue, we propose an Uncertainty-Aware Multi-View Visual Semantic
Embedding (UAMVSE)} framework that decomposes the overall image-text matching
into multiple view-text matchings. Our framework introduce an uncertainty-aware
loss function (UALoss) to compute the weighting of each view-text loss by
adaptively modeling the uncertainty in each view-text correspondence. Different
weightings guide the model to focus on different semantic information,
enhancing the model's ability to comprehend the correspondence of images and
texts. We also design an optimized image-text matching strategy by normalizing
the similarity matrix to improve model performance. Experimental results on the
Flicker30k and MS-COCO datasets demonstrate that UAMVSE outperforms
state-of-the-art models.
</p>
</div>
</dd>
<dt><a name="item99">[99]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08156" title="Abstract">arXiv:2309.08156</a> [<a href="/pdf/2309.08156" title="Download PDF">pdf</a>, <a href="/format/2309.08156" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shi%2C+Z">Zhengliang Shi</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weiwei Sun</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shuo Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+P">Pengjie Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhaochun Ren</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, Accepted by ACL2023 main conference
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Evaluating open-domain dialogue systems is challenging for reasons such as
the one-to-many problem, i.e., many appropriate responses other than just the
golden response. As of now, automatic evaluation methods need better
consistency with humans, while reliable human evaluation can be time- and
cost-intensive. To this end, we propose the Reference-Assisted Dialogue
Evaluation (RADE) approach under the multi-task learning framework, which
leverages the pre-created utterance as reference other than the gold response
to relief the one-to-many problem. Specifically, RADE explicitly compares
reference and the candidate response to predict their overall scores. Moreover,
an auxiliary response generation task enhances prediction via a shared encoder.
To support RADE, we extend three datasets with additional rated responses other
than just a golden response by human annotation. Experiments on our three
datasets and two existing benchmarks demonstrate the effectiveness of our
method, where Pearson, Spearman, and Kendall correlations with human evaluation
outperform state-of-the-art baselines.
</p>
</div>
</dd>
<dt><a name="item100">[100]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08158" title="Abstract">arXiv:2309.08158</a> [<a href="/pdf/2309.08158" title="Download PDF">pdf</a>, <a href="/format/2309.08158" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Testbed for Automating and Analysing Mobile Devices and their  Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Simpson%2C+L">Lachlan Simpson</a>, 
<a href="/search/cs?searchtype=author&query=Millar%2C+K">Kyle Millar</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+A">Adriel Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Chew%2C+H+G">Hong Gunn Chew</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Cheng-Chew Lim</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
<p class="mathjax">The need for improved network situational awareness has been highlighted by
the growing complexity and severity of cyber-attacks. Mobile phones pose a
significant risk to network situational awareness due to their dynamic
behaviour and lack of visibility on a network. Machine learning techniques
enhance situational awareness by providing administrators insight into the
devices and activities which form their network. Developing machine learning
techniques for situational awareness requires a testbed to generate and label
network traffic. Current testbeds, however, are unable to automate the
generation and labelling of realistic network traffic. To address this, we
describe a testbed which automates applications on mobile devices to generate
and label realistic traffic. From this testbed, two labelled datasets of
network traffic have been created. We provide an analysis of the testbed
automation reliability and benchmark the datasets for the task of application
classification.
</p>
</div>
</dd>
<dt><a name="item101">[101]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08159" title="Abstract">arXiv:2309.08159</a> [<a href="/pdf/2309.08159" title="Download PDF">pdf</a>, <a href="/format/2309.08159" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AdSEE: Investigating the Impact of Image Style Editing on Advertisement  Attractiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Liyao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenglin Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Haolan Chen</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+X">Xiaodong Gao</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+X">Xinwang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yang Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+S">Shani Ye</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+D">Di Niu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to KDD 2023 Applied Data Science Track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Information Retrieval (cs.IR); Machine Learning (cs.LG)

</div>
<p class="mathjax">Online advertisements are important elements in e-commerce sites, social
media platforms, and search engines. With the increasing popularity of mobile
browsing, many online ads are displayed with visual information in the form of
a cover image in addition to text descriptions to grab the attention of users.
Various recent studies have focused on predicting the click rates of online
advertisements aware of visual features or composing optimal advertisement
elements to enhance visibility. In this paper, we propose Advertisement Style
Editing and Attractiveness Enhancement (AdSEE), which explores whether semantic
editing to ads images can affect or alter the popularity of online
advertisements. We introduce StyleGAN-based facial semantic editing and
inversion to ads images and train a click rate predictor attributing GAN-based
face latent representations in addition to traditional visual and textual
features to click rates. Through a large collected dataset named QQ-AD,
containing 20,527 online ads, we perform extensive offline tests to study how
different semantic directions and their edit coefficients may impact click
rates. We further design a Genetic Advertisement Editor to efficiently search
for the optimal edit directions and intensity given an input ad cover image to
enhance its projected click rates. Online A/B tests performed over a period of
5 days have verified the increased click-through rates of AdSEE-edited samples
as compared to a control group of original ads, verifying the relation between
image styles and ad popularity. We open source the code for AdSEE research at
https://github.com/LiyaoJiang1998/adsee.
</p>
</div>
</dd>
<dt><a name="item102">[102]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08163" title="Abstract">arXiv:2309.08163</a> [<a href="/pdf/2309.08163" title="Download PDF">pdf</a>, <a href="/format/2309.08163" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating the Applicability of Self-Assessment Tests for Personality  Measurement of Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Akshat Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+X">Xiaoyang Song</a>, 
<a href="/search/cs?searchtype=author&query=Anumanchipalli%2C+G">Gopala Anumanchipalli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">As large language models (LLM) evolve in their capabilities, various recent
studies have tried to quantify their behavior using psychological tools created
to study human behavior. One such example is the measurement of "personality"
of LLMs using personality self-assessment tests. In this paper, we take three
such studies on personality measurement of LLMs that use personality
self-assessment tests created to study human behavior. We use the prompts used
in these three different papers to measure the personality of the same LLM. We
find that all three prompts lead very different personality scores. This simple
test reveals that personality self-assessment scores in LLMs depend on the
subjective choice of the prompter. Since we don't know the ground truth value
of personality scores for LLMs as there is no correct answer to such questions,
there's no way of claiming if one prompt is more or less correct than the
other. We then introduce the property of option order symmetry for personality
measurement of LLMs. Since most of the self-assessment tests exist in the form
of multiple choice question (MCQ) questions, we argue that the scores should
also be robust to not just the prompt template but also the order in which the
options are presented. This test unsurprisingly reveals that the answers to the
self-assessment tests are not robust to the order of the options. These simple
tests, done on ChatGPT and Llama2 models show that self-assessment personality
tests created for humans are not appropriate for measuring personality in LLMs.
</p>
</div>
</dd>
<dt><a name="item103">[103]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08164" title="Abstract">arXiv:2309.08164</a> [<a href="/pdf/2309.08164" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Ground Segmentation Method Based on Point Cloud Map for Unstructured  Roads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zixuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+H">Haiying Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhangyu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huazhi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+M">Miao Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jie Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Ground segmentation, as the basic task of unmanned intelligent perception,
provides an important support for the target detection task. Unstructured road
scenes represented by open-pit mines have irregular boundary lines and uneven
road surfaces, which lead to segmentation errors in current ground segmentation
methods. To solve this problem, a ground segmentation method based on point
cloud map is proposed, which involves three parts: region of interest
extraction, point cloud registration and background subtraction. Firstly,
establishing boundary semantic associations to obtain regions of interest in
unstructured roads. Secondly, establishing the location association between
point cloud map and the real-time point cloud of region of interest by
semantics information. Thirdly, establishing a background model based on
Gaussian distribution according to location association, and segments the
ground in real-time point cloud by the background substraction method.
Experimental results show that the correct segmentation rate of ground points
is 99.95%, and the running time is 26ms. Compared with state of the art ground
segmentation algorithm Patchwork++, the average accuracy of ground point
segmentation is increased by 7.43%, and the running time is increased by 17ms.
Furthermore, the proposed method is practically applied to unstructured road
scenarios represented by open pit mines.
</p>
</div>
</dd>
<dt><a name="item104">[104]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08165" title="Abstract">arXiv:2309.08165</a> [<a href="/pdf/2309.08165" title="Download PDF">pdf</a>, <a href="/format/2309.08165" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> To Predict or to Reject: Causal Effect Estimation with Uncertainty on  Networked Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+H">Hechuan Wen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chai%2C+L+K">Li Kheng Chai</a>, 
<a href="/search/cs?searchtype=author&query=Sadiq%2C+S">Shazia Sadiq</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+K">Kai Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+H">Hongzhi Yin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICDM'23
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Methodology (stat.ME)

</div>
<p class="mathjax">Due to the imbalanced nature of networked observational data, the causal
effect predictions for some individuals can severely violate the
positivity/overlap assumption, rendering unreliable estimations. Nevertheless,
this potential risk of individual-level treatment effect estimation on
networked data has been largely under-explored. To create a more trustworthy
causal effect estimator, we propose the uncertainty-aware graph deep kernel
learning (GraphDKL) framework with Lipschitz constraint to model the prediction
uncertainty with Gaussian process and identify unreliable estimations. To the
best of our knowledge, GraphDKL is the first framework to tackle the violation
of positivity assumption when performing causal effect estimation with graphs.
With extensive experiments, we demonstrate the superiority of our proposed
method in uncertainty-aware causal effect estimation on networked data.
</p>
</div>
</dd>
<dt><a name="item105">[105]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08166" title="Abstract">arXiv:2309.08166</a> [<a href="/pdf/2309.08166" title="Download PDF">pdf</a>, <a href="/format/2309.08166" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Controllable Residual Speaker Representation for Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Le Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+Y">Yong Ren</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+R">Rongxiu Zhong</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recently, there have been significant advancements in voice conversion,
resulting in high-quality performance. However, there are still two critical
challenges in this field. Firstly, current voice conversion methods have
limited robustness when encountering unseen speakers. Secondly, they also have
limited ability to control timbre representation. To address these challenges,
this paper presents a novel approach leverages tokens of multi-layer residual
approximations to enhance robustness when dealing with unseen speakers, called
the residual speaker module. The introduction of multi-layer approximations
facilitates the separation of information from the timbre, enabling effective
control over timbre in voice conversion. The proposed method outperforms
baselines in both subjective and objective evaluations, demonstrating superior
performance and increased robustness. Our demo page is publicly available.
</p>
</div>
</dd>
<dt><a name="item106">[106]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08167" title="Abstract">arXiv:2309.08167</a> [<a href="/pdf/2309.08167" title="Download PDF">pdf</a>, <a href="/format/2309.08167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Resolution Compression and Alignment for Efficient Video  Classification and Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deng%2C+R">Rui Deng</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Q">Qian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yuke Li</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+H">Haoran Fu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Optimizing video inference efficiency has become increasingly important with
the growing demand for video analysis in various fields. Some existing methods
achieve high efficiency by explicit discard of spatial or temporal information,
which poses challenges in fast-changing and fine-grained scenarios. To address
these issues, we propose an efficient video representation network with
Differentiable Resolution Compression and Alignment mechanism, which compresses
non-essential information in the early stage of the network to reduce
computational costs while maintaining consistent temporal correlations.
Specifically, we leverage a Differentiable Context-aware Compression Module to
encode the saliency and non-saliency frame features, refining and updating the
features into a high-low resolution video sequence. To process the new
sequence, we introduce a new Resolution-Align Transformer Layer to capture
global temporal correlations among frame features with different resolutions,
while reducing spatial computation costs quadratically by utilizing fewer
spatial tokens in low-resolution non-saliency frames. The entire network can be
end-to-end optimized via the integration of the differentiable compression
module. Experimental results show that our method achieves the best trade-off
between efficiency and performance on near-duplicate video retrieval and
competitive results on dynamic video classification compared to
state-of-the-art methods. Code:https://github.com/dun-research/DRCA
</p>
</div>
</dd>
<dt><a name="item107">[107]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08168" title="Abstract">arXiv:2309.08168</a> [<a href="/pdf/2309.08168" title="Download PDF">pdf</a>, <a href="/format/2309.08168" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Draft &amp; Verify: Lossless Large Language Model Acceleration via  Self-Speculative Decoding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jun Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jue Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Huan Li</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+L">Lidan Shou</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+K">Ke Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Mehrotra%2C+S">Sharad Mehrotra</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present a novel inference scheme, self-speculative decoding, for
accelerating Large Language Models (LLMs) without the need for an auxiliary
model. This approach is characterized by a two-stage process: drafting and
verification. The drafting stage generates draft tokens at a slightly lower
quality but more quickly, which is achieved by selectively skipping certain
intermediate layers during drafting Subsequently, the verification stage
employs the original LLM to validate those draft output tokens in one forward
pass. This process ensures the final output remains identical to that produced
by the unaltered LLM, thereby maintaining output quality. The proposed method
requires no additional neural network training and no extra memory footprint,
making it a plug-and-play and cost-effective solution for inference
acceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a
speedup up to 1.73$\times$.
</p>
</div>
</dd>
<dt><a name="item108">[108]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08171" title="Abstract">arXiv:2309.08171</a> [<a href="/pdf/2309.08171" title="Download PDF">pdf</a>, <a href="/format/2309.08171" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unveiling Invariances via Neural Network Pruning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Derek Xu</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yizhou Sun</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wei Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Invariance describes transformations that do not alter data's underlying
semantics. Neural networks that preserve natural invariance capture good
inductive biases and achieve superior performance. Hence, modern networks are
handcrafted to handle well-known invariances (ex. translations). We propose a
framework to learn novel network architectures that capture data-dependent
invariances via pruning. Our learned architectures consistently outperform
dense neural networks on both vision and tabular datasets in both efficiency
and effectiveness. We demonstrate our framework on multiple deep learning
models across 3 vision and 40 tabular datasets.
</p>
</div>
</dd>
<dt><a name="item109">[109]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08172" title="Abstract">arXiv:2309.08172</a> [<a href="/pdf/2309.08172" title="Download PDF">pdf</a>, <a href="/format/2309.08172" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LASER: LLM Agent with State-Space Exploration for Web Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+K">Kaixin Ma</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hongwei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+X">Xiaoman Pan</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Dong Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) have been successfully adapted for interactive
decision-making tasks like web navigation. While achieving decent performance,
previous methods implicitly assume a forward-only execution mode for the model,
where they only provide oracle trajectories as in-context examples to teach the
model how to reason in the interactive environment. Consequently, the model
could not handle more challenging scenarios not covered in the in-context
examples, e.g., mistakes, leading to sub-optimal performance. To address this
issue, we propose to model the interactive task as state space exploration,
where the LLM agent transitions among a pre-defined set of states by performing
actions to complete the task. This formulation enables flexible back-tracking,
allowing the model to easily recover from errors. We evaluate our proposed LLM
Agent with State-Space ExploRation (LASER) on the WebShop task. Experimental
results show that our LASER agent significantly outperforms previous methods
and closes the gap with human performance on the web navigation task.
</p>
</div>
</dd>
<dt><a name="item110">[110]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08173" title="Abstract">arXiv:2309.08173</a> [<a href="/pdf/2309.08173" title="Download PDF">pdf</a>, <a href="/format/2309.08173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedJudge: Federated Legal Large Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yue%2C+L">Linan Yue</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yichao Du</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+W">Weibo Gao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+F">Fangzhou Yao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large Language Models (LLMs) have gained prominence in the field of Legal
Intelligence, offering potential applications in assisting legal professionals
and laymen. However, the centralized training of these Legal LLMs raises data
privacy concerns, as legal data is distributed among various institutions
containing sensitive individual information. This paper addresses this
challenge by exploring the integration of Legal LLMs with Federated Learning
(FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on
devices or clients, and their parameters are aggregated and distributed on a
central server, ensuring data privacy without directly sharing raw data.
However, computation and communication overheads hinder the full fine-tuning of
LLMs under the FL setting. Moreover, the distribution shift of legal data
reduces the effectiveness of FL methods. To this end, in this paper, we propose
the first Federated Legal Large Language Model (FedJudge) framework, which
fine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge
utilizes parameter-efficient fine-tuning methods to update only a few
additional parameters during the FL training. Besides, we explore the continual
learning methods to preserve the global model's important parameters when
training local clients to mitigate the problem of data shifts. Extensive
experimental results on three real-world datasets clearly validate the
effectiveness of FedJudge. Code is released at
https://github.com/yuelinan/FedJudge.
</p>
</div>
</dd>
<dt><a name="item111">[111]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08177" title="Abstract">arXiv:2309.08177</a> [<a href="/pdf/2309.08177" title="Download PDF">pdf</a>, <a href="/ps/2309.08177" title="Download PostScript">ps</a>, <a href="/format/2309.08177" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Message Passing-Based Joint Channel Estimation and Signal Detection for  OTFS with Superimposed Pilots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+F">Fupeng Huang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qinghua Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youwen Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zakharov%2C+Y">Yuriy Zakharov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Receivers with joint channel estimation and signal detection using
superimposed pilots (SP) can achieve high transmission efficiency in orthogonal
time frequency space (OTFS) systems. However, existing receivers have high
computational complexity, hindering their practical applications. In this work,
with SP in the delay-Doppler (DD) domain and the generalized complex
exponential (GCE) basis expansion modeling (BEM) for channels, a message
passing-based SP-DD iterative receiver is proposed, which drastically reduces
the computational complexity while with marginal performance loss, compared to
existing ones. To facilitate channel estimation (CE) in the proposed receiver,
we design pilot signal to achieve pilot power concentration in the frequency
domain, thereby developing an SP-DD-D receiver that can effectively reduce the
power of the pilot signal and almost no loss of CE accuracy. Extensive
simulation results are provided to demonstrate the superiority of the proposed
SP-DD-D receiver.
</p>
</div>
</dd>
<dt><a name="item112">[112]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08178" title="Abstract">arXiv:2309.08178</a> [<a href="/pdf/2309.08178" title="Download PDF">pdf</a>, <a href="/format/2309.08178" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Safe and Individualized Motion Planning for Upper-limb Exoskeleton  Robots Using Human Demonstration and Interactive Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+G">Gong Chen</a>, 
<a href="/search/cs?searchtype=author&query=Ye%2C+J">Jing Ye</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xiangjun Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Has been submitted to ICRA_2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A typical application of upper-limb exoskeleton robots is deployment in
rehabilitation training, helping patients to regain manipulative abilities.
However, as the patient is not always capable of following the robot, safety
issues may arise during the training. Due to the bias in different patients, an
individualized scheme is also important to ensure that the robot suits the
specific conditions (e.g., movement habits) of a patient, hence guaranteeing
effectiveness. To fulfill this requirement, this paper proposes a new motion
planning scheme for upper-limb exoskeleton robots, which drives the robot to
provide customized, safe, and individualized assistance using both human
demonstration and interactive learning. Specifically, the robot first learns
from a group of healthy subjects to generate a reference motion trajectory via
probabilistic movement primitives (ProMP). It then learns from the patient
during the training process to further shape the trajectory inside a moving
safe region. The interactive data is fed back into the ProMP iteratively to
enhance the individualized features for as long as the training process
continues. The robot tracks the individualized trajectory under a variable
impedance model to realize the assistance. Finally, the experimental results
are presented in this paper to validate the proposed control scheme.
</p>
</div>
</dd>
<dt><a name="item113">[113]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08179" title="Abstract">arXiv:2309.08179</a> [<a href="/pdf/2309.08179" title="Download PDF">pdf</a>, <a href="/format/2309.08179" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> STDG: Semi-Teacher-Student Training Paradigram for Depth-guided  One-stage Scene Graph Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+X">Xukun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Z">Zhenbo Song</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jun He</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hongyan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Z">Zhaoxin Fan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Scene Graph Generation is a critical enabler of environmental comprehension
for autonomous robotic systems. Most of existing methods, however, are often
thwarted by the intricate dynamics of background complexity, which limits their
ability to fully decode the inherent topological information of the
environment. Additionally, the wealth of contextual information encapsulated
within depth cues is often left untapped, rendering existing approaches less
effective. To address these shortcomings, we present STDG, an avant-garde
Depth-Guided One-Stage Scene Graph Generation methodology. The innovative
architecture of STDG is a triad of custom-built modules: The Depth Guided HHA
Representation Generation Module, the Depth Guided Semi-Teaching Network
Learning Module, and the Depth Guided Scene Graph Generation Module. This
trifecta of modules synergistically harnesses depth information, covering all
aspects from depth signal generation and depth feature utilization, to the
final scene graph prediction. Importantly, this is achieved without imposing
additional computational burden during the inference phase. Experimental
results confirm that our method significantly enhances the performance of
one-stage scene graph generation baselines.
</p>
</div>
</dd>
<dt><a name="item114">[114]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08180" title="Abstract">arXiv:2309.08180</a> [<a href="/pdf/2309.08180" title="Download PDF">pdf</a>, <a href="/format/2309.08180" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AVM-SLAM: Semantic Visual SLAM with Multi-Sensor Fusion in a Bird&#x27;s Eye  View for Automated Valet Parking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Ye Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wenchao Yang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Ju Tao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qianlei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Cui%2C+Z">Zhe Cui</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xiaolin Qin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA2024 for review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Automated Valet Parking (AVP) requires precise localization in challenging
garage conditions, including poor lighting, sparse textures, repetitive
structures, dynamic scenes, and the absence of Global Positioning System (GPS)
signals, which often pose problems for conventional localization methods. To
address these adversities, we present AVM-SLAM, a semantic visual SLAM
framework with multi-sensor fusion in a Bird's Eye View (BEV). Our framework
integrates four fisheye cameras, four wheel encoders, and an Inertial
Measurement Unit (IMU). The fisheye cameras form an Around View Monitor (AVM)
subsystem, generating BEV images. Convolutional Neural Networks (CNNs) extract
semantic features from these images, aiding in mapping and localization tasks.
These semantic features provide long-term stability and perspective invariance,
effectively mitigating environmental challenges. Additionally, data fusion from
wheel encoders and IMU enhances system robustness by improving motion
estimation and reducing drift. To validate AVM-SLAM's efficacy and robustness,
we provide a large-scale, high-resolution underground garage dataset, available
at https://github.com/yale-cv/avm-slam. This dataset enables researchers to
further explore and assess AVM-SLAM in similar environments.
</p>
</div>
</dd>
<dt><a name="item115">[115]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08181" title="Abstract">arXiv:2309.08181</a> [<a href="/pdf/2309.08181" title="Download PDF">pdf</a>, <a href="/format/2309.08181" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Language Models for Failure Mode Classification: An Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stewart%2C+M">Michael Stewart</a>, 
<a href="/search/cs?searchtype=author&query=Hodkiewicz%2C+M">Melinda Hodkiewicz</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sirui Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">In this paper we present the first investigation into the effectiveness of
Large Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the
task of automatically labelling an observation with a corresponding failure
mode code, is a critical task in the maintenance domain as it reduces the need
for reliability engineers to spend their time manually analysing work orders.
We detail our approach to prompt engineering to enable an LLM to predict the
failure mode of a given observation using a restricted code list. We
demonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on
annotated data is a significant improvement over a currently available text
classification model (F1=0.60) trained on the same annotated data set. The
fine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This
investigation reinforces the need for high quality fine-tuning data sets for
domain-specific tasks using LLMs.
</p>
</div>
</dd>
<dt><a name="item116">[116]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08182" title="Abstract">arXiv:2309.08182</a> [<a href="/pdf/2309.08182" title="Download PDF">pdf</a>, <a href="/format/2309.08182" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Model to Solve and Explain Physics Word Problems  Approaching Human Level
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+J">Jingzhe Ding</a>, 
<a href="/search/cs?searchtype=author&query=Cen%2C+Y">Yan Cen</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinyuan Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Our work demonstrates that large language model (LLM) pre-trained on texts
can not only solve pure math word problems, but also physics word
problems-problems to be solved by calculation and inference based on some prior
physical knowledge. We collect and annotate the first physics word problem
dataset-PhysQA, which contains over 1000 junior high school physics word
problems (on Kinematics, Mass&amp;Density, Mechanics, Heat, Electricity). Then we
use OpenAI' s GPT3.5 to generate the answer of these problems and found that
GPT3.5 could automatically solve 49.3% of the problems on zero-shot learning
and 73.2% on few-shot learning. This result show that by using similar problem
and its answer as prompt, LLM could solve elementary physics word problems
approaching human level. Besides automatically solving problems, GPT3.5 could
also summarize the knowledge or topic examined by the problem, generate the
relevant explanation, and synthesis new physics word problems according tothe
input problems.Our work is the first research on automatically solving,
explaining and generating physics word problems of multiple types and scenes,
and we gain an acceptable and state-of-art accuracy, which demonstrates the
potential of LLM's further application in the field of secondary education.
</p>
</div>
</dd>
<dt><a name="item117">[117]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08185" title="Abstract">arXiv:2309.08185</a> [<a href="/pdf/2309.08185" title="Download PDF">pdf</a>, <a href="/format/2309.08185" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Multilingual Sentence-Level Semantic Search using Meta-Distillation  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=M%27hamdi%2C+M">Meryem M&#x27;hamdi</a>, 
<a href="/search/cs?searchtype=author&query=May%2C+J">Jonathan May</a>, 
<a href="/search/cs?searchtype=author&query=Dernoncourt%2C+F">Franck Dernoncourt</a>, 
<a href="/search/cs?searchtype=author&query=Bui%2C+T">Trung Bui</a>, 
<a href="/search/cs?searchtype=author&query=Yoon%2C+S">Seunghyun Yoon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Multilingual semantic search is the task of retrieving relevant contents to a
query expressed in different language combinations. This requires a better
semantic understanding of the user's intent and its contextual meaning.
Multilingual semantic search is less explored and more challenging than its
monolingual or bilingual counterparts, due to the lack of multilingual parallel
resources for this task and the need to circumvent "language bias". In this
work, we propose an alignment approach: MAML-Align, specifically for
low-resource scenarios. Our approach leverages meta-distillation learning based
on MAML, an optimization-based Model-Agnostic Meta-Learner. MAML-Align distills
knowledge from a Teacher meta-transfer model T-MAML, specialized in
transferring from monolingual to bilingual semantic search, to a Student model
S-MAML, which meta-transfers from bilingual to multilingual semantic search. To
the best of our knowledge, we are the first to extend meta-distillation to a
multilingual search application. Our empirical results show that on top of a
strong baseline based on sentence transformers, our meta-distillation approach
boosts the gains provided by MAML and significantly outperforms naive
fine-tuning methods. Furthermore, multilingual meta-distillation learning
improves generalization even to unseen languages.
</p>
</div>
</dd>
<dt><a name="item118">[118]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08186" title="Abstract">arXiv:2309.08186</a> [<a href="/pdf/2309.08186" title="Download PDF">pdf</a>, <a href="/format/2309.08186" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Precision-Scalable RISC-V DNN Processor with On-Device Learning  Capability at the Extreme Edge
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Longwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+C">Chao Fang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qiong Li</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+J">Jun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhongfeng Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To appear in the 29th Asia and South Pacific Design Automation Conference (ASP-DAC 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Hardware Architecture (cs.AR)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Extreme edge platforms, such as in-vehicle smart devices, require efficient
deployment of quantized deep neural networks (DNNs) to enable intelligent
applications with limited amounts of energy, memory, and computing resources.
However, many edge devices struggle to boost inference throughput of various
quantized DNNs due to the varying quantization levels, and these devices lack
floating-point (FP) support for on-device learning, which prevents them from
improving model accuracy while ensuring data privacy. To tackle the challenges
above, we propose a precision-scalable RISC-V DNN processor with on-device
learning capability. It facilitates diverse precision levels of fixed-point DNN
inference, spanning from 2-bit to 16-bit, and enhances on-device learning
through improved support with FP16 operations. Moreover, we employ multiple
methods such as FP16 multiplier reuse and multi-precision integer multiplier
reuse, along with balanced mapping of FPGA resources, to significantly improve
hardware resource utilization. Experimental results on the Xilinx ZCU102 FPGA
show that our processor significantly improves inference throughput by
1.6$\sim$14.6$\times$ and energy efficiency by 1.1$\sim$14.6$\times$ across
various DNNs, compared to the prior art, XpulpNN. Additionally, our processor
achieves a 16.5$\times$ higher FP throughput for on-device learning.
</p>
</div>
</dd>
<dt><a name="item119">[119]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08187" title="Abstract">arXiv:2309.08187</a> [<a href="/pdf/2309.08187" title="Download PDF">pdf</a>, <a href="/format/2309.08187" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Encoded Summarization: Summarizing Documents into Continuous Vector  Space for Legal Case Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tran%2C+V">Vu Tran</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+M+L">Minh Le Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Tojo%2C+S">Satoshi Tojo</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+K">Ken Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published 2020-01-25 in AI and Law. arXiv admin note: text overlap with <a href="/abs/2009.14083">arXiv:2009.14083</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">We present our method for tackling a legal case retrieval task by introducing
our method of encoding documents by summarizing them into continuous vector
space via our phrase scoring framework utilizing deep neural networks. On the
other hand, we explore the benefits from combining lexical features and latent
features generated with neural networks. Our experiments show that lexical
features and latent features generated with neural networks complement each
other to improve the retrieval system performance. Furthermore, our
experimental results suggest the importance of case summarization in different
aspects: using provided summaries and performing encoded summarization. Our
approach achieved F1 of 65.6% and 57.6% on the experimental datasets of legal
case retrieval tasks.
</p>
</div>
</dd>
<dt><a name="item120">[120]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08188" title="Abstract">arXiv:2309.08188</a> [<a href="/pdf/2309.08188" title="Download PDF">pdf</a>, <a href="/format/2309.08188" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Privacy-Aware Joint Source-Channel Coding for image transmission based  on Disentangled Information Bottleneck
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+L">Lunan Sun</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+C">Caili Guo</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Mingzhe Chen</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Current privacy-aware joint source-channel coding (JSCC) works aim at
avoiding private information transmission by adversarially training the JSCC
encoder and decoder under specific signal-to-noise ratios (SNRs) of
eavesdroppers. However, these approaches incur additional computational and
storage requirements as multiple neural networks must be trained for various
eavesdroppers' SNRs to determine the transmitted information. To overcome this
challenge, we propose a novel privacy-aware JSCC for image transmission based
on disentangled information bottleneck (DIB-PAJSCC). In particular, we derive a
novel disentangled information bottleneck objective to disentangle private and
public information. Given the separate information, the transmitter can
transmit only public information to the receiver while minimizing
reconstruction distortion. Since DIB-PAJSCC transmits only public information
regardless of the eavesdroppers' SNRs, it can eliminate additional training
adapted to eavesdroppers' SNRs. Experimental results show that DIB-PAJSCC can
reduce the eavesdropping accuracy on private information by up to 20\% compared
to existing methods.
</p>
</div>
</dd>
<dt><a name="item121">[121]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08190" title="Abstract">arXiv:2309.08190</a> [<a href="/pdf/2309.08190" title="Download PDF">pdf</a>, <a href="/format/2309.08190" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning in the Dark: Privacy-Preserving Machine Learning using Function  Approximation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khan%2C+T">Tanveer Khan</a>, 
<a href="/search/cs?searchtype=author&query=Michalas%2C+A">Antonis Michalas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2107.14338">arXiv:2107.14338</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Over the past few years, a tremendous growth of machine learning was brought
about by a significant increase in adoption and implementation of cloud-based
services. As a result, various solutions have been proposed in which the
machine learning models run on a remote cloud provider and not locally on a
user's machine. However, when such a model is deployed on an untrusted cloud
provider, it is of vital importance that the users' privacy is preserved. To
this end, we propose Learning in the Dark -- a hybrid machine learning model in
which the training phase occurs in plaintext data, but the classification of
the users' inputs is performed directly on homomorphically encrypted
ciphertexts. To make our construction compatible with homomorphic encryption,
we approximate the ReLU and Sigmoid activation functions using low-degree
Chebyshev polynomials. This allowed us to build Learning in the Dark -- a
privacy-preserving machine learning model that can classify encrypted images
with high accuracy. Learning in the Dark preserves users' privacy since it is
capable of performing high accuracy predictions by performing computations
directly on encrypted data. In addition to that, the output of Learning in the
Dark is generated in a blind and therefore privacy-preserving way by utilizing
the properties of homomorphic encryption.
</p>
</div>
</dd>
<dt><a name="item122">[122]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08196" title="Abstract">arXiv:2309.08196</a> [<a href="/pdf/2309.08196" title="Download PDF">pdf</a>, <a href="/format/2309.08196" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ECEA: Extensible Co-Existing Attention for Few-Shot Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xin%2C+Z">Zhimeng Xin</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tianxu Wu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yixiong Zou</a>, 
<a href="/search/cs?searchtype=author&query=Shao%2C+L">Ling Shao</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+X">Xinge You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Few-shot object detection (FSOD) identifies objects from extremely few
annotated samples. Most existing FSOD methods, recently, apply the two-stage
learning paradigm, which transfers the knowledge learned from abundant base
classes to assist the few-shot detectors by learning the global features.
However, such existing FSOD approaches seldom consider the localization of
objects from local to global. Limited by the scarce training data in FSOD, the
training samples of novel classes typically capture part of objects, resulting
in such FSOD methods cannot detect the completely unseen object during testing.
To tackle this problem, we propose an Extensible Co-Existing Attention (ECEA)
module to enable the model to infer the global object according to the local
parts. Essentially, the proposed module continuously learns the extensible
ability on the base stage with abundant samples and transfers it to the novel
stage, which can assist the few-shot model to quickly adapt in extending local
regions to co-existing regions. Specifically, we first devise an extensible
attention mechanism that starts with a local region and extends attention to
co-existing regions that are similar and adjacent to the given local region. We
then implement the extensible attention mechanism in different feature scales
to progressively discover the full object in various receptive fields.
Extensive experiments on the PASCAL VOC and COCO datasets show that our ECEA
module can assist the few-shot detector to completely predict the object
despite some regions failing to appear in the training samples and achieve the
new state of the art compared with existing FSOD methods.
</p>
</div>
</dd>
<dt><a name="item123">[123]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08198" title="Abstract">arXiv:2309.08198</a> [<a href="/pdf/2309.08198" title="Download PDF">pdf</a>, <a href="/format/2309.08198" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling up prime factorization with self-organizing gates: A  memcomputing approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharp%2C+T">Tristan Sharp</a>, 
<a href="/search/cs?searchtype=author&query=Khare%2C+R">Rishabh Khare</a>, 
<a href="/search/cs?searchtype=author&query=Pederson%2C+E">Erick Pederson</a>, 
<a href="/search/cs?searchtype=author&query=Traversa%2C+F+L">Fabio Lorenzo Traversa</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Cryptography and Security (cs.CR); Adaptation and Self-Organizing Systems (nlin.AO)

</div>
<p class="mathjax">We report preliminary results on using the MEMCPU\texttrademark{} Platform to
compute the prime factorization of large biprimes. The first approach, the
direct model, directly returns the factors of a given biprime. The second
approach, the congruence model, returns smooth congruences to address the
bottleneck of standard sieve methods. The models have size-dependent structure,
and the MEMCPU Platform requires structure-dependent tuning for optimal
performance. Therefore, for both models, we tuned the platform on sample
problems up to a given size according to available resources. Then we generated
RSA-like benchmark biprimes to perform rigorous scaling analysis. The MEMCPU
timings over the tuned range followed low degree polynomials in the number of
bits, markedly different than other tested methods including general number
field sieve. MEMCPU's congruence model was the most promising, which was scaled
up to 300-bit factorization problems while following a $2^{nd}$ degree
polynomial fit. We also discuss the approach to tuning the MEMCPU Platform for
problems beyond the reach of today's most advanced methods. Finally, basic
analysis of the acceleration expected from an ASIC implementation is provided
and suggests the possibility of real time factorization of large biprimes.
</p>
</div>
</dd>
<dt><a name="item124">[124]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08200" title="Abstract">arXiv:2309.08200</a> [<a href="/pdf/2309.08200" title="Download PDF">pdf</a>, <a href="/format/2309.08200" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity  Acoustic Scene Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cai%2C+Y">Yiqiang Cai</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peihong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shengchen Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the 2024 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Recent studies focus on developing efficient systems for acoustic scene
classification (ASC) using convolutional neural networks (CNNs), which
typically consist of consecutive kernels. This paper highlights the benefits of
using separate kernels as a more powerful and efficient design approach in ASC
tasks. Inspired by the time-frequency nature of audio signals, we propose
TF-SepNet, a CNN architecture that separates the feature processing along the
time and frequency dimensions. Features resulted from the separate paths are
then merged by channels and directly forwarded to the classifier. Instead of
the conventional two dimensional (2D) kernel, TF-SepNet incorporates one
dimensional (1D) kernels to reduce the computational costs. Experiments have
been conducted using the TAU Urban Acoustic Scene 2022 Mobile development
dataset. The results show that TF-SepNet outperforms similar state-of-the-arts
that use consecutive kernels. A further investigation reveals that the separate
kernels lead to a larger effective receptive field (ERF), which enables
TF-SepNet to capture more time-frequency features.
</p>
</div>
</dd>
<dt><a name="item125">[125]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08201" title="Abstract">arXiv:2309.08201</a> [<a href="/pdf/2309.08201" title="Download PDF">pdf</a>, <a href="/format/2309.08201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Gaussian Processes with Linear Multiple Kernel: Spectrum Design and  Distributed Learning for Multi-Dimensional Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Suwandi%2C+R+C">Richard Cornelius Suwandi</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Z">Zhidi Lin</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+F">Feng Yin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Optimization and Control (math.OC)

</div>
<p class="mathjax">Gaussian processes (GPs) have emerged as a prominent technique for machine
learning and signal processing. A key component in GP modeling is the choice of
kernel, and linear multiple kernels (LMKs) have become an attractive kernel
class due to their powerful modeling capacity and interpretability. This paper
focuses on the grid spectral mixture (GSM) kernel, an LMK that can approximate
arbitrary stationary kernels. Specifically, we propose a novel GSM kernel
formulation for multi-dimensional data that reduces the number of
hyper-parameters compared to existing formulations, while also retaining a
favorable optimization structure and approximation capability. In addition, to
make the large-scale hyper-parameter optimization in the GSM kernel tractable,
we first introduce the distributed SCA (DSCA) algorithm. Building on this, we
propose the doubly distributed SCA (D$^2$SCA) algorithm based on the
alternating direction method of multipliers (ADMM) framework, which allows us
to cooperatively learn the GSM kernel in the context of big data while
maintaining data privacy. Furthermore, we tackle the inherent communication
bandwidth restriction in distributed frameworks, by quantizing the
hyper-parameters in D$^2$SCA, resulting in the quantized doubly distributed SCA
(QD$^2$SCA) algorithm. Theoretical analysis establishes convergence guarantees
for the proposed algorithms, while experiments on diverse datasets demonstrate
the superior prediction performance and efficiency of our methods.
</p>
</div>
</dd>
<dt><a name="item126">[126]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08204" title="Abstract">arXiv:2309.08204</a> [<a href="/pdf/2309.08204" title="Download PDF">pdf</a>, <a href="/format/2309.08204" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-stage Modality Distillation for Incomplete Multimodal Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+S">Shicai Wei</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yang Luo</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+C">Chunbo Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Learning based on multimodal data has attracted increasing interest recently.
While a variety of sensory modalities can be collected for training, not all of
them are always available in development scenarios, which raises the challenge
to infer with incomplete modality. To address this issue, this paper presents a
one-stage modality distillation framework that unifies the privileged knowledge
transfer and modality information fusion into a single optimization procedure
via multi-task learning. Compared with the conventional modality distillation
that performs them independently, this helps to capture the valuable
representation that can assist the final model inference directly.
Specifically, we propose the joint adaptation network for the modality transfer
task to preserve the privileged information. This addresses the representation
heterogeneity caused by input discrepancy via the joint distribution
adaptation. Then, we introduce the cross translation network for the modality
fusion task to aggregate the restored and available modality features. It
leverages the parameters-sharing strategy to capture the cross-modal cues
explicitly. Extensive experiments on RGB-D classification and segmentation
tasks demonstrate the proposed multimodal inheritance framework can overcome
the problem of incomplete modality input in various scenes and achieve
state-of-the-art performance.
</p>
</div>
</dd>
<dt><a name="item127">[127]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08206" title="Abstract">arXiv:2309.08206</a> [<a href="/pdf/2309.08206" title="Download PDF">pdf</a>, <a href="/format/2309.08206" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Salient Object Detection in Optical Remote Sensing Images Driven by  Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gongyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Z">Zhen Bai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Zhi Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinpeng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+H">Haibin Ling</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 6 figures, Accepted by IEEE Transactions on Image Processing 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Existing methods for Salient Object Detection in Optical Remote Sensing
Images (ORSI-SOD) mainly adopt Convolutional Neural Networks (CNNs) as the
backbone, such as VGG and ResNet. Since CNNs can only extract features within
certain receptive fields, most ORSI-SOD methods generally follow the
local-to-contextual paradigm. In this paper, we propose a novel Global
Extraction Local Exploration Network (GeleNet) for ORSI-SOD following the
global-to-local paradigm. Specifically, GeleNet first adopts a transformer
backbone to generate four-level feature embeddings with global long-range
dependencies. Then, GeleNet employs a Direction-aware Shuffle Weighted Spatial
Attention Module (D-SWSAM) and its simplified version (SWSAM) to enhance local
interactions, and a Knowledge Transfer Module (KTM) to further enhance
cross-level contextual interactions. D-SWSAM comprehensively perceives the
orientation information in the lowest-level features through directional
convolutions to adapt to various orientations of salient objects in ORSIs, and
effectively enhances the details of salient objects with an improved attention
mechanism. SWSAM discards the direction-aware part of D-SWSAM to focus on
localizing salient objects in the highest-level features. KTM models the
contextual correlation knowledge of two middle-level features of different
scales based on the self-attention mechanism, and transfers the knowledge to
the raw features to generate more discriminative features. Finally, a saliency
predictor is used to generate the saliency map based on the outputs of the
above three modules. Extensive experiments on three public datasets demonstrate
that the proposed GeleNet outperforms relevant state-of-the-art methods. The
code and results of our method are available at
https://github.com/MathLee/GeleNet.
</p>
</div>
</dd>
<dt><a name="item128">[128]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08207" title="Abstract">arXiv:2309.08207</a> [<a href="/pdf/2309.08207" title="Download PDF">pdf</a>, <a href="/format/2309.08207" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MetaOCaml Theory and Implementation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselyov%2C+O">Oleg Kiselyov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Peer-reviewed, accepted for presentation and presented at the ACM SIGPLAN OCAML 2023 workshop
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>

</div>
<p class="mathjax">Quasi-quotation (or, code templates) has long been used as a convenient tool
for code generation, commonly implemented as a pre-processing/translation into
code-generation combinators. The original MetaOCaml was also based on such
translation, done post type checking. BER MetaOCaml employs a significantly
different, efficient (especially in version N114) translation integrated with
type-checking, in the least intrusive way. This paper presents the integrated
efficient translation for the first time.
</p>
</div>
</dd>
<dt><a name="item129">[129]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08208" title="Abstract">arXiv:2309.08208</a> [<a href="/pdf/2309.08208" title="Download PDF">pdf</a>, <a href="/format/2309.08208" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HM-Conformer: A Conformer-based audio deepfake detection system with  hierarchical pooling and multi-level classification token aggregation methods
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shin%2C+H">Hyun-seo Shin</a>, 
<a href="/search/cs?searchtype=author&query=Heo%2C+J">Jungwoo Heo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J">Ju-ho Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+C">Chan-yeong Lim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+W">Wonbin Kim</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Ha-Jin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2024)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Audio deepfake detection (ADD) is the task of detecting spoofing attacks
generated by text-to-speech or voice conversion systems. Spoofing evidence,
which helps to distinguish between spoofed and bona-fide utterances, might
exist either locally or globally in the input features. To capture these, the
Conformer, which consists of Transformers and CNN, possesses a suitable
structure. However, since the Conformer was designed for sequence-to-sequence
tasks, its direct application to ADD tasks may be sub-optimal. To tackle this
limitation, we propose HM-Conformer by adopting two components: (1)
Hierarchical pooling method progressively reducing the sequence length to
eliminate duplicated information (2) Multi-level classification token
aggregation method utilizing classification tokens to gather information from
different blocks. Owing to these components, HM-Conformer can efficiently
detect spoofing evidence by processing various sequence lengths and aggregating
them. In experimental results on the ASVspoof 2021 Deepfake dataset,
HM-Conformer achieved a 15.71% EER, showing competitive performance compared to
recent systems.
</p>
</div>
</dd>
<dt><a name="item130">[130]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08209" title="Abstract">arXiv:2309.08209</a> [<a href="/pdf/2309.08209" title="Download PDF">pdf</a>, <a href="/format/2309.08209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attitude Control and Low Cost Design of UAV Bicopter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fahmizal">Fahmizal</a>, 
<a href="/search/eess?searchtype=author&query=Nugroho%2C+H+A">Hanung Adi Nugroho</a>, 
<a href="/search/eess?searchtype=author&query=Cahyadi%2C+A+I">Adha Imam Cahyadi</a>, 
<a href="/search/eess?searchtype=author&query=Ardiyanto%2C+I">Igi Ardiyanto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper present a control system for the attitude and low cost design of a
Bicopter. The control system uses a PID controller that receives feedback from
an IMU to calculate control inputs that adjust the Bicopters attitude (roll,
pitch and yaw angles) which is resistant to disturbances (wind noise) on a test
bed. The control system is implemented on a hardware platform consisting of a
Bicopter, an IMU sensor, and a microcontroller with low cost design. In
mechanical design, the Bicopter is designed to more closely resemble the letter
"V" so that the distribution of the centre of mass (CoM) of the Bicopter can be
such that the servomotor torque reaction is parallel to the axis of rotation of
the Bicopter during the movement of the pitch angle attitude. In electronic
design, the Bicopter was developed using the ATmega328P microcontroller.
</p>
</div>
</dd>
<dt><a name="item131">[131]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08210" title="Abstract">arXiv:2309.08210</a> [<a href="/pdf/2309.08210" title="Download PDF">pdf</a>, <a href="/format/2309.08210" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Investigating Answerability of LLMs for Long-Form Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhat%2C+M+M">Meghana Moorthy Bhat</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+R">Rui Meng</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Ye Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yingbo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yavuz%2C+S">Semih Yavuz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">As we embark on a new era of LLMs, it becomes increasingly crucial to
understand their capabilities, limitations, and differences. Toward making
further progress in this direction, we strive to build a deeper understanding
of the gaps between massive LLMs (e.g., ChatGPT) and smaller yet effective
open-source LLMs and their distilled counterparts. To this end, we specifically
focus on long-form question answering (LFQA) because it has several practical
and impactful applications (e.g., troubleshooting, customer service, etc.) yet
is still understudied and challenging for LLMs. We propose a
question-generation method from abstractive summaries and show that generating
follow-up questions from summaries of long documents can create a challenging
setting for LLMs to reason and infer from long contexts. Our experimental
results confirm that: (1) our proposed method of generating questions from
abstractive summaries pose a challenging setup for LLMs and shows performance
gaps between LLMs like ChatGPT and open-source LLMs (Alpaca, Llama) (2)
open-source LLMs exhibit decreased reliance on context for generated questions
from the original document, but their generation capabilities drop
significantly on generated questions from summaries -- especially for longer
contexts (&gt;1024 tokens)
</p>
</div>
</dd>
<dt><a name="item132">[132]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08211" title="Abstract">arXiv:2309.08211</a> [<a href="/pdf/2309.08211" title="Download PDF">pdf</a>, <a href="/format/2309.08211" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Program Repair via Preference-based Ensemble Strategy
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhong%2C+W">Wenkang Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+K">Kui Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+T">Tongtong Xu</a>, 
<a href="/search/cs?searchtype=author&query=Bissyand%C3%A9%2C+T+F">Tegawend&#xe9; F. Bissyand&#xe9;</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+J">Jidong Ge</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+B">Bin Luo</a>, 
<a href="/search/cs?searchtype=author&query=Ng%2C+V">Vincent Ng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted by icse2024 early
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">To date, over 40 Automated Program Repair (APR) tools have been designed with
varying bug-fixing strategies, which have been demonstrated to have
complementary performance in terms of being effective for different bug
classes. Intuitively, it should be feasible to improve the overall bug-fixing
performance of APR via assembling existing tools. Unfortunately, simply
invoking all available APR tools for a given bug can result in unacceptable
costs on APR execution as well as on patch validation (via expensive testing).
Therefore, while assembling existing tools is appealing, it requires an
efficient strategy to reconcile the need to fix more bugs and the requirements
for practicality. In light of this problem, we propose a Preference-based
Ensemble Program Repair framework (P-EPR), which seeks to effectively rank APR
tools for repairing different bugs. P-EPR is the first non-learning-based APR
ensemble method that is novel in its exploitation of repair patterns as a major
source of knowledge for ranking APR tools and its reliance on a dynamic update
strategy that enables it to immediately exploit and benefit from newly derived
repair results. Experimental results show that P-EPR outperforms existing
strategies significantly both in flexibility and effectiveness.
</p>
</div>
</dd>
<dt><a name="item133">[133]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08214" title="Abstract">arXiv:2309.08214</a> [<a href="/pdf/2309.08214" title="Download PDF">pdf</a>, <a href="/format/2309.08214" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MTG: Mapless Trajectory Generator with Traversability Coverage for  Outdoor Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liang%2C+J">Jing Liang</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Peng Gao</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuesu Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Sathyamoorthy%2C+A+J">Adarsh Jagan Sathyamoorthy</a>, 
<a href="/search/cs?searchtype=author&query=Elnoor%2C+M">Mohamed Elnoor</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+M">Ming Lin</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present a novel learning algorithm for trajectory generation for outdoor
robot navigation. Our goal is to compute collision-free paths that also
satisfies the environment-specific traversability constraints. Our approach is
designed for global planning using limited onboard robot perception in mapless
environments and ensures comprehensive coverage of all traversable directions.
Our formulation uses a Conditional Variational Autoencoder (CVAE) generative
model that is enhanced with traversability constraints and an optimization
formulation used for the coverage. We highlight the benefits of our approach
over state-of-the-art trajectory generation approaches and demonstrate its
performance in challenging outdoor environments, including around buildings,
across intersections, along trails, and in off-road terrain, using a Clearpath
Husky and a Boston Dynamics Spot robot. In practice, our approach results in a
6% improvement in coverage of traversable areas and an 89% reduction in
trajectory portions residing in non-traversable regions.
</p>
</div>
</dd>
<dt><a name="item134">[134]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08216" title="Abstract">arXiv:2309.08216</a> [<a href="/pdf/2309.08216" title="Download PDF">pdf</a>, <a href="/format/2309.08216" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unified Risk Analysis for Weakly Supervised Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chiang%2C+C">Chao-Kai Chiang</a>, 
<a href="/search/cs?searchtype=author&query=Sugiyama%2C+M">Masashi Sugiyama</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Among the flourishing research of weakly supervised learning (WSL), we
recognize the lack of a unified interpretation of the mechanism behind the
weakly supervised scenarios, let alone a systematic treatment of the risk
rewrite problem, a crucial step in the empirical risk minimization approach. In
this paper, we introduce a framework providing a comprehensive understanding
and a unified methodology for WSL. The formulation component of the framework,
leveraging a contamination perspective, provides a unified interpretation of
how weak supervision is formed and subsumes fifteen existing WSL settings. The
induced reduction graphs offer comprehensive connections over WSLs. The
analysis component of the framework, viewed as a decontamination process,
provides a systematic method of conducting risk rewrite. In addition to the
conventional inverse matrix approach, we devise a novel strategy called
marginal chain aiming to decontaminate distributions. We justify the
feasibility of the proposed framework by recovering existing rewrites reported
in the literature.
</p>
</div>
</dd>
<dt><a name="item135">[135]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08220" title="Abstract">arXiv:2309.08220</a> [<a href="/pdf/2309.08220" title="Download PDF">pdf</a>, <a href="/format/2309.08220" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UniST: Towards Unifying Saliency Transformer for Video Saliency  Prediction and Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiong%2C+J">Junwen Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chuanyue Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zha%2C+Y">Yufei Zha</a>, 
<a href="/search/cs?searchtype=author&query=You%2C+T">Tao You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Video saliency prediction and detection are thriving research domains that
enable computers to simulate the distribution of visual attention akin to how
humans perceiving dynamic scenes. While many approaches have crafted
task-specific training paradigms for either video saliency prediction or video
salient object detection tasks, few attention has been devoted to devising a
generalized saliency modeling framework that seamlessly bridges both these
distinct tasks. In this study, we introduce the Unified Saliency Transformer
(UniST) framework, which comprehensively utilizes the essential attributes of
video saliency prediction and video salient object detection. In addition to
extracting representations of frame sequences, a saliency-aware transformer is
designed to learn the spatio-temporal representations at progressively
increased resolutions, while incorporating effective cross-scale saliency
information to produce a robust representation. Furthermore, a task-specific
decoder is proposed to perform the final prediction for each task. To the best
of our knowledge, this is the first work that explores designing a transformer
structure for both saliency modeling tasks. Convincible experiments demonstrate
that the proposed UniST achieves superior performance across seven challenging
benchmarks for two tasks, and significantly outperforms the other
state-of-the-art methods.
</p>
</div>
</dd>
<dt><a name="item136">[136]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08221" title="Abstract">arXiv:2309.08221</a> [<a href="/pdf/2309.08221" title="Download PDF">pdf</a>, <a href="/format/2309.08221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the Potential of ChatGPT in Automated Code Refinement: An  Empirical Study
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qi Guo</a> (Tianjin University), 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Junming Cao</a> (Fudan University), 
<a href="/search/cs?searchtype=author&query=Xie%2C+X">Xiaofei Xie</a> (Singapore Management University), 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shangqing Liu</a> (Nanyang Technological University), 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaohong Li</a> (Tianjin University), 
<a href="/search/cs?searchtype=author&query=Chen%2C+B">Bihuan Chen</a> (Fudan University), 
<a href="/search/cs?searchtype=author&query=Peng%2C+X">Xin Peng</a> (Fudan University)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Code review is an essential activity for ensuring the quality and
maintainability of software projects. However, it is a time-consuming and often
error-prone task that can significantly impact the development process.
Recently, ChatGPT, a cutting-edge language model, has demonstrated impressive
performance in various natural language processing tasks, suggesting its
potential to automate code review processes. However, it is still unclear how
well ChatGPT performs in code review tasks. To fill this gap, in this paper, we
conduct the first empirical study to understand the capabilities of ChatGPT in
code review tasks, specifically focusing on automated code refinement based on
given code reviews. To conduct the study, we select the existing benchmark
CodeReview and construct a new code review dataset with high quality. We use
CodeReviewer, a state-of-the-art code review tool, as a baseline for comparison
with ChatGPT. Our results show that ChatGPT outperforms CodeReviewer in code
refinement tasks. Specifically, our results show that ChatGPT achieves higher
EM and BLEU scores of 22.78 and 76.44 respectively, while the state-of-the-art
method achieves only 15.50 and 62.88 on a high-quality code review dataset. We
further identify the root causes for ChatGPT's underperformance and propose
several strategies to mitigate these challenges. Our study provides insights
into the potential of ChatGPT in automating the code review process, and
highlights the potential research directions.
</p>
</div>
</dd>
<dt><a name="item137">[137]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08225" title="Abstract">arXiv:2309.08225</a> [<a href="/pdf/2309.08225" title="Download PDF">pdf</a>, <a href="/format/2309.08225" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Silent Vulnerability-fixing Commit Identification Based on Graph Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vo%2C+H+D">Hieu Dinh Vo</a>, 
<a href="/search/cs?searchtype=author&query=Vu%2C+T+T">Thanh Trong Vu</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+S">Son Nguyen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: substantial text overlap with <a href="/abs/2304.08396">arXiv:2304.08396</a>, <a href="/abs/2309.01971">arXiv:2309.01971</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">The growing dependence of software projects on external libraries has
generated apprehensions regarding the security of these libraries because of
concealed vulnerabilities. Handling these vulnerabilities presents difficulties
due to the temporal delay between remediation and public exposure. Furthermore,
a substantial fraction of open-source projects covertly address vulnerabilities
without any formal notification, influencing vulnerability management.
Established solutions like OWASP predominantly hinge on public announcements,
limiting their efficacy in uncovering undisclosed vulnerabilities. To address
this challenge, the automated identification of vulnerability-fixing commits
has come to the forefront. In this paper, we present VFFINDER, a novel
graph-based approach for automated silent vulnerability fix identification.
VFFINDER captures structural changes using Abstract Syntax Trees (ASTs) and
represents them in annotated ASTs. To precisely capture the meaning of code
changes, the changed code is represented in connection with the related
unchanged code. In VFFINDER, the structure of the changed code and related
unchanged code are captured and the structural changes are represented in
annotated Abstract Syntax Trees (aAST). VFFINDER distinguishes
vulnerability-fixing commits from non-fixing ones using attention-based graph
neural network models to extract structural features expressed in aASTs. We
conducted experiments to evaluate VFFINDER on a dataset of 11K+ vulnerability
fixing commits in 507 real-world C/C++ projects. Our results show that VFFINDER
significantly improves the state-of-the-art methods by 272-420% in Precision,
22-70% in Recall, and 3.2X-8.2X in F1. Especially, VFFINDER speeds up the
silent fix identification process by up to 121% with the same effort reviewing
50K LOC compared to the existing approaches.
</p>
</div>
</dd>
<dt><a name="item138">[138]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08226" title="Abstract">arXiv:2309.08226</a> [<a href="/pdf/2309.08226" title="Download PDF">pdf</a>, <a href="/format/2309.08226" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trajectory Tracking Control of UAV Bicopter using Linear Quadratic  Gaussian
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Fahmizal">Fahmizal</a>, 
<a href="/search/eess?searchtype=author&query=Nugroho%2C+H+A">Hanung Adi Nugroho</a>, 
<a href="/search/eess?searchtype=author&query=Cahyadi%2C+A+I">Adha Imam Cahyadi</a>, 
<a href="/search/eess?searchtype=author&query=Ardiyanto%2C+I">Igi Ardiyanto</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">This paper describes the design of a linear quadratic gaussian (LQG) for
trajectory tracking control of UAV Bicopter. In this work, disturbance in the
form of payload significantly affects the trajectory tracking control process
on the UAV Bicopter when using a linear quadratic regulator (LQR) controller.
The use of a LQR control will be optimal in the case of a state regulator
towards an equilibrium point in a system, but for the tracking case, the LQR
controller is not capable of optimally, especially in systems that have high
levels of nonlinearity and system dynamic changes such as inertial
disturbances. Therefore, this paper proposes the design of a LQG control that
is expected to overcome system dynamic changes, in this case in the form of
inertial disturbances to the UAV Bicopter when carrying a payload. The success
of LQG control was tested in two scenarios, the first trajectory tracking at a
circular position and the second with the position of the trajectory number
"8". The simulation results show that the proposed LQG controller successfully
overcame inertial disturbances when the UAV Bicopter performs trajectory
tracking. When given an inertial disturbance, the trajectory tracking test
results show that the LQG control has a lower root mean square error (RMSE)
value than the LQR control.
</p>
</div>
</dd>
<dt><a name="item139">[139]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08227" title="Abstract">arXiv:2309.08227</a> [<a href="/pdf/2309.08227" title="Download PDF">pdf</a>, <a href="/format/2309.08227" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VERSE: Virtual-Gradient Aware Streaming Lifelong Learning with Anytime  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+S">Soumya Banerjee</a>, 
<a href="/search/cs?searchtype=author&query=Verma%2C+V+K">Vinay K. Verma</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+A">Avideep Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+D">Deepak Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Namboodiri%2C+V+P">Vinay P. Namboodiri</a>, 
<a href="/search/cs?searchtype=author&query=Rai%2C+P">Piyush Rai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Lifelong learning, also referred to as continual learning, is the problem of
training an AI agent continuously while also preventing it from forgetting its
previously acquired knowledge. Most of the existing methods primarily focus on
lifelong learning within a static environment and lack the ability to mitigate
forgetting in a quickly-changing dynamic environment. Streaming lifelong
learning is a challenging setting of lifelong learning with the goal of
continuous learning in a dynamic non-stationary environment without forgetting.
We introduce a novel approach to lifelong learning, which is streaming,
requires a single pass over the data, can learn in a class-incremental manner,
and can be evaluated on-the-fly (anytime inference). To accomplish these, we
propose virtual gradients for continual representation learning to prevent
catastrophic forgetting and leverage an exponential-moving-average-based
semantic memory to further enhance performance. Extensive experiments on
diverse datasets demonstrate our method's efficacy and superior performance
over existing methods.
</p>
</div>
</dd>
<dt><a name="item140">[140]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08228" title="Abstract">arXiv:2309.08228</a> [<a href="/pdf/2309.08228" title="Download PDF">pdf</a>, <a href="/format/2309.08228" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Ensuring Toplogical Data-Structure Preservation under Autoencoder  Compression due to Latent Space Regularization in Gauss--Legendre nodes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramanaik%2C+C+K">Chethan Krishnamurthy Ramanaik</a>, 
<a href="/search/cs?searchtype=author&query=Cardona%2C+J+S">Juan-Esteban Suarez Cardona</a>, 
<a href="/search/cs?searchtype=author&query=Willmann%2C+A">Anna Willmann</a>, 
<a href="/search/cs?searchtype=author&query=Hanfeld%2C+P">Pia Hanfeld</a>, 
<a href="/search/cs?searchtype=author&query=Hoffmann%2C+N">Nico Hoffmann</a>, 
<a href="/search/cs?searchtype=author&query=Hecht%2C+M">Michael Hecht</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Differential Geometry (math.DG)

</div>
<p class="mathjax">We formulate a data independent latent space regularisation constraint for
general unsupervised autoencoders. The regularisation rests on sampling the
autoencoder Jacobian in Legendre nodes, being the centre of the Gauss-Legendre
quadrature. Revisiting this classic enables to prove that regularised
autoencoders ensure a one-to-one re-embedding of the initial data manifold to
its latent representation. Demonstrations show that prior proposed
regularisation strategies, such as contractive autoencoding, cause topological
defects already for simple examples, and so do convolutional based
(variational) autoencoders. In contrast, topological preservation is ensured
already by standard multilayer perceptron neural networks when being
regularised due to our contribution. This observation extends through the
classic FashionMNIST dataset up to real world encoding problems for MRI brain
scans, suggesting that, across disciplines, reliable low dimensional
representations of complex high-dimensional datasets can be delivered due to
this regularisation technique.
</p>
</div>
</dd>
<dt><a name="item141">[141]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08229" title="Abstract">arXiv:2309.08229</a> [<a href="/pdf/2309.08229" title="Download PDF">pdf</a>, <a href="/format/2309.08229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Multi-Drugs Administration During Total Intravenous Anesthesia  Using Multi-Model Predictive Control
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aubouin-Pairault%2C+B">Bob Aubouin-Pairault</a>, 
<a href="/search/eess?searchtype=author&query=Fiacchini%2C+M">Mirko Fiacchini</a>, 
<a href="/search/eess?searchtype=author&query=Dang%2C+T">Thao Dang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In this paper, a multi-model predictive control approach is used to automate
the co-administration of propofol and remifentanil from bispectral index
measurement during general anesthesia. To handle the parameter uncertainties in
the non-linear output function, multiple Extended Kalman Filters are used to
estimate the state of the system in parallel. The best model is chosen using a
model-matching criterion and used in a non-linear MPC to compute the next drug
rates. The method is compared with a conventional non-linear MPC approach and a
PID from the literature. The robustness of the controller is evaluated using
Monte-Carlo simulations on a wide population introducing uncertainties in the
models. Both simulation setup and controller codes are accessible in open
source for further use. Our preliminary results show the potential interest in
using a multi-model method to handle parameter uncertainties.
</p>
</div>
</dd>
<dt><a name="item142">[142]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08230" title="Abstract">arXiv:2309.08230</a> [<a href="/pdf/2309.08230" title="Download PDF">pdf</a>, <a href="/format/2309.08230" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in  Machine Unlearning Services
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+H">Hongsheng Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuo Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+J">Jiamin Chang</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+H">Haonan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+R">Ruoxi Sun</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+S">Shuang Hao</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+H">Haojin Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Xue%2C+M">Minhui Xue</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To Appear in the Network and Distributed System Security Symposium (NDSS) 2024, San Diego, CA, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">The right to be forgotten requires the removal or "unlearning" of a user's
data from machine learning models. However, in the context of Machine Learning
as a Service (MLaaS), retraining a model from scratch to fulfill the unlearning
request is impractical due to the lack of training data on the service
provider's side (the server). Furthermore, approximate unlearning further
embraces a complex trade-off between utility (model performance) and privacy
(unlearning performance). In this paper, we try to explore the potential
threats posed by unlearning services in MLaaS, specifically over-unlearning,
where more information is unlearned than expected. We propose two strategies
that leverage over-unlearning to measure the impact on the trade-off balancing,
under black-box access settings, in which the existing machine unlearning
attacks are not applicable. The effectiveness of these strategies is evaluated
through extensive experiments on benchmark datasets, across various model
architectures and representative unlearning approaches. Results indicate
significant potential for both strategies to undermine model efficacy in
unlearning scenarios. This study uncovers an underexplored gap between
unlearning and contemporary MLaaS, highlighting the need for careful
considerations in balancing data unlearning, model utility, and security.
</p>
</div>
</dd>
<dt><a name="item143">[143]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08232" title="Abstract">arXiv:2309.08232</a> [<a href="/pdf/2309.08232" title="Download PDF">pdf</a>, <a href="/format/2309.08232" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Astrocyte-Integrated Dynamic Function Exchange in Spiking Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Isik%2C+M">Murat Isik</a>, 
<a href="/search/cs?searchtype=author&query=Inadagbo%2C+K">Kayode Inadagbo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at 8th International Conference on Engineering of Computer-based Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">This paper presents an innovative methodology for improving the robustness
and computational efficiency of Spiking Neural Networks (SNNs), a critical
component in neuromorphic computing. The proposed approach integrates
astrocytes, a type of glial cell prevalent in the human brain, into SNNs,
creating astrocyte-augmented networks. To achieve this, we designed and
implemented an astrocyte model in two distinct platforms: CPU/GPU and FPGA. Our
FPGA implementation notably utilizes Dynamic Function Exchange (DFX)
technology, enabling real-time hardware reconfiguration and adaptive model
creation based on current operating conditions. The novel approach of
leveraging astrocytes significantly improves the fault tolerance of SNNs,
thereby enhancing their robustness. Notably, our astrocyte-augmented SNN
displays near-zero latency and theoretically infinite throughput, implying
exceptional computational efficiency. Through comprehensive comparative
analysis with prior works, it's established that our model surpasses others in
terms of neuron and synapse count while maintaining an efficient power
consumption profile. These results underscore the potential of our methodology
in shaping the future of neuromorphic computing, by providing robust and
energy-efficient systems.
</p>
</div>
</dd>
<dt><a name="item144">[144]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08235" title="Abstract">arXiv:2309.08235</a> [<a href="/pdf/2309.08235" title="Download PDF">pdf</a>, <a href="/format/2309.08235" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PRIEST: Projection Guided Sampling-Based Optimization For Autonomous  Navigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rastgar%2C+F">Fatemeh Rastgar</a>, 
<a href="/search/cs?searchtype=author&query=Masnavi%2C+H">Houman Masnavi</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+B">Basant Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Aabloo%2C+A">Alvo Aabloo</a>, 
<a href="/search/cs?searchtype=author&query=Swevers%2C+J">Jan Swevers</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+A+K">Arun Kumar Singh</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Efficient navigation in unknown and dynamic environments is crucial for
expanding the application domain of mobile robots. The core challenge stems
from the nonavailability of a feasible global path for guiding
optimization-based local planners. As a result, existing local planners often
get trapped in poor local minima. In this paper, we present a novel optimizer
that can explore multiple homotopies to plan high-quality trajectories over
long horizons while still being fast enough for real-time applications. We
build on the gradient-free paradigm by augmenting the trajectory sampling
strategy with a projection optimization that guides the samples toward a
feasible region. As a result, our approach can recover from the frequently
encountered pathological cases wherein all the sampled trajectories lie in the
high-cost region. Furthermore, we also show that our projection optimization
has a highly parallelizable structure that can be easily accelerated over GPUs.
We push the state-of-the-art in the following respects. Over the navigation
stack of the Robot Operating System (ROS), we show an improvement of 7-13% in
success rate and up to two times in total travel time metric. On the same
benchmarks and metrics, our approach achieves up to 44% improvement over MPPI
and its recent variants. On simple point-to-point navigation tasks, our
optimizer is up to two times more reliable than SOTA gradient-based solvers, as
well as sampling-based approaches such as the Cross-Entropy Method (CEM) and
VPSTO. Codes: https://github.com/fatemeh-rastgar/PRIEST
</p>
</div>
</dd>
<dt><a name="item145">[145]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08239" title="Abstract">arXiv:2309.08239</a> [<a href="/pdf/2309.08239" title="Download PDF">pdf</a>, <a href="/format/2309.08239" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Inspired Topological Representations for Visual Object Recognition  in Unseen Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samani%2C+E+U">Ekta U. Samani</a>, 
<a href="/search/cs?searchtype=author&query=Banerjee%2C+A+G">Ashis G. Banerjee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for presentation at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Workshop on Robotic Perception and Mapping: Frontier Vision &amp; Learning Techniques
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Visual object recognition in unseen and cluttered indoor environments is a
challenging problem for mobile robots. Toward this goal, we extend our previous
work to propose the TOPS2 descriptor, and an accompanying recognition
framework, THOR2, inspired by a human reasoning mechanism known as object
unity. We interleave color embeddings obtained using the Mapper algorithm for
topological soft clustering with the shape-based TOPS descriptor to obtain the
TOPS2 descriptor. THOR2, trained using synthetic data, achieves substantially
higher recognition accuracy than the shape-based THOR framework and outperforms
RGB-D ViT on two real-world datasets: the benchmark OCID dataset and the UW-IS
Occluded dataset. Therefore, THOR2 is a promising step toward achieving robust
recognition in low-cost robots.
</p>
</div>
</dd>
<dt><a name="item146">[146]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08244" title="Abstract">arXiv:2309.08244</a> [<a href="/pdf/2309.08244" title="Download PDF">pdf</a>, <a href="/format/2309.08244" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Real-time Faint Space Debris Detector With Learning-based LCM
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+Z">Zherui Lu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+G">Gangyi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+X">Xinguo Wei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 28 figures, normal article
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Image and Video Processing (eess.IV)

</div>
<p class="mathjax">With the development of aerospace technology, the increasing population of
space debris has posed a great threat to the safety of spacecraft. However, the
low intensity of reflected light and high angular velocity of space debris
impede the extraction. Besides, due to the limitations of the ground
observation methods, small space debris can hardly be detected, making it
necessary to enhance the spacecraft's capacity for space situational awareness
(SSA). Considering that traditional methods have some defects in low-SNR target
detection, such as low effectiveness and large time consumption, this paper
proposes a method for low-SNR streak extraction based on local contrast and
maximum likelihood estimation (MLE), which can detect space objects with SNR
2.0 efficiently. In the proposed algorithm, local contrast will be applied for
crude classifications, which will return connected components as preliminary
results, and then MLE will be performed to reconstruct the connected components
of targets via orientated growth, further improving the precision. The
algorithm has been verified with both simulated streaks and real star tracker
images, and the average centroid error of the proposed algorithm is close to
the state-of-the-art method like ODCC. At the same time, the algorithm in this
paper has significant advantages in efficiency compared with ODCC. In
conclusion, the algorithm in this paper is of high speed and precision, which
guarantees its promising applications in the extraction of high dynamic
targets.
</p>
</div>
</dd>
<dt><a name="item147">[147]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08247" title="Abstract">arXiv:2309.08247</a> [<a href="/pdf/2309.08247" title="Download PDF">pdf</a>, <a href="/format/2309.08247" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Geometric Perspective on Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+Y">Yonghyeon Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 13 figures, a summary of the contents presented in publications from NeurIPS 2021, ICLR 2022, and TAG-ML at ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)

</div>
<p class="mathjax">This paper presents the geometric aspect of the autoencoder framework, which,
despite its importance, has been relatively less recognized. Given a set of
high-dimensional data points that approximately lie on some lower-dimensional
manifold, an autoencoder learns the \textit{manifold} and its
\textit{coordinate chart}, simultaneously. This geometric perspective naturally
raises inquiries like "Does a finite set of data points correspond to a single
manifold?" or "Is there only one coordinate chart that can represent the
manifold?". The responses to these questions are negative, implying that there
are multiple solution autoencoders given a dataset. Consequently, they
sometimes produce incorrect manifolds with severely distorted latent space
representations. In this paper, we introduce recent geometric approaches that
address these issues.
</p>
</div>
</dd>
<dt><a name="item148">[148]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08248" title="Abstract">arXiv:2309.08248</a> [<a href="/pdf/2309.08248" title="Download PDF">pdf</a>, <a href="/format/2309.08248" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifiable Privacy-Preserving Computing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bontekoe%2C+T">Tariq Bontekoe</a>, 
<a href="/search/cs?searchtype=author&query=Karastoyanova%2C+D">Dimka Karastoyanova</a>, 
<a href="/search/cs?searchtype=author&query=Turkmen%2C+F">Fatih Turkmen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 pages, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Privacy-enhancing technologies (PETs), such as secure multi-party computation
(MPC) and homomorphic encryption (HE), are deployed increasingly often to
guarantee data confidentiality in computations over private, distributed data.
Similarly, we observe a steep increase in the adoption of zero-knowledge proofs
(ZKPs) to guarantee (public) verifiability of locally executed computations. We
project that applications that are data intensive and require strong privacy
guarantees, are also likely to require correctness guarantees. While the
combination of methods for (public) verifiability and privacy protection has
clear significance, many attempts are far from practical adoption.
<br />In this work, we analyze existing solutions that add (public) verifiability
to privacy-preserving computations over distributed data, in order to preserve
confidentiality and guarantee correctness. To determine the required security
and usability properties and whether these are satisfied, we look at various
application areas including verifiable outsourcing, distributed ledger
technology (DLT), and genomics. We then classify the solutions and describe
frequently used approaches as well as efficiency metrics. Last but not least,
we identify open challenges and discuss directions for future research that
make verifiable, privacy-preserving computations more secure, efficient, and
applicable in the real world.
</p>
</div>
</dd>
<dt><a name="item149">[149]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08249" title="Abstract">arXiv:2309.08249</a> [<a href="/pdf/2309.08249" title="Download PDF">pdf</a>, <a href="/format/2309.08249" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Nonnegative Matrix Factorization with Beta Divergences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Leplat%2C+V">Valentin Leplat</a>, 
<a href="/search/cs?searchtype=author&query=Hien%2C+L+T+K">Le Thi Khanh Hien</a>, 
<a href="/search/cs?searchtype=author&query=Onwunta%2C+A">Akwum Onwunta</a>, 
<a href="/search/cs?searchtype=author&query=Gillis%2C+N">Nicolas Gillis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 11 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Numerical Analysis (math.NA); Machine Learning (stat.ML)

</div>
<p class="mathjax">Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a
valuable technique for extracting multiple layers of features across different
scales. However, all existing deep NMF models and algorithms have primarily
centered their evaluation on the least squares error, which may not be the most
appropriate metric for assessing the quality of approximations on diverse
datasets. For instance, when dealing with data types such as audio signals and
documents, it is widely acknowledged that $\beta$-divergences offer a more
suitable alternative. In this paper, we develop new models and algorithms for
deep NMF using $\beta$-divergences. Subsequently, we apply these techniques to
the extraction of facial features, the identification of topics within document
collections, and the identification of materials within hyperspectral images.
</p>
</div>
</dd>
<dt><a name="item150">[150]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08250" title="Abstract">arXiv:2309.08250</a> [<a href="/pdf/2309.08250" title="Download PDF">pdf</a>, <a href="/format/2309.08250" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization of Rank Losses for Image Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ramzi%2C+E">Elias Ramzi</a>, 
<a href="/search/cs?searchtype=author&query=Audebert%2C+N">Nicolas Audebert</a>, 
<a href="/search/cs?searchtype=author&query=Rambour%2C+C">Cl&#xe9;ment Rambour</a>, 
<a href="/search/cs?searchtype=author&query=Araujo%2C+A">Andr&#xe9; Araujo</a>, 
<a href="/search/cs?searchtype=author&query=Bitot%2C+X">Xavier Bitot</a>, 
<a href="/search/cs?searchtype=author&query=Thome%2C+N">Nicolas Thome</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.04873">arXiv:2207.04873</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In image retrieval, standard evaluation metrics rely on score ranking, \eg
average precision (AP), recall at k (R@k), normalized discounted cumulative
gain (NDCG). In this work we introduce a general framework for robust and
decomposable rank losses optimization. It addresses two major challenges for
end-to-end training of deep neural networks with rank losses:
non-differentiability and non-decomposability. Firstly we propose a general
surrogate for ranking operator, SupRank, that is amenable to stochastic
gradient descent. It provides an upperbound for rank losses and ensures robust
training. Secondly, we use a simple yet effective loss function to reduce the
decomposability gap between the averaged batch approximation of ranking losses
and their values on the whole training set. We apply our framework to two
standard metrics for image retrieval: AP and R@k. Additionally we apply our
framework to hierarchical image retrieval. We introduce an extension of AP, the
hierarchical average precision $\mathcal{H}$-AP, and optimize it as well as the
NDCG. Finally we create the first hierarchical landmarks retrieval dataset. We
use a semi-automatic pipeline to create hierarchical labels, extending the
large scale Google Landmarks v2 dataset. The hierarchical dataset is publicly
available at https://github.com/cvdfoundation/google-landmark. Code will be
released at https://github.com/elias-ramzi/SupRank.
</p>
</div>
</dd>
<dt><a name="item151">[151]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08251" title="Abstract">arXiv:2309.08251</a> [<a href="/pdf/2309.08251" title="Download PDF">pdf</a>, <a href="/format/2309.08251" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cartoondiff: Training-free Cartoon Image Generation with Diffusion  Transformer Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+F">Feihong He</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+G">Gang Li</a>, 
<a href="/search/cs?searchtype=author&query=Si%2C+L">Lingyu Si</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+L">Leilei Yan</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+S">Shimeng Hou</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+H">Hongwei Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fanzhang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages,5 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Image cartoonization has attracted significant interest in the field of image
generation. However, most of the existing image cartoonization techniques
require re-training models using images of cartoon style. In this paper, we
present CartoonDiff, a novel training-free sampling approach which generates
image cartoonization using diffusion transformer models. Specifically, we
decompose the reverse process of diffusion models into the semantic generation
phase and the detail generation phase. Furthermore, we implement the image
cartoonization process by normalizing high-frequency signal of the noisy image
in specific denoising steps. CartoonDiff doesn't require any additional
reference images, complex model designs, or the tedious adjustment of multiple
parameters. Extensive experimental results show the powerful ability of our
CartoonDiff. The project page is available at: https://cartoondiff.github.io/
</p>
</div>
</dd>
<dt><a name="item152">[152]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08252" title="Abstract">arXiv:2309.08252</a> [<a href="/pdf/2309.08252" title="Download PDF">pdf</a>, <a href="/format/2309.08252" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A low-rank complexity reduction algorithm for the high-dimensional  kinetic chemical master equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Einkemmer%2C+L">Lukas Einkemmer</a>, 
<a href="/search/math?searchtype=author&query=Mangott%2C+J">Julian Mangott</a>, 
<a href="/search/math?searchtype=author&query=Prugger%2C+M">Martina Prugger</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Biological Physics (physics.bio-ph); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">It is increasingly realized that taking stochastic effects into account is
important in order to study biological cells. However, the corresponding
mathematical formulation, the chemical master equation (CME), suffers from the
curse of dimensionality and thus solving it directly is not feasible for most
realistic problems. In this paper we propose a dynamical low-rank algorithm for
the CME that reduces the dimensionality of the problem by dividing the reaction
network into partitions. Only reactions that cross partitions are subject to an
approximation error (everything else is computed exactly). This approach,
compared to the commonly used stochastic simulation algorithm (SSA, a Monte
Carlo method), has the advantage that it is completely noise-free. This is
particularly important if one is interested in resolving the tails of the
probability distribution. We show that in some cases (e.g. for the lambda
phage) the proposed method can drastically reduce memory consumption and run
time and provide better accuracy than SSA.
</p>
</div>
</dd>
<dt><a name="item153">[153]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08253" title="Abstract">arXiv:2309.08253</a> [<a href="/pdf/2309.08253" title="Download PDF">pdf</a>, <a href="/format/2309.08253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed Behavior Trees for Heterogeneous Robot Teams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Heppner%2C+G">Georg Heppner</a>, 
<a href="/search/cs?searchtype=author&query=Berg%2C+N">Nils Berg</a>, 
<a href="/search/cs?searchtype=author&query=Oberacker%2C+D">David Oberacker</a>, 
<a href="/search/cs?searchtype=author&query=Spielbauer%2C+N">Niklas Spielbauer</a>, 
<a href="/search/cs?searchtype=author&query=Roennau%2C+A">Arne Roennau</a>, 
<a href="/search/cs?searchtype=author&query=Dillmann%2C+R">R&#xfc;diger Dillmann</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> To be published in the Proceedings of the IEEE 19th International Conference on Automation Science and Engineering (IEEE CASE 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Heterogeneous Robot Teams can provide a wide range of capabilities and
therefore significant benefits when handling a mission. However, they also
require new approaches to capability and mission definition that are not only
suitable to handle heterogeneous capabilities but furthermore allow a
combination or distribution of them with a coherent representation that is not
limiting the individual robot. Behavior Trees offer many of the required
properties, are growing in popularity for robot control and have been proposed
for multirobot coordination, but always as separate behavior tree, defined in
advance and without consideration for a changing team. In this paper, we
propose a new behavior tree approach that is capable to handle complex real
world robotic missions and is geared towards a distributed execution by
providing built in functionalities for cost calculation, subtree distribution
and data wiring. We present a formal definition, its open source implementation
as ros_bt_py library and experimental verification of its capabilities.
</p>
</div>
</dd>
<dt><a name="item154">[154]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08254" title="Abstract">arXiv:2309.08254</a> [<a href="/pdf/2309.08254" title="Download PDF">pdf</a>, <a href="/format/2309.08254" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quantitative and Qualitative Evaluation of Reinforcement Learning  Policies for Autonomous Vehicles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ferrarotti%2C+L">Laura Ferrarotti</a>, 
<a href="/search/cs?searchtype=author&query=Luca%2C+M">Massimiliano Luca</a>, 
<a href="/search/cs?searchtype=author&query=Santin%2C+G">Gabriele Santin</a>, 
<a href="/search/cs?searchtype=author&query=Previati%2C+G">Giorgio Previati</a>, 
<a href="/search/cs?searchtype=author&query=Mastinu%2C+G">Gianpiero Mastinu</a>, 
<a href="/search/cs?searchtype=author&query=Campi%2C+E">Elena Campi</a>, 
<a href="/search/cs?searchtype=author&query=Uccello%2C+L">Lorenzo Uccello</a>, 
<a href="/search/cs?searchtype=author&query=Albanese%2C+A">Antonino Albanese</a>, 
<a href="/search/cs?searchtype=author&query=Zalaya%2C+P">Praveen Zalaya</a>, 
<a href="/search/cs?searchtype=author&query=Roccasalva%2C+A">Alessandro Roccasalva</a>, 
<a href="/search/cs?searchtype=author&query=Lepri%2C+B">Bruno Lepri</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
<p class="mathjax">Optimizing traffic dynamics in an evolving transportation landscape is
crucial, particularly in scenarios where autonomous vehicles (AVs) with varying
levels of autonomy coexist with human-driven cars. This paper presents a novel
approach to optimizing choices of AVs using Proximal Policy Optimization (PPO),
a reinforcement learning algorithm. We learned a policy to minimize traffic
jams (i.e., minimize the time to cross the scenario) and to minimize pollution
in a roundabout in Milan, Italy. Through empirical analysis, we demonstrate
that our approach can reduce time and pollution levels. Furthermore, we
qualitatively evaluate the learned policy using a cutting-edge cockpit to
assess its performance in near-real-world conditions. To gauge the practicality
and acceptability of the policy, we conducted evaluations with human
participants using the simulator, focusing on a range of metrics like traffic
smoothness and safety perception. In general, our findings show that
human-driven vehicles benefit from optimizing AVs dynamics. Also, participants
in the study highlighted that the scenario with 80\% AVs is perceived as safer
than the scenario with 20\%. The same result is obtained for traffic smoothness
perception.
</p>
</div>
</dd>
<dt><a name="item155">[155]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08256" title="Abstract">arXiv:2309.08256</a> [<a href="/pdf/2309.08256" title="Download PDF">pdf</a>, <a href="/format/2309.08256" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sampling-Free Probabilistic Deep State-Space Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Look%2C+A">Andreas Look</a>, 
<a href="/search/cs?searchtype=author&query=Kandemir%2C+M">Melih Kandemir</a>, 
<a href="/search/cs?searchtype=author&query=Rakitsch%2C+B">Barbara Rakitsch</a>, 
<a href="/search/cs?searchtype=author&query=Peters%2C+J">Jan Peters</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">Many real-world dynamical systems can be described as State-Space Models
(SSMs). In this formulation, each observation is emitted by a latent state,
which follows first-order Markovian dynamics. A Probabilistic Deep SSM
(ProDSSM) generalizes this framework to dynamical systems of unknown parametric
form, where the transition and emission models are described by neural networks
with uncertain weights. In this work, we propose the first deterministic
inference algorithm for models of this type. Our framework allows efficient
approximations for training and testing. We demonstrate in our experiments that
our new method can be employed for a variety of tasks and enjoys a superior
balance between predictive performance and computational budget.
</p>
</div>
</dd>
<dt><a name="item156">[156]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08259" title="Abstract">arXiv:2309.08259</a> [<a href="/pdf/2309.08259" title="Download PDF">pdf</a>, <a href="/format/2309.08259" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BROW: Better featuRes fOr Whole slide image based on self-distillation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yuanfeng Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaojie Li</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Z">Zhiqiang Du</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+W">Wentao Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages including reference part, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Whole slide image (WSI) processing is becoming part of the key components of
standard clinical diagnosis for various diseases. However, the direct
application of conventional image processing algorithms to WSI faces certain
obstacles because of WSIs' distinct property: the super-high resolution. The
performance of most WSI-related tasks relies on the efficacy of the backbone
which extracts WSI patch feature representations. Hence, we proposed BROW, a
foundation model for extracting better feature representations for WSIs, which
can be conveniently adapted to downstream tasks without or with slight
fine-tuning. The model takes transformer architecture, pretrained using
self-distillation framework. To improve model's robustness, techniques such as
patch shuffling have been employed. Additionally, the model leverages the
unique properties of WSIs, utilizing WSI's multi-scale pyramid to incorporate
an additional global view, thereby further enhancing its performance. We used
both private and public data to make up a large pretraining dataset, containing
more than 11000 slides, over 180M extracted patches, encompassing WSIs related
to various organs and tissues. To assess the effectiveness of \ourmodel, we run
a wide range of downstream tasks, including slide-level subtyping, patch-level
classification and nuclei instance segmentation. The results confirmed the
efficacy, robustness and good generalization ability of the proposed model.
This substantiates its potential as foundation model for WSI feature extraction
and highlights promising prospects for its application in WSI processing.
</p>
</div>
</dd>
<dt><a name="item157">[157]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08264" title="Abstract">arXiv:2309.08264</a> [<a href="/pdf/2309.08264" title="Download PDF">pdf</a>, <a href="/format/2309.08264" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging the Power of Data Augmentation for Transformer-based Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+J">Jie Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Edstedt%2C+J">Johan Edstedt</a>, 
<a href="/search/cs?searchtype=author&query=Felsberg%2C+M">Michael Felsberg</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Huchuan Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 5 figures, 7 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Due to long-distance correlation and powerful pretrained models,
transformer-based methods have initiated a breakthrough in visual object
tracking performance. Previous works focus on designing effective architectures
suited for tracking, but ignore that data augmentation is equally crucial for
training a well-performing model. In this paper, we first explore the impact of
general data augmentations on transformer-based trackers via systematic
experiments, and reveal the limited effectiveness of these common strategies.
Motivated by experimental observations, we then propose two data augmentation
methods customized for tracking. First, we optimize existing random cropping
via a dynamic search radius mechanism and simulation for boundary samples.
Second, we propose a token-level feature mixing augmentation strategy, which
enables the model against challenges like background interference. Extensive
experiments on two transformer-based trackers and six benchmarks demonstrate
the effectiveness and data efficiency of our methods, especially under
challenging settings, like one-shot tracking and small image resolutions.
</p>
</div>
</dd>
<dt><a name="item158">[158]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08265" title="Abstract">arXiv:2309.08265</a> [<a href="/pdf/2309.08265" title="Download PDF">pdf</a>, <a href="/format/2309.08265" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Edge Based Oriented Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shen%2C+J">Jianghu Shen</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaojun Wu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 8 figures, 1 algorithm,
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In the field of remote sensing, we often utilize oriented bounding boxes
(OBB) to bound the objects. This approach significantly reduces the overlap
among dense detection boxes and minimizes the inclusion of background content
within the bounding boxes. To enhance the detection accuracy of oriented
objects, we propose a unique loss function based on edge gradients, inspired by
the similarity measurement function used in template matching task. During this
process, we address the issues of non-differentiability of the function and the
semantic alignment between gradient vectors in ground truth (GT) boxes and
predicted boxes (PB). Experimental results show that our proposed loss function
achieves $0.6\%$ mAP improvement compared to the commonly used Smooth L1 loss
in the baseline algorithm. Additionally, we design an edge-based self-attention
module to encourage the detection network to focus more on the object edges.
Leveraging these two innovations, we achieve a mAP increase of 1.3% on the DOTA
dataset.
</p>
</div>
</dd>
<dt><a name="item159">[159]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08266" title="Abstract">arXiv:2309.08266</a> [<a href="/pdf/2309.08266" title="Download PDF">pdf</a>, <a href="/ps/2309.08266" title="Download PostScript">ps</a>, <a href="/format/2309.08266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enterprise Architecture as an Enabler for a Government Business  Ecosystem: Experiences from Finland
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ghezzi%2C+R">Reetta Ghezzi</a>, 
<a href="/search/cs?searchtype=author&query=Kolehmainen%2C+T">Taija Kolehmainen</a>, 
<a href="/search/cs?searchtype=author&query=Set%C3%A4l%C3%A4%2C+M">Manu Set&#xe4;l&#xe4;</a>, 
<a href="/search/cs?searchtype=author&query=Mikkonen%2C+T">Tommi Mikkonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, Medes (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Public sector procurement units in the field of ICT suffer from siloed,
application-specific architectures, where each system operates in isolation
from others. As a consequence, similar or even identical data is maintained in
several different databases hosted by different organizations. Such problems
are caused by the lack of standard guidelines and practices that would result
in interoperable systems instead of overlapping ones. In the Finnish public
sector, enterprise architecture (EA) is a mandatory requirement so that an
ecosystem can be formed to overcome the above problems. However, the adoption
rates are low, and the focus is often on technology rather than processes and
practices. This study investigates the use of EA and its potential in Finnish
procurement units through semi-structured interviews. Five procurement units
and four vendors participated in the study, and altogether 12 interviews took
place.
</p>
</div>
</dd>
<dt><a name="item160">[160]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08271" title="Abstract">arXiv:2309.08271</a> [<a href="/pdf/2309.08271" title="Download PDF">pdf</a>, <a href="/format/2309.08271" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Greedy Optimization of Resistance-based Graph Robustness with Global and  Local Edge Insertions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Predari%2C+M">Maria Predari</a> (1), 
<a href="/search/cs?searchtype=author&query=Berner%2C+L">Lukas Berner</a> (1), 
<a href="/search/cs?searchtype=author&query=Kooij%2C+R">Robert Kooij</a> (2 and 3), 
<a href="/search/cs?searchtype=author&query=Meyerhenke%2C+H">Henning Meyerhenke</a> (1) ((1) Department of Computer Science, Humboldt-Universit&#xe4;t zu Berlin, (2) Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, (3) UNIT ICT, Strategy &amp; Policy, TNO (Netherlands Organisation for Applied Scientific Research))
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 29 pages, 13 figures, to be published in Social Network Analysis and Mining
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>

</div>
<p class="mathjax">The total effective resistance, also called the Kirchhoff index, provides a
robustness measure for a graph $G$. We consider two optimization problems of
adding $k$ new edges to $G$ such that the resulting graph has minimal total
effective resistance (i.e., is most robust) -- one where the new edges can be
anywhere in the graph and one where the new edges need to be incident to a
specified focus node. The total effective resistance and effective resistances
between nodes can be computed using the pseudoinverse of the graph Laplacian.
The pseudoinverse may be computed explicitly via pseudoinversion; yet, this
takes cubic time in practice and quadratic space. We instead exploit
combinatorial and algebraic connections to speed up gain computations in an
established generic greedy heuristic. Moreover, we leverage existing randomized
techniques to boost the performance of our approaches by introducing a
sub-sampling step. Our different graph- and matrix-based approaches are indeed
significantly faster than the state-of-the-art greedy algorithm, while their
quality remains reasonably high and is often quite close. Our experiments show
that we can now process larger graphs for which the application of the
state-of-the-art greedy approach was impractical before.
</p>
</div>
</dd>
<dt><a name="item161">[161]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08272" title="Abstract">arXiv:2309.08272</a> [<a href="/pdf/2309.08272" title="Download PDF">pdf</a>, <a href="/format/2309.08272" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structural Self-Supervised Objectives for Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Di+Liello%2C+L">Luca Di Liello</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Ph.D. Thesis
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">This thesis focuses on improving the pre-training of natural language models
using unsupervised raw data to make them more efficient and aligned with
downstream applications.
<br />In the first part, we introduce three alternative pre-training objectives to
BERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS),
Cluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling
(SLM). These objectives involve token swapping instead of masking, with RTS and
C-RTS aiming to predict token originality and SLM predicting the original token
values. Results show that RTS and C-RTS require less pre-training time while
maintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on
certain tasks despite using the same computational budget.
<br />In the second part, we proposes self-supervised pre-training tasks that align
structurally with downstream applications, reducing the need for labeled data.
We use large corpora like Wikipedia and CC-News to train models to recognize if
text spans originate from the same paragraph or document in several ways. By
doing continuous pre-training, starting from existing models like RoBERTa,
ELECTRA, DeBERTa, BART, and T5, we demonstrate significant performance
improvements in tasks like Fact Verification, Answer Sentence Selection, and
Summarization. These improvements are especially pronounced when limited
annotation data is available. The proposed objectives also achieve
state-of-the-art results on various benchmark datasets, including FEVER (dev
set), ASNQ, WikiQA, and TREC-QA, as well as enhancing the quality of summaries.
Importantly, these techniques can be easily integrated with other methods
without altering the internal structure of Transformer models, making them
versatile for various NLP applications.
</p>
</div>
</dd>
<dt><a name="item162">[162]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08273" title="Abstract">arXiv:2309.08273</a> [<a href="/pdf/2309.08273" title="Download PDF">pdf</a>, <a href="/format/2309.08273" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unsupervised Disentangling of Facial Representations with 3D-aware  Latent Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+R">Ruian He</a>, 
<a href="/search/cs?searchtype=author&query=Xing%2C+Z">Zhen Xing</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+W">Weimin Tan</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+B">Bo Yan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Unsupervised learning of facial representations has gained increasing
attention for face understanding ability without heavily relying on large-scale
annotated datasets. However, it remains unsolved due to the coupling of facial
identities, expressions, and external factors like pose and light. Prior
methods primarily focus on 2D factors and pixel-level consistency, leading to
incomplete disentangling and suboptimal performance in downstream tasks. In
this paper, we propose LatentFace, a novel unsupervised disentangling framework
for facial expression and identity representation. We suggest the disentangling
problem should be performed in latent space and propose the solution using a
3D-ware latent diffusion model. First, we introduce a 3D-aware autoencoder to
encode face images into 3D latent embeddings. Second, we propose a novel
representation diffusion model (RDM) to disentangle 3D latent into facial
identity and expression. Consequently, our method achieves state-of-the-art
performance in facial expression recognition and face verification among
unsupervised facial representation learning models.
</p>
</div>
</dd>
<dt><a name="item163">[163]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08275" title="Abstract">arXiv:2309.08275</a> [<a href="/pdf/2309.08275" title="Download PDF">pdf</a>, <a href="/ps/2309.08275" title="Download PostScript">ps</a>, <a href="/format/2309.08275" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> User Power Measurement Based IRS Channel Estimation via Single-Layer  Neural Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sun%2C+H">He Sun</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+W">Weidong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Lipeng Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Rui Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">One main challenge for implementing intelligent reflecting surface (IRS)
aided communications lies in the difficulty to obtain the channel knowledge for
the base station (BS)-IRS-user cascaded links, which is needed to design
high-performance IRS reflection in practice. Traditional methods for estimating
IRS cascaded channels are usually based on the additional pilot signals
received at the BS/users, which increase the system training overhead and also
may not be compatible with the current communication protocols. To tackle this
challenge, we propose in this paper a new single-layer neural network
(NN)-enabled IRS channel estimation method based on only the knowledge of
users' individual received signal power measurements corresponding to different
IRS random training reflections, which are easily accessible in current
wireless systems. To evaluate the effectiveness of the proposed channel
estimation method, we design the IRS reflection for data transmission based on
the estimated cascaded channels in an IRS-aided multiuser communication system.
Numerical results show that the proposed IRS channel estimation and reflection
design can significantly improve the minimum received signal-to-noise ratio
(SNR) among all users, as compared to existing power measurement based designs.
</p>
</div>
</dd>
<dt><a name="item164">[164]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08276" title="Abstract">arXiv:2309.08276</a> [<a href="/pdf/2309.08276" title="Download PDF">pdf</a>, <a href="/ps/2309.08276" title="Download PostScript">ps</a>, <a href="/format/2309.08276" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A New Adaptive Phase-locked Loop for Synchronization of a Grid-Connected  Voltage Source Converter: Simulation and Experimental Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+J">Jiachen Yan</a>, 
<a href="/search/eess?searchtype=author&query=Ortega%2C+R">Romeo Ortega</a>, 
<a href="/search/eess?searchtype=author&query=Zonetti%2C+D">Daniele Zonetti</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+W">Wangping Zhou</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">In [1] a new adaptive phase-locked loop scheme for synchronization of a grid
connected voltage source converter with guaranteed (almost) global stability
properties was reported. To guarantee a suitable synchronization with the angle
of the three-phase grid voltage we design an adaptive observer for such a
signal requiring measurements only at the point of common coupling. An
interesting feature of this scheme is the ability to synchronize in the
challenging condition of connection with a grid with reduced short-circuit
ratio. In this paper we present some simulation and experimental illustration
of the excellent performance of the proposed solution.
</p>
</div>
</dd>
<dt><a name="item165">[165]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08283" title="Abstract">arXiv:2309.08283</a> [<a href="/pdf/2309.08283" title="Download PDF">pdf</a>, <a href="/format/2309.08283" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Finite-Volume Scheme for Fractional Diffusion on Bounded Domains
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bailo%2C+R">Rafael Bailo</a>, 
<a href="/search/math?searchtype=author&query=Carrillo%2C+J+A">Jos&#xe9; A. Carrillo</a>, 
<a href="/search/math?searchtype=author&query=Fronzoni%2C+S">Stefano Fronzoni</a>, 
<a href="/search/math?searchtype=author&query=G%C3%B3mez-Castro%2C+D">David G&#xf3;mez-Castro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">We propose a new fractional Laplacian for bounded domains, expressed as a
conservation law and thus particularly suited to finite-volume schemes. Our
approach permits the direct prescription of no-flux boundary conditions. We
first show the well-posedness theory for the fractional heat equation. We also
develop a numerical scheme, which correctly captures the action of the
fractional Laplacian and its anomalous diffusion effect. We benchmark numerical
solutions for the L\'evy-Fokker-Planck equation against known analytical
solutions. We conclude by numerically exploring properties of these equations
with respect to their stationary states and long-time asymptotics.
</p>
</div>
</dd>
<dt><a name="item166">[166]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08284" title="Abstract">arXiv:2309.08284</a> [<a href="/pdf/2309.08284" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards an Interoperability Roadmap for the Energy Transition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reif%2C+V">Valerie Reif</a>, 
<a href="/search/cs?searchtype=author&query=Strasser%2C+T+I">Thomas I. Strasser</a>, 
<a href="/search/cs?searchtype=author&query=Jimeno%2C+J">Joseba Jimeno</a>, 
<a href="/search/cs?searchtype=author&query=Farre%2C+M">Marjolaine Farre</a>, 
<a href="/search/cs?searchtype=author&query=Genest%2C+O">Oliver Genest</a>, 
<a href="/search/cs?searchtype=author&query=Gyrard%2C+A">Am&#xe9;lie Gyrard</a>, 
<a href="/search/cs?searchtype=author&query=McGranaghan%2C+M">Mark McGranaghan</a>, 
<a href="/search/cs?searchtype=author&query=Lipari%2C+G">Gianluca Lipari</a>, 
<a href="/search/cs?searchtype=author&query=Sch%C3%BCtz%2C+J">Johann Sch&#xfc;tz</a>, 
<a href="/search/cs?searchtype=author&query=Uslar%2C+M">Mathias Uslar</a>, 
<a href="/search/cs?searchtype=author&query=Vogel%2C+S">Sebastian Vogel</a>, 
<a href="/search/cs?searchtype=author&query=Bytyqi%2C+A">Arsim Bytyqi</a>, 
<a href="/search/cs?searchtype=author&query=Dornmair%2C+R">Rita Dornmair</a>, 
<a href="/search/cs?searchtype=author&query=Corusa%2C+A">Andreas Corusa</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+G">Gaurav Roy</a>, 
<a href="/search/cs?searchtype=author&query=Ponci%2C+F">Ferdinanda Ponci</a>, 
<a href="/search/cs?searchtype=author&query=Dognini%2C+A">Alberto Dognini</a>, 
<a href="/search/cs?searchtype=author&query=Monti%2C+A">Antonello Monti</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12. (Hybrid) Symposium Communications for Energy Systems (ComForEn 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
<p class="mathjax">Smart grid interoperability is the means to achieve the twin green and
digital transition but re-mains heterogeneous and fragmented to date. This work
presents the first ideas and corner-stones of an Interoperability Roadmap for
the Energy Transition that is being developed by the Horizon Europe int:net
project. This roadmap builds on four cornerstones that address open
interoperability issues. These are a knowledge base to address the lack of
convergence among existing initiatives, a maturity model and a network of
testing and certification facilities to ad-dress the lack of practical tools
for the industry, and a governance process to address the gap between
standards-related approaches of Standards Development Organisations and
Research and Innovation projects. A community of practice will be set up to
ensure the continuity of the ongoing activities related to smart grid
interoperability. To outlive the duration of the int:net project, the aim is to
formalise the community of practice as a legal entity.
</p>
</div>
</dd>
<dt><a name="item167">[167]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08287" title="Abstract">arXiv:2309.08287</a> [<a href="/pdf/2309.08287" title="Download PDF">pdf</a>, <a href="/ps/2309.08287" title="Download PostScript">ps</a>, <a href="/format/2309.08287" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Sparse Grid Interpolation for American Option Pricing with Multiple  Underlying Assets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+J">Jiefei Yang</a>, 
<a href="/search/math?searchtype=author&query=Li%2C+G">Guanglian Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 22 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Finance (q-fin.CP)

</div>
<p class="mathjax">In this work, we develop a novel efficient quadrature and sparse grid based
polynomial interpolation method to price American options with multiple
underlying assets. The approach is based on first formulating the pricing of
American options using dynamic programming, and then employing static sparse
grids to interpolate the continuation value function at each time step. To
achieve high efficiency, we first transform the domain from $\mathbb{R}^d$ to
$(-1,1)^d$ via a scaled tanh map, and then remove the boundary singularity of
the resulting multivariate function over $(-1,1)^d$ by a bubble function and
simultaneously, to significantly reduce the number of interpolation points. We
rigorously establish that with a proper choice of the bubble function, the
resulting function has bounded mixed derivatives up to a certain order, which
provides theoretical underpinnings for the use of sparse grids. Numerical
experiments for American arithmetic and geometric basket put options with the
number of underlying assets up to 16 are presented to validate the
effectiveness of the approach.
</p>
</div>
</dd>
<dt><a name="item168">[168]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08289" title="Abstract">arXiv:2309.08289</a> [<a href="/pdf/2309.08289" title="Download PDF">pdf</a>, <a href="/format/2309.08289" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large Intestine 3D Shape Refinement Using Point Diffusion Models for  Digital Phantom Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mouheb%2C+K">Kaouther Mouheb</a>, 
<a href="/search/cs?searchtype=author&query=Nejad%2C+M+G">Mobina Ghojogh Nejad</a>, 
<a href="/search/cs?searchtype=author&query=Dahal%2C+L">Lavsen Dahal</a>, 
<a href="/search/cs?searchtype=author&query=Samei%2C+E">Ehsan Samei</a>, 
<a href="/search/cs?searchtype=author&query=Segars%2C+W+P">W. Paul Segars</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+J+Y">Joseph Y. Lo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Accurate 3D modeling of human organs plays a crucial role in building
computational phantoms for virtual imaging trials. However, generating
anatomically plausible reconstructions of organ surfaces from computed
tomography scans remains challenging for many structures in the human body.
This challenge is particularly evident when dealing with the large intestine.
In this study, we leverage recent advancements in geometric deep learning and
denoising diffusion probabilistic models to refine the segmentation results of
the large intestine. We begin by representing the organ as point clouds sampled
from the surface of the 3D segmentation mask. Subsequently, we employ a
hierarchical variational autoencoder to obtain global and local latent
representations of the organ's shape. We train two conditional denoising
diffusion models in the hierarchical latent space to perform shape refinement.
To further enhance our method, we incorporate a state-of-the-art surface
reconstruction model, allowing us to generate smooth meshes from the obtained
complete point clouds. Experimental results demonstrate the effectiveness of
our approach in capturing both the global distribution of the organ's shape and
its fine details. Our complete refinement pipeline demonstrates remarkable
enhancements in surface representation compared to the initial segmentation,
reducing the Chamfer distance by 70%, the Hausdorff distance by 32%, and the
Earth Mover's distance by 6%. By combining geometric deep learning, denoising
diffusion models, and advanced surface reconstruction techniques, our proposed
method offers a promising solution for accurately modeling the large
intestine's surface and can easily be extended to other anatomical structures.
</p>
</div>
</dd>
<dt><a name="item169">[169]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08291" title="Abstract">arXiv:2309.08291</a> [<a href="/pdf/2309.08291" title="Download PDF">pdf</a>, <a href="/format/2309.08291" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breaking down the relationship between academic impact and scientific  disruption
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Mingtang Li</a>, 
<a href="/search/cs?searchtype=author&query=Livan%2C+G">Giacomo Livan</a>, 
<a href="/search/cs?searchtype=author&query=Righi%2C+S">Simone Righi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>; Physics and Society (physics.soc-ph)

</div>
<p class="mathjax">We examine the tension between academic impact - the volume of citations
received by publications - and scientific disruption. Intuitively, one would
expect disruptive scientific work to be rewarded by high volumes of citations
and, symmetrically, impactful work to also be disruptive. A number of recent
studies have instead shown that such intuition is often at odds with reality.
In this paper, we break down the relationship between impact and disruption
with a detailed correlation analysis in two large data sets of publications in
Computer Science and Physics. We find that highly disruptive papers tend to be
cited at higher rates than average. Contrastingly, the opposite is not true, as
we do not find highly impactful papers to be particularly disruptive. Notably,
these results qualitatively hold even within individual scientific careers, as
we find that - on average - an author's most disruptive work tends to be well
cited, whereas their most cited work does not tend to be disruptive. We discuss
the implications of our findings in the context of academic evaluation systems,
and show how they can contribute to reconcile seemingly contradictory results
in the literature.
</p>
</div>
</dd>
<dt><a name="item170">[170]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08297" title="Abstract">arXiv:2309.08297</a> [<a href="/pdf/2309.08297" title="Download PDF">pdf</a>, <a href="/ps/2309.08297" title="Download PostScript">ps</a>, <a href="/format/2309.08297" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal Mobility and Communication Strategy to Maximize the Value of  Information in IoT Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zijing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Badiu%2C+M">Mihai-Alin Badiu</a>, 
<a href="/search/eess?searchtype=author&query=Coon%2C+J+P">Justin P. Coon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">The Internet of Things (IoT) is an emerging next-generation technology in the
fourth industrial revolution. In industrial IoT networks, sensing devices are
largely deployed to monitor various types of physical processes. They are
required to transmit the collected data in a timely manner to support real-time
monitoring, control and automation. The timeliness of information is very
important in such systems. Recently, an information-theoretic metric named the
"value of information" (VoI) has been proposed to measure the usefulness of
information. In this work, we consider an industrial IoT network with a set of
heterogeneous sensing devices and an intelligent mobile entity. The concept of
the value of information is applied to study a joint path planning and user
scheduling optimisation problem. We aim to maximise the network-level VoI under
mobility and communication constraints. We formulate this problem as a Markov
decision process (MDP), and an efficient algorithm based on reinforcement
learning is proposed to solve this problem. Through numerical results, we show
that the proposed method is able to capture the usefulness of data from both
time and space dimensions. By exploiting the correlation property of the data
source, the proposed method is suitable for applications in resource-limited
networks.
</p>
</div>
</dd>
<dt><a name="item171">[171]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08301" title="Abstract">arXiv:2309.08301</a> [<a href="/pdf/2309.08301" title="Download PDF">pdf</a>, <a href="/format/2309.08301" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RaSpectLoc: RAman SPECTroscopy-dependent robot LOCalisation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thirgood%2C+C+T">Christopher Thomas Thirgood</a>, 
<a href="/search/cs?searchtype=author&query=Maldonado%2C+O+A+M">Oscar Alejandro Mendez Maldonado</a>, 
<a href="/search/cs?searchtype=author&query=Ling%2C+C">Chao Ling</a>, 
<a href="/search/cs?searchtype=author&query=Storey%2C+J">Jonathan Storey</a>, 
<a href="/search/cs?searchtype=author&query=Hadfield%2C+S+J">Simon J Hadfield</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures. This work will be presented at IROS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a new information source for supporting robot
localisation: material composition. The proposed method complements the
existing visual, structural, and semantic cues utilized in the literature.
However, it has a distinct advantage in its ability to differentiate
structurally, visually or categorically similar objects such as different
doors, by using Raman spectrometers. Such devices can identify the material of
objects it probes through the bonds between the material's molecules. Unlike
similar sensors, such as mass spectroscopy, it does so without damaging the
material or environment. In addition to introducing the first material-based
localisation algorithm, this paper supports the future growth of the field by
presenting a gazebo plugin for Raman spectrometers, material sensing
demonstrations, as well as the first-ever localisation data-set with benchmarks
for material-based localisation. This benchmarking shows that the proposed
technique results in a significant improvement over current state-of-the-art
localisation techniques, achieving 16\% more accurate localisation than the
leading baseline.
</p>
</div>
</dd>
<dt><a name="item172">[172]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08302" title="Abstract">arXiv:2309.08302</a> [<a href="/pdf/2309.08302" title="Download PDF">pdf</a>, <a href="/format/2309.08302" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> T-UDA: Temporal Unsupervised Domain Adaptation in Sequential Point  Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gebrehiwot%2C+A+H">Awet Haileslassie Gebrehiwot</a>, 
<a href="/search/cs?searchtype=author&query=Hurych%2C+D">David Hurych</a>, 
<a href="/search/cs?searchtype=author&query=Zimmermann%2C+K">Karel Zimmermann</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+P">Patrick P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Svoboda%2C+T">Tom&#xe1;&#x161; Svoboda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Will appear at IEEE/RSJ International Conference on Intelligent Robots and Systems 2023 (IROS 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">Deep perception models have to reliably cope with an open-world setting of
domain shifts induced by different geographic regions, sensor properties,
mounting positions, and several other reasons. Since covering all domains with
annotated data is technically intractable due to the endless possible
variations, researchers focus on unsupervised domain adaptation (UDA) methods
that adapt models trained on one (source) domain with annotations available to
another (target) domain for which only unannotated data are available. Current
predominant methods either leverage semi-supervised approaches, e.g.,
teacher-student setup, or exploit privileged data, such as other sensor
modalities or temporal data consistency. We introduce a novel domain adaptation
method that leverages the best of both trends. Our approach combines input
data's temporal and cross-sensor geometric consistency with the mean teacher
method. Dubbed T-UDA for "temporal UDA", such a combination yields massive
performance gains for the task of 3D semantic segmentation of driving scenes.
Experiments are conducted on Waymo Open Dataset, nuScenes and SemanticKITTI,
for two popular 3D point cloud architectures, Cylinder3D and MinkowskiNet. Our
codes are publicly available at https://github.com/ctu-vras/T-UDA.
</p>
</div>
</dd>
<dt><a name="item173">[173]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08303" title="Abstract">arXiv:2309.08303</a> [<a href="/pdf/2309.08303" title="Download PDF">pdf</a>, <a href="/format/2309.08303" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Consistent Narrative Prompts on Abductive Natural Language  Inference
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chan%2C+C">Chunkit Chan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+T+H">Tsz Ho Chan</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+J">Jiayang Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+Y">Yangqiu Song</a>, 
<a href="/search/cs?searchtype=author&query=Wong%2C+G">Ginny Wong</a>, 
<a href="/search/cs?searchtype=author&query=See%2C+S">Simon See</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at IJCNLP-AACL 2023 main track
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Abduction has long been seen as crucial for narrative comprehension and
reasoning about everyday situations. The abductive natural language inference
($\alpha$NLI) task has been proposed, and this narrative text-based task aims
to infer the most plausible hypothesis from the candidates given two
observations. However, the inter-sentential coherence and the model consistency
have not been well exploited in the previous works on this task. In this work,
we propose a prompt tuning model $\alpha$-PACE, which takes self-consistency
and inter-sentential coherence into consideration. Besides, we propose a
general self-consistent framework that considers various narrative sequences
(e.g., linear narrative and reverse chronology) for guiding the pre-trained
language model in understanding the narrative context of input. We conduct
extensive experiments and thorough ablation studies to illustrate the necessity
and effectiveness of $\alpha$-PACE. The performance of our method shows
significant improvement against extensive competitive baselines.
</p>
</div>
</dd>
<dt><a name="item174">[174]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08304" title="Abstract">arXiv:2309.08304</a> [<a href="/pdf/2309.08304" title="Download PDF">pdf</a>, <a href="/ps/2309.08304" title="Download PostScript">ps</a>, <a href="/format/2309.08304" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice attack on group ring NTRU: The case of the dihedral group
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+V">Vikas Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Raya%2C+A">Ali Raya</a>, 
<a href="/search/cs?searchtype=author&query=Gangopadhyay%2C+S">Sugata Gangopadhyay</a>, 
<a href="/search/cs?searchtype=author&query=Gangopadhyay%2C+A+K">Aditi Kar Gangopadhyay</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
<p class="mathjax">Group ring NTRU (GR-NTRU) provides a general structure to design different
variants of NTRU-like schemes by employing different groups. Although, most of
the schemes in literature are built over cyclic groups, nonabelian groups can
also be used. Coppersmith and Shamir in 1997 have suggested that
noncommutativity may result in better security against some lattice attacks for
some groups. Lattice attacks on the public key of NTRU-like cryptosystems try
to retrieve the private key by solving the shortest vector problem (SVP) or its
approximation in a lattice of a certain dimension, assuming the knowledge of
the public key only. This paper shows that dihedral groups do not guarantee
better security against this class of attacks. We prove that retrieving the
private key is possible by solving the SVP in two lattices with half the
dimension of the original lattice generated for GR-NTRU based on dihedral
groups. The possibility of such an attack was mentioned by Yasuda et
al.(IACR/2015/1170). In contrast to their proposed approach, we explicitly
provide the lattice reduction without any structure theorem from the
representation theory for finite groups. Furthermore, we demonstrate the
effectiveness of our technique with experimental results.
</p>
</div>
</dd>
<dt><a name="item175">[175]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08312" title="Abstract">arXiv:2309.08312</a> [<a href="/pdf/2309.08312" title="Download PDF">pdf</a>, <a href="/format/2309.08312" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Two-fingered Hand with Gear-type Synchronization Mechanism with Magnet  for Improved Small and Offset Objects Grasping: F2 Hand
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fukaya%2C+N">Naoki Fukaya</a>, 
<a href="/search/cs?searchtype=author&query=Ummadisingu%2C+A">Avinash Ummadisingu</a>, 
<a href="/search/cs?searchtype=author&query=Takahashi%2C+K">Kuniyuki Takahashi</a>, 
<a href="/search/cs?searchtype=author&query=Maeda%2C+G">Guilherme Maeda</a>, 
<a href="/search/cs?searchtype=author&query=Maeda%2C+S">Shin-ichi Maeda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages. Accepted at IEEE IROS 2023. An accompanying video is available at <a href="https://www.youtube.com/watch?v=RVLpog5mXVs">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A problem that plagues robotic grasping is the misalignment of the object and
gripper due to difficulties in precise localization, actuation, etc.
Under-actuated robotic hands with compliant mechanisms are used to adapt and
compensate for these inaccuracies. However, these mechanisms come at the cost
of controllability and coordination. For instance, adaptive functions that let
the fingers of a two-fingered gripper adapt independently may affect the
coordination necessary for grasping small objects. In this work, we develop a
two-fingered robotic hand capable of grasping objects that are offset from the
gripper's center, while still having the requisite coordination for grasping
small objects via a novel gear-type synchronization mechanism with a magnet.
This gear synchronization mechanism allows the adaptive finger's tips to be
aligned enabling it to grasp objects as small as toothpicks and washers. The
magnetic component allows this coordination to automatically turn off when
needed, allowing for the grasping of objects that are offset/misaligned from
the gripper. This equips the hand with the capability of grasping light,
fragile objects (strawberries, creampuffs, etc) to heavy frying pan lids, all
while maintaining their position and posture which is vital in numerous
applications that require precise positioning or careful manipulation.
</p>
</div>
</dd>
<dt><a name="item176">[176]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08315" title="Abstract">arXiv:2309.08315</a> [<a href="/pdf/2309.08315" title="Download PDF">pdf</a>, <a href="/format/2309.08315" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> i-Octree: A Fast, Lightweight, and Dynamic Octree for Proximity Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">Jun Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Hongyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhepeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Establishing the correspondences between newly acquired points and
historically accumulated data (i.e., map) through nearest neighbors search is
crucial in numerous robotic applications.However, static tree data structures
are inadequate to handle large and dynamically growing maps in real-time.To
address this issue, we present the i-Octree, a dynamic octree data structure
that supports both fast nearest neighbor search and real-time dynamic updates,
such as point insertion, deletion, and on-tree down-sampling. The i-Octree is
built upon a leaf-based octree and has two key features: a local spatially
continuous storing strategy that allows for fast access to points while
minimizing memory usage, and local on-tree updates that significantly reduce
computation time compared to existing static or dynamic tree structures.The
experiments show that i-Octree surpasses state-of-the-art methods by reducing
run-time by over 50% on real-world open datasets.
</p>
</div>
</dd>
<dt><a name="item177">[177]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08316" title="Abstract">arXiv:2309.08316</a> [<a href="/pdf/2309.08316" title="Download PDF">pdf</a>, <a href="/format/2309.08316" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bridging Topic, Domain, and Language Shifts: An Evaluation of  Comprehensive Out-of-Distribution Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Waldis%2C+A">Andreas Waldis</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Language models (LMs) excel in in-distribution (ID) scenarios where train and
test data are independent and identically distributed. However, their
performance often degrades in real-world applications like argument mining.
Such degradation happens when new topics emerge, or other text domains and
languages become relevant. To assess LMs' generalization abilities in such
out-of-distribution (OOD) scenarios, we simulate such distribution shifts by
deliberately withholding specific instances for testing, as from the social
media domain or the topic Solar Energy.
<br />Unlike prior studies focusing on specific shifts and metrics in isolation, we
comprehensively analyze OOD generalization. We define three metrics to pinpoint
generalization flaws and propose eleven classification tasks covering topic,
domain, and language shifts. Overall, we find superior performance of
prompt-based fine-tuning, notably when train and test splits primarily differ
semantically. Simultaneously, in-context learning is more effective than
prompt-based or vanilla fine-tuning for tasks when training data embodies heavy
discrepancies in label distribution compared to testing data. This reveals a
crucial drawback of gradient-based learning: it biases LMs regarding such
structural obstacles.
</p>
</div>
</dd>
<dt><a name="item178">[178]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08321" title="Abstract">arXiv:2309.08321</a> [<a href="/pdf/2309.08321" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reset thresholds of transformation monoids
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rystsov%2C+I">Igor Rystsov</a>, 
<a href="/search/cs?searchtype=author&query=Szyku%C5%82a%2C+M">Marek Szyku&#x142;a</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
<p class="mathjax">Motivated by the \v{C}ern\'y conjecture for automata, we introduce the
concept of monoidal automata, which allows the formulation of the \v{C}ern\'y
conjecture for monoids. We show upper bounds on the reset threshold of monoids
with certain properties. In particular, we obtain a quadratic upper bound if
the transformation monoid contains a primitive group of permutations and a
singular of maximal rank with only one point of contraction.
</p>
</div>
</dd>
<dt><a name="item179">[179]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08322" title="Abstract">arXiv:2309.08322</a> [<a href="/pdf/2309.08322" title="Download PDF">pdf</a>, <a href="/format/2309.08322" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-bounded Active Monitoring of Unknown Dynamic Targets in  Road-networks with Minimum Fleet
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuaikang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kantaros%2C+Y">Yiannis Kantaros</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+M">Meng Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures, 1 table
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Fleets of unmanned robots can be beneficial for the long-term monitoring of
large areas, e.g., to monitor wild flocks, detect intruders, search and rescue.
Monitoring numerous dynamic targets in a collaborative and efficient way is a
challenging problem that requires online coordination and information fusion.
The majority of existing works either assume a passive all-to-all observation
model to minimize the summed uncertainties over all targets by all robots, or
optimize over the jointed discrete actions while neglecting the dynamic
constraints of the robots and unknown behaviors of the targets. This work
proposes an online task and motion coordination algorithm that ensures an
explicitly-bounded estimation uncertainty for the target states, while
minimizing the average number of active robots. The robots have a limited-range
perception to actively track a limited number of targets simultaneously, of
which their future control decisions are all unknown. It includes: (i) the
assignment of monitoring tasks, modeled as a flexible size multiple vehicle
routing problem with time windows (m-MVRPTW), given the predicted target
trajectories with uncertainty measure in the road-networks; (ii) the nonlinear
model predictive control (NMPC) for optimizing the robot trajectories under
uncertainty and safety constraints. It is shown that the robots can switch
between active and inactive roles dynamically online as required by the unknown
monitoring task. The proposed methods are validated via large-scale simulations
of up to $100$ robots and targets.
</p>
</div>
</dd>
<dt><a name="item180">[180]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08323" title="Abstract">arXiv:2309.08323</a> [<a href="/pdf/2309.08323" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MLP Based Continuous Gait Recognition of a Powered Ankle Prosthesis with  Serial Elastic Actuator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yanze Li</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+F">Feixing Chen</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+J">Jingqi Cao</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+R">Ruoqi Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xuan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xingbang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+Y">Yubo Fan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">Powered ankle prostheses effectively assist people with lower limb amputation
to perform daily activities. High performance prostheses with adjustable
compliance and capability to predict and implement amputee's intent are crucial
for them to be comparable to or better than a real limb. However, current
designs fail to provide simple yet effective compliance of the joint with full
potential of modification, and lack accurate gait prediction method in real
time. This paper proposes an innovative design of powered ankle prosthesis with
serial elastic actuator (SEA), and puts forward a MLP based gait recognition
method that can accurately and continuously predict more gait parameters for
motion sensing and control. The prosthesis mimics biological joint with similar
weight, torque, and power which can assist walking of up to 4 m/s. A new design
of planar torsional spring is proposed for the SEA, which has better stiffness,
endurance, and potential of modification than current designs. The gait
recognition system simultaneously generates locomotive speed, gait phase, ankle
angle and angular velocity only utilizing signals of single IMU, holding
advantage in continuity, adaptability for speed range, accuracy, and capability
of multi-functions.
</p>
</div>
</dd>
<dt><a name="item181">[181]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08324" title="Abstract">arXiv:2309.08324</a> [<a href="/pdf/2309.08324" title="Download PDF">pdf</a>, <a href="/format/2309.08324" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Object-oriented mapping in dynamic environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pekkanen%2C+M">Matti Pekkanen</a>, 
<a href="/search/cs?searchtype=author&query=Verdoja%2C+F">Francesco Verdoja</a>, 
<a href="/search/cs?searchtype=author&query=Kyrki%2C+V">Ville Kyrki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE-ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Grid maps, especially occupancy grid maps, are ubiquitous in many mobile
robot applications. To simplify the process of learning the map, grid maps
subdivide the world into a grid of cells, whose occupancies are independently
estimated using only measurements in the perceptual field of the particular
cell. However, the world consists of objects that span multiple cells, which
means that measurements falling onto a cell provide evidence on the occupancy
of other cells belonging to the same object. This correlation is not captured
by current models. In this work, we present a way to generalize the update of
grid maps relaxing the assumption of independence by modeling the relationship
between the measurements and the occupancy of each cell as a set of latent
variables, and jointly estimating those variables and the posterior of the map.
Additionally, we propose a method to estimate the latent variables by
clustering based on semantic labels and an extension to the Normal
Distributions Transfer Occupancy Map (NDT-OM) to facilitate the proposed map
update method. We perform comprehensive experiments of map creation and
localization with real world data sets, and show that the proposed method
creates better maps in highly dynamic environments compared to state-of-the-art
methods. Finally, we demonstrate the ability of the proposed method to remove
occluded objects from the map in a lifelong map update scenario.
</p>
</div>
</dd>
<dt><a name="item182">[182]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08325" title="Abstract">arXiv:2309.08325</a> [<a href="/pdf/2309.08325" title="Download PDF">pdf</a>, <a href="/format/2309.08325" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributional Inclusion Hypothesis and Quantifications: Probing  Hypernymy in Functional Distributional Semantics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lo%2C+C+H">Chun Hei Lo</a>, 
<a href="/search/cs?searchtype=author&query=Emerson%2C+G">Guy Emerson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Functional Distributional Semantics (FDS) models the meaning of words by
truth-conditional functions. This provides a natural representation for
hypernymy, but no guarantee that it is learnt when FDS models are trained on a
corpus. We demonstrate that FDS models learn hypernymy when a corpus strictly
follows the Distributional Inclusion Hypothesis. We further introduce a
training objective that allows FDS to handle simple universal quantifications,
thus enabling hypernymy learning under the reverse of DIH. Experimental results
on both synthetic and real data sets confirm our hypotheses and the
effectiveness of our proposed objective.
</p>
</div>
</dd>
<dt><a name="item183">[183]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08332" title="Abstract">arXiv:2309.08332</a> [<a href="/pdf/2309.08332" title="Download PDF">pdf</a>, <a href="/format/2309.08332" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Estimation of Counterfactual Interventions under Uncertainties
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weilbach%2C+J">Juliane Weilbach</a>, 
<a href="/search/cs?searchtype=author&query=Gerwinn%2C+S">Sebastian Gerwinn</a>, 
<a href="/search/cs?searchtype=author&query=Kandemir%2C+M">Melih Kandemir</a>, 
<a href="/search/cs?searchtype=author&query=Fraenzle%2C+M">Martin Fraenzle</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
<p class="mathjax">Counterfactual analysis is intuitively performed by humans on a daily basis
eg. "What should I have done differently to get the loan approved?". Such
counterfactual questions also steer the formulation of scientific hypotheses.
More formally it provides insights about potential improvements of a system by
inferring the effects of hypothetical interventions into a past observation of
the system's behaviour which plays a prominent role in a variety of industrial
applications. Due to the hypothetical nature of such analysis, counterfactual
distributions are inherently ambiguous. This ambiguity is particularly
challenging in continuous settings in which a continuum of explanations exist
for the same observation. In this paper, we address this problem by following a
hierarchical Bayesian approach which explicitly models such uncertainty. In
particular, we derive counterfactual distributions for a Bayesian Warped
Gaussian Process thereby allowing for non-Gaussian distributions and
non-additive noise. We illustrate the properties our approach on a synthetic
and on a semi-synthetic example and show its performance when used within an
algorithmic recourse downstream task.
</p>
</div>
</dd>
<dt><a name="item184">[184]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08333" title="Abstract">arXiv:2309.08333</a> [<a href="/pdf/2309.08333" title="Download PDF">pdf</a>, <a href="/format/2309.08333" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Let&#x27;s Predict Who Will Move to a New Job
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gahar%2C+R+M">Rania Mkhinini Gahar</a>, 
<a href="/search/cs?searchtype=author&query=Hidri%2C+A">Adel Hidri</a>, 
<a href="/search/cs?searchtype=author&query=Hidri%2C+M+S">Minyar Sassi Hidri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Advanced Systems and
  Emergent Technologies (IC_ASET)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Any company's human resources department faces the challenge of predicting
whether an applicant will search for a new job or stay with the company. In
this paper, we discuss how machine learning (ML) is used to predict who will
move to a new job. First, the data is pre-processed into a suitable format for
ML models. To deal with categorical features, data encoding is applied and
several MLA (ML Algorithms) are performed including Random Forest (RF),
Logistic Regression (LR), Decision Tree (DT), and eXtreme Gradient Boosting
(XGBoost). To improve the performance of ML models, the synthetic minority
oversampling technique (SMOTE) is used to retain them. Models are assessed
using decision support metrics such as precision, recall, F1-Score, and
accuracy.
</p>
</div>
</dd>
<dt><a name="item185">[185]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08337" title="Abstract">arXiv:2309.08337</a> [<a href="/pdf/2309.08337" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Proceedings of the XII International Workshop on Locational Analysis and  Related Problems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Baldomero-Naranjo%2C+M">Marta Baldomero-Naranjo</a>, 
<a href="/search/cs?searchtype=author&query=Blanco%2C+V">V&#xed;ctor Blanco</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa%2C+S">Sergio Garc&#xed;a</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%A1zquez%2C+R">Ricardo G&#xe1;zquez</a>, 
<a href="/search/cs?searchtype=author&query=Kalcsics%2C+J">J&#xf6;rg Kalcsics</a>, 
<a href="/search/cs?searchtype=author&query=Mart%C3%ADnez-Merino%2C+L+I">Luisa I. Mart&#xed;nez-Merino</a>, 
<a href="/search/cs?searchtype=author&query=Mu%C3%B1oz-Oca%C3%B1a%2C+J+M">Juan M. Mu&#xf1;oz-Oca&#xf1;a</a>, 
<a href="/search/cs?searchtype=author&query=Temprano%2C+F">Francisco Temprano</a>, 
<a href="/search/cs?searchtype=author&query=Torrej%C3%B3n%2C+A">Alberto Torrej&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The proceedings book of the previous editions can be found at <a href="/abs/2002.08287">arXiv:2002.08287</a> <a href="/abs/2002.08293">arXiv:2002.08293</a> <a href="/abs/2002.08300">arXiv:2002.08300</a> <a href="/abs/2002.01702">arXiv:2002.01702</a> <a href="/abs/2202.13878">arXiv:2202.13878</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Other Computer Science (cs.OH)</span>

</div>
<p class="mathjax">The International Workshop on Locational Analysis and Related Problems will
take place during September 7-8, 2023 in Edinburgh (United Kingdom). It is
organized by the Spanish Location Network and the Location Group GELOCA from
the Spanish Society of Statistics and Operations Research (SEIO). The Spanish
Location Network is a group of more than 140 researchers from several Spanish
universities organized into 7 thematic groups. The Network has been funded by
the Spanish Government since 2003. The current project is RED2022-134149-T. One
of the main activities of the Network is a yearly meeting aimed at promoting
the communication among its members and between them and other researchers, and
to contribute to the development of the location field and related problems. As
a proof of the internationalization of this research group, this will be the
first time that the meeting is held out of Spain. The topics of interest are
location analysis and related problems. This includes location models,
networks, transportation, logistics, exact and heuristic solution methods, and
computational geometry, among others.
</p>
</div>
</dd>
<dt><a name="item186">[186]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08339" title="Abstract">arXiv:2309.08339</a> [<a href="/pdf/2309.08339" title="Download PDF">pdf</a>, <a href="/format/2309.08339" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of ADAM with Constant Step Size in Non-Convex Settings: A  Simple Proof
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mazumder%2C+A">Alokendu Mazumder</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+B">Bhartendu Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Tayal%2C+M">Manan Tayal</a>, 
<a href="/search/cs?searchtype=author&query=Rathore%2C+P">Punit Rathore</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages including references and appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC)

</div>
<p class="mathjax">In neural network training, RMSProp and ADAM remain widely favoured
optimization algorithms. One of the keys to their performance lies in selecting
the correct step size, which can significantly influence their effectiveness.
It is worth noting that these algorithms performance can vary considerably,
depending on the chosen step sizes. Additionally, questions about their
theoretical convergence properties continue to be a subject of interest. In
this paper, we theoretically analyze a constant stepsize version of ADAM in the
non-convex setting. We show sufficient conditions for the stepsize to achieve
almost sure asymptotic convergence of the gradients to zero with minimal
assumptions. We also provide runtime bounds for deterministic ADAM to reach
approximate criticality when working with smooth, non-convex functions.
</p>
</div>
</dd>
<dt><a name="item187">[187]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08341" title="Abstract">arXiv:2309.08341</a> [<a href="/pdf/2309.08341" title="Download PDF">pdf</a>, <a href="/format/2309.08341" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Road Boundary Estimation Using Sparse Automotive Radar Inputs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kingery%2C+A">Aaron Kingery</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Dezhen Song</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">This paper presents a new approach to detecting road boundaries based on
sparse radar signals. We model the roadway using a homogeneous model and derive
its conditional predictive model under known radar motion. Using the
conditional predictive model and model radar points using a Dirichlet Process
Mixture Model (DPMM), we employ Mean Field Variational Inference (MFVI) to
derive an unconditional road boundary model distribution. In order to generate
initial candidate solutions for the MFVI, we develop a custom Random Sample and
Consensus (RANSAC) variant to propose unseen model instances as candidate road
boundaries. For each radar point cloud we alternate the MFVI and RANSAC
proposal steps until convergence to generate the best estimate of all candidate
models. We select the candidate model with the minimum lateral distance to the
radar on each side as the estimates of the left and right boundaries. We have
implemented the proposed algorithm in C++. We have tested the algorithm and it
has shown satisfactory results. More specifically, the mean lane boundary
estimation error is not more than 11.0 cm.
</p>
</div>
</dd>
<dt><a name="item188">[188]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08342" title="Abstract">arXiv:2309.08342</a> [<a href="/pdf/2309.08342" title="Download PDF">pdf</a>, <a href="/format/2309.08342" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Achievable Rate of a STAR-RIS Assisted Massive MIMO System Under  Spatially-Correlated Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Papazafeiropoulos%2C+A">Anastasios Papazafeiropoulos</a>, 
<a href="/search/cs?searchtype=author&query=Tran%2C+L">Le-Nam Tran</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+Z">Zaid Abdullah</a>, 
<a href="/search/cs?searchtype=author&query=Kourtessis%2C+P">Pandelis Kourtessis</a>, 
<a href="/search/cs?searchtype=author&query=Chatzinotas%2C+S">Symeon Chatzinotas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted in IEEE TWC
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Reconfigurable intelligent surfaces (RIS)-assisted massive multiple-input
multiple-output (mMIMO) is a promising technology for applications in
next-generation networks. However, reflecting-only RIS provides limited
coverage compared to a simultaneously transmitting and reflecting RIS
(STAR-RIS). Hence, in this paper, we focus on the downlink achievable rate and
its optimization of a STAR-RIS-assisted mMIMO system. Contrary to previous
works on STAR-RIS, we consider mMIMO, correlated fading, and multiple user
equipments (UEs) at both sides of the RIS. In particular, we introduce an
estimation approach of the aggregated channel with the main benefit of reduced
overhead links instead of estimating the individual channels. {Next, leveraging
channel hardening in mMIMO and the use-and-forget bounding technique, we obtain
an achievable rate in closed-form that only depends on statistical channel
state information (CSI). To optimize the amplitudes and phase shifts of the
STAR-RIS, we employ a projected gradient ascent method (PGAM) that
simultaneously adjusts the amplitudes and phase shifts for both energy
splitting (ES) and mode switching (MS) STAR-RIS operation protocols.} By
considering large-scale fading, the proposed optimization can be performed
every several coherence intervals, which can significantly reduce overhead.
Considering that STAR-RIS has twice the number of controllable parameters
<br />compared to conventional reflecting-only RIS, this accomplishment offers
substantial practical benefits. Simulations are carried out to verify the
analytical results, reveal the interplay of the achievable rate with
fundamental parameters, and show the superiority of STAR-RIS regarding its
achievable rate compared to its reflecting-only counterpart.
</p>
</div>
</dd>
<dt><a name="item189">[189]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08345" title="Abstract">arXiv:2309.08345</a> [<a href="/pdf/2309.08345" title="Download PDF">pdf</a>, <a href="/format/2309.08345" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data Distribution Bottlenecks in Grounding Language Models to Knowledge  Bases
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shu%2C+Y">Yiheng Shu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zhiwei Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Language models (LMs) have already demonstrated remarkable abilities in
understanding and generating both natural and formal language. Despite these
advances, their integration with real-world environments such as large-scale
knowledge bases (KBs) remains an underdeveloped area, affecting applications
such as semantic parsing and indulging in "hallucinated" information. This
paper is an experimental investigation aimed at uncovering the robustness
challenges that LMs encounter when tasked with knowledge base question
answering (KBQA). The investigation covers scenarios with inconsistent data
distribution between training and inference, such as generalization to unseen
domains, adaptation to various language variations, and transferability across
different datasets. Our comprehensive experiments reveal that even when
employed with our proposed data augmentation techniques, advanced small and
large language models exhibit poor performance in various dimensions. While the
LM is a promising technology, the robustness of the current form in dealing
with complex environments is fragile and of limited practicality because of the
data distribution issue. This calls for future research on data collection and
LM learning paradims.
</p>
</div>
</dd>
<dt><a name="item190">[190]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08347" title="Abstract">arXiv:2309.08347</a> [<a href="/pdf/2309.08347" title="Download PDF">pdf</a>, <a href="/format/2309.08347" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reward Engineering for Generating Semi-structured Explanation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Han%2C+J">Jiuzhou Han</a>, 
<a href="/search/cs?searchtype=author&query=Buntine%2C+W">Wray Buntine</a>, 
<a href="/search/cs?searchtype=author&query=Shareghi%2C+E">Ehsan Shareghi</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Semi-structured explanation depicts the implicit process of a reasoner with
an explicit representation. This explanation highlights how available
information in a specific query is supplemented with information a reasoner
produces from its internal weights towards generating an answer. Despite the
recent improvements in generative capabilities of language models, producing
structured explanations to verify model's true reasoning capabilities remains a
challenge. This issue is particularly pronounced for not-so-large LMs, as the
reasoner is expected to couple a sequential answer with a structured
explanation which embodies both the correct presentation and the correct
reasoning process. In this work, we first underscore the limitations of
supervised fine-tuning (SFT) in tackling this challenge, and then introduce a
carefully crafted reward engineering method in reinforcement learning (RL) to
better address this problem. We investigate multiple reward aggregation methods
and provide a detailed discussion which sheds light on the promising potential
of RL for future research. Our proposed reward on two semi-structured
explanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new
state-of-the-art results.
</p>
</div>
</dd>
<dt><a name="item191">[191]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08351" title="Abstract">arXiv:2309.08351</a> [<a href="/pdf/2309.08351" title="Download PDF">pdf</a>, <a href="/format/2309.08351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Headless Language Models: Learning without Predicting with Contrastive  Weight Tying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Godey%2C+N">Nathan Godey</a>, 
<a href="/search/cs?searchtype=author&query=de+la+Clergerie%2C+%C3%89">&#xc9;ric de la Clergerie</a>, 
<a href="/search/cs?searchtype=author&query=Sagot%2C+B">Beno&#xee;t Sagot</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Self-supervised pre-training of language models usually consists in
predicting probability distributions over extensive token vocabularies. In this
study, we propose an innovative method that shifts away from probability
prediction and instead focuses on reconstructing input embeddings in a
contrastive fashion via Constrastive Weight Tying (CWT). We apply this approach
to pretrain Headless Language Models in both monolingual and multilingual
contexts. Our method offers practical advantages, substantially reducing
training computational requirements by up to 20 times, while simultaneously
enhancing downstream performance and data efficiency. We observe a significant
+1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement
compared to classical LMs within similar compute budgets.
</p>
</div>
</dd>
<dt><a name="item192">[192]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08353" title="Abstract">arXiv:2309.08353</a> [<a href="/pdf/2309.08353" title="Download PDF">pdf</a>, <a href="/format/2309.08353" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Continual Learning with Deep Streaming Regularized Discriminant Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khawand%2C+J">Joe Khawand</a>, 
<a href="/search/cs?searchtype=author&query=Hanappe%2C+P">Peter Hanappe</a>, 
<a href="/search/cs?searchtype=author&query=Colliaux%2C+D">David Colliaux</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Continual learning is increasingly sought after in real world machine
learning applications, as it enables learning in a more human-like manner.
Conventional machine learning approaches fail to achieve this, as incrementally
updating the model with non-identically distributed data leads to catastrophic
forgetting, where existing representations are overwritten. Although
traditional continual learning methods have mostly focused on batch learning,
which involves learning from large collections of labeled data sequentially,
this approach is not well-suited for real-world applications where we would
like new data to be integrated directly. This necessitates a paradigm shift
towards streaming learning. In this paper, we propose a streaming version of
regularized discriminant analysis as a solution to this challenge. We combine
our algorithm with a convolutional neural network and demonstrate that it
outperforms both batch learning and existing streaming learning algorithms on
the ImageNet ILSVRC-2012 dataset.
</p>
</div>
</dd>
<dt><a name="item193">[193]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08360" title="Abstract">arXiv:2309.08360</a> [<a href="/pdf/2309.08360" title="Download PDF">pdf</a>, <a href="/format/2309.08360" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advanced White-Box Heuristics for Search-Based Fuzzing of REST APIs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arcuri%2C+A">Andrea Arcuri</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Man Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Galeotti%2C+J+P">Juan Pablo Galeotti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
<p class="mathjax">Due to its importance and widespread use in industry, automated testing of
REST APIs has attracted major interest from the research community in the last
few years. However, most of the work in the literature has been focused on
black-box fuzzing. Although existing fuzzers have been used to automatically
find many faults in existing APIs, there are still several open research
challenges that hinder the achievement of better results (e.g., in terms of
code coverage and fault finding). For example, under-specified schemas are a
major issue for black-box fuzzers. Currently, EvoMaster is the only existing
tool that supports white-box fuzzing of REST APIs. In this paper, we provide a
series of novel white-box heuristics, including for example how to deal with
under-specified constrains in API schemas, as well as under-specified schemas
in SQL databases. Our novel techniques are implemented as an extension to our
open-source, search-based fuzzer EvoMaster. An empirical study on 14 APIs from
the EMB corpus, plus one industrial API, shows clear improvements of the
results in some of these APIs.
</p>
</div>
</dd>
<dt><a name="item194">[194]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08361" title="Abstract">arXiv:2309.08361</a> [<a href="/pdf/2309.08361" title="Download PDF">pdf</a>, <a href="/format/2309.08361" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bystanders of Online Moderation: Examining the Effects of Witnessing  Post-Removal Explanations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jhaver%2C+S">Shagun Jhaver</a>, 
<a href="/search/cs?searchtype=author&query=Rathi%2C+H">Himanshu Rathi</a>, 
<a href="/search/cs?searchtype=author&query=Saha%2C+K">Koustuv Saha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Prior research on transparency in content moderation has demonstrated the
benefits of offering post-removal explanations to sanctioned users. In this
paper, we examine whether the influence of such explanations transcends those
who are moderated to the bystanders who witness such explanations. We conduct a
quasi-experimental study on two popular Reddit communities (r/askreddit and
r/science) by collecting their data spanning 13 months-a total of 85.5M posts
made by 5.9M users. Our causal-inference analyses show that bystanders
significantly increase their posting activity and interactivity levels as
compared to their matched control set of users. Our findings suggest that
explanations clarify and reinforce the social norms of online spaces, enhance
community engagement, and benefit many more members than previously understood.
We discuss the theoretical implications and design recommendations of this
research, focusing on how investing more efforts in post-removal explanations
can help build thriving online communities.
</p>
</div>
</dd>
<dt><a name="item195">[195]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08362" title="Abstract">arXiv:2309.08362</a> [<a href="/pdf/2309.08362" title="Download PDF">pdf</a>, <a href="/format/2309.08362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Big Data Modeling and Management Systems: From DBMS to BDMS
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gahar%2C+R+M">Rania Mkhinini Gahar</a>, 
<a href="/search/cs?searchtype=author&query=Arfaoui%2C+O">Olfa Arfaoui</a>, 
<a href="/search/cs?searchtype=author&query=Hidri%2C+M+S">Minyar Sassi Hidri</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 9 Figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> 2023 IEEE International Conference on Advanced Systems and
  Emergent Technologies (IC_ASET)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>

</div>
<p class="mathjax">To succeed in a Big Data strategy, you have to arm yourself with a wide range
of data skills and best practices. This strategy can result in an impressive
asset that can streamline operational costs, reduce time to market, and enable
the creation of new products. However, several Big Data challenges may take
place in enterprises when it comes to moving initiatives of boardroom
discussions to effective practices. From a broader perspective, we take on this
paper two very important challenges, namely modeling, and management. The main
context here is to highlight the importance of understanding data modeling and
knowing how to process complex data while supporting the characteristics of
each model.
</p>
</div>
</dd>
<dt><a name="item196">[196]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08363" title="Abstract">arXiv:2309.08363</a> [<a href="/pdf/2309.08363" title="Download PDF">pdf</a>, <a href="/format/2309.08363" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Narratives of War: Ukrainian Memetic Warfare on Twitter
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mejova%2C+Y">Yelena Mejova</a>, 
<a href="/search/cs?searchtype=author&query=Capozzi%2C+A">Arthur Capozzi</a>, 
<a href="/search/cs?searchtype=author&query=Monti%2C+C">Corrado Monti</a>, 
<a href="/search/cs?searchtype=author&query=De+Francisci+Morales%2C+G">Gianmarco De Francisci Morales</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>; Human-Computer Interaction (cs.HC); Social and Information Networks (cs.SI)

</div>
<p class="mathjax">The 2022 Russian invasion of Ukraine has seen an intensification in the use
of social media by governmental actors in cyber warfare. Wartime communication
via memes has been a successful strategy used not only by independent accounts
such as @uamemesforces, but also-for the first time in a full-scale interstate
war-by official Ukrainian government accounts such as @Ukraine and @DefenceU.
We study this prominent example of memetic warfare through the lens of its
narratives, and find them to be a key component of success: tweets with a
'victim' narrative garner twice as many retweets. However, malevolent
narratives focusing on the enemy resonate more than those about heroism or
victims with countries providing more assistance to Ukraine. Our findings
present a nuanced examination of Ukraine's influence operations and of the
worldwide response to it, thus contributing new insights into the evolution of
socio-technical systems in times of war.
</p>
</div>
</dd>
<dt><a name="item197">[197]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08365" title="Abstract">arXiv:2309.08365</a> [<a href="/pdf/2309.08365" title="Download PDF">pdf</a>, <a href="/format/2309.08365" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M$^3$Net: Multilevel, Mixed and Multistage Attention Network for Salient  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yao Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+P">Pan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">XiaoYang Tan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Most existing salient object detection methods mostly use U-Net or feature
pyramid structure, which simply aggregates feature maps of different scales,
ignoring the uniqueness and interdependence of them and their respective
contributions to the final prediction. To overcome these, we propose the
M$^3$Net, i.e., the Multilevel, Mixed and Multistage attention network for
Salient Object Detection (SOD). Firstly, we propose Multiscale Interaction
Block which innovatively introduces the cross-attention approach to achieve the
interaction between multilevel features, allowing high-level features to guide
low-level feature learning and thus enhancing salient regions. Secondly,
considering the fact that previous Transformer based SOD methods locate salient
regions only using global self-attention while inevitably overlooking the
details of complex objects, we propose the Mixed Attention Block. This block
combines global self-attention and window self-attention, aiming at modeling
context at both global and local levels to further improve the accuracy of the
prediction map. Finally, we proposed a multilevel supervision strategy to
optimize the aggregated feature stage-by-stage. Experiments on six challenging
datasets demonstrate that the proposed M$^3$Net surpasses recent CNN and
Transformer-based SOD arts in terms of four metrics. Codes are available at
https://github.com/I2-Multimedia-Lab/M3Net.
</p>
</div>
</dd>
<dt><a name="item198">[198]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08368" title="Abstract">arXiv:2309.08368</a> [<a href="/pdf/2309.08368" title="Download PDF">pdf</a>, <a href="/format/2309.08368" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Burned Area Delineation through Multitask Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnaudo%2C+E">Edoardo Arnaudo</a>, 
<a href="/search/cs?searchtype=author&query=Barco%2C+L">Luca Barco</a>, 
<a href="/search/cs?searchtype=author&query=Merlo%2C+M">Matteo Merlo</a>, 
<a href="/search/cs?searchtype=author&query=Rossi%2C+C">Claudio Rossi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ECML PKDD 2023 - MACLEAN Workshop (11 pages, 3 figures)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">In recent years, wildfires have posed a significant challenge due to their
increasing frequency and severity. For this reason, accurate delineation of
burned areas is crucial for environmental monitoring and post-fire assessment.
However, traditional approaches relying on binary segmentation models often
struggle to achieve robust and accurate results, especially when trained from
scratch, due to limited resources and the inherent imbalance of this
segmentation task. We propose to address these limitations in two ways: first,
we construct an ad-hoc dataset to cope with the limited resources, combining
information from Sentinel-2 feeds with Copernicus activations and other data
sources. In this dataset, we provide annotations for multiple tasks, including
burned area delineation and land cover segmentation. Second, we propose a
multitask learning framework that incorporates land cover classification as an
auxiliary task to enhance the robustness and performance of the burned area
segmentation models. We compare the performance of different models, including
UPerNet and SegFormer, demonstrating the effectiveness of our approach in
comparison to standard binary segmentation.
</p>
</div>
</dd>
<dt><a name="item199">[199]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08369" title="Abstract">arXiv:2309.08369</a> [<a href="/pdf/2309.08369" title="Download PDF">pdf</a>, <a href="/format/2309.08369" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Efficient Wide-Range Pseudo-3D Vehicle Detection Using A Single  Camera
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ye%2C+Z">Zhupeng Ye</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yinqi Li</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Z">Zejian Yuan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 27 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Wide-range and fine-grained vehicle detection plays a critical role in
enabling active safety features in intelligent driving systems. However,
existing vehicle detection methods based on rectangular bounding boxes (BBox)
often struggle with perceiving wide-range objects, especially small objects at
long distances. And BBox expression cannot provide detailed geometric shape and
pose information of vehicles. This paper proposes a novel wide-range Pseudo-3D
Vehicle Detection method based on images from a single camera and incorporates
efficient learning methods. This model takes a spliced image as input, which is
obtained by combining two sub-window images from a high-resolution image. This
image format maximizes the utilization of limited image resolution to retain
essential information about wide-range vehicle objects. To detect pseudo-3D
objects, our model adopts specifically designed detection heads. These heads
simultaneously output extended BBox and Side Projection Line (SPL)
representations, which capture vehicle shapes and poses, enabling
high-precision detection. To further enhance the performance of detection, a
joint constraint loss combining both the object box and SPL is designed during
model training, improving the efficiency, stability, and prediction accuracy of
the model. Experimental results on our self-built dataset demonstrate that our
model achieves favorable performance in wide-range pseudo-3D vehicle detection
across multiple evaluation metrics. Our demo video has been placed at
https://www.youtube.com/watch?v=1gk1PmsQ5Q8.
</p>
</div>
</dd>
<dt><a name="item200">[200]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08372" title="Abstract">arXiv:2309.08372</a> [<a href="/pdf/2309.08372" title="Download PDF">pdf</a>, <a href="/format/2309.08372" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Domain Gap: Exploiting Subjectivity in Sketch-Based Person  Retrieval
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+K">Kejun Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhixiang Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yinqiang Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Satoh%2C+S">Shin&#x27;ichi Satoh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ACM Multimedia 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Multimedia (cs.MM)

</div>
<p class="mathjax">Person re-identification (re-ID) requires densely distributed cameras. In
practice, the person of interest may not be captured by cameras and, therefore,
needs to be retrieved using subjective information (e.g., sketches from
witnesses). Previous research defines this case using the sketch as sketch
re-identification (Sketch re-ID) and focuses on eliminating the domain gap.
Actually, subjectivity is another significant challenge. We model and
investigate it by posing a new dataset with multi-witness descriptions. It
features two aspects. 1) Large-scale. It contains over 4,763 sketches and
32,668 photos, making it the largest Sketch re-ID dataset. 2) Multi-perspective
and multi-style. Our dataset offers multiple sketches for each identity.
Witnesses' subjective cognition provides multiple perspectives on the same
individual, while different artists' drawing styles provide variation in sketch
styles. We further have two novel designs to alleviate the challenge of
subjectivity. 1) Fusing subjectivity. We propose a non-local (NL) fusion module
that gathers sketches from different witnesses for the same identity. 2)
Introducing objectivity. An AttrAlign module utilizes attributes as an implicit
mask to align cross-domain features. To push forward the advance of Sketch
re-ID, we set three benchmarks (large-scale, multi-style, cross-style).
Extensive experiments demonstrate our leading performance in these benchmarks.
Dataset and Codes are publicly available at:
https://github.com/Lin-Kayla/subjectivity-sketch-reid
</p>
</div>
</dd>
<dt><a name="item201">[201]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08374" title="Abstract">arXiv:2309.08374</a> [<a href="/pdf/2309.08374" title="Download PDF">pdf</a>, <a href="/format/2309.08374" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Understanding the limitations of self-supervised learning for tabular  anomaly detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mai%2C+K+T">Kimberly T. Mai</a>, 
<a href="/search/cs?searchtype=author&query=Davies%2C+T">Toby Davies</a>, 
<a href="/search/cs?searchtype=author&query=Griffin%2C+L+D">Lewis D. Griffin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">While self-supervised learning has improved anomaly detection in computer
vision and natural language processing, it is unclear whether tabular data can
benefit from it. This paper explores the limitations of self-supervision for
tabular anomaly detection. We conduct several experiments spanning various
pretext tasks on 26 benchmark datasets to understand why this is the case. Our
results confirm representations derived from self-supervision do not improve
tabular anomaly detection performance compared to using the raw representations
of the data. We show this is due to neural networks introducing irrelevant
features, which reduces the effectiveness of anomaly detectors. However, we
demonstrate that using a subspace of the neural network's representation can
recover performance.
</p>
</div>
</dd>
<dt><a name="item202">[202]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08375" title="Abstract">arXiv:2309.08375</a> [<a href="/pdf/2309.08375" title="Download PDF">pdf</a>, <a href="/format/2309.08375" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Adaptive Priority Reweighing for Generalizing Fairness Improvement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhihao Hu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yiran Xu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+M">Mengnan Du</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+J">Jindong Gu</a>, 
<a href="/search/cs?searchtype=author&query=Tian%2C+X">Xinmei Tian</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+F">Fengxiang He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">With the increasing penetration of machine learning applications in critical
decision-making areas, calls for algorithmic fairness are more prominent.
Although there have been various modalities to improve algorithmic fairness
through learning with fairness constraints, their performance does not
generalize well in the test set. A performance-promising fair algorithm with
better generalizability is needed. This paper proposes a novel adaptive
reweighing method to eliminate the impact of the distribution shifts between
training and test data on model generalizability. Most previous reweighing
methods propose to assign a unified weight for each (sub)group. Rather, our
method granularly models the distance from the sample predictions to the
decision boundary. Our adaptive reweighing method prioritizes samples closer to
the decision boundary and assigns a higher weight to improve the
generalizability of fair classifiers. Extensive experiments are performed to
validate the generalizability of our adaptive priority reweighing method for
accuracy and fairness measures (i.e., equal opportunity, equalized odds, and
demographic parity) in tabular benchmarks. We also highlight the performance of
our method in improving the fairness of language and vision models. The code is
available at https://github.com/che2198/APW.
</p>
</div>
</dd>
<dt><a name="item203">[203]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08379" title="Abstract">arXiv:2309.08379</a> [<a href="/pdf/2309.08379" title="Download PDF">pdf</a>, <a href="/format/2309.08379" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PatFig: Generating Short and Long Captions for Patent Figures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aubakirova%2C+D">Dana Aubakirova</a>, 
<a href="/search/cs?searchtype=author&query=Gerdes%2C+K">Kim Gerdes</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+L">Lufei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> accepted to the ICCV 2023, CLVL: 5th Workshop on Closing the Loop Between Vision and Language
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">This paper introduces Qatent PatFig, a novel large-scale patent figure
dataset comprising 30,000+ patent figures from over 11,000 European patent
applications. For each figure, this dataset provides short and long captions,
reference numerals, their corresponding terms, and the minimal claim set that
describes the interactions between the components of the image. To assess the
usability of the dataset, we finetune an LVLM model on Qatent PatFig to
generate short and long descriptions, and we investigate the effects of
incorporating various text-based cues at the prediction stage of the patent
figure captioning process.
</p>
</div>
</dd>
<dt><a name="item204">[204]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08380" title="Abstract">arXiv:2309.08380</a> [<a href="/pdf/2309.08380" title="Download PDF">pdf</a>, <a href="/format/2309.08380" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unleashing Potential of Evidence in Knowledge-Intensive Dialogue  Generation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xianjie Wu</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+T">Tongliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+D">Di Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+S">Shiwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yiyang Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhoujun Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Incorporating external knowledge into dialogue generation (KIDG) is crucial
for improving the correctness of response, where evidence fragments serve as
knowledgeable snippets supporting the factual dialogue replies. However,
introducing irrelevant content often adversely impacts reply quality and easily
leads to hallucinated responses. Prior work on evidence retrieval and
integration in dialogue systems falls short of fully leveraging existing
evidence since the model fails to locate useful fragments accurately and
overlooks hidden evidence labels within the KIDG dataset. To fully Unleash the
potential of evidence, we propose a framework to effectively incorporate
Evidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we
introduce an automatic evidence generation framework that harnesses the power
of Large Language Models (LLMs) to mine reliable evidence veracity labels from
unlabeled data. By utilizing these evidence labels, we train a reliable
evidence indicator to effectively identify relevant evidence from retrieved
passages. Furthermore, we propose an evidence-augmented generator with an
evidence-focused attention mechanism, which allows the model to concentrate on
evidenced segments. Experimental results on MultiDoc2Dial demonstrate the
efficacy of evidential label augmentation and refined attention mechanisms in
improving model performance. Further analysis confirms that the proposed method
outperforms other baselines (+3~+5 points) regarding coherence and factual
consistency.
</p>
</div>
</dd>
<dt><a name="item205">[205]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08382" title="Abstract">arXiv:2309.08382</a> [<a href="/pdf/2309.08382" title="Download PDF">pdf</a>, <a href="/format/2309.08382" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Double Domain Guided Real-Time Low-Light Image Enhancement for  Ultra-High-Definition Transportation Surveillance
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qu%2C+J">Jingxiang Qu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+R+W">Ryan Wen Liu</a>, 
<a href="/search/cs?searchtype=author&query=Gao%2C+Y">Yuan Gao</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yu Guo</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+F">Fenghua Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fei-yue Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Real-time transportation surveillance is an essential part of the intelligent
transportation system (ITS). However, images captured under low-light
conditions often suffer the poor visibility with types of degradation, such as
noise interference and vague edge features, etc. With the development of
imaging devices, the quality of the visual surveillance data is continually
increasing, like 2K and 4K, which has more strict requirements on the
efficiency of image processing. To satisfy the requirements on both enhancement
quality and computational speed, this paper proposes a double domain guided
real-time low-light image enhancement network (DDNet) for ultra-high-definition
(UHD) transportation surveillance. Specifically, we design an encoder-decoder
structure as the main architecture of the learning network. In particular, the
enhancement processing is divided into two subtasks (i.e., color enhancement
and gradient enhancement) via the proposed coarse enhancement module (CEM) and
LoG-based gradient enhancement module (GEM), which are embedded in the
encoder-decoder structure. It enables the network to enhance the color and edge
features simultaneously. Through the decomposition and reconstruction on both
color and gradient domains, our DDNet can restore the detailed feature
information concealed by the darkness with better visual quality and
efficiency. The evaluation experiments on standard and transportation-related
datasets demonstrate that our DDNet provides superior enhancement quality and
efficiency compared with the state-of-the-art methods. Besides, the object
detection and scene segmentation experiments indicate the practical benefits
for higher-level image analysis under low-light environments in ITS.
</p>
</div>
</dd>
<dt><a name="item206">[206]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08385" title="Abstract">arXiv:2309.08385</a> [<a href="/pdf/2309.08385" title="Download PDF">pdf</a>, <a href="/format/2309.08385" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Unified View Between Tensor Hypergraph Neural Networks And Signal  Denoising
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fuli Wang</a>, 
<a href="/search/cs?searchtype=author&query=Pena-Pena%2C+K">Karelia Pena-Pena</a>, 
<a href="/search/cs?searchtype=author&query=Qian%2C+W">Wei Qian</a>, 
<a href="/search/cs?searchtype=author&query=Arce%2C+G+R">Gonzalo R. Arce</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, accepted by EUSIPCO 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Hypergraph Neural networks (HyperGNNs) and hypergraph signal denoising
(HyperGSD) are two fundamental topics in higher-order network modeling.
Understanding the connection between these two domains is particularly useful
for designing novel HyperGNNs from a HyperGSD perspective, and vice versa. In
particular, the tensor-hypergraph convolutional network (T-HGCN) has emerged as
a powerful architecture for preserving higher-order interactions on
hypergraphs, and this work shows an equivalence relation between a HyperGSD
problem and the T-HGCN. Inspired by this intriguing result, we further design a
tensor-hypergraph iterative network (T-HGIN) based on the HyperGSD problem,
which takes advantage of a multi-step updating scheme in every single layer.
Numerical experiments are conducted to show the promising applications of the
proposed T-HGIN approach.
</p>
</div>
</dd>
<dt><a name="item207">[207]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08387" title="Abstract">arXiv:2309.08387</a> [<a href="/pdf/2309.08387" title="Download PDF">pdf</a>, <a href="/format/2309.08387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Graphics Representation with Differentiable Indirection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Datta%2C+S">Sayantan Datta</a>, 
<a href="/search/cs?searchtype=author&query=Marshall%2C+C">Carl Marshall</a>, 
<a href="/search/cs?searchtype=author&query=Dong%2C+Z">Zhao Dong</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zhengqin Li</a>, 
<a href="/search/cs?searchtype=author&query=Nowrouzezahrai%2C+D">Derek Nowrouzezahrai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project website: <a href="https://sayan1an.github.io/din.html">this https URL</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> SIGGRAPH Asia 2023 Conference Papers (SA Conference Papers '23),
  December 12--15, 2023, Sydney, NSW, Australia
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Graphics (cs.GR)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">We introduce differentiable indirection -- a novel learned primitive that
employs differentiable multi-scale lookup tables as an effective substitute for
traditional compute and data operations across the graphics pipeline. We
demonstrate its flexibility on a number of graphics tasks, i.e., geometric and
image representation, texture mapping, shading, and radiance field
representation. In all cases, differentiable indirection seamlessly integrates
into existing architectures, trains rapidly, and yields both versatile and
efficient results.
</p>
</div>
</dd>
<dt><a name="item208">[208]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08395" title="Abstract">arXiv:2309.08395</a> [<a href="/pdf/2309.08395" title="Download PDF">pdf</a>, <a href="/format/2309.08395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Learning by Self-Explaining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Stammer%2C+W">Wolfgang Stammer</a>, 
<a href="/search/cs?searchtype=author&query=Friedrich%2C+F">Felix Friedrich</a>, 
<a href="/search/cs?searchtype=author&query=Steinmann%2C+D">David Steinmann</a>, 
<a href="/search/cs?searchtype=author&query=Shindo%2C+H">Hikaru Shindo</a>, 
<a href="/search/cs?searchtype=author&query=Kersting%2C+K">Kristian Kersting</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Artificial intelligence (AI) research has a long track record of drawing
inspirations from findings from biology, in particular human intelligence. In
contrast to current AI research that mainly treats explanations as a means for
model inspection, a somewhat neglected finding from human psychology is the
benefit of self-explaining in an agents' learning process. Motivated by this,
we introduce a novel learning paradigm, termed Learning by Self-Explaining
(LSX). The underlying idea is that a learning module (learner) performs a base
task, e.g. image classification, and provides explanations to its decisions. An
internal critic module next evaluates the quality of these explanations given
the original task. Finally, the learner is refined with the critic's feedback
and the loop is repeated as required. The intuition behind this is that an
explanation is considered "good" if the critic can perform the same task given
the respective explanation. Despite many implementation possibilities the
structure of any LSX instantiation can be taxonomized based on four learning
modules which we identify as: Fit, Explain, Reflect and Revise. In our work, we
provide distinct instantiations of LSX for two different learner models, each
illustrating different choices for the various LSX components. We broadly
evaluate these on several datasets and show that Learning by Self-Explaining
not only boosts the generalization abilities of AI models, particularly in
small-data regimes, but also aids in mitigating the influence of confounding
factors, as well as leading to more task specific and faithful model
explanations. Overall, our results provide experimental evidence of the
potential of self-explaining within the learning phase of an AI model.
</p>
</div>
</dd>
<dt><a name="item209">[209]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08396" title="Abstract">arXiv:2309.08396</a> [<a href="/pdf/2309.08396" title="Download PDF">pdf</a>, <a href="/format/2309.08396" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Resource Optimization Using A Step-by-step Scheme in Wireless Sensing  and Localization Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruihang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jiayan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Jia%2C+M">Mu Jia</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+T">Tingting Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 28 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
<p class="mathjax">Due to the lack of wireless spectrum resources, people are focusing on the
versatile wireless networks. Wireless localization and target sensing both rely
on precise extraction of parameters such as signal amplitude, propagation delay
and Doppler shift from the received signals. Due to the high multi-path
resolution and strong penetration of UWB signals, both localization and sensing
can be achieved through the same UWB waveform. Practical networks are often
resource-constrained, in order to improve the accuracy of integrated networks,
we need to optimize the allocation of resources in the networks. Considering
the complexity of the multi-slot networks, this paper derives the Fisher
Information Matrix (FIM) expressions for single-slot and dual-slot integrated
sensing and localization (ISAL) networks respectively, and proposes two
resource optimization schemes, namely step-by-step scheme and integrated
scheme. The numerical results show that: (i) for the sensing-resource-deficient
networks with relatively uniform node distribution, the energy allocated to
each step in the step-by-step scheme satisfies the relationship: energy for
clock offset &lt; energy for radar localization &lt; energy for target sensing. (ii)
In the multi-slot ISAL networks, the system will allocate more energy to the
time slots where the networks are relatively sensing-resource-deficient. (iii)
The step-by-step scheme is more suitable for the sensing-resource-abundant
networks, while the integrated scheme is more suitable for the
sensing-resource-deficient networks.
</p>
</div>
</dd>
<dt><a name="item210">[210]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08397" title="Abstract">arXiv:2309.08397</a> [<a href="/pdf/2309.08397" title="Download PDF">pdf</a>, <a href="/format/2309.08397" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Exploration using Segmented Map with Keyframe Contribution  in Subterranean Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Boseong Kim</a>, 
<a href="/search/cs?searchtype=author&query=Seong%2C+H">Hyunki Seong</a>, 
<a href="/search/cs?searchtype=author&query=Shim%2C+D+H">D. Hyunchul Shim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Existing exploration algorithms mainly generate frontiers using random
sampling or motion primitive methods within a specific sensor range or search
space. However, frontiers generated within constrained spaces lead to
back-and-forth maneuvers in large-scale environments, thereby diminishing
exploration efficiency. To address this issue, we propose a method that
utilizes a 3D dense map to generate Segmented Exploration Regions (SERs) and
generate frontiers from a global-scale perspective. In particular, this paper
presents a novel topological map generation approach that fully utilizes
Line-of-Sight (LOS) features of LiDAR sensor points to enhance exploration
efficiency inside large-scale subterranean environments. Our topological map
contains the contributions of keyframes that generate each SER, enabling rapid
exploration through a switch between local path planning and global path
planning to each frontier. The proposed method achieved higher explored volume
generation than the state-of-the-art algorithm in a large-scale simulation
environment and demonstrated a 62% improvement in explored volume increment
performance. For validation, we conducted field tests using UAVs in real
subterranean environments, demonstrating the efficiency and speed of our
method.
</p>
</div>
</dd>
<dt><a name="item211">[211]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08398" title="Abstract">arXiv:2309.08398</a> [<a href="/pdf/2309.08398" title="Download PDF">pdf</a>, <a href="/format/2309.08398" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring Meta Information for Audio-based Zero-shot Bird Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gebhard%2C+A">Alexander Gebhard</a>, 
<a href="/search/cs?searchtype=author&query=Triantafyllopoulos%2C+A">Andreas Triantafyllopoulos</a>, 
<a href="/search/cs?searchtype=author&query=Bez%2C+T">Teresa Bez</a>, 
<a href="/search/cs?searchtype=author&query=Christ%2C+L">Lukas Christ</a>, 
<a href="/search/cs?searchtype=author&query=Kathan%2C+A">Alexander Kathan</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B+W">Bj&#xf6;rn W. Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been submitted to the IEEE for possible publication
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Advances in passive acoustic monitoring and machine learning have led to the
procurement of vast datasets for computational bioacoustic research.
Nevertheless, data scarcity is still an issue for rare and underrepresented
species. This study investigates how meta-information can improve zero-shot
audio classification, utilising bird species as an example case study due to
the availability of rich and diverse metadata. We investigate three different
sources of metadata: textual bird sound descriptions encoded via (S)BERT,
functional traits (AVONET), and bird life-history (BLH) characteristics. As
audio features, we extract audio spectrogram transformer (AST) embeddings and
project them to the dimension of the auxiliary information by adopting a single
linear layer. Then, we employ the dot product as compatibility function and a
standard zero-shot learning ranking hinge loss to determine the correct class.
The best results are achieved by concatenating the AVONET and BLH features
attaining a mean F1-score of .233 over five different test sets with 8 to 10
classes.
</p>
</div>
</dd>
<dt><a name="item212">[212]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08399" title="Abstract">arXiv:2309.08399</a> [<a href="/pdf/2309.08399" title="Download PDF">pdf</a>, <a href="/format/2309.08399" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimizing Modular Robot Composition: A Lexicographic Genetic Algorithm  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BClz%2C+J">Jonathan K&#xfc;lz</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)

</div>
<p class="mathjax">Industrial robots are designed as general-purpose hardware, which limits
their ability to adapt to changing task requirements or environments. Modular
robots, on the other hand, offer flexibility and can be easily customized to
suit diverse needs. The morphology, i.e., the form and structure of a robot,
significantly impacts the primary performance metrics acquisition cost, cycle
time, and energy efficiency. However, identifying an optimal module composition
for a specific task remains an open problem, presenting a substantial hurdle in
developing task-tailored modular robots. Previous approaches either lack
adequate exploration of the design space or the possibility to adapt to complex
tasks. We propose combining a genetic algorithm with a lexicographic evaluation
of solution candidates to overcome this problem and navigate search spaces
exceeding those in prior work by magnitudes in the number of possible
compositions. We demonstrate that our approach outperforms a state-of-the-art
baseline and is able to synthesize modular robots for industrial tasks in
cluttered environments.
</p>
</div>
</dd>
<dt><a name="item213">[213]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08401" title="Abstract">arXiv:2309.08401</a> [<a href="/pdf/2309.08401" title="Download PDF">pdf</a>, <a href="/format/2309.08401" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new upper bound for angular resolution
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Miyata%2C+H">Hiroyuki Miyata</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
<p class="mathjax">The angular resolution of a planar straight-line drawing of a graph is the
smallest angle formed by two edges incident to the same vertex. Garg and
Tamassia (ESA '94) constructed a family of planar graphs with maximum degree
$d$ that have angular resolution $O((\log d)^{\frac{1}{2}}/d^{\frac{3}{2}})$ in
any planar straight-line drawing. This upper bound has been the best known
upper bound on angular resolution for a long time. In this paper, we improve
this upper bound. For an arbitrarily small positive constant $\varepsilon$, we
construct a family of planar graphs with maximum degree $d$ that have angular
resolution $O((\log d)^\varepsilon/d^{\frac{3}{2}})$ in any planar
straight-line drawing.
</p>
</div>
</dd>
<dt><a name="item214">[214]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08404" title="Abstract">arXiv:2309.08404</a> [<a href="/pdf/2309.08404" title="Download PDF">pdf</a>, <a href="/format/2309.08404" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bayes-Optimal Estimation in Generalized Linear Models via Spatial  Coupling
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cobo%2C+P+P">Pablo Pascual Cobo</a>, 
<a href="/search/cs?searchtype=author&query=Hsieh%2C+K">Kuan Hsieh</a>, 
<a href="/search/cs?searchtype=author&query=Venkataramanan%2C+R">Ramji Venkataramanan</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 39 pages, 4 figures. A shorter version of this paper appeared in the proceedings of the 2023 IEEE International Symposium on Information Theory
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider the problem of signal estimation in a generalized linear model
(GLM). GLMs include many canonical problems in statistical estimation, such as
linear regression, phase retrieval, and 1-bit compressed sensing. Recent work
has precisely characterized the asymptotic minimum mean-squared error (MMSE)
for GLMs with i.i.d. Gaussian sensing matrices. However, in many models there
is a significant gap between the MMSE and the performance of the best known
feasible estimators. In this work, we address this issue by considering GLMs
defined via spatially coupled sensing matrices. We propose an efficient
approximate message passing (AMP) algorithm for estimation and prove that with
a simple choice of spatially coupled design, the MSE of a carefully tuned AMP
estimator approaches the asymptotic MMSE in the high-dimensional limit. To
prove the result, we first rigorously characterize the asymptotic performance
of AMP for a GLM with a generic spatially coupled design. This characterization
is in terms of a deterministic recursion (`state evolution') that depends on
the parameters defining the spatial coupling. Then, using a simple spatially
coupled design and judicious choice of functions defining the AMP, we analyze
the fixed points of the resulting state evolution and show that it achieves the
asymptotic MMSE. Numerical results for phase retrieval and rectified linear
regression show that spatially coupled designs can yield substantially lower
MSE than i.i.d. Gaussian designs at finite dimensions when used with AMP
algorithms.
</p>
</div>
</dd>
<dt><a name="item215">[215]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08406" title="Abstract">arXiv:2309.08406</a> [<a href="/pdf/2309.08406" title="Download PDF">pdf</a>, <a href="/format/2309.08406" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Free Structure Learning with Smooth Acyclic Orientations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Massidda%2C+R">Riccardo Massidda</a>, 
<a href="/search/cs?searchtype=author&query=Landolfi%2C+F">Francesco Landolfi</a>, 
<a href="/search/cs?searchtype=author&query=Cinquini%2C+M">Martina Cinquini</a>, 
<a href="/search/cs?searchtype=author&query=Bacciu%2C+D">Davide Bacciu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Machine Learning (stat.ML)

</div>
<p class="mathjax">The structure learning problem consists of fitting data generated by a
Directed Acyclic Graph (DAG) to correctly reconstruct its arcs. In this
context, differentiable approaches constrain or regularize the optimization
problem using a continuous relaxation of the acyclicity property. The
computational cost of evaluating graph acyclicity is cubic on the number of
nodes and significantly affects scalability. In this paper we introduce COSMO,
a constraint-free continuous optimization scheme for acyclic structure
learning. At the core of our method, we define a differentiable approximation
of an orientation matrix parameterized by a single priority vector. Differently
from previous work, our parameterization fits a smooth orientation matrix and
the resulting acyclic adjacency matrix without evaluating acyclicity at any
step. Despite the absence of explicit constraints, we prove that COSMO always
converges to an acyclic solution. In addition to being asymptotically faster,
our empirical analysis highlights how COSMO performance on graph reconstruction
compares favorably with competing structure learning methods.
</p>
</div>
</dd>
<dt><a name="item216">[216]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08408" title="Abstract">arXiv:2309.08408</a> [<a href="/pdf/2309.08408" title="Download PDF">pdf</a>, <a href="/format/2309.08408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-Visual Active Speaker Extraction for Sparsely Overlapped  Multi-talker Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junjie Li</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+R">Ruijie Tao</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+Z">Zexu Pan</a>, 
<a href="/search/cs?searchtype=author&query=Ge%2C+M">Meng Ge</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shuai Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H">Haizhou Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Target speaker extraction aims to extract the speech of a specific speaker
from a multi-talker mixture as specified by an auxiliary reference. Most
studies focus on the scenario where the target speech is highly overlapped with
the interfering speech. However, this scenario only accounts for a small
percentage of real-world conversations. In this paper, we aim at the sparsely
overlapped scenarios in which the auxiliary reference needs to perform two
tasks simultaneously: detect the activity of the target speaker and disentangle
the active speech from any interfering speech. We propose an audio-visual
speaker extraction model named ActiveExtract, which leverages speaking activity
from audio-visual active speaker detection (ASD). The ASD directly provides the
frame-level activity of the target speaker, while its intermediate feature
representation is trained to discriminate speech-lip synchronization that could
be used for speaker disentanglement. Experimental results show our model
outperforms baselines across various overlapping ratios, achieving an average
improvement of more than 4 dB in terms of SI-SNR.
</p>
</div>
</dd>
<dt><a name="item217">[217]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08414" title="Abstract">arXiv:2309.08414</a> [<a href="/pdf/2309.08414" title="Download PDF">pdf</a>, <a href="/format/2309.08414" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Make Deep Networks Shallow Again
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bermeitinger%2C+B">Bernhard Bermeitinger</a>, 
<a href="/search/cs?searchtype=author&query=Hrycej%2C+T">Tomas Hrycej</a>, 
<a href="/search/cs?searchtype=author&query=Handschuh%2C+S">Siegfried Handschuh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to be published at KDIR2023, Rome
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Deep neural networks have a good success record and are thus viewed as the
best architecture choice for complex applications. Their main shortcoming has
been, for a long time, the vanishing gradient which prevented the numerical
optimization algorithms from acceptable convergence. A breakthrough has been
achieved by the concept of residual connections -- an identity mapping parallel
to a conventional layer. This concept is applicable to stacks of layers of the
same dimension and substantially alleviates the vanishing gradient problem. A
stack of residual connection layers can be expressed as an expansion of terms
similar to the Taylor expansion. This expansion suggests the possibility of
truncating the higher-order terms and receiving an architecture consisting of a
single broad layer composed of all initially stacked layers in parallel. In
other words, a sequential deep architecture is substituted by a parallel
shallow one. Prompted by this theory, we investigated the performance
capabilities of the parallel architecture in comparison to the sequential one.
The computer vision datasets MNIST and CIFAR10 were used to train both
architectures for a total of 6912 combinations of varying numbers of
convolutional layers, numbers of filters, kernel sizes, and other meta
parameters. Our findings demonstrate a surprising equivalence between the deep
(sequential) and shallow (parallel) architectures. Both layouts produced
similar results in terms of training and validation set loss. This discovery
implies that a wide, shallow architecture can potentially replace a deep
network without sacrificing performance. Such substitution has the potential to
simplify network architectures, improve optimization efficiency, and accelerate
the training process.
</p>
</div>
</dd>
<dt><a name="item218">[218]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08415" title="Abstract">arXiv:2309.08415</a> [<a href="/pdf/2309.08415" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A new method of modeling the multi-stage decision-making process of CRT  using machine learning with uncertainty quantification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Larsena%2C+K">Kristoffer Larsena</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chen Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Keyak%2C+J">Joyce Keyak</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+Q">Qiuying Sha</a>, 
<a href="/search/cs?searchtype=author&query=Paezd%2C+D">Diana Paezd</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+X">Xinwei Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+J">Jiangang Zou</a>, 
<a href="/search/cs?searchtype=author&query=Peixf%2C+A">Amalia Peixf</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+W">Weihua Zhou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages,5 figures. arXiv admin note: text overlap with <a href="/abs/2305.02475">arXiv:2305.02475</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Aims. The purpose of this study is to create a multi-stage machine learning
model to predict cardiac resynchronization therapy (CRT) response for heart
failure (HF) patients. This model exploits uncertainty quantification to
recommend additional collection of single-photon emission computed tomography
myocardial perfusion imaging (SPECT MPI) variables if baseline clinical
variables and features from electrocardiogram (ECG) are not sufficient.
Methods. 218 patients who underwent rest-gated SPECT MPI were enrolled in this
study. CRT response was defined as an increase in left ventricular ejection
fraction (LVEF) &gt; 5% at a 6 month follow-up. A multi-stage ML model was created
by combining two ensemble models. Results. The response rate for CRT was 55.5%
(n = 121) with overall male gender 61.0% (n = 133), an average age of 62.0, and
LVEF of 27.7. The multi-stage model performed similarly to Ensemble 2 (which
utilized the additional SPECT data) with AUC of 0.75 vs. 0.77, accuracy of 0.71
vs. 0.69, sensitivity of 0.70 vs. 0.72, and specificity 0.72 vs. 0.65,
respectively. However, the multi-stage model only required SPECT MPI data for
52.7% of the patients across all folds. Conclusions. By using rule-based logic
stemming from uncertainty quantification, the multi-stage model was able to
reduce the need for additional SPECT MPI data acquisition without sacrificing
performance.
</p>
</div>
</dd>
<dt><a name="item219">[219]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08416" title="Abstract">arXiv:2309.08416</a> [<a href="/pdf/2309.08416" title="Download PDF">pdf</a>, <a href="/format/2309.08416" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deformable Neural Radiance Fields using RGB and Event Cameras
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ma%2C+Q">Qi Ma</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+D+P">Danda Pani Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Chhatkuli%2C+A">Ajad Chhatkuli</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Modeling Neural Radiance Fields for fast-moving deformable objects from
visual data alone is a challenging problem. A major issue arises due to the
high deformation and low acquisition rates. To address this problem, we propose
to use event cameras that offer very fast acquisition of visual change in an
asynchronous manner. In this work, we develop a novel method to model the
deformable neural radiance fields using RGB and event cameras. The proposed
method uses the asynchronous stream of events and calibrated sparse RGB frames.
In our setup, the camera pose at the individual events required to integrate
them into the radiance fields remains unknown. Our method jointly optimizes
these poses and the radiance field. This happens efficiently by leveraging the
collection of events at once and actively sampling the events during learning.
Experiments conducted on both realistically rendered graphics and real-world
datasets demonstrate a significant benefit of the proposed method over the
state-of-the-art and the compared baseline.
<br />This shows a promising direction for modeling deformable neural radiance
fields in real-world dynamic scenes.
</p>
</div>
</dd>
<dt><a name="item220">[220]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08420" title="Abstract">arXiv:2309.08420</a> [<a href="/pdf/2309.08420" title="Download PDF">pdf</a>, <a href="/format/2309.08420" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> FedDCSR: Federated Cross-domain Sequential Recommendation via  Disentangled Representation Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hongyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+D">Dongyi Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+X">Xu Yang</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jiyuan Feng</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+Q">Qing Liao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Cross-domain Sequential Recommendation (CSR) which leverages user sequence
data from multiple domains has received extensive attention in recent years.
However, the existing CSR methods require sharing origin user data across
domains, which violates the General Data Protection Regulation (GDPR). Thus, it
is necessary to combine federated learning (FL) and CSR to fully utilize
knowledge from different domains while preserving data privacy. Nonetheless,
the sequence feature heterogeneity across different domains significantly
impacts the overall performance of FL. In this paper, we propose FedDCSR, a
novel federated cross-domain sequential recommendation framework via
disentangled representation learning. Specifically, to address the sequence
feature heterogeneity across domains, we introduce an approach called
inter-intra domain sequence representation disentanglement (SRD) to disentangle
the user sequence features into domain-shared and domain-exclusive features. In
addition, we design an intra domain contrastive infomax (CIM) strategy to learn
richer domain-exclusive features of users by performing data augmentation on
user sequences. Extensive experiments on three real-world scenarios demonstrate
that FedDCSR achieves significant improvements over existing baselines.
</p>
</div>
</dd>
<dt><a name="item221">[221]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08423" title="Abstract">arXiv:2309.08423</a> [<a href="/pdf/2309.08423" title="Download PDF">pdf</a>, <a href="/ps/2309.08423" title="Download PostScript">ps</a>, <a href="/format/2309.08423" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Simple Method for the Performance Analysis of Fluid Antenna Systems  under Correlated Nakagami-$m$ Fading
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vega-S%C3%A1nchez%2C+J+D">Jos&#xe9;~David~Vega-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=Urquiza-Aguiar%2C+L">Luis~Urquiza-Aguiar</a>, 
<a href="/search/cs?searchtype=author&query=Paredes%2C+M+C+P">Martha Cecilia Paredes Paredes</a>, 
<a href="/search/cs?searchtype=author&query=Osorio%2C+D+P+M">Diana~Pamela~Moya~Osorio</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">By recognizing the tremendous flexibility of the emerging fluid antenna
system (FAS), which allows dynamic reconfigurability of the location of the
antenna within a given space, this paper investigates the performance of a
single-antenna FAS over spatially correlated Nakagami-$m$ fading channels.
Specifically, simple and highly accurate closed-form approximations for the
cumulative density function of the FAS channel and the outage probability of
the proposed system are obtained by employing a novel asymptotic matching
method, which is an improved version of the well-known moment matching. With
this method, the outage probability can be computed {simply} without incurring
complex multi-fold integrals, thus requiring negligible computational effort.
Finally, the accuracy of the proposed approximations is validated, and it is
shown that the FAS can meet or even exceed the performance attained by the
conventional maximal ratio combining (MRC) technique.
</p>
</div>
</dd>
<dt><a name="item222">[222]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08424" title="Abstract">arXiv:2309.08424</a> [<a href="/pdf/2309.08424" title="Download PDF">pdf</a>, <a href="/format/2309.08424" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> X-PDNet: Accurate Joint Plane Instance Segmentation and Monocular Depth  Estimation with Cross-Task Distillation and Boundary Correction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dinh%2C+D+C">Duc Cao Dinh</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+J">J Lim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to BMVC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Segmentation of planar regions from a single RGB image is a particularly
important task in the perception of complex scenes. To utilize both visual and
geometric properties in images, recent approaches often formulate the problem
as a joint estimation of planar instances and dense depth through feature
fusion mechanisms and geometric constraint losses. Despite promising results,
these methods do not consider cross-task feature distillation and perform
poorly in boundary regions. To overcome these limitations, we propose X-PDNet,
a framework for the multitask learning of plane instance segmentation and depth
estimation with improvements in the following two aspects. Firstly, we
construct the cross-task distillation design which promotes early information
sharing between dual-tasks for specific task improvements. Secondly, we
highlight the current limitations of using the ground truth boundary to develop
boundary regression loss, and propose a novel method that exploits depth
information to support precise boundary region segmentation. Finally, we
manually annotate more than 3000 images from Stanford 2D-3D-Semantics dataset
and make available for evaluation of plane instance segmentation. Through the
experiments, our proposed methods prove the advantages, outperforming the
baseline with large improvement margins in the quantitative results on the
ScanNet and the Stanford 2D-3D-S dataset, demonstrating the effectiveness of
our proposals.
</p>
</div>
</dd>
<dt><a name="item223">[223]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08427" title="Abstract">arXiv:2309.08427</a> [<a href="/pdf/2309.08427" title="Download PDF">pdf</a>, <a href="/format/2309.08427" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A posteriori error control for fourth-order semilinear problems with  quadratic nonlinearity
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Carstensen%2C+C">Carsten Carstensen</a>, 
<a href="/search/math?searchtype=author&query=Gr%C3%A4%C3%9Fle%2C+B">Benedikt Gr&#xe4;&#xdf;le</a>, 
<a href="/search/math?searchtype=author&query=Nataraj%2C+N">Neela Nataraj</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
<p class="mathjax">A general a posteriori error analysis applies to five lowest-order finite
element methods for two fourth-order semi-linear problems with trilinear
non-linearity and a general source. A quasi-optimal smoother extends the source
term to the discrete trial space, and more importantly, modifies the trilinear
term in the stream-function vorticity formulation of the incompressible 2D
Navier-Stokes and the von K\'{a}rm\'{a}n equations. This enables the first
efficient and reliable a posteriori error estimates for the 2D Navier-Stokes
equations in the stream-function vorticity formulation for Morley, two
discontinuous Galerkin, $C^0$ interior penalty, and WOPSIP discretizations with
piecewise quadratic polynomials.
</p>
</div>
</dd>
<dt><a name="item224">[224]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08428" title="Abstract">arXiv:2309.08428</a> [<a href="/pdf/2309.08428" title="Download PDF">pdf</a>, <a href="/format/2309.08428" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virtual Harassment, Real Understanding: Using a Serious Game and  Bayesian Networks to Study Cyberbullying
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=P%C3%A9rez%2C+J">Jaime P&#xe9;rez</a>, 
<a href="/search/cs?searchtype=author&query=Castro%2C+M">Mario Castro</a>, 
<a href="/search/cs?searchtype=author&query=Awad%2C+E">Edmond Awad</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez%2C+G">Gregorio L&#xf3;pez</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
<p class="mathjax">Cyberbullying among minors is a pressing concern in our digital society,
necessitating effective prevention and intervention strategies. Traditional
data collection methods often intrude on privacy and yield limited insights.
This study explores an innovative approach, employing a serious game - designed
with purposes beyond entertainment - as a non-intrusive tool for data
collection and education. In contrast to traditional correlation-based
analyses, we propose a causality-based approach using Bayesian Networks to
unravel complex relationships in the collected data and quantify result
uncertainties. This robust analytical tool yields interpretable outcomes,
enhances transparency in assumptions, and fosters open scientific discourse.
Preliminary pilot studies with the serious game show promising results,
surpassing the informative capacity of traditional demographic and
psychological questionnaires, suggesting its potential as an alternative
methodology. Additionally, we demonstrate how our approach facilitates the
examination of risk profiles and the identification of intervention strategies
to mitigate this cybercrime. We also address research limitations and potential
enhancements, considering the noise and variability of data in social studies
and video games. This research advances our understanding of cyberbullying and
showcase the potential of serious games and causality-based approaches in
studying complex social issues.
</p>
</div>
</dd>
<dt><a name="item225">[225]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08435" title="Abstract">arXiv:2309.08435</a> [<a href="/pdf/2309.08435" title="Download PDF">pdf</a>, <a href="/format/2309.08435" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TOMAS: Topology Optimization of Multiscale Fluid Devices using  Variational Autoencoders and Super-Shapes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Padhy%2C+R+K">Rahul Kumar Padhy</a>, 
<a href="/search/cs?searchtype=author&query=Suresh%2C+K">Krishnan Suresh</a>, 
<a href="/search/cs?searchtype=author&query=Chandrasekhar%2C+A">Aaditya Chandrasekhar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">In this paper, we present a framework for multiscale topology optimization of
fluid-flow devices. The objective is to minimize dissipated power, subject to a
desired contact-area. The proposed strategy is to design optimal
microstructures in individual finite element cells, while simultaneously
optimizing the overall fluid flow. In particular, parameterized super-shape
microstructures are chosen here to represent microstructures since they exhibit
a wide range of permeability and contact area. To avoid repeated
homogenization, a finite set of these super-shapes are analyzed a priori, and a
variational autoencoder (VAE) is trained on their fluid constitutive properties
(permeability), contact area and shape parameters. The resulting differentiable
latent space is integrated with a coordinate neural network to carry out a
global multi-scale fluid flow optimization. The latent space enables the use of
new microstructures that were not present in the original data-set. The
proposed method is illustrated using numerous examples in 2D.
</p>
</div>
</dd>
<dt><a name="item226">[226]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08438" title="Abstract">arXiv:2309.08438</a> [<a href="/pdf/2309.08438" title="Download PDF">pdf</a>, <a href="/format/2309.08438" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Can Users Correctly Interpret Machine Learning Explanations and  Simultaneously Identify Their Limitations?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xuan%2C+Y">Yueqing Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Small%2C+E">Edward Small</a>, 
<a href="/search/cs?searchtype=author&query=Sokol%2C+K">Kacper Sokol</a>, 
<a href="/search/cs?searchtype=author&query=Hettiachchi%2C+D">Danula Hettiachchi</a>, 
<a href="/search/cs?searchtype=author&query=Sanderson%2C+M">Mark Sanderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
<p class="mathjax">Automated decision-making systems are becoming increasingly ubiquitous,
motivating an immediate need for their explainability. However, it remains
unclear whether users know what insights an explanation offers and, more
importantly, what information it lacks. We conducted an online study with 200
participants to assess explainees' ability to realise known and unknown
information for four representative explanations: transparent modelling,
decision boundary visualisation, counterfactual explainability and feature
importance. Our findings demonstrate that feature importance and decision
boundary visualisation are the most comprehensible, but their limitations are
not necessarily recognised by the users. In addition, correct interpretation of
an explanation -- i.e., understanding known information -- is accompanied by
high confidence, but a failure to gauge its limits -- thus grasp unknown
information -- yields overconfidence; the latter phenomenon is especially
prominent for feature importance and transparent modelling. Machine learning
explanations should therefore embrace their richness and limitations to
maximise understanding and curb misinterpretation.
</p>
</div>
</dd>
<dt><a name="item227">[227]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08441" title="Abstract">arXiv:2309.08441</a> [<a href="/pdf/2309.08441" title="Download PDF">pdf</a>, <a href="/ps/2309.08441" title="Download PostScript">ps</a>, <a href="/format/2309.08441" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Novel Expressions for the Outage Probability and Diversity Gains in  Fluid Antenna System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vega-S%C3%A1nchez%2C+J+D">Jos&#xe9;~David~Vega-S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Ram%C3%ADrez%2C+A+E">Arianna Estefan&#xed;a L&#xf3;pez-Ram&#xed;rez</a>, 
<a href="/search/cs?searchtype=author&query=Urquiza-Aguiar%2C+L">Luis~Urquiza-Aguiar</a>, 
<a href="/search/cs?searchtype=author&query=Osorio%2C+D+P+M">Diana~Pamela~Moya~Osorio</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> N/A
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">The flexibility and reconfigurability at the radio frequency (RF) front-end
offered by the fluid antenna system (FAS) make this technology promising for
providing remarkable diversity gains in networks with small and constrained
devices. Toward this direction, this letter compares the outage probability
(OP) performance of non-diversity and diversity FAS receivers undergoing
spatially correlated Nakagami-$m$ fading channels. Although the system
properties of FAS incur in complex analysis, we derive a simple yet accurate
closed-form approximation by relying on a novel asymptotic matching method for
the OP of a maximum-gain combining-FAS (MGC-FAS). The approximation is
performed in two stages, the approximation of the cumulative density function
(CDF) of each MGC-FAS branch, and then the approximation of the end-to-end CDF
of the MGC-FAS scheme. With these results, closed-form expressions for the OP
and the asymptotic OP are derived. Finally, numerical results validate our
approximation of the MGC-FAS scheme and demonstrate its accuracy under
different diversity FAS scenarios.
</p>
</div>
</dd>
<dt><a name="item228">[228]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08442" title="Abstract">arXiv:2309.08442</a> [<a href="/pdf/2309.08442" title="Download PDF">pdf</a>, <a href="/format/2309.08442" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Toward responsible face datasets: modeling the distribution of a  disentangled latent space for sampling face images from demographic groups
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rahimi%2C+P">Parsa Rahimi</a>, 
<a href="/search/cs?searchtype=author&query=Ecabert%2C+C">Christophe Ecabert</a>, 
<a href="/search/cs?searchtype=author&query=Marcel%2C+S">Sebastien Marcel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> IJCB 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">Recently, it has been exposed that some modern facial recognition systems
could discriminate specific demographic groups and may lead to unfair attention
with respect to various facial attributes such as gender and origin. The main
reason are the biases inside datasets, unbalanced demographics, used to train
theses models. Unfortunately, collecting a large-scale balanced dataset with
respect to various demographics is impracticable.
<br />In this paper, we investigate as an alternative the generation of a balanced
and possibly bias-free synthetic dataset that could be used to train, to
regularize or to evaluate deep learning-based facial recognition models. We
propose to use a simple method for modeling and sampling a disentangled
projection of a StyleGAN latent space to generate any combination of
demographic groups (e.g. $hispanic-female$). Our experiments show that we can
synthesis any combination of demographic groups effectively and the identities
are different from the original training dataset. We also released the source
code.
</p>
</div>
</dd>
<dt><a name="item229">[229]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08444" title="Abstract">arXiv:2309.08444</a> [<a href="/pdf/2309.08444" title="Download PDF">pdf</a>, <a href="/format/2309.08444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Exemplar Parallelization with Go
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wiesinger%2C+G">Georg Wiesinger</a>, 
<a href="/search/cs?searchtype=author&query=Schikuta%2C+E">Erich Schikuta</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, to be submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
<p class="mathjax">This paper presents a case for exemplar parallelism of neural networks using
Go as parallelization framework. Further it is shown that also limited
multi-core hardware systems are feasible for these parallelization tasks, as
notebooks and single board computer systems. The main question was how much
speedup can be generated when using concurrent Go goroutines specifically. A
simple concurrent feedforward network for MNIST digit recognition with the
programming language Go was created to find the answer. The first findings when
using a notebook (Lenovo Yoga 2) showed a speedup of 252% when utilizing 4
goroutines. Testing a single board computer (Banana Pi M3) delivered more
convincing results: 320% with 4 goroutines, and 432% with 8 goroutines.
</p>
</div>
</dd>
<dt><a name="item230">[230]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08448" title="Abstract">arXiv:2309.08448</a> [<a href="/pdf/2309.08448" title="Download PDF">pdf</a>, <a href="/ps/2309.08448" title="Download PostScript">ps</a>, <a href="/format/2309.08448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Advancing the Evaluation of Traditional Chinese Language Models: Towards  a Comprehensive Benchmark Suite
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hsu%2C+C">Chan-Jan Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chang-Le Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liao%2C+F">Feng-Ting Liao</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+P">Po-Chun Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yi-Chang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Shiu%2C+D">Da-shan Shiu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The evaluation of large language models is an essential task in the field of
language understanding and generation. As language models continue to advance,
the need for effective benchmarks to assess their performance has become
imperative. In the context of Traditional Chinese, there is a scarcity of
comprehensive and diverse benchmarks to evaluate the capabilities of language
models, despite the existence of certain benchmarks such as DRCD, TTQA, CMDQA,
and FGC dataset. To address this gap, we propose a novel set of benchmarks that
leverage existing English datasets and are tailored to evaluate language models
in Traditional Chinese. These benchmarks encompass a wide range of tasks,
including contextual question-answering, summarization, classification, and
table understanding. The proposed benchmarks offer a comprehensive evaluation
framework, enabling the assessment of language models' capabilities across
different tasks. In this paper, we evaluate the performance of GPT-3.5,
Taiwan-LLaMa-v1.0, and Model 7-C, our proprietary model, on these benchmarks.
The evaluation results highlight that our model, Model 7-C, achieves
performance comparable to GPT-3.5 with respect to a part of the evaluated
capabilities. In an effort to advance the evaluation of language models in
Traditional Chinese and stimulate further research in this field, we have
open-sourced our benchmark and opened the model for trial.
</p>
</div>
</dd>
<dt><a name="item231">[231]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08449" title="Abstract">arXiv:2309.08449</a> [<a href="/pdf/2309.08449" title="Download PDF">pdf</a>, <a href="/format/2309.08449" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Do Random and Chaotic Sequences Really Cause Different PSO Performance?  Further Results
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=N%C3%B6renberg%2C+%7B+M">{Paul Moritz N&#xf6;renberg</a>, 
<a href="/search/cs?searchtype=author&query=Richter%2C+H">Hendrik Richter</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2303.14099">arXiv:2303.14099</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>

</div>
<p class="mathjax">Empirical results show that PSO performance may be different if using either
chaotic or random sequences to drive the algorithm's search dynamics. We
analyze the phenomenon by evaluating the performance based on a benchmark of
test functions and comparing random and chaotic sequences according to equality
or difference in underlying distribution or density. Our results show that the
underlying distribution is the main influential factor in performance and thus
the assumption of general and systematic performance differences between chaos
and random appears not plausible.
</p>
</div>
</dd>
<dt><a name="item232">[232]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08452" title="Abstract">arXiv:2309.08452</a> [<a href="/pdf/2309.08452" title="Download PDF">pdf</a>, <a href="/format/2309.08452" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MBAPPE: MCTS-Built-Around Prediction for Planning Explicitly
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chekroun%2C+R">Raphael Chekroun</a>, 
<a href="/search/cs?searchtype=author&query=Gilles%2C+T">Thomas Gilles</a>, 
<a href="/search/cs?searchtype=author&query=Toromanoff%2C+M">Marin Toromanoff</a>, 
<a href="/search/cs?searchtype=author&query=Hornauer%2C+S">Sascha Hornauer</a>, 
<a href="/search/cs?searchtype=author&query=Moutarde%2C+F">Fabien Moutarde</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">We present MBAPPE, a novel approach to motion planning for autonomous driving
combining tree search with a partially-learned model of the environment.
Leveraging the inherent explainable exploration and optimization capabilities
of the Monte-Carlo Search Tree (MCTS), our method addresses complex
decision-making in a dynamic environment. We propose a framework that combines
MCTS with supervised learning, enabling the autonomous vehicle to effectively
navigate through diverse scenarios. Experimental results demonstrate the
effectiveness and adaptability of our approach, showcasing improved real-time
decision-making and collision avoidance. This paper contributes to the field by
providing a robust solution for motion planning in autonomous driving systems,
enhancing their explainability and reliability.
</p>
</div>
</dd>
<dt><a name="item233">[233]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08457" title="Abstract">arXiv:2309.08457</a> [<a href="/pdf/2309.08457" title="Download PDF">pdf</a>, <a href="/format/2309.08457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sim-to-Real Brush Manipulation using Behavior Cloning and Reinforcement  Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+B">Biao Jia</a>, 
<a href="/search/cs?searchtype=author&query=Manocha%2C+D">Dinesh Manocha</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Developing proficient brush manipulation capabilities in real-world scenarios
is a complex and challenging endeavor, with wide-ranging applications in fields
such as art, robotics, and digital design. In this study, we introduce an
approach designed to bridge the gap between simulated environments and
real-world brush manipulation. Our framework leverages behavior cloning and
reinforcement learning to train a painting agent, seamlessly integrating it
into both virtual and real-world environments. Additionally, we employ a real
painting environment featuring a robotic arm and brush, mirroring the MyPaint
virtual environment. Our results underscore the agent's effectiveness in
acquiring policies for high-dimensional continuous action spaces, facilitating
the smooth transfer of brush manipulation techniques from simulation to
practical, real-world applications.
</p>
</div>
</dd>
<dt><a name="item234">[234]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08460" title="Abstract">arXiv:2309.08460</a> [<a href="/pdf/2309.08460" title="Download PDF">pdf</a>, <a href="/format/2309.08460" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explaining Search Result Stances to Opinionated People
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wu%2C+Z">Z. Wu</a>, 
<a href="/search/cs?searchtype=author&query=Draws%2C+T">T. Draws</a>, 
<a href="/search/cs?searchtype=author&query=Cau%2C+F">F. Cau</a>, 
<a href="/search/cs?searchtype=author&query=Barile%2C+F">F. Barile</a>, 
<a href="/search/cs?searchtype=author&query=Rieger%2C+A">A. Rieger</a>, 
<a href="/search/cs?searchtype=author&query=Tintarev%2C+N">N. Tintarev</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 6 figures (World Conference on eXplainable Artificial Intelligence xAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
<p class="mathjax">People use web search engines to find information before forming opinions,
which can lead to practical decisions with different levels of impact. The
cognitive effort of search can leave opinionated users vulnerable to cognitive
biases, e.g., the confirmation bias. In this paper, we investigate whether
stance labels and their explanations can help users consume more diverse search
results. We automatically classify and label search results on three topics
(i.e., intellectual property rights, school uniforms, and atheism) as against,
neutral, and in favor, and generate explanations for these labels. In a user
study (N =203), we then investigate whether search result stance bias (balanced
vs biased) and the level of explanation (plain text, label only, label and
explanation) influence the diversity of search results clicked. We find that
stance labels and explanations lead to a more diverse search result
consumption. However, we do not find evidence for systematic opinion change
among users in this context. We believe these results can help designers of
search engines to make more informed design decisions.
</p>
</div>
</dd>
<dt><a name="item235">[235]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08464" title="Abstract">arXiv:2309.08464</a> [<a href="/pdf/2309.08464" title="Download PDF">pdf</a>, <a href="/ps/2309.08464" title="Download PostScript">ps</a>, <a href="/format/2309.08464" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentially Private Average Consensus with Improved Accuracy-Privacy  Trade-off
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+L">Lei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+W">Weijia Liu</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+F">Fanghong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Qiao%2C+Z">Zixin Qiao</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhengguang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">This paper studies the average consensus problem with differential privacy of
initial states, for which it is widely recognized that there is a trade-off
between the mean-square computation accuracy and privacy level. Considering the
trade-off gap between the average consensus algorithm and the centralized
averaging approach with differential privacy, we propose a distributed
shuffling mechanism based on the Paillier cryptosystem to generate correlated
zero-sum randomness. By randomizing each local privacy-sensitive initial state
with an i.i.d. Gaussian noise and the output of the mechanism using Gaussian
noises, it is shown that the resulting average consensus algorithm can
eliminate the gap in the sense that the accuracy-privacy trade-off of the
centralized averaging approach with differential privacy can be almost
recovered by appropriately designing the variances of the added noises. We also
extend such a design framework with Gaussian noises to the one using Laplace
noises, and show that the improved privacy-accuracy trade-off is preserved.
</p>
</div>
</dd>
<dt><a name="item236">[236]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08469" title="Abstract">arXiv:2309.08469</a> [<a href="/pdf/2309.08469" title="Download PDF">pdf</a>, <a href="/format/2309.08469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SilverRetriever: Advancing Neural Passage Retrieval for Polish Question  Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rybak%2C+P">Piotr Rybak</a>, 
<a href="/search/cs?searchtype=author&query=Ogrodniczuk%2C+M">Maciej Ogrodniczuk</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Information Retrieval (cs.IR)

</div>
<p class="mathjax">Modern open-domain question answering systems often rely on accurate and
efficient retrieval components to find passages containing the facts necessary
to answer the question. Recently, neural retrievers have gained popularity over
lexical alternatives due to their superior performance. However, most of the
work concerns popular languages such as English or Chinese. For others, such as
Polish, few models are available. In this work, we present SilverRetriever, a
neural retriever for Polish trained on a diverse collection of manually or
weakly labeled datasets. SilverRetriever achieves much better results than
other Polish models and is competitive with larger multilingual models.
Together with the model, we open-source five new passage retrieval datasets.
</p>
</div>
</dd>
<dt><a name="item237">[237]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08471" title="Abstract">arXiv:2309.08471</a> [<a href="/pdf/2309.08471" title="Download PDF">pdf</a>, <a href="/format/2309.08471" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TreeLearn: A Comprehensive Deep Learning Method for Segmenting  Individual Trees from Forest Point Clouds
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Henrich%2C+J">Jonathan Henrich</a>, 
<a href="/search/cs?searchtype=author&query=van+Delden%2C+J">Jan van Delden</a>, 
<a href="/search/cs?searchtype=author&query=Seidel%2C+D">Dominik Seidel</a>, 
<a href="/search/cs?searchtype=author&query=Kneib%2C+T">Thomas Kneib</a>, 
<a href="/search/cs?searchtype=author&query=Ecker%2C+A">Alexander Ecker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Laser-scanned point clouds of forests make it possible to extract valuable
information for forest management. To consider single trees, a forest point
cloud needs to be segmented into individual tree point clouds. Existing
segmentation methods are usually based on hand-crafted algorithms, such as
identifying trunks and growing trees from them, and face difficulties in dense
forests with overlapping tree crowns. In this study, we propose
\mbox{TreeLearn}, a deep learning-based approach for semantic and instance
segmentation of forest point clouds. Unlike previous methods, TreeLearn is
trained on already segmented point clouds in a data-driven manner, making it
less reliant on predefined features and algorithms. Additionally, we introduce
a new manually segmented benchmark forest dataset containing 156 full trees,
and 79 partial trees, that have been cleanly segmented by hand. This enables
the evaluation of instance segmentation performance going beyond just
evaluating the detection of individual trees. We trained TreeLearn on forest
point clouds of 6665 trees, labeled using the Lidar360 software. An evaluation
on the benchmark dataset shows that TreeLearn performs equally well or better
than the algorithm used to generate its training data. Furthermore, the
method's performance can be vastly improved by fine-tuning on the cleanly
labeled benchmark dataset. The TreeLearn code is availabe from
https://github.com/ecker-lab/TreeLearn. The data as well as trained models can
be found at https://doi.org/10.25625/VPMPID.
</p>
</div>
</dd>
<dt><a name="item238">[238]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08474" title="Abstract">arXiv:2309.08474</a> [<a href="/pdf/2309.08474" title="Download PDF">pdf</a>, <a href="/format/2309.08474" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VulnSense: Efficient Vulnerability Detection in Ethereum Smart Contracts  by Multimodal Learning with Graph Neural Network and Language Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duy%2C+P+T">Phan The Duy</a>, 
<a href="/search/cs?searchtype=author&query=Khoa%2C+N+H">Nghi Hoang Khoa</a>, 
<a href="/search/cs?searchtype=author&query=Quyen%2C+N+H">Nguyen Huu Quyen</a>, 
<a href="/search/cs?searchtype=author&query=Trinh%2C+L+C">Le Cong Trinh</a>, 
<a href="/search/cs?searchtype=author&query=Kien%2C+V+T">Vu Trung Kien</a>, 
<a href="/search/cs?searchtype=author&query=Hoang%2C+T+M">Trinh Minh Hoang</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+V">Van-Hau Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">This paper presents VulnSense framework, a comprehensive approach to
efficiently detect vulnerabilities in Ethereum smart contracts using a
multimodal learning approach on graph-based and natural language processing
(NLP) models. Our proposed framework combines three types of features from
smart contracts comprising source code, opcode sequences, and control flow
graph (CFG) extracted from bytecode. We employ Bidirectional Encoder
Representations from Transformers (BERT), Bidirectional Long Short-Term Memory
(BiLSTM) and Graph Neural Network (GNN) models to extract and analyze these
features. The final layer of our multimodal approach consists of a fully
connected layer used to predict vulnerabilities in Ethereum smart contracts.
Addressing limitations of existing vulnerability detection methods relying on
single-feature or single-model deep learning techniques, our method surpasses
accuracy and effectiveness constraints. We assess VulnSense using a collection
of 1.769 smart contracts derived from the combination of three datasets:
Curated, SolidiFI-Benchmark, and Smartbugs Wild. We then make a comparison with
various unimodal and multimodal learning techniques contributed by GNN, BiLSTM
and BERT architectures. The experimental outcomes demonstrate the superior
performance of our proposed approach, achieving an average accuracy of 77.96\%
across all three categories of vulnerable smart contracts.
</p>
</div>
</dd>
<dt><a name="item239">[239]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08475" title="Abstract">arXiv:2309.08475</a> [<a href="/pdf/2309.08475" title="Download PDF">pdf</a>, <a href="/ps/2309.08475" title="Download PostScript">ps</a>, <a href="/format/2309.08475" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Doeblin Coefficients and Related Measures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Makur%2C+A">Anuran Makur</a>, 
<a href="/search/cs?searchtype=author&query=Singh%2C+J">Japneet Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Probability (math.PR); Statistics Theory (math.ST)

</div>
<p class="mathjax">Doeblin coefficients are a classical tool for analyzing the ergodicity and
exponential convergence rates of Markov chains. Propelled by recent works on
contraction coefficients of strong data processing inequalities, we investigate
whether Doeblin coefficients also exhibit some of the notable properties of
canonical contraction coefficients. In this paper, we present several new
structural and geometric properties of Doeblin coefficients. Specifically, we
show that Doeblin coefficients form a multi-way divergence, exhibit
tensorization, and possess an extremal trace characterization. We then show
that they also have extremal coupling and simultaneously maximal coupling
characterizations. By leveraging these characterizations, we demonstrate that
Doeblin coefficients act as a nice generalization of the well-known total
variation (TV) distance to a multi-way divergence, enabling us to measure the
"distance" between multiple distributions rather than just two. We then prove
that Doeblin coefficients exhibit contraction properties over Bayesian networks
similar to other canonical contraction coefficients. We additionally derive
some other results and discuss an application of Doeblin coefficients to
distribution fusion. Finally, in a complementary vein, we introduce and discuss
three new quantities: max-Doeblin coefficient, max-DeGroot distance, and
min-DeGroot distance. The max-Doeblin coefficient shares a connection with the
concept of maximal leakage in information security; we explore its properties
and provide a coupling characterization. On the other hand, the max-DeGroot and
min-DeGroot measures extend the concept of DeGroot distance to multiple
distributions.
</p>
</div>
</dd>
<dt><a name="item240">[240]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08476" title="Abstract">arXiv:2309.08476</a> [<a href="/pdf/2309.08476" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Spiking Binary Neuron -- Detector of Causal Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kiselev%2C+M">Mikhail Kiselev</a>, 
<a href="/search/cs?searchtype=author&query=Larionov%2C+D">Denis Larionov</a>, 
<a href="/search/cs?searchtype=author&query=Urusov%2C+A">Andrey Urusov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Neural and Evolutionary Computing (cs.NE)</span>; Neurons and Cognition (q-bio.NC)

</div>
<p class="mathjax">Causal relationship recognition is a fundamental operation in neural networks
aimed at learning behavior, action planning, and inferring external world
dynamics. This operation is particularly crucial for reinforcement learning
(RL). In the context of spiking neural networks (SNNs), events are represented
as spikes emitted by network neurons or input nodes. Detecting causal
relationships within these events is essential for effective RL implementation.
This research paper presents a novel approach to realize causal relationship
recognition using a simple spiking binary neuron. The proposed method leverages
specially designed synaptic plasticity rules, which are both straightforward
and efficient. Notably, our approach accounts for the temporal aspects of
detected causal links and accommodates the representation of spiking signals as
single spikes or tight spike sequences (bursts), as observed in biological
brains. Furthermore, this study places a strong emphasis on the
hardware-friendliness of the proposed models, ensuring their efficient
implementation on modern and future neuroprocessors. Being compared with
precise machine learning techniques, such as decision tree algorithms and
convolutional neural networks, our neuron demonstrates satisfactory accuracy
despite its simplicity. In conclusion, we introduce a multi-neuron structure
capable of operating in more complex environments with enhanced accuracy,
making it a promising candidate for the advancement of RL applications in SNNs.
</p>
</div>
</dd>
<dt><a name="item241">[241]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08480" title="Abstract">arXiv:2309.08480</a> [<a href="/pdf/2309.08480" title="Download PDF">pdf</a>, <a href="/format/2309.08480" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PoseFix: Correcting 3D Human Poses with Natural Language
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delmas%2C+G">Ginger Delmas</a>, 
<a href="/search/cs?searchtype=author&query=Weinzaepfel%2C+P">Philippe Weinzaepfel</a>, 
<a href="/search/cs?searchtype=author&query=Moreno-Noguer%2C+F">Francesc Moreno-Noguer</a>, 
<a href="/search/cs?searchtype=author&query=Rogez%2C+G">Gr&#xe9;gory Rogez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automatically producing instructions to modify one's posture could open the
door to endless applications, such as personalized coaching and in-home
physical therapy. Tackling the reverse problem (i.e., refining a 3D pose based
on some natural language feedback) could help for assisted 3D character
animation or robot teaching, for instance. Although a few recent works explore
the connections between natural language and 3D human pose, none focus on
describing 3D body pose differences. In this paper, we tackle the problem of
correcting 3D human poses with natural language. To this end, we introduce the
PoseFix dataset, which consists of several thousand paired 3D poses and their
corresponding text feedback, that describe how the source pose needs to be
modified to obtain the target pose. We demonstrate the potential of this
dataset on two tasks: (1) text-based pose editing, that aims at generating
corrected 3D body poses given a query pose and a text modifier; and (2)
correctional text generation, where instructions are generated based on the
differences between two body poses.
</p>
</div>
</dd>
<dt><a name="item242">[242]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08481" title="Abstract">arXiv:2309.08481</a> [<a href="/pdf/2309.08481" title="Download PDF">pdf</a>, <a href="/format/2309.08481" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D Arterial Segmentation via Single 2D Projections and Depth Supervision  in Contrast-Enhanced CT Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dima%2C+A+F">Alina F. Dima</a>, 
<a href="/search/cs?searchtype=author&query=Zimmer%2C+V+A">Veronika A. Zimmer</a>, 
<a href="/search/cs?searchtype=author&query=Menten%2C+M+J">Martin J. Menten</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+H+B">Hongwei Bran Li</a>, 
<a href="/search/cs?searchtype=author&query=Graf%2C+M">Markus Graf</a>, 
<a href="/search/cs?searchtype=author&query=Lemke%2C+T">Tristan Lemke</a>, 
<a href="/search/cs?searchtype=author&query=Raffler%2C+P">Philipp Raffler</a>, 
<a href="/search/cs?searchtype=author&query=Graf%2C+R">Robert Graf</a>, 
<a href="/search/cs?searchtype=author&query=Kirschke%2C+J+S">Jan S. Kirschke</a>, 
<a href="/search/cs?searchtype=author&query=Braren%2C+R">Rickmer Braren</a>, 
<a href="/search/cs?searchtype=author&query=Rueckert%2C+D">Daniel Rueckert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Automated segmentation of the blood vessels in 3D volumes is an essential
step for the quantitative diagnosis and treatment of many vascular diseases. 3D
vessel segmentation is being actively investigated in existing works, mostly in
deep learning approaches. However, training 3D deep networks requires large
amounts of manual 3D annotations from experts, which are laborious to obtain.
This is especially the case for 3D vessel segmentation, as vessels are sparse
yet spread out over many slices and disconnected when visualized in 2D slices.
In this work, we propose a novel method to segment the 3D peripancreatic
arteries solely from one annotated 2D projection per training image with depth
supervision. We perform extensive experiments on the segmentation of
peripancreatic arteries on 3D contrast-enhanced CT images and demonstrate how
well we capture the rich depth information from 2D projections. We demonstrate
that by annotating a single, randomly chosen projection for each training
sample, we obtain comparable performance to annotating multiple 2D projections,
thereby reducing the annotation effort. Furthermore, by mapping the 2D labels
to the 3D space using depth information and incorporating this into training,
we almost close the performance gap between 3D supervision and 2D supervision.
Our code is available at: https://github.com/alinafdima/3Dseg-mip-depth.
</p>
</div>
</dd>
<dt><a name="item243">[243]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08482" title="Abstract">arXiv:2309.08482</a> [<a href="/pdf/2309.08482" title="Download PDF">pdf</a>, <a href="/format/2309.08482" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> YCB-Ev: Event-vision dataset for 6DoF object pose estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rojtberg%2C+P">Pavel Rojtberg</a>, 
<a href="/search/cs?searchtype=author&query=P%C3%B6llabauer%2C+T">Thomas P&#xf6;llabauer</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Our work introduces the YCB-Ev dataset, which contains synchronized RGB-D
frames and event data that enables evaluating 6DoF object pose estimation
algorithms using these modalities.
<br />This dataset provides ground truth 6DoF object poses for the same 21 YCB
objects \cite{calli2017yale} that were used in the YCB-Video (YCB-V) dataset,
enabling the evaluation of algorithm performance when transferred across
datasets.
<br />The dataset consists of 21 synchronized event and RGB-D sequences, amounting
to a total of 7:43 minutes of video. Notably, 12 of these sequences feature the
same object arrangement as the YCB-V subset used in the BOP challenge.
<br />Our dataset is the first to provide ground truth 6DoF pose data for event
streams. Furthermore, we evaluate the generalization capabilities of two
state-of-the-art algorithms, which were pre-trained for the BOP challenge,
using our novel YCB-V sequences.
<br />The proposed dataset is available at https://github.com/paroj/ycbev.
</p>
</div>
</dd>
<dt><a name="item244">[244]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08485" title="Abstract">arXiv:2309.08485</a> [<a href="/pdf/2309.08485" title="Download PDF">pdf</a>, <a href="/format/2309.08485" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XFedHunter: An Explainable Federated Learning Framework for Advanced  Persistent Threat Detection in SDN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Thi%2C+H+T">Huynh Thai Thi</a>, 
<a href="/search/cs?searchtype=author&query=Son%2C+N+D+H">Ngo Duc Hoang Son</a>, 
<a href="/search/cs?searchtype=author&query=Duy%2C+P+T">Phan The Duy</a>, 
<a href="/search/cs?searchtype=author&query=Khoa%2C+N+H">Nghi Hoang Khoa</a>, 
<a href="/search/cs?searchtype=author&query=Ngo-Khanh%2C+K">Khoa Ngo-Khanh</a>, 
<a href="/search/cs?searchtype=author&query=Pham%2C+V">Van-Hau Pham</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Advanced Persistent Threat (APT) attacks are highly sophisticated and employ
a multitude of advanced methods and techniques to target organizations and
steal sensitive and confidential information. APT attacks consist of multiple
stages and have a defined strategy, utilizing new and innovative techniques and
technologies developed by hackers to evade security software monitoring. To
effectively protect against APTs, detecting and predicting APT indicators with
an explanation from Machine Learning (ML) prediction is crucial to reveal the
characteristics of attackers lurking in the network system. Meanwhile,
Federated Learning (FL) has emerged as a promising approach for building
intelligent applications without compromising privacy. This is particularly
important in cybersecurity, where sensitive data and high-quality labeling play
a critical role in constructing effective machine learning models for detecting
cyber threats. Therefore, this work proposes XFedHunter, an explainable
federated learning framework for APT detection in Software-Defined Networking
(SDN) leveraging local cyber threat knowledge from many training collaborators.
In XFedHunter, Graph Neural Network (GNN) and Deep Learning model are utilized
to reveal the malicious events effectively in the large number of normal ones
in the network system. The experimental results on NF-ToN-IoT and DARPA TCE3
datasets indicate that our framework can enhance the trust and accountability
of ML-based systems utilized for cybersecurity purposes without privacy
leakage.
</p>
</div>
</dd>
<dt><a name="item245">[245]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08491" title="Abstract">arXiv:2309.08491</a> [<a href="/pdf/2309.08491" title="Download PDF">pdf</a>, <a href="/format/2309.08491" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Using Large Language Models for Knowledge Engineering (LLMKE): A Case  Study on Wikidata
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+B">Bohui Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Reklos%2C+I">Ioannis Reklos</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+N">Nitisha Jain</a>, 
<a href="/search/cs?searchtype=author&query=Pe%C3%B1uela%2C+A+M">Albert Mero&#xf1;o Pe&#xf1;uela</a>, 
<a href="/search/cs?searchtype=author&query=Simperl%2C+E">Elena Simperl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Knowledge Base Construction from Pre-trained Language Models (LM-KBC) Challenge @ ISWC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In this work, we explore the use of Large Language Models (LLMs) for
knowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge.
For this task, given subject and relation pairs sourced from Wikidata, we
utilize pre-trained LLMs to produce the relevant objects in string format and
link them to their respective Wikidata QIDs. We developed a pipeline using LLMs
for Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata
entity mapping. The method achieved a macro-averaged F1-score of 0.701 across
the properties, with the scores varying from 1.00 to 0.328. These results
demonstrate that the knowledge of LLMs varies significantly depending on the
domain and that further experimentation is required to determine the
circumstances under which LLMs can be used for automatic Knowledge Base (e.g.,
Wikidata) completion and correction. The investigation of the results also
suggests the promising contribution of LLMs in collaborative knowledge
engineering. LLMKE won Track 2 of the challenge. The implementation is
available at https://github.com/bohuizhang/LLMKE.
</p>
</div>
</dd>
<dt><a name="item246">[246]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08499" title="Abstract">arXiv:2309.08499</a> [<a href="/pdf/2309.08499" title="Download PDF">pdf</a>, <a href="/format/2309.08499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> P-ROCKET: Pruning Random Convolution Kernels for Time Series  Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shaowu Chen</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">Weize Sun</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+L">Lei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiaopeng Li</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Q">Qingyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=John%2C+D">Deepu John</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">In recent years, two time series classification models, ROCKET and
MINIROCKET, have attracted much attention for their low training cost and
state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without
training, ROCKET and MINIROCKET can rapidly extract features from time series
data, allowing for the efficient fitting of linear classifiers. However, to
comprehensively capture useful features, a large number of random kernels are
required, which is incompatible for resource-constrained devices. Therefore, a
heuristic evolutionary algorithm named S-ROCKET is devised to recognize and
prune redundant kernels. Nevertheless, the inherent nature of evolutionary
algorithms renders the evaluation of kernels within S-ROCKET an unacceptable
time-consuming process. In this paper, diverging from S-ROCKET, which directly
evaluates random kernels with nonsignificant differences, we remove kernels
from a feature selection perspective by eliminating associating connections in
the sequential classification layer. To this end, we start by formulating the
pruning challenge as a Group Elastic Net classification problem and employ the
ADMM method to arrive at a solution. Sequentially, we accelerate the
aforementioned time-consuming solving process by bifurcating the $l_{2,1}$ and
$l_2$ regularizations into two sequential stages and solve them separately,
which ultimately forms our core algorithm, named P-ROCKET. Stage 1 of P-ROCKET
employs group-wise regularization similarly to our initial ADMM-based
Algorithm, but introduces dynamically varying penalties to greatly accelerate
the process. To mitigate overfitting, Stage 2 of P-ROCKET implements
element-wise regularization to refit a linear classifier, utilizing the
retained features.
</p>
</div>
</dd>
<dt><a name="item247">[247]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08503" title="Abstract">arXiv:2309.08503</a> [<a href="/pdf/2309.08503" title="Download PDF">pdf</a>, <a href="/format/2309.08503" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HealthFC: A Dataset of Health Claims for Evidence-Based Medical  Fact-Checking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Vladika%2C+J">Juraj Vladika</a>, 
<a href="/search/cs?searchtype=author&query=Schneider%2C+P">Phillip Schneider</a>, 
<a href="/search/cs?searchtype=author&query=Matthes%2C+F">Florian Matthes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Seeking health-related advice on the internet has become a common practice in
the digital era. Determining the trustworthiness of medical claims found online
and finding appropriate evidence for this information is increasingly
challenging. Fact-checking has emerged as an approach to assess the veracity of
factual claims using evidence from credible knowledge sources. To help advance
the automation of this task, in this paper, we introduce a novel dataset of 750
health-related claims, labeled for veracity by medical experts and backed with
evidence from appropriate clinical studies. We provide an analysis of the
dataset, highlighting its characteristics and challenges. The dataset can be
used for Machine Learning tasks related to automated fact-checking such as
evidence retrieval, veracity prediction, and explanation generation. For this
purpose, we provide baseline models based on different approaches, examine
their performance, and discuss the findings.
</p>
</div>
</dd>
<dt><a name="item248">[248]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08504" title="Abstract">arXiv:2309.08504</a> [<a href="/pdf/2309.08504" title="Download PDF">pdf</a>, <a href="/format/2309.08504" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OccupancyDETR: Making Semantic Scene Completion as Straightforward as  Object Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jia%2C+Y">Yupeng Jia</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jie He</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+R">Runze Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+F">Fang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Haiyong Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Visual-based 3D semantic occupancy perception (also known as 3D semantic
scene completion) is a new perception paradigm for robotic applications like
autonomous driving. Compared with Bird's Eye View (BEV) perception, it extends
the vertical dimension, significantly enhancing the ability of robots to
understand their surroundings. However, due to this very reason, the
computational demand for current 3D semantic occupancy perception methods
generally surpasses that of BEV perception methods and 2D perception methods.
We propose a novel 3D semantic occupancy perception method, OccupancyDETR,
which consists of a DETR-like object detection module and a 3D occupancy
decoder module. The integration of object detection simplifies our method
structurally - instead of predicting the semantics of each voxels, it
identifies objects in the scene and their respective 3D occupancy grids. This
speeds up our method, reduces required resources, and leverages object
detection algorithm, giving our approach notable performance on small objects.
We demonstrate the effectiveness of our proposed method on the SemanticKITTI
dataset, showcasing an mIoU of 23 and a processing speed of 6 frames per
second, thereby presenting a promising solution for real-time 3D semantic scene
completion.
</p>
</div>
</dd>
<dt><a name="item249">[249]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08508" title="Abstract">arXiv:2309.08508</a> [<a href="/pdf/2309.08508" title="Download PDF">pdf</a>, <a href="/format/2309.08508" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOSAIC: Learning Unified Multi-Sensory Object Property Representations  for Robot Perception
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tatiya%2C+G">Gyan Tatiya</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+J">Jonathan Francis</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+H">Ho-Hsiang Wu</a>, 
<a href="/search/cs?searchtype=author&query=Bisk%2C+Y">Yonatan Bisk</a>, 
<a href="/search/cs?searchtype=author&query=Sinapov%2C+J">Jivko Sinapov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13 to 17, 2024, Yokohama, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">A holistic understanding of object properties across diverse sensory
modalities (e.g., visual, audio, and haptic) is essential for tasks ranging
from object categorization to complex manipulation. Drawing inspiration from
cognitive science studies that emphasize the significance of multi-sensory
integration in human perception, we introduce MOSAIC (Multi-modal Object
property learning with Self-Attention and Integrated Comprehension), a novel
framework designed to facilitate the learning of unified multi-sensory object
property representations. While it is undeniable that visual information plays
a prominent role, we acknowledge that many fundamental object properties extend
beyond the visual domain to encompass attributes like texture, mass
distribution, or sounds, which significantly influence how we interact with
objects. In MOSAIC, we leverage this profound insight by distilling knowledge
from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP)
model, aligning these representations not only across vision but also haptic
and auditory sensory modalities. Through extensive experiments on a dataset
where a humanoid robot interacts with 100 objects across 10 exploratory
behaviors, we demonstrate the versatility of MOSAIC in two task families:
object categorization and object-fetching tasks. Our results underscore the
efficacy of MOSAIC's unified representations, showing competitive performance
in category recognition through a simple linear probe setup and excelling in
the fetch object task under zero-shot transfer conditions. This work pioneers
the application of CLIP-based sensory grounding in robotics, promising a
significant leap in multi-sensory perception capabilities for autonomous
systems. We have released the code, datasets, and additional results:
https://github.com/gtatiya/MOSAIC.
</p>
</div>
</dd>
<dt><a name="item250">[250]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08513" title="Abstract">arXiv:2309.08513</a> [<a href="/pdf/2309.08513" title="Download PDF">pdf</a>, <a href="/format/2309.08513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SCT: A Simple Baseline for Parameter-Efficient Fine-Tuning via Salient  Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+H">Henry Hengyuan Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pichao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yuyang Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+H">Hao Luo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Shou%2C+M+Z">Mike Zheng Shou</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work has been accepted by IJCV2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Pre-trained vision transformers have strong representation benefits to
various downstream tasks. Recently, many parameter-efficient fine-tuning (PEFT)
methods have been proposed, and their experiments demonstrate that tuning only
1% of extra parameters could surpass full fine-tuning in low-data resource
scenarios. However, these methods overlook the task-specific information when
fine-tuning diverse downstream tasks. In this paper, we propose a simple yet
effective method called "Salient Channel Tuning" (SCT) to leverage the
task-specific information by forwarding the model with the task images to
select partial channels in a feature map that enables us to tune only 1/8
channels leading to significantly lower parameter costs. Experiments outperform
full fine-tuning on 18 out of 19 tasks in the VTAB-1K benchmark by adding only
0.11M parameters of the ViT-B, which is 780$\times$ fewer than its full
fine-tuning counterpart. Furthermore, experiments on domain generalization and
few-shot learning surpass other PEFT methods with lower parameter costs,
demonstrating our proposed tuning technique's strong capability and
effectiveness in the low-data regime.
</p>
</div>
</dd>
<dt><a name="item251">[251]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08520" title="Abstract">arXiv:2309.08520</a> [<a href="/pdf/2309.08520" title="Download PDF">pdf</a>, <a href="/format/2309.08520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scaling Laws for Sparsely-Connected Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Frantar%2C+E">Elias Frantar</a>, 
<a href="/search/cs?searchtype=author&query=Riquelme%2C+C">Carlos Riquelme</a>, 
<a href="/search/cs?searchtype=author&query=Houlsby%2C+N">Neil Houlsby</a>, 
<a href="/search/cs?searchtype=author&query=Alistarh%2C+D">Dan Alistarh</a>, 
<a href="/search/cs?searchtype=author&query=Evci%2C+U">Utku Evci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We explore the impact of parameter sparsity on the scaling behavior of
Transformers trained on massive datasets (i.e., "foundation models"), in both
vision and language domains. In this setting, we identify the first scaling law
describing the relationship between weight sparsity, number of non-zero
parameters, and amount of training data, which we validate empirically across
model and data scales; on ViT/JFT-4B and T5/C4. These results allow us to
characterize the "optimal sparsity", the sparsity level which yields the best
performance for a given effective model size and training budget. For a fixed
number of non-zero parameters, we identify that the optimal sparsity increases
with the amount of data used for training. We also extend our study to
different sparsity structures (such as the hardware-friendly n:m pattern) and
strategies (such as starting from a pretrained dense model). Our findings shed
light on the power and limitations of weight sparsity across various parameter
and computational settings, offering both theoretical understanding and
practical implications for leveraging sparsity towards computational efficiency
improvements.
</p>
</div>
</dd>
<dt><a name="item252">[252]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08523" title="Abstract">arXiv:2309.08523</a> [<a href="/pdf/2309.08523" title="Download PDF">pdf</a>, <a href="/format/2309.08523" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Breathing New Life into 3D Assets with Generative Repainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianfu Wang</a>, 
<a href="/search/cs?searchtype=author&query=Kanakis%2C+M">Menelaos Kanakis</a>, 
<a href="/search/cs?searchtype=author&query=Schindler%2C+K">Konrad Schindler</a>, 
<a href="/search/cs?searchtype=author&query=Van+Gool%2C+L">Luc Van Gool</a>, 
<a href="/search/cs?searchtype=author&query=Obukhov%2C+A">Anton Obukhov</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR)

</div>
<p class="mathjax">Diffusion-based text-to-image models ignited immense attention from the
vision community, artists, and content creators. Broad adoption of these models
is due to significant improvement in the quality of generations and efficient
conditioning on various modalities, not just text. However, lifting the rich
generative priors of these 2D models into 3D is challenging. Recent works have
proposed various pipelines powered by the entanglement of diffusion models and
neural fields. We explore the power of pretrained 2D diffusion models and
standard 3D neural radiance fields as independent, standalone tools and
demonstrate their ability to work together in a non-learned fashion. Such
modularity has the intrinsic advantage of eased partial upgrades, which became
an important property in such a fast-paced domain. Our pipeline accepts any
legacy renderable geometry, such as textured or untextured meshes, orchestrates
the interaction between 2D generative refinement and 3D consistency enforcement
tools, and outputs a painted input geometry in several formats. We conduct a
large-scale study on a wide range of objects and categories from the
ShapeNetSem dataset and demonstrate the advantages of our approach, both
qualitatively and quantitatively. Project page:
https://www.obukhov.ai/repainting_3d_assets
</p>
</div>
</dd>
<dt><a name="item253">[253]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08531" title="Abstract">arXiv:2309.08531</a> [<a href="/pdf/2309.08531" title="Download PDF">pdf</a>, <a href="/format/2309.08531" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Practical and Efficient Image-to-Speech Captioning with  Vision-Language Pre-training and Multi-modal Tokens
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Choi%2C+J">Jeongsoo Choi</a>, 
<a href="/search/cs?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J+H">Jeong Hun Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Computation and Language (cs.CL); Audio and Speech Processing (eess.AS); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">In this paper, we propose methods to build a powerful and efficient
Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing
the rich knowledge related to image comprehension and language modeling from a
large-scale pre-trained vision-language model into Im2Sp. We set the output of
the proposed Im2Sp as discretized speech units, i.e., the quantized speech
features of a self-supervised speech model. The speech units mainly contain
linguistic information while suppressing other characteristics of speech. This
allows us to incorporate the language modeling capability of the pre-trained
vision-language model into the spoken language modeling of Im2Sp. With the
vision-language pre-training strategy, we set new state-of-the-art Im2Sp
performances on two widely used benchmark databases, COCO and Flickr8k. Then,
we further improve the efficiency of the Im2Sp model. Similar to the speech
unit case, we convert the original image into image units, which are derived
through vector quantization of the raw image. With these image units, we can
drastically reduce the required data storage for saving image data to just 0.8%
when compared to the original image data in terms of bits. Demo page:
https://ms-dot-k.github.io/Image-to-Speech-Captioning.
</p>
</div>
</dd>
<dt><a name="item254">[254]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08532" title="Abstract">arXiv:2309.08532</a> [<a href="/pdf/2309.08532" title="Download PDF">pdf</a>, <a href="/format/2309.08532" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Connecting Large Language Models with Evolutionary Algorithms Yields  Powerful Prompt Optimizers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Guo%2C+Q">Qingyan Guo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+J">Junliang Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bei Li</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+K">Kaitao Song</a>, 
<a href="/search/cs?searchtype=author&query=Tan%2C+X">Xu Tan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+G">Guoqing Liu</a>, 
<a href="/search/cs?searchtype=author&query=Bian%2C+J">Jiang Bian</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yujiu Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in progress
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Large Language Models (LLMs) excel in various tasks, but they rely on
carefully crafted prompts that often demand substantial human effort. To
automate this process, in this paper, we propose a novel framework for discrete
prompt optimization, called EvoPrompt, which borrows the idea of evolutionary
algorithms (EAs) as they exhibit good performance and fast convergence. To
enable EAs to work on discrete prompts, which are natural language expressions
that need to be coherent and human-readable, we connect LLMs with EAs. This
approach allows us to simultaneously leverage the powerful language processing
capabilities of LLMs and the efficient optimization performance of EAs.
Specifically, abstaining from any gradients or parameters, EvoPrompt starts
from a population of prompts and iteratively generates new prompts with LLMs
based on the evolutionary operators, improving the population based on the
development set. We optimize prompts for both closed- and open-source LLMs
including GPT-3.5 and Alpaca, on 9 datasets spanning language understanding and
generation tasks. EvoPrompt significantly outperforms human-engineered prompts
and existing methods for automatic prompt generation by up to 25% and 14%
respectively. Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs
creates synergies, which could inspire further research on the combination of
LLMs and conventional algorithms.
</p>
</div>
</dd>
<dt><a name="item255">[255]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08533" title="Abstract">arXiv:2309.08533</a> [<a href="/pdf/2309.08533" title="Download PDF">pdf</a>, <a href="/format/2309.08533" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated dermatoscopic pattern discovery by clustering neural network  output for human-computer interaction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Talavera-Martinez%2C+L">Lidia Talavera-Martinez</a>, 
<a href="/search/cs?searchtype=author&query=Tschandl%2C+P">Philipp Tschandl</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Eur Acad Dermatol Venereol. 2023 May 31. Epub ahead of print
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC)

</div>
<p class="mathjax">Background: As available medical image datasets increase in size, it becomes
infeasible for clinicians to review content manually for knowledge extraction.
The objective of this study was to create an automated clustering resulting in
human-interpretable pattern discovery.
<br />Methods: Images from the public HAM10000 dataset, including 7 common
pigmented skin lesion diagnoses, were tiled into 29420 tiles and clustered via
k-means using neural network-extracted image features. The final number of
clusters per diagnosis was chosen by either the elbow method or a compactness
metric balancing intra-lesion variance and cluster numbers. The amount of
resulting non-informative clusters, defined as those containing less than six
image tiles, was compared between the two methods.
<br />Results: Applying k-means, the optimal elbow cutoff resulted in a mean of
24.7 (95%-CI: 16.4-33) clusters for every included diagnosis, including 14.9%
(95% CI: 0.8-29.0) non-informative clusters. The optimal cutoff, as estimated
by the compactness metric, resulted in significantly fewer clusters (13.4;
95%-CI 11.8-15.1; p=0.03) and less non-informative ones (7.5%; 95% CI: 0-19.5;
p=0.017). The majority of clusters (93.6%) from the compactness metric could be
manually mapped to previously described dermatoscopic diagnostic patterns.
<br />Conclusions: Automatically constraining unsupervised clustering can produce
an automated extraction of diagnostically relevant and human-interpretable
clusters of visual patterns from a large image dataset.
</p>
</div>
</dd>
<dt><a name="item256">[256]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08534" title="Abstract">arXiv:2309.08534</a> [<a href="/pdf/2309.08534" title="Download PDF">pdf</a>, <a href="/format/2309.08534" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Last-layer Retraining for Group Robustness with Fewer  Annotations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=LaBonte%2C+T">Tyler LaBonte</a>, 
<a href="/search/cs?searchtype=author&query=Muthukumar%2C+V">Vidya Muthukumar</a>, 
<a href="/search/cs?searchtype=author&query=Kumar%2C+A">Abhishek Kumar</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">Empirical risk minimization (ERM) of neural networks is prone to
over-reliance on spurious correlations and poor generalization on minority
groups. The recent deep feature reweighting (DFR) technique achieves
state-of-the-art group robustness via simple last-layer retraining, but it
requires held-out group and class annotations to construct a group-balanced
reweighting dataset. In this work, we examine this impractical requirement and
find that last-layer retraining can be surprisingly effective with no group
annotations (other than for model selection) and only a handful of class
annotations. We first show that last-layer retraining can greatly improve
worst-group accuracy even when the reweighting dataset has only a small
proportion of worst-group data. This implies a "free lunch" where holding out a
subset of training data to retrain the last layer can substantially outperform
ERM on the entire dataset with no additional data or annotations. To further
improve group robustness, we introduce a lightweight method called selective
last-layer finetuning (SELF), which constructs the reweighting dataset using
misclassifications or disagreements. Our empirical and theoretical results
present the first evidence that model disagreement upsamples worst-group data,
enabling SELF to nearly match DFR on four well-established benchmarks across
vision and language tasks with no group annotations and less than 3% of the
held-out class annotations. Our code is available at
https://github.com/tmlabonte/last-layer-retraining.
</p>
</div>
</dd>
<dt><a name="item257">[257]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08535" title="Abstract">arXiv:2309.08535</a> [<a href="/pdf/2309.08535" title="Download PDF">pdf</a>, <a href="/format/2309.08535" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Visual Speech Recognition for Low-resource Languages with Automatic  Labels From Whisper Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeo%2C+J+H">Jeong Hun Yeo</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+M">Minsu Kim</a>, 
<a href="/search/cs?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/cs?searchtype=author&query=Ro%2C+Y+M">Yong Man Ro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">This paper proposes a powerful Visual Speech Recognition (VSR) method for
multiple languages, especially for low-resource languages that have a limited
number of labeled data. Different from previous methods that tried to improve
the VSR performance for the target language by using knowledge learned from
other languages, we explore whether we can increase the amount of training data
itself for the different languages without human intervention. To this end, we
employ a Whisper model which can conduct both language identification and
audio-based speech recognition. It serves to filter data of the desired
languages and transcribe labels from the unannotated, multilingual audio-visual
data pool. By comparing the performances of VSR models trained on automatic
labels and the human-annotated labels, we show that we can achieve similar VSR
performance to that of human-annotated labels even without utilizing human
annotations. Through the automated labeling process, we label large-scale
unlabeled multilingual databases, VoxCeleb2 and AVSpeech, producing 1,002 hours
of data for four low VSR resource languages, French, Italian, Spanish, and
Portuguese. With the automatic labels, we achieve new state-of-the-art
performance on mTEDx in four languages, significantly surpassing the previous
methods. The automatic labels are available online:
https://github.com/JeongHun0716/Visual-Speech-Recognition-for-Low-Resource-Languages
</p>
</div>
</dd>
<dt><a name="item258">[258]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08537" title="Abstract">arXiv:2309.08537</a> [<a href="/pdf/2309.08537" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Operational Integration Potential of Regional Uncrewed Aircraft Systems  into the Airspace System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sievers%2C+T+F">Tim Felix Sievers</a>, 
<a href="/search/eess?searchtype=author&query=Sakakeeny%2C+J">Jordan Sakakeeny</a>, 
<a href="/search/eess?searchtype=author&query=Dimitrova%2C+N">Nadezhda Dimitrova</a>, 
<a href="/search/eess?searchtype=author&query=Idris%2C+H">Husni Idris</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
<p class="mathjax">As part of newly developing aviation markets, fixed-wing Uncrewed Aircraft
Systems (UAS) are projected to impact airspace systems and conventional air
traffic in the future. The initial introduction of fixed-wing cargo UAS for
regional operations is anticipated to occur at smaller under-utilized airports.
Therefore, this paper assesses the integration potential of regional fixed-wing
cargo UAS into the airspace system. A baseline is established to identify
potential airports for cargo UAS operations in different areas. Additionally,
using 2022 data, regional aircraft eligible for future cargo UAS operations are
investigated. Finally, the accessibility of these regional aircraft at the
identified airports was analysed. Based on the availability of current
certified landing systems needed for initial UAS operations, potential airports
in the areas Germany, Texas, and California for UAS operations are compared.
Additionally, based on the maximum takeoff weight allowances of airport
runways, current air transport operations at airports, and airspace classes,
individual airports with a high potential for the introduction of initial cargo
UAS operations with and without the availability of landing systems needed for
UAS are identified and compared among the investigated areas. Despite a total
of 173 identified airports for potential UAS operations in Germany, 376 in
Texas, and 231 in California, only eleven of these airports currently have the
certified landing systems needed for initial UAS operations. However, other
landing system technologies that are currently under development, such as
vision-based landing systems, might support UAS accessibility at the identified
airports for potential UAS operations in the future.
</p>
</div>
</dd>
<dt><a name="item259">[259]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08541" title="Abstract">arXiv:2309.08541</a> [<a href="/pdf/2309.08541" title="Download PDF">pdf</a>, <a href="/format/2309.08541" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> When do Generative Query and Document Expansions Fail? A Comprehensive  Study Across Methods, Retrievers, and Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Weller%2C+O">Orion Weller</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+K">Kyle Lo</a>, 
<a href="/search/cs?searchtype=author&query=Wadden%2C+D">David Wadden</a>, 
<a href="/search/cs?searchtype=author&query=Lawrie%2C+D">Dawn Lawrie</a>, 
<a href="/search/cs?searchtype=author&query=Van+Durme%2C+B">Benjamin Van Durme</a>, 
<a href="/search/cs?searchtype=author&query=Cohan%2C+A">Arman Cohan</a>, 
<a href="/search/cs?searchtype=author&query=Soldaini%2C+L">Luca Soldaini</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Using large language models (LMs) for query or document expansion can improve
generalization in information retrieval. However, it is unknown whether these
techniques are universally beneficial or only effective in specific settings,
such as for particular retrieval models, dataset domains, or query types. To
answer this, we conduct the first comprehensive analysis of LM-based expansion.
We find that there exists a strong negative correlation between retriever
performance and gains from expansion: expansion improves scores for weaker
models, but generally harms stronger models. We show this trend holds across a
set of eleven expansion techniques, twelve datasets with diverse distribution
shifts, and twenty-four retrieval models. Through qualitative error analysis,
we hypothesize that although expansions provide extra information (potentially
improving recall), they add additional noise that makes it difficult to discern
between the top relevant documents (thus introducing false positives). Our
results suggest the following recipe: use expansions for weaker models or when
the target dataset significantly differs from training corpus in format;
otherwise, avoid expansions to keep the relevance signal clear.
</p>
</div>
</dd>
<dt><a name="item260">[260]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08544" title="Abstract">arXiv:2309.08544</a> [<a href="/pdf/2309.08544" title="Download PDF">pdf</a>, <a href="/format/2309.08544" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Quadcopter Trajectory Time Minimization and Robust Collision Avoidance  via Optimal Time Allocation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xu%2C+Z">Zhefan Xu</a>, 
<a href="/search/cs?searchtype=author&query=Shimada%2C+K">Kenji Shimada</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Autonomous navigation requires robots to generate trajectories for collision
avoidance efficiently. Although plenty of previous works have proven successful
in generating smooth and spatially collision-free trajectories, their solutions
often suffer from suboptimal time efficiency and potential unsafety,
particularly when accounting for uncertainties in robot perception and control.
To address this issue, this paper presents the Robust Optimal Time Allocation
(ROTA) framework. This framework is designed to optimize the time progress of
the trajectories temporally, serving as a post-processing tool to enhance
trajectory time efficiency and safety under uncertainties. In this study, we
begin by formulating a non-convex optimization problem aimed at minimizing
trajectory execution time while incorporating constraints on collision
probability as the robot approaches obstacles. Subsequently, we introduce the
concept of the trajectory braking zone and adopt the chance-constrained
formulation for robust collision avoidance in the braking zones. Finally, the
non-convex optimization problem is reformulated into a second-order cone
programming problem to achieve real-time performance. Through simulations and
physical flight experiments, we demonstrate that the proposed approach
effectively reduces trajectory execution time while enabling robust collision
avoidance in complex environments.
</p>
</div>
</dd>
<dt><a name="item261">[261]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08545" title="Abstract">arXiv:2309.08545</a> [<a href="/pdf/2309.08545" title="Download PDF">pdf</a>, <a href="/format/2309.08545" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient and robust Sensor Placement in Complex Environments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Taus%2C+L">Lukas Taus</a>, 
<a href="/search/cs?searchtype=author&query=Tsai%2C+Y+R">Yen-Hsi Richard Tsai</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Robotics (cs.RO); Optimization and Control (math.OC)

</div>
<p class="mathjax">We address the problem of efficient and unobstructed surveillance or
communication in complex environments. On one hand, one wishes to use a minimal
number of sensors to cover the environment. On the other hand, it is often
important to consider solutions that are robust against sensor failure or
adversarial attacks. This paper addresses these challenges of designing minimal
sensor sets that achieve multi-coverage constraints -- every point in the
environment is covered by a prescribed number of sensors. We propose a greedy
algorithm to achieve the objective. Further, we explore deep learning
techniques to accelerate the evaluation of the objective function formulated in
the greedy algorithm. The training of the neural network reveals that the
geometric properties of the data significantly impact the network's
performance, particularly at the end stage. By taking into account these
properties, we discuss the differences in using greedy and $\epsilon$-greedy
algorithms to generate data and their impact on the robustness of the network.
</p>
</div>
</dd>
<dt><a name="item262">[262]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08546" title="Abstract">arXiv:2309.08546</a> [<a href="/pdf/2309.08546" title="Download PDF">pdf</a>, <a href="/format/2309.08546" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Robust Continual Learning with Bayesian Adaptive Moment  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Foster%2C+J">Jack Foster</a>, 
<a href="/search/cs?searchtype=author&query=Brintrup%2C+A">Alexandra Brintrup</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The pursuit of long-term autonomy mandates that robotic agents must
continuously adapt to their changing environments and learn to solve new tasks.
Continual learning seeks to overcome the challenge of catastrophic forgetting,
where learning to solve new tasks causes a model to forget previously learnt
information. Prior-based continual learning methods are appealing for robotic
applications as they are space efficient and typically do not increase in
computational complexity as the number of tasks grows. Despite these desirable
properties, prior-based approaches typically fail on important benchmarks and
consequently are limited in their potential applications compared to their
memory-based counterparts. We introduce Bayesian adaptive moment regularization
(BAdam), a novel prior-based method that better constrains parameter growth,
leading to lower catastrophic forgetting. Our method boasts a range of
desirable properties for robotic applications such as being lightweight and
task label-free, converging quickly, and offering calibrated uncertainty that
is important for safe real-world deployment. Results show that BAdam achieves
state-of-the-art performance for prior-based methods on challenging
single-headed class-incremental experiments such as Split MNIST and Split
FashionMNIST, and does so without relying on task labels or discrete task
boundaries.
</p>
</div>
</dd>
<dt><a name="item263">[263]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08549" title="Abstract">arXiv:2309.08549</a> [<a href="/pdf/2309.08549" title="Download PDF">pdf</a>, <a href="/format/2309.08549" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HINT: Healthy Influential-Noise based Training to Defend against Data  Poisoning Attacks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Van%2C+M">Minh-Hao Van</a>, 
<a href="/search/cs?searchtype=author&query=Carey%2C+A+N">Alycia N. Carey</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)

</div>
<p class="mathjax">While numerous defense methods have been proposed to prohibit potential
poisoning attacks from untrusted data sources, most research works only defend
against specific attacks, which leaves many avenues for an adversary to
exploit. In this work, we propose an efficient and robust training approach to
defend against data poisoning attacks based on influence functions, named
Healthy Influential-Noise based Training. Using influence functions, we craft
healthy noise that helps to harden the classification model against poisoning
attacks without significantly affecting the generalization ability on test
data. In addition, our method can perform effectively when only a subset of the
training data is modified, instead of the current method of adding noise to all
examples that has been used in several previous works. We conduct comprehensive
evaluations over two image datasets with state-of-the-art poisoning attacks
under different realistic attack scenarios. Our empirical results show that
HINT can efficiently protect deep learning models against the effect of both
untargeted and targeted poisoning attacks.
</p>
</div>
</dd>
<dt><a name="item264">[264]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08551" title="Abstract">arXiv:2309.08551</a> [<a href="/pdf/2309.08551" title="Download PDF">pdf</a>, <a href="/format/2309.08551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Augmenting conformers with structured state space models for online  speech recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shan%2C+H">Haozhe Shan</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+A">Albert Gu</a>, 
<a href="/search/cs?searchtype=author&query=Meng%2C+Z">Zhong Meng</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Choromanski%2C+K">Krzysztof Choromanski</a>, 
<a href="/search/cs?searchtype=author&query=Sainath%2C+T">Tara Sainath</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Sound (cs.SD); Audio and Speech Processing (eess.AS)

</div>
<p class="mathjax">Online speech recognition, where the model only accesses context to the left,
is an important and challenging use case for ASR systems. In this work, we
investigate augmenting neural encoders for online ASR by incorporating
structured state-space sequence models (S4), which are a family of models that
provide a parameter-efficient way of accessing arbitrarily long left context.
We perform systematic ablation studies to compare variants of S4 models and
propose two novel approaches that combine them with convolutions. We find that
the most effective design is to stack a small S4 using real-valued recurrent
weights with a local convolution, allowing them to work complementarily. Our
best model achieves WERs of 4.01%/8.53% on test sets from Librispeech,
outperforming Conformers with extensively tuned convolution.
</p>
</div>
</dd>
<dt><a name="item265">[265]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08555" title="Abstract">arXiv:2309.08555</a> [<a href="/pdf/2309.08555" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enhancing scientific exploration of the deep sea through shared autonomy  in remote manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Phung%2C+A">Amy Phung</a>, 
<a href="/search/cs?searchtype=author&query=Billings%2C+G">Gideon Billings</a>, 
<a href="/search/cs?searchtype=author&query=Daniele%2C+A+F">Andrea F. Daniele</a>, 
<a href="/search/cs?searchtype=author&query=Walter%2C+M+R">Matthew R. Walter</a>, 
<a href="/search/cs?searchtype=author&query=Camilli%2C+R">Richard Camilli</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
<p class="mathjax">Shared autonomy enables novice remote users to conduct deep-ocean science
operations with robotic manipulators.
</p>
</div>
</dd>
<dt><a name="item266">[266]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08560" title="Abstract">arXiv:2309.08560</a> [<a href="/pdf/2309.08560" title="Download PDF">pdf</a>, <a href="/format/2309.08560" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Reinforcement Learning for Efficient and Fair Allocation of Health  Care Resources
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yikuan Li</a>, 
<a href="/search/cs?searchtype=author&query=Mao%2C+C">Chengsheng Mao</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+K">Kaixuan Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+H">Hanyin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+Z">Zheng Yu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+M">Mengdi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuan Luo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 4 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Scarcity of health care resources could result in the unavoidable consequence
of rationing. For example, ventilators are often limited in supply, especially
during public health emergencies or in resource-constrained health care
settings, such as amid the pandemic of COVID-19. Currently, there is no
universally accepted standard for health care resource allocation protocols,
resulting in different governments prioritizing patients based on various
criteria and heuristic-based protocols. In this study, we investigate the use
of reinforcement learning for critical care resource allocation policy
optimization to fairly and effectively ration resources. We propose a
transformer-based deep Q-network to integrate the disease progression of
individual patients and the interaction effects among patients during the
critical care resource allocation. We aim to improve both fairness of
allocation and overall patient outcomes. Our experiments demonstrate that our
method significantly reduces excess deaths and achieves a more equitable
distribution under different levels of ventilator shortage, when compared to
existing severity-based and comorbidity-based methods in use by different
governments. Our source code is included in the supplement and will be released
on Github upon publication.
</p>
</div>
</dd>
<dt><a name="item267">[267]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08564" title="Abstract">arXiv:2309.08564</a> [<a href="/pdf/2309.08564" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Impact of Different Backbone Architecture on Autonomous Vehicle  Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ding%2C+N">Ning Ding</a>, 
<a href="/search/cs?searchtype=author&query=Eskandarian%2C+A">Azim Eskandarian</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has been accepted by IMECE2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Object detection is a crucial component of autonomous driving, and many
detection applications have been developed to address this task. These
applications often rely on backbone architectures, which extract representation
features from inputs to perform the object detection task. The quality of the
features extracted by the backbone architecture can have a significant impact
on the overall detection performance. Many researchers have focused on
developing new and improved backbone architectures to enhance the efficiency
and accuracy of object detection applications. While these backbone
architectures have shown state-of-the-art performance on generic object
detection datasets like MS-COCO and PASCAL-VOC, evaluating their performance
under an autonomous driving environment has not been previously explored. To
address this, our study evaluates three well-known autonomous vehicle datasets,
namely KITTI, NuScenes, and BDD, to compare the performance of different
backbone architectures on object detection tasks.
</p>
</div>
</dd>
<dt><a name="item268">[268]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08565" title="Abstract">arXiv:2309.08565</a> [<a href="/pdf/2309.08565" title="Download PDF">pdf</a>, <a href="/format/2309.08565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How Transferable are Attribute Controllers on Pretrained Multilingual  Translation Models?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+D">Danni Liu</a>, 
<a href="/search/cs?searchtype=author&query=Niehues%2C+J">Jan Niehues</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
<p class="mathjax">Customizing machine translation models to comply with fine-grained attributes
such as formality has seen tremendous progress recently. However, current
approaches mostly rely on at least some supervised data with attribute
annotation. Data scarcity therefore remains a bottleneck to democratizing such
customization possibilities to a wider range of languages, lower-resource ones
in particular. Given recent progress in pretrained massively multilingual
translation models, we use them as a foundation to transfer the attribute
controlling capabilities to languages without supervised data. In this work, we
present a comprehensive analysis of transferring attribute controllers based on
a pretrained NLLB-200 model. We investigate both training- and inference-time
control techniques under various data scenarios, and uncover their relative
strengths and weaknesses in zero-shot performance and domain robustness. We
show that both paradigms are complementary, as shown by consistent improvements
on 5 zero-shot directions. Moreover, a human evaluation on a real low-resource
language, Bengali, confirms our findings on zero-shot transfer to new target
languages. The code is
$\href{https://github.com/dannigt/attribute-controller-transfer}{\text{here}}$.
</p>
</div>
</dd>
<dt><a name="item269">[269]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08568" title="Abstract">arXiv:2309.08568</a> [<a href="/pdf/2309.08568" title="Download PDF">pdf</a>, <a href="/format/2309.08568" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Denoising Diffusion Probabilistic Models for Hardware-Impaired  Communications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Letafati%2C+M">Mehdi Letafati</a>, 
<a href="/search/cs?searchtype=author&query=Ali%2C+S">Samad Ali</a>, 
<a href="/search/cs?searchtype=author&query=Latva-aho%2C+M">Matti Latva-aho</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>; Signal Processing (eess.SP)

</div>
<p class="mathjax">Generative AI has received significant attention among a spectrum of diverse
industrial and academic domains, thanks to the magnificent results achieved
from deep generative models such as generative pre-trained transformers (GPT)
and diffusion models. In this paper, we explore the applications of denoising
diffusion probabilistic models (DDPMs) in wireless communication systems under
practical assumptions such as hardware impairments (HWI), low-SNR regime, and
quantization error. Diffusion models are a new class of state-of-the-art
generative models that have already showcased notable success with some of the
popular examples by OpenAI and Google Brain. The intuition behind DDPM is to
decompose the data generation process over small "denoising" steps. Inspired by
this, we propose using denoising diffusion model-based receiver for a practical
wireless communication scheme, while providing network resilience in low-SNR
regimes, non-Gaussian noise, different HWI levels, and quantization error. We
evaluate the reconstruction performance of our scheme in terms of bit error
rate (BER) and mean-squared error (MSE). Our results show that 30% and 20%
improvement in BER could be achieved compared to deep neural network
(DNN)-based receivers in AWGN and non-Gaussian scenarios, respectively.
</p>
</div>
</dd>
<dt><a name="item270">[270]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08569" title="Abstract">arXiv:2309.08569</a> [<a href="/pdf/2309.08569" title="Download PDF">pdf</a>, <a href="/format/2309.08569" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Local Differential Privacy in Graph Neural Networks: a Reconstruction  Approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhaila%2C+K">Karuna Bhaila</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen Huang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yongkai Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xintao Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Graph Neural Networks have achieved tremendous success in modeling complex
graph data in a variety of applications. However, there are limited studies
investigating privacy protection in GNNs. In this work, we propose a learning
framework that can provide node privacy at the user level, while incurring low
utility loss. We focus on a decentralized notion of Differential Privacy,
namely Local Differential Privacy, and apply randomization mechanisms to
perturb both feature and label data at the node level before the data is
collected by a central server for model training. Specifically, we investigate
the application of randomization mechanisms in high-dimensional feature
settings and propose an LDP protocol with strict privacy guarantees. Based on
frequency estimation in statistical analysis of randomized data, we develop
reconstruction methods to approximate features and labels from perturbed data.
We also formulate this learning framework to utilize frequency estimates of
graph clusters to supervise the training procedure at a sub-graph level.
Extensive experiments on real-world and semi-synthetic datasets demonstrate the
validity of our proposed model.
</p>
</div>
</dd>
<dt><a name="item271">[271]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08571" title="Abstract">arXiv:2309.08571</a> [<a href="/pdf/2309.08571" title="Download PDF">pdf</a>, <a href="/format/2309.08571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Bayesian Approach to Robust Inverse Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wei%2C+R">Ran Wei</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+S">Siliang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+C">Chenliang Li</a>, 
<a href="/search/cs?searchtype=author&query=Garcia%2C+A">Alfredo Garcia</a>, 
<a href="/search/cs?searchtype=author&query=McDonald%2C+A">Anthony McDonald</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+M">Mingyi Hong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">We consider a Bayesian approach to offline model-based inverse reinforcement
learning (IRL). The proposed framework differs from existing offline
model-based IRL approaches by performing simultaneous estimation of the
expert's reward function and subjective model of environment dynamics. We make
use of a class of prior distributions which parameterizes how accurate the
expert's model of the environment is to develop efficient algorithms to
estimate the expert's reward and subjective dynamics in high-dimensional
settings. Our analysis reveals a novel insight that the estimated policy
exhibits robust performance when the expert is believed (a priori) to have a
highly accurate model of the environment. We verify this observation in the
MuJoCo environments and show that our algorithms outperform state-of-the-art
offline IRL algorithms.
</p>
</div>
</dd>
<dt><a name="item272">[272]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08573" title="Abstract">arXiv:2309.08573</a> [<a href="/pdf/2309.08573" title="Download PDF">pdf</a>, <a href="/format/2309.08573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Casteist but Not Racist? Quantifying Disparities in Large Language Model  Bias between India and the West
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Khandelwal%2C+K">Khyati Khandelwal</a>, 
<a href="/search/cs?searchtype=author&query=Tonneau%2C+M">Manuel Tonneau</a>, 
<a href="/search/cs?searchtype=author&query=Bean%2C+A+M">Andrew M. Bean</a>, 
<a href="/search/cs?searchtype=author&query=Kirk%2C+H+R">Hannah Rose Kirk</a>, 
<a href="/search/cs?searchtype=author&query=Hale%2C+S+A">Scott A. Hale</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">Large Language Models (LLMs), now used daily by millions of users, can encode
societal biases, exposing their users to representational harms. A large body
of scholarship on LLM bias exists but it predominantly adopts a Western-centric
frame and attends comparatively less to bias levels and potential harms in the
Global South. In this paper, we quantify stereotypical bias in popular LLMs
according to an Indian-centric frame and compare bias levels between the Indian
and Western contexts. To do this, we develop a novel dataset which we call
Indian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and
anti-stereotypical examples for caste and religion contexts. We find that the
majority of LLMs tested are strongly biased towards stereotypes in the Indian
context, especially as compared to the Western context. We finally investigate
Instruction Prompting as a simple intervention to mitigate such bias and find
that it significantly reduces both stereotypical and anti-stereotypical biases
in the majority of cases for GPT-3.5. The findings of this work highlight the
need for including more diverse voices when evaluating LLMs.
</p>
</div>
</dd>
<dt><a name="item273">[273]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08574" title="Abstract">arXiv:2309.08574</a> [<a href="/pdf/2309.08574" title="Download PDF">pdf</a>, <a href="/format/2309.08574" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DP-PQD: Privately Detecting Per-Query Gaps In Synthetic Data Generated  By Black-Box Mechanisms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Patwa%2C+S">Shweta Patwa</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+D">Danyu Sun</a>, 
<a href="/search/cs?searchtype=author&query=Gilad%2C+A">Amir Gilad</a>, 
<a href="/search/cs?searchtype=author&query=Machanavajjhala%2C+A">Ashwin Machanavajjhala</a>, 
<a href="/search/cs?searchtype=author&query=Roy%2C+S">Sudeepa Roy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Databases (cs.DB)</span>; Cryptography and Security (cs.CR)

</div>
<p class="mathjax">Synthetic data generation methods, and in particular, private synthetic data
generation methods, are gaining popularity as a means to make copies of
sensitive databases that can be shared widely for research and data analysis.
Some of the fundamental operations in data analysis include analyzing
aggregated statistics, e.g., count, sum, or median, on a subset of data
satisfying some conditions. When synthetic data is generated, users may be
interested in knowing if their aggregated queries generating such statistics
can be reliably answered on the synthetic data, for instance, to decide if the
synthetic data is suitable for specific tasks. However, the standard data
generation systems do not provide "per-query" quality guarantees on the
synthetic data, and the users have no way of knowing how much the aggregated
statistics on the synthetic data can be trusted. To address this problem, we
present a novel framework named DP-PQD (differentially-private per-query
decider) to detect if the query answers on the private and synthetic datasets
are within a user-specified threshold of each other while guaranteeing
differential privacy. We give a suite of private algorithms for per-query
deciders for count, sum, and median queries, analyze their properties, and
evaluate them experimentally.
</p>
</div>
</dd>
<dt><a name="item274">[274]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08577" title="Abstract">arXiv:2309.08577</a> [<a href="/pdf/2309.08577" title="Download PDF">pdf</a>, <a href="/format/2309.08577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lamination-based efficient treatment of weak discontinuities for  non-conforming finite element meshes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Dobrzanski%2C+J">Jedrzej Dobrzanski</a>, 
<a href="/search/cs?searchtype=author&query=Wojtacki%2C+K">Kajetan Wojtacki</a>, 
<a href="/search/cs?searchtype=author&query=Stupkiewicz%2C+S">Stanislaw Stupkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">When modelling discontinuities (interfaces) using the finite element method,
the standard approach is to use a conforming finite-element mesh in which the
mesh matches the interfaces. However, this approach can prove cumbersome if the
geometry is complex, in particular in 3D. In this work, we develop an efficient
technique for a non-conforming finite-element treatment of weak discontinuities
by using laminated microstructures. The approach is inspired by the so-called
composite voxel technique that has been developed for FFT-based spectral
solvers in computational homogenization. The idea behind the method is rather
simple. Each finite element that is cut by an interface is treated as a simple
laminate with the volume fraction of the phases and the lamination orientation
determined in terms of the actual geometrical arrangement of the interface
within the element. The approach is illustrated by several computational
examples relevant to the micromechanics of heterogeneous materials. Elastic and
elastic-plastic materials at small and finite strain are considered in the
examples. The performance of the proposed method is compared to two
alternative, simple methods showing that the new approach is in most cases
superior to them while maintaining the simplicity.
</p>
</div>
</dd>
<dt><a name="item275">[275]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08579" title="Abstract">arXiv:2309.08579</a> [<a href="/pdf/2309.08579" title="Download PDF">pdf</a>, <a href="/ps/2309.08579" title="Download PostScript">ps</a>, <a href="/format/2309.08579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Polytopal composite finite elements for modeling concrete fracture based  on nonlocal damage models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huynh%2C+H+D">Hai D. Huynh</a>, 
<a href="/search/cs?searchtype=author&query=Natarajan%2C+S">S. Natarajan</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen-Xuan%2C+H">H. Nguyen-Xuan</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xiaoying Zhuang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">The paper presents an assumed strain formulation over polygonal meshes to
accurately evaluate the strain fields in nonlocal damage models. An assume
strained technique based on the Hu-Washizu variational principle is employed to
generate a new strain approximation instead of direct derivation from the basis
functions and the displacement fields. The underlying idea embedded in
arbitrary finite polygons is named as Polytopal composite finite elements
(PCFEM). The PCFEM is accordingly applied within the framework of the nonlocal
model of continuum damage mechanics to enhance the description of damage
behaviours in which highly localized deformations must be captured accurately.
This application is helpful to reduce the mesh-sensitivity and elaborate the
process-zone of damage models. Several numerical examples are designed for
various cases of fracture to discuss and validate the computational capability
of the present method through comparison with published numerical results and
experimental data from the literature.
</p>
</div>
</dd>
<dt><a name="item276">[276]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08580" title="Abstract">arXiv:2309.08580</a> [<a href="/pdf/2309.08580" title="Download PDF">pdf</a>, <a href="/format/2309.08580" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Automated Characterization and Monitoring of Material Shape using  Riemannian Geometry
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Smith%2C+A">Alexander Smith</a>, 
<a href="/search/cs?searchtype=author&query=Schilling%2C+S">Steven Schilling</a>, 
<a href="/search/cs?searchtype=author&query=Daoutidis%2C+P">Prodromos Daoutidis</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Applications (stat.AP)

</div>
<p class="mathjax">Shape affects both the physical and chemical properties of a material.
Characterizing the roughness, convexity, and general geometry of a material can
yield information on its catalytic efficiency, solubility, elasticity,
porosity, and overall effectiveness in the application of interest. However,
material shape can be defined in a multitude of conflicting ways where
different aspects of a material's geometry are emphasized over others, leading
to bespoke measures of shape that are not easily generalizable. In this paper,
we explore the use of Riemannian geometry in the analysis of shape and show
that a Riemannian geometric framework for shape analysis is generalizable,
computationally scalable, and can be directly integrated into common data
analysis methods. In this framework, material shapes are abstracted as points
on a Riemannian manifold. This information can be used to construct statistical
moments (e.g., means, variances) and perform tasks such as dimensionality
reduction and statistical process control. We provide a practical introduction
to the mathematics of shape analysis through Riemannian geometry and illustrate
its application on a manufactured/mined granular material dataset provided by
Covia Corp. We show that the Riemannian framework can be used to automatically
extract and quantify the shape of granular materials in a statistically
rigorous manner.
</p>
</div>
</dd>
<dt><a name="item277">[277]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08581" title="Abstract">arXiv:2309.08581</a> [<a href="/pdf/2309.08581" title="Download PDF">pdf</a>, <a href="/ps/2309.08581" title="Download PostScript">ps</a>, <a href="/format/2309.08581" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dependent Type Refinements for Futures
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Somayyajula%2C+S">Siva Somayyajula</a>, 
<a href="/search/cs?searchtype=author&query=Pfenning%2C+F">Frank Pfenning</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, MFPS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Programming Languages (cs.PL)</span>; Logic in Computer Science (cs.LO)

</div>
<p class="mathjax">Type refinements combine the compositionality of typechecking with the
expressivity of program logics, offering a synergistic approach to program
verification. In this paper we apply dependent type refinements to SAX, a
futures-based process calculus that arises from the Curry-Howard interpretation
of the intuitionistic semi-axiomatic sequent calculus and includes unrestricted
recursion both at the level of types and processes. With our type refinement
system, we can reason about the partial correctness of SAX programs,
complementing prior work on sized type refinements that supports reasoning
about termination. Our design regime synthesizes the infinitary proof theory of
SAX with that of bidirectional typing and Hoare logic, deriving some standard
reasoning principles for data and (co)recursion while enabling information
hiding for codata. We prove syntactic type soundness, which entails a notion of
partial correctness that respects codata encapsulation. We illustrate our
language through a few simple examples.
</p>
</div>
</dd>
<dt><a name="item278">[278]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08583" title="Abstract">arXiv:2309.08583</a> [<a href="/pdf/2309.08583" title="Download PDF">pdf</a>, <a href="/format/2309.08583" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ICLEF: In-Context Learning with Expert Feedback for Explainable Style  Transfer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Saakyan%2C+A">Arkadiy Saakyan</a>, 
<a href="/search/cs?searchtype=author&query=Muresan%2C+S">Smaranda Muresan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">While state-of-the-art language models excel at the style transfer task,
current work does not address explainability of style transfer systems.
Explanations could be generated using large language models such as GPT-3.5 and
GPT-4, but the use of such complex systems is inefficient when smaller, widely
distributed, and transparent alternatives are available. We propose a framework
to augment and improve a formality style transfer dataset with explanations via
model distillation from ChatGPT. To further refine the generated explanations,
we propose a novel way to incorporate scarce expert human feedback using
in-context learning (ICLEF: In-Context Learning from Expert Feedback) by
prompting ChatGPT to act as a critic to its own outputs. We use the resulting
dataset of 9,960 explainable formality style transfer instances (e-GYAFC) to
show that current openly distributed instruction-tuned models (and, in some
settings, ChatGPT) perform poorly on the task, and that fine-tuning on our
high-quality dataset leads to significant improvements as shown by automatic
evaluation. In human evaluation, we show that models much smaller than ChatGPT
fine-tuned on our data align better with expert preferences. Finally, we
discuss two potential applications of models fine-tuned on the explainable
style transfer task: interpretable authorship verification and interpretable
adversarial attacks on AI-generated text detectors.
</p>
</div>
</dd>
<dt><a name="item279">[279]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08584" title="Abstract">arXiv:2309.08584</a> [<a href="/pdf/2309.08584" title="Download PDF">pdf</a>, <a href="/format/2309.08584" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase field method for quasi-static hydro-fracture in porous media under  stress boundary condition considering the effect of initial stress field
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+S">Shuwei Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zhuang%2C+X">Xiaoying Zhuang</a>, 
<a href="/search/cs?searchtype=author&query=Rabczuk%2C+T">Timon Rabczuk</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Theoretical and Applied Fracture Mechanics, 2020, 107: 102523
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
<p class="mathjax">Phase field model (PFM) is an efficient fracture modeling method and has high
potential for hydraulic fracturing (HF). However, the current PFMs in HF do not
consider well the effect of in-situ stress field and the numerical examples of
porous media with stress boundary conditions were rarely presented. The main
reason is that if the remote stress is applied on the boundaries of the
calculation domain, there will be relatively large deformation induced on these
stress boundaries, which is not consistent with the engineering observations.
To eliminate this limitation, this paper proposes a new phase field method to
describe quasi-static hydraulic fracture propagation in porous media subjected
to stress boundary conditions, and the new method is more in line with
engineering practice. A new energy functional, which considers the effect of
initial in-situ stress field, is established and then it is used to achieve the
governing equations for the displacement and phase fields through the
variational approach. Biot poroelasticity theory is used to couple the fluid
pressure field and the displacement field while the phase field is used for
determining the fluid properties from the intact domain to the fully broken
domain. In addition, we present several 2D and 3D examples to show the effects
of in-situ stress on hydraulic fracture propagation. The numerical examples
indicate that under stress boundary condition our approach obtains correct
displacement distribution and it is capable of capturing complex hydraulic
fracture growth patterns.
</p>
</div>
</dd>
<dt><a name="item280">[280]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08585" title="Abstract">arXiv:2309.08585</a> [<a href="/pdf/2309.08585" title="Download PDF">pdf</a>, <a href="/format/2309.08585" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Viewpoint Integration and Registration with Vision Language Foundation  Model for Image Change Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lu%2C+X">Xiaonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Yuan%2C+J">Jianlong Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+R">Ruigang Niu</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+Y">Yuan Hu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+F">Fan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
<p class="mathjax">Recently, the development of pre-trained vision language foundation models
(VLFMs) has led to remarkable performance in many tasks. However, these models
tend to have strong single-image understanding capability but lack the ability
to understand multiple images. Therefore, they cannot be directly applied to
cope with image change understanding (ICU), which requires models to capture
actual changes between multiple images and describe them in language. In this
paper, we discover that existing VLFMs perform poorly when applied directly to
ICU because of the following problems: (1) VLFMs generally learn the global
representation of a single image, while ICU requires capturing nuances between
multiple images. (2) The ICU performance of VLFMs is significantly affected by
viewpoint variations, which is caused by the altered relationships between
objects when viewpoint changes. To address these problems, we propose a
Viewpoint Integration and Registration method. Concretely, we introduce a fused
adapter image encoder that fine-tunes pre-trained encoders by inserting
designed trainable adapters and fused adapters, to effectively capture nuances
between image pairs. Additionally, a viewpoint registration flow and a semantic
emphasizing module are designed to reduce the performance degradation caused by
viewpoint variations in the visual and semantic space, respectively.
Experimental results on CLEVR-Change and Spot-the-Diff demonstrate that our
method achieves state-of-the-art performance in all metrics.
</p>
</div>
</dd>
<dt><a name="item281">[281]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08586" title="Abstract">arXiv:2309.08586</a> [<a href="/pdf/2309.08586" title="Download PDF">pdf</a>, <a href="/format/2309.08586" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Replacing softmax with ReLU in Vision Transformers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wortsman%2C+M">Mitchell Wortsman</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaehoon Lee</a>, 
<a href="/search/cs?searchtype=author&query=Gilmer%2C+J">Justin Gilmer</a>, 
<a href="/search/cs?searchtype=author&query=Kornblith%2C+S">Simon Kornblith</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Previous research observed accuracy degradation when replacing the attention
softmax with a point-wise activation such as ReLU. In the context of vision
transformers, we find that this degradation is mitigated when dividing by
sequence length. Our experiments training small to large vision transformers on
ImageNet-21k indicate that ReLU-attention can approach or match the performance
of softmax-attention in terms of scaling behavior as a function of compute.
</p>
</div>
</dd>
<dt><a name="item282">[282]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08587" title="Abstract">arXiv:2309.08587</a> [<a href="/pdf/2309.08587" title="Download PDF">pdf</a>, <a href="/format/2309.08587" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional Foundation Models for Hierarchical Planning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ajay%2C+A">Anurag Ajay</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Seungwook Han</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yilun Du</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaung Li</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhi Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
<a href="/search/cs?searchtype=author&query=Tenenbaum%2C+J">Josh Tenenbaum</a>, 
<a href="/search/cs?searchtype=author&query=Kaelbling%2C+L">Leslie Kaelbling</a>, 
<a href="/search/cs?searchtype=author&query=Srivastava%2C+A">Akash Srivastava</a>, 
<a href="/search/cs?searchtype=author&query=Agrawal%2C+P">Pulkit Agrawal</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Website: <a href="https://hierarchical-planning-foundation-model.github.io/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Robotics (cs.RO)

</div>
<p class="mathjax">To make effective decisions in novel environments with long-horizon goals, it
is crucial to engage in hierarchical reasoning across spatial and temporal
scales. This entails planning abstract subgoal sequences, visually reasoning
about the underlying plans, and executing actions in accordance with the
devised plan through visual-motor control. We propose Compositional Foundation
Models for Hierarchical Planning (HiP), a foundation model which leverages
multiple expert foundation model trained on language, vision and action data
individually jointly together to solve long-horizon tasks. We use a large
language model to construct symbolic plans that are grounded in the environment
through a large video diffusion model. Generated video plans are then grounded
to visual-motor control, through an inverse dynamics model that infers actions
from generated videos. To enable effective reasoning within this hierarchy, we
enforce consistency between the models via iterative refinement. We illustrate
the efficacy and adaptability of our approach in three different long-horizon
table-top manipulation tasks.
</p>
</div>
</dd>
<dt><a name="item283">[283]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08588" title="Abstract">arXiv:2309.08588</a> [<a href="/pdf/2309.08588" title="Download PDF">pdf</a>, <a href="/format/2309.08588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Frame-to-Frame Camera Rotation Estimation in Crowded Scenes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Delattre%2C+F">Fabien Delattre</a>, 
<a href="/search/cs?searchtype=author&query=Dirnfeld%2C+D">David Dirnfeld</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+P">Phat Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Scarano%2C+S">Stephen Scarano</a>, 
<a href="/search/cs?searchtype=author&query=Jones%2C+M+J">Michael J. Jones</a>, 
<a href="/search/cs?searchtype=author&query=Miraldo%2C+P">Pedro Miraldo</a>, 
<a href="/search/cs?searchtype=author&query=Learned-Miller%2C+E">Erik Learned-Miller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">We present an approach to estimating camera rotation in crowded, real-world
scenes from handheld monocular video. While camera rotation estimation is a
well-studied problem, no previous methods exhibit both high accuracy and
acceptable speed in this setting. Because the setting is not addressed well by
other datasets, we provide a new dataset and benchmark, with high-accuracy,
rigorously verified ground truth, on 17 video sequences. Methods developed for
wide baseline stereo (e.g., 5-point methods) perform poorly on monocular video.
On the other hand, methods used in autonomous driving (e.g., SLAM) leverage
specific sensor setups, specific motion models, or local optimization
strategies (lagging batch processing) and do not generalize well to handheld
video. Finally, for dynamic scenes, commonly used robustification techniques
like RANSAC require large numbers of iterations, and become prohibitively slow.
We introduce a novel generalization of the Hough transform on SO(3) to
efficiently and robustly find the camera rotation most compatible with optical
flow. Among comparably fast methods, ours reduces error by almost 50\% over the
next best, and is more accurate than any method, irrespective of speed. This
represents a strong new performance point for crowded scenes, an important
setting for computer vision. The code and the dataset are available at
https://fabiendelattre.com/robust-rotation-estimation.
</p>
</div>
</dd>
<dt><a name="item284">[284]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08589" title="Abstract">arXiv:2309.08589</a> [<a href="/pdf/2309.08589" title="Download PDF">pdf</a>, <a href="/format/2309.08589" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chain-of-Thought Reasoning is a Policy Improvement Operator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hugh Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Parkes%2C+D+C">David C. Parkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
<p class="mathjax">Large language models have astounded the world with fascinating new
capabilities. However, they currently lack the ability to teach themselves new
skills, relying instead on being trained on large amounts of human-generated
data. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a
proof-of-concept demonstration that language models can successfully teach
themselves new skills using chain-of-thought reasoning. Inspired by previous
work in both reinforcement learning (Silver et al., 2017) and human cognition
(Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think
its way through problems. SECToR then fine-tunes the model to generate those
same answers, this time without using chain-of-thought reasoning. Language
models trained via SECToR autonomously learn to add up to 29-digit numbers
without any access to any ground truth examples beyond an initial supervised
fine-tuning phase consisting only of numbers with 6 or fewer digits. Our
central hypothesis is that chain-of-thought reasoning can act as a policy
improvement operator, analogously to how Monte-Carlo Tree Search is used in
AlphaZero. We hope that this research can lead to new directions in which
language models can learn to teach themselves without the need for human
demonstrations.
</p>
</div>
</dd>
<dt><a name="item285">[285]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08590" title="Abstract">arXiv:2309.08590</a> [<a href="/pdf/2309.08590" title="Download PDF">pdf</a>, <a href="/format/2309.08590" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Machine Translation Models Can Learn to be Few-shot Learners
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Reinauer%2C+R">Raphael Reinauer</a>, 
<a href="/search/cs?searchtype=author&query=Simianer%2C+P">Patrick Simianer</a>, 
<a href="/search/cs?searchtype=author&query=Uhlig%2C+K">Kaden Uhlig</a>, 
<a href="/search/cs?searchtype=author&query=Mosig%2C+J+E+M">Johannes E. M. Mosig</a>, 
<a href="/search/cs?searchtype=author&query=Wuebker%2C+J">Joern Wuebker</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">The emergent ability of Large Language Models to use a small number of
examples to learn to perform in novel domains and tasks, also called in-context
learning (ICL). In this work, we show that a much smaller model can be trained
to perform ICL by fine-tuning towards a specialized training objective,
exemplified on the task of domain adaptation for neural machine translation.
With this capacity for ICL, the model can take advantage of relevant few-shot
examples to adapt its output towards the domain. We compare the quality of this
domain adaptation to traditional supervised techniques and ICL with a
40B-parameter Large Language Model. Our approach allows efficient batch
inference on a mix of domains and outperforms state-of-the-art baselines in
terms of both translation quality and immediate adaptation rate, i.e. the
ability to reproduce a specific term after being shown a single example.
</p>
</div>
</dd>
<dt><a name="item286">[286]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08591" title="Abstract">arXiv:2309.08591</a> [<a href="/pdf/2309.08591" title="Download PDF">pdf</a>, <a href="/format/2309.08591" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation  into Multicultural Proverbs and Sayings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C+C">Chen Cecilia Liu</a>, 
<a href="/search/cs?searchtype=author&query=Koto%2C+F">Fajri Koto</a>, 
<a href="/search/cs?searchtype=author&query=Baldwin%2C+T">Timothy Baldwin</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) are highly adept at question answering and
reasoning tasks, but when reasoning in situational context, human expectations
vary depending on the relevant cultural common ground. As human languages are
associated with diverse cultures, LLMs should also be culturally-diverse
reasoners. In this paper, we study the ability of a wide range of
state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings
in a conversational context. Our experiments reveal that: (1) mLLMs 'knows'
limited proverbs and memorizing proverbs does not mean understanding them
within a conversational context; (2) mLLMs struggle to reason with figurative
proverbs and sayings, and when asked to select the wrong answer (instead of
asking it to select the correct answer); and (3) there is a "culture gap" in
mLLMs when reasoning about proverbs and sayings translated from other
languages. We construct and release our evaluation dataset MAPS (MulticultrAl
Proverbs and Sayings) for proverb understanding with conversational context for
six different languages.
</p>
</div>
</dd>
<dt><a name="item287">[287]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08593" title="Abstract">arXiv:2309.08593</a> [<a href="/pdf/2309.08593" title="Download PDF">pdf</a>, <a href="/ps/2309.08593" title="Download PostScript">ps</a>, <a href="/format/2309.08593" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Attention-Only Transformers and Implementing MLPs with Attention Heads
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huben%2C+R">Robert Huben</a>, 
<a href="/search/cs?searchtype=author&query=Morris%2C+V">Valerie Morris</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
<p class="mathjax">The transformer architecture is widely used in machine learning models and
consists of two alternating sublayers: attention heads and MLPs. We prove that
an MLP neuron can be implemented by a masked attention head with internal
dimension 1 so long as the MLP's activation function comes from a restricted
class including SiLU and close approximations of ReLU and GeLU. This allows one
to convert an MLP-and-attention transformer into an attention-only transformer
at the cost of greatly increasing the number of attention heads. We also prove
that attention heads can perform the components of an MLP (linear
transformations and activation functions) separately. Finally, we prove that
attention heads can encode arbitrary masking patterns in their weight matrices
to within arbitrarily small error.
</p>
</div>
</dd>
<dt><a name="item288">[288]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08594" title="Abstract">arXiv:2309.08594</a> [<a href="/pdf/2309.08594" title="Download PDF">pdf</a>, <a href="/format/2309.08594" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> &quot;Merge Conflicts!&quot; Exploring the Impacts of External Distractors to  Parametric Knowledge Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Qian%2C+C">Cheng Qian</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X">Xinran Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+S+T">Sherry Tongshuang Wu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
<p class="mathjax">Large language models (LLMs) acquire extensive knowledge during pre-training,
known as their parametric knowledge. However, in order to remain up-to-date and
align with human instructions, LLMs inevitably require external knowledge
during their interactions with users. This raises a crucial question: How will
LLMs respond when external knowledge interferes with their parametric
knowledge? To investigate this question, we propose a framework that
systematically elicits LLM parametric knowledge and introduces external
knowledge. Specifically, we uncover the impacts by constructing a parametric
knowledge graph to reveal the different knowledge structures of LLMs, and
introduce external knowledge through distractors of varying degrees, methods,
positions, and formats. Our experiments on both black-box and open-source
models demonstrate that LLMs tend to produce responses that deviate from their
parametric knowledge, particularly when they encounter direct conflicts or
confounding changes of information within detailed contexts. We also find that
while LLMs are sensitive to the veracity of external knowledge, they can still
be distracted by unrelated information. These findings highlight the risk of
hallucination when integrating external knowledge, even indirectly, during
interactions with current LLMs. All the data and results are publicly
available.
</p>
</div>
</dd>
<dt><a name="item289">[289]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08596" title="Abstract">arXiv:2309.08596</a> [<a href="/pdf/2309.08596" title="Download PDF">pdf</a>, <a href="/format/2309.08596" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust e-NeRF: NeRF from Sparse &amp; Noisy Events under Non-Uniform Motion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Low%2C+W+F">Weng Fei Low</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+G+H">Gim Hee Lee</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to ICCV 2023. Project website is accessible at <a href="https://wengflow.github.io/robust-e-nerf">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Robotics (cs.RO)

</div>
<p class="mathjax">Event cameras offer many advantages over standard cameras due to their
distinctive principle of operation: low power, low latency, high temporal
resolution and high dynamic range. Nonetheless, the success of many downstream
visual applications also hinges on an efficient and effective scene
representation, where Neural Radiance Field (NeRF) is seen as the leading
candidate. Such promise and potential of event cameras and NeRF inspired recent
works to investigate on the reconstruction of NeRF from moving event cameras.
However, these works are mainly limited in terms of the dependence on dense and
low-noise event streams, as well as generalization to arbitrary contrast
threshold values and camera speed profiles. In this work, we propose Robust
e-NeRF, a novel method to directly and robustly reconstruct NeRFs from moving
event cameras under various real-world conditions, especially from sparse and
noisy events generated under non-uniform motion. It consists of two key
components: a realistic event generation model that accounts for various
intrinsic parameters (e.g. time-independent, asymmetric threshold and
refractory period) and non-idealities (e.g. pixel-to-pixel threshold
variation), as well as a complementary pair of normalized reconstruction losses
that can effectively generalize to arbitrary speed profiles and intrinsic
parameter values without such prior knowledge. Experiments on real and novel
realistically simulated sequences verify our effectiveness. Our code, synthetic
dataset and improved event simulator are public.
</p>
</div>
</dd>
<dt><a name="item290">[290]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08600" title="Abstract">arXiv:2309.08600</a> [<a href="/pdf/2309.08600" title="Download PDF">pdf</a>, <a href="/format/2309.08600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sparse Autoencoders Find Highly Interpretable Features in Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cunningham%2C+H">Hoagy Cunningham</a>, 
<a href="/search/cs?searchtype=author&query=Ewart%2C+A">Aidan Ewart</a>, 
<a href="/search/cs?searchtype=author&query=Riggs%2C+L">Logan Riggs</a>, 
<a href="/search/cs?searchtype=author&query=Huben%2C+R">Robert Huben</a>, 
<a href="/search/cs?searchtype=author&query=Sharkey%2C+L">Lee Sharkey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages, 20 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computation and Language (cs.CL)

</div>
<p class="mathjax">One of the roadblocks to a better understanding of neural networks' internals
is \textit{polysemanticity}, where neurons appear to activate in multiple,
semantically distinct contexts. Polysemanticity prevents us from identifying
concise, human-understandable explanations for what neural networks are doing
internally. One hypothesised cause of polysemanticity is
\textit{superposition}, where neural networks represent more features than they
have neurons by assigning features to an overcomplete set of directions in
activation space, rather than to individual neurons. Here, we attempt to
identify those directions, using sparse autoencoders to reconstruct the
internal activations of a language model. These autoencoders learn sets of
sparsely activating features that are more interpretable and monosemantic than
directions identified by alternative approaches, where interpretability is
measured by automated methods. Ablating these features enables precise model
editing, for example, by removing capabilities such as pronoun prediction,
while disrupting model behaviour less than prior techniques. This work
indicates that it is possible to resolve superposition in language models using
a scalable, unsupervised method. Our method may serve as a foundation for
future mechanistic interpretability work, which we hope will enable greater
model transparency and steerability.
</p>
</div>
</dd>
<dt><a name="item291">[291]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08603" title="Abstract">arXiv:2309.08603</a> [<a href="/pdf/2309.08603" title="Download PDF">pdf</a>, <a href="/format/2309.08603" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Closing the Loop on Runtime Monitors with Fallback-Safe MPC
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Sinha%2C+R">Rohan Sinha</a>, 
<a href="/search/eess?searchtype=author&query=Schmerling%2C+E">Edward Schmerling</a>, 
<a href="/search/eess?searchtype=author&query=Pavone%2C+M">Marco Pavone</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted to the 2023 IEEE Conference on Decision and Control
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Robotics (cs.RO)

</div>
<p class="mathjax">When we rely on deep-learned models for robotic perception, we must recognize
that these models may behave unreliably on inputs dissimilar from the training
data, compromising the closed-loop system's safety. This raises fundamental
questions on how we can assess confidence in perception systems and to what
extent we can take safety-preserving actions when external environmental
changes degrade our perception model's performance. Therefore, we present a
framework to certify the safety of a perception-enabled system deployed in
novel contexts. To do so, we leverage robust model predictive control (MPC) to
control the system using the perception estimates while maintaining the
feasibility of a safety-preserving fallback plan that does not rely on the
perception system. In addition, we calibrate a runtime monitor using recently
proposed conformal prediction techniques to certifiably detect when the
perception system degrades beyond the tolerance of the MPC controller,
resulting in an end-to-end safety assurance. We show that this control
framework and calibration technique allows us to certify the system's safety
with orders of magnitudes fewer samples than required to retrain the perception
network when we deploy in a novel context on a photo-realistic aircraft taxiing
simulator. Furthermore, we illustrate the safety-preserving behavior of the MPC
on simulated examples of a quadrotor. We open-source our simulation platform
and provide videos of our results at our project page:
\url{https://tinyurl.com/fallback-safe-mpc}.
</p>
</div>
</dd>
</dl>
<h3>Cross-lists for Mon, 18 Sep 23</h3>
<dl>
<dt><a name="item292">[292]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07924" title="Abstract">arXiv:2309.07924</a> (cross-list from math.HO) [<a href="/pdf/2309.07924" title="Download PDF">pdf</a>, <a href="/format/2309.07924" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving the Problem of Induction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yang%2C+X">Xuezhi Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">History and Overview (math.HO)</span>; Information Theory (cs.IT); Probability (math.PR)

</div>
<p class="mathjax">This article solves the Hume's problem of induction using a probabilistic
approach. From the probabilistic perspective, the core task of induction is to
estimate the probability of an event and judge the accuracy of the estimation.
Following this principle, the article provides a method for calculating the
confidence on a given confidence interval, and furthermore, degree of
confirmation. The law of large numbers shows that as the number of experiments
tends to infinity, for any small confidence interval, the confidence approaches
100\% in a probabilistic sense, thus the Hume's problem of induction is solved.
The foundation of this method is the existence of probability, or in other
words, the identity of physical laws. The article points out that it cannot be
guaranteed that all things possess identity, but humans only concern themselves
with things that possess identity, and identity is built on the foundation of
pragmatism. After solving the Hum's problem, a novel demarcation of science are
proposed, providing science with the legitimacy of being referred to as truth.
</p>
</div>
</dd>
<dt><a name="item293">[293]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07925" title="Abstract">arXiv:2309.07925</a> (cross-list from eess.AS) [<a href="/pdf/2309.07925" title="Download PDF">pdf</a>, <a href="/format/2309.07925" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hierarchical Audio-Visual Information Fusion with Multi-label Joint  Decoding for MER 2023
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Haotian Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xi%2C+Y">Yuxuan Xi</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Y">Yan Song</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qing Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhou%2C+H">Hengshun Zhou</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chenxi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+J">Jiefeng Ma</a>, 
<a href="/search/eess?searchtype=author&query=Hu%2C+P">Pengfei Hu</a>, 
<a href="/search/eess?searchtype=author&query=Jiang%2C+Y">Ya Jiang</a>, 
<a href="/search/eess?searchtype=author&query=Cheng%2C+S">Shi Cheng</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Weng%2C+Y">Yuzhe Weng</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> The 31st ACM International Conference on Multimedia (MM'23), 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we propose a novel framework for recognizing both discrete and
dimensional emotions. In our framework, deep features extracted from foundation
models are used as robust acoustic and visual representations of raw video.
Three different structures based on attention-guided feature gathering (AFG)
are designed for deep feature fusion. Then, we introduce a joint decoding
structure for emotion classification and valence regression in the decoding
stage. A multi-task loss based on uncertainty is also designed to optimize the
whole process. Finally, by combining three different structures on the
posterior probability level, we obtain the final predictions of discrete and
dimensional emotions. When tested on the dataset of multimodal emotion
recognition challenge (MER 2023), the proposed framework yields consistent
improvements in both emotion classification and valence regression. Our final
system achieves state-of-the-art performance and ranks third on the leaderboard
on MER-MULTI sub-challenge.
</p>
</div>
</dd>
<dt><a name="item294">[294]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07926" title="Abstract">arXiv:2309.07926</a> (cross-list from eess.IV) [<a href="/pdf/2309.07926" title="Download PDF">pdf</a>, <a href="/format/2309.07926" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> COMPASS: High-Efficiency Deep Image Compression with Arbitrary-scale  Spatial Scalability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Park%2C+J">Jongmin Park</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+J">Jooyoung Lee</a>, 
<a href="/search/eess?searchtype=author&query=Kim%2C+M">Munchurl Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Recently, neural network (NN)-based image compression studies have actively
been made and has shown impressive performance in comparison to traditional
methods. However, most of the works have focused on non-scalable image
compression (single-layer coding) while spatially scalable image compression
has drawn less attention although it has many applications. In this paper, we
propose a novel NN-based spatially scalable image compression method, called
COMPASS, which supports arbitrary-scale spatial scalability. Our proposed
COMPASS has a very flexible structure where the number of layers and their
respective scale factors can be arbitrarily determined during inference. To
reduce the spatial redundancy between adjacent layers for arbitrary scale
factors, our COMPASS adopts an inter-layer arbitrary scale prediction method,
called LIFF, based on implicit neural representation. We propose a combined RD
loss function to effectively train multiple layers. Experimental results show
that our COMPASS achieves BD-rate gain of -58.33% and -47.17% at maximum
compared to SHVC and the state-of-the-art NN-based spatially scalable image
compression method, respectively, for various combinations of scale factors.
Our COMPASS also shows comparable or even better coding efficiency than the
single-layer coding for various scale factors.
</p>
</div>
</dd>
<dt><a name="item295">[295]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07927" title="Abstract">arXiv:2309.07927</a> (cross-list from eess.AS) [<a href="/pdf/2309.07927" title="Download PDF">pdf</a>, <a href="/ps/2309.07927" title="Download PostScript">ps</a>, <a href="/format/2309.07927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech  Recognition for Children VS. Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Attia%2C+A+A">Ahmed Adel Attia</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+J">Jing Liu</a>, 
<a href="/search/eess?searchtype=author&query=Ai%2C+W">Wei Ai</a>, 
<a href="/search/eess?searchtype=author&query=Demszky%2C+D">Dorottya Demszky</a>, 
<a href="/search/eess?searchtype=author&query=Espy-Wilson%2C+C">Carol Espy-Wilson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Recent advancements in Automatic Speech Recognition (ASR) systems,
exemplified by Whisper, have demonstrated the potential of these systems to
approach human-level performance given sufficient data. However, this progress
doesn't readily extend to ASR for children due to the limited availability of
suitable child-specific databases and the distinct characteristics of
children's speech. A recent study investigated leveraging the My Science Tutor
(MyST) children's speech corpus to enhance Whisper's performance in recognizing
children's speech. This paper builds on these findings by enhancing the utility
of the MyST dataset through more efficient data preprocessing. We also
highlight important challenges towards improving children's ASR performance.
The results showcase the viable and efficient integration of Whisper for
effective children's speech recognition.
</p>
</div>
</dd>
<dt><a name="item296">[296]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07932" title="Abstract">arXiv:2309.07932</a> (cross-list from math.CO) [<a href="/pdf/2309.07932" title="Download PDF">pdf</a>, <a href="/ps/2309.07932" title="Download PostScript">ps</a>, <a href="/format/2309.07932" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Flat origami is Turing Complete
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hull%2C+T+C">Thomas C. Hull</a>, 
<a href="/search/math?searchtype=author&query=Zakharevich%2C+I">Inna Zakharevich</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC)

</div>
<p class="mathjax">Flat origami refers to the folding of flat, zero-curvature paper such that
the finished object lies in a plane. Mathematically, flat origami consists of a
continuous, piecewise isometric map $f:P\subseteq\mathbb{R}^2\to\mathbb{R}^2$
along with a layer ordering $\lambda_f:P\times P\to \{-1,1\}$ that tracks which
points of $P$ are above/below others when folded. The set of crease lines that
a flat origami makes (i.e., the set on which the mapping $f$ is
non-differentiable) is called its \textit{crease pattern}. Flat origami
mappings and their layer orderings can possess surprisingly intricate
structure. For instance, determining whether or not a given straight-line
planar graph drawn on $P$ is the crease pattern for some flat origami has been
shown to be an NP-complete problem, and this result from 1996 led to numerous
explorations in computational aspects of flat origami. In this paper we prove
that flat origami, when viewed as a computational device, is Turing complete.
We do this by showing that flat origami crease patterns with \textit{optional
creases} (creases that might be folded or remain unfolded depending on
constraints imposed by other creases or inputs) can be constructed to simulate
Rule 110, a one-dimensional cellular automaton that was proven to be Turing
complete by Matthew Cook in 2004.
</p>
</div>
</dd>
<dt><a name="item297">[297]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07937" title="Abstract">arXiv:2309.07937</a> (cross-list from eess.AS) [<a href="/pdf/2309.07937" title="Download PDF">pdf</a>, <a href="/format/2309.07937" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Voxtlm: unified decoder-only models for consolidating speech  recognition/synthesis and speech/text continuation tasks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Maiti%2C+S">Soumi Maiti</a>, 
<a href="/search/eess?searchtype=author&query=Peng%2C+Y">Yifan Peng</a>, 
<a href="/search/eess?searchtype=author&query=Choi%2C+S">Shukjae Choi</a>, 
<a href="/search/eess?searchtype=author&query=Jung%2C+J">Jee-weon Jung</a>, 
<a href="/search/eess?searchtype=author&query=Chang%2C+X">Xuankai Chang</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We propose a decoder-only language model, VoxtLM, that can perform four
tasks: speech recognition, speech synthesis, text generation, and speech
continuation. VoxtLM integrates text vocabulary with discrete speech tokens
from self-supervised speech features and uses special tokens to enable
multitask learning. Compared to a single-task model, VoxtLM exhibits a
significant improvement in speech synthesis, with improvements in both speech
intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90.
VoxtLM also improves speech generation and speech recognition performance over
the single-task counterpart. VoxtLM is trained with publicly available data and
training recipes and model checkpoints will be open-sourced to make fully
reproducible work.
</p>
</div>
</dd>
<dt><a name="item298">[298]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07946" title="Abstract">arXiv:2309.07946</a> (cross-list from math.DS) [<a href="/pdf/2309.07946" title="Download PDF">pdf</a>, <a href="/ps/2309.07946" title="Download PostScript">ps</a>, <a href="/format/2309.07946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Slow Invariant Manifolds of Singularly Perturbed Systems via  Physics-Informed Machine Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Patsatzis%2C+D+G">Dimitrios G. Patsatzis</a>, 
<a href="/search/math?searchtype=author&query=Fabiani%2C+G">Gianluca Fabiani</a>, 
<a href="/search/math?searchtype=author&query=Russo%2C+L">Lucia Russo</a>, 
<a href="/search/math?searchtype=author&query=Siettos%2C+C">Constantinos Siettos</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Dynamical Systems (math.DS)</span>; Machine Learning (cs.LG); Numerical Analysis (math.NA)

</div>
<p class="mathjax">We present a physics-informed machine-learning (PIML) approach for the
approximation of slow invariant manifolds (SIMs) of singularly perturbed
systems, providing functionals in an explicit form that facilitate the
construction and numerical integration of reduced order models (ROMs). The
proposed scheme solves a partial differential equation corresponding to the
invariance equation (IE) within the Geometric Singular Perturbation Theory
(GSPT) framework. For the solution of the IE, we used two neural network
structures, namely feedforward neural networks (FNNs), and random projection
neural networks (RPNNs), with symbolic differentiation for the computation of
the gradients required for the learning process. The efficiency of our PIML
method is assessed via three benchmark problems, namely the Michaelis-Menten,
the target mediated drug disposition reaction mechanism, and the 3D Sel'kov
model. We show that the proposed PIML scheme provides approximations, of
equivalent or even higher accuracy, than those provided by other traditional
GSPT-based methods, and importantly, for any practical purposes, it is not
affected by the magnitude of the perturbation parameter. This is of particular
importance, as there are many systems for which the gap between the fast and
slow timescales is not that big, but still ROMs can be constructed. A
comparison of the computational costs between symbolic, automatic and numerical
approximation of the required derivatives in the learning process is also
provided.
</p>
</div>
</dd>
<dt><a name="item299">[299]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07948" title="Abstract">arXiv:2309.07948</a> (cross-list from eess.SP) [<a href="/pdf/2309.07948" title="Download PDF">pdf</a>, <a href="/format/2309.07948" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Complex-Valued Neural Networks for Data-Driven Signal Processing and  Signal Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Smith%2C+J+W">Josiah W. Smith</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Preprint
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Complex-valued neural networks have emerged boasting superior modeling
performance for many tasks across the signal processing, sensing, and
communications arenas. However, developing complex-valued models currently
demands development of basic deep learning operations, such as linear or
convolution layers, as modern deep learning frameworks like PyTorch and Tensor
flow do not adequately support complex-valued neural networks. This paper
overviews a package built on PyTorch with the intention of implementing
light-weight interfaces for common complex-valued neural network operations and
architectures. Similar to natural language understanding (NLU), which as
recently made tremendous leaps towards text-based intelligence, RF Signal
Understanding (RFSU) is a promising field extending conventional signal
processing algorithms using a hybrid approach of signal mechanics-based insight
with data-driven modeling power. Notably, we include efficient implementations
for linear, convolution, and attention modules in addition to activation
functions and normalization layers such as batchnorm and layernorm.
Additionally, we include efficient implementations of manifold-based
complex-valued neural network layers that have shown tremendous promise but
remain relatively unexplored in many research contexts. Although there is an
emphasis on 1-D data tensors, due to a focus on signal processing,
communications, and radar data, many of the routines are implemented for 2-D
and 3-D data as well. Specifically, the proposed approach offers a useful set
of tools and documentation for data-driven signal processing research and
practical implementation.
</p>
</div>
</dd>
<dt><a name="item300">[300]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07973" title="Abstract">arXiv:2309.07973</a> (cross-list from eess.IV) [<a href="/pdf/2309.07973" title="Download PDF">pdf</a>, <a href="/format/2309.07973" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> M3Dsynth: A dataset of medical 3D images with AI-generated local  manipulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zingarini%2C+G">Giada Zingarini</a>, 
<a href="/search/eess?searchtype=author&query=Cozzolino%2C+D">Davide Cozzolino</a>, 
<a href="/search/eess?searchtype=author&query=Corvi%2C+R">Riccardo Corvi</a>, 
<a href="/search/eess?searchtype=author&query=Poggi%2C+G">Giovanni Poggi</a>, 
<a href="/search/eess?searchtype=author&query=Verdoliva%2C+L">Luisa Verdoliva</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The ability to detect manipulated visual content is becoming increasingly
important in many application fields, given the rapid advances in image
synthesis methods. Of particular concern is the possibility of modifying the
content of medical images, altering the resulting diagnoses. Despite its
relevance, this issue has received limited attention from the research
community. One reason is the lack of large and curated datasets to use for
development and benchmarking purposes. Here, we investigate this issue and
propose M3Dsynth, a large dataset of manipulated Computed Tomography (CT) lung
images. We create manipulated images by injecting or removing lung cancer
nodules in real CT scans, using three different methods based on Generative
Adversarial Networks (GAN) or Diffusion Models (DM), for a total of 8,577
manipulated samples. Experiments show that these images easily fool automated
diagnostic tools. We also tested several state-of-the-art forensic detectors
and demonstrated that, once trained on the proposed dataset, they are able to
accurately detect and localize manipulated synthetic content, including when
training and test sets are not aligned, showing good generalization ability.
Dataset and code will be publicly available at
https://grip-unina.github.io/M3Dsynth/.
</p>
</div>
</dd>
<dt><a name="item301">[301]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07982" title="Abstract">arXiv:2309.07982</a> (cross-list from stat.ML) [<a href="/pdf/2309.07982" title="Download PDF">pdf</a>, <a href="/format/2309.07982" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty quantification for learned ISTA
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hoppe%2C+F">Frederik Hoppe</a>, 
<a href="/search/stat?searchtype=author&query=Verdun%2C+C+M">Claudio Mayrink Verdun</a>, 
<a href="/search/stat?searchtype=author&query=Krahmer%2C+F">Felix Krahmer</a>, 
<a href="/search/stat?searchtype=author&query=Laus%2C+H">Hannah Laus</a>, 
<a href="/search/stat?searchtype=author&query=Rauhut%2C+H">Holger Rauhut</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> to appear at the 33rd IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Information Theory (cs.IT); Machine Learning (cs.LG); Image and Video Processing (eess.IV); Signal Processing (eess.SP)

</div>
<p class="mathjax">Model-based deep learning solutions to inverse problems have attracted
increasing attention in recent years as they bridge state-of-the-art numerical
performance with interpretability. In addition, the incorporated prior domain
knowledge can make the training more efficient as the smaller number of
parameters allows the training step to be executed with smaller datasets.
Algorithm unrolling schemes stand out among these model-based learning
techniques. Despite their rapid advancement and their close connection to
traditional high-dimensional statistical methods, they lack certainty estimates
and a theory for uncertainty quantification is still elusive. This work
provides a step towards closing this gap proposing a rigorous way to obtain
confidence intervals for the LISTA estimator.
</p>
</div>
</dd>
<dt><a name="item302">[302]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08005" title="Abstract">arXiv:2309.08005</a> (cross-list from eess.AS) [<a href="/pdf/2309.08005" title="Download PDF">pdf</a>, <a href="/ps/2309.08005" title="Download PostScript">ps</a>, <a href="/format/2309.08005" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Face Detection with Audio-Based Region Proposals
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Aris%2C+W">William Aris</a>, 
<a href="/search/eess?searchtype=author&query=Grondin%2C+F">Fran&#xe7;ois Grondin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Image and Video Processing (eess.IV)

</div>
<p class="mathjax">Robot vision often involves a large computational load due to large images to
process in a short amount of time. Existing solutions often involve reducing
image quality which can negatively impact processing. Another approach is to
generate regions of interest with expensive vision algorithms. In this paper,
we evaluate how audio can be used to generate regions of interest in optical
images. To achieve this, we propose a unique attention mechanism to localize
speech sources and evaluate its impact on a face detection algorithm. Our
results show that the attention mechanism reduces the computational load. The
proposed pipeline is flexible and can be easily adapted for human-robot
interactions, robot surveillance, video-conferences or smart glasses.
</p>
</div>
</dd>
<dt><a name="item303">[303]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08007" title="Abstract">arXiv:2309.08007</a> (cross-list from eess.AS) [<a href="/pdf/2309.08007" title="Download PDF">pdf</a>, <a href="/ps/2309.08007" title="Download PostScript">ps</a>, <a href="/format/2309.08007" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiariST: Streaming Speech Translation with Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yang%2C+M">Mu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Kanda%2C+N">Naoyuki Kanda</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Junkun Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Peidong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Xue%2C+J">Jian Xue</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinyu Li</a>, 
<a href="/search/eess?searchtype=author&query=Yoshioka%2C+T">Takuya Yoshioka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">End-to-end speech translation (ST) for conversation recordings involves
several under-explored challenges such as speaker diarization (SD) without
accurate word time stamps and handling of overlapping speech in a streaming
fashion. In this work, we propose DiariST, the first streaming ST and SD
solution. It is built upon a neural transducer-based streaming ST system and
integrates token-level serialized output training and t-vector, which were
originally developed for multi-talker speech recognition. Due to the absence of
evaluation benchmarks in this area, we develop a new evaluation dataset,
DiariST-AliMeeting, by translating the reference Chinese transcriptions of the
AliMeeting corpus into English. We also propose new metrics, called
speaker-agnostic BLEU and speaker-attributed BLEU, to measure the ST quality
while taking SD accuracy into account. Our system achieves a strong ST and SD
capability compared to offline systems based on Whisper, while performing
streaming inference for overlapping speech. To facilitate the research in this
new direction, we release the evaluation data, the offline baseline systems,
and the evaluation code.
</p>
</div>
</dd>
<dt><a name="item304">[304]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08023" title="Abstract">arXiv:2309.08023</a> (cross-list from eess.AS) [<a href="/pdf/2309.08023" title="Download PDF">pdf</a>, <a href="/format/2309.08023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> USM-SCD: Multilingual Speaker Change Detection Based on Large Pretrained  Foundation Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yongqiang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pelecanos%2C+J">Jason Pelecanos</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yu Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiling Huang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Han Lu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Quan Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We introduce a multilingual speaker change detection model (USM-SCD) that can
simultaneously detect speaker turns and perform ASR for 96 languages. This
model is adapted from a speech foundation model trained on a large quantity of
supervised and unsupervised data, demonstrating the utility of fine-tuning from
a large generic foundation model for a downstream task. We analyze the
performance of this multilingual speaker change detection model through a
series of ablation studies. We show that the USM-SCD model can achieve more
than 75% average speaker change detection F1 score across a test set that
consists of data from 96 languages. On American English, the USM-SCD model can
achieve an 85.8% speaker change detection F1 score across various public and
internal test sets, beating the previous monolingual baseline model by 21%
relative. We also show that we only need to fine-tune one-quarter of the
trainable model parameters to achieve the best model performance. The USM-SCD
model exhibits state-of-the-art ASR quality compared with a strong public ASR
baseline, making it suitable to handle both tasks with negligible additional
computational cost.
</p>
</div>
</dd>
<dt><a name="item305">[305]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08030" title="Abstract">arXiv:2309.08030</a> (cross-list from eess.AS) [<a href="/pdf/2309.08030" title="Download PDF">pdf</a>, <a href="/format/2309.08030" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised  Features for Audio-Visual Speech Enhancement
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chou%2C+J">Ju-Chieh Chou</a>, 
<a href="/search/eess?searchtype=author&query=Chien%2C+C">Chung-Ming Chien</a>, 
<a href="/search/eess?searchtype=author&query=Livescu%2C+K">Karen Livescu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">Speech enhancement systems are typically trained using pairs of clean and
noisy speech. In audio-visual speech enhancement (AVSE), there is not as much
ground-truth clean data available; most audio-visual datasets are collected in
real-world environments with background noise and reverberation, hampering the
development of AVSE. In this work, we introduce AV2Wav, a resynthesis-based
audio-visual speech enhancement approach that can generate clean speech despite
the challenges of real-world training data. We obtain a subset of nearly clean
speech from an audio-visual corpus using a neural quality estimator, and then
train a diffusion model on this subset to generate waveforms conditioned on
continuous speech representations from AV-HuBERT with noise-robust training. We
use continuous rather than discrete representations to retain prosody and
speaker information. With this vocoding task alone, the model can perform
speech enhancement better than a masking-based baseline. We further fine-tune
the diffusion model on clean/noisy utterance pairs to improve the performance.
Our approach outperforms a masking-based baseline in terms of both automatic
metrics and a human listening test and is close in quality to the target speech
in the listening test. Audio samples can be found at
https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html.
</p>
</div>
</dd>
<dt><a name="item306">[306]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08034" title="Abstract">arXiv:2309.08034</a> (cross-list from math.OC) [<a href="/pdf/2309.08034" title="Download PDF">pdf</a>, <a href="/format/2309.08034" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved Small-Signal L2 Gain Analysis for Nonlinear Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Strong%2C+A">Amy Strong</a>, 
<a href="/search/math?searchtype=author&query=Lavaei%2C+R">Reza Lavaei</a>, 
<a href="/search/math?searchtype=author&query=Bridgeman%2C+L+J">Leila J. Bridgeman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
<p class="mathjax">The L2-gain characterizes a dynamical system's input-output properties and is
used for important control methods, like H-infinity control. However, gain can
be difficult to determine for nonlinear systems. Previous work designed a
nonconvex optimization problem to simultaneously search for a continuous
piecewise affine (CPA) storage function and an upper bound on the small-signal
L2-gain of a dynamical system over a triangulated region about the origin. This
work improves upon those results to establish a tighter upper-bound on a
system's gain through a convex optimization problem. By reformulating the
relationship between the Hamilton-Jacobi equations and gain as a linear matrix
inequality (LMI) and then developing novel LMI error bounds for a
triangulation, tighter gain bounds are derived and computed more efficiently.
Numerical results demonstrate the less conservative upper bound on a dynamical
system's gain.
</p>
</div>
</dd>
<dt><a name="item307">[307]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08044" title="Abstract">arXiv:2309.08044</a> (cross-list from stat.ML) [<a href="/pdf/2309.08044" title="Download PDF">pdf</a>, <a href="/ps/2309.08044" title="Download PostScript">ps</a>, <a href="/format/2309.08044" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How many Neurons do we need? A refined Analysis for Shallow Networks  trained with Gradient Descent
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Nguyen%2C+M">Mike Nguyen</a>, 
<a href="/search/stat?searchtype=author&query=M%C3%BCcke%2C+N">Nicole M&#xfc;cke</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">We analyze the generalization properties of two-layer neural networks in the
neural tangent kernel (NTK) regime, trained with gradient descent (GD). For
early stopped GD we derive fast rates of convergence that are known to be
minimax optimal in the framework of non-parametric regression in reproducing
kernel Hilbert spaces. On our way, we precisely keep track of the number of
hidden neurons required for generalization and improve over existing results.
We further show that the weights during training remain in a vicinity around
initialization, the radius being dependent on structural assumptions such as
degree of smoothness of the regression function and eigenvalue decay of the
integral operator associated to the NTK.
</p>
</div>
</dd>
<dt><a name="item308">[308]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08060" title="Abstract">arXiv:2309.08060</a> (cross-list from eess.AS) [<a href="/pdf/2309.08060" title="Download PDF">pdf</a>, <a href="/format/2309.08060" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DDSP-SFX: Acoustically-guided sound effects generation with  differentiable digital signal processing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yunyi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Jin%2C+C">Craig Jin</a>, 
<a href="/search/eess?searchtype=author&query=Gunawan%2C+D">David Gunawan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Controlling the variations of sound effects using neural audio synthesis
models has been a difficult task. Differentiable digital signal processing
(DDSP) provides a lightweight solution that achieves high-quality sound
synthesis while enabling deterministic acoustic attribute control by
incorporating pre-processed audio features and digital synthesizers. In this
research, we introduce DDSP-SFX, a model based on the DDSP architecture capable
of synthesizing high-quality sound effects while enabling users to control the
timbre variations easily. We propose a transient modelling technique with
higher objective evaluation scores and subjective ratings over impulsive
signals (footsteps, gunshots). We propose a simple method that achieves timbre
variation control while also allowing deterministic attribute control. We
further qualitatively show the timbre transfer performance using voice as the
guiding sound.
</p>
</div>
</dd>
<dt><a name="item309">[309]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08081" title="Abstract">arXiv:2309.08081</a> (cross-list from math.CO) [<a href="/pdf/2309.08081" title="Download PDF">pdf</a>, <a href="/ps/2309.08081" title="Download PostScript">ps</a>, <a href="/format/2309.08081" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A note on the Assmus--Mattson theorem for some non-binary codes (a  resume)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bannai%2C+E">Eiichi Bannai</a>, 
<a href="/search/math?searchtype=author&query=Miezaki%2C+T">Tsuyoshi Miezaki</a>, 
<a href="/search/math?searchtype=author&query=Nakasora%2C+H">Hiroyuki Nakasora</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, this is a resume of "A note on the Assmus--Mattson theorem for some non-binary codes"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">Let $C$ be a two and three-weight ternary code. Furthermore, we assume that
$C_\ell$ are $t$-designs for all $\ell$ by the Assmus--Mattson theorem. We show
that $t \leq 5$. As a corollary, we provide a new characterization of the
(extended) ternary Golay code.
</p>
</div>
</dd>
<dt><a name="item310">[310]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08105" title="Abstract">arXiv:2309.08105</a> (cross-list from eess.AS) [<a href="/pdf/2309.08105" title="Download PDF">pdf</a>, <a href="/format/2309.08105" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Libriheavy: a 50,000 hours ASR corpus with punctuation casing and  context
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kang%2C+W">Wei Kang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+X">Xiaoyu Yang</a>, 
<a href="/search/eess?searchtype=author&query=Yao%2C+Z">Zengwei Yao</a>, 
<a href="/search/eess?searchtype=author&query=Kuang%2C+F">Fangjun Kuang</a>, 
<a href="/search/eess?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/eess?searchtype=author&query=Guo%2C+L">Liyong Guo</a>, 
<a href="/search/eess?searchtype=author&query=Lin%2C+L">Long Lin</a>, 
<a href="/search/eess?searchtype=author&query=Povey%2C+D">Daniel Povey</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In this paper, we introduce Libriheavy, a large-scale ASR corpus consisting
of 50,000 hours of read English speech derived from LibriVox. To the best of
our knowledge, Libriheavy is the largest freely-available corpus of speech with
supervisions. Different from other open-sourced datasets that only provide
normalized transcriptions, Libriheavy contains richer information such as
punctuation, casing and text context, which brings more flexibility for system
building. Specifically, we propose a general and efficient pipeline to locate,
align and segment the audios in previously published Librilight to its
corresponding texts. The same as Librilight, Libriheavy also has three training
subsets small, medium, large of the sizes 500h, 5000h, 50000h respectively. We
also extract the dev and test evaluation sets from the aligned audios and
guarantee there is no overlapping speakers and books in training sets. Baseline
systems are built on the popular CTC-Attention and transducer models.
Additionally, we open-source our dataset creatation pipeline which can also be
used to other audio alignment tasks.
</p>
</div>
</dd>
<dt><a name="item311">[311]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08129" title="Abstract">arXiv:2309.08129</a> (cross-list from eess.IV) [<a href="/pdf/2309.08129" title="Download PDF">pdf</a>, <a href="/format/2309.08129" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Increasing diversity of omni-directional images generated from single  image using cGAN based on MLPMixer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Nakata%2C+A">Atsuya Nakata</a>, 
<a href="/search/eess?searchtype=author&query=Miyazaki%2C+R">Ryuto Miyazaki</a>, 
<a href="/search/eess?searchtype=author&query=Yamanaka%2C+T">Takao Yamanaka</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This is a pre-print of an article in ACPR2023. The proceedings will be published in Lecture Notes in Computer Science (LNCS). The code is available at <a href="https://github.com/islab-sophia/odigen-mlpmixer">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">This paper proposes a novel approach to generating omni-directional images
from a single snapshot picture. The previous method has relied on the
generative adversarial networks based on convolutional neural networks (CNN).
Although this method has successfully generated omni-directional images, CNN
has two drawbacks for this task. First, since a convolutional layer only
processes a local area, it is difficult to propagate the information of an
input snapshot picture embedded in the center of the omni-directional image to
the edges of the image. Thus, the omni-directional images created by the
CNN-based generator tend to have less diversity at the edges of the generated
images, creating similar scene images. Second, the CNN-based model requires
large video memory in graphics processing units due to the nature of the deep
structure in CNN since shallow-layer networks only receives signals from a
limited range of the receptive field. To solve these problems, MLPMixer-based
method was proposed in this paper. The MLPMixer has been proposed as an
alternative to the self-attention in the transformer, which captures long-range
dependencies and contextual information. This enables to propagate information
efficiently in the omni-directional image generation task. As a result,
competitive performance has been achieved with reduced memory consumption and
computational cost, in addition to increasing diversity of the generated
omni-directional images.
</p>
</div>
</dd>
<dt><a name="item312">[312]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08131" title="Abstract">arXiv:2309.08131</a> (cross-list from eess.AS) [<a href="/pdf/2309.08131" title="Download PDF">pdf</a>, <a href="/format/2309.08131" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> t-SOT FNT: Streaming Multi-talker ASR with Text-only Domain Adaptation  Capability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+J">Jian Wu</a>, 
<a href="/search/eess?searchtype=author&query=Kanda%2C+N">Naoyuki Kanda</a>, 
<a href="/search/eess?searchtype=author&query=Yoshioka%2C+T">Takuya Yoshioka</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+R">Rui Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Zhuo Chen</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+J">Jinyu Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Token-level serialized output training (t-SOT) was recently proposed to
address the challenge of streaming multi-talker automatic speech recognition
(ASR). T-SOT effectively handles overlapped speech by representing multi-talker
transcriptions as a single token stream with $\langle \text{cc}\rangle$ symbols
interspersed. However, the use of a naive neural transducer architecture
significantly constrained its applicability for text-only adaptation. To
overcome this limitation, we propose a novel t-SOT model structure that
incorporates the idea of factorized neural transducers (FNT). The proposed
method separates a language model (LM) from the transducer's predictor and
handles the unnatural token order resulting from the use of $\langle
\text{cc}\rangle$ symbols in t-SOT. We achieve this by maintaining multiple
hidden states and introducing special handling of the $\langle
\text{cc}\rangle$ tokens within the LM. The proposed t-SOT FNT model achieves
comparable performance to the original t-SOT model while retaining the ability
to reduce word error rate (WER) on both single and multi-talker datasets
through text-only adaptation.
</p>
</div>
</dd>
<dt><a name="item313">[313]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08140" title="Abstract">arXiv:2309.08140</a> (cross-list from eess.AS) [<a href="/pdf/2309.08140" title="Download PDF">pdf</a>, <a href="/format/2309.08140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech  Using Natural Language Descriptions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shimizu%2C+R">Reo Shimizu</a>, 
<a href="/search/eess?searchtype=author&query=Yamamoto%2C+R">Ryuichi Yamamoto</a>, 
<a href="/search/eess?searchtype=author&query=Kawamura%2C+M">Masaya Kawamura</a>, 
<a href="/search/eess?searchtype=author&query=Shirahata%2C+Y">Yuma Shirahata</a>, 
<a href="/search/eess?searchtype=author&query=Doi%2C+H">Hironori Doi</a>, 
<a href="/search/eess?searchtype=author&query=Komatsu%2C+T">Tatsuya Komatsu</a>, 
<a href="/search/eess?searchtype=author&query=Tachibana%2C+K">Kentaro Tachibana</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system
that allows control over speaker identity using natural language descriptions.
To control speaker identity within the prompt-based TTS framework, we introduce
the concept of speaker prompt, which describes voice characteristics (e.g.,
gender-neutral, young, old, and muffled) designed to be approximately
independent of speaking style. Since there is no large-scale dataset containing
speaker prompts, we first construct a dataset based on the LibriTTS-R corpus
with manually annotated speaker prompts. We then employ a diffusion-based
acoustic model with mixture density networks to model diverse speaker factors
in the training data. Unlike previous studies that rely on style prompts
describing only a limited aspect of speaker individuality, such as pitch,
speaking speed, and energy, our method utilizes an additional speaker prompt to
effectively learn the mapping from natural language descriptions to the
acoustic features of diverse speakers. Our subjective evaluation results show
that the proposed method can better control speaker characteristics than the
methods without the speaker prompt. Audio samples are available at
https://reppy4620.github.io/demo.promptttspp/.
</p>
</div>
</dd>
<dt><a name="item314">[314]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08141" title="Abstract">arXiv:2309.08141</a> (cross-list from eess.AS) [<a href="/pdf/2309.08141" title="Download PDF">pdf</a>, <a href="/format/2309.08141" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio Difference Learning for Audio Captioning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Komatsu%2C+T">Tatsuya Komatsu</a>, 
<a href="/search/eess?searchtype=author&query=Fujita%2C+Y">Yusuke Fujita</a>, 
<a href="/search/eess?searchtype=author&query=Takeda%2C+K">Kazuya Takeda</a>, 
<a href="/search/eess?searchtype=author&query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Signal Processing (eess.SP)

</div>
<p class="mathjax">This study introduces a novel training paradigm, audio difference learning,
for improving audio captioning. The fundamental concept of the proposed
learning method is to create a feature representation space that preserves the
relationship between audio, enabling the generation of captions that detail
intricate audio information. This method employs a reference audio along with
the input audio, both of which are transformed into feature representations via
a shared encoder. Captions are then generated from these differential features
to describe their differences. Furthermore, a unique technique is proposed that
involves mixing the input audio with additional audio, and using the additional
audio as a reference. This results in the difference between the mixed audio
and the reference audio reverting back to the original input audio. This allows
the original input's caption to be used as the caption for their difference,
eliminating the need for additional annotations for the differences. In the
experiments using the Clotho and ESC50 datasets, the proposed method
demonstrated an improvement in the SPIDEr score by 7% compared to conventional
methods.
</p>
</div>
</dd>
<dt><a name="item315">[315]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08153" title="Abstract">arXiv:2309.08153</a> (cross-list from eess.AS) [<a href="/pdf/2309.08153" title="Download PDF">pdf</a>, <a href="/format/2309.08153" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Fine-tune the pretrained ATST model for sound event detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Shao%2C+N">Nian Shao</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xian Li</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures, this paper is submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Sound event detection (SED) often suffers from the data deficiency problem.
The recent baseline system in the DCASE2023 challenge task 4 leverages the
large pretrained self-supervised learning (SelfSL) models to mitigate such
restriction, where the pretrained models help to produce more discriminative
features for SED. However, the pretrained models are regarded as a frozen
feature extractor in the challenge baseline system and most of the challenge
submissions, and fine-tuning of the pretrained models has been rarely studied.
In this work, we study the fine-tuning method of the pretrained models for SED.
We first introduce ATST-Frame, our newly proposed SelfSL model, to the SED
system. ATST-Frame was especially designed for learning frame-level
representations of audio signals and obtained state-of-the-art (SOTA)
performances on a series of downstream tasks. We then propose a fine-tuning
method for ATST-Frame using both (in-domain) unlabelled and labelled SED data.
Our experiments show that, the proposed method overcomes the overfitting
problem when fine-tuning the large pretrained network, and our SED system
obtains new SOTA results of 0.587/0.812 PSDS1/PSDS2 scores on the DCASE
challenge task 4 dataset.
</p>
</div>
</dd>
<dt><a name="item316">[316]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08157" title="Abstract">arXiv:2309.08157</a> (cross-list from eess.AS) [<a href="/pdf/2309.08157" title="Download PDF">pdf</a>, <a href="/format/2309.08157" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RVAE-EM: Generative speech dereverberation based on recurrent  variational auto-encoder and convolutive transfer function
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+P">Pengyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+X">Xiaofei Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">In indoor scenes, reverberation is a crucial factor in degrading the
perceived quality and intelligibility of speech. In this work, we propose a
generative dereverberation method. Our approach is based on a probabilistic
model utilizing a recurrent variational auto-encoder (RVAE) network and the
convolutive transfer function (CTF) approximation. Different from most previous
approaches, the output of our RVAE serves as the prior of the clean speech. And
our target is the maximum a posteriori (MAP) estimation of clean speech, which
is achieved iteratively through the expectation maximization (EM) algorithm.
The proposed method integrates the capabilities of network-based speech prior
modelling and CTF-based observation modelling. Experiments on single-channel
speech dereverberation show that the proposed generative method noticeably
outperforms the advanced discriminative networks.
</p>
</div>
</dd>
<dt><a name="item317">[317]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08160" title="Abstract">arXiv:2309.08160</a> (cross-list from eess.IV) [<a href="/pdf/2309.08160" title="Download PDF">pdf</a>, <a href="/format/2309.08160" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Modal Synthesis of Structural MRI and Functional Connectivity  Networks via Conditional ViT-GANs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Bi%2C+Y">Yuda Bi</a>, 
<a href="/search/eess?searchtype=author&query=Abrol%2C+A">Anees Abrol</a>, 
<a href="/search/eess?searchtype=author&query=Sui%2C+J">Jing Sui</a>, 
<a href="/search/eess?searchtype=author&query=Calhoun%2C+V">Vince Calhoun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">The cross-modal synthesis between structural magnetic resonance imaging
(sMRI) and functional network connectivity (FNC) is a relatively unexplored
area in medical imaging, especially with respect to schizophrenia. This study
employs conditional Vision Transformer Generative Adversarial Networks
(cViT-GANs) to generate FNC data based on sMRI inputs. After training on a
comprehensive dataset that included both individuals with schizophrenia and
healthy control subjects, our cViT-GAN model effectively synthesized the FNC
matrix for each subject, and then formed a group difference FNC matrix,
obtaining a Pearson correlation of 0.73 with the actual FNC matrix. In
addition, our FNC visualization results demonstrate significant correlations in
particular subcortical brain regions, highlighting the model's capability of
capturing detailed structural-functional associations. This performance
distinguishes our model from conditional CNN-based GAN alternatives such as
Pix2Pix. Our research is one of the first attempts to link sMRI and FNC
synthesis, setting it apart from other cross-modal studies that concentrate on
T1- and T2-weighted MR images or the fusion of MRI and CT scans.
</p>
</div>
</dd>
<dt><a name="item318">[318]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08169" title="Abstract">arXiv:2309.08169</a> (cross-list from math.CO) [<a href="/pdf/2309.08169" title="Download PDF">pdf</a>, <a href="/format/2309.08169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On Induced Versions of Menger&#x27;s Theorem on Sparse Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Gartland%2C+P">Peter Gartland</a>, 
<a href="/search/math?searchtype=author&query=Korhonen%2C+T">Tuukka Korhonen</a>, 
<a href="/search/math?searchtype=author&query=Lokshtanov%2C+D">Daniel Lokshtanov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Data Structures and Algorithms (cs.DS)

</div>
<p class="mathjax">Let $A$ and $B$ be sets of vertices in a graph $G$. Menger's theorem states
that for every positive integer $k$, either there exists a collection of $k$
vertex-disjoint paths between $A$ and $B$, or $A$ can be separated from $B$ by
a set of at most $k-1$ vertices. Let $\Delta$ be the maximum degree of $G$. We
show that there exists a function $f(\Delta) = (\Delta+1)^{\Delta^2+1}$, so
that for every positive integer $k$, either there exists a collection of $k$
vertex-disjoint and pairwise anticomplete paths between $A$ and $B$, or $A$ can
be separated from $B$ by a set of at most $k \cdot f(\Delta)$ vertices. We also
show that the result can be generalized from bounded-degree graphs to graphs
excluding a topological minor. On the negative side, we show that no such
relation holds on graphs that have degeneracy 2 and arbitrarily large girth,
even when $k = 2$. Similar results were obtained independently and concurrently
by Hendrey, Norin, Steiner, and Turcotte [<a href="/abs/2309.07905">arXiv:2309.07905</a>].
</p>
</div>
</dd>
<dt><a name="item319">[319]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08195" title="Abstract">arXiv:2309.08195</a> (cross-list from astro-ph.EP) [<a href="/pdf/2309.08195" title="Download PDF">pdf</a>, <a href="/format/2309.08195" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An Explainable Deep-learning Model of Proton Auroras on Mars
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Dhuri%2C+D+B">Dattaraj B. Dhuri</a>, 
<a href="/search/astro-ph?searchtype=author&query=Atri%2C+D">Dimitra Atri</a>, 
<a href="/search/astro-ph?searchtype=author&query=AlHantoobi%2C+A">Ahmed AlHantoobi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 17 Pages, 10 Figures, 4 Tables, Submitted to PsJ
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Machine Learning (cs.LG)

</div>
<p class="mathjax">Proton auroras are widely observed on the day side of Mars, identified as a
significant intensity enhancement in the hydrogen Ly alpha (121.6 nm) emission
between 120 and 150~km altitudes. Solar wind protons penetrating as energetic
neutral atoms into the Martian thermosphere are thought to be responsible for
these auroras. Understanding proton auroras is therefore important for
characterizing the solar wind interaction with the atmosphere of Mars. Recent
observations of spatially localized "patchy" proton auroras suggest a possible
direct deposition of protons into the atmosphere of Mars during unstable solar
wind conditions. Here, we develop a purely data-driven model of proton auroras
using Mars Atmosphere and Volatile EvolutioN (MAVEN) in situ observations and
limb scans of Ly alpha emissions between 2014 and 2022. We train an artificial
neural network that reproduces individual Ly alpha intensities with a Pearson
correlation of 0.95 along with a faithful reconstruction of the observed Ly
alpha emission altitude profiles. By performing a SHapley Additive exPlanations
(SHAP) analysis, we find that Solar Zenith Angle, seasonal CO2 atmosphere
variability, solar wind temperature, and density are the most important
features for the modelled proton auroras. We also demonstrate that our model
can serve as an inexpensive tool for simulating and characterizing Ly alpha
response under a variety of seasonal and upstream solar wind conditions.
</p>
</div>
</dd>
<dt><a name="item320">[320]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08197" title="Abstract">arXiv:2309.08197</a> (cross-list from eess.IV) [<a href="/pdf/2309.08197" title="Download PDF">pdf</a>, <a href="/format/2309.08197" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Hyperspectral Image Denoising via Self-Modulating Convolutional Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Torun%2C+O">Orhan Torun</a>, 
<a href="/search/eess?searchtype=author&query=Yuksel%2C+S+E">Seniha Esen Yuksel</a>, 
<a href="/search/eess?searchtype=author&query=Erdem%2C+E">Erkut Erdem</a>, 
<a href="/search/eess?searchtype=author&query=Imamoglu%2C+N">Nevrez Imamoglu</a>, 
<a href="/search/eess?searchtype=author&query=Erdem%2C+A">Aykut Erdem</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Signal Processing, Volume 214, January 2024, 109248
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Compared to natural images, hyperspectral images (HSIs) consist of a large
number of bands, with each band capturing different spectral information from a
certain wavelength, even some beyond the visible spectrum. These
characteristics of HSIs make them highly effective for remote sensing
applications. That said, the existing hyperspectral imaging devices introduce
severe degradation in HSIs. Hence, hyperspectral image denoising has attracted
lots of attention by the community lately. While recent deep HSI denoising
methods have provided effective solutions, their performance under real-life
complex noise remains suboptimal, as they lack adaptability to new data. To
overcome these limitations, in our work, we introduce a self-modulating
convolutional neural network which we refer to as SM-CNN, which utilizes
correlated spectral and spatial information. At the core of the model lies a
novel block, which we call spectral self-modulating residual block (SSMRB),
that allows the network to transform the features in an adaptive manner based
on the adjacent spectral data, enhancing the network's ability to handle
complex noise. In particular, the introduction of SSMRB transforms our
denoising network into a dynamic network that adapts its predicted features
while denoising every input HSI with respect to its spatio-spectral
characteristics. Experimental analysis on both synthetic and real data shows
that the proposed SM-CNN outperforms other state-of-the-art HSI denoising
methods both quantitatively and qualitatively on public benchmark datasets.
</p>
</div>
</dd>
<dt><a name="item321">[321]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08217" title="Abstract">arXiv:2309.08217</a> (cross-list from astro-ph.EP) [<a href="/pdf/2309.08217" title="Download PDF">pdf</a>, <a href="/format/2309.08217" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speeding up the GENGA N-body integrator on consumer-grade graphics cards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Brasser%2C+R">R. Brasser</a>, 
<a href="/search/astro-ph?searchtype=author&query=Grimm%2C+S+L">S. L. Grimm</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hatalova%2C+P">P. Hatalova</a>, 
<a href="/search/astro-ph?searchtype=author&query=Stadel%2C+J+G">J. G. Stadel</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in Astronomy &amp; Astrophysics
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; Instrumentation and Methods for Astrophysics (astro-ph.IM); Distributed, Parallel, and Cluster Computing (cs.DC); Computational Physics (physics.comp-ph)

</div>
<p class="mathjax">GPU computing is popular due to the calculation potential of a single card.
The N-body integrator GENGA is built to for this, but it suffers a performance
penalty on consumer-grade GPUs due to their truncated double precision (FP64)
performance. We aim to speed up GENGA on consumer-grade cards by harvesting
their high single-precision performance (FP32). We modified GENGA to be able to
compute the long-distance forces between bodies in FP32 precision and tested
this with 5 experiments. We ran simulations with similar initial conditions of
6600 planetesimals in both FP32 and FP64 precision. We also ran simulations
that i) began with a mixture of planetesimals and planetary embryos, ii)
planetesimal-driven giant planet migration, and iii) terrestrial planet
formation with a gas disc. Second, we ran the same simulation beginning with 40
000 planetesimals using both FP32 and FP64 precision forces on a variety of
consumer-grade and Tesla GPUs to measure the performance boost of FP32
computing. There are no statistical differences when running in FP32 or FP64
precision that can be attributed to the force prescription rather than
stochastic effects. The uncertainties in energy are almost identical when using
both precisions. However, the uncertainty in the angular momentum using FP32
rather than FP64 precision long-range forces is about two orders of magnitude
greater, but still very low. Running the simulations in single precision on
consumer-grade cards decreases running time by a factor of three and becomes
within a factor of three of a Tesla A100 GPU. Additional tuning speeds up the
simulation by a factor of two across all types of cards. The option to compute
the long-range forces in single precision in GENGA when using consumer-grade
GPUs dramatically improves performance at a little penalty to accuracy. There
is an additional environmental benefit because it reduces energy usage.
</p>
</div>
</dd>
<dt><a name="item322">[322]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08222" title="Abstract">arXiv:2309.08222</a> (cross-list from math.OC) [<a href="/pdf/2309.08222" title="Download PDF">pdf</a>, <a href="/format/2309.08222" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exact Computation of LTI Reach Set from Integrator Reach Set with  Bounded Input
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Haddad%2C+S">Shadi Haddad</a>, 
<a href="/search/math?searchtype=author&query=Khodary%2C+P">Pansie Khodary</a>, 
<a href="/search/math?searchtype=author&query=Halder%2C+A">Abhishek Halder</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY); Dynamical Systems (math.DS)

</div>
<p class="mathjax">We present a semi-analytical method for exact computation of the boundary of
the reach set of a single-input controllable linear time invariant (LTI) system
with given bounds on its input range. In doing so, we deduce a parametric
formula for the boundary of the reach set of an integrator linear system with
time-varying bounded input. This formula generalizes recent results on the
geometry of an integrator reach set with time-invariant bounded input. We show
that the same ideas allow for computing the volume of the LTI reach set.
</p>
</div>
</dd>
<dt><a name="item323">[323]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08234" title="Abstract">arXiv:2309.08234</a> (cross-list from eess.IV) [<a href="/pdf/2309.08234" title="Download PDF">pdf</a>, <a href="/format/2309.08234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Efficient Polyp Segmentation Via Integrity Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+Z">Ziqiang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+K">Kang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yun Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submited to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Accurate polyp delineation in colonoscopy is crucial for assisting in
diagnosis, guiding interventions, and treatments. However, current
deep-learning approaches fall short due to integrity deficiency, which often
manifests as missing lesion parts. This paper introduces the integrity concept
in polyp segmentation at both macro and micro levels, aiming to alleviate
integrity deficiency. Specifically, the model should distinguish entire polyps
at the macro level and identify all components within polyps at the micro
level. Our Integrity Capturing Polyp Segmentation (IC-PolypSeg) network
utilizes lightweight backbones and 3 key components for integrity ameliorating:
1) Pixel-wise feature redistribution (PFR) module captures global spatial
correlations across channels in the final semantic-rich encoder features. 2)
Cross-stage pixel-wise feature redistribution (CPFR) module dynamically fuses
high-level semantics and low-level spatial features to capture contextual
information. 3) Coarse-to-fine calibration module combines PFR and CPFR modules
to achieve precise boundary detection. Extensive experiments on 5 public
datasets demonstrate that the proposed IC-PolypSeg outperforms 8
state-of-the-art methods in terms of higher precision and significantly
improved computational efficiency with lower computational consumption.
IC-PolypSeg-EF0 employs 300 times fewer parameters than PraNet while achieving
a real-time processing speed of 235 FPS. Importantly, IC-PolypSeg reduces the
false negative ratio on five datasets, meeting clinical requirements.
</p>
</div>
</dd>
<dt><a name="item324">[324]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08241" title="Abstract">arXiv:2309.08241</a> (cross-list from stat.ML) [<a href="/pdf/2309.08241" title="Download PDF">pdf</a>, <a href="/format/2309.08241" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Topological Node2vec: Enhanced Graph Embedding via Persistent Homology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Hiraoka%2C+Y">Yasuaki Hiraoka</a>, 
<a href="/search/stat?searchtype=author&query=Imoto%2C+Y">Yusuke Imoto</a>, 
<a href="/search/stat?searchtype=author&query=Meehan%2C+K">Killian Meehan</a>, 
<a href="/search/stat?searchtype=author&query=Lacombe%2C+T">Th&#xe9;o Lacombe</a>, 
<a href="/search/stat?searchtype=author&query=Yachimura%2C+T">Toshiaki Yachimura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For associated repository, see <a href="https://github.com/killianfmeehan/topological_node2vec">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Algebraic Topology (math.AT); Optimization and Control (math.OC)

</div>
<p class="mathjax">Node2vec is a graph embedding method that learns a vector representation for
each node of a weighted graph while seeking to preserve relative proximity and
global structure. Numerical experiments suggest Node2vec struggles to recreate
the topology of the input graph. To resolve this we introduce a topological
loss term to be added to the training loss of Node2vec which tries to align the
persistence diagram (PD) of the resulting embedding as closely as possible to
that of the input graph. Following results in computational optimal transport,
we carefully adapt entropic regularization to PD metrics, allowing us to
measure the discrepancy between PDs in a differentiable way. Our modified loss
function can then be minimized through gradient descent to reconstruct both the
geometry and the topology of the input graph. We showcase the benefits of this
approach using demonstrative synthetic examples.
</p>
</div>
</dd>
<dt><a name="item325">[325]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08255" title="Abstract">arXiv:2309.08255</a> (cross-list from eess.AS) [<a href="/pdf/2309.08255" title="Download PDF">pdf</a>, <a href="/format/2309.08255" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for  Robust Polyglot Text-To-Speech
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Piotrowski%2C+D">Dariusz Piotrowski</a>, 
<a href="/search/eess?searchtype=author&query=Korzeniowski%2C+R">Renard Korzeniowski</a>, 
<a href="/search/eess?searchtype=author&query=Falai%2C+A">Alessio Falai</a>, 
<a href="/search/eess?searchtype=author&query=Cygert%2C+S">Sebastian Cygert</a>, 
<a href="/search/eess?searchtype=author&query=Pokora%2C+K">Kamil Pokora</a>, 
<a href="/search/eess?searchtype=author&query=Tinchev%2C+G">Georgi Tinchev</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Ziyao Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Yanagisawa%2C+K">Kayoko Yanagisawa</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICONIP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">In this work, we introduce a framework for cross-lingual speech synthesis,
which involves an upstream Voice Conversion (VC) model and a downstream
Text-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the
first two stages, we use a VC model to convert utterances in the target locale
to the voice of the target speaker. In the third stage, the converted data is
combined with the linguistic features and durations from recordings in the
target language, which are then used to train a single-speaker acoustic model.
Finally, the last stage entails the training of a locale-independent vocoder.
Our evaluations show that the proposed paradigm outperforms state-of-the-art
approaches which are based on training a large multilingual TTS model. In
addition, our experiments demonstrate the robustness of our approach with
different model architectures, languages, speakers and amounts of data.
Moreover, our solution is especially beneficial in low-resource settings.
</p>
</div>
</dd>
<dt><a name="item326">[326]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08263" title="Abstract">arXiv:2309.08263</a> (cross-list from eess.AS) [<a href="/pdf/2309.08263" title="Download PDF">pdf</a>, <a href="/format/2309.08263" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Voice Conversion for Dissimilar Speakers Using Perceptual  Losses
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ghosh1%2C+S">Suhita Ghosh1</a>, 
<a href="/search/eess?searchtype=author&query=Sinha%2C+Y">Yamini Sinha</a>, 
<a href="/search/eess?searchtype=author&query=Siegert%2C+I">Ingo Siegert</a>, 
<a href="/search/eess?searchtype=author&query=Stober%2C+S">Sebastian Stober</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in The German Annual Conference on Acoustics 2023 (DAGA)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The rising trend of using voice as a means of interacting with smart devices
has sparked worries over the protection of users' privacy and data security.
These concerns have become more pressing, especially after the European Union's
adoption of the General Data Protection Regulation (GDPR). The information
contained in an utterance encompasses critical personal details about the
speaker, such as their age, gender, socio-cultural origins and more. If there
is a security breach and the data is compromised, attackers may utilise the
speech data to circumvent the speaker verification systems or imitate
authorised users. Therefore, it is pertinent to anonymise the speech data
before being shared across devices, such that the source speaker of the
utterance cannot be traced. Voice conversion (VC) can be used to achieve speech
anonymisation, which involves altering the speaker's characteristics while
preserving the linguistic content.
</p>
</div>
</dd>
<dt><a name="item327">[327]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08279" title="Abstract">arXiv:2309.08279</a> (cross-list from eess.AS) [<a href="/pdf/2309.08279" title="Download PDF">pdf</a>, <a href="/format/2309.08279" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improving Short Utterance Anti-Spoofing with AASIST2
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jingze Lu</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+Z">Zengqiang Shang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenchao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The wav2vec 2.0 and integrated spectro-temporal graph attention network
(AASIST) based countermeasure achieves great performance in speech
anti-spoofing. However, current spoof speech detection systems have fixed
training and evaluation durations, while the performance degrades significantly
during short utterance evaluation. To solve this problem, AASIST can be
improved to AASIST2 by modifying the residual blocks to Res2Net blocks. The
modified Res2Net blocks can extract multi-scale features and improve the
detection performance for speech of different durations, thus improving the
short utterance evaluation performance. On the other hand, adaptive large
margin fine-tuning (ALMFT) has achieved performance improvement in short
utterance speaker verification. Therefore, we apply Dynamic Chunk Size (DCS)
and ALMFT training strategies in speech anti-spoofing to further improve the
performance of short utterance evaluation. Experiments demonstrate that the
proposed AASIST2 improves the performance of short utterance evaluation while
maintaining the performance of regular evaluation on different datasets.
</p>
</div>
</dd>
<dt><a name="item328">[328]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08285" title="Abstract">arXiv:2309.08285</a> (cross-list from eess.AS) [<a href="/pdf/2309.08285" title="Download PDF">pdf</a>, <a href="/format/2309.08285" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> One-Class Knowledge Distillation for Spoofing Speech Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lu%2C+J">Jingze Lu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yuxiang Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Wenchao Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shang%2C+Z">Zengqiang Shang</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Pengyuan Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to icassp 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">The detection of spoofing speech generated by unseen algorithms remains an
unresolved challenge. One reason for the lack of generalization ability is
traditional detecting systems follow the binary classification paradigm, which
inherently assumes the possession of prior knowledge of spoofing speech.
One-class methods attempt to learn the distribution of bonafide speech and are
inherently suited to the task where spoofing speech exhibits significant
differences. However, training a one-class system using only bonafide speech is
challenging. In this paper, we introduce a teacher-student framework to provide
guidance for the training of a one-class model. The proposed one-class
knowledge distillation method outperforms other state-of-the-art methods on the
ASVspoof 21DF dataset and InTheWild dataset, which demonstrates its superior
generalization ability.
</p>
</div>
</dd>
<dt><a name="item329">[329]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08290" title="Abstract">arXiv:2309.08290</a> (cross-list from eess.AS) [<a href="/pdf/2309.08290" title="Download PDF">pdf</a>, <a href="/format/2309.08290" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Head-Related Transfer Function Interpolation with a Spherical CNN
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Chen%2C+X">Xingyu Chen</a>, 
<a href="/search/eess?searchtype=author&query=Ma%2C+F">Fei Ma</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Y">Yile Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Bastine%2C+A">Amy Bastine</a>, 
<a href="/search/eess?searchtype=author&query=Samarasinghe%2C+P+N">Prasanga N. Samarasinghe</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Head-related transfer functions (HRTFs) are crucial for spatial soundfield
reproduction in virtual reality applications. However, obtaining personalized,
high-resolution HRTFs is a time-consuming and costly task. Recently, deep
learning-based methods showed promise in interpolating high-resolution HRTFs
from sparse measurements. Some of these methods treat HRTF interpolation as an
image super-resolution task, which neglects spatial acoustic features. This
paper proposes a spherical convolutional neural network method for HRTF
interpolation. The proposed method realizes the convolution process by
decomposing and reconstructing HRTF through the Spherical Harmonics (SHs). The
SHs, an orthogonal function set defined on a sphere, allow the convolution
layers to effectively capture the spatial features of HRTFs, which are sampled
on a sphere. Simulation results demonstrate the effectiveness of the proposed
method in achieving accurate interpolation from sparse measurements,
outperforming the SH method and learning-based methods.
</p>
</div>
</dd>
<dt><a name="item330">[330]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08294" title="Abstract">arXiv:2309.08294</a> (cross-list from eess.AS) [<a href="/pdf/2309.08294" title="Download PDF">pdf</a>, <a href="/format/2309.08294" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Speech-dependent Modeling of Own Voice Transfer Characteristics for  In-ear Microphones in Hearables
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Ohlenbusch%2C+M">Mattes Ohlenbusch</a>, 
<a href="/search/eess?searchtype=author&query=Rollwage%2C+C">Christian Rollwage</a>, 
<a href="/search/eess?searchtype=author&query=Doclo%2C+S">Simon Doclo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Presented at Forum Acusticum 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Many hearables contain an in-ear microphone, which may be used to capture the
own voice of its user in noisy environments. Since the in-ear microphone mostly
records body-conducted speech due to ear canal occlusion, it suffers from
band-limitation effects while only capturing a limited amount of external
noise. To enhance the quality of the in-ear microphone signal using algorithms
aiming at joint bandwidth extension, equalization, and noise reduction, it is
desirable to have an accurate model of the own voice transfer characteristics
between the entrance of the ear canal and the in-ear microphone. Such a model
can be used, e.g., to simulate a large amount of in-ear recordings to train
supervised learning-based algorithms. Since previous research on ear canal
occlusion suggests that own voice transfer characteristics depend on speech
content, in this contribution we propose a speech-dependent system
identification model based on phoneme recognition. We assess the accuracy of
simulating own voice speech by speech-dependent and speech-independent modeling
and investigate how well modeling approaches are able to generalize to
different talkers. Simulation results show that using the proposed
speech-dependent model is preferable for simulating in-ear recordings compared
to using a speech-independent model.
</p>
</div>
</dd>
<dt><a name="item331">[331]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08295" title="Abstract">arXiv:2309.08295</a> (cross-list from eess.AS) [<a href="/pdf/2309.08295" title="Download PDF">pdf</a>, <a href="/format/2309.08295" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Real-Time Active Speaker Detection System Integrating an Audio-Visual  Signal with a Spatial Querying Mechanism
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Gurvich%2C+I">Ilya Gurvich</a>, 
<a href="/search/eess?searchtype=author&query=Leichter%2C+I">Ido Leichter</a>, 
<a href="/search/eess?searchtype=author&query=Palle%2C+D+R">Dharmendar Reddy Palle</a>, 
<a href="/search/eess?searchtype=author&query=Asher%2C+Y">Yossi Asher</a>, 
<a href="/search/eess?searchtype=author&query=Vinnikov%2C+A">Alon Vinnikov</a>, 
<a href="/search/eess?searchtype=author&query=Abramovski%2C+I">Igor Abramovski</a>, 
<a href="/search/eess?searchtype=author&query=Gopal%2C+V">Vishak Gopal</a>, 
<a href="/search/eess?searchtype=author&query=Cutler%2C+R">Ross Cutler</a>, 
<a href="/search/eess?searchtype=author&query=Krupka%2C+E">Eyal Krupka</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">We introduce a distinctive real-time, causal, neural network-based active
speaker detection system optimized for low-power edge computing. This system
drives a virtual cinematography module and is deployed on a commercial device.
The system uses data originating from a microphone array and a 360-degree
camera. Our network requires only 127 MFLOPs per participant, for a meeting
with 14 participants. Unlike previous work, we examine the error rate of our
network when the computational budget is exhausted, and find that it exhibits
graceful degradation, allowing the system to operate reasonably well even in
this case. Departing from conventional DOA estimation approaches, our network
learns to query the available acoustic data, considering the detected head
locations. We train and evaluate our algorithm on a realistic meetings dataset
featuring up to 14 participants in the same meeting, overlapped speech, and
other challenging scenarios.
</p>
</div>
</dd>
<dt><a name="item332">[332]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08313" title="Abstract">arXiv:2309.08313</a> (cross-list from stat.ML) [<a href="/pdf/2309.08313" title="Download PDF">pdf</a>, <a href="/format/2309.08313" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Heteroskedastic conformal regression
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Dewolf%2C+N">Nicolas Dewolf</a>, 
<a href="/search/stat?searchtype=author&query=De+Baets%2C+B">Bernard De Baets</a>, 
<a href="/search/stat?searchtype=author&query=Waegeman%2C+W">Willem Waegeman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG)

</div>
<p class="mathjax">Conformal prediction, and split conformal prediction as a specific
implementation, offer a distribution-free approach to estimating prediction
intervals with statistical guarantees. Recent work has shown that split
conformal prediction can produce state-of-the-art prediction intervals when
focusing on marginal coverage, i.e., on a calibration dataset the method
produces on average prediction intervals that contain the ground truth with a
predefined coverage level. However, such intervals are often not adaptive,
which can be problematic for regression problems with heteroskedastic noise.
This paper tries to shed new light on how adaptive prediction intervals can be
constructed using methods such as normalized and Mondrian conformal prediction.
We present theoretical and experimental results in which these methods are
investigated in a systematic way.
</p>
</div>
</dd>
<dt><a name="item333">[333]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08320" title="Abstract">arXiv:2309.08320</a> (cross-list from eess.AS) [<a href="/pdf/2309.08320" title="Download PDF">pdf</a>, <a href="/format/2309.08320" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diff-SV: A Unified Hierarchical Framework for Noise-Robust Speaker  Verification Using Score-Based Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kim%2C+J">Ju-ho Kim</a>, 
<a href="/search/eess?searchtype=author&query=Heo%2C+J">Jungwoo Heo</a>, 
<a href="/search/eess?searchtype=author&query=Shin%2C+H">Hyun-seo Shin</a>, 
<a href="/search/eess?searchtype=author&query=Lim%2C+C">Chan-yeong Lim</a>, 
<a href="/search/eess?searchtype=author&query=Yu%2C+H">Ha-Jin Yu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures, submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Background noise considerably reduces the accuracy and reliability of speaker
verification (SV) systems. These challenges can be addressed using a speech
enhancement system as a front-end module. Recently, diffusion probabilistic
models (DPMs) have exhibited remarkable noise-compensation capabilities in the
speech enhancement domain. Building on this success, we propose Diff-SV, a
noise-robust SV framework that leverages DPM. Diff-SV unifies a DPM-based
speech enhancement system with a speaker embedding extractor, and yields a
discriminative and noise-tolerable speaker representation through a
hierarchical structure. The proposed model was evaluated under both in-domain
and out-of-domain noisy conditions using the VoxCeleb1 test set, an external
noise source, and the VOiCES corpus. The obtained experimental results
demonstrate that Diff-SV achieves state-of-the-art performance, outperforming
recently proposed noise-robust SV systems.
</p>
</div>
</dd>
<dt><a name="item334">[334]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08327" title="Abstract">arXiv:2309.08327</a> (cross-list from math.CO) [<a href="/pdf/2309.08327" title="Download PDF">pdf</a>, <a href="/ps/2309.08327" title="Download PostScript">ps</a>, <a href="/format/2309.08327" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Forbidden Tournaments and the Orientation Completion Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bodirsky%2C+M">Manuel Bodirsky</a>, 
<a href="/search/math?searchtype=author&query=Guzm%C3%A1n-Pro%2C+S">Santiago Guzm&#xe1;n-Pro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Complexity (cs.CC); Logic (math.LO)

</div>
<p class="mathjax">For a fixed finite set of finite tournaments ${\mathcal F}$, the ${\mathcal
F}$-free orientation problem asks whether a given finite undirected graph $G$
has an $\mathcal F$-free orientation, i.e., whether the edges of $G$ can be
oriented so that the resulting digraph does not embed any of the tournaments
from ${\mathcal F}$. We prove that for every ${\mathcal F}$, this problem is in
P or NP-complete. Our proof reduces the classification task to a complete
complexity classification of the orientation completion problem for ${\mathcal
F}$, which is the variant of the problem above where the input is a directed
graph instead of an undirected graph, introduced by Bang-Jensen, Huang, and Zhu
(2017). Our proof uses results from the theory of constraint satisfaction, and
a result of Agarwal and Kompatscher (2018) about infinite permutation groups
and transformation monoids.
</p>
</div>
</dd>
<dt><a name="item335">[335]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08340" title="Abstract">arXiv:2309.08340</a> (cross-list from math.CT) [<a href="/pdf/2309.08340" title="Download PDF">pdf</a>, <a href="/ps/2309.08340" title="Download PostScript">ps</a>, <a href="/format/2309.08340" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Formalizing the $\infty$-categorical Yoneda lemma
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kudasov%2C+N">Nikolai Kudasov</a>, 
<a href="/search/math?searchtype=author&query=Riehl%2C+E">Emily Riehl</a>, 
<a href="/search/math?searchtype=author&query=Weinberger%2C+J">Jonathan Weinberger</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages + references
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO); Algebraic Topology (math.AT); Logic (math.LO)

</div>
<p class="mathjax">The field of category theory seeks to unify and generalize concepts and
constructions across different areas of mathematics, from algebra to geometry
to topology and also to logic and theoretical computer science. Formalized
$1$-category theory forms a core component of various libraries of mathematical
proofs. However, more sophisticated results in fields from algebraic topology
to theoretical physics, where objects have "higher structure", rely on
infinite-dimensional categories in place of $1$-dimensional categories, and
$\infty$-category theory has thus far proved unamenable to computer
formalization.
<br />Using a new proof assistant called Rzk, which is designed to support
Riehl-Shulman's simplicial extension of homotopy type theory for synthetic
$\infty$-category theory, we provide the first formalizations of results from
$\infty$-category theory. This includes in particular a formalization of the
Yoneda lemma, often regarded as the fundamental theorem of category theory, a
theorem which roughly states that an object of a given category is determined
by its relationship to all of the other objects of the category. A key feature
of our framework is that, thanks to the synthetic theory, many constructions
are automatically natural or functorial. We plan to use Rzk to formalize
further results from $\infty$-category theory, such as the theory of limits and
colimits and adjunctions.
</p>
</div>
</dd>
<dt><a name="item336">[336]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08348" title="Abstract">arXiv:2309.08348</a> (cross-list from eess.AS) [<a href="/pdf/2309.08348" title="Download PDF">pdf</a>, <a href="/format/2309.08348" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Multimodal Information Based Speech Processing (MISP) 2023  Challenge: Audio-Visual Target Speaker Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+S">Shilong Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+C">Chenxi Wang</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+H">Hang Chen</a>, 
<a href="/search/eess?searchtype=author&query=Dai%2C+Y">Yusheng Dai</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+C">Chenyue Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+R">Ruoyu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Lan%2C+H">Hongbo Lan</a>, 
<a href="/search/eess?searchtype=author&query=Du%2C+J">Jun Du</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+C">Chin-Hui Lee</a>, 
<a href="/search/eess?searchtype=author&query=Chen%2C+J">Jingdong Chen</a>, 
<a href="/search/eess?searchtype=author&query=Watanabe%2C+S">Shinji Watanabe</a>, 
<a href="/search/eess?searchtype=author&query=Siniscalchi%2C+S+M">Sabato Marco Siniscalchi</a>, 
<a href="/search/eess?searchtype=author&query=Scharenborg%2C+O">Odette Scharenborg</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Z">Zhong-Qiu Wang</a>, 
<a href="/search/eess?searchtype=author&query=Pan%2C+J">Jia Pan</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+J">Jianqing Gao</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Previous Multimodal Information based Speech Processing (MISP) challenges
mainly focused on audio-visual speech recognition (AVSR) with commendable
success. However, the most advanced back-end recognition systems often hit
performance limits due to the complex acoustic environments. This has prompted
a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE)
task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand
Challenges. Unlike existing audio-visual speech enhance-ment challenges
primarily focused on simulation data, the MISP 2023 challenge uniquely explores
how front-end speech processing, combined with visual clues, impacts back-end
tasks in real-world scenarios. This pioneering effort aims to set the first
benchmark for the AVTSE task, offering fresh insights into enhancing the
ac-curacy of back-end speech recognition systems through AVTSE in challenging
and real acoustic environments. This paper delivers a thorough overview of the
task setting, dataset, and baseline system of the MISP 2023 challenge. It also
includes an in-depth analysis of the challenges participants may encounter. The
experimental results highlight the demanding nature of this task, and we look
forward to the innovative solutions participants will bring forward.
</p>
</div>
</dd>
<dt><a name="item337">[337]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08355" title="Abstract">arXiv:2309.08355</a> (cross-list from eess.AS) [<a href="/pdf/2309.08355" title="Download PDF">pdf</a>, <a href="/format/2309.08355" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semi-supervised Sound Event Detection with Local and Global Consistency  Regularization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hong Liu</a>, 
<a href="/search/eess?searchtype=author&query=Tao%2C+R">Rui Tao</a>, 
<a href="/search/eess?searchtype=author&query=Yan%2C+L">Long Yan</a>, 
<a href="/search/eess?searchtype=author&query=Ouchi%2C+K">Kazushige Ouchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Learning meaningful frame-wise features on a partially labeled dataset is
crucial to semi-supervised sound event detection. Prior works either maintain
consistency on frame-level predictions or seek feature-level similarity among
neighboring frames, which cannot exploit the potential of unlabeled data. In
this work, we design a Local and Global Consistency (LGC) regularization scheme
to enhance the model on both label- and feature-level. The audio CutMix is
introduced to change the contextual information of clips. Then, the local
consistency is adopted to encourage the model to leverage local features for
frame-level predictions, and the global consistency is applied to force
features to align with global prototypes through a specially designed
contrastive loss. Experiments on the DESED dataset indicate the superiority of
LGC, surpassing its respective competitors largely with the same settings as
the baseline system. Besides, combining LGC with existing methods can obtain
further improvements. The code will be released soon.
</p>
</div>
</dd>
<dt><a name="item338">[338]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08357" title="Abstract">arXiv:2309.08357</a> (cross-list from eess.AS) [<a href="/pdf/2309.08357" title="Download PDF">pdf</a>, <a href="/format/2309.08357" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Audio-free Prompt Tuning for Language-Audio Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Li%2C+Y">Yiming Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xiangdong Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+H">Hong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
<p class="mathjax">Contrastive Language-Audio Pretraining (CLAP) is pre-trained to associate
audio features with human language, making it a natural zero-shot classifier to
recognize unseen sound categories. To adapt CLAP to downstream tasks, prior
works inevitably require labeled domain audios, which limits their scalability
under data scarcity and deprives them of the capability to detect novel classes
as the original CLAP. In this work, by leveraging the modality alignment in
CLAP, we propose an efficient audio-free prompt tuning scheme aimed at
optimizing a few prompt tokens from texts instead of audios, which regularizes
the model space to avoid overfitting the seen classes as well. Based on this, a
multi-grained prompt design is further explored to fuse global and local
information. Experiments on several tasks demonstrate that our approach can
boost the CLAP and outperform other training methods on model performance and
training efficiency. While conducting zero-shot inference on unseen categories,
it still shows better transferability than the vanilla CLAP. Moreover, our
method is flexible enough even if only knowing the downstream class names. The
code will be released soon.
</p>
</div>
</dd>
<dt><a name="item339">[339]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08373" title="Abstract">arXiv:2309.08373</a> (cross-list from math.PR) [<a href="/pdf/2309.08373" title="Download PDF">pdf</a>, <a href="/ps/2309.08373" title="Download PostScript">ps</a>, <a href="/format/2309.08373" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Extreme values for the waiting time in large fork-join queues
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Schol%2C+D">Dennis Schol</a>, 
<a href="/search/math?searchtype=author&query=Vlasiou%2C+M">Maria Vlasiou</a>, 
<a href="/search/math?searchtype=author&query=Zwart%2C+B">Bert Zwart</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Probability (math.PR)</span>; Performance (cs.PF)

</div>
<p class="mathjax">We prove that the scaled maximum steady-state waiting time and the scaled
maximum steady-state queue length among $N$ $GI/GI/1$-queues in the $N$-server
fork-join queue, converge to a normally distributed random variable as
$N\to\infty$. The maximum steady-state waiting time in this queueing system
scales around $\frac{1}{\gamma}\log N$, where $\gamma$ is determined by the
cumulant generating function $\Lambda$ of the service distribution and solves
the Cram\'er-Lundberg equation with stochastic service times and deterministic
inter-arrival times. This value $\frac{1}{\gamma}\log N$ is reached at a
certain hitting time. The number of arrivals until that hitting time satisfies
the central limit theorem, with standard deviation
$\frac{\sigma_A}{\sqrt{\Lambda'(\gamma)\gamma}}$. By using distributional
Little's law, we can extend this result to the maximum queue length. Finally,
we extend these results to a fork-join queue with different classes of servers.
</p>
</div>
</dd>
<dt><a name="item340">[340]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08376" title="Abstract">arXiv:2309.08376</a> (cross-list from math.AP) [<a href="/pdf/2309.08376" title="Download PDF">pdf</a>, <a href="/format/2309.08376" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The monotonicity method for inclusion detection and the time harmonic  elastic wave equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Eberle-Blick%2C+S">Sarah Eberle-Blick</a>, 
<a href="/search/math?searchtype=author&query=Pohjola%2C+V">Valter Pohjola</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Analysis of PDEs (math.AP)</span>; Numerical Analysis (math.NA)

</div>
<p class="mathjax">We consider the problem of reconstructing inhomogeneities in an isotropic
elastic body using time harmonic waves. Here we extend the so called
monotonicity method for inclusion detection and show how to determine certain
types of inhomogeneities in the Lam\'e parameters and the density. We also
included some numerical tests of the method.
</p>
</div>
</dd>
<dt><a name="item341">[341]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08377" title="Abstract">arXiv:2309.08377</a> (cross-list from eess.AS) [<a href="/pdf/2309.08377" title="Download PDF">pdf</a>, <a href="/format/2309.08377" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DiaCorrect: Error Correction Back-end For Speaker Diarization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Han%2C+J">Jiangyu Han</a>, 
<a href="/search/eess?searchtype=author&query=Landini%2C+F">Federico Landini</a>, 
<a href="/search/eess?searchtype=author&query=Rohdin%2C+J">Johan Rohdin</a>, 
<a href="/search/eess?searchtype=author&query=Diez%2C+M">Mireia Diez</a>, 
<a href="/search/eess?searchtype=author&query=Burget%2C+L">Lukas Burget</a>, 
<a href="/search/eess?searchtype=author&query=Cao%2C+Y">Yuhang Cao</a>, 
<a href="/search/eess?searchtype=author&query=Lu%2C+H">Heng Lu</a>, 
<a href="/search/eess?searchtype=author&query=Cernocky%2C+J">Jan Cernocky</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Sound (cs.SD)

</div>
<p class="mathjax">In this work, we propose an error correction framework, named DiaCorrect, to
refine the output of a diarization system in a simple yet effective way. This
method is inspired by error correction techniques in automatic speech
recognition. Our model consists of two parallel convolutional encoders and a
transform-based decoder. By exploiting the interactions between the input
recording and the initial system's outputs, DiaCorrect can automatically
correct the initial speaker activities to minimize the diarization errors.
Experiments on 2-speaker telephony data show that the proposed DiaCorrect can
effectively improve the initial model's results. Our source code is publicly
available at https://github.com/BUTSpeechFIT/diacorrect.
</p>
</div>
</dd>
<dt><a name="item342">[342]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08381" title="Abstract">arXiv:2309.08381</a> (cross-list from eess.IV) [<a href="/pdf/2309.08381" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Reconsidering evaluation practices in modular systems: On the  propagation of errors in MRI prostate cancer detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Rolfsnes%2C+E+S">Erlend Sortland Rolfsnes</a>, 
<a href="/search/eess?searchtype=author&query=Thangngat%2C+P">Philip Thangngat</a>, 
<a href="/search/eess?searchtype=author&query=Eftest%C3%B8l%2C+T">Trygve Eftest&#xf8;l</a>, 
<a href="/search/eess?searchtype=author&query=Nordstr%C3%B6m%2C+T">Tobias Nordstr&#xf6;m</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4derling%2C+F">Fredrik J&#xe4;derling</a>, 
<a href="/search/eess?searchtype=author&query=Eklund%2C+M">Martin Eklund</a>, 
<a href="/search/eess?searchtype=author&query=Fernandez-Quilez%2C+A">Alvaro Fernandez-Quilez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Medical Physics (physics.med-ph)

</div>
<p class="mathjax">Magnetic resonance imaging has evolved as a key component for prostate cancer
(PCa) detection, substantially increasing the radiologist workload. Artificial
intelligence (AI) systems can support radiological assessment by segmenting and
classifying lesions in clinically significant (csPCa) and non-clinically
significant (ncsPCa). Commonly, AI systems for PCa detection involve an
automatic prostate segmentation followed by the lesion detection using the
extracted prostate. However, evaluation reports are typically presented in
terms of detection under the assumption of the availability of a highly
accurate segmentation and an idealistic scenario, omitting the propagation of
errors between modules. For that purpose, we evaluate the effect of two
different segmentation networks (s1 and s2) with heterogeneous performances in
the detection stage and compare it with an idealistic setting (s1:89.90+-2.23
vs 88.97+-3.06 ncsPCa, P&lt;.001, 89.30+-4.07 and 88.12+-2.71 csPCa, P&lt;.001). Our
results depict the relevance of a holistic evaluation, accounting for all the
sub-modules involved in the system.
</p>
</div>
</dd>
<dt><a name="item343">[343]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08402" title="Abstract">arXiv:2309.08402</a> (cross-list from eess.IV) [<a href="/pdf/2309.08402" title="Download PDF">pdf</a>, <a href="/format/2309.08402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D SA-UNet: 3D Spatial Attention UNet with 3D ASPP for White Matter  Hyperintensities Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Guo%2C+C">Changlu Guo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Changlu Guo is applying for a doctoral position, and if there are any relevant collaboration opportunities, please feel free to contact me at clguo.ai@gmail.com
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">White Matter Hyperintensity (WMH) is an imaging feature related to various
diseases such as dementia and stroke. Accurately segmenting WMH using computer
technology is crucial for early disease diagnosis. However, this task remains
challenging due to the small lesions with low contrast and high discontinuity
in the images, which contain limited contextual and spatial information. To
address this challenge, we propose a deep learning model called 3D Spatial
Attention U-Net (3D SA-UNet) for automatic WMH segmentation using only Fluid
Attenuation Inversion Recovery (FLAIR) scans. The 3D SA-UNet introduces a 3D
Spatial Attention Module that highlights important lesion features, such as
WMH, while suppressing unimportant regions. Additionally, to capture features
at different scales, we extend the Atrous Spatial Pyramid Pooling (ASPP) module
to a 3D version, enhancing the segmentation performance of the network. We
evaluate our method on publicly available dataset and demonstrate the
effectiveness of 3D spatial attention module and 3D ASPP in WMH segmentation.
Through experimental results, it has been demonstrated that our proposed 3D
SA-UNet model achieves higher accuracy compared to other state-of-the-art 3D
convolutional neural networks.
</p>
</div>
</dd>
<dt><a name="item344">[344]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08411" title="Abstract">arXiv:2309.08411</a> (cross-list from eess.SP) [<a href="/pdf/2309.08411" title="Download PDF">pdf</a>, <a href="/ps/2309.08411" title="Download PostScript">ps</a>, <a href="/format/2309.08411" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Channel Estimation in Underdetermined Systems Utilizing Variational  Autoencoders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Baur%2C+M">Michael Baur</a>, 
<a href="/search/eess?searchtype=author&query=Turan%2C+N">Nurettin Turan</a>, 
<a href="/search/eess?searchtype=author&query=Fesl%2C+B">Benedikt Fesl</a>, 
<a href="/search/eess?searchtype=author&query=Utschick%2C+W">Wolfgang Utschick</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this work, we propose to utilize a variational autoencoder (VAE) for
channel estimation (CE) in underdetermined (UD) systems. The basis of the
method forms a recently proposed concept in which a VAE is trained on channel
state information (CSI) data and used to parameterize an approximation to the
mean squared error (MSE)-optimal estimator. The contributions in this work
extend the existing framework from fully-determined (FD) to UD systems, which
are of high practical relevance. Particularly noteworthy is the extension of
the estimator variant, which does not require perfect CSI during its offline
training phase. This is a significant advantage compared to most other deep
learning (DL)-based CE methods, where perfect CSI during the training phase is
a crucial prerequisite. Numerical simulations for hybrid and wideband systems
demonstrate the excellent performance of the proposed methods compared to
related estimators.
</p>
</div>
</dd>
<dt><a name="item345">[345]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08421" title="Abstract">arXiv:2309.08421</a> (cross-list from eess.IV) [<a href="/pdf/2309.08421" title="Download PDF">pdf</a>, <a href="/format/2309.08421" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MIML: Multiplex Image Machine Learning for High Precision Cell  Classification via Mechanical Traits within Microfluidic Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Islam%2C+K">Khayrul Islam</a>, 
<a href="/search/eess?searchtype=author&query=Paul%2C+R">Ratul Paul</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Shen Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+Y">Yaling Liu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">Label-free cell classification is advantageous for supplying pristine cells
for further use or examination, yet existing techniques frequently fall short
in terms of specificity and speed. In this study, we address these limitations
through the development of a novel machine learning framework, Multiplex Image
Machine Learning (MIML). This architecture uniquely combines label-free cell
images with biomechanical property data, harnessing the vast, often
underutilized morphological information intrinsic to each cell. By integrating
both types of data, our model offers a more holistic understanding of the
cellular properties, utilizing morphological information typically discarded in
traditional machine learning models. This approach has led to a remarkable
98.3\% accuracy in cell classification, a substantial improvement over models
that only consider a single data type. MIML has been proven effective in
classifying white blood cells and tumor cells, with potential for broader
application due to its inherent flexibility and transfer learning capability.
It's particularly effective for cells with similar morphology but distinct
biomechanical properties. This innovative approach has significant implications
across various fields, from advancing disease diagnostics to understanding
cellular behavior.
</p>
</div>
</dd>
<dt><a name="item346">[346]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08434" title="Abstract">arXiv:2309.08434</a> (cross-list from eess.IV) [<a href="/pdf/2309.08434" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Segment Anything Model for Brain Tumor Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Peng Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y">Yaping Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 60 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
<p class="mathjax">Glioma is a prevalent brain tumor that poses a significant health risk to
individuals. Accurate segmentation of brain tumor is essential for clinical
diagnosis and treatment. The Segment Anything Model(SAM), released by Meta AI,
is a fundamental model in image segmentation and has excellent zero-sample
generalization capabilities. Thus, it is interesting to apply SAM to the task
of brain tumor segmentation. In this study, we evaluated the performance of SAM
on brain tumor segmentation and found that without any model fine-tuning, there
is still a gap between SAM and the current state-of-the-art(SOTA) model.
</p>
</div>
</dd>
<dt><a name="item347">[347]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08436" title="Abstract">arXiv:2309.08436</a> (cross-list from eess.AS) [<a href="/pdf/2309.08436" title="Download PDF">pdf</a>, <a href="/format/2309.08436" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chunked Attention-based Encoder-Decoder Model for Streaming Speech  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zeineldeen%2C+M">Mohammad Zeineldeen</a>, 
<a href="/search/eess?searchtype=author&query=Zeyer%2C+A">Albert Zeyer</a>, 
<a href="/search/eess?searchtype=author&query=Schl%C3%BCter%2C+R">Ralf Schl&#xfc;ter</a>, 
<a href="/search/eess?searchtype=author&query=Ney%2C+H">Hermann Ney</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Machine Learning (stat.ML)

</div>
<p class="mathjax">We study a streamable attention-based encoder-decoder model in which either
the decoder, or both the encoder and decoder, operate on pre-defined,
fixed-size windows called chunks. A special end-of-chunk (EOC) symbol advances
from one chunk to the next chunk, effectively replacing the conventional
end-of-sequence symbol. This modification, while minor, situates our model as
equivalent to a transducer model that operates on chunks instead of frames,
where EOC corresponds to the blank symbol. We further explore the remaining
differences between a standard transducer and our model. Additionally, we
examine relevant aspects such as long-form speech generalization, beam size,
and length normalization. Through experiments on Librispeech and TED-LIUM-v2,
and by concatenating consecutive sequences for long-form trials, we find that
our streamable model maintains competitive performance compared to the
non-streamable variant and generalizes very well to long-form speech.
</p>
</div>
</dd>
<dt><a name="item348">[348]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08454" title="Abstract">arXiv:2309.08454</a> (cross-list from eess.AS) [<a href="/pdf/2309.08454" title="Download PDF">pdf</a>, <a href="/format/2309.08454" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mixture Encoder Supporting Continuous Speech Separation for Meeting  Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vieting%2C+P">Peter Vieting</a>, 
<a href="/search/eess?searchtype=author&query=Berger%2C+S">Simon Berger</a>, 
<a href="/search/eess?searchtype=author&query=von+Neumann%2C+T">Thilo von Neumann</a>, 
<a href="/search/eess?searchtype=author&query=Boeddeker%2C+C">Christoph Boeddeker</a>, 
<a href="/search/eess?searchtype=author&query=Schl%C3%BCter%2C+R">Ralf Schl&#xfc;ter</a>, 
<a href="/search/eess?searchtype=author&query=Haeb-Umbach%2C+R">Reinhold Haeb-Umbach</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Many real-life applications of automatic speech recognition (ASR) require
processing of overlapped speech. A commonmethod involves first separating the
speech into overlap-free streams and then performing ASR on the resulting
signals. Recently, the inclusion of a mixture encoder in the ASR model has been
proposed. This mixture encoder leverages the original overlapped speech to
mitigate the effect of artifacts introduced by the speech separation.
Previously, however, the method only addressed two-speaker scenarios. In this
work, we extend this approach to more natural meeting contexts featuring an
arbitrary number of speakers and dynamic overlaps. We evaluate the performance
using different speech separators, including the powerful TF-GridNet model. Our
experiments show state-of-the-art performance on the LibriCSS dataset and
highlight the advantages of the mixture encoder. Furthermore, they demonstrate
the strong separation of TF-GridNet which largely closes the gap between
previous methods and oracle separation.
</p>
</div>
</dd>
<dt><a name="item349">[349]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08473" title="Abstract">arXiv:2309.08473</a> (cross-list from stat.ML) [<a href="/pdf/2309.08473" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the limitations of data-driven weather forecasting models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bonavita%2C+M">Massimo Bonavita</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
<p class="mathjax">As in many other areas of engineering and applied science, Machine Learning
(ML) is having a profound impact in the domain of Weather and Climate
Prediction. A very recent development in this area has been the emergence of
fully data-driven ML prediction models which routinely claim superior
performance to that of traditional physics-based models. In this work, we
examine some aspects of the forecasts produced by an exemplar of the current
generation of ML models, Pangu-Weather, with a focus on the fidelity and
physical consistency of those forecasts and how these characteristics relate to
perceived forecast performance. The main conclusion is that Pangu-Weather
forecasts, and by extension those of similar ML models, do not have the
fidelity and physical consistency of physics-based models and their advantage
in accuracy on traditional deterministic metrics of forecast skill can be
attributed, to a large extent, to these peculiarities. Similarly to other
current post-processing technologies, ML models appear to be able to add value
to standard NWP outputs for specific forecast applications and combined with
their extremely low computational cost during deployment, will likely provide
an additional, useful source of forecast information.
</p>
</div>
</dd>
<dt><a name="item350">[350]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08477" title="Abstract">arXiv:2309.08477</a> (cross-list from stat.ML) [<a href="/pdf/2309.08477" title="Download PDF">pdf</a>, <a href="/format/2309.08477" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep Multi-Agent Reinforcement Learning for Decentralized Active  Hypothesis Testing
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Szostak%2C+H">Hadar Szostak</a>, 
<a href="/search/stat?searchtype=author&query=Cohen%2C+K">Kobi Cohen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this paper was presented at the annual Allerton Conference on Communication, Control, and Computing (Allerton) 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Multiagent Systems (cs.MA); Signal Processing (eess.SP)

</div>
<p class="mathjax">We consider a decentralized formulation of the active hypothesis testing
(AHT) problem, where multiple agents gather noisy observations from the
environment with the purpose of identifying the correct hypothesis. At each
time step, agents have the option to select a sampling action. These different
actions result in observations drawn from various distributions, each
associated with a specific hypothesis. The agents collaborate to accomplish the
task, where message exchanges between agents are allowed over a rate-limited
communications channel. The objective is to devise a multi-agent policy that
minimizes the Bayes risk. This risk comprises both the cost of sampling and the
joint terminal cost incurred by the agents upon making a hypothesis
declaration. Deriving optimal structured policies for AHT problems is generally
mathematically intractable, even in the context of a single agent. As a result,
recent efforts have turned to deep learning methodologies to address these
problems, which have exhibited significant success in single-agent learning
scenarios. In this paper, we tackle the multi-agent AHT formulation by
introducing a novel algorithm rooted in the framework of deep multi-agent
reinforcement learning. This algorithm, named Multi-Agent Reinforcement
Learning for AHT (MARLA), operates at each time step by having each agent map
its state to an action (sampling rule or stopping rule) using a trained deep
neural network with the goal of minimizing the Bayes risk. We present a
comprehensive set of experimental results that effectively showcase the agents'
ability to learn collaborative strategies and enhance performance using MARLA.
Furthermore, we demonstrate the superiority of MARLA over single-agent learning
approaches. Finally, we provide an open-source implementation of the MARLA
framework, for the benefit of researchers and developers in related domains.
</p>
</div>
</dd>
<dt><a name="item351">[351]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08489" title="Abstract">arXiv:2309.08489</a> (cross-list from eess.AS) [<a href="/pdf/2309.08489" title="Download PDF">pdf</a>, <a href="/format/2309.08489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Word-Level End-to-End Neural Speaker Diarization with Auxiliary  Network
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Huang%2C+Y">Yiling Huang</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/eess?searchtype=author&query=Zhao%2C+G">Guanlong Zhao</a>, 
<a href="/search/eess?searchtype=author&query=Liao%2C+H">Hank Liao</a>, 
<a href="/search/eess?searchtype=author&query=Xia%2C+W">Wei Xia</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Quan Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD); Machine Learning (stat.ML)

</div>
<p class="mathjax">While standard speaker diarization attempts to answer the question "who
spoken when", most of relevant applications in reality are more interested in
determining "who spoken what". Whether it is the conventional modularized
approach or the more recent end-to-end neural diarization (EEND), an additional
automatic speech recognition (ASR) model and an orchestration algorithm are
required to associate the speaker labels with recognized words. In this paper,
we propose Word-level End-to-End Neural Diarization (WEEND) with auxiliary
network, a multi-task learning algorithm that performs end-to-end ASR and
speaker diarization in the same neural architecture. That is, while speech is
being recognized, speaker labels are predicted simultaneously for each
recognized word. Experimental results demonstrate that WEEND outperforms the
turn-based diarization baseline system on all 2-speaker short-form scenarios
and has the capability to generalize to audio lengths of 5 minutes. Although
3+speaker conversations are harder, we find that with enough in-domain training
data, WEEND has the potential to deliver high quality diarized text.
</p>
</div>
</dd>
<dt><a name="item352">[352]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08500" title="Abstract">arXiv:2309.08500</a> (cross-list from physics.bio-ph) [<a href="/pdf/2309.08500" title="Download PDF">pdf</a>, <a href="/format/2309.08500" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep-learning-powered data analysis in plankton ecology
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Bachimanchi%2C+H">Harshith Bachimanchi</a>, 
<a href="/search/physics?searchtype=author&query=Pinder%2C+M+I+M">Matthew I.M. Pinder</a>, 
<a href="/search/physics?searchtype=author&query=Robert%2C+C">Chlo&#xe9; Robert</a>, 
<a href="/search/physics?searchtype=author&query=De+Wit%2C+P">Pierre De Wit</a>, 
<a href="/search/physics?searchtype=author&query=Havenhand%2C+J">Jonathan Havenhand</a>, 
<a href="/search/physics?searchtype=author&query=Kinnby%2C+A">Alexandra Kinnby</a>, 
<a href="/search/physics?searchtype=author&query=Midtvedt%2C+D">Daniel Midtvedt</a>, 
<a href="/search/physics?searchtype=author&query=Selander%2C+E">Erik Selander</a>, 
<a href="/search/physics?searchtype=author&query=Volpe%2C+G">Giovanni Volpe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> For the associated GitHub repository, see <a href="https://github.com/softmatterlab/Deep-learning-in-plankton-ecology">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biological Physics (physics.bio-ph)</span>; Soft Condensed Matter (cond-mat.soft); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)

</div>
<p class="mathjax">The implementation of deep learning algorithms has brought new perspectives
to plankton ecology. Emerging as an alternative approach to established
methods, deep learning offers objective schemes to investigate plankton
organisms in diverse environments. We provide an overview of
deep-learning-based methods including detection and classification of phyto-
and zooplankton images, foraging and swimming behaviour analysis, and finally
ecological modelling. Deep learning has the potential to speed up the analysis
and reduce the human experimental bias, thus enabling data acquisition at
relevant temporal and spatial scales with improved reproducibility. We also
discuss shortcomings and show how deep learning architectures have evolved to
mitigate imprecise readouts. Finally, we suggest opportunities where deep
learning is particularly likely to catalyze plankton research. The examples are
accompanied by detailed tutorials and code samples that allow readers to apply
the methods described in this review to their own data.
</p>
</div>
</dd>
<dt><a name="item353">[353]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08511" title="Abstract">arXiv:2309.08511</a> (cross-list from eess.IV) [<a href="/pdf/2309.08511" title="Download PDF">pdf</a>, <a href="/format/2309.08511" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Generalised Probabilistic Diffusion Scale-Spaces
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Peter%2C+P">Pascal Peter</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
<p class="mathjax">Probabilistic diffusion models excel at sampling new images from learned
distributions. Originally motivated by drift-diffusion concepts from physics,
they apply image perturbations such as noise and blur in a forward process that
results in a tractable probability distribution. A corresponding learned
reverse process generates images and can be conditioned on side information,
which leads to a wide variety of practical applications. Most of the research
focus currently lies on practice-oriented extensions. In contrast, the
theoretical background remains largely unexplored, in particular the relations
to drift-diffusion. In order to shed light on these connections to classical
image filtering, we propose a generalised scale-space theory for probabilistic
diffusion models. Moreover, we show conceptual and empirical connections to
diffusion and osmosis filters.
</p>
</div>
</dd>
<dt><a name="item354">[354]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08526" title="Abstract">arXiv:2309.08526</a> (cross-list from eess.SP) [<a href="/pdf/2309.08526" title="Download PDF">pdf</a>, <a href="/ps/2309.08526" title="Download PostScript">ps</a>, <a href="/format/2309.08526" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust IRS-Element Activation for Energy Efficiency Optimization in  IRS-Assisted Communication Systems With Imperfect CSI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Efrem%2C+C+N">Christos N. Efrem</a>, 
<a href="/search/eess?searchtype=author&query=Krikidis%2C+I">Ioannis Krikidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 5 figures. arXiv admin note: substantial text overlap with <a href="/abs/2210.16662">arXiv:2210.16662</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Information Theory (cs.IT)

</div>
<p class="mathjax">In this paper, we study an intelligent reflecting surface (IRS)-aided
communication system with single-antenna transmitter and receiver, under
imperfect channel state information (CSI). More specifically, we deal with the
robust selection of binary (on/off) states of the IRS elements in order to
maximize the worst-case energy efficiency (EE), given a bounded CSI
uncertainty, while satisfying a minimum signal-to-noise ratio (SNR). In
addition, we consider not only continuous but also discrete IRS phase shifts.
First, we derive closed-form expressions of the worst-case SNRs, and then
formulate the robust (discrete) optimization problems for each case. In the
case of continuous phase shifts, we design a dynamic programming (DP) algorithm
that is theoretically guaranteed to achieve the global maximum with polynomial
complexity $O(L\,{\log L})$, where $L$ is the number of IRS elements. In the
case of discrete phase shifts, we develop a convex-relaxation-based method
(CRBM) to obtain a feasible (sub-optimal) solution in polynomial time
$O(L^{3.5})$, with a posteriori performance guarantee. Furthermore, numerical
simulations provide useful insights and confirm the theoretical results. In
particular, the proposed algorithms are several orders of magnitude faster than
the exhaustive search when $L$ is large, thus being highly scalable and
suitable for practical applications. Moreover, both algorithms outperform a
baseline scheme, namely, the activation of all IRS elements.
</p>
</div>
</dd>
<dt><a name="item355">[355]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08558" title="Abstract">arXiv:2309.08558</a> (cross-list from stat.ME) [<a href="/pdf/2309.08558" title="Download PDF">pdf</a>, <a href="/format/2309.08558" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A modern approach to transition analysis and process mining with Markov  models: A tutorial with R
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Helske%2C+J">Jouni Helske</a>, 
<a href="/search/stat?searchtype=author&query=Helske%2C+S">Satu Helske</a>, 
<a href="/search/stat?searchtype=author&query=Saqr%2C+M">Mohammed Saqr</a>, 
<a href="/search/stat?searchtype=author&query=L%C3%B3pez-Pernas%2C+S">Sonsoles L&#xf3;pez-Pernas</a>, 
<a href="/search/stat?searchtype=author&query=Murphy%2C+K">Keefe Murphy</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Computers and Society (cs.CY)

</div>
<p class="mathjax">This chapter presents an introduction to Markovian modeling for the analysis
of sequence data. Contrary to the deterministic approach seen in the previous
sequence analysis chapters, Markovian models are probabilistic models, focusing
on the transitions between states instead of studying sequences as a whole. The
chapter provides an introduction to this method and differentiates between its
most common variations: first-order Markov models, hidden Markov models,
mixture Markov models, and mixture hidden Markov models. In addition to a
thorough explanation and contextualization within the existing literature, the
chapter provides a step-by-step tutorial on how to implement each type of
Markovian model using the R package seqHMM. The chaper also provides a complete
guide to performing stochastic process mining with Markovian models as well as
plotting, comparing and clustering different process models.
</p>
</div>
</dd>
<dt><a name="item356">[356]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08561" title="Abstract">arXiv:2309.08561</a> (cross-list from eess.AS) [<a href="/pdf/2309.08561" title="Download PDF">pdf</a>, <a href="/format/2309.08561" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Open-vocabulary Keyword-spotting with Adaptive Instance Normalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Navon%2C+A">Aviv Navon</a>, 
<a href="/search/eess?searchtype=author&query=Shamsian%2C+A">Aviv Shamsian</a>, 
<a href="/search/eess?searchtype=author&query=Glazer%2C+N">Neta Glazer</a>, 
<a href="/search/eess?searchtype=author&query=Hetz%2C+G">Gill Hetz</a>, 
<a href="/search/eess?searchtype=author&query=Keshet%2C+J">Joseph Keshet</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under Review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Machine Learning (cs.LG); Sound (cs.SD)

</div>
<p class="mathjax">Open vocabulary keyword spotting is a crucial and challenging task in
automatic speech recognition (ASR) that focuses on detecting user-defined
keywords within a spoken utterance. Keyword spotting methods commonly map the
audio utterance and keyword into a joint embedding space to obtain some
affinity score. In this work, we propose AdaKWS, a novel method for keyword
spotting in which a text encoder is trained to output keyword-conditioned
normalization parameters. These parameters are used to process the auditory
input. We provide an extensive evaluation using challenging and diverse
multi-lingual benchmarks and show significant improvements over recent keyword
spotting and ASR baselines. Furthermore, we study the effectiveness of our
approach on low-resource languages that were unseen during the training. The
results demonstrate a substantial performance improvement compared to baseline
methods.
</p>
</div>
</dd>
<dt><a name="item357">[357]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.08570" title="Abstract">arXiv:2309.08570</a> (cross-list from stat.ML) [<a href="/pdf/2309.08570" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Driven, Interactive Design for Nonlinear Optical  Molecules Based on Group Contribution Method
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Fan%2C+J">Jinming Fan</a> (1 and 2), 
<a href="/search/stat?searchtype=author&query=Qian%2C+C">Chao Qian</a> (1 and 2), 
<a href="/search/stat?searchtype=author&query=Zhou%2C+S">Shaodong Zhou</a> (1 and 2) ((1) College of Chemical and Biological Engineering, Zhejiang Provincial Key Laboratory of Advanced Chemical Engineering Manufacture Technology, Zhejiang University, Hangzhou, P. R. China, (2) Zhejiang Provincial Innovation Center of Advanced Chemicals Technology, Institute of Zhejiang University - Quzhou,P.R. China)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optics (physics.optics)

</div>
<p class="mathjax">A Lewis-mode group contribution method (LGC) -- multi-stage Bayesian neural
network (msBNN) -- evolutionary algorithm (EA) framework is reported for
rational design of D-Pi-A type organic small-molecule nonlinear optical
materials is presented. Upon combination of msBNN and corrected Lewis-mode
group contribution method (cLGC), different optical properties of molecules are
afforded accurately and efficiently - by using only a small data set for
training. Moreover, by employing the EA model designed specifically for LGC,
structural search is well achievable. The logical origins of the well
performance of the framework are discussed in detail. Considering that such a
theory guided, machine learning framework combines chemical principles and
data-driven tools, most likely, it will be proven efficient to solve molecular
design related problems in wider fields.
</p>
</div>
</dd>
</dl>
<h3>Replacements for Mon, 18 Sep 23</h3>
<dl>
<dt><a name="item358">[358]</a>&nbsp;  <span class="list-identifier"><a href="/abs/1610.06631" title="Abstract">arXiv:1610.06631</a> (replaced) [<a href="/pdf/1610.06631" title="Download PDF">pdf</a>, <a href="/format/1610.06631" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Inverse Power Flow Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yuan%2C+Y">Ye Yuan</a>, 
<a href="/search/eess?searchtype=author&query=Low%2C+S">Steven Low</a>, 
<a href="/search/eess?searchtype=author&query=Ardakanian%2C+O">Omid Ardakanian</a>, 
<a href="/search/eess?searchtype=author&query=Tomlin%2C+C">Claire Tomlin</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item359">[359]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2005.00610" title="Abstract">arXiv:2005.00610</a> (replaced) [<a href="/pdf/2005.00610" title="Download PDF">pdf</a>, <a href="/ps/2005.00610" title="Download PostScript">ps</a>, <a href="/format/2005.00610" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constraint-Based Causal Discovery using Partial Ancestral Graphs in the  presence of Cycles
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Mooij%2C+J+M">Joris M. Mooij</a>, 
<a href="/search/math?searchtype=author&query=Claassen%2C+T">Tom Claassen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This version corrects some typos in the published version (Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI), PMLR volume 124, 2020); it also provides proofs inline instead of in a supplement for improved readability
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Proceedings of Machine Learning Research 124 (2020) 1159-1168
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Statistics Theory (math.ST)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item360">[360]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2007.07806" title="Abstract">arXiv:2007.07806</a> (replaced) [<a href="/pdf/2007.07806" title="Download PDF">pdf</a>, <a href="/format/2007.07806" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Plattenbauten: Touching Rectangles in Space
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Felsner%2C+S">Stefan Felsner</a>, 
<a href="/search/math?searchtype=author&query=Knauer%2C+K">Kolja Knauer</a>, 
<a href="/search/math?searchtype=author&query=Ueckerdt%2C+T">Torsten Ueckerdt</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Keywords: Touching graphs, contact graphs, boxicity, planar graphs
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Computational Geometry (cs.CG); Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item361">[361]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2009.07140" title="Abstract">arXiv:2009.07140</a> (replaced) [<a href="/pdf/2009.07140" title="Download PDF">pdf</a>, <a href="/format/2009.07140" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HGCN-GJS: Hierarchical Graph Convolutional Network with Groupwise Joint  Sampling for Trajectory Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yuying Chen</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Congcong Liu</a>, 
<a href="/search/cs?searchtype=author&query=Mei%2C+X">Xiaodong Mei</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B+E">Bertram E. Shi</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+M">Ming Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages, 8 figures, accepted by IROS 2022
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item362">[362]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2104.00640" title="Abstract">arXiv:2104.00640</a> (replaced) [<a href="/pdf/2104.00640" title="Download PDF">pdf</a>, <a href="/format/2104.00640" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AmbiFC: Fact-Checking Ambiguous Claims with Evidence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glockner%2C+M">Max Glockner</a>, 
<a href="/search/cs?searchtype=author&query=Stali%C5%ABnait%C4%97%2C+I">Ieva Stali&#x16b;nait&#x117;</a>, 
<a href="/search/cs?searchtype=author&query=Thorne%2C+J">James Thorne</a>, 
<a href="/search/cs?searchtype=author&query=Vallejo%2C+G">Gisela Vallejo</a>, 
<a href="/search/cs?searchtype=author&query=Vlachos%2C+A">Andreas Vlachos</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at TACL; pre-MIT Press publication version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item363">[363]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.08800" title="Abstract">arXiv:2106.08800</a> (replaced) [<a href="/pdf/2106.08800" title="Download PDF">pdf</a>, <a href="/format/2106.08800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Design and Analysis of High Performance Heterogeneous Block-based  Approximate Adders
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Farahmand%2C+E">Ebrahim Farahmand</a>, 
<a href="/search/cs?searchtype=author&query=Mahani%2C+A">Ali Mahani</a>, 
<a href="/search/cs?searchtype=author&query=Hanif%2C+M+A">Muhammad Abdullah Hanif</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for publication in ACM Transactions on Embedded Computing Systems (TECS)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Distributed, Parallel, and Cluster Computing (cs.DC)</span>; Hardware Architecture (cs.AR)

</div>
</div>
</dd>
<dt><a name="item364">[364]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2106.10310" title="Abstract">arXiv:2106.10310</a> (replaced) [<a href="/pdf/2106.10310" title="Download PDF">pdf</a>, <a href="/format/2106.10310" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Verifying Safe Transitions between Dynamic Motion Primitives on Legged  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ubellacker%2C+W">Wyatt Ubellacker</a>, 
<a href="/search/cs?searchtype=author&query=Csomay-Shanklin%2C+N">Noel Csomay-Shanklin</a>, 
<a href="/search/cs?searchtype=author&query=Molnar%2C+T+G">Tamas G. Molnar</a>, 
<a href="/search/cs?searchtype=author&query=Ames%2C+A+D">Aaron D. Ames</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item365">[365]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2107.02053" title="Abstract">arXiv:2107.02053</a> (replaced) [<a href="/pdf/2107.02053" title="Download PDF">pdf</a>, <a href="/format/2107.02053" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MixStyle Neural Networks for Domain Generalization and Adaptation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+K">Kaiyang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yongxin Yang</a>, 
<a href="/search/cs?searchtype=author&query=Qiao%2C+Y">Yu Qiao</a>, 
<a href="/search/cs?searchtype=author&query=Xiang%2C+T">Tao Xiang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extension of <a href="https://openreview.net/forum?id=6xHJ37MVxxp.">this https URL</a> Code available at <a href="https://github.com/KaiyangZhou/mixstyle-release.">this https URL</a> To appear in IJCV
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item366">[366]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2110.04987" title="Abstract">arXiv:2110.04987</a> (replaced) [<a href="/pdf/2110.04987" title="Download PDF">pdf</a>, <a href="/ps/2110.04987" title="Download PostScript">ps</a>, <a href="/format/2110.04987" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Binary Programming Formulations for the Upper Domination Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Burdett%2C+R">Ryan Burdett</a>, 
<a href="/search/math?searchtype=author&query=Haythorpe%2C+M">Michael Haythorpe</a>, 
<a href="/search/math?searchtype=author&query=Newcombe%2C+A">Alex Newcombe</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item367">[367]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2111.05841" title="Abstract">arXiv:2111.05841</a> (replaced) [<a href="/pdf/2111.05841" title="Download PDF">pdf</a>, <a href="/format/2111.05841" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Physics-enhanced deep surrogates for PDEs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pestourie%2C+R">Rapha&#xeb;l Pestourie</a>, 
<a href="/search/cs?searchtype=author&query=Mroueh%2C+Y">Youssef Mroueh</a>, 
<a href="/search/cs?searchtype=author&query=Rackauckas%2C+C">Chris Rackauckas</a>, 
<a href="/search/cs?searchtype=author&query=Das%2C+P">Payel Das</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+S+G">Steven G. Johnson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Applied Physics (physics.app-ph)

</div>
</div>
</dd>
<dt><a name="item368">[368]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2112.03816" title="Abstract">arXiv:2112.03816</a> (replaced) [<a href="/pdf/2112.03816" title="Download PDF">pdf</a>, <a href="/format/2112.03816" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Deep Learning Driven Algorithmic Pipeline for Autonomous Navigation in  Row-Based Crops
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cerrato%2C+S">Simone Cerrato</a>, 
<a href="/search/cs?searchtype=author&query=Mazzia%2C+V">Vittorio Mazzia</a>, 
<a href="/search/cs?searchtype=author&query=Salvetti%2C+F">Francesco Salvetti</a>, 
<a href="/search/cs?searchtype=author&query=Martini%2C+M">Mauro Martini</a>, 
<a href="/search/cs?searchtype=author&query=Angarano%2C+S">Simone Angarano</a>, 
<a href="/search/cs?searchtype=author&query=Navone%2C+A">Alessandro Navone</a>, 
<a href="/search/cs?searchtype=author&query=Chiaberge%2C+M">Marcello Chiaberge</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to Robotics and Autonomous Systems (Elsevier)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item369">[369]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.00733" title="Abstract">arXiv:2202.00733</a> (replaced) [<a href="/pdf/2202.00733" title="Download PDF">pdf</a>, <a href="/format/2202.00733" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> New Insights on Target Speaker Extraction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Elminshawi%2C+M">Mohamed Elminshawi</a>, 
<a href="/search/eess?searchtype=author&query=Mack%2C+W">Wolfgang Mack</a>, 
<a href="/search/eess?searchtype=author&query=Chetupalli%2C+S+R">Srikanth Raj Chetupalli</a>, 
<a href="/search/eess?searchtype=author&query=Chakrabarty%2C+S">Soumitro Chakrabarty</a>, 
<a href="/search/eess?searchtype=author&query=Habets%2C+E+A+P">Emanu&#xeb;l A. P. Habets</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item370">[370]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.05946" title="Abstract">arXiv:2202.05946</a> (replaced) [<a href="/pdf/2202.05946" title="Download PDF">pdf</a>, <a href="/format/2202.05946" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Artificial Intelligence and Statistical Collusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/econ?searchtype=author&query=Banchio%2C+M">Martino Banchio</a>, 
<a href="/search/econ?searchtype=author&query=Mantegazza%2C+G">Giacomo Mantegazza</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 61 pages, 14 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Theoretical Economics (econ.TH)</span>; Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item371">[371]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.06851" title="Abstract">arXiv:2202.06851</a> (replaced) [<a href="/pdf/2202.06851" title="Download PDF">pdf</a>, <a href="/format/2202.06851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAKE: A Knowledge Engine Foundation for Human Activity Understanding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yong-Lu Li</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xinpeng Liu</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+X">Xiaoqian Wu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yizhuo Li</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Z">Zuoyu Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+L">Liang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+Y">Yue Xu</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+H">Hao-Shu Fang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Cewu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> HAKE 2.0; website: <a href="http://hake-mvig.cn/">this http URL</a>, code: <a href="https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/HAKE-Reason">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item372">[372]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2202.09573" title="Abstract">arXiv:2202.09573</a> (replaced) [<a href="/pdf/2202.09573" title="Download PDF">pdf</a>, <a href="/format/2202.09573" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversity in deep generative models and generative AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Turinici%2C+G">Gabriel Turinici</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item373">[373]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.07861" title="Abstract">arXiv:2203.07861</a> (replaced) [<a href="/pdf/2203.07861" title="Download PDF">pdf</a>, <a href="/format/2203.07861" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Don&#x27;t Get Me Wrong: How to Apply Deep Visual Interpretations to Time  Series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Loeffler%2C+C">Christoffer Loeffler</a>, 
<a href="/search/cs?searchtype=author&query=Lai%2C+W">Wei-Cheng Lai</a>, 
<a href="/search/cs?searchtype=author&query=Eskofier%2C+B">Bjoern Eskofier</a>, 
<a href="/search/cs?searchtype=author&query=Zanca%2C+D">Dario Zanca</a>, 
<a href="/search/cs?searchtype=author&query=Schmidt%2C+L">Lukas Schmidt</a>, 
<a href="/search/cs?searchtype=author&query=Mutschler%2C+C">Christopher Mutschler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 36 pages, 13 figues
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item374">[374]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.10729" title="Abstract">arXiv:2203.10729</a> (replaced) [<a href="/e-print/2203.10729" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DSRRTracker: Dynamic Search Region Refinement for Attention-based  Siamese Multi-Object Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wan%2C+J">JiaXu Wan</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hong Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jin Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yuan Ding</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Y">Yifan Yang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yan Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xuliang Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper contained some errors in the legends and visualisations, such as incorrectly using the visualisations of the next generation model we studied. We have rewritten our paper on its next-generation model based on that paper. Since we do not want readers to misunderstand the next-generation paper due to the errors in this preprint paper, we have decided to withdraw this preprint paper
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item375">[375]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2203.11155" title="Abstract">arXiv:2203.11155</a> (replaced) [<a href="/pdf/2203.11155" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Application of Quantum Density Matrix in Classical Question Answering  and Classical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+X+Q">X. Q. Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Wan%2C+H">H. Wan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG); Quantum Physics (quant-ph)

</div>
</div>
</dd>
<dt><a name="item376">[376]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.02112" title="Abstract">arXiv:2204.02112</a> (replaced) [<a href="/pdf/2204.02112" title="Download PDF">pdf</a>, <a href="/format/2204.02112" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> GP-BART: a novel Bayesian additive regression trees approach using  Gaussian processes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Maia%2C+M">Mateus Maia</a>, 
<a href="/search/stat?searchtype=author&query=Murphy%2C+K">Keefe Murphy</a>, 
<a href="/search/stat?searchtype=author&query=Parnell%2C+A+C">Andrew C. Parnell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item377">[377]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.04457" title="Abstract">arXiv:2204.04457</a> (replaced) [<a href="/pdf/2204.04457" title="Download PDF">pdf</a>, <a href="/format/2204.04457" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Refining time-space traffic diagrams: A simple multiple linear  regression model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+Z">Zhengbing He</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item378">[378]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2204.11701" title="Abstract">arXiv:2204.11701</a> (replaced) [<a href="/pdf/2204.11701" title="Download PDF">pdf</a>, <a href="/format/2204.11701" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Tac2Pose: Tactile Object Pose Estimation from the First Touch
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bauza%2C+M">Maria Bauza</a>, 
<a href="/search/cs?searchtype=author&query=Bronars%2C+A">Antonia Bronars</a>, 
<a href="/search/cs?searchtype=author&query=Rodriguez%2C+A">Alberto Rodriguez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IJRR, 22 pages + Appendix, 11 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item379">[379]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2205.11501" title="Abstract">arXiv:2205.11501</a> (replaced) [<a href="/pdf/2205.11501" title="Download PDF">pdf</a>, <a href="/format/2205.11501" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks  for Visual Question Answering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yanan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Yasunaga%2C+M">Michihiro Yasunaga</a>, 
<a href="/search/cs?searchtype=author&query=Ren%2C+H">Hongyu Ren</a>, 
<a href="/search/cs?searchtype=author&query=Wada%2C+S">Shinya Wada</a>, 
<a href="/search/cs?searchtype=author&query=Leskovec%2C+J">Jure Leskovec</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted at ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item380">[380]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.12447" title="Abstract">arXiv:2206.12447</a> (replaced) [<a href="/pdf/2206.12447" title="Download PDF">pdf</a>, <a href="/format/2206.12447" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> XMD: An Expansive Hardware-telemetry based Mobile Malware Detector to  enhance Endpoint Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kumar%2C+H">Harshit Kumar</a>, 
<a href="/search/cs?searchtype=author&query=Chakraborty%2C+B">Biswadeep Chakraborty</a>, 
<a href="/search/cs?searchtype=author&query=Sharma%2C+S">Sudarshan Sharma</a>, 
<a href="/search/cs?searchtype=author&query=Mukhopadhyay%2C+S">Saibal Mukhopadhyay</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Revised version based on peer review feedback. Manuscript to appear in IEEE Transactions on Information Forensics and Security
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item381">[381]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2206.14213" title="Abstract">arXiv:2206.14213</a> (replaced) [<a href="/pdf/2206.14213" title="Download PDF">pdf</a>, <a href="/format/2206.14213" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Improved resource-tunable near-term quantum algorithms for transition  probabilities, with applications in physics and variational quantum linear  algebra
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Sawaya%2C+N+P">Nicolas PD Sawaya</a>, 
<a href="/search/quant-ph?searchtype=author&query=Huh%2C+J">Joonsuk Huh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages, 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Advanced Quantum Technologies 6 (9), 2300042 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Other Condensed Matter (cond-mat.other); Data Structures and Algorithms (cs.DS)

</div>
</div>
</dd>
<dt><a name="item382">[382]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2207.07444" title="Abstract">arXiv:2207.07444</a> (replaced) [<a href="/pdf/2207.07444" title="Download PDF">pdf</a>, <a href="/format/2207.07444" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Federated Learning with Quantum Secure Aggregation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+Y">Yichi Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+C">Chao Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zhang%2C+C">Cai Zhang</a>, 
<a href="/search/quant-ph?searchtype=author&query=Fan%2C+L">Lixin Fan</a>, 
<a href="/search/quant-ph?searchtype=author&query=Zeng%2C+B">Bei Zeng</a>, 
<a href="/search/quant-ph?searchtype=author&query=Yang%2C+Q">Qiang Yang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Quantum Physics (quant-ph)</span>; Cryptography and Security (cs.CR)

</div>
</div>
</dd>
<dt><a name="item383">[383]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.04466" title="Abstract">arXiv:2208.04466</a> (replaced) [<a href="/pdf/2208.04466" title="Download PDF">pdf</a>, <a href="/ps/2208.04466" title="Download PostScript">ps</a>, <a href="/format/2208.04466" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimal scheduling of entropy regulariser for continuous-time  linear-quadratic reinforcement learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Szpruch%2C+L">Lukasz Szpruch</a>, 
<a href="/search/cs?searchtype=author&query=Treetanthiploet%2C+T">Tanut Treetanthiploet</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Yufei Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by SIAM Journal on Control and Optimization
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Optimization and Control (math.OC); Probability (math.PR); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item384">[384]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.08236" title="Abstract">arXiv:2208.08236</a> (replaced) [<a href="/pdf/2208.08236" title="Download PDF">pdf</a>, <a href="/format/2208.08236" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular  Simulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Zhang%2C+D">Duo Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Bi%2C+H">Hangrui Bi</a>, 
<a href="/search/physics?searchtype=author&query=Dai%2C+F">Fu-Zhi Dai</a>, 
<a href="/search/physics?searchtype=author&query=Jiang%2C+W">Wanrun Jiang</a>, 
<a href="/search/physics?searchtype=author&query=Zhang%2C+L">Linfeng Zhang</a>, 
<a href="/search/physics?searchtype=author&query=Wang%2C+H">Han Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Chemical Physics (physics.chem-ph)</span>; Machine Learning (cs.LG); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item385">[385]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.09483" title="Abstract">arXiv:2208.09483</a> (replaced) [<a href="/pdf/2208.09483" title="Download PDF">pdf</a>, <a href="/format/2208.09483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Blind Image Deblurring with Unknown Kernel Size and Substantial Noise
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhuang%2C+Z">Zhong Zhuang</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+T">Taihui Li</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+H">Hengkang Wang</a>, 
<a href="/search/eess?searchtype=author&query=Sun%2C+J">Ju Sun</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> International Journal of Computer Vision, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item386">[386]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2208.10489" title="Abstract">arXiv:2208.10489</a> (replaced) [<a href="/pdf/2208.10489" title="Download PDF">pdf</a>, <a href="/format/2208.10489" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> System Fingerprint Recognition for Deepfake Audio: An Initial Dataset  and Investigation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+X">Xinrui Yan</a>, 
<a href="/search/cs?searchtype=author&query=Yi%2C+J">Jiangyan Yi</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chenglong Wang</a>, 
<a href="/search/cs?searchtype=author&query=Tao%2C+J">Jianhua Tao</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+J">Junzuo Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Gu%2C+H">Hao Gu</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+R">Ruibo Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 4 figures. Submit to IEEE Transactions on Audio, Speech and Language Processing (TASLP). arXiv admin note: text overlap with <a href="/abs/2208.09646">arXiv:2208.09646</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item387">[387]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06028" title="Abstract">arXiv:2209.06028</a> (replaced) [<a href="/pdf/2209.06028" title="Download PDF">pdf</a>, <a href="/format/2209.06028" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Review and computational comparison of adaptive least-squares finite  element schemes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Bringmann%2C+P">Philipp Bringmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item388">[388]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.06758" title="Abstract">arXiv:2209.06758</a> (replaced) [<a href="/pdf/2209.06758" title="Download PDF">pdf</a>, <a href="/format/2209.06758" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Timor Python: A Toolbox for Industrial Modular Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BClz%2C+J">Jonathan K&#xfc;lz</a>, 
<a href="/search/cs?searchtype=author&query=Mayer%2C+M">Matthias Mayer</a>, 
<a href="/search/cs?searchtype=author&query=Althoff%2C+M">Matthias Althoff</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item389">[389]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.09336" title="Abstract">arXiv:2209.09336</a> (replaced) [<a href="/pdf/2209.09336" title="Download PDF">pdf</a>, <a href="/ps/2209.09336" title="Download PostScript">ps</a>, <a href="/format/2209.09336" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Constructing Concise Characteristic Samples for Acceptors of Omega  Regular Languages
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Angluin%2C+D">Dana Angluin</a>, 
<a href="/search/cs?searchtype=author&query=Fisman%2C+D">Dana Fisman</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Formal Languages and Automata Theory (cs.FL)</span>

</div>
</div>
</dd>
<dt><a name="item390">[390]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2209.12234" title="Abstract">arXiv:2209.12234</a> (replaced) [<a href="/pdf/2209.12234" title="Download PDF">pdf</a>, <a href="/format/2209.12234" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diachronic Data Analysis Supports and Refines Conceptual Metaphor Theory
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Teich%2C+M">Marie Teich</a>, 
<a href="/search/cs?searchtype=author&query=Leal%2C+W">Wilmer Leal</a>, 
<a href="/search/cs?searchtype=author&query=Jost%2C+J">Juergen Jost</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages, 7 figures, 2 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item391">[391]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.00040" title="Abstract">arXiv:2210.00040</a> (replaced) [<a href="/pdf/2210.00040" title="Download PDF">pdf</a>, <a href="/format/2210.00040" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Utility of the Koopman operator in output regulation of disturbed  nonlinear systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Kieboom%2C+B">Bart Kieboom</a>, 
<a href="/search/eess?searchtype=author&query=Bartzioka%2C+M">Maria Bartzioka</a>, 
<a href="/search/eess?searchtype=author&query=Jafarian%2C+M">Matin Jafarian</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item392">[392]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.02051" title="Abstract">arXiv:2210.02051</a> (replaced) [<a href="/pdf/2210.02051" title="Download PDF">pdf</a>, <a href="/ps/2210.02051" title="Download PostScript">ps</a>, <a href="/format/2210.02051" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Weak error analysis for the stochastic Allen-Cahn equation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Breit%2C+D">Dominic Breit</a>, 
<a href="/search/math?searchtype=author&query=Prohl%2C+A">Andreas Prohl</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Analysis of PDEs (math.AP); Probability (math.PR)

</div>
</div>
</dd>
<dt><a name="item393">[393]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04643" title="Abstract">arXiv:2210.04643</a> (replaced) [<a href="/pdf/2210.04643" title="Download PDF">pdf</a>, <a href="/format/2210.04643" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Critical Learning Periods for Multisensory Integration in Deep Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kleinman%2C+M">Michael Kleinman</a>, 
<a href="/search/cs?searchtype=author&query=Achille%2C+A">Alessandro Achille</a>, 
<a href="/search/cs?searchtype=author&query=Soatto%2C+S">Stefano Soatto</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> CVPR 2023 (Highlighted Paper)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neurons and Cognition (q-bio.NC)

</div>
</div>
</dd>
<dt><a name="item394">[394]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.04688" title="Abstract">arXiv:2210.04688</a> (replaced) [<a href="/pdf/2210.04688" title="Download PDF">pdf</a>, <a href="/format/2210.04688" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> BAFFLE: Backdoor Attack in Offline Reinforcement Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gong%2C+C">Chen Gong</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+Z">Zhou Yang</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+Y">Yunpeng Bai</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Junda He</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+J">Jieke Shi</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+K">Kecen Li</a>, 
<a href="/search/cs?searchtype=author&query=Sinha%2C+A">Arunesh Sinha</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+B">Bowen Xu</a>, 
<a href="/search/cs?searchtype=author&query=Hou%2C+X">Xinwen Hou</a>, 
<a href="/search/cs?searchtype=author&query=Lo%2C+D">David Lo</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+T">Tianhao Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages, 7 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item395">[395]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.07592" title="Abstract">arXiv:2210.07592</a> (replaced) [<a href="/pdf/2210.07592" title="Download PDF">pdf</a>, <a href="/format/2210.07592" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TSP-Bot: Robotic TSP Pen Art using High-DoF Manipulators
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Song%2C+D">Daeun Song</a>, 
<a href="/search/cs?searchtype=author&query=Lim%2C+E">Eunjung Lim</a>, 
<a href="/search/cs?searchtype=author&query=Park%2C+J">Jiyoon Park</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+M">Minjung Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+Y+J">Young J. Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to IEEE ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item396">[396]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2210.10128" title="Abstract">arXiv:2210.10128</a> (replaced) [<a href="/pdf/2210.10128" title="Download PDF">pdf</a>, <a href="/ps/2210.10128" title="Download PostScript">ps</a>, <a href="/format/2210.10128" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Distributed MPC for Self-Organized Cooperation of Multi-Agent Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=K%C3%B6hler%2C+M">Matthias K&#xf6;hler</a>, 
<a href="/search/eess?searchtype=author&query=M%C3%BCller%2C+M+A">Matthias A. M&#xfc;ller</a>, 
<a href="/search/eess?searchtype=author&query=Allg%C3%B6wer%2C+F">Frank Allg&#xf6;wer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Moved supplementary material to appendix
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item397">[397]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08209" title="Abstract">arXiv:2211.08209</a> (replaced) [<a href="/pdf/2211.08209" title="Download PDF">pdf</a>, <a href="/format/2211.08209" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On counterfactual inference with unobserved confounding
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shah%2C+A">Abhin Shah</a>, 
<a href="/search/cs?searchtype=author&query=Dwivedi%2C+R">Raaz Dwivedi</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+D">Devavrat Shah</a>, 
<a href="/search/cs?searchtype=author&query=Wornell%2C+G+W">Gregory W. Wornell</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Methodology (stat.ME)

</div>
</div>
</dd>
<dt><a name="item398">[398]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.08700" title="Abstract">arXiv:2211.08700</a> (replaced) [<a href="/pdf/2211.08700" title="Download PDF">pdf</a>, <a href="/format/2211.08700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Bi-directional Digital Twin and Edge Computing in the Metaverse
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Yu%2C+J">Jiadong Yu</a>, 
<a href="/search/eess?searchtype=author&query=Alhilal%2C+A">Ahmad Alhilal</a>, 
<a href="/search/eess?searchtype=author&query=Hui%2C+P">Pan Hui</a>, 
<a href="/search/eess?searchtype=author&query=Tsang%2C+D+H+K">Danny H.K. Tsang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item399">[399]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2211.12184" title="Abstract">arXiv:2211.12184</a> (replaced) [<a href="/pdf/2211.12184" title="Download PDF">pdf</a>, <a href="/format/2211.12184" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging Memory Effects and Gradient Information in Consensus-Based  Optimization: On Global Convergence in Mean-Field Law
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Riedl%2C+K">Konstantin Riedl</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 35 pages, 6 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Neural and Evolutionary Computing (cs.NE); Analysis of PDEs (math.AP); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item400">[400]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.01867" title="Abstract">arXiv:2212.01867</a> (replaced) [<a href="/pdf/2212.01867" title="Download PDF">pdf</a>, <a href="/format/2212.01867" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Numerical methods for rectangular multiparameter eigenvalue problems,  with applications to finding optimal ARMA and LTI models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Hochstenbach%2C+M+E">Michiel E. Hochstenbach</a>, 
<a href="/search/math?searchtype=author&query=Ko%C5%A1ir%2C+T">Toma&#x17e; Ko&#x161;ir</a>, 
<a href="/search/math?searchtype=author&query=Plestenjak%2C+B">Bor Plestenjak</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item401">[401]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02448" title="Abstract">arXiv:2212.02448</a> (replaced) [<a href="/pdf/2212.02448" title="Download PDF">pdf</a>, <a href="/ps/2212.02448" title="Download PostScript">ps</a>, <a href="/format/2212.02448" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Multi-cluster Fluctuating Two-Ray Fading Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=S%C3%A1nchez%2C+J+D+V">Jos&#xe9; David Vega S&#xe1;nchez</a>, 
<a href="/search/cs?searchtype=author&query=L%C3%B3pez-Mart%C3%ADnez%2C+F+J">F. Javier L&#xf3;pez-Mart&#xed;nez</a>, 
<a href="/search/cs?searchtype=author&query=Paris%2C+J+F">Jos&#xe9; F. Paris</a>, 
<a href="/search/cs?searchtype=author&query=Romero-Jerez%2C+J+M">Juan M. Romero-Jerez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This work was submitted to the IEEE for publication on May 31, 2022. Copyright may be transferred without notice, after which this version may no longer be accessible
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item402">[402]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.02483" title="Abstract">arXiv:2212.02483</a> (replaced) [<a href="/pdf/2212.02483" title="Download PDF">pdf</a>, <a href="/format/2212.02483" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> TIDE: Time Derivative Diffusion for Deep Learning on Graphs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Behmanesh%2C+M">Maysam Behmanesh</a>, 
<a href="/search/cs?searchtype=author&query=Krahn%2C+M">Maximilian Krahn</a>, 
<a href="/search/cs?searchtype=author&query=Ovsjanikov%2C+M">Maks Ovsjanikov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV); Social and Information Networks (cs.SI)

</div>
</div>
</dd>
<dt><a name="item403">[403]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.07771" title="Abstract">arXiv:2212.07771</a> (replaced) [<a href="/pdf/2212.07771" title="Download PDF">pdf</a>, <a href="/format/2212.07771" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Temporal Saliency Detection Towards Explainable Transformer-based  Timeseries Forecasting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Duong-Trung%2C+N">Nghia Duong-Trung</a>, 
<a href="/search/cs?searchtype=author&query=Nguyen%2C+D">Duc-Manh Nguyen</a>, 
<a href="/search/cs?searchtype=author&query=Le-Phuoc%2C+D">Danh Le-Phuoc</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Published at the International Workshop on Explainable and Interpretable Machine Learning (XI-ML), 26th European Conference on Artificial Intelligence (ECAI 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item404">[404]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2212.11969" title="Abstract">arXiv:2212.11969</a> (replaced) [<a href="/pdf/2212.11969" title="Download PDF">pdf</a>, <a href="/ps/2212.11969" title="Download PostScript">ps</a>, <a href="/format/2212.11969" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Invertibility of digraphs and tournaments
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Alon%2C+N">Noga Alon</a>, 
<a href="/search/math?searchtype=author&query=Powierski%2C+E">Emil Powierski</a>, 
<a href="/search/math?searchtype=author&query=Savery%2C+M">Michael Savery</a>, 
<a href="/search/math?searchtype=author&query=Scott%2C+A">Alex Scott</a>, 
<a href="/search/math?searchtype=author&query=Wilmer%2C+E">Elizabeth Wilmer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 25 pages; final version; minor changes incorporating referees' comments, and addition of Conjecture 3
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item405">[405]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.01253" title="Abstract">arXiv:2301.01253</a> (replaced) [<a href="/pdf/2301.01253" title="Download PDF">pdf</a>, <a href="/format/2301.01253" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Deep learning for bias-correcting CMIP6-class Earth system models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Hess%2C+P">Philipp Hess</a>, 
<a href="/search/physics?searchtype=author&query=Lange%2C+S">Stefan Lange</a>, 
<a href="/search/physics?searchtype=author&query=Sch%C3%B6tz%2C+C">Christof Sch&#xf6;tz</a>, 
<a href="/search/physics?searchtype=author&query=Boers%2C+N">Niklas Boers</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Atmospheric and Oceanic Physics (physics.ao-ph)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item406">[406]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07362" title="Abstract">arXiv:2301.07362</a> (replaced) [<a href="/pdf/2301.07362" title="Download PDF">pdf</a>, <a href="/format/2301.07362" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A light- and heat-seeking vine-inspired robot with material-level  responsiveness
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Deglurkar%2C+S">Shivani Deglurkar</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+C">Charles Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Gockowski%2C+L+F">Luke F. Gockowski</a>, 
<a href="/search/cs?searchtype=author&query=Valentine%2C+M+T">Megan T. Valentine</a>, 
<a href="/search/cs?searchtype=author&query=Hawkes%2C+E+W">Elliot W. Hawkes</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item407">[407]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.07628" title="Abstract">arXiv:2301.07628</a> (replaced) [<a href="/pdf/2301.07628" title="Download PDF">pdf</a>, <a href="/format/2301.07628" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Universal Neural-Cracking-Machines: Self-Configurable Password Models  from Auxiliary Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Pasquini%2C+D">Dario Pasquini</a>, 
<a href="/search/cs?searchtype=author&query=Ateniese%2C+G">Giuseppe Ateniese</a>, 
<a href="/search/cs?searchtype=author&query=Troncoso%2C+C">Carmela Troncoso</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appearing in the proceedings of the 45nd IEEE Symposium on Security and Privacy S&amp;P 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item408">[408]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.09201" title="Abstract">arXiv:2301.09201</a> (replaced) [<a href="/pdf/2301.09201" title="Download PDF">pdf</a>, <a href="/format/2301.09201" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Karim%2C+I">Imtiaz Karim</a>, 
<a href="/search/cs?searchtype=author&query=Mubasshir%2C+K+S">Kazi Samin Mubasshir</a>, 
<a href="/search/cs?searchtype=author&query=Rahman%2C+M+M">Mirza Masfiqur Rahman</a>, 
<a href="/search/cs?searchtype=author&query=Bertino%2C+E">Elisa Bertino</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item409">[409]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2301.12351" title="Abstract">arXiv:2301.12351</a> (replaced) [<a href="/pdf/2301.12351" title="Download PDF">pdf</a>, <a href="/format/2301.12351" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Emerging Synergies in Causality and Deep Generative Models: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhou%2C+G">Guanglin Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+S">Shaoan Xie</a>, 
<a href="/search/cs?searchtype=author&query=Hao%2C+G">Guangyuan Hao</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+S">Shiming Chen</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+B">Biwei Huang</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+X">Xiwei Xu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+C">Chen Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+L">Liming Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Yao%2C+L">Lina Yao</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+K">Kun Zhang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item410">[410]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.00026" title="Abstract">arXiv:2302.00026</a> (replaced) [<a href="/pdf/2302.00026" title="Download PDF">pdf</a>, <a href="/format/2302.00026" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> 3D-Spatiotemporal Forecasting the Expansion of Supernova Shells Using  Deep Learning toward High-Resolution Galaxy Simulations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Hirashima%2C+K">Keiya Hirashima</a>, 
<a href="/search/astro-ph?searchtype=author&query=Moriwaki%2C+K">Kana Moriwaki</a>, 
<a href="/search/astro-ph?searchtype=author&query=Fujii%2C+M+S">Michiko S. Fujii</a>, 
<a href="/search/astro-ph?searchtype=author&query=Hirai%2C+Y">Yutaka Hirai</a>, 
<a href="/search/astro-ph?searchtype=author&query=Saitoh%2C+T+R">Takayuki R. Saitoh</a>, 
<a href="/search/astro-ph?searchtype=author&query=Makino%2C+J">Junichiro Makino</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 14 pages, 14 figures, 3 tables, accepted for MNRAS
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Astrophysics of Galaxies (astro-ph.GA)</span>; Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item411">[411]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.02173" title="Abstract">arXiv:2302.02173</a> (replaced) [<a href="/pdf/2302.02173" title="Download PDF">pdf</a>, <a href="/format/2302.02173" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Survey on Deep Learning based Time Series Analysis with Frequency  Transformation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yi%2C+K">Kun Yi</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Cao%2C+L">Longbing Cao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shoujin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Long%2C+G">Guodong Long</a>, 
<a href="/search/cs?searchtype=author&query=Hu%2C+L">Liang Hu</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+H">Hui He</a>, 
<a href="/search/cs?searchtype=author&query=Niu%2C+Z">Zhendong Niu</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+W">Wei Fan</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+H">Hui Xiong</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item412">[412]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.03080" title="Abstract">arXiv:2302.03080</a> (replaced) [<a href="/pdf/2302.03080" title="Download PDF">pdf</a>, <a href="/format/2302.03080" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Five policy uses of algorithmic transparency and explainability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=O%27Shaughnessy%2C+M">Matthew O&#x27;Shaughnessy</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 21 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item413">[413]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.05164" title="Abstract">arXiv:2302.05164</a> (replaced) [<a href="/pdf/2302.05164" title="Download PDF">pdf</a>, <a href="/format/2302.05164" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A highly efficient computational framework for fast scan-resolved  simulations of metal additive manufacturing processes on the scale of real  parts
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Proell%2C+S+D">Sebastian D. Proell</a>, 
<a href="/search/cs?searchtype=author&query=Munch%2C+P">Peter Munch</a>, 
<a href="/search/cs?searchtype=author&query=Kronbichler%2C+M">Martin Kronbichler</a>, 
<a href="/search/cs?searchtype=author&query=Wall%2C+W+A">Wolfgang A. Wall</a>, 
<a href="/search/cs?searchtype=author&query=Meier%2C+C">Christoph Meier</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>

</div>
</div>
</dd>
<dt><a name="item414">[414]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06692" title="Abstract">arXiv:2302.06692</a> (replaced) [<a href="/pdf/2302.06692" title="Download PDF">pdf</a>, <a href="/format/2302.06692" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Guiding Pretraining in Reinforcement Learning with Large Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yuqing Du</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+O">Olivia Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zihan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Colas%2C+C">C&#xe9;dric Colas</a>, 
<a href="/search/cs?searchtype=author&query=Darrell%2C+T">Trevor Darrell</a>, 
<a href="/search/cs?searchtype=author&query=Abbeel%2C+P">Pieter Abbeel</a>, 
<a href="/search/cs?searchtype=author&query=Gupta%2C+A">Abhishek Gupta</a>, 
<a href="/search/cs?searchtype=author&query=Andreas%2C+J">Jacob Andreas</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICML 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item415">[415]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.06821" title="Abstract">arXiv:2302.06821</a> (replaced) [<a href="/pdf/2302.06821" title="Download PDF">pdf</a>, <a href="/format/2302.06821" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Model-Based Underwater 6D Pose Estimation from RGB
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sapienza%2C+D">Davide Sapienza</a>, 
<a href="/search/cs?searchtype=author&query=Govi%2C+E">Elena Govi</a>, 
<a href="/search/cs?searchtype=author&query=Aldhaheri%2C+S">Sara Aldhaheri</a>, 
<a href="/search/cs?searchtype=author&query=Bertogna%2C+M">Marko Bertogna</a>, 
<a href="/search/cs?searchtype=author&query=Roura%2C+E">Eloy Roura</a>, 
<a href="/search/cs?searchtype=author&query=Pairet%2C+%C3%88">&#xc8;ric Pairet</a>, 
<a href="/search/cs?searchtype=author&query=Verucchi%2C+M">Micaela Verucchi</a>, 
<a href="/search/cs?searchtype=author&query=Ard%C3%B3n%2C+P">Paola Ard&#xf3;n</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under RA-L Submission
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item416">[416]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.08571" title="Abstract">arXiv:2302.08571</a> (replaced) [<a href="/pdf/2302.08571" title="Download PDF">pdf</a>, <a href="/format/2302.08571" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Review and a Taxonomy of Edge Machine Learning:  Requirements, Paradigms, and Techniques
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wenbin Li</a>, 
<a href="/search/cs?searchtype=author&query=Hacid%2C+H">Hakim Hacid</a>, 
<a href="/search/cs?searchtype=author&query=Almazrouei%2C+E">Ebtesam Almazrouei</a>, 
<a href="/search/cs?searchtype=author&query=Debbah%2C+M">Merouane Debbah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 60 pages, 8 figures, 8 tables, AI ISSN: 2673-2688
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item417">[417]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.09933" title="Abstract">arXiv:2302.09933</a> (replaced) [<a href="/pdf/2302.09933" title="Download PDF">pdf</a>, <a href="/ps/2302.09933" title="Download PostScript">ps</a>, <a href="/format/2302.09933" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Mysterious and Manipulative Black Boxes: A Qualitative Analysis of  Perceptions on Recommender Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruohonen%2C+J">Jukka Ruohonen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item418">[418]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2302.13221" title="Abstract">arXiv:2302.13221</a> (replaced) [<a href="/pdf/2302.13221" title="Download PDF">pdf</a>, <a href="/format/2302.13221" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Beyond Discrete Selection: Continuous Embedding Space Optimization for  Generative Feature Selection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+M">Meng Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+D">Dongjie Wang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+M">Min Wu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+P">Pengfei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuanchun Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Fu%2C+Y">Yanjie Fu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> keywords: Automated Feature Selection, Continuous Space Optimization, Deep Sequential Learning, 10 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item419">[419]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02572" title="Abstract">arXiv:2303.02572</a> (replaced) [<a href="/pdf/2303.02572" title="Download PDF">pdf</a>, <a href="/ps/2303.02572" title="Download PostScript">ps</a>, <a href="/format/2303.02572" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Semantics of multimodal adjoint type theory (extended version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Shulman%2C+M">Michael Shulman</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages. v2: Improved notation; extended pre-proceedings version for MFPS 2023. v3: correct some mis-wordings, final
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Category Theory (math.CT)</span>; Logic in Computer Science (cs.LO)

</div>
</div>
</dd>
<dt><a name="item420">[420]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.02744" title="Abstract">arXiv:2303.02744</a> (replaced) [<a href="/pdf/2303.02744" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scientometric Rules as a Guide to Transform Science Systems in the  Middle East &amp; North Africa
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=El-Ouahi%2C+J">Jamal El-Ouahi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 20 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Digital Libraries (cs.DL)</span>

</div>
</div>
</dd>
<dt><a name="item421">[421]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.04023" title="Abstract">arXiv:2303.04023</a> (replaced) [<a href="/pdf/2303.04023" title="Download PDF">pdf</a>, <a href="/format/2303.04023" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Cross-Tool and Cross-Behavior Perceptual Knowledge Transfer for Grounded  Object Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tatiya%2C+G">Gyan Tatiya</a>, 
<a href="/search/cs?searchtype=author&query=Francis%2C+J">Jonathan Francis</a>, 
<a href="/search/cs?searchtype=author&query=Sinapov%2C+J">Jivko Sinapov</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review for 2024 IEEE International Conference on Robotics and Automation (ICRA), May 13 to 17, 2024, Yokohama, Japan
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item422">[422]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06016" title="Abstract">arXiv:2303.06016</a> (replaced) [<a href="/pdf/2303.06016" title="Download PDF">pdf</a>, <a href="/format/2303.06016" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Probe: Learning Users&#x27; Personalized Projection Bias in Intertemporal  Choices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Q">Qingming Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+H+V">H. Vicky Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item423">[423]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06308" title="Abstract">arXiv:2303.06308</a> (replaced) [<a href="/pdf/2303.06308" title="Download PDF">pdf</a>, <a href="/format/2303.06308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Necessity Feature Correspondence Estimation for Large-scale Global Place  Recognition and Relocalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kang%2C+K">Kyeongsu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hyeonwoo Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item424">[424]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.06335" title="Abstract">arXiv:2303.06335</a> (replaced) [<a href="/pdf/2303.06335" title="Download PDF">pdf</a>, <a href="/format/2303.06335" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Just Flip: Flipped Observation Generation and Optimization for Neural  Radiance Fields to Cover Unobserved View
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Minjae Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+K">Kyeongsu Kang</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+H">Hyeonwoo Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item425">[425]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07853" title="Abstract">arXiv:2303.07853</a> (replaced) [<a href="/pdf/2303.07853" title="Download PDF">pdf</a>, <a href="/format/2303.07853" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReFit: A Framework for Refinement of Weakly Supervised Semantic  Segmentation using Object Border Fitting for Medical Images
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Prabakaran%2C+B+S">Bharath Srinivas Prabakaran</a>, 
<a href="/search/cs?searchtype=author&query=Ostrowski%2C+E">Erik Ostrowski</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Publication at the International Symposium on Visual Computing (ISVC), October 2023, Lake Tahoe, NV, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item426">[426]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.07898" title="Abstract">arXiv:2303.07898</a> (replaced) [<a href="/pdf/2303.07898" title="Download PDF">pdf</a>, <a href="/format/2303.07898" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ISLE: A Framework for Image Level Semantic Segmentation Ensemble
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ostrowski%2C+E">Erik Ostrowski</a>, 
<a href="/search/cs?searchtype=author&query=Shafique%2C+M">Muhammad Shafique</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for Publication at the International Symposium on Visual Computing (ISVC), October 2023, Lake Tahoe, NV, USA
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item427">[427]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.10637" title="Abstract">arXiv:2303.10637</a> (replaced) [<a href="/pdf/2303.10637" title="Download PDF">pdf</a>, <a href="/ps/2303.10637" title="Download PostScript">ps</a>, <a href="/format/2303.10637" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A proof complexity conjecture and the Incompleteness theorem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Krajicek%2C+J">Jan Krajicek</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> preliminary version March 2023, revised September 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Logic (math.LO)

</div>
</div>
</dd>
<dt><a name="item428">[428]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.11087" title="Abstract">arXiv:2303.11087</a> (replaced) [<a href="/pdf/2303.11087" title="Download PDF">pdf</a>, <a href="/format/2303.11087" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Non-intrusive Hybrid Scheme for Multiscale Heat Transfer: Thermal  Runaway in a Battery Pack
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Yao%2C+Y+N">Yinuo Noah Yao</a>, 
<a href="/search/math?searchtype=author&query=Harabin%2C+P">Perry Harabin</a>, 
<a href="/search/math?searchtype=author&query=Behandish%2C+M">Morad Behandish</a>, 
<a href="/search/math?searchtype=author&query=Battiato%2C+I">Ilenia Battiato</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 53 pages, 36 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J. Comput. Sci. (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>; Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item429">[429]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.12700" title="Abstract">arXiv:2303.12700</a> (replaced) [<a href="/pdf/2303.12700" title="Download PDF">pdf</a>, <a href="/format/2303.12700" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> ReorientDiff: Diffusion Model based Reorientation for Object  Manipulation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mishra%2C+U+A">Utkarsh A. Mishra</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Y">Yongxin Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 5 figures; More details here: <a href="https://utkarshmishra04.github.io/ReorientDiff">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item430">[430]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.13843" title="Abstract">arXiv:2303.13843</a> (replaced) [<a href="/pdf/2303.13843" title="Download PDF">pdf</a>, <a href="/format/2303.13843" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D  Scene Layout
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bai%2C+H">Haotian Bai</a>, 
<a href="/search/cs?searchtype=author&query=Lyu%2C+Y">Yuanhuiyi Lyu</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+L">Lutao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Sijia Li</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+H">Haonan Lu</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+X">Xiaodong Lin</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Lin Wang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item431">[431]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17086" title="Abstract">arXiv:2303.17086</a> (replaced) [<a href="/pdf/2303.17086" title="Download PDF">pdf</a>, <a href="/ps/2303.17086" title="Download PostScript">ps</a>, <a href="/format/2303.17086" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Modularized Control Synthesis for Complex Signal Temporal Logic  Specifications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+Z">Zengjie Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item432">[432]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2303.17958" title="Abstract">arXiv:2303.17958</a> (replaced) [<a href="/pdf/2303.17958" title="Download PDF">pdf</a>, <a href="/format/2303.17958" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Data-enabled Policy Optimization for the Linear Quadratic Regulator
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Zhao%2C+F">Feiran Zhao</a>, 
<a href="/search/math?searchtype=author&query=D%C3%B6rfler%2C+F">Florian D&#xf6;rfler</a>, 
<a href="/search/math?searchtype=author&query=You%2C+K">Keyou You</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted in IEEE CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item433">[433]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.00346" title="Abstract">arXiv:2304.00346</a> (replaced) [<a href="/pdf/2304.00346" title="Download PDF">pdf</a>, <a href="/ps/2304.00346" title="Download PostScript">ps</a>, <a href="/format/2304.00346" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergent iLQR for Safe Trajectory Planning and Control of Legged  Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+J">James Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Payne%2C+J+J">J. Joe Payne</a>, 
<a href="/search/cs?searchtype=author&query=Johnson%2C+A+M">Aaron M. Johnson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICRA 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item434">[434]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.01169" title="Abstract">arXiv:2304.01169</a> (replaced) [<a href="/pdf/2304.01169" title="Download PDF">pdf</a>, <a href="/format/2304.01169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Click-aware Structure Transfer with Sample Weight Assignment for  Post-Click Conversion Rate Estimation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ouyang%2C+K">Kai Ouyang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+W">Wenhao Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+C">Chen Tang</a>, 
<a href="/search/cs?searchtype=author&query=Xiao%2C+X">Xuanji Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+H">Hai-Tao Zheng</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>

</div>
</div>
</dd>
<dt><a name="item435">[435]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.02976" title="Abstract">arXiv:2304.02976</a> (replaced) [<a href="/pdf/2304.02976" title="Download PDF">pdf</a>, <a href="/format/2304.02976" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Unconstrained Parametrization of Dissipative and Contracting Neural  Ordinary Differential Equations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Martinelli%2C+D">Daniele Martinelli</a>, 
<a href="/search/eess?searchtype=author&query=Galimberti%2C+C+L">Clara Luc&#xed;a Galimberti</a>, 
<a href="/search/eess?searchtype=author&query=Manchester%2C+I+R">Ian R. Manchester</a>, 
<a href="/search/eess?searchtype=author&query=Furieri%2C+L">Luca Furieri</a>, 
<a href="/search/eess?searchtype=author&query=Ferrari-Trecate%2C+G">Giancarlo Ferrari-Trecate</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted for CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item436">[436]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.03696" title="Abstract">arXiv:2304.03696</a> (replaced) [<a href="/pdf/2304.03696" title="Download PDF">pdf</a>, <a href="/format/2304.03696" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MOPA: Modular Object Navigation with PointGoal Agents
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Raychaudhuri%2C+S">Sonia Raychaudhuri</a>, 
<a href="/search/cs?searchtype=author&query=Campari%2C+T">Tommaso Campari</a>, 
<a href="/search/cs?searchtype=author&query=Jain%2C+U">Unnat Jain</a>, 
<a href="/search/cs?searchtype=author&query=Savva%2C+M">Manolis Savva</a>, 
<a href="/search/cs?searchtype=author&query=Chang%2C+A+X">Angel X. Chang</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item437">[437]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.05770" title="Abstract">arXiv:2304.05770</a> (replaced) [<a href="/pdf/2304.05770" title="Download PDF">pdf</a>, <a href="/format/2304.05770" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Abstracting Linear Stochastic Systems via Knowledge Filtering
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Engelaar%2C+M+H+W">Maico Hendrikus Wilhelmus Engelaar</a>, 
<a href="/search/eess?searchtype=author&query=Romao%2C+L">Licio Romao</a>, 
<a href="/search/eess?searchtype=author&query=Gao%2C+Y">Yulong Gao</a>, 
<a href="/search/eess?searchtype=author&query=Lazar%2C+M">Mircea Lazar</a>, 
<a href="/search/eess?searchtype=author&query=Abate%2C+A">Alessandro Abate</a>, 
<a href="/search/eess?searchtype=author&query=Haesaert%2C+S">Sofie Haesaert</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 3 figures, accepted for CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>

</div>
</div>
</dd>
<dt><a name="item438">[438]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.06623" title="Abstract">arXiv:2304.06623</a> (replaced) [<a href="/pdf/2304.06623" title="Download PDF">pdf</a>, <a href="/format/2304.06623" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Exploring the State of the Art in Legal QA Systems
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Abdallah%2C+A">Abdelrahman Abdallah</a>, 
<a href="/search/cs?searchtype=author&query=Piryani%2C+B">Bhawna Piryani</a>, 
<a href="/search/cs?searchtype=author&query=Jatowt%2C+A">Adam Jatowt</a>
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> J Big Data 10, 127 (2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item439">[439]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.07756" title="Abstract">arXiv:2304.07756</a> (replaced) [<a href="/pdf/2304.07756" title="Download PDF">pdf</a>, <a href="/format/2304.07756" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Arbitrary Reduction of MRI Inter-slice Spacing Using Hierarchical  Feature Conditional Diffusion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/eess?searchtype=author&query=Shen%2C+Z">Zhenrong Shen</a>, 
<a href="/search/eess?searchtype=author&query=Song%2C+Z">Zhiyun Song</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+S">Sheng Wang</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+M">Mengjun Liu</a>, 
<a href="/search/eess?searchtype=author&query=Zhang%2C+L">Lichi Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Xuan%2C+K">Kai Xuan</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Q">Qian Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> new version
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item440">[440]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.10136" title="Abstract">arXiv:2304.10136</a> (replaced) [<a href="/pdf/2304.10136" title="Download PDF">pdf</a>, <a href="/format/2304.10136" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diversifying the High-level Features for better Adversarial  Transferability
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zhiyuan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zeliang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+S">Siyuan Liang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaosen Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by BMVC 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item441">[441]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.13787" title="Abstract">arXiv:2304.13787</a> (replaced) [<a href="/pdf/2304.13787" title="Download PDF">pdf</a>, <a href="/format/2304.13787" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Surrogate Assisted Generation of Human-Robot Interaction Scenarios
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bhatt%2C+V">Varun Bhatt</a>, 
<a href="/search/cs?searchtype=author&query=Nemlekar%2C+H">Heramb Nemlekar</a>, 
<a href="/search/cs?searchtype=author&query=Fontaine%2C+M+C">Matthew C. Fontaine</a>, 
<a href="/search/cs?searchtype=author&query=Tjanaka%2C+B">Bryon Tjanaka</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Hejia Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Hsu%2C+Y">Ya-Chuan Hsu</a>, 
<a href="/search/cs?searchtype=author&query=Nikolaidis%2C+S">Stefanos Nikolaidis</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 18 pages; 9 figures; 2 tables; Accepted for oral presentation at CoRL 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item442">[442]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14633" title="Abstract">arXiv:2304.14633</a> (replaced) [<a href="/pdf/2304.14633" title="Download PDF">pdf</a>, <a href="/format/2304.14633" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CVRecon: Rethinking 3D Geometric Feature Learning For Neural  Reconstruction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Feng%2C+Z">Ziyue Feng</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+L">Liang Yang</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+P">Pengsheng Guo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bing Li</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item443">[443]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2304.14852" title="Abstract">arXiv:2304.14852</a> (replaced) [<a href="/pdf/2304.14852" title="Download PDF">pdf</a>, <a href="/format/2304.14852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Wasserstein Dictionaries of Persistence Diagrams
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sisouk%2C+K">Keanu Sisouk</a>, 
<a href="/search/cs?searchtype=author&query=Delon%2C+J">Julie Delon</a>, 
<a href="/search/cs?searchtype=author&query=Tierny%2C+J">Julien Tierny</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> arXiv admin note: text overlap with <a href="/abs/2207.10960">arXiv:2207.10960</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computational Geometry (cs.CG); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)

</div>
</div>
</dd>
<dt><a name="item444">[444]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.00967" title="Abstract">arXiv:2305.00967</a> (replaced) [<a href="/pdf/2305.00967" title="Download PDF">pdf</a>, <a href="/format/2305.00967" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comparison of Pneumatic Actuators for Soft Growing Vine Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=K%C3%BCbler%2C+A+M">Alexander M. K&#xfc;bler</a>, 
<a href="/search/cs?searchtype=author&query=Pasquier%2C+C+d">Cosima du Pasquier</a>, 
<a href="/search/cs?searchtype=author&query=Low%2C+A">Andrew Low</a>, 
<a href="/search/cs?searchtype=author&query=Djambazi%2C+B">Betim Djambazi</a>, 
<a href="/search/cs?searchtype=author&query=Aymon%2C+N">Nicolas Aymon</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%B6rster%2C+J">Julian F&#xf6;rster</a>, 
<a href="/search/cs?searchtype=author&query=Agharese%2C+N">Nathaniel Agharese</a>, 
<a href="/search/cs?searchtype=author&query=Siegwart%2C+R">Roland Siegwart</a>, 
<a href="/search/cs?searchtype=author&query=Okamura%2C+A+M">Allison M. Okamura</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 13 pages, 8 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item445">[445]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.03066" title="Abstract">arXiv:2305.03066</a> (replaced) [<a href="/pdf/2305.03066" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> An array of microresonators as a Photonic Extreme Learning Machine
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Biasi%2C+S">Stefano Biasi</a>, 
<a href="/search/cs?searchtype=author&query=Franchi%2C+R">Riccardo Franchi</a>, 
<a href="/search/cs?searchtype=author&query=Cerini%2C+L">Lorenzo Cerini</a>, 
<a href="/search/cs?searchtype=author&query=Pavesi%2C+L">Lorenzo Pavesi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 12 pages and 6 figures
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> APL Photonics 1 September 2023; 8 (9): 096105
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Emerging Technologies (cs.ET)</span>; Optics (physics.optics)

</div>
</div>
</dd>
<dt><a name="item446">[446]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.04809" title="Abstract">arXiv:2305.04809</a> (replaced) [<a href="/pdf/2305.04809" title="Download PDF">pdf</a>, <a href="/format/2305.04809" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Whittle Index Policy for the Remote Estimation of Multiple Continuous  Gauss-Markov Processes over Parallel Channels
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ornee%2C+T+Z">Tasmeen Zaman Ornee</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+Y">Yin Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 23 pages, 4 figures, part of this manuscript has been accepted by ACM MobiHoc 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Networking and Internet Architecture (cs.NI)</span>

</div>
</div>
</dd>
<dt><a name="item447">[447]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.06630" title="Abstract">arXiv:2305.06630</a> (replaced) [<a href="/pdf/2305.06630" title="Download PDF">pdf</a>, <a href="/format/2305.06630" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Predictive change point detection for heterogeneous data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Glock%2C+A">Anna-Christina Glock</a>, 
<a href="/search/cs?searchtype=author&query=Sobieczky%2C+F">Florian Sobieczky</a>, 
<a href="/search/cs?searchtype=author&query=F%C3%BCrnkranz%2C+J">Johannes F&#xfc;rnkranz</a>, 
<a href="/search/cs?searchtype=author&query=Filzmoser%2C+P">Peter Filzmoser</a>, 
<a href="/search/cs?searchtype=author&query=Jech%2C+M">Martin Jech</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item448">[448]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.08339" title="Abstract">arXiv:2305.08339</a> (replaced) [<a href="/pdf/2305.08339" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Assessing the potential of AI-assisted pragmatic annotation: The case of  apologies
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yu%2C+D">Danni Yu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Luyang Li</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+H">Hang Su</a>, 
<a href="/search/cs?searchtype=author&query=Fuoli%2C+M">Matteo Fuoli</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 24 pages, 2 figures, 3 tablels
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item449">[449]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.11870" title="Abstract">arXiv:2305.11870</a> (replaced) [<a href="/pdf/2305.11870" title="Download PDF">pdf</a>, <a href="/format/2305.11870" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D  Diffusion Probabilistic Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Kim%2C+B">Byungjun Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kwon%2C+P">Patrick Kwon</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+K">Kwangho Lee</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+M">Myunggi Lee</a>, 
<a href="/search/cs?searchtype=author&query=Han%2C+S">Sookwan Han</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+D">Daesik Kim</a>, 
<a href="/search/cs?searchtype=author&query=Joo%2C+H">Hanbyul Joo</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project Page: <a href="https://snuvclab.github.io/chupa/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item450">[450]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.12343" title="Abstract">arXiv:2305.12343</a> (replaced) [<a href="/pdf/2305.12343" title="Download PDF">pdf</a>, <a href="/format/2305.12343" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Entropy and energy conservation for thermal atmospheric dynamics using  mixed compatible finite elements
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Ricardo%2C+K">Kieran Ricardo</a>, 
<a href="/search/math?searchtype=author&query=Lee%2C+D">David Lee</a>, 
<a href="/search/math?searchtype=author&query=Duru%2C+K">Kenneth Duru</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item451">[451]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14402" title="Abstract">arXiv:2305.14402</a> (replaced) [<a href="/pdf/2305.14402" title="Download PDF">pdf</a>, <a href="/format/2305.14402" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> emoDARTS : Enhancing Speech Emotion Recognition Through Differentiable  Architecture Search
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Rajapakshe%2C+T">Thejan Rajapakshe</a>, 
<a href="/search/cs?searchtype=author&query=Rana%2C+R">Rajib Rana</a>, 
<a href="/search/cs?searchtype=author&query=Khalifa%2C+S">Sara Khalifa</a>, 
<a href="/search/cs?searchtype=author&query=Sisman%2C+B">Berrak Sisman</a>, 
<a href="/search/cs?searchtype=author&query=Schuller%2C+B">Bj&#xf6;rn Schuller</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 4 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item452">[452]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.14408" title="Abstract">arXiv:2305.14408</a> (replaced) [<a href="/pdf/2305.14408" title="Download PDF">pdf</a>, <a href="/format/2305.14408" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Pressure- and time-dependent alveolar recruitment/derecruitment in a  spatially resolved patient-specific computational model for injured human  lungs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Geitner%2C+C+M">Carolin M. Geitner</a> (1), 
<a href="/search/physics?searchtype=author&query=K%C3%B6glmeier%2C+L+J">Lea J. K&#xf6;glmeier</a> (1), 
<a href="/search/physics?searchtype=author&query=Frerichs%2C+I">In&#xe9;z Frerichs</a> (2), 
<a href="/search/physics?searchtype=author&query=Langguth%2C+P">Patrick Langguth</a> (3), 
<a href="/search/physics?searchtype=author&query=Lindner%2C+M">Matthias Lindner</a> (2), 
<a href="/search/physics?searchtype=author&query=Sch%C3%A4dler%2C+D">Dirk Sch&#xe4;dler</a> (2), 
<a href="/search/physics?searchtype=author&query=Weiler%2C+N">Norbert Weiler</a> (2), 
<a href="/search/physics?searchtype=author&query=Becher%2C+T">Tobias Becher</a> (2), 
<a href="/search/physics?searchtype=author&query=Wall%2C+W+A">Wolfgang A. Wall</a> (1) ((1) Institute for Computational Mechanics, Technical University of Munich, Garching b. Muenchen, Germany, (2) Department of Anesthesiology and Intensive Care Medicine, University Medical Center Schleswig-Holstein, Campus Kiel, Kiel, Germany, (3) Department of Radiology and Neuroradiology, University Medical Center Schleswig-Holstein, Campus Kiel, Kiel, Germany)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Medical Physics (physics.med-ph)</span>; Computational Engineering, Finance, and Science (cs.CE); Biological Physics (physics.bio-ph); Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item453">[453]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15096" title="Abstract">arXiv:2305.15096</a> (replaced) [<a href="/pdf/2305.15096" title="Download PDF">pdf</a>, <a href="/format/2305.15096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Masking Rate Schedules for MLM Pretraining
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ankner%2C+Z">Zachary Ankner</a>, 
<a href="/search/cs?searchtype=author&query=Saphra%2C+N">Naomi Saphra</a>, 
<a href="/search/cs?searchtype=author&query=Blalock%2C+D">Davis Blalock</a>, 
<a href="/search/cs?searchtype=author&query=Frankle%2C+J">Jonathan Frankle</a>, 
<a href="/search/cs?searchtype=author&query=Leavitt%2C+M+L">Matthew L. Leavitt</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item454">[454]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15266" title="Abstract">arXiv:2305.15266</a> (replaced) [<a href="/pdf/2305.15266" title="Download PDF">pdf</a>, <a href="/format/2305.15266" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Diffusion-Based Audio Inpainting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Moliner%2C+E">Eloi Moliner</a>, 
<a href="/search/eess?searchtype=author&query=V%C3%A4lim%C3%A4ki%2C+V">Vesa V&#xe4;lim&#xe4;ki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted for publication to the Journal of Audio Engineering Society on January 30th, 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD)

</div>
</div>
</dd>
<dt><a name="item455">[455]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15776" title="Abstract">arXiv:2305.15776</a> (replaced) [<a href="/pdf/2305.15776" title="Download PDF">pdf</a>, <a href="/format/2305.15776" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AUC Optimization from Multiple Unlabeled Datasets
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xie%2C+Z">Zheng Xie</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Y">Yu Liu</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Ming Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item456">[456]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.15905" title="Abstract">arXiv:2305.15905</a> (replaced) [<a href="/pdf/2305.15905" title="Download PDF">pdf</a>, <a href="/format/2305.15905" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Latent Diffusion Model Based Foley Sound Generation System For DCASE  Challenge 2023 Task 7
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiyuan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DCASE 2023 task 7 technical report, ranked 1st in the challenge
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Multimedia (cs.MM); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item457">[457]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2305.17103" title="Abstract">arXiv:2305.17103</a> (replaced) [<a href="/pdf/2305.17103" title="Download PDF">pdf</a>, <a href="/ps/2305.17103" title="Download PostScript">ps</a>, <a href="/format/2305.17103" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On regular sets of affine type in finite Desarguesian planes and related  codes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Aguglia%2C+A">Angela Aguglia</a>, 
<a href="/search/math?searchtype=author&query=Csajb%C3%B3k%2C+B">Bence Csajb&#xf3;k</a>, 
<a href="/search/math?searchtype=author&query=Giuzzi%2C+L">Luca Giuzzi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 16 pages/updated grants and founding agencies
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Combinatorics (math.CO)</span>; Discrete Mathematics (cs.DM)

</div>
</div>
</dd>
<dt><a name="item458">[458]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.00565" title="Abstract">arXiv:2306.00565</a> (replaced) [<a href="/pdf/2306.00565" title="Download PDF">pdf</a>, <a href="/format/2306.00565" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Optimization Algorithm Synthesis based on Integral Quadratic  Constraints: A Tutorial
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Scherer%2C+C+W">Carsten W. Scherer</a>, 
<a href="/search/math?searchtype=author&query=Ebenbauer%2C+C">Christian Ebenbauer</a>, 
<a href="/search/math?searchtype=author&query=Holicki%2C+T">Tobias Holicki</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A short version of this paper has been accepted for publication at the CDC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item459">[459]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.05554" title="Abstract">arXiv:2306.05554</a> (replaced) [<a href="/pdf/2306.05554" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Simulation and Prediction of Countercurrent Spontaneous Imbibition at  Early and Late Times Using Physics-Informed Neural Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Abbasi%2C+J">Jassem Abbasi</a>, 
<a href="/search/physics?searchtype=author&query=Andersen%2C+P+%C3%98">P&#xe5;l &#xd8;steb&#xf8; Andersen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item460">[460]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.08960" title="Abstract">arXiv:2306.08960</a> (replaced) [<a href="/pdf/2306.08960" title="Download PDF">pdf</a>, <a href="/format/2306.08960" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Neural Network Compression using Binarization and Few Full-Precision  Weights
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Nardini%2C+F+M">Franco Maria Nardini</a>, 
<a href="/search/cs?searchtype=author&query=Rulli%2C+C">Cosimo Rulli</a>, 
<a href="/search/cs?searchtype=author&query=Trani%2C+S">Salvatore Trani</a>, 
<a href="/search/cs?searchtype=author&query=Venturini%2C+R">Rossano Venturini</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages, 6 figures, 3 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item461">[461]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.10359" title="Abstract">arXiv:2306.10359</a> (replaced) [<a href="/pdf/2306.10359" title="Download PDF">pdf</a>, <a href="/format/2306.10359" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Text-Driven Foley Sound Generation With Latent Diffusion Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yuan%2C+Y">Yi Yuan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Haohe Liu</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xubo Liu</a>, 
<a href="/search/cs?searchtype=author&query=Kang%2C+X">Xiyuan Kang</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+P">Peipei Wu</a>, 
<a href="/search/cs?searchtype=author&query=Plumbley%2C+M+D">Mark D. Plumbley</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Wenwu Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submit to DCASE-workshop 2023, an extension and supersedes the previous technical report <a href="/abs/2305.15905">arXiv:2305.15905</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item462">[462]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12111" title="Abstract">arXiv:2306.12111</a> (replaced) [<a href="/pdf/2306.12111" title="Download PDF">pdf</a>, <a href="/format/2306.12111" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> A Comprehensive Study on the Robustness of Image Classification and  Object Detection in Remote Sensing: Surveying and Benchmarking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+S">Shaohui Mei</a>, 
<a href="/search/cs?searchtype=author&query=Lian%2C+J">Jiawei Lian</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiaofei Wang</a>, 
<a href="/search/cs?searchtype=author&query=Su%2C+Y">Yuru Su</a>, 
<a href="/search/cs?searchtype=author&query=Ma%2C+M">Mingyang Ma</a>, 
<a href="/search/cs?searchtype=author&query=Chau%2C+L">Lap-Pui Chau</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item463">[463]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.12652" title="Abstract">arXiv:2306.12652</a> (replaced) [<a href="/pdf/2306.12652" title="Download PDF">pdf</a>, <a href="/format/2306.12652" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> UltraGlove: Hand Pose Estimation with Mems-Ultrasonic Sensors
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qiang Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yuanqiao Lin</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+Y">Yubin Lin</a>, 
<a href="/search/cs?searchtype=author&query=Rusinkiewicz%2C+S">Szymon Rusinkiewicz</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Graphics (cs.GR); Human-Computer Interaction (cs.HC); Robotics (cs.RO)

</div>
</div>
</dd>
<dt><a name="item464">[464]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.13551" title="Abstract">arXiv:2306.13551</a> (replaced) [<a href="/pdf/2306.13551" title="Download PDF">pdf</a>, <a href="/ps/2306.13551" title="Download PostScript">ps</a>, <a href="/format/2306.13551" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Landscape of Computing Symmetric $n$-Variable Functions with $2n$  Cards
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruangwises%2C+S">Suthee Ruangwises</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper has appeared at ICTAC 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item465">[465]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14066" title="Abstract">arXiv:2306.14066</a> (replaced) [<a href="/pdf/2306.14066" title="Download PDF">pdf</a>, <a href="/format/2306.14066" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> SEEDS: Emulation of Weather Forecast Ensembles with Diffusion Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+L">Lizao Li</a>, 
<a href="/search/cs?searchtype=author&query=Carver%2C+R">Rob Carver</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Gomez%2C+I">Ignacio Lopez-Gomez</a>, 
<a href="/search/cs?searchtype=author&query=Sha%2C+F">Fei Sha</a>, 
<a href="/search/cs?searchtype=author&query=Anderson%2C+J">John Anderson</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Atmospheric and Oceanic Physics (physics.ao-ph)

</div>
</div>
</dd>
<dt><a name="item466">[466]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14096" title="Abstract">arXiv:2306.14096</a> (replaced) [<a href="/pdf/2306.14096" title="Download PDF">pdf</a>, <a href="/format/2306.14096" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chinese Fine-Grained Financial Sentiment Analysis with Large Language  Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lan%2C+Y">Yinyu Lan</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+Y">Yanru Wu</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">Wang Xu</a>, 
<a href="/search/cs?searchtype=author&query=Feng%2C+W">Weiqiang Feng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Y">Youhao Zhang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by (FinLLM 2023)@IJCAI 2023, <a href="https://finllm.github.io/workshop/#/fcb">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item467">[467]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14520" title="Abstract">arXiv:2306.14520</a> (replaced) [<a href="/pdf/2306.14520" title="Download PDF">pdf</a>, <a href="/format/2306.14520" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Approximation algorithms for $k$-submodular maximization subject to a  knapsack constraint
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Hao Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Q">Qian Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yang Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+M">Min Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item468">[468]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.14600" title="Abstract">arXiv:2306.14600</a> (replaced) [<a href="/pdf/2306.14600" title="Download PDF">pdf</a>, <a href="/format/2306.14600" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trefftz Discontinuous Galerkin discretization for the Stokes problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Lederer%2C+P+L">Philip L. Lederer</a>, 
<a href="/search/math?searchtype=author&query=Lehrenfeld%2C+C">Christoph Lehrenfeld</a>, 
<a href="/search/math?searchtype=author&query=Stocker%2C+P">Paul Stocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 30 pages, 5 figures, 8 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Numerical Analysis (math.NA)</span>

</div>
</div>
</dd>
<dt><a name="item469">[469]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.15725" title="Abstract">arXiv:2306.15725</a> (replaced) [<a href="/pdf/2306.15725" title="Download PDF">pdf</a>, <a href="/format/2306.15725" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Supportive Fintech for Individuals with Bipolar Disorder: Financial Data  Sharing Preferences to Support Longitudinal Care Management
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Brozena%2C+J">Jeff Brozena</a>, 
<a href="/search/cs?searchtype=author&query=Blair%2C+J">Johnna Blair</a>, 
<a href="/search/cs?searchtype=author&query=Richardson%2C+T">Thomas Richardson</a>, 
<a href="/search/cs?searchtype=author&query=Matthews%2C+M">Mark Matthews</a>, 
<a href="/search/cs?searchtype=author&query=Mukherjee%2C+D">Dahlia Mukherjee</a>, 
<a href="/search/cs?searchtype=author&query=Saunders%2C+E+F+H">Erika F H Saunders</a>, 
<a href="/search/cs?searchtype=author&query=Abdullah%2C+S">Saeed Abdullah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 5 figures, submitted to ACM CHI conference on Human Factors in Computing Systems
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item470">[470]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.16559" title="Abstract">arXiv:2306.16559</a> (replaced) [<a href="/pdf/2306.16559" title="Download PDF">pdf</a>, <a href="/format/2306.16559" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Selection: A perspective on inter-attribute cooperation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sosa-Cabrera%2C+G">Gustavo Sosa-Cabrera</a>, 
<a href="/search/cs?searchtype=author&query=G%C3%B3mez-Guerrero%2C+S">Santiago G&#xf3;mez-Guerrero</a>, 
<a href="/search/cs?searchtype=author&query=Garc%C3%ADa-Torres%2C+M">Miguel Garc&#xed;a-Torres</a>, 
<a href="/search/cs?searchtype=author&query=Schaerer%2C+C+E">Christian E. Schaerer</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in International Journal of Data Science and Analytics, and is available online at <a href="https://doi.org/10.1007/s41060-023-00439-z">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI); Information Theory (cs.IT)

</div>
</div>
</dd>
<dt><a name="item471">[471]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17137" title="Abstract">arXiv:2306.17137</a> (replaced) [<a href="/e-print/2306.17137" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Data-Driven Control Part I: Trajectory Representation under  quasi-Linear Parameter Varying Embeddings
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morato%2C+M+M">Marcelo Menezes Morato</a>, 
<a href="/search/eess?searchtype=author&query=Normey-Rico%2C+J+E">Julio Elias Normey-Rico</a>, 
<a href="/search/eess?searchtype=author&query=Sename%2C+O">Olivier Sename</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Many changes are being performed on the manuscript. A revised version will be available soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item472">[472]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2306.17139" title="Abstract">arXiv:2306.17139</a> (replaced) [<a href="/e-print/2306.17139" title="Download source">src</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Nonlinear Data-Driven Control Part II: qLPV Predictive Control using  Parameter Extrapolation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Morato%2C+M+M">Marcelo Menezes Morato</a>, 
<a href="/search/eess?searchtype=author&query=Normey-Rico%2C+J+E">Julio Elias Normey-Rico</a>, 
<a href="/search/eess?searchtype=author&query=Sename%2C+O">Olivier Sename</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Many changes are being performed on the manuscript. A revised version will be available soon
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Dynamical Systems (math.DS)

</div>
</div>
</dd>
<dt><a name="item473">[473]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.00835" title="Abstract">arXiv:2307.00835</a> (replaced) [<a href="/pdf/2307.00835" title="Download PDF">pdf</a>, <a href="/format/2307.00835" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Engression: Extrapolation for Nonlinear Regression?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Shen%2C+X">Xinwei Shen</a>, 
<a href="/search/stat?searchtype=author&query=Meinshausen%2C+N">Nicolai Meinshausen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Methodology (stat.ME)</span>; Machine Learning (cs.LG); Machine Learning (stat.ML)

</div>
</div>
</dd>
<dt><a name="item474">[474]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.01717" title="Abstract">arXiv:2307.01717</a> (replaced) [<a href="/pdf/2307.01717" title="Download PDF">pdf</a>, <a href="/format/2307.01717" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On the Constrained Time-Series Generation Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Coletta%2C+A">Andrea Coletta</a>, 
<a href="/search/cs?searchtype=author&query=Gopalakrishan%2C+S">Sriram Gopalakrishan</a>, 
<a href="/search/cs?searchtype=author&query=Borrajo%2C+D">Daniel Borrajo</a>, 
<a href="/search/cs?searchtype=author&query=Vyetrenko%2C+S">Svitlana Vyetrenko</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item475">[475]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.04513" title="Abstract">arXiv:2307.04513</a> (replaced) [<a href="/pdf/2307.04513" title="Download PDF">pdf</a>, <a href="/format/2307.04513" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CoactSeg: Learning from Heterogeneous Data for New Multiple Sclerosis  Lesion Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Wu%2C+Y">Yicheng Wu</a>, 
<a href="/search/eess?searchtype=author&query=Wu%2C+Z">Zhonghua Wu</a>, 
<a href="/search/eess?searchtype=author&query=Shi%2C+H">Hengcan Shi</a>, 
<a href="/search/eess?searchtype=author&query=Picker%2C+B">Bjoern Picker</a>, 
<a href="/search/eess?searchtype=author&query=Chong%2C+W">Winston Chong</a>, 
<a href="/search/eess?searchtype=author&query=Cai%2C+J">Jianfei Cai</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by MICCAI 2023 (Early Acceptance)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item476">[476]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.07577" title="Abstract">arXiv:2307.07577</a> (replaced) [<a href="/pdf/2307.07577" title="Download PDF">pdf</a>, <a href="/ps/2307.07577" title="Download PostScript">ps</a>, <a href="/format/2307.07577" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Decomposition Based Refinement for the Network Interdiction Problem
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Matta%2C+K">Krish Matta</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiaoyuan Liu</a>, 
<a href="/search/cs?searchtype=author&query=Safro%2C+I">Ilya Safro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>

</div>
</div>
</dd>
<dt><a name="item477">[477]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.09039" title="Abstract">arXiv:2307.09039</a> (replaced) [<a href="/pdf/2307.09039" title="Download PDF">pdf</a>, <a href="/format/2307.09039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PottsMGNet: A Mathematical Explanation of Encoder-Decoder Based Neural  Networks
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Tai%2C+X">Xue-Cheng Tai</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+H">Hao Liu</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+R">Raymond Chan</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item478">[478]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.11099" title="Abstract">arXiv:2307.11099</a> (replaced) [<a href="/pdf/2307.11099" title="Download PDF">pdf</a>, <a href="/format/2307.11099" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Solving multiphysics-based inverse problems with learned surrogates and  constraints
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Yin%2C+Z">Ziyi Yin</a>, 
<a href="/search/physics?searchtype=author&query=Orozco%2C+R">Rafael Orozco</a>, 
<a href="/search/physics?searchtype=author&query=Louboutin%2C+M">Mathias Louboutin</a>, 
<a href="/search/physics?searchtype=author&query=Herrmann%2C+F+J">Felix J. Herrmann</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Geophysics (physics.geo-ph)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Numerical Analysis (math.NA); Computational Physics (physics.comp-ph)

</div>
</div>
</dd>
<dt><a name="item479">[479]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12463" title="Abstract">arXiv:2307.12463</a> (replaced) [<a href="/pdf/2307.12463" title="Download PDF">pdf</a>, <a href="/format/2307.12463" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Rethinking Data Distillation: Do Not Overlook Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhu%2C+D">Dongyao Zhu</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+B">Bowen Lei</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+J">Jie Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Fang%2C+Y">Yanbo Fang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+R">Ruqi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+Y">Yiqun Xie</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+D">Dongkuan Xu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item480">[480]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12622" title="Abstract">arXiv:2307.12622</a> (replaced) [<a href="/pdf/2307.12622" title="Download PDF">pdf</a>, <a href="/format/2307.12622" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Phase Matching for Out-of-Distribution Generalization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+C">Chengming Hu</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+Y">Yeqian Du</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+R">Rui Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+H">Hao Chen</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item481">[481]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.12703" title="Abstract">arXiv:2307.12703</a> (replaced) [<a href="/pdf/2307.12703" title="Download PDF">pdf</a>, <a href="/ps/2307.12703" title="Download PostScript">ps</a>, <a href="/format/2307.12703" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Policy Gradient Optimal Correlation Search for Variance Reduction in  Monte Carlo simulation and Maximum Optimal Transport
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/stat?searchtype=author&query=Bras%2C+P">Pierre Bras</a>, 
<a href="/search/stat?searchtype=author&query=Pag%C3%A8s%2C+G">Gilles Pag&#xe8;s</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (stat.ML)</span>; Machine Learning (cs.LG); Optimization and Control (math.OC)

</div>
</div>
</dd>
<dt><a name="item482">[482]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.13149" title="Abstract">arXiv:2307.13149</a> (replaced) [<a href="/pdf/2307.13149" title="Download PDF">pdf</a>, <a href="/format/2307.13149" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bahmani%2C+B">Bahador Bahmani</a>, 
<a href="/search/cs?searchtype=author&query=Suh%2C+H+S">Hyoung Suk Suh</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+W">WaiChing Sun</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Engineering, Finance, and Science (cs.CE)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item483">[483]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16387" title="Abstract">arXiv:2307.16387</a> (replaced) [<a href="/pdf/2307.16387" title="Download PDF">pdf</a>, <a href="/format/2307.16387" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Relation-Oriented: Toward Knowledge-Aligned Causal AI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jia Li</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>

</div>
</div>
</dd>
<dt><a name="item484">[484]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2307.16440" title="Abstract">arXiv:2307.16440</a> (replaced) [<a href="/pdf/2307.16440" title="Download PDF">pdf</a>, <a href="/format/2307.16440" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Towards Head Computed Tomography Image Reconstruction Standardization  with Deep Learning Assisted Automatic Detection
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zheng%2C+B">Bowen Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+C">Chenxi Huang</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Y">Yuemei Luo</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Machine Learning (cs.LG); Image and Video Processing (eess.IV)

</div>
</div>
</dd>
<dt><a name="item485">[485]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.01921" title="Abstract">arXiv:2308.01921</a> (replaced) [<a href="/pdf/2308.01921" title="Download PDF">pdf</a>, <a href="/format/2308.01921" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Transferable Graph Neural Fingerprint Models for Quick Response to  Future Bio-Threats
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+W">Wei Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Ren%2C+Y">Yihui Ren</a>, 
<a href="/search/q-bio?searchtype=author&query=Kagawa%2C+A">Ai Kagawa</a>, 
<a href="/search/q-bio?searchtype=author&query=Carbone%2C+M+R">Matthew R. Carbone</a>, 
<a href="/search/q-bio?searchtype=author&query=Chen%2C+S+Y">Samuel Yen-Chi Chen</a>, 
<a href="/search/q-bio?searchtype=author&query=Qu%2C+X">Xiaohui Qu</a>, 
<a href="/search/q-bio?searchtype=author&query=Yoo%2C+S">Shinjae Yoo</a>, 
<a href="/search/q-bio?searchtype=author&query=Clyde%2C+A">Austin Clyde</a>, 
<a href="/search/q-bio?searchtype=author&query=Ramanathan%2C+A">Arvind Ramanathan</a>, 
<a href="/search/q-bio?searchtype=author&query=Stevens%2C+R+L">Rick L. Stevens</a>, 
<a href="/search/q-bio?searchtype=author&query=van+Dam%2C+H+J+J">Hubertus J. J. van Dam</a>, 
<a href="/search/q-bio?searchtype=author&query=Lu%2C+D">Deyu Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 8 pages, 5 figures, 2 tables, accepted by ICLMA2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Biomolecules (q-bio.BM)</span>; Artificial Intelligence (cs.AI); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item486">[486]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.03046" title="Abstract">arXiv:2308.03046</a> (replaced) [<a href="/pdf/2308.03046" title="Download PDF">pdf</a>, <a href="/ps/2308.03046" title="Download PostScript">ps</a>, <a href="/format/2308.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> On a factorization result of &#x15e;tef&#x103;nescu -- II
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Kumar%2C+S">Sanjeev Kumar</a>, 
<a href="/search/math?searchtype=author&query=Singh%2C+J">Jitender Singh</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> pp5
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Number Theory (math.NT)</span>; Commutative Algebra (math.AC); Numerical Analysis (math.NA)

</div>
</div>
</dd>
<dt><a name="item487">[487]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.05394" title="Abstract">arXiv:2308.05394</a> (replaced) [<a href="/pdf/2308.05394" title="Download PDF">pdf</a>, <a href="/format/2308.05394" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robust Localization with Visual-Inertial Odometry Constraints for  Markerless Mobile AR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Changkun Liu</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+Y">Yukun Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Braud%2C+T">Tristan Braud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item488">[488]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06378" title="Abstract">arXiv:2308.06378</a> (replaced) [<a href="/pdf/2308.06378" title="Download PDF">pdf</a>, <a href="/format/2308.06378" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yeganejou%2C+M">Mojtaba Yeganejou</a>, 
<a href="/search/cs?searchtype=author&query=Honari%2C+K">Kimia Honari</a>, 
<a href="/search/cs?searchtype=author&query=Kluzinski%2C+R">Ryan Kluzinski</a>, 
<a href="/search/cs?searchtype=author&query=Dick%2C+S">Scott Dick</a>, 
<a href="/search/cs?searchtype=author&query=Lipsett%2C+M">Michael Lipsett</a>, 
<a href="/search/cs?searchtype=author&query=Miller%2C+J">James Miller</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item489">[489]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06477" title="Abstract">arXiv:2308.06477</a> (replaced) [<a href="/pdf/2308.06477" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Leveraging multi-view data without annotations for prostate MRI  segmentation: A contrastive approach
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Lindeijer%2C+T+N">Tim Nikolass Lindeijer</a>, 
<a href="/search/eess?searchtype=author&query=Ytredal%2C+T+M">Tord Martin Ytredal</a>, 
<a href="/search/eess?searchtype=author&query=Eftest%C3%B8l%2C+T">Trygve Eftest&#xf8;l</a>, 
<a href="/search/eess?searchtype=author&query=Nordstr%C3%B6m%2C+T">Tobias Nordstr&#xf6;m</a>, 
<a href="/search/eess?searchtype=author&query=J%C3%A4derling%2C+F">Fredrik J&#xe4;derling</a>, 
<a href="/search/eess?searchtype=author&query=Eklund%2C+M">Martin Eklund</a>, 
<a href="/search/eess?searchtype=author&query=Fernandez-Quilez%2C+A">Alvaro Fernandez-Quilez</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Under review
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item490">[490]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.06889" title="Abstract">arXiv:2308.06889</a> (replaced) [<a href="/pdf/2308.06889" title="Download PDF">pdf</a>, <a href="/format/2308.06889" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Robustness Stress Testing in Medical Image Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Islam%2C+M">Mobarakol Islam</a>, 
<a href="/search/eess?searchtype=author&query=Li%2C+Z">Zeju Li</a>, 
<a href="/search/eess?searchtype=author&query=Glocker%2C+B">Ben Glocker</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item491">[491]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.07229" title="Abstract">arXiv:2308.07229</a> (replaced) [<a href="/pdf/2308.07229" title="Download PDF">pdf</a>, <a href="/format/2308.07229" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Compositional nonlinear audio signal processing with Volterra series
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Araujo-Simon%2C+J">Jake Araujo-Simon</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Audio and Speech Processing (eess.AS)</span>; Sound (cs.SD); Signal Processing (eess.SP); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item492">[492]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08469" title="Abstract">arXiv:2308.08469</a> (replaced) [<a href="/pdf/2308.08469" title="Download PDF">pdf</a>, <a href="/format/2308.08469" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with  Pre-Trained LLMs
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Chang%2C+C">Ching Chang</a>, 
<a href="/search/cs?searchtype=author&query=Peng%2C+W">Wen-Chih Peng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+T">Tien-Fu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> This paper is currently under review. The code will be made available upon acceptance
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item493">[493]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.08873" title="Abstract">arXiv:2308.08873</a> (replaced) [<a href="/pdf/2308.08873" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Feature Enforcing PINN (FE-PINN): A Framework for Learning the  Underlying-Physics to Resolve Unbalancing in the Objective Function Terms
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Jahaninasab%2C+M">Mahyar Jahaninasab</a>, 
<a href="/search/cs?searchtype=author&query=Bijarchi%2C+M+A">Mohamad Ali Bijarchi</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 26 pages, 9 figures, 4 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item494">[494]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09308" title="Abstract">arXiv:2308.09308</a> (replaced) [<a href="/pdf/2308.09308" title="Download PDF">pdf</a>, <a href="/format/2308.09308" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Differentiable Retrieval Augmentation via Generative Language Modeling  for E-commerce Query Intent Classification
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Zhao%2C+C">Chenyu Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+Y">Yunjiang Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+Y">Yiming Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+H">Han Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+W">Wen-Yun Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 5 pages, 2 figures; accepted by CIKM2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Retrieval (cs.IR)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item495">[495]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.09729" title="Abstract">arXiv:2308.09729</a> (replaced) [<a href="/pdf/2308.09729" title="Download PDF">pdf</a>, <a href="/format/2308.09729" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large  Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wen%2C+Y">Yilin Wen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Z">Zifeng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Sun%2C+J">Jimeng Sun</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 8 figures, 9 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item496">[496]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10755" title="Abstract">arXiv:2308.10755</a> (replaced) [<a href="/pdf/2308.10755" title="Download PDF">pdf</a>, <a href="/format/2308.10755" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> WanJuan: A Comprehensive Multimodal Dataset for Advancing English and  Chinese Large Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=He%2C+C">Conghui He</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+Z">Zhenjiang Jin</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+C">Chao Xu</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+J">Jiantao Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+W">Wei Li</a>, 
<a href="/search/cs?searchtype=author&query=Yan%2C+H">Hang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Jiaqi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lin%2C+D">Dahua Lin</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Technical Report
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item497">[497]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.10856" title="Abstract">arXiv:2308.10856</a> (replaced) [<a href="/pdf/2308.10856" title="Download PDF">pdf</a>, <a href="/format/2308.10856" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Majorana Demonstrator Data Release for AI/ML Applications
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Arnquist%2C+I+J">I.J. Arnquist</a>, 
<a href="/search/cs?searchtype=author&query=Avignone%2C+F+T">F.T. Avignone III</a>, 
<a href="/search/cs?searchtype=author&query=Barabash%2C+A+S">A.S. Barabash</a>, 
<a href="/search/cs?searchtype=author&query=Barton%2C+C+J">C.J. Barton</a>, 
<a href="/search/cs?searchtype=author&query=Bhimani%2C+K+H">K.H. Bhimani</a>, 
<a href="/search/cs?searchtype=author&query=Blalock%2C+E">E. Blalock</a>, 
<a href="/search/cs?searchtype=author&query=Bos%2C+B">B. Bos</a>, 
<a href="/search/cs?searchtype=author&query=Busch%2C+M">M. Busch</a>, 
<a href="/search/cs?searchtype=author&query=Buuck%2C+M">M. Buuck</a>, 
<a href="/search/cs?searchtype=author&query=Caldwell%2C+T+S">T.S. Caldwell</a>, 
<a href="/search/cs?searchtype=author&query=Chan%2C+Y+-">Y.-D. Chan</a>, 
<a href="/search/cs?searchtype=author&query=Christofferson%2C+C+D">C.D. Christofferson</a>, 
<a href="/search/cs?searchtype=author&query=Chu%2C+P+-">P.-H. Chu</a>, 
<a href="/search/cs?searchtype=author&query=Clark%2C+M+L">M.L. Clark</a>, 
<a href="/search/cs?searchtype=author&query=Cuesta%2C+C">C. Cuesta</a>, 
<a href="/search/cs?searchtype=author&query=Detwiler%2C+J+A">J.A. Detwiler</a>, 
<a href="/search/cs?searchtype=author&query=Efremenko%2C+Y">Yu. Efremenko</a>, 
<a href="/search/cs?searchtype=author&query=Ejiri%2C+H">H. Ejiri</a>, 
<a href="/search/cs?searchtype=author&query=Elliott%2C+S+R">S.R. Elliott</a>, 
<a href="/search/cs?searchtype=author&query=Fuad%2C+N">N. Fuad</a>, 
<a href="/search/cs?searchtype=author&query=Giovanetti%2C+G+K">G.K. Giovanetti</a>, 
<a href="/search/cs?searchtype=author&query=Green%2C+M+P">M.P. Green</a>, 
<a href="/search/cs?searchtype=author&query=Gruszko%2C+J">J. Gruszko</a>, 
<a href="/search/cs?searchtype=author&query=Guinn%2C+I+S">I.S. Guinn</a>, 
<a href="/search/cs?searchtype=author&query=Guiseppe%2C+V+E">V.E. Guiseppe</a>, 
<a href="/search/cs?searchtype=author&query=Haufe%2C+C+R">C.R. Haufe</a>, 
<a href="/search/cs?searchtype=author&query=Henning%2C+R">R. Henning</a>, 
<a href="/search/cs?searchtype=author&query=Aguilar%2C+D+H">D. Hervas Aguilar</a>, 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+E+W">E.W. Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Hostiuc%2C+A">A. Hostiuc</a>, 
<a href="/search/cs?searchtype=author&query=Kidd%2C+M+F">M.F. Kidd</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+I">I. Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kouzes%2C+R+T">R.T. Kouzes</a>, 
<a href="/search/cs?searchtype=author&query=V%2C+T+E+L">T.E. Lannen V</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+A">A. Li</a>, 
<a href="/search/cs?searchtype=author&query=Lopez-Castano%2C+J+M">J.M. Lopez-Castano</a>, 
<a href="/search/cs?searchtype=author&query=Martin%2C+R+D">R.D. Martin</a>, 
<a href="/search/cs?searchtype=author&query=Massarczyk%2C+R">R. Massarczyk</a>, 
<a href="/search/cs?searchtype=author&query=Meijer%2C+S+J">S.J. Meijer</a>, 
<a href="/search/cs?searchtype=author&query=Mertens%2C+S">S. Mertens</a>, 
<a href="/search/cs?searchtype=author&query=Oli%2C+T+K">T.K. Oli</a>, 
<a href="/search/cs?searchtype=author&query=Paudel%2C+L+S">L.S. Paudel</a>, 
<a href="/search/cs?searchtype=author&query=Pettus%2C+W">W. Pettus</a>, 
<a href="/search/cs?searchtype=author&query=Poon%2C+A+W+P">A.W.P. Poon</a>, 
<a href="/search/cs?searchtype=author&query=Quenallata%2C+B">B. Quenallata</a>, 
<a href="/search/cs?searchtype=author&query=Radford%2C+D+C">D.C. Radford</a>, 
<a href="/search/cs?searchtype=author&query=Reine%2C+A+L">A.L. Reine</a>, 
<a href="/search/cs?searchtype=author&query=Rielage%2C+K">K. Rielage</a>, 
<a href="/search/cs?searchtype=author&query=Ruof%2C+N+W">N.W. Ruof</a>, 
<a href="/search/cs?searchtype=author&query=Schaper%2C+D+C">D.C. Schaper</a>, 
<a href="/search/cs?searchtype=author&query=Schleich%2C+S+J">S.J. Schleich</a>, 
<a href="/search/cs?searchtype=author&query=Tedeschi%2C+D">D. Tedeschi</a>, 
<a href="/search/cs?searchtype=author&query=Varner%2C+R+L">R.L. Varner</a>, 
<a href="/search/cs?searchtype=author&query=Vasilyev%2C+S">S. Vasilyev</a>, 
<a href="/search/cs?searchtype=author&query=Watkins%2C+S+L">S.L. Watkins</a>, 
<a href="/search/cs?searchtype=author&query=Wilkerson%2C+J+F">J.F. Wilkerson</a>, 
<a href="/search/cs?searchtype=author&query=Wiseman%2C+C">C. Wiseman</a>, 
<a href="/search/cs?searchtype=author&query=Xu%2C+W">W. Xu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+C+-">C.-H. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+B+X">B.X. Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> DataPlanet Access: <a href="https://dataplanet.ucsd.edu/dataset.xhtml?persistentId=perma:83.ucsddata/UQWQAV">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Nuclear Experiment (nucl-ex); Data Analysis, Statistics and Probability (physics.data-an); Instrumentation and Detectors (physics.ins-det)

</div>
</div>
</dd>
<dt><a name="item498">[498]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.13981" title="Abstract">arXiv:2308.13981</a> (replaced) [<a href="/pdf/2308.13981" title="Download PDF">pdf</a>, <a href="/format/2308.13981" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Lattice Codes for CRYSTALS-Kyber
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Liu%2C+S">Shuiyin Liu</a>, 
<a href="/search/cs?searchtype=author&query=Sakzad%2C+A">Amin Sakzad</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages,3 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Information Theory (cs.IT)</span>

</div>
</div>
</dd>
<dt><a name="item499">[499]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2308.15039" title="Abstract">arXiv:2308.15039</a> (replaced) [<a href="/pdf/2308.15039" title="Download PDF">pdf</a>, <a href="/format/2308.15039" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> R^3: On-device Real-Time Deep Reinforcement Learning for Autonomous  Robotics
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Z">Zexin Li</a>, 
<a href="/search/cs?searchtype=author&query=Samanta%2C+A">Aritra Samanta</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yufei Li</a>, 
<a href="/search/cs?searchtype=author&query=Soltoggio%2C+A">Andrea Soltoggio</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Hyoseung Kim</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Cong Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted by RTSS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Artificial Intelligence (cs.AI); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item500">[500]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.00655" title="Abstract">arXiv:2309.00655</a> (replaced) [<a href="/pdf/2309.00655" title="Download PDF">pdf</a>, <a href="/format/2309.00655" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> RigNet++: Efficient Repetitive Image Guided Network for Depth Completion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Yan%2C+Z">Zhiqiang Yan</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+X">Xiang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Z">Zhenyu Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jun Li</a>, 
<a href="/search/cs?searchtype=author&query=Yang%2C+J">Jian Yang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 15 pages. arXiv admin note: text overlap with <a href="/abs/2107.13802">arXiv:2107.13802</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item501">[501]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01167" title="Abstract">arXiv:2309.01167</a> (replaced) [<a href="/pdf/2309.01167" title="Download PDF">pdf</a>, <a href="/format/2309.01167" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Symbolically integrating tensor networks over various random tensors by  the second version of Python RTNI
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/physics?searchtype=author&query=Fukuda%2C+M">Motohisa Fukuda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The title was slitely changed, typos were fixed. PyRTNI2 is available at <a href="https://github.com/MotohisaFukuda/PyRTNI2">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Physics (physics.comp-ph)</span>; Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG); High Energy Physics - Theory (hep-th); Mathematical Physics (math-ph)

</div>
</div>
</dd>
<dt><a name="item502">[502]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.01632" title="Abstract">arXiv:2309.01632</a> (replaced) [<a href="/pdf/2309.01632" title="Download PDF">pdf</a>, <a href="/format/2309.01632" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Representing Edge Flows on Graphs via Sparse Cell Complexes
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hoppe%2C+J">Josef Hoppe</a>, 
<a href="/search/cs?searchtype=author&query=Schaub%2C+M+T">Michael T. Schaub</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 9 pages, 6 figures (plus appendix). For evaluation code, see <a href="https://anonymous.4open.science/r/edge-flow-repr-cell-complexes-11C5">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Machine Learning (cs.LG); Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item503">[503]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02014" title="Abstract">arXiv:2309.02014</a> (replaced) [<a href="/pdf/2309.02014" title="Download PDF">pdf</a>, <a href="/format/2309.02014" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> PROMISE: Preconditioned Stochastic Optimization Methods by Incorporating  Scalable Curvature Estimates
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/math?searchtype=author&query=Frangella%2C+Z">Zachary Frangella</a>, 
<a href="/search/math?searchtype=author&query=Rathore%2C+P">Pratik Rathore</a>, 
<a href="/search/math?searchtype=author&query=Zhao%2C+S">Shipu Zhao</a>, 
<a href="/search/math?searchtype=author&query=Udell%2C+M">Madeleine Udell</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 128 pages, 31 Figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Optimization and Control (math.OC)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item504">[504]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02338" title="Abstract">arXiv:2309.02338</a> (replaced) [<a href="/pdf/2309.02338" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sustainability assessment of Low Earth Orbit (LEO) satellite broadband  mega-constellations
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/astro-ph?searchtype=author&query=Osoro%2C+O+B">Ogutu B. Osoro</a>, 
<a href="/search/astro-ph?searchtype=author&query=Oughton%2C+E+J">Edward J. Oughton</a>, 
<a href="/search/astro-ph?searchtype=author&query=Wilson%2C+A+R">Andrew R. Wilson</a>, 
<a href="/search/astro-ph?searchtype=author&query=Rao%2C+A">Akhil Rao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Earth and Planetary Astrophysics (astro-ph.EP)</span>; General Economics (econ.GN); Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item505">[505]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02706" title="Abstract">arXiv:2309.02706</a> (replaced) [<a href="/pdf/2309.02706" title="Download PDF">pdf</a>, <a href="/format/2309.02706" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Son%2C+G">Guijin Son</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+H">Hanwool Lee</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Suwan Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+H">Huiseo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Lee%2C+J">Jaecheol Lee</a>, 
<a href="/search/cs?searchtype=author&query=Yeom%2C+J+W">Je Won Yeom</a>, 
<a href="/search/cs?searchtype=author&query=Jung%2C+J">Jihyu Jung</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+J+W">Jung Woo Kim</a>, 
<a href="/search/cs?searchtype=author&query=Kim%2C+S">Songseong Kim</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Work in Progress. Error in evaluation results. For the updated version of evaluation pleaser refer to : <a href="https://github.com/HAETAE-project/HAE-RAE-BENCH">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item506">[506]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.02852" title="Abstract">arXiv:2309.02852</a> (replaced) [<a href="/pdf/2309.02852" title="Download PDF">pdf</a>, <a href="/format/2309.02852" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CelticGraph: Drawing Graphs as Celtic Knots and Links
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Eades%2C+P">Peter Eades</a>, 
<a href="/search/cs?searchtype=author&query=Gr%C3%B6ne%2C+N">Niklas Gr&#xf6;ne</a>, 
<a href="/search/cs?searchtype=author&query=Klein%2C+K">Karsten Klein</a>, 
<a href="/search/cs?searchtype=author&query=Eades%2C+P">Patrick Eades</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+L">Leo Schreiber</a>, 
<a href="/search/cs?searchtype=author&query=Hailer%2C+U">Ulf Hailer</a>, 
<a href="/search/cs?searchtype=author&query=Schreiber%2C+F">Falk Schreiber</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Appears in the Proceedings of the 31st International Symposium on Graph Drawing and Network Visualization (GD 2023)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computational Geometry (cs.CG)</span>

</div>
</div>
</dd>
<dt><a name="item507">[507]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03046" title="Abstract">arXiv:2309.03046</a> (replaced) [<a href="/pdf/2309.03046" title="Download PDF">pdf</a>, <a href="/format/2309.03046" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Grove: a Separation-Logic Library for Verifying Distributed Systems  (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sharma%2C+U">Upamanyu Sharma</a> (MIT), 
<a href="/search/cs?searchtype=author&query=Jung%2C+R">Ralf Jung</a> (ETH Zurich), 
<a href="/search/cs?searchtype=author&query=Tassarotti%2C+J">Joseph Tassarotti</a> (NYU), 
<a href="/search/cs?searchtype=author&query=Kaashoek%2C+M+F">M. Frans Kaashoek</a> (MIT), 
<a href="/search/cs?searchtype=author&query=Zeldovich%2C+N">Nickolai Zeldovich</a> (MIT)
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Extended version of paper appearing at SOSP 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Logic in Computer Science (cs.LO)</span>; Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item508">[508]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03126" title="Abstract">arXiv:2309.03126</a> (replaced) [<a href="/pdf/2309.03126" title="Download PDF">pdf</a>, <a href="/format/2309.03126" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Everyone Deserves A Reward: Learning Customized Human Preferences
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cheng%2C+P">Pengyu Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Xie%2C+J">Jiawen Xie</a>, 
<a href="/search/cs?searchtype=author&query=Bai%2C+K">Ke Bai</a>, 
<a href="/search/cs?searchtype=author&query=Dai%2C+Y">Yong Dai</a>, 
<a href="/search/cs?searchtype=author&query=Du%2C+N">Nan Du</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item509">[509]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03292" title="Abstract">arXiv:2309.03292</a> (replaced) [<a href="/pdf/2309.03292" title="Download PDF">pdf</a>, <a href="/format/2309.03292" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Scalable Learning of Intrusion Responses through Recursive Decomposition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Hammar%2C+K">Kim Hammar</a>, 
<a href="/search/eess?searchtype=author&query=Stadler%2C+R">Rolf Stadler</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> A shortened version of this paper will appear in the conference proceedings of GameSec 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Cryptography and Security (cs.CR); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item510">[510]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03554" title="Abstract">arXiv:2309.03554</a> (replaced) [<a href="/pdf/2309.03554" title="Download PDF">pdf</a>, <a href="/format/2309.03554" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Software Testing of Generative AI Systems: Challenges and Opportunities
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Aleti%2C+A">Aldeida Aleti</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item511">[511]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03851" title="Abstract">arXiv:2309.03851</a> (replaced) [<a href="/pdf/2309.03851" title="Download PDF">pdf</a>, <a href="/format/2309.03851" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CenTime: Event-Conditional Modelling of Censoring in Survival Analysis
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Shahin%2C+A+H">Ahmed H. Shahin</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+A">An Zhao</a>, 
<a href="/search/cs?searchtype=author&query=Whitehead%2C+A+C">Alexander C. Whitehead</a>, 
<a href="/search/cs?searchtype=author&query=Alexander%2C+D+C">Daniel C. Alexander</a>, 
<a href="/search/cs?searchtype=author&query=Jacob%2C+J">Joseph Jacob</a>, 
<a href="/search/cs?searchtype=author&query=Barber%2C+D">David Barber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Computer Vision and Pattern Recognition (cs.CV)

</div>
</div>
</dd>
<dt><a name="item512">[512]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.03989" title="Abstract">arXiv:2309.03989</a> (replaced) [<a href="/pdf/2309.03989" title="Download PDF">pdf</a>, <a href="/format/2309.03989" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CDFSL-V: Cross-Domain Few-Shot Learning for Videos
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Samarasinghe%2C+S">Sarinda Samarasinghe</a>, 
<a href="/search/cs?searchtype=author&query=Rizve%2C+M+N">Mamshad Nayeem Rizve</a>, 
<a href="/search/cs?searchtype=author&query=Kardan%2C+N">Navid Kardan</a>, 
<a href="/search/cs?searchtype=author&query=Shah%2C+M">Mubarak Shah</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item513">[513]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04278" title="Abstract">arXiv:2309.04278</a> (replaced) [<a href="/pdf/2309.04278" title="Download PDF">pdf</a>, <a href="/format/2309.04278" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> How can feature usage be tracked across product variants? Implicit  Feedback in Software Product Lines
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=D%C3%ADaz%2C+O">Oscar D&#xed;az</a>, 
<a href="/search/cs?searchtype=author&query=Medeiros%2C+R">Raul Medeiros</a>, 
<a href="/search/cs?searchtype=author&query=Al-Hajjaji%2C+M">Mustafa Al-Hajjaji</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Software Engineering (cs.SE)</span>

</div>
</div>
</dd>
<dt><a name="item514">[514]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.04723" title="Abstract">arXiv:2309.04723</a> (replaced) [<a href="/pdf/2309.04723" title="Download PDF">pdf</a>, <a href="/format/2309.04723" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency-Aware Self-Supervised Long-Tailed Learning
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Lin%2C+C">Ci-Siang Lin</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+M">Min-Hung Chen</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y+F">Yu-Chiang Frank Wang</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> ICCV Workshop 2023 (Oral)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item515">[515]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05300" title="Abstract">arXiv:2309.05300</a> (replaced) [<a href="/pdf/2309.05300" title="Download PDF">pdf</a>, <a href="/format/2309.05300" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> DeCUR: decoupling common &amp; unique representations for multimodal  self-supervision
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yi Wang</a>, 
<a href="/search/cs?searchtype=author&query=Albrecht%2C+C+M">Conrad M Albrecht</a>, 
<a href="/search/cs?searchtype=author&query=Braham%2C+N+A+A">Nassim Ait Ali Braham</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+C">Chenying Liu</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+Z">Zhitong Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhu%2C+X+X">Xiao Xiang Zhu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 19 pages, 10 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item516">[516]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05395" title="Abstract">arXiv:2309.05395</a> (replaced) [<a href="/pdf/2309.05395" title="Download PDF">pdf</a>, <a href="/format/2309.05395" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Practical Homomorphic Aggregation for Byzantine ML
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Choffrut%2C+A">Antoine Choffrut</a>, 
<a href="/search/cs?searchtype=author&query=Guerraoui%2C+R">Rachid Guerraoui</a>, 
<a href="/search/cs?searchtype=author&query=Pinot%2C+R">Rafael Pinot</a>, 
<a href="/search/cs?searchtype=author&query=Sirdey%2C+R">Renaud Sirdey</a>, 
<a href="/search/cs?searchtype=author&query=Stephan%2C+J">John Stephan</a>, 
<a href="/search/cs?searchtype=author&query=Zuber%2C+M">Martin Zuber</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Cryptography and Security (cs.CR); Distributed, Parallel, and Cluster Computing (cs.DC)

</div>
</div>
</dd>
<dt><a name="item517">[517]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05499" title="Abstract">arXiv:2309.05499</a> (replaced) [<a href="/pdf/2309.05499" title="Download PDF">pdf</a>, <a href="/format/2309.05499" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Zero-Shot Co-salient Object Detection Framework
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xiao%2C+H">Haoke Xiao</a>, 
<a href="/search/cs?searchtype=author&query=Tang%2C+L">Lv Tang</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+B">Bo Li</a>, 
<a href="/search/cs?searchtype=author&query=Luo%2C+Z">Zhiming Luo</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+S">Shaozi Li</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item518">[518]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05595" title="Abstract">arXiv:2309.05595</a> (replaced) [<a href="/pdf/2309.05595" title="Download PDF">pdf</a>, <a href="/ps/2309.05595" title="Download PostScript">ps</a>, <a href="/format/2309.05595" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Undecidability Results and Their Relevance in Modern Music Making
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Young%2C+H">Halley Young</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item519">[519]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05840" title="Abstract">arXiv:2309.05840</a> (replaced) [<a href="/pdf/2309.05840" title="Download PDF">pdf</a>, <a href="/format/2309.05840" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Self-Correlation and Cross-Correlation Learning for Few-Shot Remote  Sensing Image Semantic Segmentation
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+L">Linhan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Lei%2C+S">Shuo Lei</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+J">Jianfeng He</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+S">Shengkun Wang</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Min Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Lu%2C+C">Chang-Tien Lu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 10 pages, 6 figures. Accepted to Sigspatial 2023. arXiv admin note: text overlap with <a href="/abs/2104.01538">arXiv:2104.01538</a> by other authors
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item520">[520]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.05955" title="Abstract">arXiv:2309.05955</a> (replaced) [<a href="/pdf/2309.05955" title="Download PDF">pdf</a>, <a href="/format/2309.05955" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Trust-Region Neural Moving Horizon Estimation for Robots
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Wang%2C+B">Bingheng Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xuyang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Zhao%2C+L">Lin Zhao</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>; Systems and Control (eess.SY)

</div>
</div>
</dd>
<dt><a name="item521">[521]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06584" title="Abstract">arXiv:2309.06584</a> (replaced) [<a href="/pdf/2309.06584" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Explainable Graph Neural Network for Alzheimer&#x27;s Disease And Related  Dementias Risk Prediction
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+X">Xinyue Hu</a> (1), 
<a href="/search/cs?searchtype=author&query=Sun%2C+Z">Zenan Sun</a> (1), 
<a href="/search/cs?searchtype=author&query=Nian%2C+Y">Yi Nian</a> (1), 
<a href="/search/cs?searchtype=author&query=Dang%2C+Y">Yifang Dang</a> (1), 
<a href="/search/cs?searchtype=author&query=Li%2C+F">Fang Li</a> (1), 
<a href="/search/cs?searchtype=author&query=Feng%2C+J">Jingna Feng</a> (1), 
<a href="/search/cs?searchtype=author&query=Yu%2C+E">Evan Yu</a> (1), 
<a href="/search/cs?searchtype=author&query=Tao%2C+C">Cui Tao</a> (1) ((1) The University of Texas Health Science Center at Houston)
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>

</div>
</div>
</dd>
<dt><a name="item522">[522]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06588" title="Abstract">arXiv:2309.06588</a> (replaced) [<a href="/pdf/2309.06588" title="Download PDF">pdf</a>, <a href="/format/2309.06588" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Convergence of Gradient-based MAML in LQR
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Musavi%2C+N">Negin Musavi</a>, 
<a href="/search/eess?searchtype=author&query=Dullerud%2C+G+E">Geir E. Dullerud</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Systems and Control (eess.SY)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item523">[523]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06611" title="Abstract">arXiv:2309.06611</a> (replaced) [<a href="/pdf/2309.06611" title="Download PDF">pdf</a>, <a href="/format/2309.06611" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Enabling the Deployment of Any-Scale Robotic Applications in  Microservice Architectures through Automated Containerization
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Busch%2C+J">Jean-Pierre Busch</a>, 
<a href="/search/cs?searchtype=author&query=Reiher%2C+L">Lennart Reiher</a>, 
<a href="/search/cs?searchtype=author&query=Eckstein%2C+L">Lutz Eckstein</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 6 pages; Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2024
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Robotics (cs.RO)</span>

</div>
</div>
</dd>
<dt><a name="item524">[524]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06721" title="Abstract">arXiv:2309.06721</a> (replaced) [<a href="/pdf/2309.06721" title="Download PDF">pdf</a>, <a href="/format/2309.06721" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Dynamic Spectrum Mixer for Visual Recognition
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Hu%2C+Z">Zhiqiang Hu</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+T">Tao Yu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item525">[525]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06745" title="Abstract">arXiv:2309.06745</a> (replaced) [<a href="/pdf/2309.06745" title="Download PDF">pdf</a>, <a href="/format/2309.06745" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> VEATIC: Video-based Emotion and Affect Tracking in Context Dataset
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ren%2C+Z">Zhihang Ren</a>, 
<a href="/search/cs?searchtype=author&query=Ortega%2C+J">Jefferson Ortega</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+Y">Yifan Wang</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+Z">Zhimin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+Y">Yunhui Guo</a>, 
<a href="/search/cs?searchtype=author&query=Yu%2C+S+X">Stella X. Yu</a>, 
<a href="/search/cs?searchtype=author&query=Whitney%2C+D">David Whitney</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>; Human-Computer Interaction (cs.HC); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item526">[526]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06800" title="Abstract">arXiv:2309.06800</a> (replaced) [<a href="/pdf/2309.06800" title="Download PDF">pdf</a>, <a href="/format/2309.06800" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Uncertainty-aware Traffic Prediction under Missing Data
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Mei%2C+H">Hao Mei</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Junxian Li</a>, 
<a href="/search/cs?searchtype=author&query=Liang%2C+Z">Zhiming Liang</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+G">Guanjie Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Shi%2C+B">Bin Shi</a>, 
<a href="/search/cs?searchtype=author&query=Wei%2C+H">Hua Wei</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 11 pages, 3 figures, Accepted as a short paper of IEEE International Conference on Data Mining (ICDM) 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Artificial Intelligence (cs.AI)

</div>
</div>
</dd>
<dt><a name="item527">[527]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06927" title="Abstract">arXiv:2309.06927</a> (replaced) [<a href="/pdf/2309.06927" title="Download PDF">pdf</a>, <a href="/format/2309.06927" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> OMOD: An open-source tool for creating disaggregated mobility demand  based on OpenStreetMap
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Strobel%2C+L">Leo Strobel</a>, 
<a href="/search/cs?searchtype=author&query=Pruckner%2C+M">Marco Pruckner</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Accepted version
</div>
<div class="list-journal-ref">
<span class="descriptor">Journal-ref:</span> Computers, Environment and Urban Systems, Volume 106, December
  2023, 102029
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computers and Society (cs.CY)</span>

</div>
</div>
</dd>
<dt><a name="item528">[528]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.06938" title="Abstract">arXiv:2309.06938</a> (replaced) [<a href="/pdf/2309.06938" title="Download PDF">pdf</a>, <a href="/format/2309.06938" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Collectionless Artificial Intelligence
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Gori%2C+M">Marco Gori</a>, 
<a href="/search/cs?searchtype=author&query=Melacci%2C+S">Stefano Melacci</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computers and Society (cs.CY); Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item529">[529]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07033" title="Abstract">arXiv:2309.07033</a> (replaced) [<a href="/pdf/2309.07033" title="Download PDF">pdf</a>, <a href="/format/2309.07033" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Human-Robot Co-Creativity: A Scoping Review -- Informing a Research  Agenda for Human-Robot Co-Creativity with Older Adults
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Bossema%2C+M">Marianne Bossema</a>, 
<a href="/search/cs?searchtype=author&query=Allouch%2C+S+B">Somaya Ben Allouch</a>, 
<a href="/search/cs?searchtype=author&query=Plaat%2C+A">Aske Plaat</a>, 
<a href="/search/cs?searchtype=author&query=Saunders%2C+R">Rob Saunders</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>

</div>
</div>
</dd>
<dt><a name="item530">[530]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07075" title="Abstract">arXiv:2309.07075</a> (replaced) [<a href="/pdf/2309.07075" title="Download PDF">pdf</a>, <a href="/format/2309.07075" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Chained-DP: Can We Recycle Privacy Budget?
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jingyi Li</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+G">Guangjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Zeng%2C+L">Liekang Zeng</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+L">Lin Chen</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+X">Xu Chen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> The paper was accepted by IEEE/ACM IWQoS 2023
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>; Distributed, Parallel, and Cluster Computing (cs.DC); Computer Science and Game Theory (cs.GT)

</div>
</div>
</dd>
<dt><a name="item531">[531]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07161" title="Abstract">arXiv:2309.07161</a> (replaced) [<a href="/pdf/2309.07161" title="Download PDF">pdf</a>, <a href="/ps/2309.07161" title="Download PostScript">ps</a>, <a href="/format/2309.07161" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Sumplete is Hard, Even with Two Different Numbers
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Ruangwises%2C+S">Suthee Ruangwises</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Data Structures and Algorithms (cs.DS)</span>; Computational Complexity (cs.CC)

</div>
</div>
</dd>
<dt><a name="item532">[532]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07169" title="Abstract">arXiv:2309.07169</a> (replaced) [<a href="/pdf/2309.07169" title="Download PDF">pdf</a>, <a href="/format/2309.07169" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Frequency Convergence of Complexon Shift Operators (Extended Version)
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Zhang%2C+P">Purui Zhang</a>, 
<a href="/search/eess?searchtype=author&query=Jian%2C+X">Xingchao Jian</a>, 
<a href="/search/eess?searchtype=author&query=Ji%2C+F">Feng Ji</a>, 
<a href="/search/eess?searchtype=author&query=Tay%2C+W+P">Wee Peng Tay</a>, 
<a href="/search/eess?searchtype=author&query=Wen%2C+B">Bihan Wen</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 7 pages, 1 figure
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Signal Processing (eess.SP)</span>; Machine Learning (cs.LG)

</div>
</div>
</dd>
<dt><a name="item533">[533]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07563" title="Abstract">arXiv:2309.07563</a> (replaced) [<a href="/pdf/2309.07563" title="Download PDF">pdf</a>, <a href="/format/2309.07563" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Keep your Identity Small: Privacy-preserving Client-side Fingerprinting
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Fernandez-de-Retana%2C+A">Alberto Fernandez-de-Retana</a>, 
<a href="/search/cs?searchtype=author&query=Santos-Grueiro%2C+I">Igor Santos-Grueiro</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Cryptography and Security (cs.CR)</span>

</div>
</div>
</dd>
<dt><a name="item534">[534]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07579" title="Abstract">arXiv:2309.07579</a> (replaced) [<a href="/pdf/2309.07579" title="Download PDF">pdf</a>, <a href="/format/2309.07579" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Structure-Preserving Transformers for Sequences of SPD Matrices
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Seraphim%2C+M">Mathieu Seraphim</a>, 
<a href="/search/cs?searchtype=author&query=Lechervy%2C+A">Alexis Lechervy</a>, 
<a href="/search/cs?searchtype=author&query=Yger%2C+F">Florian Yger</a>, 
<a href="/search/cs?searchtype=author&query=Brun%2C+L">Luc Brun</a>, 
<a href="/search/cs?searchtype=author&query=Etard%2C+O">Olivier Etard</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to the ICASSP 2024 Conference. Error correction relative to v1: Section 1, changed "less anisotropic" to "less isotropic"
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Machine Learning (cs.LG)</span>; Signal Processing (eess.SP)

</div>
</div>
</dd>
<dt><a name="item535">[535]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07598" title="Abstract">arXiv:2309.07598</a> (replaced) [<a href="/pdf/2309.07598" title="Download PDF">pdf</a>, <a href="/format/2309.07598" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> AAS-VC: On the Generalization Ability of Automatic Alignment Search  based Non-autoregressive Sequence-to-sequence Voice Conversion
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Huang%2C+W">Wen-Chin Huang</a>, 
<a href="/search/cs?searchtype=author&query=Kobayashi%2C+K">Kazuhiro Kobayashi</a>, 
<a href="/search/cs?searchtype=author&query=Toda%2C+T">Tomoki Toda</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Submitted to ICASSP 2024. Demo: <a href="https://unilight.github.io/Publication-Demos/publications/aas-vc/index.html.">this https URL</a> Code: <a href="https://github.com/unilight/seq2seq-vc">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Sound (cs.SD)</span>; Audio and Speech Processing (eess.AS)

</div>
</div>
</dd>
<dt><a name="item536">[536]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07745" title="Abstract">arXiv:2309.07745</a> (replaced) [<a href="/pdf/2309.07745" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Disinformation Echo-chambers on Facebook
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=de-Lima-Santos%2C+M">Mathias-Felipe de-Lima-Santos</a>, 
<a href="/search/cs?searchtype=author&query=Ceron%2C+W">Wilson Ceron</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Social and Information Networks (cs.SI)</span>; Computers and Society (cs.CY)

</div>
</div>
</dd>
<dt><a name="item537">[537]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07773" title="Abstract">arXiv:2309.07773</a> (replaced) [<a href="/pdf/2309.07773" title="Download PDF">pdf</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games:  A Usability Assessment
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Korre%2C+D">Danai Korre</a>, 
<a href="/search/cs?searchtype=author&query=Robertson%2C+J">Judy Robertson</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 46 pages, 9 figures, 14 tables
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Human-Computer Interaction (cs.HC)</span>; Computation and Language (cs.CL); Multimedia (cs.MM)

</div>
</div>
</dd>
<dt><a name="item538">[538]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07778" title="Abstract">arXiv:2309.07778</a> (replaced) [<a href="/pdf/2309.07778" title="Download PDF">pdf</a>, <a href="/format/2309.07778" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Virchow: A Million-Slide Digital Pathology Foundation Model
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/eess?searchtype=author&query=Vorontsov%2C+E">Eugene Vorontsov</a>, 
<a href="/search/eess?searchtype=author&query=Bozkurt%2C+A">Alican Bozkurt</a>, 
<a href="/search/eess?searchtype=author&query=Casson%2C+A">Adam Casson</a>, 
<a href="/search/eess?searchtype=author&query=Shaikovski%2C+G">George Shaikovski</a>, 
<a href="/search/eess?searchtype=author&query=Zelechowski%2C+M">Michal Zelechowski</a>, 
<a href="/search/eess?searchtype=author&query=Liu%2C+S">Siqi Liu</a>, 
<a href="/search/eess?searchtype=author&query=Mathieu%2C+P">Philippe Mathieu</a>, 
<a href="/search/eess?searchtype=author&query=van+Eck%2C+A">Alexander van Eck</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+D">Donghun Lee</a>, 
<a href="/search/eess?searchtype=author&query=Viret%2C+J">Julian Viret</a>, 
<a href="/search/eess?searchtype=author&query=Robert%2C+E">Eric Robert</a>, 
<a href="/search/eess?searchtype=author&query=Wang%2C+Y+K">Yi Kan Wang</a>, 
<a href="/search/eess?searchtype=author&query=Kunz%2C+J+D">Jeremy D. Kunz</a>, 
<a href="/search/eess?searchtype=author&query=Lee%2C+M+C+H">Matthew C. H. Lee</a>, 
<a href="/search/eess?searchtype=author&query=Bernhard%2C+J">Jan Bernhard</a>, 
<a href="/search/eess?searchtype=author&query=Godrich%2C+R+A">Ran A. Godrich</a>, 
<a href="/search/eess?searchtype=author&query=Oakley%2C+G">Gerard Oakley</a>, 
<a href="/search/eess?searchtype=author&query=Millar%2C+E">Ewan Millar</a>, 
<a href="/search/eess?searchtype=author&query=Hanna%2C+M">Matthew Hanna</a>, 
<a href="/search/eess?searchtype=author&query=Retamero%2C+J">Juan Retamero</a>, 
<a href="/search/eess?searchtype=author&query=Moye%2C+W+A">William A. Moye</a>, 
<a href="/search/eess?searchtype=author&query=Yousfi%2C+R">Razik Yousfi</a>, 
<a href="/search/eess?searchtype=author&query=Kanan%2C+C">Christopher Kanan</a>, 
<a href="/search/eess?searchtype=author&query=Klimstra%2C+D">David Klimstra</a>, 
<a href="/search/eess?searchtype=author&query=Rothrock%2C+B">Brandon Rothrock</a>, 
<a href="/search/eess?searchtype=author&query=Fuchs%2C+T+J">Thomas J. Fuchs</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Image and Video Processing (eess.IV)</span>; Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Tissues and Organs (q-bio.TO)

</div>
</div>
</dd>
<dt><a name="item539">[539]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07796" title="Abstract">arXiv:2309.07796</a> (replaced) [<a href="/pdf/2309.07796" title="Download PDF">pdf</a>, <a href="/format/2309.07796" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> For A More Comprehensive Evaluation of 6DoF Object Pose Tracking
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Li%2C+Y">Yang Li</a>, 
<a href="/search/cs?searchtype=author&query=Zhong%2C+F">Fan Zhong</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xin Wang</a>, 
<a href="/search/cs?searchtype=author&query=Song%2C+S">Shuangbing Song</a>, 
<a href="/search/cs?searchtype=author&query=Li%2C+J">Jiachen Li</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+X">Xueying Qin</a>, 
<a href="/search/cs?searchtype=author&query=Tu%2C+C">Changhe Tu</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
<dt><a name="item540">[540]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07822" title="Abstract">arXiv:2309.07822</a> (replaced) [<a href="/pdf/2309.07822" title="Download PDF">pdf</a>, <a href="/format/2309.07822" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain  Performance and Calibration
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Sachdeva%2C+R">Rachneet Sachdeva</a>, 
<a href="/search/cs?searchtype=author&query=Tutek%2C+M">Martin Tutek</a>, 
<a href="/search/cs?searchtype=author&query=Gurevych%2C+I">Iryna Gurevych</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> We make our code available at: <a href="https://github.com/UKPLab/CATfOOD">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computation and Language (cs.CL)</span>

</div>
</div>
</dd>
<dt><a name="item541">[541]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07864" title="Abstract">arXiv:2309.07864</a> (replaced) [<a href="/pdf/2309.07864" title="Download PDF">pdf</a>, <a href="/format/2309.07864" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> The Rise and Potential of Large Language Model Based Agents: A Survey
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Xi%2C+Z">Zhiheng Xi</a>, 
<a href="/search/cs?searchtype=author&query=Chen%2C+W">Wenxiang Chen</a>, 
<a href="/search/cs?searchtype=author&query=Guo%2C+X">Xin Guo</a>, 
<a href="/search/cs?searchtype=author&query=He%2C+W">Wei He</a>, 
<a href="/search/cs?searchtype=author&query=Ding%2C+Y">Yiwen Ding</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+B">Boyang Hong</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+M">Ming Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+J">Junzhe Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jin%2C+S">Senjie Jin</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+E">Enyu Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+R">Rui Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Fan%2C+X">Xiaoran Fan</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+X">Xiao Wang</a>, 
<a href="/search/cs?searchtype=author&query=Xiong%2C+L">Limao Xiong</a>, 
<a href="/search/cs?searchtype=author&query=Zhou%2C+Y">Yuhao Zhou</a>, 
<a href="/search/cs?searchtype=author&query=Wang%2C+W">Weiran Wang</a>, 
<a href="/search/cs?searchtype=author&query=Jiang%2C+C">Changhao Jiang</a>, 
<a href="/search/cs?searchtype=author&query=Zou%2C+Y">Yicheng Zou</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+X">Xiangyang Liu</a>, 
<a href="/search/cs?searchtype=author&query=Yin%2C+Z">Zhangyue Yin</a>, 
<a href="/search/cs?searchtype=author&query=Dou%2C+S">Shihan Dou</a>, 
<a href="/search/cs?searchtype=author&query=Weng%2C+R">Rongxiang Weng</a>, 
<a href="/search/cs?searchtype=author&query=Cheng%2C+W">Wensen Cheng</a>, 
<a href="/search/cs?searchtype=author&query=Zhang%2C+Q">Qi Zhang</a>, 
<a href="/search/cs?searchtype=author&query=Qin%2C+W">Wenjuan Qin</a>, 
<a href="/search/cs?searchtype=author&query=Zheng%2C+Y">Yongyan Zheng</a>, 
<a href="/search/cs?searchtype=author&query=Qiu%2C+X">Xipeng Qiu</a>, 
<a href="/search/cs?searchtype=author&query=Huang%2C+X">Xuanjing Huang</a>, 
<a href="/search/cs?searchtype=author&query=Gui%2C+T">Tao Gui</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> 86 pages, 12 figures
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Artificial Intelligence (cs.AI)</span>; Computation and Language (cs.CL)

</div>
</div>
</dd>
<dt><a name="item542">[542]</a>&nbsp;  <span class="list-identifier"><a href="/abs/2309.07920" title="Abstract">arXiv:2309.07920</a> (replaced) [<a href="/pdf/2309.07920" title="Download PDF">pdf</a>, <a href="/format/2309.07920" title="Other formats">other</a>]</span></dt>
<dd>
<div class="meta">
<div class="list-title mathjax">
<span class="descriptor">Title:</span> Large-Vocabulary 3D Diffusion Model with Transformer
</div>
<div class="list-authors">
<span class="descriptor">Authors:</span> 
<a href="/search/cs?searchtype=author&query=Cao%2C+Z">Ziang Cao</a>, 
<a href="/search/cs?searchtype=author&query=Hong%2C+F">Fangzhou Hong</a>, 
<a href="/search/cs?searchtype=author&query=Wu%2C+T">Tong Wu</a>, 
<a href="/search/cs?searchtype=author&query=Pan%2C+L">Liang Pan</a>, 
<a href="/search/cs?searchtype=author&query=Liu%2C+Z">Ziwei Liu</a>
</div>
<div class="list-comments mathjax">
<span class="descriptor">Comments:</span> Project page at <a href="https://ziangcao0312.github.io/difftf_pages/">this https URL</a>
</div>
<div class="list-subjects">
<span class="descriptor">Subjects:</span> <span class="primary-subject">Computer Vision and Pattern Recognition (cs.CV)</span>

</div>
</div>
</dd>
</dl>
<ul>
<li><a href="/list/cs/new?skip=0&amp;show=2000">New submissions</a></li>
<li><a href="#item292">Cross-lists</a></li>
<li><a href="#item358">Replacements</a></li>
</ul>
<small>[ total of 542 entries:  <b>1-542</b>  ]</small><br />
<small>[ showing up to 2000 entries per page:  <a href="/list/cs/new?skip=0&amp;show=1000">fewer</a> |  <font color="#999999">more</font> ]</small><br />
</div>
<br/><small><a id="mathjax_toggle" href="javascript:setMathjaxCookie()">Disable MathJax</a> (<a href="/help/mathjax">What is MathJax?</a>)</small><script type="text/javascript" language="javascript">mathjaxToggle();</script>

<hr />
<p>Links to:
<a href="/" accesskey="a">arXiv</a>,
<a href="/form/cs">form interface</a>,
<a href="/find/cs">find</a>,
<a href="/archive/cs">cs</a>, <a href="/list/cs/recent">recent</a>, <a href="/list/cs/2309">2309</a>,
<a href="/help/contact">contact</a>,
<a href="/help/" accesskey="h"><span class="accesskey">h</span>elp</a>&nbsp;
<small>(<a href="/help/accesskeys">Access key</a> information)</small>
</p>
<hr />
</div>
</div>
 <footer style="clear: both;">
      <div class="columns is-desktop" role="navigation" aria-label="Secondary" style="margin: -0.75em -0.75em 0.75em -0.75em">
        <!-- Macro-Column 1 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/about">About</a></li>
                <li><a href="https://arxiv.org/help">Help</a></li>
              </ul>
            </div>
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
                  <a href="https://arxiv.org/help/contact"> Contact</a>
                </li>
                <li>
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
                  <a href="https://arxiv.org/help/subscribe"> Subscribe</a>
                </li>
              </ul>
            </div>
          </div>
        </div>
        <!-- End Macro-Column 1 -->
        <!-- Macro-Column 2 -->
        <div class="column" style="padding: 0;">
          <div class="columns">
            <div class="column">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/license">Copyright</a></li>
                <li><a href="https://arxiv.org/help/policies/privacy_policy">Privacy Policy</a></li>
              </ul>
            </div>
            <div class="column sorry-app-links">
              <ul style="list-style: none; line-height: 2;">
                <li><a href="https://arxiv.org/help/web_accessibility">Web Accessibility Assistance</a></li>
                <li>
                  <p class="help">
                    <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
                    Get status notifications via
                    <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
                    or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
                  </p>
                </li>
              </ul>
            </div>
          </div>
        </div> <!-- end MetaColumn 2 -->
        <!-- End Macro-Column 2 -->
      </div>
    </footer>
</body>
</html>
